import{S as Te,i as $e,s as ke,e as n,k as l,w as $,t as k,M as Ne,c as i,d as o,m as p,a,x as N,h as P,b as m,F as t,g as F,y as L,L as Pe,q as E,o as A,B as W}from"../../chunks/vendor-19e06bd2.js";import{D as Y}from"../../chunks/Docstring-395e5a9c.js";import{I as Re}from"../../chunks/IconCopyLink-3c713d38.js";function Fe(Z){let u,T,s,d,I,b,ee,D,te,q,h,f,X,v,oe,S,ne,B,r,z,ie,H,ae,re,_,y,me,U,se,le,x,w,pe,C,de,ue,O,R,ce,G,he,V;return b=new Re({}),v=new Re({}),z=new Y({props:{name:"class optimum.onnxruntime.ORTOptimizer",anchor:"optimum.onnxruntime.ORTOptimizer",parameters:[{name:"ort_config",val:": typing.Union[str, optimum.onnxruntime.configuration.ORTConfig]"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/pr_100/src/optimum/onnxruntime/optimization.py#L43"}}),y=new Y({props:{name:"export",anchor:"optimum.onnxruntime.ORTOptimizer.export",parameters:[{name:"model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"output_path",val:": typing.Union[str, os.PathLike]"},{name:"feature",val:": str = 'default'"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/pr_100/src/optimum/onnxruntime/optimization.py#L86",parametersDescription:[{anchor:"optimum.onnxruntime.ORTOptimizer.export.model_name_or_path",description:`<strong>model_name_or_path</strong> (<em>Union[str, os.PathLike]</em>) &#x2014;
Repository name in the Hugging Face Hub or path to a local directory hosting the model.`,name:"model_name_or_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.output_path",description:`<strong>output_path</strong> (<em>os.PathLike</em>) &#x2014;
The path used to save the model exported to an ONNX Intermediate Representation (IR).`,name:"output_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.feature",description:`<strong>feature</strong> (<em>str</em>, defaults to <em>&#x201C;default&#x201D;</em>) &#x2014;
Feature to use when exporting the model.`,name:"feature"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>) &#x2014;
The specific version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"}]}}),w=new Y({props:{name:"fit",anchor:"optimum.onnxruntime.ORTOptimizer.fit",parameters:[{name:"model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"output_dir",val:": typing.Union[str, os.PathLike]"},{name:"feature",val:": str = 'default'"},{name:"config",val:": typing.Optional[transformers.configuration_utils.PretrainedConfig] = None"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/pr_100/src/optimum/onnxruntime/optimization.py#L139",parametersDescription:[{anchor:"optimum.onnxruntime.ORTOptimizer.fit.model_name_or_path",description:`<strong>model_name_or_path</strong> (<em>Union[str, os.PathLike]</em>) &#x2014;
Repository name in the Hugging Face Hub, path to a local directory hosting the model or path to a
pre-existing onnx model.`,name:"model_name_or_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.output_dir",description:`<strong>output_dir</strong> (<em>Union[str, os.PathLike]</em>) &#x2014;
The output directory where the optimized model will be saved.`,name:"output_dir"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.feature",description:`<strong>feature</strong> (<em>str</em>, defaults to <em>&#x201C;default&#x201D;</em>) &#x2014;
Feature to use when exporting the model.`,name:"feature"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.config",description:`<strong>config</strong> (<em>PretrainedConfig</em>, <em>optional</em>) &#x2014;
A configuration associated to the pre-existing ONNX model.`,name:"config"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>) &#x2014;
The specific version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_gelu",description:`<strong>disable_gelu</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Gelu fusion.`,name:"disable_gelu"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_layer_norm",description:`<strong>disable_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable LayerNormalization fusion.`,name:"disable_layer_norm"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_attention",description:`<strong>disable_attention</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Attention fusion.`,name:"disable_attention"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_skip_layer_norm",description:`<strong>disable_skip_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable SkipLayerNormalization fusion.`,name:"disable_skip_layer_norm"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_bias_skip_layer_norm",description:`<strong>disable_bias_skip_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Add Bias and SkipLayerNormalization fusion.`,name:"disable_bias_skip_layer_norm"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_bias_gelu",description:`<strong>disable_bias_gelu</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Add Bias and Gelu/FastGelu fusion.`,name:"disable_bias_gelu"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.enable_gelu_approximation",description:`<strong>enable_gelu_approximation</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to enable Gelu/BiasGelu to FastGelu conversion. The default value
is set to <em>False</em> since the approximation might slightly impact the accuracy of
models.`,name:"enable_gelu_approximation"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.use_mask_index",description:`<strong>use_mask_index</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to use mask index instead of raw attention mask in attention operator.`,name:"use_mask_index"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.no_attention_mask",description:`<strong>no_attention_mask</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
No attention mask. Only works for <em>model_type=bert</em>.`,name:"no_attention_mask"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_embed_layer_norm",description:`<strong>disable_embed_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>True</em>) &#x2014;
Whether or not to disable EmbedLayerNormalization fusion. The default value is set to
<em>True</em> since the fusion is incompatible with ONNX Runtime quantization.`,name:"disable_embed_layer_norm"}]}}),R=new Y({props:{name:"get_optimize_details",anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details",parameters:[{name:"onnx_model_path",val:": typing.Optional[str] = None"},{name:"optimized_model_path",val:": typing.Optional[str] = None"},{name:"summary",val:": bool = True"},{name:"nodes_details",val:": bool = True"}],source:"https://github.com/huggingface/optimum/blob/pr_100/src/optimum/onnxruntime/optimization.py#L253",parametersDescription:[{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.onnx_model_path",description:`<strong>onnx_model_path</strong> (<code>str</code>, <code>optional</code>) &#x2014;
Path of a stored ONNX model.`,name:"onnx_model_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.optimized_model_path",description:`<strong>optimized_model_path</strong> (<code>str</code>, <code>optional</code>) &#x2014;
Path of the corresponding optimized ONNX model.`,name:"optimized_model_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.summary",description:`<strong>summary</strong> (<code>bool</code>, defaults to <code>True</code>) &#x2014;
Whether report the optimization details: reduction of nodes, and complex node fusions.`,name:"summary"},{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.nodes_details",description:`<strong>nodes_details</strong> (<code>bool</code>, defaults to <code>True</code>) &#x2014;
Whether report the top 5 reduced op_types, and return the detailed node change list.`,name:"nodes_details"}],returnDescription:`
<p>Returns a sorted list with op types and its change after the optimization.</p>
`,returnType:`
<p>sorted_nodes_change (<code>List[Tuple[str, int]]</code>)</p>
`}}),{c(){u=n("meta"),T=l(),s=n("h1"),d=n("a"),I=n("span"),$(b.$$.fragment),ee=l(),D=n("span"),te=k("Optimization"),q=l(),h=n("h2"),f=n("a"),X=n("span"),$(v.$$.fragment),oe=l(),S=n("span"),ne=k("ORTOptimizer"),B=l(),r=n("div"),$(z.$$.fragment),ie=l(),H=n("p"),ae=k("Handles the ONNX Runtime optimization process for models shared on huggingface.co/models."),re=l(),_=n("div"),$(y.$$.fragment),me=l(),U=n("p"),se=k("Loads and exports a model to an ONNX Intermediate Representation (IR)."),le=l(),x=n("div"),$(w.$$.fragment),pe=l(),C=n("p"),de=k("Applies the ONNX Runtime graph-level optimization on a given model and saves the resulting model."),ue=l(),O=n("div"),$(R.$$.fragment),ce=l(),G=n("p"),he=k("Returns a dictionary reporting the optimization."),this.h()},l(e){const g=Ne('[data-svelte="svelte-1phssyn"]',document.head);u=i(g,"META",{name:!0,content:!0}),g.forEach(o),T=p(e),s=i(e,"H1",{class:!0});var M=a(s);d=i(M,"A",{id:!0,class:!0,href:!0});var ge=a(d);I=i(ge,"SPAN",{});var fe=a(I);N(b.$$.fragment,fe),fe.forEach(o),ge.forEach(o),ee=p(M),D=i(M,"SPAN",{});var _e=a(D);te=P(_e,"Optimization"),_e.forEach(o),M.forEach(o),q=p(e),h=i(e,"H2",{class:!0});var J=a(h);f=i(J,"A",{id:!0,class:!0,href:!0});var xe=a(f);X=i(xe,"SPAN",{});var Oe=a(X);N(v.$$.fragment,Oe),Oe.forEach(o),xe.forEach(o),oe=p(J),S=i(J,"SPAN",{});var be=a(S);ne=P(be,"ORTOptimizer"),be.forEach(o),J.forEach(o),B=p(e),r=i(e,"DIV",{class:!0});var c=a(r);N(z.$$.fragment,c),ie=p(c),H=i(c,"P",{});var ve=a(H);ae=P(ve,"Handles the ONNX Runtime optimization process for models shared on huggingface.co/models."),ve.forEach(o),re=p(c),_=i(c,"DIV",{class:!0});var j=a(_);N(y.$$.fragment,j),me=p(j),U=i(j,"P",{});var ze=a(U);se=P(ze,"Loads and exports a model to an ONNX Intermediate Representation (IR)."),ze.forEach(o),j.forEach(o),le=p(c),x=i(c,"DIV",{class:!0});var K=a(x);N(w.$$.fragment,K),pe=p(K),C=i(K,"P",{});var ye=a(C);de=P(ye,"Applies the ONNX Runtime graph-level optimization on a given model and saves the resulting model."),ye.forEach(o),K.forEach(o),ue=p(c),O=i(c,"DIV",{class:!0});var Q=a(O);N(R.$$.fragment,Q),ce=p(Q),G=i(Q,"P",{});var we=a(G);he=P(we,"Returns a dictionary reporting the optimization."),we.forEach(o),Q.forEach(o),c.forEach(o),this.h()},h(){m(u,"name","hf:doc:metadata"),m(u,"content",JSON.stringify(Le)),m(d,"id","optimization"),m(d,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(d,"href","#optimization"),m(s,"class","relative group"),m(f,"id","optimum.onnxruntime.ORTOptimizer"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#optimum.onnxruntime.ORTOptimizer"),m(h,"class","relative group"),m(_,"class","docstring"),m(x,"class","docstring"),m(O,"class","docstring"),m(r,"class","docstring")},m(e,g){t(document.head,u),F(e,T,g),F(e,s,g),t(s,d),t(d,I),L(b,I,null),t(s,ee),t(s,D),t(D,te),F(e,q,g),F(e,h,g),t(h,f),t(f,X),L(v,X,null),t(h,oe),t(h,S),t(S,ne),F(e,B,g),F(e,r,g),L(z,r,null),t(r,ie),t(r,H),t(H,ae),t(r,re),t(r,_),L(y,_,null),t(_,me),t(_,U),t(U,se),t(r,le),t(r,x),L(w,x,null),t(x,pe),t(x,C),t(C,de),t(r,ue),t(r,O),L(R,O,null),t(O,ce),t(O,G),t(G,he),V=!0},p:Pe,i(e){V||(E(b.$$.fragment,e),E(v.$$.fragment,e),E(z.$$.fragment,e),E(y.$$.fragment,e),E(w.$$.fragment,e),E(R.$$.fragment,e),V=!0)},o(e){A(b.$$.fragment,e),A(v.$$.fragment,e),A(z.$$.fragment,e),A(y.$$.fragment,e),A(w.$$.fragment,e),A(R.$$.fragment,e),V=!1},d(e){o(u),e&&o(T),e&&o(s),W(b),e&&o(q),e&&o(h),W(v),e&&o(B),e&&o(r),W(z),W(y),W(w),W(R)}}}const Le={local:"optimization",sections:[{local:"optimum.onnxruntime.ORTOptimizer",title:"ORTOptimizer"}],title:"Optimization"};function Ee(Z,u,T){let{fw:s}=u;return Z.$$set=d=>{"fw"in d&&T(0,s=d.fw)},[s]}class De extends Te{constructor(u){super();$e(this,u,Ee,Fe,ke,{fw:0})}}export{De as default,Le as metadata};
