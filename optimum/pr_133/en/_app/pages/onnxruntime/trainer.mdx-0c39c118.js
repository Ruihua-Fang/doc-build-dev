import{S as Gn,i as Qn,s as Zn,H as ea,e as a,c as r,a as o,d as t,b as u,g as N,I as ta,J as na,K as aa,q as b,o as T,k as c,w as x,t as i,M as ra,m as d,x as O,h as s,F as e,y as k,B as E,v as oa}from"../../chunks/vendor-19e06bd2.js";import{D}from"../../chunks/Docstring-395e5a9c.js";import{I as xn}from"../../chunks/IconCopyLink-3c713d38.js";function ia(_){let m,g;const h=_[3].default,l=ea(h,_,_[2],null);return{c(){m=a("div"),l&&l.c(),this.h()},l(p){m=r(p,"DIV",{class:!0});var v=o(m);l&&l.l(v),v.forEach(t),this.h()},h(){u(m,"class","course-tip "+(_[0]==="orange"?"course-tip-orange":"")+" bg-gradient-to-br dark:bg-gradient-to-r before:border-"+_[0]+"-500 dark:before:border-"+_[0]+"-800 from-"+_[0]+"-50 dark:from-gray-900 to-white dark:to-gray-950 border border-"+_[0]+"-50 text-"+_[0]+"-700 dark:text-gray-400")},m(p,v){N(p,m,v),l&&l.m(m,null),g=!0},p(p,[v]){l&&l.p&&(!g||v&4)&&ta(l,h,p,p[2],g?aa(h,p[2],v,null):na(p[2]),null)},i(p){g||(b(l,p),g=!0)},o(p){T(l,p),g=!1},d(p){p&&t(m),l&&l.d(p)}}}function sa(_,m,g){let{$$slots:h={},$$scope:l}=m,{warning:p=!1}=m;const v=p?"orange":"green";return _.$$set=V=>{"warning"in V&&g(1,p=V.warning),"$$scope"in V&&g(2,l=V.$$scope)},[v,p,l,h]}class la extends Gn{constructor(m){super();Qn(this,m,sa,ia,Zn,{warning:1})}}function ma(_){let m,g;return{c(){m=a("p"),g=i(`If your predictions or labels have different sequence lengths (for instance because you\u2019re doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`)},l(h){m=r(h,"P",{});var l=o(m);g=s(l,`If your predictions or labels have different sequence lengths (for instance because you\u2019re doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`),l.forEach(t)},m(h,l){N(h,m,l),e(m,g)},d(h){h&&t(m)}}}function ca(_){let m,g,h,l,p,v,V,$e,mt,We,S,U,we,G,ct,xe,dt,Xe,f,Q,pt,F,Z,ut,Oe,ht,ft,H,ee,gt,te,_t,ke,vt,yt,bt,W,ne,Tt,P,$t,Ee,wt,xt,Ne,Ot,kt,Et,X,ae,Nt,re,qt,qe,Rt,Dt,St,B,oe,Pt,L,Lt,Re,It,Ct,De,At,Mt,zt,j,ie,Vt,Se,Ut,Be,I,J,Pe,se,Ft,Le,Ht,je,q,le,Wt,Y,me,Xt,ce,Bt,Ie,jt,Jt,Yt,$,de,Kt,pe,Gt,Ce,Qt,Zt,en,K,tn,ue,nn,Ae,an,rn,on,C,A,sn,Me,ln,mn,ze,cn,dn,pn,M,un,Ve,hn,fn,Ue,gn,_n,vn,z,yn,Fe,bn,Tn,He,$n,wn,Je;return v=new xn({}),G=new xn({}),Q=new D({props:{name:"class optimum.onnxruntime.ORTTrainer",anchor:"optimum.onnxruntime.ORTTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer.py#L122"}}),Z=new D({props:{name:"compute_loss_ort",anchor:"optimum.onnxruntime.ORTTrainer.compute_loss_ort",parameters:[{name:"model",val:""},{name:"inputs",val:""},{name:"input_names",val:""},{name:"output_names",val:""},{name:"return_outputs",val:" = False"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer.py#L1213"}}),ee=new D({props:{name:"evaluate",anchor:"optimum.onnxruntime.ORTTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer.py#L645"}}),ne=new D({props:{name:"evaluation_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.evaluation_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer.py#L773"}}),ae=new D({props:{name:"predict",anchor:"optimum.onnxruntime.ORTTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'test'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer.py#L717"}}),oe=new D({props:{name:"prediction_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.prediction_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer.py#L972"}}),ie=new D({props:{name:"train",anchor:"optimum.onnxruntime.ORTTrainer.train",parameters:[{name:"resume_from_checkpoint",val:": typing.Union[str, bool, NoneType] = None"},{name:"trial",val:": typing.Union[ForwardRef('optuna.Trial'), typing.Dict[str, typing.Any]] = None"},{name:"ignore_keys_for_eval",val:": typing.Optional[typing.List[str]] = None"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer.py#L159",parametersDescription:[{anchor:"optimum.onnxruntime.ORTTrainer.train.resume_from_checkpoint",description:`<strong>resume_from_checkpoint</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
If a <code>str</code>, local path to a saved checkpoint as saved by a previous instance of <code>Trainer</code>. If a
<code>bool</code> and equals <code>True</code>, load the last checkpoint in <em>args.output_dir</em> as saved by a previous instance
of <code>Trainer</code>. If present, training will resume from the model/optimizer/scheduler states loaded here.`,name:"resume_from_checkpoint"},{anchor:"optimum.onnxruntime.ORTTrainer.train.trial",description:`<strong>trial</strong> (<code>optuna.Trial</code> or <code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The trial run or the hyperparameter dictionary for hyperparameter search.`,name:"trial"},{anchor:"optimum.onnxruntime.ORTTrainer.train.ignore_keys_for_eval",description:`<strong>ignore_keys_for_eval</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions for evaluation during the training.
kwargs &#x2014;
Additional keyword arguments used to hide deprecated arguments`,name:"ignore_keys_for_eval"}]}}),se=new xn({}),le=new D({props:{name:"class optimum.onnxruntime.Seq2SeqORTTrainer",anchor:"optimum.onnxruntime.Seq2SeqORTTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer_seq2seq.py#L40"}}),me=new D({props:{name:"evaluate",anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"num_beams",val:": typing.Optional[int] = None"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer_seq2seq.py#L41",parametersDescription:[{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.eval_dataset",description:`<strong>eval_dataset</strong> (<code>Dataset</code>, <em>optional</em>) &#x2014;
Pass a dataset if you wish to override <code>self.eval_dataset</code>. If it is an <code>datasets.Dataset</code>,
columns not accepted by the <code>model.forward()</code> method are automatically removed. It must implement the
<code>__len__</code> method.`,name:"eval_dataset"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.`,name:"num_beams"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.inference_with_ort",description:`<strong>inference_with_ort</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.`,name:"inference_with_ort"}],returnDescription:`
<p>A dictionary containing the evaluation loss(only within PyTorch) and the potential metrics computed from the predictions. The
dictionary also contains the epoch number which comes from the training state.</p>
`}}),de=new D({props:{name:"predict",anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"num_beams",val:": typing.Optional[int] = None"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_133/src/optimum/onnxruntime/trainer_seq2seq.py#L90",parametersDescription:[{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.test_dataset",description:`<strong>test_dataset</strong> (<code>Dataset</code>) &#x2014;
Dataset to run the predictions on. If it is an <code>datasets.Dataset</code>, columns not accepted by the
<code>model.forward()</code> method are automatically removed. Has to implement the method <code>__len__</code>`,name:"test_dataset"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.`,name:"num_beams"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.inference_with_ort",description:`<strong>inference_with_ort</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.`,name:"inference_with_ort"}]}}),K=new la({props:{$$slots:{default:[ma]},$$scope:{ctx:_}}}),{c(){m=a("meta"),g=c(),h=a("h1"),l=a("a"),p=a("span"),x(v.$$.fragment),V=c(),$e=a("span"),mt=i("Trainer"),We=c(),S=a("h2"),U=a("a"),we=a("span"),x(G.$$.fragment),ct=c(),xe=a("span"),dt=i("ORTTrainer"),Xe=c(),f=a("div"),x(Q.$$.fragment),pt=c(),F=a("div"),x(Z.$$.fragment),ut=c(),Oe=a("p"),ht=i(`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),ft=c(),H=a("div"),x(ee.$$.fragment),gt=c(),te=a("p"),_t=i("Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),ke=a("code"),vt=i("Trainer.evaluate()"),yt=i(")"),bt=c(),W=a("div"),x(ne.$$.fragment),Tt=c(),P=a("p"),$t=i("Prediction/evaluation loop, shared by "),Ee=a("code"),wt=i("ORTTrainer.evaluate()"),xt=i(" and "),Ne=a("code"),Ot=i("ORTTrainer.predict()"),kt=i(`.
Works both with or without labels.`),Et=c(),X=a("div"),x(ae.$$.fragment),Nt=c(),re=a("p"),qt=i(`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),qe=a("code"),Rt=i("Trainer.predict()"),Dt=i(")"),St=c(),B=a("div"),x(oe.$$.fragment),Pt=c(),L=a("p"),Lt=i("Prediction/evaluation loop, shared by "),Re=a("code"),It=i("Trainer.evaluate()"),Ct=i(" and "),De=a("code"),At=i("Trainer.predict()"),Mt=i(`.
Works both with or without labels.`),zt=c(),j=a("div"),x(ie.$$.fragment),Vt=c(),Se=a("p"),Ut=i("Main onnxruntime training entry point."),Be=c(),I=a("h2"),J=a("a"),Pe=a("span"),x(se.$$.fragment),Ft=c(),Le=a("span"),Ht=i("Seq2SeqORTTrainer"),je=c(),q=a("div"),x(le.$$.fragment),Wt=c(),Y=a("div"),x(me.$$.fragment),Xt=c(),ce=a("p"),Bt=i(`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Ie=a("code"),jt=i("compute_metrics"),Jt=i(` argument).
You can also subclass and override this method to inject custom behavior.`),Yt=c(),$=a("div"),x(de.$$.fragment),Kt=c(),pe=a("p"),Gt=i(`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Ce=a("code"),Qt=i("evaluate()"),Zt=i("."),en=c(),x(K.$$.fragment),tn=c(),ue=a("p"),nn=i("Returns: "),Ae=a("em"),an=i("NamedTuple"),rn=i(" A namedtuple with the following keys:"),on=c(),C=a("ul"),A=a("li"),sn=i("predictions ("),Me=a("code"),ln=i("np.ndarray"),mn=i("): The predictions on "),ze=a("code"),cn=i("test_dataset"),dn=i("."),pn=c(),M=a("li"),un=i("label_ids ("),Ve=a("code"),hn=i("np.ndarray"),fn=i(", "),Ue=a("em"),gn=i("optional"),_n=i("): The labels (if the dataset contained some)."),vn=c(),z=a("li"),yn=i("metrics ("),Fe=a("code"),bn=i("Dict[str, float]"),Tn=i(", "),He=a("em"),$n=i("optional"),wn=i(`): The potential dictionary of metrics (if the dataset
contained labels).`),this.h()},l(n){const y=ra('[data-svelte="svelte-1phssyn"]',document.head);m=r(y,"META",{name:!0,content:!0}),y.forEach(t),g=d(n),h=r(n,"H1",{class:!0});var he=o(h);l=r(he,"A",{id:!0,class:!0,href:!0});var On=o(l);p=r(On,"SPAN",{});var kn=o(p);O(v.$$.fragment,kn),kn.forEach(t),On.forEach(t),V=d(he),$e=r(he,"SPAN",{});var En=o($e);mt=s(En,"Trainer"),En.forEach(t),he.forEach(t),We=d(n),S=r(n,"H2",{class:!0});var Ye=o(S);U=r(Ye,"A",{id:!0,class:!0,href:!0});var Nn=o(U);we=r(Nn,"SPAN",{});var qn=o(we);O(G.$$.fragment,qn),qn.forEach(t),Nn.forEach(t),ct=d(Ye),xe=r(Ye,"SPAN",{});var Rn=o(xe);dt=s(Rn,"ORTTrainer"),Rn.forEach(t),Ye.forEach(t),Xe=d(n),f=r(n,"DIV",{class:!0});var w=o(f);O(Q.$$.fragment,w),pt=d(w),F=r(w,"DIV",{class:!0});var Ke=o(F);O(Z.$$.fragment,Ke),ut=d(Ke),Oe=r(Ke,"P",{});var Dn=o(Oe);ht=s(Dn,`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),Dn.forEach(t),Ke.forEach(t),ft=d(w),H=r(w,"DIV",{class:!0});var Ge=o(H);O(ee.$$.fragment,Ge),gt=d(Ge),te=r(Ge,"P",{});var Qe=o(te);_t=s(Qe,"Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),ke=r(Qe,"CODE",{});var Sn=o(ke);vt=s(Sn,"Trainer.evaluate()"),Sn.forEach(t),yt=s(Qe,")"),Qe.forEach(t),Ge.forEach(t),bt=d(w),W=r(w,"DIV",{class:!0});var Ze=o(W);O(ne.$$.fragment,Ze),Tt=d(Ze),P=r(Ze,"P",{});var fe=o(P);$t=s(fe,"Prediction/evaluation loop, shared by "),Ee=r(fe,"CODE",{});var Pn=o(Ee);wt=s(Pn,"ORTTrainer.evaluate()"),Pn.forEach(t),xt=s(fe," and "),Ne=r(fe,"CODE",{});var Ln=o(Ne);Ot=s(Ln,"ORTTrainer.predict()"),Ln.forEach(t),kt=s(fe,`.
Works both with or without labels.`),fe.forEach(t),Ze.forEach(t),Et=d(w),X=r(w,"DIV",{class:!0});var et=o(X);O(ae.$$.fragment,et),Nt=d(et),re=r(et,"P",{});var tt=o(re);qt=s(tt,`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),qe=r(tt,"CODE",{});var In=o(qe);Rt=s(In,"Trainer.predict()"),In.forEach(t),Dt=s(tt,")"),tt.forEach(t),et.forEach(t),St=d(w),B=r(w,"DIV",{class:!0});var nt=o(B);O(oe.$$.fragment,nt),Pt=d(nt),L=r(nt,"P",{});var ge=o(L);Lt=s(ge,"Prediction/evaluation loop, shared by "),Re=r(ge,"CODE",{});var Cn=o(Re);It=s(Cn,"Trainer.evaluate()"),Cn.forEach(t),Ct=s(ge," and "),De=r(ge,"CODE",{});var An=o(De);At=s(An,"Trainer.predict()"),An.forEach(t),Mt=s(ge,`.
Works both with or without labels.`),ge.forEach(t),nt.forEach(t),zt=d(w),j=r(w,"DIV",{class:!0});var at=o(j);O(ie.$$.fragment,at),Vt=d(at),Se=r(at,"P",{});var Mn=o(Se);Ut=s(Mn,"Main onnxruntime training entry point."),Mn.forEach(t),at.forEach(t),w.forEach(t),Be=d(n),I=r(n,"H2",{class:!0});var rt=o(I);J=r(rt,"A",{id:!0,class:!0,href:!0});var zn=o(J);Pe=r(zn,"SPAN",{});var Vn=o(Pe);O(se.$$.fragment,Vn),Vn.forEach(t),zn.forEach(t),Ft=d(rt),Le=r(rt,"SPAN",{});var Un=o(Le);Ht=s(Un,"Seq2SeqORTTrainer"),Un.forEach(t),rt.forEach(t),je=d(n),q=r(n,"DIV",{class:!0});var _e=o(q);O(le.$$.fragment,_e),Wt=d(_e),Y=r(_e,"DIV",{class:!0});var ot=o(Y);O(me.$$.fragment,ot),Xt=d(ot),ce=r(ot,"P",{});var it=o(ce);Bt=s(it,`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Ie=r(it,"CODE",{});var Fn=o(Ie);jt=s(Fn,"compute_metrics"),Fn.forEach(t),Jt=s(it,` argument).
You can also subclass and override this method to inject custom behavior.`),it.forEach(t),ot.forEach(t),Yt=d(_e),$=r(_e,"DIV",{class:!0});var R=o($);O(de.$$.fragment,R),Kt=d(R),pe=r(R,"P",{});var st=o(pe);Gt=s(st,`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Ce=r(st,"CODE",{});var Hn=o(Ce);Qt=s(Hn,"evaluate()"),Hn.forEach(t),Zt=s(st,"."),st.forEach(t),en=d(R),O(K.$$.fragment,R),tn=d(R),ue=r(R,"P",{});var lt=o(ue);nn=s(lt,"Returns: "),Ae=r(lt,"EM",{});var Wn=o(Ae);an=s(Wn,"NamedTuple"),Wn.forEach(t),rn=s(lt," A namedtuple with the following keys:"),lt.forEach(t),on=d(R),C=r(R,"UL",{});var ve=o(C);A=r(ve,"LI",{});var ye=o(A);sn=s(ye,"predictions ("),Me=r(ye,"CODE",{});var Xn=o(Me);ln=s(Xn,"np.ndarray"),Xn.forEach(t),mn=s(ye,"): The predictions on "),ze=r(ye,"CODE",{});var Bn=o(ze);cn=s(Bn,"test_dataset"),Bn.forEach(t),dn=s(ye,"."),ye.forEach(t),pn=d(ve),M=r(ve,"LI",{});var be=o(M);un=s(be,"label_ids ("),Ve=r(be,"CODE",{});var jn=o(Ve);hn=s(jn,"np.ndarray"),jn.forEach(t),fn=s(be,", "),Ue=r(be,"EM",{});var Jn=o(Ue);gn=s(Jn,"optional"),Jn.forEach(t),_n=s(be,"): The labels (if the dataset contained some)."),be.forEach(t),vn=d(ve),z=r(ve,"LI",{});var Te=o(z);yn=s(Te,"metrics ("),Fe=r(Te,"CODE",{});var Yn=o(Fe);bn=s(Yn,"Dict[str, float]"),Yn.forEach(t),Tn=s(Te,", "),He=r(Te,"EM",{});var Kn=o(He);$n=s(Kn,"optional"),Kn.forEach(t),wn=s(Te,`): The potential dictionary of metrics (if the dataset
contained labels).`),Te.forEach(t),ve.forEach(t),R.forEach(t),_e.forEach(t),this.h()},h(){u(m,"name","hf:doc:metadata"),u(m,"content",JSON.stringify(da)),u(l,"id","trainer"),u(l,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(l,"href","#trainer"),u(h,"class","relative group"),u(U,"id","optimum.onnxruntime.ORTTrainer"),u(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(U,"href","#optimum.onnxruntime.ORTTrainer"),u(S,"class","relative group"),u(F,"class","docstring"),u(H,"class","docstring"),u(W,"class","docstring"),u(X,"class","docstring"),u(B,"class","docstring"),u(j,"class","docstring"),u(f,"class","docstring"),u(J,"id","optimum.onnxruntime.Seq2SeqORTTrainer"),u(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(J,"href","#optimum.onnxruntime.Seq2SeqORTTrainer"),u(I,"class","relative group"),u(Y,"class","docstring"),u($,"class","docstring"),u(q,"class","docstring")},m(n,y){e(document.head,m),N(n,g,y),N(n,h,y),e(h,l),e(l,p),k(v,p,null),e(h,V),e(h,$e),e($e,mt),N(n,We,y),N(n,S,y),e(S,U),e(U,we),k(G,we,null),e(S,ct),e(S,xe),e(xe,dt),N(n,Xe,y),N(n,f,y),k(Q,f,null),e(f,pt),e(f,F),k(Z,F,null),e(F,ut),e(F,Oe),e(Oe,ht),e(f,ft),e(f,H),k(ee,H,null),e(H,gt),e(H,te),e(te,_t),e(te,ke),e(ke,vt),e(te,yt),e(f,bt),e(f,W),k(ne,W,null),e(W,Tt),e(W,P),e(P,$t),e(P,Ee),e(Ee,wt),e(P,xt),e(P,Ne),e(Ne,Ot),e(P,kt),e(f,Et),e(f,X),k(ae,X,null),e(X,Nt),e(X,re),e(re,qt),e(re,qe),e(qe,Rt),e(re,Dt),e(f,St),e(f,B),k(oe,B,null),e(B,Pt),e(B,L),e(L,Lt),e(L,Re),e(Re,It),e(L,Ct),e(L,De),e(De,At),e(L,Mt),e(f,zt),e(f,j),k(ie,j,null),e(j,Vt),e(j,Se),e(Se,Ut),N(n,Be,y),N(n,I,y),e(I,J),e(J,Pe),k(se,Pe,null),e(I,Ft),e(I,Le),e(Le,Ht),N(n,je,y),N(n,q,y),k(le,q,null),e(q,Wt),e(q,Y),k(me,Y,null),e(Y,Xt),e(Y,ce),e(ce,Bt),e(ce,Ie),e(Ie,jt),e(ce,Jt),e(q,Yt),e(q,$),k(de,$,null),e($,Kt),e($,pe),e(pe,Gt),e(pe,Ce),e(Ce,Qt),e(pe,Zt),e($,en),k(K,$,null),e($,tn),e($,ue),e(ue,nn),e(ue,Ae),e(Ae,an),e(ue,rn),e($,on),e($,C),e(C,A),e(A,sn),e(A,Me),e(Me,ln),e(A,mn),e(A,ze),e(ze,cn),e(A,dn),e(C,pn),e(C,M),e(M,un),e(M,Ve),e(Ve,hn),e(M,fn),e(M,Ue),e(Ue,gn),e(M,_n),e(C,vn),e(C,z),e(z,yn),e(z,Fe),e(Fe,bn),e(z,Tn),e(z,He),e(He,$n),e(z,wn),Je=!0},p(n,[y]){const he={};y&2&&(he.$$scope={dirty:y,ctx:n}),K.$set(he)},i(n){Je||(b(v.$$.fragment,n),b(G.$$.fragment,n),b(Q.$$.fragment,n),b(Z.$$.fragment,n),b(ee.$$.fragment,n),b(ne.$$.fragment,n),b(ae.$$.fragment,n),b(oe.$$.fragment,n),b(ie.$$.fragment,n),b(se.$$.fragment,n),b(le.$$.fragment,n),b(me.$$.fragment,n),b(de.$$.fragment,n),b(K.$$.fragment,n),Je=!0)},o(n){T(v.$$.fragment,n),T(G.$$.fragment,n),T(Q.$$.fragment,n),T(Z.$$.fragment,n),T(ee.$$.fragment,n),T(ne.$$.fragment,n),T(ae.$$.fragment,n),T(oe.$$.fragment,n),T(ie.$$.fragment,n),T(se.$$.fragment,n),T(le.$$.fragment,n),T(me.$$.fragment,n),T(de.$$.fragment,n),T(K.$$.fragment,n),Je=!1},d(n){t(m),n&&t(g),n&&t(h),E(v),n&&t(We),n&&t(S),E(G),n&&t(Xe),n&&t(f),E(Q),E(Z),E(ee),E(ne),E(ae),E(oe),E(ie),n&&t(Be),n&&t(I),E(se),n&&t(je),n&&t(q),E(le),E(me),E(de),E(K)}}}const da={local:"trainer",sections:[{local:"optimum.onnxruntime.ORTTrainer",title:"ORTTrainer"},{local:"optimum.onnxruntime.Seq2SeqORTTrainer",title:"Seq2SeqORTTrainer"}],title:"Trainer"};function pa(_){return oa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ga extends Gn{constructor(m){super();Qn(this,m,pa,ca,Zn,{})}}export{ga as default,da as metadata};
