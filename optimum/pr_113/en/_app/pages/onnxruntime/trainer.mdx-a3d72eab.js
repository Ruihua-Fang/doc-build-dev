import{S as Kn,i as Qn,s as Zn,e as a,k as l,w as v,t as i,M as ea,c as r,d as n,m,a as o,x as _,h as s,b as c,F as e,g as O,y,q as T,o as b,B as $,v as ta}from"../../chunks/vendor-4918fc3c.js";import{T as na}from"../../chunks/Tip-3d800dd6.js";import{D as E}from"../../chunks/Docstring-1b707a93.js";import{I as wn}from"../../chunks/IconCopyLink-21d338b1.js";function aa(Fe){let p,I;return{c(){p=a("p"),I=i(`If your predictions or labels have different sequence lengths (for instance because you\u2019re doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`)},l(h){p=r(h,"P",{});var x=o(p);I=s(x,`If your predictions or labels have different sequence lengths (for instance because you\u2019re doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`),x.forEach(n)},m(h,x){O(h,p,x),e(p,I)},d(h){h&&n(p)}}}function ra(Fe){let p,I,h,x,ye,j,lt,Te,mt,He,N,A,be,Y,ct,$e,dt,We,d,J,pt,M,G,ut,xe,ht,gt,z,K,ft,Q,vt,we,_t,yt,Tt,U,Z,bt,q,$t,Oe,xt,wt,ke,Ot,kt,Et,V,ee,Nt,te,qt,Ee,Rt,Dt,St,F,ne,Pt,R,Lt,Ne,Ct,It,qe,At,Mt,zt,H,ae,Ut,Re,Vt,Xe,D,W,De,re,Ft,Se,Ht,Be,w,oe,Wt,X,ie,Xt,se,Bt,Pe,jt,Yt,Jt,g,le,Gt,me,Kt,Le,Qt,Zt,en,B,tn,ce,nn,Ce,an,rn,on,S,P,sn,Ie,ln,mn,Ae,cn,dn,pn,L,un,Me,hn,gn,ze,fn,vn,_n,C,yn,Ue,Tn,bn,Ve,$n,xn,je;return j=new wn({}),Y=new wn({}),J=new E({props:{name:"class optimum.onnxruntime.ORTTrainer",anchor:"optimum.onnxruntime.ORTTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer.py#L122"}}),G=new E({props:{name:"compute_loss_ort",anchor:"optimum.onnxruntime.ORTTrainer.compute_loss_ort",parameters:[{name:"model",val:""},{name:"inputs",val:""},{name:"input_names",val:""},{name:"output_names",val:""},{name:"return_outputs",val:" = False"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer.py#L1213"}}),K=new E({props:{name:"evaluate",anchor:"optimum.onnxruntime.ORTTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer.py#L645"}}),Z=new E({props:{name:"evaluation_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.evaluation_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer.py#L773"}}),ee=new E({props:{name:"predict",anchor:"optimum.onnxruntime.ORTTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'test'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer.py#L717"}}),ne=new E({props:{name:"prediction_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.prediction_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer.py#L972"}}),ae=new E({props:{name:"train",anchor:"optimum.onnxruntime.ORTTrainer.train",parameters:[{name:"resume_from_checkpoint",val:": typing.Union[bool, str, NoneType] = None"},{name:"trial",val:": typing.Union[ForwardRef('optuna.Trial'), typing.Dict[str, typing.Any]] = None"},{name:"ignore_keys_for_eval",val:": typing.Optional[typing.List[str]] = None"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer.py#L159",parametersDescription:[{anchor:"optimum.onnxruntime.ORTTrainer.train.resume_from_checkpoint",description:`<strong>resume_from_checkpoint</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
If a <code>str</code>, local path to a saved checkpoint as saved by a previous instance of <code>Trainer</code>. If a
<code>bool</code> and equals <code>True</code>, load the last checkpoint in <em>args.output_dir</em> as saved by a previous instance
of <code>Trainer</code>. If present, training will resume from the model/optimizer/scheduler states loaded here.`,name:"resume_from_checkpoint"},{anchor:"optimum.onnxruntime.ORTTrainer.train.trial",description:`<strong>trial</strong> (<code>optuna.Trial</code> or <code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The trial run or the hyperparameter dictionary for hyperparameter search.`,name:"trial"},{anchor:"optimum.onnxruntime.ORTTrainer.train.ignore_keys_for_eval",description:`<strong>ignore_keys_for_eval</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions for evaluation during the training.
kwargs &#x2014;
Additional keyword arguments used to hide deprecated arguments`,name:"ignore_keys_for_eval"}]}}),re=new wn({}),oe=new E({props:{name:"class optimum.onnxruntime.Seq2SeqORTTrainer",anchor:"optimum.onnxruntime.Seq2SeqORTTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer_seq2seq.py#L40"}}),ie=new E({props:{name:"evaluate",anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"num_beams",val:": typing.Optional[int] = None"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer_seq2seq.py#L41",parametersDescription:[{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.eval_dataset",description:`<strong>eval_dataset</strong> (<code>Dataset</code>, <em>optional</em>) &#x2014;
Pass a dataset if you wish to override <code>self.eval_dataset</code>. If it is an <code>datasets.Dataset</code>,
columns not accepted by the <code>model.forward()</code> method are automatically removed. It must implement the
<code>__len__</code> method.`,name:"eval_dataset"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.`,name:"num_beams"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.evaluate.inference_with_ort",description:`<strong>inference_with_ort</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.`,name:"inference_with_ort"}],returnDescription:`
<p>A dictionary containing the evaluation loss(only within PyTorch) and the potential metrics computed from the predictions. The
dictionary also contains the epoch number which comes from the training state.</p>
`}}),le=new E({props:{name:"predict",anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"num_beams",val:": typing.Optional[int] = None"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/pr_113/src/optimum/onnxruntime/trainer_seq2seq.py#L90",parametersDescription:[{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.test_dataset",description:`<strong>test_dataset</strong> (<code>Dataset</code>) &#x2014;
Dataset to run the predictions on. If it is an <code>datasets.Dataset</code>, columns not accepted by the
<code>model.forward()</code> method are automatically removed. Has to implement the method <code>__len__</code>`,name:"test_dataset"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.`,name:"num_beams"},{anchor:"optimum.onnxruntime.Seq2SeqORTTrainer.predict.inference_with_ort",description:`<strong>inference_with_ort</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.`,name:"inference_with_ort"}]}}),B=new na({props:{$$slots:{default:[aa]},$$scope:{ctx:Fe}}}),{c(){p=a("meta"),I=l(),h=a("h1"),x=a("a"),ye=a("span"),v(j.$$.fragment),lt=l(),Te=a("span"),mt=i("Trainer"),He=l(),N=a("h2"),A=a("a"),be=a("span"),v(Y.$$.fragment),ct=l(),$e=a("span"),dt=i("ORTTrainer"),We=l(),d=a("div"),v(J.$$.fragment),pt=l(),M=a("div"),v(G.$$.fragment),ut=l(),xe=a("p"),ht=i(`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),gt=l(),z=a("div"),v(K.$$.fragment),ft=l(),Q=a("p"),vt=i("Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),we=a("code"),_t=i("Trainer.evaluate()"),yt=i(")"),Tt=l(),U=a("div"),v(Z.$$.fragment),bt=l(),q=a("p"),$t=i("Prediction/evaluation loop, shared by "),Oe=a("code"),xt=i("ORTTrainer.evaluate()"),wt=i(" and "),ke=a("code"),Ot=i("ORTTrainer.predict()"),kt=i(`.
Works both with or without labels.`),Et=l(),V=a("div"),v(ee.$$.fragment),Nt=l(),te=a("p"),qt=i(`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),Ee=a("code"),Rt=i("Trainer.predict()"),Dt=i(")"),St=l(),F=a("div"),v(ne.$$.fragment),Pt=l(),R=a("p"),Lt=i("Prediction/evaluation loop, shared by "),Ne=a("code"),Ct=i("Trainer.evaluate()"),It=i(" and "),qe=a("code"),At=i("Trainer.predict()"),Mt=i(`.
Works both with or without labels.`),zt=l(),H=a("div"),v(ae.$$.fragment),Ut=l(),Re=a("p"),Vt=i("Main onnxruntime training entry point."),Xe=l(),D=a("h2"),W=a("a"),De=a("span"),v(re.$$.fragment),Ft=l(),Se=a("span"),Ht=i("Seq2SeqORTTrainer"),Be=l(),w=a("div"),v(oe.$$.fragment),Wt=l(),X=a("div"),v(ie.$$.fragment),Xt=l(),se=a("p"),Bt=i(`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Pe=a("code"),jt=i("compute_metrics"),Yt=i(` argument).
You can also subclass and override this method to inject custom behavior.`),Jt=l(),g=a("div"),v(le.$$.fragment),Gt=l(),me=a("p"),Kt=i(`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Le=a("code"),Qt=i("evaluate()"),Zt=i("."),en=l(),v(B.$$.fragment),tn=l(),ce=a("p"),nn=i("Returns: "),Ce=a("em"),an=i("NamedTuple"),rn=i(" A namedtuple with the following keys:"),on=l(),S=a("ul"),P=a("li"),sn=i("predictions ("),Ie=a("code"),ln=i("np.ndarray"),mn=i("): The predictions on "),Ae=a("code"),cn=i("test_dataset"),dn=i("."),pn=l(),L=a("li"),un=i("label_ids ("),Me=a("code"),hn=i("np.ndarray"),gn=i(", "),ze=a("em"),fn=i("optional"),vn=i("): The labels (if the dataset contained some)."),_n=l(),C=a("li"),yn=i("metrics ("),Ue=a("code"),Tn=i("Dict[str, float]"),bn=i(", "),Ve=a("em"),$n=i("optional"),xn=i(`): The potential dictionary of metrics (if the dataset
contained labels).`),this.h()},l(t){const u=ea('[data-svelte="svelte-1phssyn"]',document.head);p=r(u,"META",{name:!0,content:!0}),u.forEach(n),I=m(t),h=r(t,"H1",{class:!0});var de=o(h);x=r(de,"A",{id:!0,class:!0,href:!0});var On=o(x);ye=r(On,"SPAN",{});var kn=o(ye);_(j.$$.fragment,kn),kn.forEach(n),On.forEach(n),lt=m(de),Te=r(de,"SPAN",{});var En=o(Te);mt=s(En,"Trainer"),En.forEach(n),de.forEach(n),He=m(t),N=r(t,"H2",{class:!0});var Ye=o(N);A=r(Ye,"A",{id:!0,class:!0,href:!0});var Nn=o(A);be=r(Nn,"SPAN",{});var qn=o(be);_(Y.$$.fragment,qn),qn.forEach(n),Nn.forEach(n),ct=m(Ye),$e=r(Ye,"SPAN",{});var Rn=o($e);dt=s(Rn,"ORTTrainer"),Rn.forEach(n),Ye.forEach(n),We=m(t),d=r(t,"DIV",{class:!0});var f=o(d);_(J.$$.fragment,f),pt=m(f),M=r(f,"DIV",{class:!0});var Je=o(M);_(G.$$.fragment,Je),ut=m(Je),xe=r(Je,"P",{});var Dn=o(xe);ht=s(Dn,`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),Dn.forEach(n),Je.forEach(n),gt=m(f),z=r(f,"DIV",{class:!0});var Ge=o(z);_(K.$$.fragment,Ge),ft=m(Ge),Q=r(Ge,"P",{});var Ke=o(Q);vt=s(Ke,"Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),we=r(Ke,"CODE",{});var Sn=o(we);_t=s(Sn,"Trainer.evaluate()"),Sn.forEach(n),yt=s(Ke,")"),Ke.forEach(n),Ge.forEach(n),Tt=m(f),U=r(f,"DIV",{class:!0});var Qe=o(U);_(Z.$$.fragment,Qe),bt=m(Qe),q=r(Qe,"P",{});var pe=o(q);$t=s(pe,"Prediction/evaluation loop, shared by "),Oe=r(pe,"CODE",{});var Pn=o(Oe);xt=s(Pn,"ORTTrainer.evaluate()"),Pn.forEach(n),wt=s(pe," and "),ke=r(pe,"CODE",{});var Ln=o(ke);Ot=s(Ln,"ORTTrainer.predict()"),Ln.forEach(n),kt=s(pe,`.
Works both with or without labels.`),pe.forEach(n),Qe.forEach(n),Et=m(f),V=r(f,"DIV",{class:!0});var Ze=o(V);_(ee.$$.fragment,Ze),Nt=m(Ze),te=r(Ze,"P",{});var et=o(te);qt=s(et,`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),Ee=r(et,"CODE",{});var Cn=o(Ee);Rt=s(Cn,"Trainer.predict()"),Cn.forEach(n),Dt=s(et,")"),et.forEach(n),Ze.forEach(n),St=m(f),F=r(f,"DIV",{class:!0});var tt=o(F);_(ne.$$.fragment,tt),Pt=m(tt),R=r(tt,"P",{});var ue=o(R);Lt=s(ue,"Prediction/evaluation loop, shared by "),Ne=r(ue,"CODE",{});var In=o(Ne);Ct=s(In,"Trainer.evaluate()"),In.forEach(n),It=s(ue," and "),qe=r(ue,"CODE",{});var An=o(qe);At=s(An,"Trainer.predict()"),An.forEach(n),Mt=s(ue,`.
Works both with or without labels.`),ue.forEach(n),tt.forEach(n),zt=m(f),H=r(f,"DIV",{class:!0});var nt=o(H);_(ae.$$.fragment,nt),Ut=m(nt),Re=r(nt,"P",{});var Mn=o(Re);Vt=s(Mn,"Main onnxruntime training entry point."),Mn.forEach(n),nt.forEach(n),f.forEach(n),Xe=m(t),D=r(t,"H2",{class:!0});var at=o(D);W=r(at,"A",{id:!0,class:!0,href:!0});var zn=o(W);De=r(zn,"SPAN",{});var Un=o(De);_(re.$$.fragment,Un),Un.forEach(n),zn.forEach(n),Ft=m(at),Se=r(at,"SPAN",{});var Vn=o(Se);Ht=s(Vn,"Seq2SeqORTTrainer"),Vn.forEach(n),at.forEach(n),Be=m(t),w=r(t,"DIV",{class:!0});var he=o(w);_(oe.$$.fragment,he),Wt=m(he),X=r(he,"DIV",{class:!0});var rt=o(X);_(ie.$$.fragment,rt),Xt=m(rt),se=r(rt,"P",{});var ot=o(se);Bt=s(ot,`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Pe=r(ot,"CODE",{});var Fn=o(Pe);jt=s(Fn,"compute_metrics"),Fn.forEach(n),Yt=s(ot,` argument).
You can also subclass and override this method to inject custom behavior.`),ot.forEach(n),rt.forEach(n),Jt=m(he),g=r(he,"DIV",{class:!0});var k=o(g);_(le.$$.fragment,k),Gt=m(k),me=r(k,"P",{});var it=o(me);Kt=s(it,`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Le=r(it,"CODE",{});var Hn=o(Le);Qt=s(Hn,"evaluate()"),Hn.forEach(n),Zt=s(it,"."),it.forEach(n),en=m(k),_(B.$$.fragment,k),tn=m(k),ce=r(k,"P",{});var st=o(ce);nn=s(st,"Returns: "),Ce=r(st,"EM",{});var Wn=o(Ce);an=s(Wn,"NamedTuple"),Wn.forEach(n),rn=s(st," A namedtuple with the following keys:"),st.forEach(n),on=m(k),S=r(k,"UL",{});var ge=o(S);P=r(ge,"LI",{});var fe=o(P);sn=s(fe,"predictions ("),Ie=r(fe,"CODE",{});var Xn=o(Ie);ln=s(Xn,"np.ndarray"),Xn.forEach(n),mn=s(fe,"): The predictions on "),Ae=r(fe,"CODE",{});var Bn=o(Ae);cn=s(Bn,"test_dataset"),Bn.forEach(n),dn=s(fe,"."),fe.forEach(n),pn=m(ge),L=r(ge,"LI",{});var ve=o(L);un=s(ve,"label_ids ("),Me=r(ve,"CODE",{});var jn=o(Me);hn=s(jn,"np.ndarray"),jn.forEach(n),gn=s(ve,", "),ze=r(ve,"EM",{});var Yn=o(ze);fn=s(Yn,"optional"),Yn.forEach(n),vn=s(ve,"): The labels (if the dataset contained some)."),ve.forEach(n),_n=m(ge),C=r(ge,"LI",{});var _e=o(C);yn=s(_e,"metrics ("),Ue=r(_e,"CODE",{});var Jn=o(Ue);Tn=s(Jn,"Dict[str, float]"),Jn.forEach(n),bn=s(_e,", "),Ve=r(_e,"EM",{});var Gn=o(Ve);$n=s(Gn,"optional"),Gn.forEach(n),xn=s(_e,`): The potential dictionary of metrics (if the dataset
contained labels).`),_e.forEach(n),ge.forEach(n),k.forEach(n),he.forEach(n),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(oa)),c(x,"id","trainer"),c(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x,"href","#trainer"),c(h,"class","relative group"),c(A,"id","optimum.onnxruntime.ORTTrainer"),c(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A,"href","#optimum.onnxruntime.ORTTrainer"),c(N,"class","relative group"),c(M,"class","docstring"),c(z,"class","docstring"),c(U,"class","docstring"),c(V,"class","docstring"),c(F,"class","docstring"),c(H,"class","docstring"),c(d,"class","docstring"),c(W,"id","optimum.onnxruntime.Seq2SeqORTTrainer"),c(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W,"href","#optimum.onnxruntime.Seq2SeqORTTrainer"),c(D,"class","relative group"),c(X,"class","docstring"),c(g,"class","docstring"),c(w,"class","docstring")},m(t,u){e(document.head,p),O(t,I,u),O(t,h,u),e(h,x),e(x,ye),y(j,ye,null),e(h,lt),e(h,Te),e(Te,mt),O(t,He,u),O(t,N,u),e(N,A),e(A,be),y(Y,be,null),e(N,ct),e(N,$e),e($e,dt),O(t,We,u),O(t,d,u),y(J,d,null),e(d,pt),e(d,M),y(G,M,null),e(M,ut),e(M,xe),e(xe,ht),e(d,gt),e(d,z),y(K,z,null),e(z,ft),e(z,Q),e(Q,vt),e(Q,we),e(we,_t),e(Q,yt),e(d,Tt),e(d,U),y(Z,U,null),e(U,bt),e(U,q),e(q,$t),e(q,Oe),e(Oe,xt),e(q,wt),e(q,ke),e(ke,Ot),e(q,kt),e(d,Et),e(d,V),y(ee,V,null),e(V,Nt),e(V,te),e(te,qt),e(te,Ee),e(Ee,Rt),e(te,Dt),e(d,St),e(d,F),y(ne,F,null),e(F,Pt),e(F,R),e(R,Lt),e(R,Ne),e(Ne,Ct),e(R,It),e(R,qe),e(qe,At),e(R,Mt),e(d,zt),e(d,H),y(ae,H,null),e(H,Ut),e(H,Re),e(Re,Vt),O(t,Xe,u),O(t,D,u),e(D,W),e(W,De),y(re,De,null),e(D,Ft),e(D,Se),e(Se,Ht),O(t,Be,u),O(t,w,u),y(oe,w,null),e(w,Wt),e(w,X),y(ie,X,null),e(X,Xt),e(X,se),e(se,Bt),e(se,Pe),e(Pe,jt),e(se,Yt),e(w,Jt),e(w,g),y(le,g,null),e(g,Gt),e(g,me),e(me,Kt),e(me,Le),e(Le,Qt),e(me,Zt),e(g,en),y(B,g,null),e(g,tn),e(g,ce),e(ce,nn),e(ce,Ce),e(Ce,an),e(ce,rn),e(g,on),e(g,S),e(S,P),e(P,sn),e(P,Ie),e(Ie,ln),e(P,mn),e(P,Ae),e(Ae,cn),e(P,dn),e(S,pn),e(S,L),e(L,un),e(L,Me),e(Me,hn),e(L,gn),e(L,ze),e(ze,fn),e(L,vn),e(S,_n),e(S,C),e(C,yn),e(C,Ue),e(Ue,Tn),e(C,bn),e(C,Ve),e(Ve,$n),e(C,xn),je=!0},p(t,[u]){const de={};u&2&&(de.$$scope={dirty:u,ctx:t}),B.$set(de)},i(t){je||(T(j.$$.fragment,t),T(Y.$$.fragment,t),T(J.$$.fragment,t),T(G.$$.fragment,t),T(K.$$.fragment,t),T(Z.$$.fragment,t),T(ee.$$.fragment,t),T(ne.$$.fragment,t),T(ae.$$.fragment,t),T(re.$$.fragment,t),T(oe.$$.fragment,t),T(ie.$$.fragment,t),T(le.$$.fragment,t),T(B.$$.fragment,t),je=!0)},o(t){b(j.$$.fragment,t),b(Y.$$.fragment,t),b(J.$$.fragment,t),b(G.$$.fragment,t),b(K.$$.fragment,t),b(Z.$$.fragment,t),b(ee.$$.fragment,t),b(ne.$$.fragment,t),b(ae.$$.fragment,t),b(re.$$.fragment,t),b(oe.$$.fragment,t),b(ie.$$.fragment,t),b(le.$$.fragment,t),b(B.$$.fragment,t),je=!1},d(t){n(p),t&&n(I),t&&n(h),$(j),t&&n(He),t&&n(N),$(Y),t&&n(We),t&&n(d),$(J),$(G),$(K),$(Z),$(ee),$(ne),$(ae),t&&n(Xe),t&&n(D),$(re),t&&n(Be),t&&n(w),$(oe),$(ie),$(le),$(B)}}}const oa={local:"trainer",sections:[{local:"optimum.onnxruntime.ORTTrainer",title:"ORTTrainer"},{local:"optimum.onnxruntime.Seq2SeqORTTrainer",title:"Seq2SeqORTTrainer"}],title:"Trainer"};function ia(Fe){return ta(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class da extends Kn{constructor(p){super();Qn(this,p,ia,ra,Zn,{})}}export{da as default,oa as metadata};
