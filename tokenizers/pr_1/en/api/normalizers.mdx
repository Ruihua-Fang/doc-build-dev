<script lang="ts">
import {onMount} from "svelte";
import Tip from "$lib/Tip.svelte";
import Youtube from "$lib/Youtube.svelte";
import Docstring from "$lib/Docstring.svelte";
import CodeBlock from "$lib/CodeBlock.svelte";
import CodeBlockFw from "$lib/CodeBlockFw.svelte";
import DocNotebookDropdown from "$lib/DocNotebookDropdown.svelte";
import IconCopyLink from "$lib/IconCopyLink.svelte";
import FrameworkContent from "$lib/FrameworkContent.svelte";
import Markdown from "$lib/Markdown.svelte";
import Question from "$lib/Question.svelte";
import FrameworkSwitchCourse from "$lib/FrameworkSwitchCourse.svelte";
import InferenceApi from "$lib/InferenceApi.svelte";
import TokenizersLanguageContent from "$lib/TokenizersLanguageContent.svelte";
let fw: "pt" | "tf" = "pt";
onMount(() => {
    const urlParams = new URLSearchParams(window.location.search);
    fw = urlParams.get("fw") || "pt";
});
</script>
<svelte:head>
  <meta name="hf:doc:metadata" content={JSON.stringify(metadata)} >
</svelte:head>
# Normalizers

<tokenizerslangcontent>
<python>
## BertNormalizer[[tokenizers.normalizers.BertNormalizer]][[tokenizers.normalizers.BertNormalizer]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.BertNormalizer</name><anchor>tokenizers.normalizers.BertNormalizer</anchor><parameters>[{"name": "clean_text", "val": " = True"}, {"name": "handle_chinese_chars", "val": " = True"}, {"name": "strip_accents", "val": " = None"}, {"name": "lowercase", "val": " = True"}]</parameters><paramsdesc>- **clean_text** (`bool`, *optional*, defaults to `True`) --
  Whether to clean the text, by removing any control characters
  and replacing all whitespaces by the classic one.

- **handle_chinese_chars** (`bool`, *optional*, defaults to `True`) --
  Whether to handle chinese chars by putting spaces around them.

- **strip_accents** (`bool`, *optional*) --
  Whether to strip all accents. If this option is not specified (ie == None),
  then it will be determined by the value for *lowercase* (as in the original Bert).

- **lowercase** (`bool`, *optional*, defaults to `True`) --
  Whether to lowercase.</paramsdesc><paramgroups>0</paramgroups></docstring>
BertNormalizer

Takes care of normalizing raw text before giving it to a Bert model.
This includes cleaning the text, handling accents, chinese chars and lowercasing




</div>

## Lowercase[[tokenizers.normalizers.Lowercase]][[tokenizers.normalizers.Lowercase]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.Lowercase</name><anchor>tokenizers.normalizers.Lowercase</anchor><parameters>[]</parameters></docstring>
Lowercase Normalizer

</div>

## NFC[[tokenizers.normalizers.NFC]][[tokenizers.normalizers.NFC]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.NFC</name><anchor>tokenizers.normalizers.NFC</anchor><parameters>[]</parameters></docstring>
NFC Unicode Normalizer

</div>

## NFD[[tokenizers.normalizers.NFD]][[tokenizers.normalizers.NFD]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.NFD</name><anchor>tokenizers.normalizers.NFD</anchor><parameters>[]</parameters></docstring>
NFD Unicode Normalizer

</div>

## NFKC[[tokenizers.normalizers.NFKC]][[tokenizers.normalizers.NFKC]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.NFKC</name><anchor>tokenizers.normalizers.NFKC</anchor><parameters>[]</parameters></docstring>
NFKC Unicode Normalizer

</div>

## NFKD[[tokenizers.normalizers.NFKD]][[tokenizers.normalizers.NFKD]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.NFKD</name><anchor>tokenizers.normalizers.NFKD</anchor><parameters>[]</parameters></docstring>
NFKD Unicode Normalizer

</div>

## Nmt[[tokenizers.normalizers.Nmt]][[tokenizers.normalizers.Nmt]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.Nmt</name><anchor>tokenizers.normalizers.Nmt</anchor><parameters>[]</parameters></docstring>
Nmt normalizer

</div>

## Normalizer[[tokenizers.normalizers.Normalizer]][[tokenizers.normalizers.Normalizer]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.Normalizer</name><anchor>tokenizers.normalizers.Normalizer</anchor><parameters>[]</parameters></docstring>
Base class for all normalizers

This class is not supposed to be instantiated directly. Instead, any implementation of a
Normalizer will return an instance of this class when instantiated.


<div class="docstring">
<docstring><name>normalize</name><anchor>tokenizers.normalizers.Normalizer.normalize</anchor><parameters>[{"name": "normalized", "val": ""}]</parameters><paramsdesc>- **normalized** ([`~tokenizers.NormalizedString`]) --
  The normalized string on which to apply this
  [`~tokenizers.normalizers.Normalizer`]</paramsdesc><paramgroups>0</paramgroups></docstring>
Normalize a [`~tokenizers.NormalizedString`] in-place

This method allows to modify a [`~tokenizers.NormalizedString`] to
keep track of the alignment information. If you just want to see the result
of the normalization on a raw string, you can use
[`~tokenizers.normalizers.Normalizer.normalize_str`]




</div>
<div class="docstring">
<docstring><name>normalize_str</name><anchor>tokenizers.normalizers.Normalizer.normalize_str</anchor><parameters>[{"name": "sequence", "val": ""}]</parameters><paramsdesc>- **sequence** (`str`) --
  A string to normalize</paramsdesc><paramgroups>0</paramgroups><rettype>`str`</rettype><retdesc>A string after normalization</retdesc></docstring>
Normalize the given string

This method provides a way to visualize the effect of a
[`~tokenizers.normalizers.Normalizer`] but it does not keep track of the alignment
information. If you need to get/convert offsets, you can use
[`~tokenizers.normalizers.Normalizer.normalize`]








</div></div>

## Precompiled[[tokenizers.normalizers.Precompiled]][[tokenizers.normalizers.Precompiled]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.Precompiled</name><anchor>tokenizers.normalizers.Precompiled</anchor><parameters>[{"name": "precompiled_charsmap", "val": ""}]</parameters></docstring>
Precompiled normalizer
Don't use manually it is used for compatiblity for SentencePiece.

</div>

## Replace[[tokenizers.normalizers.Replace]][[tokenizers.normalizers.Replace]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.Replace</name><anchor>tokenizers.normalizers.Replace</anchor><parameters>[{"name": "pattern", "val": ""}, {"name": "content", "val": ""}]</parameters></docstring>
Replace normalizer

</div>

## Sequence[[tokenizers.normalizers.Sequence]][[tokenizers.normalizers.Sequence]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.Sequence</name><anchor>tokenizers.normalizers.Sequence</anchor><parameters>""</parameters><paramsdesc>- **normalizers** (`List[Normalizer]`) --
  A list of Normalizer to be run as a sequence</paramsdesc><paramgroups>0</paramgroups></docstring>
Allows concatenating multiple other Normalizer as a Sequence.
All the normalizers run in sequence in the given order




</div>

## Strip[[tokenizers.normalizers.Strip]][[tokenizers.normalizers.Strip]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.Strip</name><anchor>tokenizers.normalizers.Strip</anchor><parameters>[{"name": "left", "val": " = True"}, {"name": "right", "val": " = True"}]</parameters></docstring>
Strip normalizer

</div>

## StripAccents[[tokenizers.normalizers.StripAccents]][[tokenizers.normalizers.StripAccents]]

<div class="docstring">

<docstring><name>class tokenizers.normalizers.StripAccents</name><anchor>tokenizers.normalizers.StripAccents</anchor><parameters>[]</parameters></docstring>
StripAccents normalizer

</div>

</python>
<rust>
The Rust API Reference is available directly on the [Docs.rs](https://docs.rs/tokenizers/latest/tokenizers/) website.
</rust>
<node>
The node API has not been documented yet.
</node>
</tokenizerslangcontent>