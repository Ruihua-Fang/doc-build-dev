import{S as vn,i as gn,s as En,e as l,k as i,w as hr,t as a,M as mn,c as o,d as t,m as s,a as r,x as fr,h as n,b as d,F as e,g as $,y as ur,q as pr,o as vr,B as gr,v as _n}from"../chunks/vendor-a667fb6e.js";import{I as Gr}from"../chunks/IconCopyLink-3bc33587.js";import{T as pn,M as Ea}from"../chunks/TokenizersLanguageContent-c33e4dff.js";function bn(Oo){let u,m,h,p,G,zt,le,al,Sl,X,Jt,Hl,f,g,x,nl,Rt,j,il,oe,Z,Ae,U,Ie,Nl,Ll,re,Bl,xl,ke,mt,ae,D,Fl,It,qe,_t,Ol,me,Oe,V,_e,ne,Pe,je,$l,F,Pt,Ve,ie,Je,S,Al,be,sl,ql,H,Cl,P,Ul,dl,se,Qe,Xe,Wl,Ze,cl,de,y,hl,St,et,zl,bt,O,Te,$e,fl,W,De,ul,Ml,Ue,Qt,Ht,A,Tt,N,we,Xt,Kl,tt,We,Yl,M,C,J,Zt,Gl,lt,Me,Nt,L,jl,K,Se,Vl,Jl,ot,He,el,k,Y,Ce,Ql,Xl,ye,Ke,Zl,w,Dt,Lt,rt,eo,to,ce,Q,tl,lo,Ne,ll,z,wt,at,q,he,Bt,oo,fe,ro,Rl,b,ao,nt,xt,no,ee,ve,it,st,ze,ue,dt,Le,Ft,ge;return{c(){u=l("table"),m=l("thead"),h=l("tr"),p=l("th"),G=a("Name"),zt=i(),le=l("th"),al=a("Description"),Sl=i(),X=l("th"),Jt=a("Example"),Hl=i(),f=l("tbody"),g=l("tr"),x=l("td"),nl=a("NFD"),Rt=i(),j=l("td"),il=a("NFD unicode normalization"),oe=i(),Z=l("td"),Ae=i(),U=l("tr"),Ie=l("td"),Nl=a("NFKD"),Ll=i(),re=l("td"),Bl=a("NFKD unicode normalization"),xl=i(),ke=l("td"),mt=i(),ae=l("tr"),D=l("td"),Fl=a("NFC"),It=i(),qe=l("td"),_t=a("NFC unicode normalization"),Ol=i(),me=l("td"),Oe=i(),V=l("tr"),_e=l("td"),ne=a("NFKC"),Pe=i(),je=l("td"),$l=a("NFKC unicode normalization"),F=i(),Pt=l("td"),Ve=i(),ie=l("tr"),Je=l("td"),S=a("Lowercase"),Al=i(),be=l("td"),sl=a("Replaces all uppercase to lowercase"),ql=i(),H=l("td"),Cl=a("Input: "),P=l("code"),Ul=a("HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),dl=i(),se=l("br"),Qe=a(" Output: "),Xe=l("code"),Wl=a("hello"),Ze=a("\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),cl=i(),de=l("tr"),y=l("td"),hl=a("Strip"),St=i(),et=l("td"),zl=a("Removes all whitespace characters on the specified sides (left, right or both) of the input"),bt=i(),O=l("td"),Te=a("Input: "),$e=l("code"),fl=a('"'),W=a("hi"),De=l("code"),ul=a('"'),Ml=i(),Ue=l("br"),Qt=a(" Output: "),Ht=l("code"),A=a('"hi"'),Tt=i(),N=l("tr"),we=l("td"),Xt=a("StripAccents"),Kl=i(),tt=l("td"),We=a("Removes all accent symbols in unicode (to be used with NFD for consistency)"),Yl=i(),M=l("td"),C=a("Input: "),J=l("code"),Zt=a("\xE9"),Gl=i(),lt=l("br"),Me=a(" Ouput: "),Nt=l("code"),L=a("e"),jl=i(),K=l("tr"),Se=l("td"),Vl=a("Replace"),Jl=i(),ot=l("td"),He=a("Replaces a custom string or regexp and changes it with given content"),el=i(),k=l("td"),Y=l("code"),Ce=a('Replace("a", "e")'),Ql=a(" will behave like this: "),Xl=l("br"),ye=a(" Input: "),Ke=l("code"),Zl=a('"banana"'),w=i(),Dt=l("br"),Lt=a(" Ouput: "),rt=l("code"),eo=a('"benene"'),to=i(),ce=l("tr"),Q=l("td"),tl=a("BertNormalizer"),lo=i(),Ne=l("td"),ll=a("Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),z=l("ul"),wt=l("li"),at=a("clean_text"),q=i(),he=l("li"),Bt=a("handle_chinese_chars"),oo=i(),fe=l("li"),ro=a("strip_accents"),Rl=i(),b=l("li"),ao=a("lowercase"),nt=i(),xt=l("td"),no=i(),ee=l("tr"),ve=l("td"),it=a("Sequence"),st=i(),ze=l("td"),ue=a("Composes multiple normalizers that will run in the provided order"),dt=i(),Le=l("td"),Ft=l("code"),ge=a("Sequence([NFKC(), Lowercase()])"),this.h()},l(At){u=o(At,"TABLE",{});var B=r(u);m=o(B,"THEAD",{});var pl=r(m);h=o(pl,"TR",{});var qt=r(h);p=o(qt,"TH",{align:!0});var Ut=r(p);G=n(Ut,"Name"),Ut.forEach(t),zt=s(qt),le=o(qt,"TH",{align:!0});var T=r(le);al=n(T,"Description"),T.forEach(t),Sl=s(qt),X=o(qt,"TH",{align:!0});var vl=r(X);Jt=n(vl,"Example"),vl.forEach(t),qt.forEach(t),pl.forEach(t),Hl=s(B),f=o(B,"TBODY",{});var _=r(f);g=o(_,"TR",{});var Ee=r(g);x=o(Ee,"TD",{align:!0});var gl=r(x);nl=n(gl,"NFD"),gl.forEach(t),Rt=s(Ee),j=o(Ee,"TD",{align:!0});var Wt=r(j);il=n(Wt,"NFD unicode normalization"),Wt.forEach(t),oe=s(Ee),Z=o(Ee,"TD",{align:!0}),r(Z).forEach(t),Ee.forEach(t),Ae=s(_),U=o(_,"TR",{});var El=r(U);Ie=o(El,"TD",{align:!0});var ct=r(Ie);Nl=n(ct,"NFKD"),ct.forEach(t),Ll=s(El),re=o(El,"TD",{align:!0});var po=r(re);Bl=n(po,"NFKD unicode normalization"),po.forEach(t),xl=s(El),ke=o(El,"TD",{align:!0}),r(ke).forEach(t),El.forEach(t),mt=s(_),ae=o(_,"TR",{});var R=r(ae);D=o(R,"TD",{align:!0});var ml=r(D);Fl=n(ml,"NFC"),ml.forEach(t),It=s(R),qe=o(R,"TD",{align:!0});var _l=r(qe);_t=n(_l,"NFC unicode normalization"),_l.forEach(t),Ol=s(R),me=o(R,"TD",{align:!0}),r(me).forEach(t),R.forEach(t),Oe=s(_),V=o(_,"TR",{});var bl=r(V);_e=o(bl,"TD",{align:!0});var Be=r(_e);ne=n(Be,"NFKC"),Be.forEach(t),Pe=s(bl),je=o(bl,"TD",{align:!0});var yt=r(je);$l=n(yt,"NFKC unicode normalization"),yt.forEach(t),F=s(bl),Pt=o(bl,"TD",{align:!0}),r(Pt).forEach(t),bl.forEach(t),Ve=s(_),ie=o(_,"TR",{});var Tl=r(ie);Je=o(Tl,"TD",{align:!0});var ht=r(Je);S=n(ht,"Lowercase"),ht.forEach(t),Al=s(Tl),be=o(Tl,"TD",{align:!0});var E=r(be);sl=n(E,"Replaces all uppercase to lowercase"),E.forEach(t),ql=s(Tl),H=o(Tl,"TD",{align:!0});var Mt=r(H);Cl=n(Mt,"Input: "),P=o(Mt,"CODE",{});var Ye=r(P);Ul=n(Ye,"HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),Ye.forEach(t),dl=s(Mt),se=o(Mt,"BR",{}),Qe=n(Mt," Output: "),Xe=o(Mt,"CODE",{});var vo=r(Xe);Wl=n(vo,"hello"),vo.forEach(t),Ze=n(Mt,"\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),Mt.forEach(t),Tl.forEach(t),cl=s(_),de=o(_,"TR",{});var xe=r(de);y=o(xe,"TD",{align:!0});var kt=r(y);hl=n(kt,"Strip"),kt.forEach(t),St=s(xe),et=o(xe,"TD",{align:!0});var go=r(et);zl=n(go,"Removes all whitespace characters on the specified sides (left, right or both) of the input"),go.forEach(t),bt=s(xe),O=o(xe,"TD",{align:!0});var pe=r(O);Te=n(pe,"Input: "),$e=o(pe,"CODE",{});var Eo=r($e);fl=n(Eo,'"'),Eo.forEach(t),W=n(pe,"hi"),De=o(pe,"CODE",{});var ft=r(De);ul=n(ft,'"'),ft.forEach(t),Ml=s(pe),Ue=o(pe,"BR",{}),Qt=n(pe," Output: "),Ht=o(pe,"CODE",{});var io=r(Ht);A=n(io,'"hi"'),io.forEach(t),pe.forEach(t),xe.forEach(t),Tt=s(_),N=o(_,"TR",{});var Kt=r(N);we=o(Kt,"TD",{align:!0});var Ge=r(we);Xt=n(Ge,"StripAccents"),Ge.forEach(t),Kl=s(Kt),tt=o(Kt,"TD",{align:!0});var mo=r(tt);We=n(mo,"Removes all accent symbols in unicode (to be used with NFD for consistency)"),mo.forEach(t),Yl=s(Kt),M=o(Kt,"TD",{align:!0});var Ot=r(M);C=n(Ot,"Input: "),J=o(Ot,"CODE",{});var Yt=r(J);Zt=n(Yt,"\xE9"),Yt.forEach(t),Gl=s(Ot),lt=o(Ot,"BR",{}),Me=n(Ot," Ouput: "),Nt=o(Ot,"CODE",{});var _o=r(Nt);L=n(_o,"e"),_o.forEach(t),Ot.forEach(t),Kt.forEach(t),jl=s(_),K=o(_,"TR",{});var ut=r(K);Se=o(ut,"TD",{align:!0});var pt=r(Se);Vl=n(pt,"Replace"),pt.forEach(t),Jl=s(ut),ot=o(ut,"TD",{align:!0});var bo=r(ot);He=n(bo,"Replaces a custom string or regexp and changes it with given content"),bo.forEach(t),el=s(ut),k=o(ut,"TD",{align:!0});var I=r(k);Y=o(I,"CODE",{});var Gt=r(Y);Ce=n(Gt,'Replace("a", "e")'),Gt.forEach(t),Ql=n(I," will behave like this: "),Xl=o(I,"BR",{}),ye=n(I," Input: "),Ke=o(I,"CODE",{});var Dl=r(Ke);Zl=n(Dl,'"banana"'),Dl.forEach(t),w=s(I),Dt=o(I,"BR",{}),Lt=n(I," Ouput: "),rt=o(I,"CODE",{});var To=r(rt);eo=n(To,'"benene"'),To.forEach(t),I.forEach(t),ut.forEach(t),to=s(_),ce=o(_,"TR",{});var te=r(ce);Q=o(te,"TD",{align:!0});var vt=r(Q);tl=n(vt,"BertNormalizer"),vt.forEach(t),lo=s(te),Ne=o(te,"TD",{align:!0});var ol=r(Ne);ll=n(ol,"Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),z=o(ol,"UL",{});var $t=r(z);wt=o($t,"LI",{});var jt=r(wt);at=n(jt,"clean_text"),jt.forEach(t),q=s($t),he=o($t,"LI",{});var rl=r(he);Bt=n(rl,"handle_chinese_chars"),rl.forEach(t),oo=s($t),fe=o($t,"LI",{});var Re=r(fe);ro=n(Re,"strip_accents"),Re.forEach(t),Rl=s($t),b=o($t,"LI",{});var gt=r(b);ao=n(gt,"lowercase"),gt.forEach(t),$t.forEach(t),ol.forEach(t),nt=s(te),xt=o(te,"TD",{align:!0}),r(xt).forEach(t),te.forEach(t),no=s(_),ee=o(_,"TR",{});var Ct=r(ee);ve=o(Ct,"TD",{align:!0});var Do=r(ve);it=n(Do,"Sequence"),Do.forEach(t),st=s(Ct),ze=o(Ct,"TD",{align:!0});var Il=r(ze);ue=n(Il,"Composes multiple normalizers that will run in the provided order"),Il.forEach(t),dt=s(Ct),Le=o(Ct,"TD",{align:!0});var Uo=r(Le);Ft=o(Uo,"CODE",{});var Vt=r(Ft);ge=n(Vt,"Sequence([NFKC(), Lowercase()])"),Vt.forEach(t),Uo.forEach(t),Ct.forEach(t),_.forEach(t),B.forEach(t),this.h()},h(){d(p,"align","left"),d(le,"align","left"),d(X,"align","left"),d(x,"align","left"),d(j,"align","left"),d(Z,"align","left"),d(Ie,"align","left"),d(re,"align","left"),d(ke,"align","left"),d(D,"align","left"),d(qe,"align","left"),d(me,"align","left"),d(_e,"align","left"),d(je,"align","left"),d(Pt,"align","left"),d(Je,"align","left"),d(be,"align","left"),d(H,"align","left"),d(y,"align","left"),d(et,"align","left"),d(O,"align","left"),d(we,"align","left"),d(tt,"align","left"),d(M,"align","left"),d(Se,"align","left"),d(ot,"align","left"),d(k,"align","left"),d(Q,"align","left"),d(Ne,"align","left"),d(xt,"align","left"),d(ve,"align","left"),d(ze,"align","left"),d(Le,"align","left")},m(At,B){$(At,u,B),e(u,m),e(m,h),e(h,p),e(p,G),e(h,zt),e(h,le),e(le,al),e(h,Sl),e(h,X),e(X,Jt),e(u,Hl),e(u,f),e(f,g),e(g,x),e(x,nl),e(g,Rt),e(g,j),e(j,il),e(g,oe),e(g,Z),e(f,Ae),e(f,U),e(U,Ie),e(Ie,Nl),e(U,Ll),e(U,re),e(re,Bl),e(U,xl),e(U,ke),e(f,mt),e(f,ae),e(ae,D),e(D,Fl),e(ae,It),e(ae,qe),e(qe,_t),e(ae,Ol),e(ae,me),e(f,Oe),e(f,V),e(V,_e),e(_e,ne),e(V,Pe),e(V,je),e(je,$l),e(V,F),e(V,Pt),e(f,Ve),e(f,ie),e(ie,Je),e(Je,S),e(ie,Al),e(ie,be),e(be,sl),e(ie,ql),e(ie,H),e(H,Cl),e(H,P),e(P,Ul),e(H,dl),e(H,se),e(H,Qe),e(H,Xe),e(Xe,Wl),e(H,Ze),e(f,cl),e(f,de),e(de,y),e(y,hl),e(de,St),e(de,et),e(et,zl),e(de,bt),e(de,O),e(O,Te),e(O,$e),e($e,fl),e(O,W),e(O,De),e(De,ul),e(O,Ml),e(O,Ue),e(O,Qt),e(O,Ht),e(Ht,A),e(f,Tt),e(f,N),e(N,we),e(we,Xt),e(N,Kl),e(N,tt),e(tt,We),e(N,Yl),e(N,M),e(M,C),e(M,J),e(J,Zt),e(M,Gl),e(M,lt),e(M,Me),e(M,Nt),e(Nt,L),e(f,jl),e(f,K),e(K,Se),e(Se,Vl),e(K,Jl),e(K,ot),e(ot,He),e(K,el),e(K,k),e(k,Y),e(Y,Ce),e(k,Ql),e(k,Xl),e(k,ye),e(k,Ke),e(Ke,Zl),e(k,w),e(k,Dt),e(k,Lt),e(k,rt),e(rt,eo),e(f,to),e(f,ce),e(ce,Q),e(Q,tl),e(ce,lo),e(ce,Ne),e(Ne,ll),e(Ne,z),e(z,wt),e(wt,at),e(z,q),e(z,he),e(he,Bt),e(z,oo),e(z,fe),e(fe,ro),e(z,Rl),e(z,b),e(b,ao),e(ce,nt),e(ce,xt),e(f,no),e(f,ee),e(ee,ve),e(ve,it),e(ee,st),e(ee,ze),e(ze,ue),e(ee,dt),e(ee,Le),e(Le,Ft),e(Ft,ge)},d(At){At&&t(u)}}}function Tn(Oo){let u,m;return u=new Ea({props:{$$slots:{default:[bn]},$$scope:{ctx:Oo}}}),{c(){hr(u.$$.fragment)},l(h){fr(u.$$.fragment,h)},m(h,p){ur(u,h,p),m=!0},p(h,p){const G={};p&2&&(G.$$scope={dirty:p,ctx:h}),u.$set(G)},i(h){m||(pr(u.$$.fragment,h),m=!0)},o(h){vr(u.$$.fragment,h),m=!1},d(h){gr(u,h)}}}function Dn(Oo){let u,m,h,p,G,zt,le,al,Sl,X,Jt,Hl,f,g,x,nl,Rt,j,il,oe,Z,Ae,U,Ie,Nl,Ll,re,Bl,xl,ke,mt,ae,D,Fl,It,qe,_t,Ol,me,Oe,V,_e,ne,Pe,je,$l,F,Pt,Ve,ie,Je,S,Al,be,sl,ql,H,Cl,P,Ul,dl,se,Qe,Xe,Wl,Ze,cl,de,y,hl,St,et,zl,bt,O,Te,$e,fl,W,De,ul,Ml,Ue,Qt,Ht,A,Tt,N,we,Xt,Kl,tt,We,Yl,M,C,J,Zt,Gl,lt,Me,Nt,L,jl,K,Se,Vl,Jl,ot,He,el,k,Y,Ce,Ql,Xl,ye,Ke,Zl,w,Dt,Lt,rt,eo,to,ce,Q,tl,lo,Ne,ll,z,wt,at,q,he,Bt,oo,fe,ro,Rl,b,ao,nt,xt,no,ee,ve,it,st,ze,ue,dt,Le;return{c(){u=l("table"),m=l("thead"),h=l("tr"),p=l("th"),G=a("Name"),zt=i(),le=l("th"),al=a("Description"),Sl=i(),X=l("th"),Jt=a("Example"),Hl=i(),f=l("tbody"),g=l("tr"),x=l("td"),nl=a("NFD"),Rt=i(),j=l("td"),il=a("NFD unicode normalization"),oe=i(),Z=l("td"),Ae=i(),U=l("tr"),Ie=l("td"),Nl=a("NFKD"),Ll=i(),re=l("td"),Bl=a("NFKD unicode normalization"),xl=i(),ke=l("td"),mt=i(),ae=l("tr"),D=l("td"),Fl=a("NFC"),It=i(),qe=l("td"),_t=a("NFC unicode normalization"),Ol=i(),me=l("td"),Oe=i(),V=l("tr"),_e=l("td"),ne=a("NFKC"),Pe=i(),je=l("td"),$l=a("NFKC unicode normalization"),F=i(),Pt=l("td"),Ve=i(),ie=l("tr"),Je=l("td"),S=a("Lowercase"),Al=i(),be=l("td"),sl=a("Replaces all uppercase to lowercase"),ql=i(),H=l("td"),Cl=a("Input: "),P=l("code"),Ul=a("HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),dl=i(),se=l("br"),Qe=a(" Output: "),Xe=l("code"),Wl=a("hello"),Ze=a("\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),cl=i(),de=l("tr"),y=l("td"),hl=a("Strip"),St=i(),et=l("td"),zl=a("Removes all whitespace characters on the specified sides (left, right or both) of the input"),bt=i(),O=l("td"),Te=a("Input: "),$e=l("code"),fl=a('"'),W=a("hi"),De=l("code"),ul=a('"'),Ml=i(),Ue=l("br"),Qt=a(" Output: "),Ht=l("code"),A=a('"hi"'),Tt=i(),N=l("tr"),we=l("td"),Xt=a("StripAccents"),Kl=i(),tt=l("td"),We=a("Removes all accent symbols in unicode (to be used with NFD for consistency)"),Yl=i(),M=l("td"),C=a("Input: "),J=l("code"),Zt=a("\xE9"),Gl=i(),lt=l("br"),Me=a(" Ouput: "),Nt=l("code"),L=a("e"),jl=i(),K=l("tr"),Se=l("td"),Vl=a("Replace"),Jl=i(),ot=l("td"),He=a("Replaces a custom string or regexp and changes it with given content"),el=i(),k=l("td"),Y=l("code"),Ce=a('Replace("a", "e")'),Ql=a(" will behave like this: "),Xl=l("br"),ye=a(" Input: "),Ke=l("code"),Zl=a('"banana"'),w=i(),Dt=l("br"),Lt=a(" Ouput: "),rt=l("code"),eo=a('"benene"'),to=i(),ce=l("tr"),Q=l("td"),tl=a("BertNormalizer"),lo=i(),Ne=l("td"),ll=a("Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),z=l("ul"),wt=l("li"),at=a("cleanText"),q=i(),he=l("li"),Bt=a("handleChineseChars"),oo=i(),fe=l("li"),ro=a("stripAccents"),Rl=i(),b=l("li"),ao=a("lowercase"),nt=i(),xt=l("td"),no=i(),ee=l("tr"),ve=l("td"),it=a("Sequence"),st=i(),ze=l("td"),ue=a("Composes multiple normalizers that will run in the provided order"),dt=i(),Le=l("td"),this.h()},l(Ft){u=o(Ft,"TABLE",{});var ge=r(u);m=o(ge,"THEAD",{});var At=r(m);h=o(At,"TR",{});var B=r(h);p=o(B,"TH",{align:!0});var pl=r(p);G=n(pl,"Name"),pl.forEach(t),zt=s(B),le=o(B,"TH",{align:!0});var qt=r(le);al=n(qt,"Description"),qt.forEach(t),Sl=s(B),X=o(B,"TH",{align:!0});var Ut=r(X);Jt=n(Ut,"Example"),Ut.forEach(t),B.forEach(t),At.forEach(t),Hl=s(ge),f=o(ge,"TBODY",{});var T=r(f);g=o(T,"TR",{});var vl=r(g);x=o(vl,"TD",{align:!0});var _=r(x);nl=n(_,"NFD"),_.forEach(t),Rt=s(vl),j=o(vl,"TD",{align:!0});var Ee=r(j);il=n(Ee,"NFD unicode normalization"),Ee.forEach(t),oe=s(vl),Z=o(vl,"TD",{align:!0}),r(Z).forEach(t),vl.forEach(t),Ae=s(T),U=o(T,"TR",{});var gl=r(U);Ie=o(gl,"TD",{align:!0});var Wt=r(Ie);Nl=n(Wt,"NFKD"),Wt.forEach(t),Ll=s(gl),re=o(gl,"TD",{align:!0});var El=r(re);Bl=n(El,"NFKD unicode normalization"),El.forEach(t),xl=s(gl),ke=o(gl,"TD",{align:!0}),r(ke).forEach(t),gl.forEach(t),mt=s(T),ae=o(T,"TR",{});var ct=r(ae);D=o(ct,"TD",{align:!0});var po=r(D);Fl=n(po,"NFC"),po.forEach(t),It=s(ct),qe=o(ct,"TD",{align:!0});var R=r(qe);_t=n(R,"NFC unicode normalization"),R.forEach(t),Ol=s(ct),me=o(ct,"TD",{align:!0}),r(me).forEach(t),ct.forEach(t),Oe=s(T),V=o(T,"TR",{});var ml=r(V);_e=o(ml,"TD",{align:!0});var _l=r(_e);ne=n(_l,"NFKC"),_l.forEach(t),Pe=s(ml),je=o(ml,"TD",{align:!0});var bl=r(je);$l=n(bl,"NFKC unicode normalization"),bl.forEach(t),F=s(ml),Pt=o(ml,"TD",{align:!0}),r(Pt).forEach(t),ml.forEach(t),Ve=s(T),ie=o(T,"TR",{});var Be=r(ie);Je=o(Be,"TD",{align:!0});var yt=r(Je);S=n(yt,"Lowercase"),yt.forEach(t),Al=s(Be),be=o(Be,"TD",{align:!0});var Tl=r(be);sl=n(Tl,"Replaces all uppercase to lowercase"),Tl.forEach(t),ql=s(Be),H=o(Be,"TD",{align:!0});var ht=r(H);Cl=n(ht,"Input: "),P=o(ht,"CODE",{});var E=r(P);Ul=n(E,"HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),E.forEach(t),dl=s(ht),se=o(ht,"BR",{}),Qe=n(ht," Output: "),Xe=o(ht,"CODE",{});var Mt=r(Xe);Wl=n(Mt,"hello"),Mt.forEach(t),Ze=n(ht,"\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),ht.forEach(t),Be.forEach(t),cl=s(T),de=o(T,"TR",{});var Ye=r(de);y=o(Ye,"TD",{align:!0});var vo=r(y);hl=n(vo,"Strip"),vo.forEach(t),St=s(Ye),et=o(Ye,"TD",{align:!0});var xe=r(et);zl=n(xe,"Removes all whitespace characters on the specified sides (left, right or both) of the input"),xe.forEach(t),bt=s(Ye),O=o(Ye,"TD",{align:!0});var kt=r(O);Te=n(kt,"Input: "),$e=o(kt,"CODE",{});var go=r($e);fl=n(go,'"'),go.forEach(t),W=n(kt,"hi"),De=o(kt,"CODE",{});var pe=r(De);ul=n(pe,'"'),pe.forEach(t),Ml=s(kt),Ue=o(kt,"BR",{}),Qt=n(kt," Output: "),Ht=o(kt,"CODE",{});var Eo=r(Ht);A=n(Eo,'"hi"'),Eo.forEach(t),kt.forEach(t),Ye.forEach(t),Tt=s(T),N=o(T,"TR",{});var ft=r(N);we=o(ft,"TD",{align:!0});var io=r(we);Xt=n(io,"StripAccents"),io.forEach(t),Kl=s(ft),tt=o(ft,"TD",{align:!0});var Kt=r(tt);We=n(Kt,"Removes all accent symbols in unicode (to be used with NFD for consistency)"),Kt.forEach(t),Yl=s(ft),M=o(ft,"TD",{align:!0});var Ge=r(M);C=n(Ge,"Input: "),J=o(Ge,"CODE",{});var mo=r(J);Zt=n(mo,"\xE9"),mo.forEach(t),Gl=s(Ge),lt=o(Ge,"BR",{}),Me=n(Ge," Ouput: "),Nt=o(Ge,"CODE",{});var Ot=r(Nt);L=n(Ot,"e"),Ot.forEach(t),Ge.forEach(t),ft.forEach(t),jl=s(T),K=o(T,"TR",{});var Yt=r(K);Se=o(Yt,"TD",{align:!0});var _o=r(Se);Vl=n(_o,"Replace"),_o.forEach(t),Jl=s(Yt),ot=o(Yt,"TD",{align:!0});var ut=r(ot);He=n(ut,"Replaces a custom string or regexp and changes it with given content"),ut.forEach(t),el=s(Yt),k=o(Yt,"TD",{align:!0});var pt=r(k);Y=o(pt,"CODE",{});var bo=r(Y);Ce=n(bo,'Replace("a", "e")'),bo.forEach(t),Ql=n(pt," will behave like this: "),Xl=o(pt,"BR",{}),ye=n(pt," Input: "),Ke=o(pt,"CODE",{});var I=r(Ke);Zl=n(I,'"banana"'),I.forEach(t),w=s(pt),Dt=o(pt,"BR",{}),Lt=n(pt," Ouput: "),rt=o(pt,"CODE",{});var Gt=r(rt);eo=n(Gt,'"benene"'),Gt.forEach(t),pt.forEach(t),Yt.forEach(t),to=s(T),ce=o(T,"TR",{});var Dl=r(ce);Q=o(Dl,"TD",{align:!0});var To=r(Q);tl=n(To,"BertNormalizer"),To.forEach(t),lo=s(Dl),Ne=o(Dl,"TD",{align:!0});var te=r(Ne);ll=n(te,"Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),z=o(te,"UL",{});var vt=r(z);wt=o(vt,"LI",{});var ol=r(wt);at=n(ol,"cleanText"),ol.forEach(t),q=s(vt),he=o(vt,"LI",{});var $t=r(he);Bt=n($t,"handleChineseChars"),$t.forEach(t),oo=s(vt),fe=o(vt,"LI",{});var jt=r(fe);ro=n(jt,"stripAccents"),jt.forEach(t),Rl=s(vt),b=o(vt,"LI",{});var rl=r(b);ao=n(rl,"lowercase"),rl.forEach(t),vt.forEach(t),te.forEach(t),nt=s(Dl),xt=o(Dl,"TD",{align:!0}),r(xt).forEach(t),Dl.forEach(t),no=s(T),ee=o(T,"TR",{});var Re=r(ee);ve=o(Re,"TD",{align:!0});var gt=r(ve);it=n(gt,"Sequence"),gt.forEach(t),st=s(Re),ze=o(Re,"TD",{align:!0});var Ct=r(ze);ue=n(Ct,"Composes multiple normalizers that will run in the provided order"),Ct.forEach(t),dt=s(Re),Le=o(Re,"TD",{align:!0}),r(Le).forEach(t),Re.forEach(t),T.forEach(t),ge.forEach(t),this.h()},h(){d(p,"align","left"),d(le,"align","left"),d(X,"align","left"),d(x,"align","left"),d(j,"align","left"),d(Z,"align","left"),d(Ie,"align","left"),d(re,"align","left"),d(ke,"align","left"),d(D,"align","left"),d(qe,"align","left"),d(me,"align","left"),d(_e,"align","left"),d(je,"align","left"),d(Pt,"align","left"),d(Je,"align","left"),d(be,"align","left"),d(H,"align","left"),d(y,"align","left"),d(et,"align","left"),d(O,"align","left"),d(we,"align","left"),d(tt,"align","left"),d(M,"align","left"),d(Se,"align","left"),d(ot,"align","left"),d(k,"align","left"),d(Q,"align","left"),d(Ne,"align","left"),d(xt,"align","left"),d(ve,"align","left"),d(ze,"align","left"),d(Le,"align","left")},m(Ft,ge){$(Ft,u,ge),e(u,m),e(m,h),e(h,p),e(p,G),e(h,zt),e(h,le),e(le,al),e(h,Sl),e(h,X),e(X,Jt),e(u,Hl),e(u,f),e(f,g),e(g,x),e(x,nl),e(g,Rt),e(g,j),e(j,il),e(g,oe),e(g,Z),e(f,Ae),e(f,U),e(U,Ie),e(Ie,Nl),e(U,Ll),e(U,re),e(re,Bl),e(U,xl),e(U,ke),e(f,mt),e(f,ae),e(ae,D),e(D,Fl),e(ae,It),e(ae,qe),e(qe,_t),e(ae,Ol),e(ae,me),e(f,Oe),e(f,V),e(V,_e),e(_e,ne),e(V,Pe),e(V,je),e(je,$l),e(V,F),e(V,Pt),e(f,Ve),e(f,ie),e(ie,Je),e(Je,S),e(ie,Al),e(ie,be),e(be,sl),e(ie,ql),e(ie,H),e(H,Cl),e(H,P),e(P,Ul),e(H,dl),e(H,se),e(H,Qe),e(H,Xe),e(Xe,Wl),e(H,Ze),e(f,cl),e(f,de),e(de,y),e(y,hl),e(de,St),e(de,et),e(et,zl),e(de,bt),e(de,O),e(O,Te),e(O,$e),e($e,fl),e(O,W),e(O,De),e(De,ul),e(O,Ml),e(O,Ue),e(O,Qt),e(O,Ht),e(Ht,A),e(f,Tt),e(f,N),e(N,we),e(we,Xt),e(N,Kl),e(N,tt),e(tt,We),e(N,Yl),e(N,M),e(M,C),e(M,J),e(J,Zt),e(M,Gl),e(M,lt),e(M,Me),e(M,Nt),e(Nt,L),e(f,jl),e(f,K),e(K,Se),e(Se,Vl),e(K,Jl),e(K,ot),e(ot,He),e(K,el),e(K,k),e(k,Y),e(Y,Ce),e(k,Ql),e(k,Xl),e(k,ye),e(k,Ke),e(Ke,Zl),e(k,w),e(k,Dt),e(k,Lt),e(k,rt),e(rt,eo),e(f,to),e(f,ce),e(ce,Q),e(Q,tl),e(ce,lo),e(ce,Ne),e(Ne,ll),e(Ne,z),e(z,wt),e(wt,at),e(z,q),e(z,he),e(he,Bt),e(z,oo),e(z,fe),e(fe,ro),e(z,Rl),e(z,b),e(b,ao),e(ce,nt),e(ce,xt),e(f,no),e(f,ee),e(ee,ve),e(ve,it),e(ee,st),e(ee,ze),e(ze,ue),e(ee,dt),e(ee,Le)},d(Ft){Ft&&t(u)}}}function wn(Oo){let u,m;return u=new Ea({props:{$$slots:{default:[Dn]},$$scope:{ctx:Oo}}}),{c(){hr(u.$$.fragment)},l(h){fr(u.$$.fragment,h)},m(h,p){ur(u,h,p),m=!0},p(h,p){const G={};p&2&&(G.$$scope={dirty:p,ctx:h}),u.$set(G)},i(h){m||(pr(u.$$.fragment,h),m=!0)},o(h){vr(u.$$.fragment,h),m=!1},d(h){gr(u,h)}}}function yn(Oo){let u,m,h,p,G,zt,le,al,Sl,X,Jt,Hl,f,g,x,nl,Rt,j,il,oe,Z,Ae,U,Ie,Nl,Ll,re,Bl,xl,ke,mt,ae,D,Fl,It,qe,_t,Ol,me,Oe,V,_e,ne,Pe,je,$l,F,Pt,Ve,ie,Je,S,Al,be,sl,ql,H,Cl,P,Ul,dl,se,Qe,Xe,Wl,Ze,cl,de,y,hl,St,et,zl,bt,O,Te,$e,fl,W,De,ul,Ml,Ue,Qt,Ht,A,Tt,N,we,Xt,Kl,tt,We,Yl,M,C,J,Zt,Gl,lt,Me,Nt,L,jl,K,Se,Vl,Jl,ot,He,el,k,Y,Ce,Ql,Xl,ye,Ke,Zl,w,Dt,Lt,rt,eo,to,ce,Q,tl,lo,Ne,ll,z,wt,at,q,he,Bt,oo,fe,ro,Rl,b,ao,nt,xt,no,ee,ve,it,st,ze,ue,dt,Le,Ft,ge,At,B,pl,qt,Ut,T,vl,_,Ee,gl,Wt,El,ct,po,R,ml,_l,bl,Be,yt,Tl,ht,E,Mt,Ye,vo,xe,kt,go,pe,Eo,ft,io,Kt,Ge,mo,Ot,Yt,_o,ut,pt,bo,I,Gt,Dl,To,te,vt,ol,$t,jt,rl,Re,gt,Ct;return{c(){u=l("table"),m=l("thead"),h=l("tr"),p=l("th"),G=a("Name"),zt=i(),le=l("th"),al=a("Description"),Sl=i(),X=l("th"),Jt=a("Example"),Hl=i(),f=l("tbody"),g=l("tr"),x=l("td"),nl=a("ByteLevel"),Rt=i(),j=l("td"),il=a("Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),oe=l("ul"),Z=l("li"),Ae=a("Since it maps on bytes, a tokenizer using this only requires "),U=l("strong"),Ie=a("256"),Nl=a(" characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),Ll=i(),re=l("li"),Bl=a("A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),xl=i(),ke=l("li"),mt=a("For non ascii characters, it gets completely unreadable, but it works nonetheless!"),ae=i(),D=l("td"),Fl=a("Input: "),It=l("code"),qe=a('"Hello my friend, how are you?"'),_t=i(),Ol=l("br"),me=a(" Ouput: "),Oe=l("code"),V=a('"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),_e=i(),ne=l("tr"),Pe=l("td"),je=a("Whitespace"),$l=i(),F=l("td"),Pt=a("Splits on word boundaries (using the following regular expression: "),Ve=l("code"),ie=a("\\w+|[^\\w\\s]+"),Je=i(),S=l("td"),Al=a("Input: "),be=l("code"),sl=a('"Hello there!"'),ql=i(),H=l("br"),Cl=a(" Output: "),P=l("code"),Ul=a('"Hello", "there", "!"'),dl=i(),se=l("tr"),Qe=l("td"),Xe=a("WhitespaceSplit"),Wl=i(),Ze=l("td"),cl=a("Splits on any whitespace character"),de=i(),y=l("td"),hl=a("Input: "),St=l("code"),et=a('"Hello there!"'),zl=i(),bt=l("br"),O=a(" Output: "),Te=l("code"),$e=a('"Hello", "there!"'),fl=i(),W=l("tr"),De=l("td"),ul=a("Punctuation"),Ml=i(),Ue=l("td"),Qt=a("Will isolate all punctuation characters"),Ht=i(),A=l("td"),Tt=a("Input: "),N=l("code"),we=a('"Hello?"'),Xt=i(),Kl=l("br"),tt=a(" Ouput: "),We=l("code"),Yl=a('"Hello", "?"'),M=i(),C=l("tr"),J=l("td"),Zt=a("Metaspace"),Gl=i(),lt=l("td"),Me=a("Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),Nt=i(),L=l("td"),jl=a("Input: "),K=l("code"),Se=a('"Hello there"'),Vl=i(),Jl=l("br"),ot=a(" Ouput: "),He=l("code"),el=a('"Hello", "\u2581there"'),k=i(),Y=l("tr"),Ce=l("td"),Ql=a("CharDelimiterSplit"),Xl=i(),ye=l("td"),Ke=a("Splits on a given character"),Zl=i(),w=l("td"),Dt=a("Example with "),Lt=l("code"),rt=a("x"),eo=a(": "),to=l("br"),ce=a(" Input: "),Q=l("code"),tl=a('"Helloxthere"'),lo=i(),Ne=l("br"),ll=a(" Ouput: "),z=l("code"),wt=a('"Hello", "there"'),at=i(),q=l("tr"),he=l("td"),Bt=a("Digits"),oo=i(),fe=l("td"),ro=a("Splits the numbers from any other characters."),Rl=i(),b=l("td"),ao=a("Input: "),nt=l("code"),xt=a('"Hello123there"'),no=i(),ee=l("br"),ve=a("  Output: "),it=l("code"),st=a('"Hello", "123", "there"'),ze=i(),ue=l("tr"),dt=l("td"),Le=a("Split"),Ft=i(),ge=l("td"),At=a("Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),B=l("ul"),pl=l("li"),qt=a("pattern should be either a custom string or regexp."),Ut=i(),T=l("li"),vl=a("behavior should be one of: "),_=l("ul"),Ee=l("li"),gl=a("removed"),Wt=l("li"),El=a("isolated"),ct=l("li"),po=a("merged_with_previous"),R=l("li"),ml=a("merged_with_next"),_l=l("li"),bl=a("contiguous"),Be=i(),yt=l("li"),Tl=a("invert should be a boolean flag."),ht=i(),E=l("td"),Mt=a("Example with pattern = "),Ye=l("code"),vo=a(", behavior = "),xe=l("code"),kt=a('"isolated"'),go=a(", invert = "),pe=l("code"),Eo=a("False"),ft=a(": "),io=l("br"),Kt=a(" Input: "),Ge=l("code"),mo=a('"Hello, how are you?"'),Ot=i(),Yt=l("br"),_o=a(" Output: "),ut=l("code"),pt=a('"Hello,", " ", "how", " ", "are", " ", "you?"'),bo=i(),I=l("tr"),Gt=l("td"),Dl=a("Sequence"),To=i(),te=l("td"),vt=a("Lets you compose multiple "),ol=l("code"),$t=a("PreTokenizer"),jt=a(" that will be run in the given order"),rl=i(),Re=l("td"),gt=l("code"),Ct=a("Sequence([Punctuation(), WhitespaceSplit()])"),this.h()},l(Do){u=o(Do,"TABLE",{});var Il=r(u);m=o(Il,"THEAD",{});var Uo=r(m);h=o(Uo,"TR",{});var Vt=r(h);p=o(Vt,"TH",{align:!0});var Tr=r(p);G=n(Tr,"Name"),Tr.forEach(t),zt=s(Vt),le=o(Vt,"TH",{align:!0});var Fe=r(le);al=n(Fe,"Description"),Fe.forEach(t),Sl=s(Vt),X=o(Vt,"TH",{align:!0});var Wo=r(X);Jt=n(Wo,"Example"),Wo.forEach(t),Vt.forEach(t),Uo.forEach(t),Hl=s(Il),f=o(Il,"TBODY",{});var Et=r(f);g=o(Et,"TR",{});var $o=r(g);x=o($o,"TD",{align:!0});var Mo=r(x);nl=n(Mo,"ByteLevel"),Mo.forEach(t),Rt=s($o),j=o($o,"TD",{align:!0});var or=r(j);il=n(or,"Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),oe=o(or,"UL",{});var Ho=r(oe);Z=o(Ho,"LI",{});var Co=r(Z);Ae=n(Co,"Since it maps on bytes, a tokenizer using this only requires "),U=o(Co,"STRONG",{});var Er=r(U);Ie=n(Er,"256"),Er.forEach(t),Nl=n(Co," characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),Co.forEach(t),Ll=s(Ho),re=o(Ho,"LI",{});var co=r(re);Bl=n(co,"A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),co.forEach(t),xl=s(Ho),ke=o(Ho,"LI",{});var rr=r(ke);mt=n(rr,"For non ascii characters, it gets completely unreadable, but it works nonetheless!"),rr.forEach(t),Ho.forEach(t),or.forEach(t),ae=s($o),D=o($o,"TD",{align:!0});var No=r(D);Fl=n(No,"Input: "),It=o(No,"CODE",{});var Ko=r(It);qe=n(Ko,'"Hello my friend, how are you?"'),Ko.forEach(t),_t=s(No),Ol=o(No,"BR",{}),me=n(No," Ouput: "),Oe=o(No,"CODE",{});var ar=r(Oe);V=n(ar,'"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),ar.forEach(t),No.forEach(t),$o.forEach(t),_e=s(Et),ne=o(Et,"TR",{});var Lo=r(ne);Pe=o(Lo,"TD",{align:!0});var Dr=r(Pe);je=n(Dr,"Whitespace"),Dr.forEach(t),$l=s(Lo),F=o(Lo,"TD",{align:!0});var wl=r(F);Pt=n(wl,"Splits on word boundaries (using the following regular expression: "),Ve=o(wl,"CODE",{});var Yo=r(Ve);ie=n(Yo,"\\w+|[^\\w\\s]+"),Yo.forEach(t),wl.forEach(t),Je=s(Lo),S=o(Lo,"TD",{align:!0});var wo=r(S);Al=n(wo,"Input: "),be=o(wo,"CODE",{});var Go=r(be);sl=n(Go,'"Hello there!"'),Go.forEach(t),ql=s(wo),H=o(wo,"BR",{}),Cl=n(wo," Output: "),P=o(wo,"CODE",{});var wr=r(P);Ul=n(wr,'"Hello", "there", "!"'),wr.forEach(t),wo.forEach(t),Lo.forEach(t),dl=s(Et),se=o(Et,"TR",{});var zo=r(se);Qe=o(zo,"TD",{align:!0});var Bo=r(Qe);Xe=n(Bo,"WhitespaceSplit"),Bo.forEach(t),Wl=s(zo),Ze=o(zo,"TD",{align:!0});var yr=r(Ze);cl=n(yr,"Splits on any whitespace character"),yr.forEach(t),de=s(zo),y=o(zo,"TD",{align:!0});var ho=r(y);hl=n(ho,"Input: "),St=o(ho,"CODE",{});var Ro=r(St);et=n(Ro,'"Hello there!"'),Ro.forEach(t),zl=s(ho),bt=o(ho,"BR",{}),O=n(ho," Output: "),Te=o(ho,"CODE",{});var kr=r(Te);$e=n(kr,'"Hello", "there!"'),kr.forEach(t),ho.forEach(t),zo.forEach(t),fl=s(Et),W=o(Et,"TR",{});var jo=r(W);De=o(jo,"TD",{align:!0});var so=r(De);ul=n(so,"Punctuation"),so.forEach(t),Ml=s(jo),Ue=o(jo,"TD",{align:!0});var Or=r(Ue);Qt=n(Or,"Will isolate all punctuation characters"),Or.forEach(t),Ht=s(jo),A=o(jo,"TD",{align:!0});var Io=r(A);Tt=n(Io,"Input: "),N=o(Io,"CODE",{});var Vo=r(N);we=n(Vo,'"Hello?"'),Vo.forEach(t),Xt=s(Io),Kl=o(Io,"BR",{}),tt=n(Io," Ouput: "),We=o(Io,"CODE",{});var $r=r(We);Yl=n($r,'"Hello", "?"'),$r.forEach(t),Io.forEach(t),jo.forEach(t),M=s(Et),C=o(Et,"TR",{});var Jo=r(C);J=o(Jo,"TD",{align:!0});var fo=r(J);Zt=n(fo,"Metaspace"),fo.forEach(t),Gl=s(Jo),lt=o(Jo,"TD",{align:!0});var nr=r(lt);Me=n(nr,"Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),nr.forEach(t),Nt=s(Jo),L=o(Jo,"TD",{align:!0});var xo=r(L);jl=n(xo,"Input: "),K=o(xo,"CODE",{});var Qo=r(K);Se=n(Qo,'"Hello there"'),Qo.forEach(t),Vl=s(xo),Jl=o(xo,"BR",{}),ot=n(xo," Ouput: "),He=o(xo,"CODE",{});var Fo=r(He);el=n(Fo,'"Hello", "\u2581there"'),Fo.forEach(t),xo.forEach(t),Jo.forEach(t),k=s(Et),Y=o(Et,"TR",{});var Xo=r(Y);Ce=o(Xo,"TD",{align:!0});var Pl=r(Ce);Ql=n(Pl,"CharDelimiterSplit"),Pl.forEach(t),Xl=s(Xo),ye=o(Xo,"TD",{align:!0});var Cr=r(ye);Ke=n(Cr,"Splits on a given character"),Cr.forEach(t),Zl=s(Xo),w=o(Xo,"TD",{align:!0});var uo=r(w);Dt=n(uo,"Example with "),Lt=o(uo,"CODE",{});var mr=r(Lt);rt=n(mr,"x"),mr.forEach(t),eo=n(uo,": "),to=o(uo,"BR",{}),ce=n(uo," Input: "),Q=o(uo,"CODE",{});var c=r(Q);tl=n(c,'"Helloxthere"'),c.forEach(t),lo=s(uo),Ne=o(uo,"BR",{}),ll=n(uo," Ouput: "),z=o(uo,"CODE",{});var v=r(z);wt=n(v,'"Hello", "there"'),v.forEach(t),uo.forEach(t),Xo.forEach(t),at=s(Et),q=o(Et,"TR",{});var yo=r(q);he=o(yo,"TD",{align:!0});var Po=r(he);Bt=n(Po,"Digits"),Po.forEach(t),oo=s(yo),fe=o(yo,"TD",{align:!0});var Pr=r(fe);ro=n(Pr,"Splits the numbers from any other characters."),Pr.forEach(t),Rl=s(yo),b=o(yo,"TD",{align:!0});var Zo=r(b);ao=n(Zo,"Input: "),nt=o(Zo,"CODE",{});var ir=r(nt);xt=n(ir,'"Hello123there"'),ir.forEach(t),no=s(Zo),ee=o(Zo,"BR",{}),ve=n(Zo,"  Output: "),it=o(Zo,"CODE",{});var _r=r(it);st=n(_r,'"Hello", "123", "there"'),_r.forEach(t),Zo.forEach(t),yo.forEach(t),ze=s(Et),ue=o(Et,"TR",{});var er=r(ue);dt=o(er,"TD",{align:!0});var sr=r(dt);Le=n(sr,"Split"),sr.forEach(t),Ft=s(er),ge=o(er,"TD",{align:!0});var zr=r(ge);At=n(zr,"Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),B=o(zr,"UL",{});var ko=r(B);pl=o(ko,"LI",{});var dr=r(pl);qt=n(dr,"pattern should be either a custom string or regexp."),dr.forEach(t),Ut=s(ko),T=o(ko,"LI",{});var Rr=r(T);vl=n(Rr,"behavior should be one of: "),_=o(Rr,"UL",{});var Ao=r(_);Ee=o(Ao,"LI",{});var Sr=r(Ee);gl=n(Sr,"removed"),Sr.forEach(t),Wt=o(Ao,"LI",{});var br=r(Wt);El=n(br,"isolated"),br.forEach(t),ct=o(Ao,"LI",{});var Hr=r(ct);po=n(Hr,"merged_with_previous"),Hr.forEach(t),R=o(Ao,"LI",{});var Nr=r(R);ml=n(Nr,"merged_with_next"),Nr.forEach(t),_l=o(Ao,"LI",{});var yl=r(_l);bl=n(yl,"contiguous"),yl.forEach(t),Ao.forEach(t),Rr.forEach(t),Be=s(ko),yt=o(ko,"LI",{});var tr=r(yt);Tl=n(tr,"invert should be a boolean flag."),tr.forEach(t),ko.forEach(t),zr.forEach(t),ht=s(er),E=o(er,"TD",{align:!0});var kl=r(E);Mt=n(kl,"Example with pattern = "),Ye=o(kl,"CODE",{});var Ar=r(Ye);Ar.forEach(t),vo=n(kl,", behavior = "),xe=o(kl,"CODE",{});var Lr=r(xe);kt=n(Lr,'"isolated"'),Lr.forEach(t),go=n(kl,", invert = "),pe=o(kl,"CODE",{});var So=r(pe);Eo=n(So,"False"),So.forEach(t),ft=n(kl,": "),io=o(kl,"BR",{}),Kt=n(kl," Input: "),Ge=o(kl,"CODE",{});var cr=r(Ge);mo=n(cr,'"Hello, how are you?"'),cr.forEach(t),Ot=s(kl),Yt=o(kl,"BR",{}),_o=n(kl," Output: "),ut=o(kl,"CODE",{});var Br=r(ut);pt=n(Br,'"Hello,", " ", "how", " ", "are", " ", "you?"'),Br.forEach(t),kl.forEach(t),er.forEach(t),bo=s(Et),I=o(Et,"TR",{});var qo=r(I);Gt=o(qo,"TD",{align:!0});var xr=r(Gt);Dl=n(xr,"Sequence"),xr.forEach(t),To=s(qo),te=o(qo,"TD",{align:!0});var Ir=r(te);vt=n(Ir,"Lets you compose multiple "),ol=o(Ir,"CODE",{});var jr=r(ol);$t=n(jr,"PreTokenizer"),jr.forEach(t),jt=n(Ir," that will be run in the given order"),Ir.forEach(t),rl=s(qo),Re=o(qo,"TD",{align:!0});var Vr=r(Re);gt=o(Vr,"CODE",{});var Jr=r(gt);Ct=n(Jr,"Sequence([Punctuation(), WhitespaceSplit()])"),Jr.forEach(t),Vr.forEach(t),qo.forEach(t),Et.forEach(t),Il.forEach(t),this.h()},h(){d(p,"align","left"),d(le,"align","left"),d(X,"align","left"),d(x,"align","left"),d(j,"align","left"),d(D,"align","left"),d(Pe,"align","left"),d(F,"align","left"),d(S,"align","left"),d(Qe,"align","left"),d(Ze,"align","left"),d(y,"align","left"),d(De,"align","left"),d(Ue,"align","left"),d(A,"align","left"),d(J,"align","left"),d(lt,"align","left"),d(L,"align","left"),d(Ce,"align","left"),d(ye,"align","left"),d(w,"align","left"),d(he,"align","left"),d(fe,"align","left"),d(b,"align","left"),d(dt,"align","left"),d(ge,"align","left"),d(E,"align","left"),d(Gt,"align","left"),d(te,"align","left"),d(Re,"align","left")},m(Do,Il){$(Do,u,Il),e(u,m),e(m,h),e(h,p),e(p,G),e(h,zt),e(h,le),e(le,al),e(h,Sl),e(h,X),e(X,Jt),e(u,Hl),e(u,f),e(f,g),e(g,x),e(x,nl),e(g,Rt),e(g,j),e(j,il),e(j,oe),e(oe,Z),e(Z,Ae),e(Z,U),e(U,Ie),e(Z,Nl),e(oe,Ll),e(oe,re),e(re,Bl),e(oe,xl),e(oe,ke),e(ke,mt),e(g,ae),e(g,D),e(D,Fl),e(D,It),e(It,qe),e(D,_t),e(D,Ol),e(D,me),e(D,Oe),e(Oe,V),e(f,_e),e(f,ne),e(ne,Pe),e(Pe,je),e(ne,$l),e(ne,F),e(F,Pt),e(F,Ve),e(Ve,ie),e(ne,Je),e(ne,S),e(S,Al),e(S,be),e(be,sl),e(S,ql),e(S,H),e(S,Cl),e(S,P),e(P,Ul),e(f,dl),e(f,se),e(se,Qe),e(Qe,Xe),e(se,Wl),e(se,Ze),e(Ze,cl),e(se,de),e(se,y),e(y,hl),e(y,St),e(St,et),e(y,zl),e(y,bt),e(y,O),e(y,Te),e(Te,$e),e(f,fl),e(f,W),e(W,De),e(De,ul),e(W,Ml),e(W,Ue),e(Ue,Qt),e(W,Ht),e(W,A),e(A,Tt),e(A,N),e(N,we),e(A,Xt),e(A,Kl),e(A,tt),e(A,We),e(We,Yl),e(f,M),e(f,C),e(C,J),e(J,Zt),e(C,Gl),e(C,lt),e(lt,Me),e(C,Nt),e(C,L),e(L,jl),e(L,K),e(K,Se),e(L,Vl),e(L,Jl),e(L,ot),e(L,He),e(He,el),e(f,k),e(f,Y),e(Y,Ce),e(Ce,Ql),e(Y,Xl),e(Y,ye),e(ye,Ke),e(Y,Zl),e(Y,w),e(w,Dt),e(w,Lt),e(Lt,rt),e(w,eo),e(w,to),e(w,ce),e(w,Q),e(Q,tl),e(w,lo),e(w,Ne),e(w,ll),e(w,z),e(z,wt),e(f,at),e(f,q),e(q,he),e(he,Bt),e(q,oo),e(q,fe),e(fe,ro),e(q,Rl),e(q,b),e(b,ao),e(b,nt),e(nt,xt),e(b,no),e(b,ee),e(b,ve),e(b,it),e(it,st),e(f,ze),e(f,ue),e(ue,dt),e(dt,Le),e(ue,Ft),e(ue,ge),e(ge,At),e(ge,B),e(B,pl),e(pl,qt),e(B,Ut),e(B,T),e(T,vl),e(T,_),e(_,Ee),e(Ee,gl),e(_,Wt),e(Wt,El),e(_,ct),e(ct,po),e(_,R),e(R,ml),e(_,_l),e(_l,bl),e(B,Be),e(B,yt),e(yt,Tl),e(ue,ht),e(ue,E),e(E,Mt),e(E,Ye),e(E,vo),e(E,xe),e(xe,kt),e(E,go),e(E,pe),e(pe,Eo),e(E,ft),e(E,io),e(E,Kt),e(E,Ge),e(Ge,mo),e(E,Ot),e(E,Yt),e(E,_o),e(E,ut),e(ut,pt),e(f,bo),e(f,I),e(I,Gt),e(Gt,Dl),e(I,To),e(I,te),e(te,vt),e(te,ol),e(ol,$t),e(te,jt),e(I,rl),e(I,Re),e(Re,gt),e(gt,Ct)},d(Do){Do&&t(u)}}}function kn(Oo){let u,m;return u=new Ea({props:{$$slots:{default:[yn]},$$scope:{ctx:Oo}}}),{c(){hr(u.$$.fragment)},l(h){fr(u.$$.fragment,h)},m(h,p){ur(u,h,p),m=!0},p(h,p){const G={};p&2&&(G.$$scope={dirty:p,ctx:h}),u.$set(G)},i(h){m||(pr(u.$$.fragment,h),m=!0)},o(h){vr(u.$$.fragment,h),m=!1},d(h){gr(u,h)}}}function On(Oo){let u,m,h,p,G,zt,le,al,Sl,X,Jt,Hl,f,g,x,nl,Rt,j,il,oe,Z,Ae,U,Ie,Nl,Ll,re,Bl,xl,ke,mt,ae,D,Fl,It,qe,_t,Ol,me,Oe,V,_e,ne,Pe,je,$l,F,Pt,Ve,ie,Je,S,Al,be,sl,ql,H,Cl,P,Ul,dl,se,Qe,Xe,Wl,Ze,cl,de,y,hl,St,et,zl,bt,O,Te,$e,fl,W,De,ul,Ml,Ue,Qt,Ht,A,Tt,N,we,Xt,Kl,tt,We,Yl,M,C,J,Zt,Gl,lt,Me,Nt,L,jl,K,Se,Vl,Jl,ot,He,el,k,Y,Ce,Ql,Xl,ye,Ke,Zl,w,Dt,Lt,rt,eo,to,ce,Q,tl,lo,Ne,ll,z,wt,at,q,he,Bt,oo,fe,ro,Rl,b,ao,nt,xt,no,ee,ve,it,st,ze,ue,dt,Le,Ft,ge,At,B,pl,qt,Ut,T,vl,_,Ee,gl,Wt,El,ct,po,R,ml,_l,bl,Be,yt,Tl,ht,E,Mt,Ye,vo,xe,kt,go,pe,Eo,ft,io,Kt,Ge,mo,Ot,Yt,_o,ut,pt,bo,I,Gt,Dl,To,te,vt,ol,$t,jt,rl,Re;return{c(){u=l("table"),m=l("thead"),h=l("tr"),p=l("th"),G=a("Name"),zt=i(),le=l("th"),al=a("Description"),Sl=i(),X=l("th"),Jt=a("Example"),Hl=i(),f=l("tbody"),g=l("tr"),x=l("td"),nl=a("ByteLevel"),Rt=i(),j=l("td"),il=a("Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),oe=l("ul"),Z=l("li"),Ae=a("Since it maps on bytes, a tokenizer using this only requires "),U=l("strong"),Ie=a("256"),Nl=a(" characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),Ll=i(),re=l("li"),Bl=a("A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),xl=i(),ke=l("li"),mt=a("For non ascii characters, it gets completely unreadable, but it works nonetheless!"),ae=i(),D=l("td"),Fl=a("Input: "),It=l("code"),qe=a('"Hello my friend, how are you?"'),_t=i(),Ol=l("br"),me=a(" Ouput: "),Oe=l("code"),V=a('"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),_e=i(),ne=l("tr"),Pe=l("td"),je=a("Whitespace"),$l=i(),F=l("td"),Pt=a("Splits on word boundaries (using the following regular expression: "),Ve=l("code"),ie=a("\\w+|[^\\w\\s]+"),Je=i(),S=l("td"),Al=a("Input: "),be=l("code"),sl=a('"Hello there!"'),ql=i(),H=l("br"),Cl=a(" Output: "),P=l("code"),Ul=a('"Hello", "there", "!"'),dl=i(),se=l("tr"),Qe=l("td"),Xe=a("WhitespaceSplit"),Wl=i(),Ze=l("td"),cl=a("Splits on any whitespace character"),de=i(),y=l("td"),hl=a("Input: "),St=l("code"),et=a('"Hello there!"'),zl=i(),bt=l("br"),O=a(" Output: "),Te=l("code"),$e=a('"Hello", "there!"'),fl=i(),W=l("tr"),De=l("td"),ul=a("Punctuation"),Ml=i(),Ue=l("td"),Qt=a("Will isolate all punctuation characters"),Ht=i(),A=l("td"),Tt=a("Input: "),N=l("code"),we=a('"Hello?"'),Xt=i(),Kl=l("br"),tt=a(" Ouput: "),We=l("code"),Yl=a('"Hello", "?"'),M=i(),C=l("tr"),J=l("td"),Zt=a("Metaspace"),Gl=i(),lt=l("td"),Me=a("Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),Nt=i(),L=l("td"),jl=a("Input: "),K=l("code"),Se=a('"Hello there"'),Vl=i(),Jl=l("br"),ot=a(" Ouput: "),He=l("code"),el=a('"Hello", "\u2581there"'),k=i(),Y=l("tr"),Ce=l("td"),Ql=a("CharDelimiterSplit"),Xl=i(),ye=l("td"),Ke=a("Splits on a given character"),Zl=i(),w=l("td"),Dt=a("Example with "),Lt=l("code"),rt=a("x"),eo=a(": "),to=l("br"),ce=a(" Input: "),Q=l("code"),tl=a('"Helloxthere"'),lo=i(),Ne=l("br"),ll=a(" Ouput: "),z=l("code"),wt=a('"Hello", "there"'),at=i(),q=l("tr"),he=l("td"),Bt=a("Digits"),oo=i(),fe=l("td"),ro=a("Splits the numbers from any other characters."),Rl=i(),b=l("td"),ao=a("Input: "),nt=l("code"),xt=a('"Hello123there"'),no=i(),ee=l("br"),ve=a("  Output: "),it=l("code"),st=a('"Hello", "123", "there"'),ze=i(),ue=l("tr"),dt=l("td"),Le=a("Split"),Ft=i(),ge=l("td"),At=a("Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),B=l("ul"),pl=l("li"),qt=a("pattern should be either a custom string or regexp."),Ut=i(),T=l("li"),vl=a("behavior should be one of: "),_=l("ul"),Ee=l("li"),gl=a("removed"),Wt=l("li"),El=a("isolated"),ct=l("li"),po=a("mergedWithPrevious"),R=l("li"),ml=a("mergedWithNext"),_l=l("li"),bl=a("contiguous"),Be=i(),yt=l("li"),Tl=a("invert should be a boolean flag."),ht=i(),E=l("td"),Mt=a("Example with pattern = "),Ye=l("code"),vo=a(", behavior = "),xe=l("code"),kt=a('"isolated"'),go=a(", invert = "),pe=l("code"),Eo=a("False"),ft=a(": "),io=l("br"),Kt=a(" Input: "),Ge=l("code"),mo=a('"Hello, how are you?"'),Ot=i(),Yt=l("br"),_o=a(" Output: "),ut=l("code"),pt=a('"Hello,", " ", "how", " ", "are", " ", "you?"'),bo=i(),I=l("tr"),Gt=l("td"),Dl=a("Sequence"),To=i(),te=l("td"),vt=a("Lets you compose multiple "),ol=l("code"),$t=a("PreTokenizer"),jt=a(" that will be run in the given order"),rl=i(),Re=l("td"),this.h()},l(gt){u=o(gt,"TABLE",{});var Ct=r(u);m=o(Ct,"THEAD",{});var Do=r(m);h=o(Do,"TR",{});var Il=r(h);p=o(Il,"TH",{align:!0});var Uo=r(p);G=n(Uo,"Name"),Uo.forEach(t),zt=s(Il),le=o(Il,"TH",{align:!0});var Vt=r(le);al=n(Vt,"Description"),Vt.forEach(t),Sl=s(Il),X=o(Il,"TH",{align:!0});var Tr=r(X);Jt=n(Tr,"Example"),Tr.forEach(t),Il.forEach(t),Do.forEach(t),Hl=s(Ct),f=o(Ct,"TBODY",{});var Fe=r(f);g=o(Fe,"TR",{});var Wo=r(g);x=o(Wo,"TD",{align:!0});var Et=r(x);nl=n(Et,"ByteLevel"),Et.forEach(t),Rt=s(Wo),j=o(Wo,"TD",{align:!0});var $o=r(j);il=n($o,"Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),oe=o($o,"UL",{});var Mo=r(oe);Z=o(Mo,"LI",{});var or=r(Z);Ae=n(or,"Since it maps on bytes, a tokenizer using this only requires "),U=o(or,"STRONG",{});var Ho=r(U);Ie=n(Ho,"256"),Ho.forEach(t),Nl=n(or," characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),or.forEach(t),Ll=s(Mo),re=o(Mo,"LI",{});var Co=r(re);Bl=n(Co,"A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),Co.forEach(t),xl=s(Mo),ke=o(Mo,"LI",{});var Er=r(ke);mt=n(Er,"For non ascii characters, it gets completely unreadable, but it works nonetheless!"),Er.forEach(t),Mo.forEach(t),$o.forEach(t),ae=s(Wo),D=o(Wo,"TD",{align:!0});var co=r(D);Fl=n(co,"Input: "),It=o(co,"CODE",{});var rr=r(It);qe=n(rr,'"Hello my friend, how are you?"'),rr.forEach(t),_t=s(co),Ol=o(co,"BR",{}),me=n(co," Ouput: "),Oe=o(co,"CODE",{});var No=r(Oe);V=n(No,'"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),No.forEach(t),co.forEach(t),Wo.forEach(t),_e=s(Fe),ne=o(Fe,"TR",{});var Ko=r(ne);Pe=o(Ko,"TD",{align:!0});var ar=r(Pe);je=n(ar,"Whitespace"),ar.forEach(t),$l=s(Ko),F=o(Ko,"TD",{align:!0});var Lo=r(F);Pt=n(Lo,"Splits on word boundaries (using the following regular expression: "),Ve=o(Lo,"CODE",{});var Dr=r(Ve);ie=n(Dr,"\\w+|[^\\w\\s]+"),Dr.forEach(t),Lo.forEach(t),Je=s(Ko),S=o(Ko,"TD",{align:!0});var wl=r(S);Al=n(wl,"Input: "),be=o(wl,"CODE",{});var Yo=r(be);sl=n(Yo,'"Hello there!"'),Yo.forEach(t),ql=s(wl),H=o(wl,"BR",{}),Cl=n(wl," Output: "),P=o(wl,"CODE",{});var wo=r(P);Ul=n(wo,'"Hello", "there", "!"'),wo.forEach(t),wl.forEach(t),Ko.forEach(t),dl=s(Fe),se=o(Fe,"TR",{});var Go=r(se);Qe=o(Go,"TD",{align:!0});var wr=r(Qe);Xe=n(wr,"WhitespaceSplit"),wr.forEach(t),Wl=s(Go),Ze=o(Go,"TD",{align:!0});var zo=r(Ze);cl=n(zo,"Splits on any whitespace character"),zo.forEach(t),de=s(Go),y=o(Go,"TD",{align:!0});var Bo=r(y);hl=n(Bo,"Input: "),St=o(Bo,"CODE",{});var yr=r(St);et=n(yr,'"Hello there!"'),yr.forEach(t),zl=s(Bo),bt=o(Bo,"BR",{}),O=n(Bo," Output: "),Te=o(Bo,"CODE",{});var ho=r(Te);$e=n(ho,'"Hello", "there!"'),ho.forEach(t),Bo.forEach(t),Go.forEach(t),fl=s(Fe),W=o(Fe,"TR",{});var Ro=r(W);De=o(Ro,"TD",{align:!0});var kr=r(De);ul=n(kr,"Punctuation"),kr.forEach(t),Ml=s(Ro),Ue=o(Ro,"TD",{align:!0});var jo=r(Ue);Qt=n(jo,"Will isolate all punctuation characters"),jo.forEach(t),Ht=s(Ro),A=o(Ro,"TD",{align:!0});var so=r(A);Tt=n(so,"Input: "),N=o(so,"CODE",{});var Or=r(N);we=n(Or,'"Hello?"'),Or.forEach(t),Xt=s(so),Kl=o(so,"BR",{}),tt=n(so," Ouput: "),We=o(so,"CODE",{});var Io=r(We);Yl=n(Io,'"Hello", "?"'),Io.forEach(t),so.forEach(t),Ro.forEach(t),M=s(Fe),C=o(Fe,"TR",{});var Vo=r(C);J=o(Vo,"TD",{align:!0});var $r=r(J);Zt=n($r,"Metaspace"),$r.forEach(t),Gl=s(Vo),lt=o(Vo,"TD",{align:!0});var Jo=r(lt);Me=n(Jo,"Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),Jo.forEach(t),Nt=s(Vo),L=o(Vo,"TD",{align:!0});var fo=r(L);jl=n(fo,"Input: "),K=o(fo,"CODE",{});var nr=r(K);Se=n(nr,'"Hello there"'),nr.forEach(t),Vl=s(fo),Jl=o(fo,"BR",{}),ot=n(fo," Ouput: "),He=o(fo,"CODE",{});var xo=r(He);el=n(xo,'"Hello", "\u2581there"'),xo.forEach(t),fo.forEach(t),Vo.forEach(t),k=s(Fe),Y=o(Fe,"TR",{});var Qo=r(Y);Ce=o(Qo,"TD",{align:!0});var Fo=r(Ce);Ql=n(Fo,"CharDelimiterSplit"),Fo.forEach(t),Xl=s(Qo),ye=o(Qo,"TD",{align:!0});var Xo=r(ye);Ke=n(Xo,"Splits on a given character"),Xo.forEach(t),Zl=s(Qo),w=o(Qo,"TD",{align:!0});var Pl=r(w);Dt=n(Pl,"Example with "),Lt=o(Pl,"CODE",{});var Cr=r(Lt);rt=n(Cr,"x"),Cr.forEach(t),eo=n(Pl,": "),to=o(Pl,"BR",{}),ce=n(Pl," Input: "),Q=o(Pl,"CODE",{});var uo=r(Q);tl=n(uo,'"Helloxthere"'),uo.forEach(t),lo=s(Pl),Ne=o(Pl,"BR",{}),ll=n(Pl," Ouput: "),z=o(Pl,"CODE",{});var mr=r(z);wt=n(mr,'"Hello", "there"'),mr.forEach(t),Pl.forEach(t),Qo.forEach(t),at=s(Fe),q=o(Fe,"TR",{});var c=r(q);he=o(c,"TD",{align:!0});var v=r(he);Bt=n(v,"Digits"),v.forEach(t),oo=s(c),fe=o(c,"TD",{align:!0});var yo=r(fe);ro=n(yo,"Splits the numbers from any other characters."),yo.forEach(t),Rl=s(c),b=o(c,"TD",{align:!0});var Po=r(b);ao=n(Po,"Input: "),nt=o(Po,"CODE",{});var Pr=r(nt);xt=n(Pr,'"Hello123there"'),Pr.forEach(t),no=s(Po),ee=o(Po,"BR",{}),ve=n(Po,"  Output: "),it=o(Po,"CODE",{});var Zo=r(it);st=n(Zo,'"Hello", "123", "there"'),Zo.forEach(t),Po.forEach(t),c.forEach(t),ze=s(Fe),ue=o(Fe,"TR",{});var ir=r(ue);dt=o(ir,"TD",{align:!0});var _r=r(dt);Le=n(_r,"Split"),_r.forEach(t),Ft=s(ir),ge=o(ir,"TD",{align:!0});var er=r(ge);At=n(er,"Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),B=o(er,"UL",{});var sr=r(B);pl=o(sr,"LI",{});var zr=r(pl);qt=n(zr,"pattern should be either a custom string or regexp."),zr.forEach(t),Ut=s(sr),T=o(sr,"LI",{});var ko=r(T);vl=n(ko,"behavior should be one of: "),_=o(ko,"UL",{});var dr=r(_);Ee=o(dr,"LI",{});var Rr=r(Ee);gl=n(Rr,"removed"),Rr.forEach(t),Wt=o(dr,"LI",{});var Ao=r(Wt);El=n(Ao,"isolated"),Ao.forEach(t),ct=o(dr,"LI",{});var Sr=r(ct);po=n(Sr,"mergedWithPrevious"),Sr.forEach(t),R=o(dr,"LI",{});var br=r(R);ml=n(br,"mergedWithNext"),br.forEach(t),_l=o(dr,"LI",{});var Hr=r(_l);bl=n(Hr,"contiguous"),Hr.forEach(t),dr.forEach(t),ko.forEach(t),Be=s(sr),yt=o(sr,"LI",{});var Nr=r(yt);Tl=n(Nr,"invert should be a boolean flag."),Nr.forEach(t),sr.forEach(t),er.forEach(t),ht=s(ir),E=o(ir,"TD",{align:!0});var yl=r(E);Mt=n(yl,"Example with pattern = "),Ye=o(yl,"CODE",{});var tr=r(Ye);tr.forEach(t),vo=n(yl,", behavior = "),xe=o(yl,"CODE",{});var kl=r(xe);kt=n(kl,'"isolated"'),kl.forEach(t),go=n(yl,", invert = "),pe=o(yl,"CODE",{});var Ar=r(pe);Eo=n(Ar,"False"),Ar.forEach(t),ft=n(yl,": "),io=o(yl,"BR",{}),Kt=n(yl," Input: "),Ge=o(yl,"CODE",{});var Lr=r(Ge);mo=n(Lr,'"Hello, how are you?"'),Lr.forEach(t),Ot=s(yl),Yt=o(yl,"BR",{}),_o=n(yl," Output: "),ut=o(yl,"CODE",{});var So=r(ut);pt=n(So,'"Hello,", " ", "how", " ", "are", " ", "you?"'),So.forEach(t),yl.forEach(t),ir.forEach(t),bo=s(Fe),I=o(Fe,"TR",{});var cr=r(I);Gt=o(cr,"TD",{align:!0});var Br=r(Gt);Dl=n(Br,"Sequence"),Br.forEach(t),To=s(cr),te=o(cr,"TD",{align:!0});var qo=r(te);vt=n(qo,"Lets you compose multiple "),ol=o(qo,"CODE",{});var xr=r(ol);$t=n(xr,"PreTokenizer"),xr.forEach(t),jt=n(qo," that will be run in the given order"),qo.forEach(t),rl=s(cr),Re=o(cr,"TD",{align:!0}),r(Re).forEach(t),cr.forEach(t),Fe.forEach(t),Ct.forEach(t),this.h()},h(){d(p,"align","left"),d(le,"align","left"),d(X,"align","left"),d(x,"align","left"),d(j,"align","left"),d(D,"align","left"),d(Pe,"align","left"),d(F,"align","left"),d(S,"align","left"),d(Qe,"align","left"),d(Ze,"align","left"),d(y,"align","left"),d(De,"align","left"),d(Ue,"align","left"),d(A,"align","left"),d(J,"align","left"),d(lt,"align","left"),d(L,"align","left"),d(Ce,"align","left"),d(ye,"align","left"),d(w,"align","left"),d(he,"align","left"),d(fe,"align","left"),d(b,"align","left"),d(dt,"align","left"),d(ge,"align","left"),d(E,"align","left"),d(Gt,"align","left"),d(te,"align","left"),d(Re,"align","left")},m(gt,Ct){$(gt,u,Ct),e(u,m),e(m,h),e(h,p),e(p,G),e(h,zt),e(h,le),e(le,al),e(h,Sl),e(h,X),e(X,Jt),e(u,Hl),e(u,f),e(f,g),e(g,x),e(x,nl),e(g,Rt),e(g,j),e(j,il),e(j,oe),e(oe,Z),e(Z,Ae),e(Z,U),e(U,Ie),e(Z,Nl),e(oe,Ll),e(oe,re),e(re,Bl),e(oe,xl),e(oe,ke),e(ke,mt),e(g,ae),e(g,D),e(D,Fl),e(D,It),e(It,qe),e(D,_t),e(D,Ol),e(D,me),e(D,Oe),e(Oe,V),e(f,_e),e(f,ne),e(ne,Pe),e(Pe,je),e(ne,$l),e(ne,F),e(F,Pt),e(F,Ve),e(Ve,ie),e(ne,Je),e(ne,S),e(S,Al),e(S,be),e(be,sl),e(S,ql),e(S,H),e(S,Cl),e(S,P),e(P,Ul),e(f,dl),e(f,se),e(se,Qe),e(Qe,Xe),e(se,Wl),e(se,Ze),e(Ze,cl),e(se,de),e(se,y),e(y,hl),e(y,St),e(St,et),e(y,zl),e(y,bt),e(y,O),e(y,Te),e(Te,$e),e(f,fl),e(f,W),e(W,De),e(De,ul),e(W,Ml),e(W,Ue),e(Ue,Qt),e(W,Ht),e(W,A),e(A,Tt),e(A,N),e(N,we),e(A,Xt),e(A,Kl),e(A,tt),e(A,We),e(We,Yl),e(f,M),e(f,C),e(C,J),e(J,Zt),e(C,Gl),e(C,lt),e(lt,Me),e(C,Nt),e(C,L),e(L,jl),e(L,K),e(K,Se),e(L,Vl),e(L,Jl),e(L,ot),e(L,He),e(He,el),e(f,k),e(f,Y),e(Y,Ce),e(Ce,Ql),e(Y,Xl),e(Y,ye),e(ye,Ke),e(Y,Zl),e(Y,w),e(w,Dt),e(w,Lt),e(Lt,rt),e(w,eo),e(w,to),e(w,ce),e(w,Q),e(Q,tl),e(w,lo),e(w,Ne),e(w,ll),e(w,z),e(z,wt),e(f,at),e(f,q),e(q,he),e(he,Bt),e(q,oo),e(q,fe),e(fe,ro),e(q,Rl),e(q,b),e(b,ao),e(b,nt),e(nt,xt),e(b,no),e(b,ee),e(b,ve),e(b,it),e(it,st),e(f,ze),e(f,ue),e(ue,dt),e(dt,Le),e(ue,Ft),e(ue,ge),e(ge,At),e(ge,B),e(B,pl),e(pl,qt),e(B,Ut),e(B,T),e(T,vl),e(T,_),e(_,Ee),e(Ee,gl),e(_,Wt),e(Wt,El),e(_,ct),e(ct,po),e(_,R),e(R,ml),e(_,_l),e(_l,bl),e(B,Be),e(B,yt),e(yt,Tl),e(ue,ht),e(ue,E),e(E,Mt),e(E,Ye),e(E,vo),e(E,xe),e(xe,kt),e(E,go),e(E,pe),e(pe,Eo),e(E,ft),e(E,io),e(E,Kt),e(E,Ge),e(Ge,mo),e(E,Ot),e(E,Yt),e(E,_o),e(E,ut),e(ut,pt),e(f,bo),e(f,I),e(I,Gt),e(Gt,Dl),e(I,To),e(I,te),e(te,vt),e(te,ol),e(ol,$t),e(te,jt),e(I,rl),e(I,Re)},d(gt){gt&&t(u)}}}function $n(Oo){let u,m;return u=new Ea({props:{$$slots:{default:[On]},$$scope:{ctx:Oo}}}),{c(){hr(u.$$.fragment)},l(h){fr(u.$$.fragment,h)},m(h,p){ur(u,h,p),m=!0},p(h,p){const G={};p&2&&(G.$$scope={dirty:p,ctx:h}),u.$set(G)},i(h){m||(pr(u.$$.fragment,h),m=!0)},o(h){vr(u.$$.fragment,h),m=!1},d(h){gr(u,h)}}}function Cn(Oo){let u,m,h,p,G,zt,le,al,Sl,X,Jt,Hl,f,g,x,nl,Rt,j,il,oe,Z,Ae,U,Ie,Nl,Ll,re,Bl,xl,ke,mt,ae,D,Fl,It,qe,_t,Ol,me,Oe,V,_e,ne,Pe,je,$l,F,Pt,Ve,ie,Je,S,Al,be,sl,ql,H,Cl,P,Ul,dl,se,Qe,Xe,Wl,Ze,cl,de,y,hl,St,et,zl,bt,O,Te,$e,fl,W,De,ul,Ml,Ue,Qt,Ht,A,Tt,N,we,Xt,Kl,tt,We,Yl,M,C,J,Zt,Gl,lt,Me,Nt,L,jl,K,Se,Vl,Jl,ot,He,el,k,Y,Ce,Ql,Xl,ye,Ke,Zl,w,Dt,Lt,rt,eo,to,ce,Q,tl,lo,Ne,ll,z,wt,at,q,he,Bt,oo,fe,ro,Rl,b,ao,nt,xt,no,ee,ve,it,st,ze,ue,dt,Le,Ft,ge,At,B,pl,qt,Ut,T,vl,_,Ee,gl,Wt,El,ct,po,R,ml,_l,bl,Be,yt,Tl,ht,E,Mt,Ye,vo,xe,kt,go,pe,Eo,ft,io,Kt,Ge,mo,Ot,Yt,_o,ut,pt,bo,I,Gt,Dl,To,te,vt,ol,$t,jt,rl,Re,gt,Ct,Do,Il,Uo,Vt,Tr,Fe,Wo,Et,$o,Mo,or,Ho,Co,Er,co,rr,No,Ko,ar,Lo,Dr,wl,Yo,wo,Go,wr,zo,Bo,yr,ho,Ro,kr,jo,so,Or,Io,Vo,$r,Jo,fo,nr,xo,Qo,Fo,Xo,Pl,Cr,uo,mr;return zt=new Gr({}),Rt=new Gr({}),_t=new pn({props:{python:!0,rust:!1,node:!0,$$slots:{node:[wn],python:[Tn]},$$scope:{ctx:Oo}}}),_e=new Gr({}),bt=new pn({props:{python:!0,rust:!1,node:!0,$$slots:{node:[$n],python:[kn]},$$scope:{ctx:Oo}}}),W=new Gr({}),Bt=new Gr({}),gt=new Gr({}),{c(){u=l("meta"),m=i(),h=l("h1"),p=l("a"),G=l("span"),hr(zt.$$.fragment),le=i(),al=l("span"),Sl=a("Components"),X=i(),Jt=l("p"),Hl=a(`When building a Tokenizer, you can attach various types of components to
this Tokenizer in order to customize its behavior. This page lists most
provided components.`),f=i(),g=l("h2"),x=l("a"),nl=l("span"),hr(Rt.$$.fragment),j=i(),il=l("span"),oe=a("Normalizers"),Z=i(),Ae=l("p"),U=a("A "),Ie=l("code"),Nl=a("Normalizer"),Ll=a(` is in charge of pre-processing the input string in order
to normalize it as relevant for a given use case. Some common examples
of normalization are the Unicode normalization algorithms (NFD, NFKD,
NFC & NFKC), lowercasing etc\u2026 The specificity of `),re=l("code"),Bl=a("tokenizers"),xl=a(` is that
we keep track of the alignment while normalizing. This is essential to
allow mapping from the generated tokens back to the input text.`),ke=i(),mt=l("p"),ae=a("The "),D=l("code"),Fl=a("Normalizer"),It=a(" is optional."),qe=i(),hr(_t.$$.fragment),Ol=i(),me=l("h2"),Oe=l("a"),V=l("span"),hr(_e.$$.fragment),ne=i(),Pe=l("span"),je=a("Pre-tokenizers"),$l=i(),F=l("p"),Pt=a("The "),Ve=l("code"),ie=a("PreTokenizer"),Je=a(` takes care of splitting the input according to a set
of rules. This pre-processing lets you ensure that the underlying
`),S=l("code"),Al=a("Model"),be=a(` does not build tokens across multiple \u201Csplits\u201D. For example if
you don\u2019t want to have whitespaces inside a token, then you can have a
`),sl=l("code"),ql=a("PreTokenizer"),H=a(" that splits on these whitespaces."),Cl=i(),P=l("p"),Ul=a("You can easily combine multiple "),dl=l("code"),se=a("PreTokenizer"),Qe=a(` together using a
`),Xe=l("code"),Wl=a("Sequence"),Ze=a(" (see below). The "),cl=l("code"),de=a("PreTokenizer"),y=a(` is also allowed to modify the
string, just like a `),hl=l("code"),St=a("Normalizer"),et=a(` does. This is necessary to allow some
complicated algorithms that require to split before normalizing (e.g.
the ByteLevel)`),zl=i(),hr(bt.$$.fragment),O=i(),Te=l("h2"),$e=l("a"),fl=l("span"),hr(W.$$.fragment),De=i(),ul=l("span"),Ml=a("Models"),Ue=i(),Qt=l("p"),Ht=a(`Models are the core algorithms used to actually tokenize, and therefore,
they are the only mandatory component of a Tokenizer.`),A=i(),Tt=l("table"),N=l("thead"),we=l("tr"),Xt=l("th"),Kl=a("Name"),tt=i(),We=l("th"),Yl=a("Description"),M=i(),C=l("tbody"),J=l("tr"),Zt=l("td"),Gl=a("WordLevel"),lt=i(),Me=l("td"),Nt=a("This is the \u201Cclassic\u201D tokenization algorithm. It let\u2019s you simply map words to IDs without anything fancy. This has the advantage of being really simple to use and understand, but it requires extremely large vocabularies for a good coverage. Using this "),L=l("code"),jl=a("Model"),K=a(" requires the use of a "),Se=l("code"),Vl=a("PreTokenizer"),Jl=a(". No choice will be made by this model directly, it simply maps input tokens to IDs."),ot=i(),He=l("tr"),el=l("td"),k=a("BPE"),Y=i(),Ce=l("td"),Ql=a("One of the most popular subword tokenization algorithm. The Byte-Pair-Encoding works by starting with characters, while merging those that are the most frequently seen together, thus creating new tokens. It then works iteratively to build new tokens out of the most frequent pairs it sees in a corpus. BPE is able to build words it has never seen by using multiple subword tokens, and thus requires smaller vocabularies, with less chances of having \u201Cunk\u201D (unknown) tokens."),Xl=i(),ye=l("tr"),Ke=l("td"),Zl=a("WordPiece"),w=i(),Dt=l("td"),Lt=a("This is a subword tokenization algorithm quite similar to BPE, used mainly by Google in models like BERT. It uses a greedy algorithm, that tries to build long words first, splitting in multiple tokens when entire words don\u2019t exist in the vocabulary. This is different from BPE that starts from characters, building bigger tokens as possible. It uses the famous "),rt=l("code"),eo=a("##"),to=a(" prefix to identify tokens that are part of a word (ie not starting a word)."),ce=i(),Q=l("tr"),tl=l("td"),lo=a("Unigram"),Ne=i(),ll=l("td"),z=a("Unigram is also a subword tokenization algorithm, and works by trying to identify the best set of subword tokens to maximize the probability for a given sentence. This is different from BPE in the way that this is not deterministic based on a set of rules applied sequentially. Instead Unigram will be able to compute multiple ways of tokenizing, while choosing the most probable one."),wt=i(),at=l("h2"),q=l("a"),he=l("span"),hr(Bt.$$.fragment),oo=i(),fe=l("span"),ro=a("Post-Processors"),Rl=i(),b=l("p"),ao=a(`After the whole pipeline, we sometimes want to insert some special
tokens before feed a tokenized string into a model like \u201D[CLS] My
horse is amazing [SEP]\u201D. The `),nt=l("code"),xt=a("PostProcessor"),no=a(` is the component doing
just that.`),ee=i(),ve=l("table"),it=l("thead"),st=l("tr"),ze=l("th"),ue=a("Name"),dt=i(),Le=l("th"),Ft=a("Description"),ge=i(),At=l("th"),B=a("Example"),pl=i(),qt=l("tbody"),Ut=l("tr"),T=l("td"),vl=a("TemplateProcessing"),_=i(),Ee=l("td"),gl=a("Let\u2019s you easily template the post processing, adding special tokens, and specifying the "),Wt=l("code"),El=a("type_id"),ct=a(" for each sequence/special token. The template is given two strings representing the single sequence and the pair of sequences, as well as a set of special tokens to use."),po=i(),R=l("td"),ml=a("Example, when specifying a template with these values:"),_l=l("br"),bl=i(),Be=l("ul"),yt=l("li"),Tl=a("single: "),ht=l("code"),E=a('"[CLS] $A [SEP]"'),Mt=i(),Ye=l("li"),vo=a("pair: "),xe=l("code"),kt=a('"[CLS] $A [SEP] $B [SEP]"'),go=i(),pe=l("li"),Eo=a("special tokens: "),ft=l("ul"),io=l("li"),Kt=l("code"),Ge=a('"[CLS]"'),mo=i(),Ot=l("li"),Yt=l("code"),_o=a('"[SEP]"'),ut=i(),pt=l("br"),bo=a(" Input: "),I=l("code"),Gt=a('("I like this", "but not this")'),Dl=i(),To=l("br"),te=a(" Output: "),vt=l("code"),ol=a('"[CLS] I like this [SEP] but not this [SEP]"'),$t=i(),jt=l("h2"),rl=l("a"),Re=l("span"),hr(gt.$$.fragment),Ct=i(),Do=l("span"),Il=a("Decoders"),Uo=i(),Vt=l("p"),Tr=a(`The Decoder knows how to go from the IDs used by the Tokenizer, back to
a readable piece of text. Some `),Fe=l("code"),Wo=a("Normalizer"),Et=a(" and "),$o=l("code"),Mo=a("PreTokenizer"),or=a(` use
special characters or identifiers that need to be reverted for example.`),Ho=i(),Co=l("table"),Er=l("thead"),co=l("tr"),rr=l("th"),No=a("Name"),Ko=i(),ar=l("th"),Lo=a("Description"),Dr=i(),wl=l("tbody"),Yo=l("tr"),wo=l("td"),Go=a("ByteLevel"),wr=i(),zo=l("td"),Bo=a("Reverts the ByteLevel PreTokenizer. This PreTokenizer encodes at the byte-level, using a set of visible Unicode characters to represent each byte, so we need a Decoder to revert this process and get something readable again."),yr=i(),ho=l("tr"),Ro=l("td"),kr=a("Metaspace"),jo=i(),so=l("td"),Or=a("Reverts the Metaspace PreTokenizer. This PreTokenizer uses a special identifer "),Io=l("code"),Vo=a("\u2581"),$r=a(" to identify whitespaces, and so this Decoder helps with decoding these."),Jo=i(),fo=l("tr"),nr=l("td"),xo=a("WordPiece"),Qo=i(),Fo=l("td"),Xo=a("Reverts the WordPiece Model. This model uses a special identifier "),Pl=l("code"),Cr=a("##"),uo=a(" for continuing subwords, and so this Decoder helps with decoding these."),this.h()},l(c){const v=mn('[data-svelte="svelte-1phssyn"]',document.head);u=o(v,"META",{name:!0,content:!0}),v.forEach(t),m=s(c),h=o(c,"H1",{class:!0});var yo=r(h);p=o(yo,"A",{id:!0,class:!0,href:!0});var Po=r(p);G=o(Po,"SPAN",{});var Pr=r(G);fr(zt.$$.fragment,Pr),Pr.forEach(t),Po.forEach(t),le=s(yo),al=o(yo,"SPAN",{});var Zo=r(al);Sl=n(Zo,"Components"),Zo.forEach(t),yo.forEach(t),X=s(c),Jt=o(c,"P",{});var ir=r(Jt);Hl=n(ir,`When building a Tokenizer, you can attach various types of components to
this Tokenizer in order to customize its behavior. This page lists most
provided components.`),ir.forEach(t),f=s(c),g=o(c,"H2",{class:!0});var _r=r(g);x=o(_r,"A",{id:!0,class:!0,href:!0});var er=r(x);nl=o(er,"SPAN",{});var sr=r(nl);fr(Rt.$$.fragment,sr),sr.forEach(t),er.forEach(t),j=s(_r),il=o(_r,"SPAN",{});var zr=r(il);oe=n(zr,"Normalizers"),zr.forEach(t),_r.forEach(t),Z=s(c),Ae=o(c,"P",{});var ko=r(Ae);U=n(ko,"A "),Ie=o(ko,"CODE",{});var dr=r(Ie);Nl=n(dr,"Normalizer"),dr.forEach(t),Ll=n(ko,` is in charge of pre-processing the input string in order
to normalize it as relevant for a given use case. Some common examples
of normalization are the Unicode normalization algorithms (NFD, NFKD,
NFC & NFKC), lowercasing etc\u2026 The specificity of `),re=o(ko,"CODE",{});var Rr=r(re);Bl=n(Rr,"tokenizers"),Rr.forEach(t),xl=n(ko,` is that
we keep track of the alignment while normalizing. This is essential to
allow mapping from the generated tokens back to the input text.`),ko.forEach(t),ke=s(c),mt=o(c,"P",{});var Ao=r(mt);ae=n(Ao,"The "),D=o(Ao,"CODE",{});var Sr=r(D);Fl=n(Sr,"Normalizer"),Sr.forEach(t),It=n(Ao," is optional."),Ao.forEach(t),qe=s(c),fr(_t.$$.fragment,c),Ol=s(c),me=o(c,"H2",{class:!0});var br=r(me);Oe=o(br,"A",{id:!0,class:!0,href:!0});var Hr=r(Oe);V=o(Hr,"SPAN",{});var Nr=r(V);fr(_e.$$.fragment,Nr),Nr.forEach(t),Hr.forEach(t),ne=s(br),Pe=o(br,"SPAN",{});var yl=r(Pe);je=n(yl,"Pre-tokenizers"),yl.forEach(t),br.forEach(t),$l=s(c),F=o(c,"P",{});var tr=r(F);Pt=n(tr,"The "),Ve=o(tr,"CODE",{});var kl=r(Ve);ie=n(kl,"PreTokenizer"),kl.forEach(t),Je=n(tr,` takes care of splitting the input according to a set
of rules. This pre-processing lets you ensure that the underlying
`),S=o(tr,"CODE",{});var Ar=r(S);Al=n(Ar,"Model"),Ar.forEach(t),be=n(tr,` does not build tokens across multiple \u201Csplits\u201D. For example if
you don\u2019t want to have whitespaces inside a token, then you can have a
`),sl=o(tr,"CODE",{});var Lr=r(sl);ql=n(Lr,"PreTokenizer"),Lr.forEach(t),H=n(tr," that splits on these whitespaces."),tr.forEach(t),Cl=s(c),P=o(c,"P",{});var So=r(P);Ul=n(So,"You can easily combine multiple "),dl=o(So,"CODE",{});var cr=r(dl);se=n(cr,"PreTokenizer"),cr.forEach(t),Qe=n(So,` together using a
`),Xe=o(So,"CODE",{});var Br=r(Xe);Wl=n(Br,"Sequence"),Br.forEach(t),Ze=n(So," (see below). The "),cl=o(So,"CODE",{});var qo=r(cl);de=n(qo,"PreTokenizer"),qo.forEach(t),y=n(So,` is also allowed to modify the
string, just like a `),hl=o(So,"CODE",{});var xr=r(hl);St=n(xr,"Normalizer"),xr.forEach(t),et=n(So,` does. This is necessary to allow some
complicated algorithms that require to split before normalizing (e.g.
the ByteLevel)`),So.forEach(t),zl=s(c),fr(bt.$$.fragment,c),O=s(c),Te=o(c,"H2",{class:!0});var Ir=r(Te);$e=o(Ir,"A",{id:!0,class:!0,href:!0});var jr=r($e);fl=o(jr,"SPAN",{});var Vr=r(fl);fr(W.$$.fragment,Vr),Vr.forEach(t),jr.forEach(t),De=s(Ir),ul=o(Ir,"SPAN",{});var Jr=r(ul);Ml=n(Jr,"Models"),Jr.forEach(t),Ir.forEach(t),Ue=s(c),Qt=o(c,"P",{});var Ta=r(Qt);Ht=n(Ta,`Models are the core algorithms used to actually tokenize, and therefore,
they are the only mandatory component of a Tokenizer.`),Ta.forEach(t),A=s(c),Tt=o(c,"TABLE",{});var Qr=r(Tt);N=o(Qr,"THEAD",{});var Da=r(N);we=o(Da,"TR",{});var Xr=r(we);Xt=o(Xr,"TH",{align:!0});var wa=r(Xt);Kl=n(wa,"Name"),wa.forEach(t),tt=s(Xr),We=o(Xr,"TH",{align:!0});var ya=r(We);Yl=n(ya,"Description"),ya.forEach(t),Xr.forEach(t),Da.forEach(t),M=s(Qr),C=o(Qr,"TBODY",{});var Fr=r(C);J=o(Fr,"TR",{});var Zr=r(J);Zt=o(Zr,"TD",{align:!0});var ka=r(Zt);Gl=n(ka,"WordLevel"),ka.forEach(t),lt=s(Zr),Me=o(Zr,"TD",{align:!0});var qr=r(Me);Nt=n(qr,"This is the \u201Cclassic\u201D tokenization algorithm. It let\u2019s you simply map words to IDs without anything fancy. This has the advantage of being really simple to use and understand, but it requires extremely large vocabularies for a good coverage. Using this "),L=o(qr,"CODE",{});var Oa=r(L);jl=n(Oa,"Model"),Oa.forEach(t),K=n(qr," requires the use of a "),Se=o(qr,"CODE",{});var $a=r(Se);Vl=n($a,"PreTokenizer"),$a.forEach(t),Jl=n(qr,". No choice will be made by this model directly, it simply maps input tokens to IDs."),qr.forEach(t),Zr.forEach(t),ot=s(Fr),He=o(Fr,"TR",{});var ea=r(He);el=o(ea,"TD",{align:!0});var Ca=r(el);k=n(Ca,"BPE"),Ca.forEach(t),Y=s(ea),Ce=o(ea,"TD",{align:!0});var za=r(Ce);Ql=n(za,"One of the most popular subword tokenization algorithm. The Byte-Pair-Encoding works by starting with characters, while merging those that are the most frequently seen together, thus creating new tokens. It then works iteratively to build new tokens out of the most frequent pairs it sees in a corpus. BPE is able to build words it has never seen by using multiple subword tokens, and thus requires smaller vocabularies, with less chances of having \u201Cunk\u201D (unknown) tokens."),za.forEach(t),ea.forEach(t),Xl=s(Fr),ye=o(Fr,"TR",{});var ta=r(ye);Ke=o(ta,"TD",{align:!0});var Ra=r(Ke);Zl=n(Ra,"WordPiece"),Ra.forEach(t),w=s(ta),Dt=o(ta,"TD",{align:!0});var la=r(Dt);Lt=n(la,"This is a subword tokenization algorithm quite similar to BPE, used mainly by Google in models like BERT. It uses a greedy algorithm, that tries to build long words first, splitting in multiple tokens when entire words don\u2019t exist in the vocabulary. This is different from BPE that starts from characters, building bigger tokens as possible. It uses the famous "),rt=o(la,"CODE",{});var Ia=r(rt);eo=n(Ia,"##"),Ia.forEach(t),to=n(la," prefix to identify tokens that are part of a word (ie not starting a word)."),la.forEach(t),ta.forEach(t),ce=s(Fr),Q=o(Fr,"TR",{});var oa=r(Q);tl=o(oa,"TD",{align:!0});var Pa=r(tl);lo=n(Pa,"Unigram"),Pa.forEach(t),Ne=s(oa),ll=o(oa,"TD",{align:!0});var Sa=r(ll);z=n(Sa,"Unigram is also a subword tokenization algorithm, and works by trying to identify the best set of subword tokens to maximize the probability for a given sentence. This is different from BPE in the way that this is not deterministic based on a set of rules applied sequentially. Instead Unigram will be able to compute multiple ways of tokenizing, while choosing the most probable one."),Sa.forEach(t),oa.forEach(t),Fr.forEach(t),Qr.forEach(t),wt=s(c),at=o(c,"H2",{class:!0});var ra=r(at);q=o(ra,"A",{id:!0,class:!0,href:!0});var Ha=r(q);he=o(Ha,"SPAN",{});var Na=r(he);fr(Bt.$$.fragment,Na),Na.forEach(t),Ha.forEach(t),oo=s(ra),fe=o(ra,"SPAN",{});var La=r(fe);ro=n(La,"Post-Processors"),La.forEach(t),ra.forEach(t),Rl=s(c),b=o(c,"P",{});var aa=r(b);ao=n(aa,`After the whole pipeline, we sometimes want to insert some special
tokens before feed a tokenized string into a model like \u201D[CLS] My
horse is amazing [SEP]\u201D. The `),nt=o(aa,"CODE",{});var Ba=r(nt);xt=n(Ba,"PostProcessor"),Ba.forEach(t),no=n(aa,` is the component doing
just that.`),aa.forEach(t),ee=s(c),ve=o(c,"TABLE",{});var na=r(ve);it=o(na,"THEAD",{});var xa=r(it);st=o(xa,"TR",{});var Ur=r(st);ze=o(Ur,"TH",{align:!0});var Fa=r(ze);ue=n(Fa,"Name"),Fa.forEach(t),dt=s(Ur),Le=o(Ur,"TH",{align:!0});var Aa=r(Le);Ft=n(Aa,"Description"),Aa.forEach(t),ge=s(Ur),At=o(Ur,"TH",{align:!0});var qa=r(At);B=n(qa,"Example"),qa.forEach(t),Ur.forEach(t),xa.forEach(t),pl=s(na),qt=o(na,"TBODY",{});var Ua=r(qt);Ut=o(Ua,"TR",{});var Wr=r(Ut);T=o(Wr,"TD",{align:!0});var Wa=r(T);vl=n(Wa,"TemplateProcessing"),Wa.forEach(t),_=s(Wr),Ee=o(Wr,"TD",{align:!0});var ia=r(Ee);gl=n(ia,"Let\u2019s you easily template the post processing, adding special tokens, and specifying the "),Wt=o(ia,"CODE",{});var Ma=r(Wt);El=n(Ma,"type_id"),Ma.forEach(t),ct=n(ia," for each sequence/special token. The template is given two strings representing the single sequence and the pair of sequences, as well as a set of special tokens to use."),ia.forEach(t),po=s(Wr),R=o(Wr,"TD",{align:!0});var lr=r(R);ml=n(lr,"Example, when specifying a template with these values:"),_l=o(lr,"BR",{}),bl=s(lr),Be=o(lr,"UL",{});var Mr=r(Be);yt=o(Mr,"LI",{});var ma=r(yt);Tl=n(ma,"single: "),ht=o(ma,"CODE",{});var Ka=r(ht);E=n(Ka,'"[CLS] $A [SEP]"'),Ka.forEach(t),ma.forEach(t),Mt=s(Mr),Ye=o(Mr,"LI",{});var _a=r(Ye);vo=n(_a,"pair: "),xe=o(_a,"CODE",{});var Ya=r(xe);kt=n(Ya,'"[CLS] $A [SEP] $B [SEP]"'),Ya.forEach(t),_a.forEach(t),go=s(Mr),pe=o(Mr,"LI",{});var ba=r(pe);Eo=n(ba,"special tokens: "),ft=o(ba,"UL",{});var sa=r(ft);io=o(sa,"LI",{});var Ga=r(io);Kt=o(Ga,"CODE",{});var ja=r(Kt);Ge=n(ja,'"[CLS]"'),ja.forEach(t),Ga.forEach(t),mo=s(sa),Ot=o(sa,"LI",{});var Va=r(Ot);Yt=o(Va,"CODE",{});var Ja=r(Yt);_o=n(Ja,'"[SEP]"'),Ja.forEach(t),Va.forEach(t),sa.forEach(t),ba.forEach(t),Mr.forEach(t),ut=s(lr),pt=o(lr,"BR",{}),bo=n(lr," Input: "),I=o(lr,"CODE",{});var Qa=r(I);Gt=n(Qa,'("I like this", "but not this")'),Qa.forEach(t),Dl=s(lr),To=o(lr,"BR",{}),te=n(lr," Output: "),vt=o(lr,"CODE",{});var Xa=r(vt);ol=n(Xa,'"[CLS] I like this [SEP] but not this [SEP]"'),Xa.forEach(t),lr.forEach(t),Wr.forEach(t),Ua.forEach(t),na.forEach(t),$t=s(c),jt=o(c,"H2",{class:!0});var da=r(jt);rl=o(da,"A",{id:!0,class:!0,href:!0});var Za=r(rl);Re=o(Za,"SPAN",{});var en=r(Re);fr(gt.$$.fragment,en),en.forEach(t),Za.forEach(t),Ct=s(da),Do=o(da,"SPAN",{});var tn=r(Do);Il=n(tn,"Decoders"),tn.forEach(t),da.forEach(t),Uo=s(c),Vt=o(c,"P",{});var Kr=r(Vt);Tr=n(Kr,`The Decoder knows how to go from the IDs used by the Tokenizer, back to
a readable piece of text. Some `),Fe=o(Kr,"CODE",{});var ln=r(Fe);Wo=n(ln,"Normalizer"),ln.forEach(t),Et=n(Kr," and "),$o=o(Kr,"CODE",{});var on=r($o);Mo=n(on,"PreTokenizer"),on.forEach(t),or=n(Kr,` use
special characters or identifiers that need to be reverted for example.`),Kr.forEach(t),Ho=s(c),Co=o(c,"TABLE",{});var ca=r(Co);Er=o(ca,"THEAD",{});var rn=r(Er);co=o(rn,"TR",{});var ha=r(co);rr=o(ha,"TH",{align:!0});var an=r(rr);No=n(an,"Name"),an.forEach(t),Ko=s(ha),ar=o(ha,"TH",{align:!0});var nn=r(ar);Lo=n(nn,"Description"),nn.forEach(t),ha.forEach(t),rn.forEach(t),Dr=s(ca),wl=o(ca,"TBODY",{});var Yr=r(wl);Yo=o(Yr,"TR",{});var fa=r(Yo);wo=o(fa,"TD",{align:!0});var sn=r(wo);Go=n(sn,"ByteLevel"),sn.forEach(t),wr=s(fa),zo=o(fa,"TD",{align:!0});var dn=r(zo);Bo=n(dn,"Reverts the ByteLevel PreTokenizer. This PreTokenizer encodes at the byte-level, using a set of visible Unicode characters to represent each byte, so we need a Decoder to revert this process and get something readable again."),dn.forEach(t),fa.forEach(t),yr=s(Yr),ho=o(Yr,"TR",{});var ua=r(ho);Ro=o(ua,"TD",{align:!0});var cn=r(Ro);kr=n(cn,"Metaspace"),cn.forEach(t),jo=s(ua),so=o(ua,"TD",{align:!0});var pa=r(so);Or=n(pa,"Reverts the Metaspace PreTokenizer. This PreTokenizer uses a special identifer "),Io=o(pa,"CODE",{});var hn=r(Io);Vo=n(hn,"\u2581"),hn.forEach(t),$r=n(pa," to identify whitespaces, and so this Decoder helps with decoding these."),pa.forEach(t),ua.forEach(t),Jo=s(Yr),fo=o(Yr,"TR",{});var va=r(fo);nr=o(va,"TD",{align:!0});var fn=r(nr);xo=n(fn,"WordPiece"),fn.forEach(t),Qo=s(va),Fo=o(va,"TD",{align:!0});var ga=r(Fo);Xo=n(ga,"Reverts the WordPiece Model. This model uses a special identifier "),Pl=o(ga,"CODE",{});var un=r(Pl);Cr=n(un,"##"),un.forEach(t),uo=n(ga," for continuing subwords, and so this Decoder helps with decoding these."),ga.forEach(t),va.forEach(t),Yr.forEach(t),ca.forEach(t),this.h()},h(){d(u,"name","hf:doc:metadata"),d(u,"content",JSON.stringify(zn)),d(p,"id","components"),d(p,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p,"href","#components"),d(h,"class","relative group"),d(x,"id","normalizers"),d(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(x,"href","#normalizers"),d(g,"class","relative group"),d(Oe,"id","pretokenizers"),d(Oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Oe,"href","#pretokenizers"),d(me,"class","relative group"),d($e,"id","models"),d($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($e,"href","#models"),d(Te,"class","relative group"),d(Xt,"align","left"),d(We,"align","left"),d(Zt,"align","left"),d(Me,"align","left"),d(el,"align","left"),d(Ce,"align","left"),d(Ke,"align","left"),d(Dt,"align","left"),d(tl,"align","left"),d(ll,"align","left"),d(q,"id","postprocessors"),d(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(q,"href","#postprocessors"),d(at,"class","relative group"),d(ze,"align","left"),d(Le,"align","left"),d(At,"align","left"),d(T,"align","left"),d(Ee,"align","left"),d(R,"align","left"),d(rl,"id","decoders"),d(rl,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(rl,"href","#decoders"),d(jt,"class","relative group"),d(rr,"align","left"),d(ar,"align","left"),d(wo,"align","left"),d(zo,"align","left"),d(Ro,"align","left"),d(so,"align","left"),d(nr,"align","left"),d(Fo,"align","left")},m(c,v){e(document.head,u),$(c,m,v),$(c,h,v),e(h,p),e(p,G),ur(zt,G,null),e(h,le),e(h,al),e(al,Sl),$(c,X,v),$(c,Jt,v),e(Jt,Hl),$(c,f,v),$(c,g,v),e(g,x),e(x,nl),ur(Rt,nl,null),e(g,j),e(g,il),e(il,oe),$(c,Z,v),$(c,Ae,v),e(Ae,U),e(Ae,Ie),e(Ie,Nl),e(Ae,Ll),e(Ae,re),e(re,Bl),e(Ae,xl),$(c,ke,v),$(c,mt,v),e(mt,ae),e(mt,D),e(D,Fl),e(mt,It),$(c,qe,v),ur(_t,c,v),$(c,Ol,v),$(c,me,v),e(me,Oe),e(Oe,V),ur(_e,V,null),e(me,ne),e(me,Pe),e(Pe,je),$(c,$l,v),$(c,F,v),e(F,Pt),e(F,Ve),e(Ve,ie),e(F,Je),e(F,S),e(S,Al),e(F,be),e(F,sl),e(sl,ql),e(F,H),$(c,Cl,v),$(c,P,v),e(P,Ul),e(P,dl),e(dl,se),e(P,Qe),e(P,Xe),e(Xe,Wl),e(P,Ze),e(P,cl),e(cl,de),e(P,y),e(P,hl),e(hl,St),e(P,et),$(c,zl,v),ur(bt,c,v),$(c,O,v),$(c,Te,v),e(Te,$e),e($e,fl),ur(W,fl,null),e(Te,De),e(Te,ul),e(ul,Ml),$(c,Ue,v),$(c,Qt,v),e(Qt,Ht),$(c,A,v),$(c,Tt,v),e(Tt,N),e(N,we),e(we,Xt),e(Xt,Kl),e(we,tt),e(we,We),e(We,Yl),e(Tt,M),e(Tt,C),e(C,J),e(J,Zt),e(Zt,Gl),e(J,lt),e(J,Me),e(Me,Nt),e(Me,L),e(L,jl),e(Me,K),e(Me,Se),e(Se,Vl),e(Me,Jl),e(C,ot),e(C,He),e(He,el),e(el,k),e(He,Y),e(He,Ce),e(Ce,Ql),e(C,Xl),e(C,ye),e(ye,Ke),e(Ke,Zl),e(ye,w),e(ye,Dt),e(Dt,Lt),e(Dt,rt),e(rt,eo),e(Dt,to),e(C,ce),e(C,Q),e(Q,tl),e(tl,lo),e(Q,Ne),e(Q,ll),e(ll,z),$(c,wt,v),$(c,at,v),e(at,q),e(q,he),ur(Bt,he,null),e(at,oo),e(at,fe),e(fe,ro),$(c,Rl,v),$(c,b,v),e(b,ao),e(b,nt),e(nt,xt),e(b,no),$(c,ee,v),$(c,ve,v),e(ve,it),e(it,st),e(st,ze),e(ze,ue),e(st,dt),e(st,Le),e(Le,Ft),e(st,ge),e(st,At),e(At,B),e(ve,pl),e(ve,qt),e(qt,Ut),e(Ut,T),e(T,vl),e(Ut,_),e(Ut,Ee),e(Ee,gl),e(Ee,Wt),e(Wt,El),e(Ee,ct),e(Ut,po),e(Ut,R),e(R,ml),e(R,_l),e(R,bl),e(R,Be),e(Be,yt),e(yt,Tl),e(yt,ht),e(ht,E),e(Be,Mt),e(Be,Ye),e(Ye,vo),e(Ye,xe),e(xe,kt),e(Be,go),e(Be,pe),e(pe,Eo),e(pe,ft),e(ft,io),e(io,Kt),e(Kt,Ge),e(ft,mo),e(ft,Ot),e(Ot,Yt),e(Yt,_o),e(R,ut),e(R,pt),e(R,bo),e(R,I),e(I,Gt),e(R,Dl),e(R,To),e(R,te),e(R,vt),e(vt,ol),$(c,$t,v),$(c,jt,v),e(jt,rl),e(rl,Re),ur(gt,Re,null),e(jt,Ct),e(jt,Do),e(Do,Il),$(c,Uo,v),$(c,Vt,v),e(Vt,Tr),e(Vt,Fe),e(Fe,Wo),e(Vt,Et),e(Vt,$o),e($o,Mo),e(Vt,or),$(c,Ho,v),$(c,Co,v),e(Co,Er),e(Er,co),e(co,rr),e(rr,No),e(co,Ko),e(co,ar),e(ar,Lo),e(Co,Dr),e(Co,wl),e(wl,Yo),e(Yo,wo),e(wo,Go),e(Yo,wr),e(Yo,zo),e(zo,Bo),e(wl,yr),e(wl,ho),e(ho,Ro),e(Ro,kr),e(ho,jo),e(ho,so),e(so,Or),e(so,Io),e(Io,Vo),e(so,$r),e(wl,Jo),e(wl,fo),e(fo,nr),e(nr,xo),e(fo,Qo),e(fo,Fo),e(Fo,Xo),e(Fo,Pl),e(Pl,Cr),e(Fo,uo),mr=!0},p(c,[v]){const yo={};v&2&&(yo.$$scope={dirty:v,ctx:c}),_t.$set(yo);const Po={};v&2&&(Po.$$scope={dirty:v,ctx:c}),bt.$set(Po)},i(c){mr||(pr(zt.$$.fragment,c),pr(Rt.$$.fragment,c),pr(_t.$$.fragment,c),pr(_e.$$.fragment,c),pr(bt.$$.fragment,c),pr(W.$$.fragment,c),pr(Bt.$$.fragment,c),pr(gt.$$.fragment,c),mr=!0)},o(c){vr(zt.$$.fragment,c),vr(Rt.$$.fragment,c),vr(_t.$$.fragment,c),vr(_e.$$.fragment,c),vr(bt.$$.fragment,c),vr(W.$$.fragment,c),vr(Bt.$$.fragment,c),vr(gt.$$.fragment,c),mr=!1},d(c){t(u),c&&t(m),c&&t(h),gr(zt),c&&t(X),c&&t(Jt),c&&t(f),c&&t(g),gr(Rt),c&&t(Z),c&&t(Ae),c&&t(ke),c&&t(mt),c&&t(qe),gr(_t,c),c&&t(Ol),c&&t(me),gr(_e),c&&t($l),c&&t(F),c&&t(Cl),c&&t(P),c&&t(zl),gr(bt,c),c&&t(O),c&&t(Te),gr(W),c&&t(Ue),c&&t(Qt),c&&t(A),c&&t(Tt),c&&t(wt),c&&t(at),gr(Bt),c&&t(Rl),c&&t(b),c&&t(ee),c&&t(ve),c&&t($t),c&&t(jt),gr(gt),c&&t(Uo),c&&t(Vt),c&&t(Ho),c&&t(Co)}}}const zn={local:"components",sections:[{local:"normalizers",title:"Normalizers"},{local:"pretokenizers",title:"Pre-tokenizers"},{local:"models",title:"Models"},{local:"postprocessors",title:"Post-Processors"},{local:"decoders",title:"Decoders"}],title:"Components"};function Rn(Oo){return _n(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Hn extends vn{constructor(u){super();gn(this,u,Rn,Cn,En,{})}}export{Hn as default,zn as metadata};
