import{S as vn,i as gn,s as En,e as t,k as i,w as ur,t as a,M as _n,c as l,d as o,m as s,a as r,x as pr,h as n,b as d,F as e,g as _e,y as vr,q as gr,o as Er,B as _r,v as mn}from"../chunks/vendor-a667fb6e.js";import{I as Jr}from"../chunks/IconCopyLink-3bc33587.js";import{T as pn,M as Qr}from"../chunks/TokenizersLanguageContent-c33e4dff.js";function bn(ko){let u,g,f,p,V,Kt,te,ul,Hl,J,Xt,Ll,h,E,A,pl,Mt,M,vl,le,Q,vt,B,Le,Nl,Pl,ce,Bl,xl,Te,Lt,oe,m,Fl,wt,We,Nt,wl,Ce,Ne,j,De,re,Pe,Ye,yl,Y,yt,st,ae,Ge,I,ql,ve,gl,Al,R,Ol,W,Wl,El,ne,Ve,dt,Ul,je,_l,ie,T,ml,Ot,Je,kl,Pt,y,Re,Be,bl,K,ge,Tl,Kl,Ue,Zt,kt,N,Bt,z,we,el,Ml,Qe,Xe,Yl,x,S,X,tl,Gl,Ze,gt,Ct,H,Vl,F,xe,jl,Jl,et,Ke,ll,D,q,$e,Ql,Xl,ye,tt,Zl,_,xt,Rt,ct,eo,to,se,Z,ol,lo,Ie,rl,O,Et,$t,U,he,Yt,oo,fe,ro,Cl,b,ao,ht,It,no,ee,me,ft,zt,ze,de,lt,Se,St,Ee;return{c(){u=t("table"),g=t("thead"),f=t("tr"),p=t("th"),V=a("Name"),Kt=i(),te=t("th"),ul=a("Description"),Hl=i(),J=t("th"),Xt=a("Example"),Ll=i(),h=t("tbody"),E=t("tr"),A=t("td"),pl=a("NFD"),Mt=i(),M=t("td"),vl=a("NFD unicode normalization"),le=i(),Q=t("td"),vt=i(),B=t("tr"),Le=t("td"),Nl=a("NFKD"),Pl=i(),ce=t("td"),Bl=a("NFKD unicode normalization"),xl=i(),Te=t("td"),Lt=i(),oe=t("tr"),m=t("td"),Fl=a("NFC"),wt=i(),We=t("td"),Nt=a("NFC unicode normalization"),wl=i(),Ce=t("td"),Ne=i(),j=t("tr"),De=t("td"),re=a("NFKC"),Pe=i(),Ye=t("td"),yl=a("NFKC unicode normalization"),Y=i(),yt=t("td"),st=i(),ae=t("tr"),Ge=t("td"),I=a("Lowercase"),ql=i(),ve=t("td"),gl=a("Replaces all uppercase to lowercase"),Al=i(),R=t("td"),Ol=a("Input: "),W=t("code"),Wl=a("HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),El=i(),ne=t("br"),Ve=a(" Output: "),dt=t("code"),Ul=a("hello"),je=a("\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),_l=i(),ie=t("tr"),T=t("td"),ml=a("Strip"),Ot=i(),Je=t("td"),kl=a("Removes all whitespace characters on the specified sides (left, right or both) of the input"),Pt=i(),y=t("td"),Re=a("Input: "),Be=t("code"),bl=a('"'),K=a("hi"),ge=t("code"),Tl=a('"'),Kl=i(),Ue=t("br"),Zt=a(" Output: "),kt=t("code"),N=a('"hi"'),Bt=i(),z=t("tr"),we=t("td"),el=a("StripAccents"),Ml=i(),Qe=t("td"),Xe=a("Removes all accent symbols in unicode (to be used with NFD for consistency)"),Yl=i(),x=t("td"),S=a("Input: "),X=t("code"),tl=a("\xE9"),Gl=i(),Ze=t("br"),gt=a(" Ouput: "),Ct=t("code"),H=a("e"),Vl=i(),F=t("tr"),xe=t("td"),jl=a("Replace"),Jl=i(),et=t("td"),Ke=a("Replaces a custom string or regexp and changes it with given content"),ll=i(),D=t("td"),q=t("code"),$e=a('Replace("a", "e")'),Ql=a(" will behave like this: "),Xl=t("br"),ye=a(" Input: "),tt=t("code"),Zl=a('"banana"'),_=i(),xt=t("br"),Rt=a(" Ouput: "),ct=t("code"),eo=a('"benene"'),to=i(),se=t("tr"),Z=t("td"),ol=a("BertNormalizer"),lo=i(),Ie=t("td"),rl=a("Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),O=t("ul"),Et=t("li"),$t=a("clean_text"),U=i(),he=t("li"),Yt=a("handle_chinese_chars"),oo=i(),fe=t("li"),ro=a("strip_accents"),Cl=i(),b=t("li"),ao=a("lowercase"),ht=i(),It=t("td"),no=i(),ee=t("tr"),me=t("td"),ft=a("Sequence"),zt=i(),ze=t("td"),de=a("Composes multiple normalizers that will run in the provided order"),lt=i(),Se=t("td"),St=t("code"),Ee=a("Sequence([NFKC(), Lowercase()])"),this.h()},l(Gt){u=l(Gt,"TABLE",{});var L=r(u);g=l(L,"THEAD",{});var _t=r(g);f=l(_t,"TR",{});var al=r(f);p=l(al,"TH",{align:!0});var mt=r(p);V=n(mt,"Name"),mt.forEach(o),Kt=s(al),te=l(al,"TH",{align:!0});var $=r(te);ul=n($,"Description"),$.forEach(o),Hl=s(al),J=l(al,"TH",{align:!0});var Rl=r(J);Xt=n(Rl,"Example"),Rl.forEach(o),al.forEach(o),_t.forEach(o),Ll=s(L),h=l(L,"TBODY",{});var w=r(h);E=l(w,"TR",{});var k=r(E);A=l(k,"TD",{align:!0});var Ft=r(A);pl=n(Ft,"NFD"),Ft.forEach(o),Mt=s(k),M=l(k,"TD",{align:!0});var qt=r(M);vl=n(qt,"NFD unicode normalization"),qt.forEach(o),le=s(k),Q=l(k,"TD",{align:!0}),r(Q).forEach(o),k.forEach(o),vt=s(w),B=l(w,"TR",{});var $l=r(B);Le=l($l,"TD",{align:!0});var Fe=r(Le);Nl=n(Fe,"NFKD"),Fe.forEach(o),Pl=s($l),ce=l($l,"TD",{align:!0});var fo=r(ce);Bl=n(fo,"NFKD unicode normalization"),fo.forEach(o),xl=s($l),Te=l($l,"TD",{align:!0}),r(Te).forEach(o),$l.forEach(o),Lt=s(w),oe=l(w,"TR",{});var G=r(oe);m=l(G,"TD",{align:!0});var At=r(m);Fl=n(At,"NFC"),At.forEach(o),wt=s(G),We=l(G,"TD",{align:!0});var nl=r(We);Nt=n(nl,"NFC unicode normalization"),nl.forEach(o),wl=s(G),Ce=l(G,"TD",{align:!0}),r(Ce).forEach(o),G.forEach(o),Ne=s(w),j=l(w,"TR",{});var Il=r(j);De=l(Il,"TD",{align:!0});var qe=r(De);re=n(qe,"NFKC"),qe.forEach(o),Pe=s(Il),Ye=l(Il,"TD",{align:!0});var Ht=r(Ye);yl=n(Ht,"NFKC unicode normalization"),Ht.forEach(o),Y=s(Il),yt=l(Il,"TD",{align:!0}),r(yt).forEach(o),Il.forEach(o),st=s(w),ae=l(w,"TR",{});var zl=r(ae);Ge=l(zl,"TD",{align:!0});var ot=r(Ge);I=n(ot,"Lowercase"),ot.forEach(o),ql=s(zl),ve=l(zl,"TD",{align:!0});var v=r(ve);gl=n(v,"Replaces all uppercase to lowercase"),v.forEach(o),Al=s(zl),R=l(zl,"TD",{align:!0});var il=r(R);Ol=n(il,"Input: "),W=l(il,"CODE",{});var Oe=r(W);Wl=n(Oe,"HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),Oe.forEach(o),El=s(il),ne=l(il,"BR",{}),Ve=n(il," Output: "),dt=l(il,"CODE",{});var uo=r(dt);Ul=n(uo,"hello"),uo.forEach(o),je=n(il,"\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),il.forEach(o),zl.forEach(o),_l=s(w),ie=l(w,"TR",{});var rt=r(ie);T=l(rt,"TD",{align:!0});var ut=r(T);ml=n(ut,"Strip"),ut.forEach(o),Ot=s(rt),Je=l(rt,"TD",{align:!0});var po=r(Je);kl=n(po,"Removes all whitespace characters on the specified sides (left, right or both) of the input"),po.forEach(o),Pt=s(rt),y=l(rt,"TD",{align:!0});var ke=r(y);Re=n(ke,"Input: "),Be=l(ke,"CODE",{});var Vt=r(Be);bl=n(Vt,'"'),Vt.forEach(o),K=n(ke,"hi"),ge=l(ke,"CODE",{});var Wt=r(ge);Tl=n(Wt,'"'),Wt.forEach(o),Kl=s(ke),Ue=l(ke,"BR",{}),Zt=n(ke," Output: "),kt=l(ke,"CODE",{});var io=r(kt);N=n(io,'"hi"'),io.forEach(o),ke.forEach(o),rt.forEach(o),Bt=s(w),z=l(w,"TR",{});var sl=r(z);we=l(sl,"TD",{align:!0});var He=r(we);el=n(He,"StripAccents"),He.forEach(o),Ml=s(sl),Qe=l(sl,"TD",{align:!0});var vo=r(Qe);Xe=n(vo,"Removes all accent symbols in unicode (to be used with NFD for consistency)"),vo.forEach(o),Yl=s(sl),x=l(sl,"TD",{align:!0});var jt=r(x);S=n(jt,"Input: "),X=l(jt,"CODE",{});var pt=r(X);tl=n(pt,"\xE9"),pt.forEach(o),Gl=s(jt),Ze=l(jt,"BR",{}),gt=n(jt," Ouput: "),Ct=l(jt,"CODE",{});var go=r(Ct);H=n(go,"e"),go.forEach(o),jt.forEach(o),sl.forEach(o),Vl=s(w),F=l(w,"TR",{});var bt=r(F);xe=l(bt,"TD",{align:!0});var at=r(xe);jl=n(at,"Replace"),at.forEach(o),Jl=s(bt),et=l(bt,"TD",{align:!0});var Eo=r(et);Ke=n(Eo,"Replaces a custom string or regexp and changes it with given content"),Eo.forEach(o),ll=s(bt),D=l(bt,"TD",{align:!0});var P=r(D);q=l(P,"CODE",{});var be=r(q);$e=n(be,'Replace("a", "e")'),be.forEach(o),Ql=n(P," will behave like this: "),Xl=l(P,"BR",{}),ye=n(P," Input: "),tt=l(P,"CODE",{});var Sl=r(tt);Zl=n(Sl,'"banana"'),Sl.forEach(o),_=s(P),xt=l(P,"BR",{}),Rt=n(P," Ouput: "),ct=l(P,"CODE",{});var _o=r(ct);eo=n(_o,'"benene"'),_o.forEach(o),P.forEach(o),bt.forEach(o),to=s(w),se=l(w,"TR",{});var ue=r(se);Z=l(ue,"TD",{align:!0});var nt=r(Z);ol=n(nt,"BertNormalizer"),nt.forEach(o),lo=s(ue),Ie=l(ue,"TD",{align:!0});var Jt=r(Ie);rl=n(Jt,"Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),O=l(Jt,"UL",{});var Ut=r(O);Et=l(Ut,"LI",{});var it=r(Et);$t=n(it,"clean_text"),it.forEach(o),U=s(Ut),he=l(Ut,"LI",{});var Dl=r(he);Yt=n(Dl,"handle_chinese_chars"),Dl.forEach(o),oo=s(Ut),fe=l(Ut,"LI",{});var Ae=r(fe);ro=n(Ae,"strip_accents"),Ae.forEach(o),Cl=s(Ut),b=l(Ut,"LI",{});var Tt=r(b);ao=n(Tt,"lowercase"),Tt.forEach(o),Ut.forEach(o),Jt.forEach(o),ht=s(ue),It=l(ue,"TD",{align:!0}),r(It).forEach(o),ue.forEach(o),no=s(w),ee=l(w,"TR",{});var Qt=r(ee);me=l(Qt,"TD",{align:!0});var dl=r(me);ft=n(dl,"Sequence"),dl.forEach(o),zt=s(Qt),ze=l(Qt,"TD",{align:!0});var cl=r(ze);de=n(cl,"Composes multiple normalizers that will run in the provided order"),cl.forEach(o),lt=s(Qt),Se=l(Qt,"TD",{align:!0});var Wo=r(Se);St=l(Wo,"CODE",{});var Dt=r(St);Ee=n(Dt,"Sequence([NFKC(), Lowercase()])"),Dt.forEach(o),Wo.forEach(o),Qt.forEach(o),w.forEach(o),L.forEach(o),this.h()},h(){d(p,"align","left"),d(te,"align","left"),d(J,"align","left"),d(A,"align","left"),d(M,"align","left"),d(Q,"align","left"),d(Le,"align","left"),d(ce,"align","left"),d(Te,"align","left"),d(m,"align","left"),d(We,"align","left"),d(Ce,"align","left"),d(De,"align","left"),d(Ye,"align","left"),d(yt,"align","left"),d(Ge,"align","left"),d(ve,"align","left"),d(R,"align","left"),d(T,"align","left"),d(Je,"align","left"),d(y,"align","left"),d(we,"align","left"),d(Qe,"align","left"),d(x,"align","left"),d(xe,"align","left"),d(et,"align","left"),d(D,"align","left"),d(Z,"align","left"),d(Ie,"align","left"),d(It,"align","left"),d(me,"align","left"),d(ze,"align","left"),d(Se,"align","left")},m(Gt,L){_e(Gt,u,L),e(u,g),e(g,f),e(f,p),e(p,V),e(f,Kt),e(f,te),e(te,ul),e(f,Hl),e(f,J),e(J,Xt),e(u,Ll),e(u,h),e(h,E),e(E,A),e(A,pl),e(E,Mt),e(E,M),e(M,vl),e(E,le),e(E,Q),e(h,vt),e(h,B),e(B,Le),e(Le,Nl),e(B,Pl),e(B,ce),e(ce,Bl),e(B,xl),e(B,Te),e(h,Lt),e(h,oe),e(oe,m),e(m,Fl),e(oe,wt),e(oe,We),e(We,Nt),e(oe,wl),e(oe,Ce),e(h,Ne),e(h,j),e(j,De),e(De,re),e(j,Pe),e(j,Ye),e(Ye,yl),e(j,Y),e(j,yt),e(h,st),e(h,ae),e(ae,Ge),e(Ge,I),e(ae,ql),e(ae,ve),e(ve,gl),e(ae,Al),e(ae,R),e(R,Ol),e(R,W),e(W,Wl),e(R,El),e(R,ne),e(R,Ve),e(R,dt),e(dt,Ul),e(R,je),e(h,_l),e(h,ie),e(ie,T),e(T,ml),e(ie,Ot),e(ie,Je),e(Je,kl),e(ie,Pt),e(ie,y),e(y,Re),e(y,Be),e(Be,bl),e(y,K),e(y,ge),e(ge,Tl),e(y,Kl),e(y,Ue),e(y,Zt),e(y,kt),e(kt,N),e(h,Bt),e(h,z),e(z,we),e(we,el),e(z,Ml),e(z,Qe),e(Qe,Xe),e(z,Yl),e(z,x),e(x,S),e(x,X),e(X,tl),e(x,Gl),e(x,Ze),e(x,gt),e(x,Ct),e(Ct,H),e(h,Vl),e(h,F),e(F,xe),e(xe,jl),e(F,Jl),e(F,et),e(et,Ke),e(F,ll),e(F,D),e(D,q),e(q,$e),e(D,Ql),e(D,Xl),e(D,ye),e(D,tt),e(tt,Zl),e(D,_),e(D,xt),e(D,Rt),e(D,ct),e(ct,eo),e(h,to),e(h,se),e(se,Z),e(Z,ol),e(se,lo),e(se,Ie),e(Ie,rl),e(Ie,O),e(O,Et),e(Et,$t),e(O,U),e(O,he),e(he,Yt),e(O,oo),e(O,fe),e(fe,ro),e(O,Cl),e(O,b),e(b,ao),e(se,ht),e(se,It),e(h,no),e(h,ee),e(ee,me),e(me,ft),e(ee,zt),e(ee,ze),e(ze,de),e(ee,lt),e(ee,Se),e(Se,St),e(St,Ee)},d(Gt){Gt&&o(u)}}}function Tn(ko){let u,g;return u=new Qr({props:{$$slots:{default:[bn]},$$scope:{ctx:ko}}}),{c(){ur(u.$$.fragment)},l(f){pr(u.$$.fragment,f)},m(f,p){vr(u,f,p),g=!0},p(f,p){const V={};p&2&&(V.$$scope={dirty:p,ctx:f}),u.$set(V)},i(f){g||(gr(u.$$.fragment,f),g=!0)},o(f){Er(u.$$.fragment,f),g=!1},d(f){_r(u,f)}}}function Dn(ko){let u,g,f,p,V,Kt,te,ul,Hl,J,Xt,Ll,h,E,A,pl,Mt,M,vl,le,Q,vt,B,Le,Nl,Pl,ce,Bl,xl,Te,Lt,oe,m,Fl,wt,We,Nt,wl,Ce,Ne,j,De,re,Pe,Ye,yl,Y,yt,st,ae,Ge,I,ql,ve,gl,Al,R,Ol,W,Wl,El,ne,Ve,dt,Ul,je,_l,ie,T,ml,Ot,Je,kl,Pt,y,Re,Be,bl,K,ge,Tl,Kl,Ue,Zt,kt,N,Bt,z,we,el,Ml,Qe,Xe,Yl,x,S,X,tl,Gl,Ze,gt,Ct,H,Vl,F,xe,jl,Jl,et,Ke,ll,D,q,$e,Ql,Xl,ye,tt,Zl,_,xt,Rt,ct,eo,to,se,Z,ol,lo,Ie,rl,O,Et,$t,U,he,Yt,oo,fe,ro,Cl,b,ao,ht,It,no,ee,me,ft,zt,ze,de,lt,Se,St,Ee,Gt;return{c(){u=t("table"),g=t("thead"),f=t("tr"),p=t("th"),V=a("Name"),Kt=i(),te=t("th"),ul=a("Description"),Hl=i(),J=t("th"),Xt=a("Example"),Ll=i(),h=t("tbody"),E=t("tr"),A=t("td"),pl=a("NFD"),Mt=i(),M=t("td"),vl=a("NFD unicode normalization"),le=i(),Q=t("td"),vt=i(),B=t("tr"),Le=t("td"),Nl=a("NFKD"),Pl=i(),ce=t("td"),Bl=a("NFKD unicode normalization"),xl=i(),Te=t("td"),Lt=i(),oe=t("tr"),m=t("td"),Fl=a("NFC"),wt=i(),We=t("td"),Nt=a("NFC unicode normalization"),wl=i(),Ce=t("td"),Ne=i(),j=t("tr"),De=t("td"),re=a("NFKC"),Pe=i(),Ye=t("td"),yl=a("NFKC unicode normalization"),Y=i(),yt=t("td"),st=i(),ae=t("tr"),Ge=t("td"),I=a("Lowercase"),ql=i(),ve=t("td"),gl=a("Replaces all uppercase to lowercase"),Al=i(),R=t("td"),Ol=a("Input: "),W=t("code"),Wl=a("HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),El=i(),ne=t("br"),Ve=a(" Output: "),dt=t("code"),Ul=a("hello"),je=a("\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),_l=i(),ie=t("tr"),T=t("td"),ml=a("Strip"),Ot=i(),Je=t("td"),kl=a("Removes all whitespace characters on the specified sides (left, right or both) of the input"),Pt=i(),y=t("td"),Re=a("Input: "),Be=t("code"),bl=a('"'),K=a("hi"),ge=t("code"),Tl=a('"'),Kl=i(),Ue=t("br"),Zt=a(" Output: "),kt=t("code"),N=a('"hi"'),Bt=i(),z=t("tr"),we=t("td"),el=a("StripAccents"),Ml=i(),Qe=t("td"),Xe=a("Removes all accent symbols in unicode (to be used with NFD for consistency)"),Yl=i(),x=t("td"),S=a("Input: "),X=t("code"),tl=a("\xE9"),Gl=i(),Ze=t("br"),gt=a(" Ouput: "),Ct=t("code"),H=a("e"),Vl=i(),F=t("tr"),xe=t("td"),jl=a("Replace"),Jl=i(),et=t("td"),Ke=a("Replaces a custom string or regexp and changes it with given content"),ll=i(),D=t("td"),q=t("code"),$e=a('Replace("a", "e")'),Ql=a(" will behave like this: "),Xl=t("br"),ye=a(" Input: "),tt=t("code"),Zl=a('"banana"'),_=i(),xt=t("br"),Rt=a(" Ouput: "),ct=t("code"),eo=a('"benene"'),to=i(),se=t("tr"),Z=t("td"),ol=a("BertNormalizer"),lo=i(),Ie=t("td"),rl=a("Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),O=t("ul"),Et=t("li"),$t=a("clean_text"),U=i(),he=t("li"),Yt=a("handle_chinese_chars"),oo=i(),fe=t("li"),ro=a("strip_accents"),Cl=i(),b=t("li"),ao=a("lowercase"),ht=i(),It=t("td"),no=i(),ee=t("tr"),me=t("td"),ft=a("Sequence"),zt=i(),ze=t("td"),de=a("Composes multiple normalizers that will run in the provided order"),lt=i(),Se=t("td"),St=t("code"),Ee=a("Sequence::new(vec![NFKC,"),Gt=a("Lowercase])`"),this.h()},l(L){u=l(L,"TABLE",{});var _t=r(u);g=l(_t,"THEAD",{});var al=r(g);f=l(al,"TR",{});var mt=r(f);p=l(mt,"TH",{align:!0});var $=r(p);V=n($,"Name"),$.forEach(o),Kt=s(mt),te=l(mt,"TH",{align:!0});var Rl=r(te);ul=n(Rl,"Description"),Rl.forEach(o),Hl=s(mt),J=l(mt,"TH",{align:!0});var w=r(J);Xt=n(w,"Example"),w.forEach(o),mt.forEach(o),al.forEach(o),Ll=s(_t),h=l(_t,"TBODY",{});var k=r(h);E=l(k,"TR",{});var Ft=r(E);A=l(Ft,"TD",{align:!0});var qt=r(A);pl=n(qt,"NFD"),qt.forEach(o),Mt=s(Ft),M=l(Ft,"TD",{align:!0});var $l=r(M);vl=n($l,"NFD unicode normalization"),$l.forEach(o),le=s(Ft),Q=l(Ft,"TD",{align:!0}),r(Q).forEach(o),Ft.forEach(o),vt=s(k),B=l(k,"TR",{});var Fe=r(B);Le=l(Fe,"TD",{align:!0});var fo=r(Le);Nl=n(fo,"NFKD"),fo.forEach(o),Pl=s(Fe),ce=l(Fe,"TD",{align:!0});var G=r(ce);Bl=n(G,"NFKD unicode normalization"),G.forEach(o),xl=s(Fe),Te=l(Fe,"TD",{align:!0}),r(Te).forEach(o),Fe.forEach(o),Lt=s(k),oe=l(k,"TR",{});var At=r(oe);m=l(At,"TD",{align:!0});var nl=r(m);Fl=n(nl,"NFC"),nl.forEach(o),wt=s(At),We=l(At,"TD",{align:!0});var Il=r(We);Nt=n(Il,"NFC unicode normalization"),Il.forEach(o),wl=s(At),Ce=l(At,"TD",{align:!0}),r(Ce).forEach(o),At.forEach(o),Ne=s(k),j=l(k,"TR",{});var qe=r(j);De=l(qe,"TD",{align:!0});var Ht=r(De);re=n(Ht,"NFKC"),Ht.forEach(o),Pe=s(qe),Ye=l(qe,"TD",{align:!0});var zl=r(Ye);yl=n(zl,"NFKC unicode normalization"),zl.forEach(o),Y=s(qe),yt=l(qe,"TD",{align:!0}),r(yt).forEach(o),qe.forEach(o),st=s(k),ae=l(k,"TR",{});var ot=r(ae);Ge=l(ot,"TD",{align:!0});var v=r(Ge);I=n(v,"Lowercase"),v.forEach(o),ql=s(ot),ve=l(ot,"TD",{align:!0});var il=r(ve);gl=n(il,"Replaces all uppercase to lowercase"),il.forEach(o),Al=s(ot),R=l(ot,"TD",{align:!0});var Oe=r(R);Ol=n(Oe,"Input: "),W=l(Oe,"CODE",{});var uo=r(W);Wl=n(uo,"HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),uo.forEach(o),El=s(Oe),ne=l(Oe,"BR",{}),Ve=n(Oe," Output: "),dt=l(Oe,"CODE",{});var rt=r(dt);Ul=n(rt,"hello"),rt.forEach(o),je=n(Oe,"\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),Oe.forEach(o),ot.forEach(o),_l=s(k),ie=l(k,"TR",{});var ut=r(ie);T=l(ut,"TD",{align:!0});var po=r(T);ml=n(po,"Strip"),po.forEach(o),Ot=s(ut),Je=l(ut,"TD",{align:!0});var ke=r(Je);kl=n(ke,"Removes all whitespace characters on the specified sides (left, right or both) of the input"),ke.forEach(o),Pt=s(ut),y=l(ut,"TD",{align:!0});var Vt=r(y);Re=n(Vt,"Input: "),Be=l(Vt,"CODE",{});var Wt=r(Be);bl=n(Wt,'"'),Wt.forEach(o),K=n(Vt,"hi"),ge=l(Vt,"CODE",{});var io=r(ge);Tl=n(io,'"'),io.forEach(o),Kl=s(Vt),Ue=l(Vt,"BR",{}),Zt=n(Vt," Output: "),kt=l(Vt,"CODE",{});var sl=r(kt);N=n(sl,'"hi"'),sl.forEach(o),Vt.forEach(o),ut.forEach(o),Bt=s(k),z=l(k,"TR",{});var He=r(z);we=l(He,"TD",{align:!0});var vo=r(we);el=n(vo,"StripAccents"),vo.forEach(o),Ml=s(He),Qe=l(He,"TD",{align:!0});var jt=r(Qe);Xe=n(jt,"Removes all accent symbols in unicode (to be used with NFD for consistency)"),jt.forEach(o),Yl=s(He),x=l(He,"TD",{align:!0});var pt=r(x);S=n(pt,"Input: "),X=l(pt,"CODE",{});var go=r(X);tl=n(go,"\xE9"),go.forEach(o),Gl=s(pt),Ze=l(pt,"BR",{}),gt=n(pt," Ouput: "),Ct=l(pt,"CODE",{});var bt=r(Ct);H=n(bt,"e"),bt.forEach(o),pt.forEach(o),He.forEach(o),Vl=s(k),F=l(k,"TR",{});var at=r(F);xe=l(at,"TD",{align:!0});var Eo=r(xe);jl=n(Eo,"Replace"),Eo.forEach(o),Jl=s(at),et=l(at,"TD",{align:!0});var P=r(et);Ke=n(P,"Replaces a custom string or regexp and changes it with given content"),P.forEach(o),ll=s(at),D=l(at,"TD",{align:!0});var be=r(D);q=l(be,"CODE",{});var Sl=r(q);$e=n(Sl,'Replace("a", "e")'),Sl.forEach(o),Ql=n(be," will behave like this: "),Xl=l(be,"BR",{}),ye=n(be," Input: "),tt=l(be,"CODE",{});var _o=r(tt);Zl=n(_o,'"banana"'),_o.forEach(o),_=s(be),xt=l(be,"BR",{}),Rt=n(be," Ouput: "),ct=l(be,"CODE",{});var ue=r(ct);eo=n(ue,'"benene"'),ue.forEach(o),be.forEach(o),at.forEach(o),to=s(k),se=l(k,"TR",{});var nt=r(se);Z=l(nt,"TD",{align:!0});var Jt=r(Z);ol=n(Jt,"BertNormalizer"),Jt.forEach(o),lo=s(nt),Ie=l(nt,"TD",{align:!0});var Ut=r(Ie);rl=n(Ut,"Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),O=l(Ut,"UL",{});var it=r(O);Et=l(it,"LI",{});var Dl=r(Et);$t=n(Dl,"clean_text"),Dl.forEach(o),U=s(it),he=l(it,"LI",{});var Ae=r(he);Yt=n(Ae,"handle_chinese_chars"),Ae.forEach(o),oo=s(it),fe=l(it,"LI",{});var Tt=r(fe);ro=n(Tt,"strip_accents"),Tt.forEach(o),Cl=s(it),b=l(it,"LI",{});var Qt=r(b);ao=n(Qt,"lowercase"),Qt.forEach(o),it.forEach(o),Ut.forEach(o),ht=s(nt),It=l(nt,"TD",{align:!0}),r(It).forEach(o),nt.forEach(o),no=s(k),ee=l(k,"TR",{});var dl=r(ee);me=l(dl,"TD",{align:!0});var cl=r(me);ft=n(cl,"Sequence"),cl.forEach(o),zt=s(dl),ze=l(dl,"TD",{align:!0});var Wo=r(ze);de=n(Wo,"Composes multiple normalizers that will run in the provided order"),Wo.forEach(o),lt=s(dl),Se=l(dl,"TD",{align:!0});var Dt=r(Se);St=l(Dt,"CODE",{});var or=r(St);Ee=n(or,"Sequence::new(vec![NFKC,"),or.forEach(o),Gt=n(Dt,"Lowercase])`"),Dt.forEach(o),dl.forEach(o),k.forEach(o),_t.forEach(o),this.h()},h(){d(p,"align","left"),d(te,"align","left"),d(J,"align","left"),d(A,"align","left"),d(M,"align","left"),d(Q,"align","left"),d(Le,"align","left"),d(ce,"align","left"),d(Te,"align","left"),d(m,"align","left"),d(We,"align","left"),d(Ce,"align","left"),d(De,"align","left"),d(Ye,"align","left"),d(yt,"align","left"),d(Ge,"align","left"),d(ve,"align","left"),d(R,"align","left"),d(T,"align","left"),d(Je,"align","left"),d(y,"align","left"),d(we,"align","left"),d(Qe,"align","left"),d(x,"align","left"),d(xe,"align","left"),d(et,"align","left"),d(D,"align","left"),d(Z,"align","left"),d(Ie,"align","left"),d(It,"align","left"),d(me,"align","left"),d(ze,"align","left"),d(Se,"align","left")},m(L,_t){_e(L,u,_t),e(u,g),e(g,f),e(f,p),e(p,V),e(f,Kt),e(f,te),e(te,ul),e(f,Hl),e(f,J),e(J,Xt),e(u,Ll),e(u,h),e(h,E),e(E,A),e(A,pl),e(E,Mt),e(E,M),e(M,vl),e(E,le),e(E,Q),e(h,vt),e(h,B),e(B,Le),e(Le,Nl),e(B,Pl),e(B,ce),e(ce,Bl),e(B,xl),e(B,Te),e(h,Lt),e(h,oe),e(oe,m),e(m,Fl),e(oe,wt),e(oe,We),e(We,Nt),e(oe,wl),e(oe,Ce),e(h,Ne),e(h,j),e(j,De),e(De,re),e(j,Pe),e(j,Ye),e(Ye,yl),e(j,Y),e(j,yt),e(h,st),e(h,ae),e(ae,Ge),e(Ge,I),e(ae,ql),e(ae,ve),e(ve,gl),e(ae,Al),e(ae,R),e(R,Ol),e(R,W),e(W,Wl),e(R,El),e(R,ne),e(R,Ve),e(R,dt),e(dt,Ul),e(R,je),e(h,_l),e(h,ie),e(ie,T),e(T,ml),e(ie,Ot),e(ie,Je),e(Je,kl),e(ie,Pt),e(ie,y),e(y,Re),e(y,Be),e(Be,bl),e(y,K),e(y,ge),e(ge,Tl),e(y,Kl),e(y,Ue),e(y,Zt),e(y,kt),e(kt,N),e(h,Bt),e(h,z),e(z,we),e(we,el),e(z,Ml),e(z,Qe),e(Qe,Xe),e(z,Yl),e(z,x),e(x,S),e(x,X),e(X,tl),e(x,Gl),e(x,Ze),e(x,gt),e(x,Ct),e(Ct,H),e(h,Vl),e(h,F),e(F,xe),e(xe,jl),e(F,Jl),e(F,et),e(et,Ke),e(F,ll),e(F,D),e(D,q),e(q,$e),e(D,Ql),e(D,Xl),e(D,ye),e(D,tt),e(tt,Zl),e(D,_),e(D,xt),e(D,Rt),e(D,ct),e(ct,eo),e(h,to),e(h,se),e(se,Z),e(Z,ol),e(se,lo),e(se,Ie),e(Ie,rl),e(Ie,O),e(O,Et),e(Et,$t),e(O,U),e(O,he),e(he,Yt),e(O,oo),e(O,fe),e(fe,ro),e(O,Cl),e(O,b),e(b,ao),e(se,ht),e(se,It),e(h,no),e(h,ee),e(ee,me),e(me,ft),e(ee,zt),e(ee,ze),e(ze,de),e(ee,lt),e(ee,Se),e(Se,St),e(St,Ee),e(Se,Gt)},d(L){L&&o(u)}}}function wn(ko){let u,g;return u=new Qr({props:{$$slots:{default:[Dn]},$$scope:{ctx:ko}}}),{c(){ur(u.$$.fragment)},l(f){pr(u.$$.fragment,f)},m(f,p){vr(u,f,p),g=!0},p(f,p){const V={};p&2&&(V.$$scope={dirty:p,ctx:f}),u.$set(V)},i(f){g||(gr(u.$$.fragment,f),g=!0)},o(f){Er(u.$$.fragment,f),g=!1},d(f){_r(u,f)}}}function yn(ko){let u,g,f,p,V,Kt,te,ul,Hl,J,Xt,Ll,h,E,A,pl,Mt,M,vl,le,Q,vt,B,Le,Nl,Pl,ce,Bl,xl,Te,Lt,oe,m,Fl,wt,We,Nt,wl,Ce,Ne,j,De,re,Pe,Ye,yl,Y,yt,st,ae,Ge,I,ql,ve,gl,Al,R,Ol,W,Wl,El,ne,Ve,dt,Ul,je,_l,ie,T,ml,Ot,Je,kl,Pt,y,Re,Be,bl,K,ge,Tl,Kl,Ue,Zt,kt,N,Bt,z,we,el,Ml,Qe,Xe,Yl,x,S,X,tl,Gl,Ze,gt,Ct,H,Vl,F,xe,jl,Jl,et,Ke,ll,D,q,$e,Ql,Xl,ye,tt,Zl,_,xt,Rt,ct,eo,to,se,Z,ol,lo,Ie,rl,O,Et,$t,U,he,Yt,oo,fe,ro,Cl,b,ao,ht,It,no,ee,me,ft,zt,ze,de,lt,Se;return{c(){u=t("table"),g=t("thead"),f=t("tr"),p=t("th"),V=a("Name"),Kt=i(),te=t("th"),ul=a("Description"),Hl=i(),J=t("th"),Xt=a("Example"),Ll=i(),h=t("tbody"),E=t("tr"),A=t("td"),pl=a("NFD"),Mt=i(),M=t("td"),vl=a("NFD unicode normalization"),le=i(),Q=t("td"),vt=i(),B=t("tr"),Le=t("td"),Nl=a("NFKD"),Pl=i(),ce=t("td"),Bl=a("NFKD unicode normalization"),xl=i(),Te=t("td"),Lt=i(),oe=t("tr"),m=t("td"),Fl=a("NFC"),wt=i(),We=t("td"),Nt=a("NFC unicode normalization"),wl=i(),Ce=t("td"),Ne=i(),j=t("tr"),De=t("td"),re=a("NFKC"),Pe=i(),Ye=t("td"),yl=a("NFKC unicode normalization"),Y=i(),yt=t("td"),st=i(),ae=t("tr"),Ge=t("td"),I=a("Lowercase"),ql=i(),ve=t("td"),gl=a("Replaces all uppercase to lowercase"),Al=i(),R=t("td"),Ol=a("Input: "),W=t("code"),Wl=a("HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),El=i(),ne=t("br"),Ve=a(" Output: "),dt=t("code"),Ul=a("hello"),je=a("\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),_l=i(),ie=t("tr"),T=t("td"),ml=a("Strip"),Ot=i(),Je=t("td"),kl=a("Removes all whitespace characters on the specified sides (left, right or both) of the input"),Pt=i(),y=t("td"),Re=a("Input: "),Be=t("code"),bl=a('"'),K=a("hi"),ge=t("code"),Tl=a('"'),Kl=i(),Ue=t("br"),Zt=a(" Output: "),kt=t("code"),N=a('"hi"'),Bt=i(),z=t("tr"),we=t("td"),el=a("StripAccents"),Ml=i(),Qe=t("td"),Xe=a("Removes all accent symbols in unicode (to be used with NFD for consistency)"),Yl=i(),x=t("td"),S=a("Input: "),X=t("code"),tl=a("\xE9"),Gl=i(),Ze=t("br"),gt=a(" Ouput: "),Ct=t("code"),H=a("e"),Vl=i(),F=t("tr"),xe=t("td"),jl=a("Replace"),Jl=i(),et=t("td"),Ke=a("Replaces a custom string or regexp and changes it with given content"),ll=i(),D=t("td"),q=t("code"),$e=a('Replace("a", "e")'),Ql=a(" will behave like this: "),Xl=t("br"),ye=a(" Input: "),tt=t("code"),Zl=a('"banana"'),_=i(),xt=t("br"),Rt=a(" Ouput: "),ct=t("code"),eo=a('"benene"'),to=i(),se=t("tr"),Z=t("td"),ol=a("BertNormalizer"),lo=i(),Ie=t("td"),rl=a("Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),O=t("ul"),Et=t("li"),$t=a("cleanText"),U=i(),he=t("li"),Yt=a("handleChineseChars"),oo=i(),fe=t("li"),ro=a("stripAccents"),Cl=i(),b=t("li"),ao=a("lowercase"),ht=i(),It=t("td"),no=i(),ee=t("tr"),me=t("td"),ft=a("Sequence"),zt=i(),ze=t("td"),de=a("Composes multiple normalizers that will run in the provided order"),lt=i(),Se=t("td"),this.h()},l(St){u=l(St,"TABLE",{});var Ee=r(u);g=l(Ee,"THEAD",{});var Gt=r(g);f=l(Gt,"TR",{});var L=r(f);p=l(L,"TH",{align:!0});var _t=r(p);V=n(_t,"Name"),_t.forEach(o),Kt=s(L),te=l(L,"TH",{align:!0});var al=r(te);ul=n(al,"Description"),al.forEach(o),Hl=s(L),J=l(L,"TH",{align:!0});var mt=r(J);Xt=n(mt,"Example"),mt.forEach(o),L.forEach(o),Gt.forEach(o),Ll=s(Ee),h=l(Ee,"TBODY",{});var $=r(h);E=l($,"TR",{});var Rl=r(E);A=l(Rl,"TD",{align:!0});var w=r(A);pl=n(w,"NFD"),w.forEach(o),Mt=s(Rl),M=l(Rl,"TD",{align:!0});var k=r(M);vl=n(k,"NFD unicode normalization"),k.forEach(o),le=s(Rl),Q=l(Rl,"TD",{align:!0}),r(Q).forEach(o),Rl.forEach(o),vt=s($),B=l($,"TR",{});var Ft=r(B);Le=l(Ft,"TD",{align:!0});var qt=r(Le);Nl=n(qt,"NFKD"),qt.forEach(o),Pl=s(Ft),ce=l(Ft,"TD",{align:!0});var $l=r(ce);Bl=n($l,"NFKD unicode normalization"),$l.forEach(o),xl=s(Ft),Te=l(Ft,"TD",{align:!0}),r(Te).forEach(o),Ft.forEach(o),Lt=s($),oe=l($,"TR",{});var Fe=r(oe);m=l(Fe,"TD",{align:!0});var fo=r(m);Fl=n(fo,"NFC"),fo.forEach(o),wt=s(Fe),We=l(Fe,"TD",{align:!0});var G=r(We);Nt=n(G,"NFC unicode normalization"),G.forEach(o),wl=s(Fe),Ce=l(Fe,"TD",{align:!0}),r(Ce).forEach(o),Fe.forEach(o),Ne=s($),j=l($,"TR",{});var At=r(j);De=l(At,"TD",{align:!0});var nl=r(De);re=n(nl,"NFKC"),nl.forEach(o),Pe=s(At),Ye=l(At,"TD",{align:!0});var Il=r(Ye);yl=n(Il,"NFKC unicode normalization"),Il.forEach(o),Y=s(At),yt=l(At,"TD",{align:!0}),r(yt).forEach(o),At.forEach(o),st=s($),ae=l($,"TR",{});var qe=r(ae);Ge=l(qe,"TD",{align:!0});var Ht=r(Ge);I=n(Ht,"Lowercase"),Ht.forEach(o),ql=s(qe),ve=l(qe,"TD",{align:!0});var zl=r(ve);gl=n(zl,"Replaces all uppercase to lowercase"),zl.forEach(o),Al=s(qe),R=l(qe,"TD",{align:!0});var ot=r(R);Ol=n(ot,"Input: "),W=l(ot,"CODE",{});var v=r(W);Wl=n(v,"HELLO \u1F48\u0394\u03A5\u03A3\u03A3\u0395\u038E\u03A3"),v.forEach(o),El=s(ot),ne=l(ot,"BR",{}),Ve=n(ot," Output: "),dt=l(ot,"CODE",{});var il=r(dt);Ul=n(il,"hello"),il.forEach(o),je=n(ot,"\u1F40\u03B4\u03C5\u03C3\u03C3\u03B5\u03CD\u03C2`"),ot.forEach(o),qe.forEach(o),_l=s($),ie=l($,"TR",{});var Oe=r(ie);T=l(Oe,"TD",{align:!0});var uo=r(T);ml=n(uo,"Strip"),uo.forEach(o),Ot=s(Oe),Je=l(Oe,"TD",{align:!0});var rt=r(Je);kl=n(rt,"Removes all whitespace characters on the specified sides (left, right or both) of the input"),rt.forEach(o),Pt=s(Oe),y=l(Oe,"TD",{align:!0});var ut=r(y);Re=n(ut,"Input: "),Be=l(ut,"CODE",{});var po=r(Be);bl=n(po,'"'),po.forEach(o),K=n(ut,"hi"),ge=l(ut,"CODE",{});var ke=r(ge);Tl=n(ke,'"'),ke.forEach(o),Kl=s(ut),Ue=l(ut,"BR",{}),Zt=n(ut," Output: "),kt=l(ut,"CODE",{});var Vt=r(kt);N=n(Vt,'"hi"'),Vt.forEach(o),ut.forEach(o),Oe.forEach(o),Bt=s($),z=l($,"TR",{});var Wt=r(z);we=l(Wt,"TD",{align:!0});var io=r(we);el=n(io,"StripAccents"),io.forEach(o),Ml=s(Wt),Qe=l(Wt,"TD",{align:!0});var sl=r(Qe);Xe=n(sl,"Removes all accent symbols in unicode (to be used with NFD for consistency)"),sl.forEach(o),Yl=s(Wt),x=l(Wt,"TD",{align:!0});var He=r(x);S=n(He,"Input: "),X=l(He,"CODE",{});var vo=r(X);tl=n(vo,"\xE9"),vo.forEach(o),Gl=s(He),Ze=l(He,"BR",{}),gt=n(He," Ouput: "),Ct=l(He,"CODE",{});var jt=r(Ct);H=n(jt,"e"),jt.forEach(o),He.forEach(o),Wt.forEach(o),Vl=s($),F=l($,"TR",{});var pt=r(F);xe=l(pt,"TD",{align:!0});var go=r(xe);jl=n(go,"Replace"),go.forEach(o),Jl=s(pt),et=l(pt,"TD",{align:!0});var bt=r(et);Ke=n(bt,"Replaces a custom string or regexp and changes it with given content"),bt.forEach(o),ll=s(pt),D=l(pt,"TD",{align:!0});var at=r(D);q=l(at,"CODE",{});var Eo=r(q);$e=n(Eo,'Replace("a", "e")'),Eo.forEach(o),Ql=n(at," will behave like this: "),Xl=l(at,"BR",{}),ye=n(at," Input: "),tt=l(at,"CODE",{});var P=r(tt);Zl=n(P,'"banana"'),P.forEach(o),_=s(at),xt=l(at,"BR",{}),Rt=n(at," Ouput: "),ct=l(at,"CODE",{});var be=r(ct);eo=n(be,'"benene"'),be.forEach(o),at.forEach(o),pt.forEach(o),to=s($),se=l($,"TR",{});var Sl=r(se);Z=l(Sl,"TD",{align:!0});var _o=r(Z);ol=n(_o,"BertNormalizer"),_o.forEach(o),lo=s(Sl),Ie=l(Sl,"TD",{align:!0});var ue=r(Ie);rl=n(ue,"Provides an implementation of the Normalizer used in the original BERT. Options that can be set are: "),O=l(ue,"UL",{});var nt=r(O);Et=l(nt,"LI",{});var Jt=r(Et);$t=n(Jt,"cleanText"),Jt.forEach(o),U=s(nt),he=l(nt,"LI",{});var Ut=r(he);Yt=n(Ut,"handleChineseChars"),Ut.forEach(o),oo=s(nt),fe=l(nt,"LI",{});var it=r(fe);ro=n(it,"stripAccents"),it.forEach(o),Cl=s(nt),b=l(nt,"LI",{});var Dl=r(b);ao=n(Dl,"lowercase"),Dl.forEach(o),nt.forEach(o),ue.forEach(o),ht=s(Sl),It=l(Sl,"TD",{align:!0}),r(It).forEach(o),Sl.forEach(o),no=s($),ee=l($,"TR",{});var Ae=r(ee);me=l(Ae,"TD",{align:!0});var Tt=r(me);ft=n(Tt,"Sequence"),Tt.forEach(o),zt=s(Ae),ze=l(Ae,"TD",{align:!0});var Qt=r(ze);de=n(Qt,"Composes multiple normalizers that will run in the provided order"),Qt.forEach(o),lt=s(Ae),Se=l(Ae,"TD",{align:!0}),r(Se).forEach(o),Ae.forEach(o),$.forEach(o),Ee.forEach(o),this.h()},h(){d(p,"align","left"),d(te,"align","left"),d(J,"align","left"),d(A,"align","left"),d(M,"align","left"),d(Q,"align","left"),d(Le,"align","left"),d(ce,"align","left"),d(Te,"align","left"),d(m,"align","left"),d(We,"align","left"),d(Ce,"align","left"),d(De,"align","left"),d(Ye,"align","left"),d(yt,"align","left"),d(Ge,"align","left"),d(ve,"align","left"),d(R,"align","left"),d(T,"align","left"),d(Je,"align","left"),d(y,"align","left"),d(we,"align","left"),d(Qe,"align","left"),d(x,"align","left"),d(xe,"align","left"),d(et,"align","left"),d(D,"align","left"),d(Z,"align","left"),d(Ie,"align","left"),d(It,"align","left"),d(me,"align","left"),d(ze,"align","left"),d(Se,"align","left")},m(St,Ee){_e(St,u,Ee),e(u,g),e(g,f),e(f,p),e(p,V),e(f,Kt),e(f,te),e(te,ul),e(f,Hl),e(f,J),e(J,Xt),e(u,Ll),e(u,h),e(h,E),e(E,A),e(A,pl),e(E,Mt),e(E,M),e(M,vl),e(E,le),e(E,Q),e(h,vt),e(h,B),e(B,Le),e(Le,Nl),e(B,Pl),e(B,ce),e(ce,Bl),e(B,xl),e(B,Te),e(h,Lt),e(h,oe),e(oe,m),e(m,Fl),e(oe,wt),e(oe,We),e(We,Nt),e(oe,wl),e(oe,Ce),e(h,Ne),e(h,j),e(j,De),e(De,re),e(j,Pe),e(j,Ye),e(Ye,yl),e(j,Y),e(j,yt),e(h,st),e(h,ae),e(ae,Ge),e(Ge,I),e(ae,ql),e(ae,ve),e(ve,gl),e(ae,Al),e(ae,R),e(R,Ol),e(R,W),e(W,Wl),e(R,El),e(R,ne),e(R,Ve),e(R,dt),e(dt,Ul),e(R,je),e(h,_l),e(h,ie),e(ie,T),e(T,ml),e(ie,Ot),e(ie,Je),e(Je,kl),e(ie,Pt),e(ie,y),e(y,Re),e(y,Be),e(Be,bl),e(y,K),e(y,ge),e(ge,Tl),e(y,Kl),e(y,Ue),e(y,Zt),e(y,kt),e(kt,N),e(h,Bt),e(h,z),e(z,we),e(we,el),e(z,Ml),e(z,Qe),e(Qe,Xe),e(z,Yl),e(z,x),e(x,S),e(x,X),e(X,tl),e(x,Gl),e(x,Ze),e(x,gt),e(x,Ct),e(Ct,H),e(h,Vl),e(h,F),e(F,xe),e(xe,jl),e(F,Jl),e(F,et),e(et,Ke),e(F,ll),e(F,D),e(D,q),e(q,$e),e(D,Ql),e(D,Xl),e(D,ye),e(D,tt),e(tt,Zl),e(D,_),e(D,xt),e(D,Rt),e(D,ct),e(ct,eo),e(h,to),e(h,se),e(se,Z),e(Z,ol),e(se,lo),e(se,Ie),e(Ie,rl),e(Ie,O),e(O,Et),e(Et,$t),e(O,U),e(O,he),e(he,Yt),e(O,oo),e(O,fe),e(fe,ro),e(O,Cl),e(O,b),e(b,ao),e(se,ht),e(se,It),e(h,no),e(h,ee),e(ee,me),e(me,ft),e(ee,zt),e(ee,ze),e(ze,de),e(ee,lt),e(ee,Se)},d(St){St&&o(u)}}}function On(ko){let u,g;return u=new Qr({props:{$$slots:{default:[yn]},$$scope:{ctx:ko}}}),{c(){ur(u.$$.fragment)},l(f){pr(u.$$.fragment,f)},m(f,p){vr(u,f,p),g=!0},p(f,p){const V={};p&2&&(V.$$scope={dirty:p,ctx:f}),u.$set(V)},i(f){g||(gr(u.$$.fragment,f),g=!0)},o(f){Er(u.$$.fragment,f),g=!1},d(f){_r(u,f)}}}function kn(ko){let u,g,f,p,V,Kt,te,ul,Hl,J,Xt,Ll,h,E,A,pl,Mt,M,vl,le,Q,vt,B,Le,Nl,Pl,ce,Bl,xl,Te,Lt,oe,m,Fl,wt,We,Nt,wl,Ce,Ne,j,De,re,Pe,Ye,yl,Y,yt,st,ae,Ge,I,ql,ve,gl,Al,R,Ol,W,Wl,El,ne,Ve,dt,Ul,je,_l,ie,T,ml,Ot,Je,kl,Pt,y,Re,Be,bl,K,ge,Tl,Kl,Ue,Zt,kt,N,Bt,z,we,el,Ml,Qe,Xe,Yl,x,S,X,tl,Gl,Ze,gt,Ct,H,Vl,F,xe,jl,Jl,et,Ke,ll,D,q,$e,Ql,Xl,ye,tt,Zl,_,xt,Rt,ct,eo,to,se,Z,ol,lo,Ie,rl,O,Et,$t,U,he,Yt,oo,fe,ro,Cl,b,ao,ht,It,no,ee,me,ft,zt,ze,de,lt,Se,St,Ee,Gt,L,_t,al,mt,$,Rl,w,k,Ft,qt,$l,Fe,fo,G,At,nl,Il,qe,Ht,zl,ot,v,il,Oe,uo,rt,ut,po,ke,Vt,Wt,io,sl,He,vo,jt,pt,go,bt,at,Eo,P,be,Sl,_o,ue,nt,Jt,Ut,it,Dl,Ae,Tt,Qt;return{c(){u=t("table"),g=t("thead"),f=t("tr"),p=t("th"),V=a("Name"),Kt=i(),te=t("th"),ul=a("Description"),Hl=i(),J=t("th"),Xt=a("Example"),Ll=i(),h=t("tbody"),E=t("tr"),A=t("td"),pl=a("ByteLevel"),Mt=i(),M=t("td"),vl=a("Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),le=t("ul"),Q=t("li"),vt=a("Since it maps on bytes, a tokenizer using this only requires "),B=t("strong"),Le=a("256"),Nl=a(" characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),Pl=i(),ce=t("li"),Bl=a("A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),xl=i(),Te=t("li"),Lt=a("For non ascii characters, it gets completely unreadable, but it works nonetheless!"),oe=i(),m=t("td"),Fl=a("Input: "),wt=t("code"),We=a('"Hello my friend, how are you?"'),Nt=i(),wl=t("br"),Ce=a(" Ouput: "),Ne=t("code"),j=a('"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),De=i(),re=t("tr"),Pe=t("td"),Ye=a("Whitespace"),yl=i(),Y=t("td"),yt=a("Splits on word boundaries (using the following regular expression: "),st=t("code"),ae=a("\\w+|[^\\w\\s]+"),Ge=i(),I=t("td"),ql=a("Input: "),ve=t("code"),gl=a('"Hello there!"'),Al=i(),R=t("br"),Ol=a(" Output: "),W=t("code"),Wl=a('"Hello", "there", "!"'),El=i(),ne=t("tr"),Ve=t("td"),dt=a("WhitespaceSplit"),Ul=i(),je=t("td"),_l=a("Splits on any whitespace character"),ie=i(),T=t("td"),ml=a("Input: "),Ot=t("code"),Je=a('"Hello there!"'),kl=i(),Pt=t("br"),y=a(" Output: "),Re=t("code"),Be=a('"Hello", "there!"'),bl=i(),K=t("tr"),ge=t("td"),Tl=a("Punctuation"),Kl=i(),Ue=t("td"),Zt=a("Will isolate all punctuation characters"),kt=i(),N=t("td"),Bt=a("Input: "),z=t("code"),we=a('"Hello?"'),el=i(),Ml=t("br"),Qe=a(" Ouput: "),Xe=t("code"),Yl=a('"Hello", "?"'),x=i(),S=t("tr"),X=t("td"),tl=a("Metaspace"),Gl=i(),Ze=t("td"),gt=a("Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),Ct=i(),H=t("td"),Vl=a("Input: "),F=t("code"),xe=a('"Hello there"'),jl=i(),Jl=t("br"),et=a(" Ouput: "),Ke=t("code"),ll=a('"Hello", "\u2581there"'),D=i(),q=t("tr"),$e=t("td"),Ql=a("CharDelimiterSplit"),Xl=i(),ye=t("td"),tt=a("Splits on a given character"),Zl=i(),_=t("td"),xt=a("Example with "),Rt=t("code"),ct=a("x"),eo=a(": "),to=t("br"),se=a(" Input: "),Z=t("code"),ol=a('"Helloxthere"'),lo=i(),Ie=t("br"),rl=a(" Ouput: "),O=t("code"),Et=a('"Hello", "there"'),$t=i(),U=t("tr"),he=t("td"),Yt=a("Digits"),oo=i(),fe=t("td"),ro=a("Splits the numbers from any other characters."),Cl=i(),b=t("td"),ao=a("Input: "),ht=t("code"),It=a('"Hello123there"'),no=i(),ee=t("br"),me=a("  Output: "),ft=t("code"),zt=a('"Hello", "123", "there"'),ze=i(),de=t("tr"),lt=t("td"),Se=a("Split"),St=i(),Ee=t("td"),Gt=a("Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),L=t("ul"),_t=t("li"),al=a("pattern should be either a custom string or regexp."),mt=i(),$=t("li"),Rl=a("behavior should be one of: "),w=t("ul"),k=t("li"),Ft=a("removed"),qt=t("li"),$l=a("isolated"),Fe=t("li"),fo=a("merged_with_previous"),G=t("li"),At=a("merged_with_next"),nl=t("li"),Il=a("contiguous"),qe=i(),Ht=t("li"),zl=a("invert should be a boolean flag."),ot=i(),v=t("td"),il=a("Example with pattern = "),Oe=t("code"),uo=a(", behavior = "),rt=t("code"),ut=a('"isolated"'),po=a(", invert = "),ke=t("code"),Vt=a("False"),Wt=a(": "),io=t("br"),sl=a(" Input: "),He=t("code"),vo=a('"Hello, how are you?"'),jt=i(),pt=t("br"),go=a(" Output: "),bt=t("code"),at=a('"Hello,", " ", "how", " ", "are", " ", "you?"'),Eo=i(),P=t("tr"),be=t("td"),Sl=a("Sequence"),_o=i(),ue=t("td"),nt=a("Lets you compose multiple "),Jt=t("code"),Ut=a("PreTokenizer"),it=a(" that will be run in the given order"),Dl=i(),Ae=t("td"),Tt=t("code"),Qt=a("Sequence([Punctuation(), WhitespaceSplit()])"),this.h()},l(dl){u=l(dl,"TABLE",{});var cl=r(u);g=l(cl,"THEAD",{});var Wo=r(g);f=l(Wo,"TR",{});var Dt=r(f);p=l(Dt,"TH",{align:!0});var or=r(p);V=n(or,"Name"),or.forEach(o),Kt=s(Dt),te=l(Dt,"TH",{align:!0});var hl=r(te);ul=n(hl,"Description"),hl.forEach(o),Hl=s(Dt),J=l(Dt,"TH",{align:!0});var Vo=r(J);Xt=n(Vo,"Example"),Vo.forEach(o),Dt.forEach(o),Wo.forEach(o),Ll=s(cl),h=l(cl,"TBODY",{});var pe=r(h);E=l(pe,"TR",{});var wo=r(E);A=l(wo,"TD",{align:!0});var jo=r(A);pl=n(jo,"ByteLevel"),jo.forEach(o),Mt=s(wo),M=l(wo,"TD",{align:!0});var Jo=r(M);vl=n(Jo,"Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),le=l(Jo,"UL",{});var Io=r(le);Q=l(Io,"LI",{});var zo=r(Q);vt=n(zo,"Since it maps on bytes, a tokenizer using this only requires "),B=l(zo,"STRONG",{});var hr=r(B);Le=n(hr,"256"),hr.forEach(o),Nl=n(zo," characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),zo.forEach(o),Pl=s(Io),ce=l(Io,"LI",{});var So=r(ce);Bl=n(So,"A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),So.forEach(o),xl=s(Io),Te=l(Io,"LI",{});var rr=r(Te);Lt=n(rr,"For non ascii characters, it gets completely unreadable, but it works nonetheless!"),rr.forEach(o),Io.forEach(o),Jo.forEach(o),oe=s(wo),m=l(wo,"TD",{align:!0});var Co=r(m);Fl=n(Co,"Input: "),wt=l(Co,"CODE",{});var Qo=r(wt);We=n(Qo,'"Hello my friend, how are you?"'),Qo.forEach(o),Nt=s(Co),wl=l(Co,"BR",{}),Ce=n(Co," Ouput: "),Ne=l(Co,"CODE",{});var ar=r(Ne);j=n(ar,'"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),ar.forEach(o),Co.forEach(o),wo.forEach(o),De=s(pe),re=l(pe,"TR",{});var Ho=r(re);Pe=l(Ho,"TD",{align:!0});var Or=r(Pe);Ye=n(Or,"Whitespace"),Or.forEach(o),yl=s(Ho),Y=l(Ho,"TD",{align:!0});var co=r(Y);yt=n(co,"Splits on word boundaries (using the following regular expression: "),st=l(co,"CODE",{});var Xo=r(st);ae=n(Xo,"\\w+|[^\\w\\s]+"),Xo.forEach(o),co.forEach(o),Ge=s(Ho),I=l(Ho,"TD",{align:!0});var ho=r(I);ql=n(ho,"Input: "),ve=l(ho,"CODE",{});var Zo=r(ve);gl=n(Zo,'"Hello there!"'),Zo.forEach(o),Al=s(ho),R=l(ho,"BR",{}),Ol=n(ho," Output: "),W=l(ho,"CODE",{});var kr=r(W);Wl=n(kr,'"Hello", "there", "!"'),kr.forEach(o),ho.forEach(o),Ho.forEach(o),El=s(pe),ne=l(pe,"TR",{});var yo=r(ne);Ve=l(yo,"TD",{align:!0});var Yo=r(Ve);dt=n(Yo,"WhitespaceSplit"),Yo.forEach(o),Ul=s(yo),je=l(yo,"TD",{align:!0});var Cr=r(je);_l=n(Cr,"Splits on any whitespace character"),Cr.forEach(o),ie=s(yo),T=l(yo,"TD",{align:!0});var so=r(T);ml=n(so,"Input: "),Ot=l(so,"CODE",{});var Uo=r(Ot);Je=n(Uo,'"Hello there!"'),Uo.forEach(o),kl=s(so),Pt=l(so,"BR",{}),y=n(so," Output: "),Re=l(so,"CODE",{});var Rr=r(Re);Be=n(Rr,'"Hello", "there!"'),Rr.forEach(o),so.forEach(o),yo.forEach(o),bl=s(pe),K=l(pe,"TR",{});var xo=r(K);ge=l(xo,"TD",{align:!0});var Ro=r(ge);Tl=n(Ro,"Punctuation"),Ro.forEach(o),Kl=s(xo),Ue=l(xo,"TD",{align:!0});var $r=r(Ue);Zt=n($r,"Will isolate all punctuation characters"),$r.forEach(o),kt=s(xo),N=l(xo,"TD",{align:!0});var mo=r(N);Bt=n(mo,"Input: "),z=l(mo,"CODE",{});var er=r(z);we=n(er,'"Hello?"'),er.forEach(o),el=s(mo),Ml=l(mo,"BR",{}),Qe=n(mo," Ouput: "),Xe=l(mo,"CODE",{});var Ir=r(Xe);Yl=n(Ir,'"Hello", "?"'),Ir.forEach(o),mo.forEach(o),xo.forEach(o),x=s(pe),S=l(pe,"TR",{});var Fo=r(S);X=l(Fo,"TD",{align:!0});var Lo=r(X);tl=n(Lo,"Metaspace"),Lo.forEach(o),Gl=s(Fo),Ze=l(Fo,"TD",{align:!0});var nr=r(Ze);gt=n(nr,"Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),nr.forEach(o),Ct=s(Fo),H=l(Fo,"TD",{align:!0});var $o=r(H);Vl=n($o,"Input: "),F=l($o,"CODE",{});var tr=r(F);xe=n(tr,'"Hello there"'),tr.forEach(o),jl=s($o),Jl=l($o,"BR",{}),et=n($o," Ouput: "),Ke=l($o,"CODE",{});var Go=r(Ke);ll=n(Go,'"Hello", "\u2581there"'),Go.forEach(o),$o.forEach(o),Fo.forEach(o),D=s(pe),q=l(pe,"TR",{});var qo=r(q);$e=l(qo,"TD",{align:!0});var Oo=r($e);Ql=n(Oo,"CharDelimiterSplit"),Oo.forEach(o),Xl=s(qo),ye=l(qo,"TD",{align:!0});var zr=r(ye);tt=n(zr,"Splits on a given character"),zr.forEach(o),Zl=s(qo),_=l(qo,"TD",{align:!0});var fl=r(_);xt=n(fl,"Example with "),Rt=l(fl,"CODE",{});var mr=r(Rt);ct=n(mr,"x"),mr.forEach(o),eo=n(fl,": "),to=l(fl,"BR",{}),se=n(fl," Input: "),Z=l(fl,"CODE",{});var c=r(Z);ol=n(c,'"Helloxthere"'),c.forEach(o),lo=s(fl),Ie=l(fl,"BR",{}),rl=n(fl," Ouput: "),O=l(fl,"CODE",{});var C=r(O);Et=n(C,'"Hello", "there"'),C.forEach(o),fl.forEach(o),qo.forEach(o),$t=s(pe),U=l(pe,"TR",{});var bo=r(U);he=l(bo,"TD",{align:!0});var Ko=r(he);Yt=n(Ko,"Digits"),Ko.forEach(o),oo=s(bo),fe=l(bo,"TD",{align:!0});var Sr=r(fe);ro=n(Sr,"Splits the numbers from any other characters."),Sr.forEach(o),Cl=s(bo),b=l(bo,"TD",{align:!0});var No=r(b);ao=n(No,"Input: "),ht=l(No,"CODE",{});var ir=r(ht);It=n(ir,'"Hello123there"'),ir.forEach(o),no=s(No),ee=l(No,"BR",{}),me=n(No,"  Output: "),ft=l(No,"CODE",{});var br=r(ft);zt=n(br,'"Hello", "123", "there"'),br.forEach(o),No.forEach(o),bo.forEach(o),ze=s(pe),de=l(pe,"TR",{});var Ao=r(de);lt=l(Ao,"TD",{align:!0});var sr=r(lt);Se=n(sr,"Split"),sr.forEach(o),St=s(Ao),Ee=l(Ao,"TD",{align:!0});var Tr=r(Ee);Gt=n(Tr,"Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),L=l(Tr,"UL",{});var To=r(L);_t=l(To,"LI",{});var dr=r(_t);al=n(dr,"pattern should be either a custom string or regexp."),dr.forEach(o),mt=s(To),$=l(To,"LI",{});var Dr=r($);Rl=n(Dr,"behavior should be one of: "),w=l(Dr,"UL",{});var Po=r(w);k=l(Po,"LI",{});var Hr=r(k);Ft=n(Hr,"removed"),Hr.forEach(o),qt=l(Po,"LI",{});var wr=r(qt);$l=n(wr,"isolated"),wr.forEach(o),Fe=l(Po,"LI",{});var Lr=r(Fe);fo=n(Lr,"merged_with_previous"),Lr.forEach(o),G=l(Po,"LI",{});var Nr=r(G);At=n(Nr,"merged_with_next"),Nr.forEach(o),nl=l(Po,"LI",{});var Do=r(nl);Il=n(Do,"contiguous"),Do.forEach(o),Po.forEach(o),Dr.forEach(o),qe=s(To),Ht=l(To,"LI",{});var lr=r(Ht);zl=n(lr,"invert should be a boolean flag."),lr.forEach(o),To.forEach(o),Tr.forEach(o),ot=s(Ao),v=l(Ao,"TD",{align:!0});var Me=r(v);il=n(Me,"Example with pattern = "),Oe=l(Me,"CODE",{});var Fr=r(Oe);Fr.forEach(o),uo=n(Me,", behavior = "),rt=l(Me,"CODE",{});var Pr=r(rt);ut=n(Pr,'"isolated"'),Pr.forEach(o),po=n(Me,", invert = "),ke=l(Me,"CODE",{});var Mo=r(ke);Vt=n(Mo,"False"),Mo.forEach(o),Wt=n(Me,": "),io=l(Me,"BR",{}),sl=n(Me," Input: "),He=l(Me,"CODE",{});var cr=r(He);vo=n(cr,'"Hello, how are you?"'),cr.forEach(o),jt=s(Me),pt=l(Me,"BR",{}),go=n(Me," Output: "),bt=l(Me,"CODE",{});var Br=r(bt);at=n(Br,'"Hello,", " ", "how", " ", "are", " ", "you?"'),Br.forEach(o),Me.forEach(o),Ao.forEach(o),Eo=s(pe),P=l(pe,"TR",{});var Bo=r(P);be=l(Bo,"TD",{align:!0});var xr=r(be);Sl=n(xr,"Sequence"),xr.forEach(o),_o=s(Bo),ue=l(Bo,"TD",{align:!0});var fr=r(ue);nt=n(fr,"Lets you compose multiple "),Jt=l(fr,"CODE",{});var qr=r(Jt);Ut=n(qr,"PreTokenizer"),qr.forEach(o),it=n(fr," that will be run in the given order"),fr.forEach(o),Dl=s(Bo),Ae=l(Bo,"TD",{align:!0});var Ar=r(Ae);Tt=l(Ar,"CODE",{});var Wr=r(Tt);Qt=n(Wr,"Sequence([Punctuation(), WhitespaceSplit()])"),Wr.forEach(o),Ar.forEach(o),Bo.forEach(o),pe.forEach(o),cl.forEach(o),this.h()},h(){d(p,"align","left"),d(te,"align","left"),d(J,"align","left"),d(A,"align","left"),d(M,"align","left"),d(m,"align","left"),d(Pe,"align","left"),d(Y,"align","left"),d(I,"align","left"),d(Ve,"align","left"),d(je,"align","left"),d(T,"align","left"),d(ge,"align","left"),d(Ue,"align","left"),d(N,"align","left"),d(X,"align","left"),d(Ze,"align","left"),d(H,"align","left"),d($e,"align","left"),d(ye,"align","left"),d(_,"align","left"),d(he,"align","left"),d(fe,"align","left"),d(b,"align","left"),d(lt,"align","left"),d(Ee,"align","left"),d(v,"align","left"),d(be,"align","left"),d(ue,"align","left"),d(Ae,"align","left")},m(dl,cl){_e(dl,u,cl),e(u,g),e(g,f),e(f,p),e(p,V),e(f,Kt),e(f,te),e(te,ul),e(f,Hl),e(f,J),e(J,Xt),e(u,Ll),e(u,h),e(h,E),e(E,A),e(A,pl),e(E,Mt),e(E,M),e(M,vl),e(M,le),e(le,Q),e(Q,vt),e(Q,B),e(B,Le),e(Q,Nl),e(le,Pl),e(le,ce),e(ce,Bl),e(le,xl),e(le,Te),e(Te,Lt),e(E,oe),e(E,m),e(m,Fl),e(m,wt),e(wt,We),e(m,Nt),e(m,wl),e(m,Ce),e(m,Ne),e(Ne,j),e(h,De),e(h,re),e(re,Pe),e(Pe,Ye),e(re,yl),e(re,Y),e(Y,yt),e(Y,st),e(st,ae),e(re,Ge),e(re,I),e(I,ql),e(I,ve),e(ve,gl),e(I,Al),e(I,R),e(I,Ol),e(I,W),e(W,Wl),e(h,El),e(h,ne),e(ne,Ve),e(Ve,dt),e(ne,Ul),e(ne,je),e(je,_l),e(ne,ie),e(ne,T),e(T,ml),e(T,Ot),e(Ot,Je),e(T,kl),e(T,Pt),e(T,y),e(T,Re),e(Re,Be),e(h,bl),e(h,K),e(K,ge),e(ge,Tl),e(K,Kl),e(K,Ue),e(Ue,Zt),e(K,kt),e(K,N),e(N,Bt),e(N,z),e(z,we),e(N,el),e(N,Ml),e(N,Qe),e(N,Xe),e(Xe,Yl),e(h,x),e(h,S),e(S,X),e(X,tl),e(S,Gl),e(S,Ze),e(Ze,gt),e(S,Ct),e(S,H),e(H,Vl),e(H,F),e(F,xe),e(H,jl),e(H,Jl),e(H,et),e(H,Ke),e(Ke,ll),e(h,D),e(h,q),e(q,$e),e($e,Ql),e(q,Xl),e(q,ye),e(ye,tt),e(q,Zl),e(q,_),e(_,xt),e(_,Rt),e(Rt,ct),e(_,eo),e(_,to),e(_,se),e(_,Z),e(Z,ol),e(_,lo),e(_,Ie),e(_,rl),e(_,O),e(O,Et),e(h,$t),e(h,U),e(U,he),e(he,Yt),e(U,oo),e(U,fe),e(fe,ro),e(U,Cl),e(U,b),e(b,ao),e(b,ht),e(ht,It),e(b,no),e(b,ee),e(b,me),e(b,ft),e(ft,zt),e(h,ze),e(h,de),e(de,lt),e(lt,Se),e(de,St),e(de,Ee),e(Ee,Gt),e(Ee,L),e(L,_t),e(_t,al),e(L,mt),e(L,$),e($,Rl),e($,w),e(w,k),e(k,Ft),e(w,qt),e(qt,$l),e(w,Fe),e(Fe,fo),e(w,G),e(G,At),e(w,nl),e(nl,Il),e(L,qe),e(L,Ht),e(Ht,zl),e(de,ot),e(de,v),e(v,il),e(v,Oe),e(v,uo),e(v,rt),e(rt,ut),e(v,po),e(v,ke),e(ke,Vt),e(v,Wt),e(v,io),e(v,sl),e(v,He),e(He,vo),e(v,jt),e(v,pt),e(v,go),e(v,bt),e(bt,at),e(h,Eo),e(h,P),e(P,be),e(be,Sl),e(P,_o),e(P,ue),e(ue,nt),e(ue,Jt),e(Jt,Ut),e(ue,it),e(P,Dl),e(P,Ae),e(Ae,Tt),e(Tt,Qt)},d(dl){dl&&o(u)}}}function Cn(ko){let u,g;return u=new Qr({props:{$$slots:{default:[kn]},$$scope:{ctx:ko}}}),{c(){ur(u.$$.fragment)},l(f){pr(u.$$.fragment,f)},m(f,p){vr(u,f,p),g=!0},p(f,p){const V={};p&2&&(V.$$scope={dirty:p,ctx:f}),u.$set(V)},i(f){g||(gr(u.$$.fragment,f),g=!0)},o(f){Er(u.$$.fragment,f),g=!1},d(f){_r(u,f)}}}function Rn(ko){let u,g,f,p,V,Kt,te,ul,Hl,J,Xt,Ll,h,E,A,pl,Mt,M,vl,le,Q,vt,B,Le,Nl,Pl,ce,Bl,xl,Te,Lt,oe,m,Fl,wt,We,Nt,wl,Ce,Ne,j,De,re,Pe,Ye,yl,Y,yt,st,ae,Ge,I,ql,ve,gl,Al,R,Ol,W,Wl,El,ne,Ve,dt,Ul,je,_l,ie,T,ml,Ot,Je,kl,Pt,y,Re,Be,bl,K,ge,Tl,Kl,Ue,Zt,kt,N,Bt,z,we,el,Ml,Qe,Xe,Yl,x,S,X,tl,Gl,Ze,gt,Ct,H,Vl,F,xe,jl,Jl,et,Ke,ll,D,q,$e,Ql,Xl,ye,tt,Zl,_,xt,Rt,ct,eo,to,se,Z,ol,lo,Ie,rl,O,Et,$t,U,he,Yt,oo,fe,ro,Cl,b,ao,ht,It,no,ee,me,ft,zt,ze,de,lt,Se,St,Ee,Gt,L,_t,al,mt,$,Rl,w,k,Ft,qt,$l,Fe,fo,G,At,nl,Il,qe,Ht,zl,ot,v,il,Oe,uo,rt,ut,po,ke,Vt,Wt,io,sl,He,vo,jt,pt,go,bt,at,Eo,P,be,Sl,_o,ue,nt,Jt,Ut,it,Dl,Ae,Tt,Qt;return{c(){u=t("table"),g=t("thead"),f=t("tr"),p=t("th"),V=a("Name"),Kt=i(),te=t("th"),ul=a("Description"),Hl=i(),J=t("th"),Xt=a("Example"),Ll=i(),h=t("tbody"),E=t("tr"),A=t("td"),pl=a("ByteLevel"),Mt=i(),M=t("td"),vl=a("Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),le=t("ul"),Q=t("li"),vt=a("Since it maps on bytes, a tokenizer using this only requires "),B=t("strong"),Le=a("256"),Nl=a(" characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),Pl=i(),ce=t("li"),Bl=a("A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),xl=i(),Te=t("li"),Lt=a("For non ascii characters, it gets completely unreadable, but it works nonetheless!"),oe=i(),m=t("td"),Fl=a("Input: "),wt=t("code"),We=a('"Hello my friend, how are you?"'),Nt=i(),wl=t("br"),Ce=a(" Ouput: "),Ne=t("code"),j=a('"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),De=i(),re=t("tr"),Pe=t("td"),Ye=a("Whitespace"),yl=i(),Y=t("td"),yt=a("Splits on word boundaries (using the following regular expression: "),st=t("code"),ae=a("\\w+|[^\\w\\s]+"),Ge=i(),I=t("td"),ql=a("Input: "),ve=t("code"),gl=a('"Hello there!"'),Al=i(),R=t("br"),Ol=a(" Output: "),W=t("code"),Wl=a('"Hello", "there", "!"'),El=i(),ne=t("tr"),Ve=t("td"),dt=a("WhitespaceSplit"),Ul=i(),je=t("td"),_l=a("Splits on any whitespace character"),ie=i(),T=t("td"),ml=a("Input: "),Ot=t("code"),Je=a('"Hello there!"'),kl=i(),Pt=t("br"),y=a(" Output: "),Re=t("code"),Be=a('"Hello", "there!"'),bl=i(),K=t("tr"),ge=t("td"),Tl=a("Punctuation"),Kl=i(),Ue=t("td"),Zt=a("Will isolate all punctuation characters"),kt=i(),N=t("td"),Bt=a("Input: "),z=t("code"),we=a('"Hello?"'),el=i(),Ml=t("br"),Qe=a(" Ouput: "),Xe=t("code"),Yl=a('"Hello", "?"'),x=i(),S=t("tr"),X=t("td"),tl=a("Metaspace"),Gl=i(),Ze=t("td"),gt=a("Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),Ct=i(),H=t("td"),Vl=a("Input: "),F=t("code"),xe=a('"Hello there"'),jl=i(),Jl=t("br"),et=a(" Ouput: "),Ke=t("code"),ll=a('"Hello", "\u2581there"'),D=i(),q=t("tr"),$e=t("td"),Ql=a("CharDelimiterSplit"),Xl=i(),ye=t("td"),tt=a("Splits on a given character"),Zl=i(),_=t("td"),xt=a("Example with "),Rt=t("code"),ct=a("x"),eo=a(": "),to=t("br"),se=a(" Input: "),Z=t("code"),ol=a('"Helloxthere"'),lo=i(),Ie=t("br"),rl=a(" Ouput: "),O=t("code"),Et=a('"Hello", "there"'),$t=i(),U=t("tr"),he=t("td"),Yt=a("Digits"),oo=i(),fe=t("td"),ro=a("Splits the numbers from any other characters."),Cl=i(),b=t("td"),ao=a("Input: "),ht=t("code"),It=a('"Hello123there"'),no=i(),ee=t("br"),me=a("  Output: "),ft=t("code"),zt=a('"Hello", "123", "there"'),ze=i(),de=t("tr"),lt=t("td"),Se=a("Split"),St=i(),Ee=t("td"),Gt=a("Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),L=t("ul"),_t=t("li"),al=a("pattern should be either a custom string or regexp."),mt=i(),$=t("li"),Rl=a("behavior should be one of: "),w=t("ul"),k=t("li"),Ft=a("Removed"),qt=t("li"),$l=a("Isolated"),Fe=t("li"),fo=a("MergedWithPrevious"),G=t("li"),At=a("MergedWithNext"),nl=t("li"),Il=a("Contiguous"),qe=i(),Ht=t("li"),zl=a("invert should be a boolean flag."),ot=i(),v=t("td"),il=a("Example with pattern = "),Oe=t("code"),uo=a(", behavior = "),rt=t("code"),ut=a('"isolated"'),po=a(", invert = "),ke=t("code"),Vt=a("False"),Wt=a(": "),io=t("br"),sl=a(" Input: "),He=t("code"),vo=a('"Hello, how are you?"'),jt=i(),pt=t("br"),go=a(" Output: "),bt=t("code"),at=a('"Hello,", " ", "how", " ", "are", " ", "you?"'),Eo=i(),P=t("tr"),be=t("td"),Sl=a("Sequence"),_o=i(),ue=t("td"),nt=a("Lets you compose multiple "),Jt=t("code"),Ut=a("PreTokenizer"),it=a(" that will be run in the given order"),Dl=i(),Ae=t("td"),Tt=t("code"),Qt=a("Sequence::new(vec![Punctuation, WhitespaceSplit])"),this.h()},l(dl){u=l(dl,"TABLE",{});var cl=r(u);g=l(cl,"THEAD",{});var Wo=r(g);f=l(Wo,"TR",{});var Dt=r(f);p=l(Dt,"TH",{align:!0});var or=r(p);V=n(or,"Name"),or.forEach(o),Kt=s(Dt),te=l(Dt,"TH",{align:!0});var hl=r(te);ul=n(hl,"Description"),hl.forEach(o),Hl=s(Dt),J=l(Dt,"TH",{align:!0});var Vo=r(J);Xt=n(Vo,"Example"),Vo.forEach(o),Dt.forEach(o),Wo.forEach(o),Ll=s(cl),h=l(cl,"TBODY",{});var pe=r(h);E=l(pe,"TR",{});var wo=r(E);A=l(wo,"TD",{align:!0});var jo=r(A);pl=n(jo,"ByteLevel"),jo.forEach(o),Mt=s(wo),M=l(wo,"TD",{align:!0});var Jo=r(M);vl=n(Jo,"Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),le=l(Jo,"UL",{});var Io=r(le);Q=l(Io,"LI",{});var zo=r(Q);vt=n(zo,"Since it maps on bytes, a tokenizer using this only requires "),B=l(zo,"STRONG",{});var hr=r(B);Le=n(hr,"256"),hr.forEach(o),Nl=n(zo," characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),zo.forEach(o),Pl=s(Io),ce=l(Io,"LI",{});var So=r(ce);Bl=n(So,"A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),So.forEach(o),xl=s(Io),Te=l(Io,"LI",{});var rr=r(Te);Lt=n(rr,"For non ascii characters, it gets completely unreadable, but it works nonetheless!"),rr.forEach(o),Io.forEach(o),Jo.forEach(o),oe=s(wo),m=l(wo,"TD",{align:!0});var Co=r(m);Fl=n(Co,"Input: "),wt=l(Co,"CODE",{});var Qo=r(wt);We=n(Qo,'"Hello my friend, how are you?"'),Qo.forEach(o),Nt=s(Co),wl=l(Co,"BR",{}),Ce=n(Co," Ouput: "),Ne=l(Co,"CODE",{});var ar=r(Ne);j=n(ar,'"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),ar.forEach(o),Co.forEach(o),wo.forEach(o),De=s(pe),re=l(pe,"TR",{});var Ho=r(re);Pe=l(Ho,"TD",{align:!0});var Or=r(Pe);Ye=n(Or,"Whitespace"),Or.forEach(o),yl=s(Ho),Y=l(Ho,"TD",{align:!0});var co=r(Y);yt=n(co,"Splits on word boundaries (using the following regular expression: "),st=l(co,"CODE",{});var Xo=r(st);ae=n(Xo,"\\w+|[^\\w\\s]+"),Xo.forEach(o),co.forEach(o),Ge=s(Ho),I=l(Ho,"TD",{align:!0});var ho=r(I);ql=n(ho,"Input: "),ve=l(ho,"CODE",{});var Zo=r(ve);gl=n(Zo,'"Hello there!"'),Zo.forEach(o),Al=s(ho),R=l(ho,"BR",{}),Ol=n(ho," Output: "),W=l(ho,"CODE",{});var kr=r(W);Wl=n(kr,'"Hello", "there", "!"'),kr.forEach(o),ho.forEach(o),Ho.forEach(o),El=s(pe),ne=l(pe,"TR",{});var yo=r(ne);Ve=l(yo,"TD",{align:!0});var Yo=r(Ve);dt=n(Yo,"WhitespaceSplit"),Yo.forEach(o),Ul=s(yo),je=l(yo,"TD",{align:!0});var Cr=r(je);_l=n(Cr,"Splits on any whitespace character"),Cr.forEach(o),ie=s(yo),T=l(yo,"TD",{align:!0});var so=r(T);ml=n(so,"Input: "),Ot=l(so,"CODE",{});var Uo=r(Ot);Je=n(Uo,'"Hello there!"'),Uo.forEach(o),kl=s(so),Pt=l(so,"BR",{}),y=n(so," Output: "),Re=l(so,"CODE",{});var Rr=r(Re);Be=n(Rr,'"Hello", "there!"'),Rr.forEach(o),so.forEach(o),yo.forEach(o),bl=s(pe),K=l(pe,"TR",{});var xo=r(K);ge=l(xo,"TD",{align:!0});var Ro=r(ge);Tl=n(Ro,"Punctuation"),Ro.forEach(o),Kl=s(xo),Ue=l(xo,"TD",{align:!0});var $r=r(Ue);Zt=n($r,"Will isolate all punctuation characters"),$r.forEach(o),kt=s(xo),N=l(xo,"TD",{align:!0});var mo=r(N);Bt=n(mo,"Input: "),z=l(mo,"CODE",{});var er=r(z);we=n(er,'"Hello?"'),er.forEach(o),el=s(mo),Ml=l(mo,"BR",{}),Qe=n(mo," Ouput: "),Xe=l(mo,"CODE",{});var Ir=r(Xe);Yl=n(Ir,'"Hello", "?"'),Ir.forEach(o),mo.forEach(o),xo.forEach(o),x=s(pe),S=l(pe,"TR",{});var Fo=r(S);X=l(Fo,"TD",{align:!0});var Lo=r(X);tl=n(Lo,"Metaspace"),Lo.forEach(o),Gl=s(Fo),Ze=l(Fo,"TD",{align:!0});var nr=r(Ze);gt=n(nr,"Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),nr.forEach(o),Ct=s(Fo),H=l(Fo,"TD",{align:!0});var $o=r(H);Vl=n($o,"Input: "),F=l($o,"CODE",{});var tr=r(F);xe=n(tr,'"Hello there"'),tr.forEach(o),jl=s($o),Jl=l($o,"BR",{}),et=n($o," Ouput: "),Ke=l($o,"CODE",{});var Go=r(Ke);ll=n(Go,'"Hello", "\u2581there"'),Go.forEach(o),$o.forEach(o),Fo.forEach(o),D=s(pe),q=l(pe,"TR",{});var qo=r(q);$e=l(qo,"TD",{align:!0});var Oo=r($e);Ql=n(Oo,"CharDelimiterSplit"),Oo.forEach(o),Xl=s(qo),ye=l(qo,"TD",{align:!0});var zr=r(ye);tt=n(zr,"Splits on a given character"),zr.forEach(o),Zl=s(qo),_=l(qo,"TD",{align:!0});var fl=r(_);xt=n(fl,"Example with "),Rt=l(fl,"CODE",{});var mr=r(Rt);ct=n(mr,"x"),mr.forEach(o),eo=n(fl,": "),to=l(fl,"BR",{}),se=n(fl," Input: "),Z=l(fl,"CODE",{});var c=r(Z);ol=n(c,'"Helloxthere"'),c.forEach(o),lo=s(fl),Ie=l(fl,"BR",{}),rl=n(fl," Ouput: "),O=l(fl,"CODE",{});var C=r(O);Et=n(C,'"Hello", "there"'),C.forEach(o),fl.forEach(o),qo.forEach(o),$t=s(pe),U=l(pe,"TR",{});var bo=r(U);he=l(bo,"TD",{align:!0});var Ko=r(he);Yt=n(Ko,"Digits"),Ko.forEach(o),oo=s(bo),fe=l(bo,"TD",{align:!0});var Sr=r(fe);ro=n(Sr,"Splits the numbers from any other characters."),Sr.forEach(o),Cl=s(bo),b=l(bo,"TD",{align:!0});var No=r(b);ao=n(No,"Input: "),ht=l(No,"CODE",{});var ir=r(ht);It=n(ir,'"Hello123there"'),ir.forEach(o),no=s(No),ee=l(No,"BR",{}),me=n(No,"  Output: "),ft=l(No,"CODE",{});var br=r(ft);zt=n(br,'"Hello", "123", "there"'),br.forEach(o),No.forEach(o),bo.forEach(o),ze=s(pe),de=l(pe,"TR",{});var Ao=r(de);lt=l(Ao,"TD",{align:!0});var sr=r(lt);Se=n(sr,"Split"),sr.forEach(o),St=s(Ao),Ee=l(Ao,"TD",{align:!0});var Tr=r(Ee);Gt=n(Tr,"Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),L=l(Tr,"UL",{});var To=r(L);_t=l(To,"LI",{});var dr=r(_t);al=n(dr,"pattern should be either a custom string or regexp."),dr.forEach(o),mt=s(To),$=l(To,"LI",{});var Dr=r($);Rl=n(Dr,"behavior should be one of: "),w=l(Dr,"UL",{});var Po=r(w);k=l(Po,"LI",{});var Hr=r(k);Ft=n(Hr,"Removed"),Hr.forEach(o),qt=l(Po,"LI",{});var wr=r(qt);$l=n(wr,"Isolated"),wr.forEach(o),Fe=l(Po,"LI",{});var Lr=r(Fe);fo=n(Lr,"MergedWithPrevious"),Lr.forEach(o),G=l(Po,"LI",{});var Nr=r(G);At=n(Nr,"MergedWithNext"),Nr.forEach(o),nl=l(Po,"LI",{});var Do=r(nl);Il=n(Do,"Contiguous"),Do.forEach(o),Po.forEach(o),Dr.forEach(o),qe=s(To),Ht=l(To,"LI",{});var lr=r(Ht);zl=n(lr,"invert should be a boolean flag."),lr.forEach(o),To.forEach(o),Tr.forEach(o),ot=s(Ao),v=l(Ao,"TD",{align:!0});var Me=r(v);il=n(Me,"Example with pattern = "),Oe=l(Me,"CODE",{});var Fr=r(Oe);Fr.forEach(o),uo=n(Me,", behavior = "),rt=l(Me,"CODE",{});var Pr=r(rt);ut=n(Pr,'"isolated"'),Pr.forEach(o),po=n(Me,", invert = "),ke=l(Me,"CODE",{});var Mo=r(ke);Vt=n(Mo,"False"),Mo.forEach(o),Wt=n(Me,": "),io=l(Me,"BR",{}),sl=n(Me," Input: "),He=l(Me,"CODE",{});var cr=r(He);vo=n(cr,'"Hello, how are you?"'),cr.forEach(o),jt=s(Me),pt=l(Me,"BR",{}),go=n(Me," Output: "),bt=l(Me,"CODE",{});var Br=r(bt);at=n(Br,'"Hello,", " ", "how", " ", "are", " ", "you?"'),Br.forEach(o),Me.forEach(o),Ao.forEach(o),Eo=s(pe),P=l(pe,"TR",{});var Bo=r(P);be=l(Bo,"TD",{align:!0});var xr=r(be);Sl=n(xr,"Sequence"),xr.forEach(o),_o=s(Bo),ue=l(Bo,"TD",{align:!0});var fr=r(ue);nt=n(fr,"Lets you compose multiple "),Jt=l(fr,"CODE",{});var qr=r(Jt);Ut=n(qr,"PreTokenizer"),qr.forEach(o),it=n(fr," that will be run in the given order"),fr.forEach(o),Dl=s(Bo),Ae=l(Bo,"TD",{align:!0});var Ar=r(Ae);Tt=l(Ar,"CODE",{});var Wr=r(Tt);Qt=n(Wr,"Sequence::new(vec![Punctuation, WhitespaceSplit])"),Wr.forEach(o),Ar.forEach(o),Bo.forEach(o),pe.forEach(o),cl.forEach(o),this.h()},h(){d(p,"align","left"),d(te,"align","left"),d(J,"align","left"),d(A,"align","left"),d(M,"align","left"),d(m,"align","left"),d(Pe,"align","left"),d(Y,"align","left"),d(I,"align","left"),d(Ve,"align","left"),d(je,"align","left"),d(T,"align","left"),d(ge,"align","left"),d(Ue,"align","left"),d(N,"align","left"),d(X,"align","left"),d(Ze,"align","left"),d(H,"align","left"),d($e,"align","left"),d(ye,"align","left"),d(_,"align","left"),d(he,"align","left"),d(fe,"align","left"),d(b,"align","left"),d(lt,"align","left"),d(Ee,"align","left"),d(v,"align","left"),d(be,"align","left"),d(ue,"align","left"),d(Ae,"align","left")},m(dl,cl){_e(dl,u,cl),e(u,g),e(g,f),e(f,p),e(p,V),e(f,Kt),e(f,te),e(te,ul),e(f,Hl),e(f,J),e(J,Xt),e(u,Ll),e(u,h),e(h,E),e(E,A),e(A,pl),e(E,Mt),e(E,M),e(M,vl),e(M,le),e(le,Q),e(Q,vt),e(Q,B),e(B,Le),e(Q,Nl),e(le,Pl),e(le,ce),e(ce,Bl),e(le,xl),e(le,Te),e(Te,Lt),e(E,oe),e(E,m),e(m,Fl),e(m,wt),e(wt,We),e(m,Nt),e(m,wl),e(m,Ce),e(m,Ne),e(Ne,j),e(h,De),e(h,re),e(re,Pe),e(Pe,Ye),e(re,yl),e(re,Y),e(Y,yt),e(Y,st),e(st,ae),e(re,Ge),e(re,I),e(I,ql),e(I,ve),e(ve,gl),e(I,Al),e(I,R),e(I,Ol),e(I,W),e(W,Wl),e(h,El),e(h,ne),e(ne,Ve),e(Ve,dt),e(ne,Ul),e(ne,je),e(je,_l),e(ne,ie),e(ne,T),e(T,ml),e(T,Ot),e(Ot,Je),e(T,kl),e(T,Pt),e(T,y),e(T,Re),e(Re,Be),e(h,bl),e(h,K),e(K,ge),e(ge,Tl),e(K,Kl),e(K,Ue),e(Ue,Zt),e(K,kt),e(K,N),e(N,Bt),e(N,z),e(z,we),e(N,el),e(N,Ml),e(N,Qe),e(N,Xe),e(Xe,Yl),e(h,x),e(h,S),e(S,X),e(X,tl),e(S,Gl),e(S,Ze),e(Ze,gt),e(S,Ct),e(S,H),e(H,Vl),e(H,F),e(F,xe),e(H,jl),e(H,Jl),e(H,et),e(H,Ke),e(Ke,ll),e(h,D),e(h,q),e(q,$e),e($e,Ql),e(q,Xl),e(q,ye),e(ye,tt),e(q,Zl),e(q,_),e(_,xt),e(_,Rt),e(Rt,ct),e(_,eo),e(_,to),e(_,se),e(_,Z),e(Z,ol),e(_,lo),e(_,Ie),e(_,rl),e(_,O),e(O,Et),e(h,$t),e(h,U),e(U,he),e(he,Yt),e(U,oo),e(U,fe),e(fe,ro),e(U,Cl),e(U,b),e(b,ao),e(b,ht),e(ht,It),e(b,no),e(b,ee),e(b,me),e(b,ft),e(ft,zt),e(h,ze),e(h,de),e(de,lt),e(lt,Se),e(de,St),e(de,Ee),e(Ee,Gt),e(Ee,L),e(L,_t),e(_t,al),e(L,mt),e(L,$),e($,Rl),e($,w),e(w,k),e(k,Ft),e(w,qt),e(qt,$l),e(w,Fe),e(Fe,fo),e(w,G),e(G,At),e(w,nl),e(nl,Il),e(L,qe),e(L,Ht),e(Ht,zl),e(de,ot),e(de,v),e(v,il),e(v,Oe),e(v,uo),e(v,rt),e(rt,ut),e(v,po),e(v,ke),e(ke,Vt),e(v,Wt),e(v,io),e(v,sl),e(v,He),e(He,vo),e(v,jt),e(v,pt),e(v,go),e(v,bt),e(bt,at),e(h,Eo),e(h,P),e(P,be),e(be,Sl),e(P,_o),e(P,ue),e(ue,nt),e(ue,Jt),e(Jt,Ut),e(ue,it),e(P,Dl),e(P,Ae),e(Ae,Tt),e(Tt,Qt)},d(dl){dl&&o(u)}}}function $n(ko){let u,g;return u=new Qr({props:{$$slots:{default:[Rn]},$$scope:{ctx:ko}}}),{c(){ur(u.$$.fragment)},l(f){pr(u.$$.fragment,f)},m(f,p){vr(u,f,p),g=!0},p(f,p){const V={};p&2&&(V.$$scope={dirty:p,ctx:f}),u.$set(V)},i(f){g||(gr(u.$$.fragment,f),g=!0)},o(f){Er(u.$$.fragment,f),g=!1},d(f){_r(u,f)}}}function In(ko){let u,g,f,p,V,Kt,te,ul,Hl,J,Xt,Ll,h,E,A,pl,Mt,M,vl,le,Q,vt,B,Le,Nl,Pl,ce,Bl,xl,Te,Lt,oe,m,Fl,wt,We,Nt,wl,Ce,Ne,j,De,re,Pe,Ye,yl,Y,yt,st,ae,Ge,I,ql,ve,gl,Al,R,Ol,W,Wl,El,ne,Ve,dt,Ul,je,_l,ie,T,ml,Ot,Je,kl,Pt,y,Re,Be,bl,K,ge,Tl,Kl,Ue,Zt,kt,N,Bt,z,we,el,Ml,Qe,Xe,Yl,x,S,X,tl,Gl,Ze,gt,Ct,H,Vl,F,xe,jl,Jl,et,Ke,ll,D,q,$e,Ql,Xl,ye,tt,Zl,_,xt,Rt,ct,eo,to,se,Z,ol,lo,Ie,rl,O,Et,$t,U,he,Yt,oo,fe,ro,Cl,b,ao,ht,It,no,ee,me,ft,zt,ze,de,lt,Se,St,Ee,Gt,L,_t,al,mt,$,Rl,w,k,Ft,qt,$l,Fe,fo,G,At,nl,Il,qe,Ht,zl,ot,v,il,Oe,uo,rt,ut,po,ke,Vt,Wt,io,sl,He,vo,jt,pt,go,bt,at,Eo,P,be,Sl,_o,ue,nt,Jt,Ut,it,Dl,Ae;return{c(){u=t("table"),g=t("thead"),f=t("tr"),p=t("th"),V=a("Name"),Kt=i(),te=t("th"),ul=a("Description"),Hl=i(),J=t("th"),Xt=a("Example"),Ll=i(),h=t("tbody"),E=t("tr"),A=t("td"),pl=a("ByteLevel"),Mt=i(),M=t("td"),vl=a("Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),le=t("ul"),Q=t("li"),vt=a("Since it maps on bytes, a tokenizer using this only requires "),B=t("strong"),Le=a("256"),Nl=a(" characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),Pl=i(),ce=t("li"),Bl=a("A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),xl=i(),Te=t("li"),Lt=a("For non ascii characters, it gets completely unreadable, but it works nonetheless!"),oe=i(),m=t("td"),Fl=a("Input: "),wt=t("code"),We=a('"Hello my friend, how are you?"'),Nt=i(),wl=t("br"),Ce=a(" Ouput: "),Ne=t("code"),j=a('"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),De=i(),re=t("tr"),Pe=t("td"),Ye=a("Whitespace"),yl=i(),Y=t("td"),yt=a("Splits on word boundaries (using the following regular expression: "),st=t("code"),ae=a("\\w+|[^\\w\\s]+"),Ge=i(),I=t("td"),ql=a("Input: "),ve=t("code"),gl=a('"Hello there!"'),Al=i(),R=t("br"),Ol=a(" Output: "),W=t("code"),Wl=a('"Hello", "there", "!"'),El=i(),ne=t("tr"),Ve=t("td"),dt=a("WhitespaceSplit"),Ul=i(),je=t("td"),_l=a("Splits on any whitespace character"),ie=i(),T=t("td"),ml=a("Input: "),Ot=t("code"),Je=a('"Hello there!"'),kl=i(),Pt=t("br"),y=a(" Output: "),Re=t("code"),Be=a('"Hello", "there!"'),bl=i(),K=t("tr"),ge=t("td"),Tl=a("Punctuation"),Kl=i(),Ue=t("td"),Zt=a("Will isolate all punctuation characters"),kt=i(),N=t("td"),Bt=a("Input: "),z=t("code"),we=a('"Hello?"'),el=i(),Ml=t("br"),Qe=a(" Ouput: "),Xe=t("code"),Yl=a('"Hello", "?"'),x=i(),S=t("tr"),X=t("td"),tl=a("Metaspace"),Gl=i(),Ze=t("td"),gt=a("Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),Ct=i(),H=t("td"),Vl=a("Input: "),F=t("code"),xe=a('"Hello there"'),jl=i(),Jl=t("br"),et=a(" Ouput: "),Ke=t("code"),ll=a('"Hello", "\u2581there"'),D=i(),q=t("tr"),$e=t("td"),Ql=a("CharDelimiterSplit"),Xl=i(),ye=t("td"),tt=a("Splits on a given character"),Zl=i(),_=t("td"),xt=a("Example with "),Rt=t("code"),ct=a("x"),eo=a(": "),to=t("br"),se=a(" Input: "),Z=t("code"),ol=a('"Helloxthere"'),lo=i(),Ie=t("br"),rl=a(" Ouput: "),O=t("code"),Et=a('"Hello", "there"'),$t=i(),U=t("tr"),he=t("td"),Yt=a("Digits"),oo=i(),fe=t("td"),ro=a("Splits the numbers from any other characters."),Cl=i(),b=t("td"),ao=a("Input: "),ht=t("code"),It=a('"Hello123there"'),no=i(),ee=t("br"),me=a("  Output: "),ft=t("code"),zt=a('"Hello", "123", "there"'),ze=i(),de=t("tr"),lt=t("td"),Se=a("Split"),St=i(),Ee=t("td"),Gt=a("Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),L=t("ul"),_t=t("li"),al=a("pattern should be either a custom string or regexp."),mt=i(),$=t("li"),Rl=a("behavior should be one of: "),w=t("ul"),k=t("li"),Ft=a("removed"),qt=t("li"),$l=a("isolated"),Fe=t("li"),fo=a("mergedWithPrevious"),G=t("li"),At=a("mergedWithNext"),nl=t("li"),Il=a("contiguous"),qe=i(),Ht=t("li"),zl=a("invert should be a boolean flag."),ot=i(),v=t("td"),il=a("Example with pattern = "),Oe=t("code"),uo=a(", behavior = "),rt=t("code"),ut=a('"isolated"'),po=a(", invert = "),ke=t("code"),Vt=a("False"),Wt=a(": "),io=t("br"),sl=a(" Input: "),He=t("code"),vo=a('"Hello, how are you?"'),jt=i(),pt=t("br"),go=a(" Output: "),bt=t("code"),at=a('"Hello,", " ", "how", " ", "are", " ", "you?"'),Eo=i(),P=t("tr"),be=t("td"),Sl=a("Sequence"),_o=i(),ue=t("td"),nt=a("Lets you compose multiple "),Jt=t("code"),Ut=a("PreTokenizer"),it=a(" that will be run in the given order"),Dl=i(),Ae=t("td"),this.h()},l(Tt){u=l(Tt,"TABLE",{});var Qt=r(u);g=l(Qt,"THEAD",{});var dl=r(g);f=l(dl,"TR",{});var cl=r(f);p=l(cl,"TH",{align:!0});var Wo=r(p);V=n(Wo,"Name"),Wo.forEach(o),Kt=s(cl),te=l(cl,"TH",{align:!0});var Dt=r(te);ul=n(Dt,"Description"),Dt.forEach(o),Hl=s(cl),J=l(cl,"TH",{align:!0});var or=r(J);Xt=n(or,"Example"),or.forEach(o),cl.forEach(o),dl.forEach(o),Ll=s(Qt),h=l(Qt,"TBODY",{});var hl=r(h);E=l(hl,"TR",{});var Vo=r(E);A=l(Vo,"TD",{align:!0});var pe=r(A);pl=n(pe,"ByteLevel"),pe.forEach(o),Mt=s(Vo),M=l(Vo,"TD",{align:!0});var wo=r(M);vl=n(wo,"Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties: "),le=l(wo,"UL",{});var jo=r(le);Q=l(jo,"LI",{});var Jo=r(Q);vt=n(Jo,"Since it maps on bytes, a tokenizer using this only requires "),B=l(Jo,"STRONG",{});var Io=r(B);Le=n(Io,"256"),Io.forEach(o),Nl=n(Jo," characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters."),Jo.forEach(o),Pl=s(jo),ce=l(jo,"LI",{});var zo=r(ce);Bl=n(zo,"A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! \u{1F389}\u{1F389})"),zo.forEach(o),xl=s(jo),Te=l(jo,"LI",{});var hr=r(Te);Lt=n(hr,"For non ascii characters, it gets completely unreadable, but it works nonetheless!"),hr.forEach(o),jo.forEach(o),wo.forEach(o),oe=s(Vo),m=l(Vo,"TD",{align:!0});var So=r(m);Fl=n(So,"Input: "),wt=l(So,"CODE",{});var rr=r(wt);We=n(rr,'"Hello my friend, how are you?"'),rr.forEach(o),Nt=s(So),wl=l(So,"BR",{}),Ce=n(So," Ouput: "),Ne=l(So,"CODE",{});var Co=r(Ne);j=n(Co,'"Hello", "\u0120my", \u0120friend", ",", "\u0120how", "\u0120are", "\u0120you", "?"'),Co.forEach(o),So.forEach(o),Vo.forEach(o),De=s(hl),re=l(hl,"TR",{});var Qo=r(re);Pe=l(Qo,"TD",{align:!0});var ar=r(Pe);Ye=n(ar,"Whitespace"),ar.forEach(o),yl=s(Qo),Y=l(Qo,"TD",{align:!0});var Ho=r(Y);yt=n(Ho,"Splits on word boundaries (using the following regular expression: "),st=l(Ho,"CODE",{});var Or=r(st);ae=n(Or,"\\w+|[^\\w\\s]+"),Or.forEach(o),Ho.forEach(o),Ge=s(Qo),I=l(Qo,"TD",{align:!0});var co=r(I);ql=n(co,"Input: "),ve=l(co,"CODE",{});var Xo=r(ve);gl=n(Xo,'"Hello there!"'),Xo.forEach(o),Al=s(co),R=l(co,"BR",{}),Ol=n(co," Output: "),W=l(co,"CODE",{});var ho=r(W);Wl=n(ho,'"Hello", "there", "!"'),ho.forEach(o),co.forEach(o),Qo.forEach(o),El=s(hl),ne=l(hl,"TR",{});var Zo=r(ne);Ve=l(Zo,"TD",{align:!0});var kr=r(Ve);dt=n(kr,"WhitespaceSplit"),kr.forEach(o),Ul=s(Zo),je=l(Zo,"TD",{align:!0});var yo=r(je);_l=n(yo,"Splits on any whitespace character"),yo.forEach(o),ie=s(Zo),T=l(Zo,"TD",{align:!0});var Yo=r(T);ml=n(Yo,"Input: "),Ot=l(Yo,"CODE",{});var Cr=r(Ot);Je=n(Cr,'"Hello there!"'),Cr.forEach(o),kl=s(Yo),Pt=l(Yo,"BR",{}),y=n(Yo," Output: "),Re=l(Yo,"CODE",{});var so=r(Re);Be=n(so,'"Hello", "there!"'),so.forEach(o),Yo.forEach(o),Zo.forEach(o),bl=s(hl),K=l(hl,"TR",{});var Uo=r(K);ge=l(Uo,"TD",{align:!0});var Rr=r(ge);Tl=n(Rr,"Punctuation"),Rr.forEach(o),Kl=s(Uo),Ue=l(Uo,"TD",{align:!0});var xo=r(Ue);Zt=n(xo,"Will isolate all punctuation characters"),xo.forEach(o),kt=s(Uo),N=l(Uo,"TD",{align:!0});var Ro=r(N);Bt=n(Ro,"Input: "),z=l(Ro,"CODE",{});var $r=r(z);we=n($r,'"Hello?"'),$r.forEach(o),el=s(Ro),Ml=l(Ro,"BR",{}),Qe=n(Ro," Ouput: "),Xe=l(Ro,"CODE",{});var mo=r(Xe);Yl=n(mo,'"Hello", "?"'),mo.forEach(o),Ro.forEach(o),Uo.forEach(o),x=s(hl),S=l(hl,"TR",{});var er=r(S);X=l(er,"TD",{align:!0});var Ir=r(X);tl=n(Ir,"Metaspace"),Ir.forEach(o),Gl=s(er),Ze=l(er,"TD",{align:!0});var Fo=r(Ze);gt=n(Fo,"Splits on whitespaces and replaces them with a special char \u201C\u2581\u201D (U+2581)"),Fo.forEach(o),Ct=s(er),H=l(er,"TD",{align:!0});var Lo=r(H);Vl=n(Lo,"Input: "),F=l(Lo,"CODE",{});var nr=r(F);xe=n(nr,'"Hello there"'),nr.forEach(o),jl=s(Lo),Jl=l(Lo,"BR",{}),et=n(Lo," Ouput: "),Ke=l(Lo,"CODE",{});var $o=r(Ke);ll=n($o,'"Hello", "\u2581there"'),$o.forEach(o),Lo.forEach(o),er.forEach(o),D=s(hl),q=l(hl,"TR",{});var tr=r(q);$e=l(tr,"TD",{align:!0});var Go=r($e);Ql=n(Go,"CharDelimiterSplit"),Go.forEach(o),Xl=s(tr),ye=l(tr,"TD",{align:!0});var qo=r(ye);tt=n(qo,"Splits on a given character"),qo.forEach(o),Zl=s(tr),_=l(tr,"TD",{align:!0});var Oo=r(_);xt=n(Oo,"Example with "),Rt=l(Oo,"CODE",{});var zr=r(Rt);ct=n(zr,"x"),zr.forEach(o),eo=n(Oo,": "),to=l(Oo,"BR",{}),se=n(Oo," Input: "),Z=l(Oo,"CODE",{});var fl=r(Z);ol=n(fl,'"Helloxthere"'),fl.forEach(o),lo=s(Oo),Ie=l(Oo,"BR",{}),rl=n(Oo," Ouput: "),O=l(Oo,"CODE",{});var mr=r(O);Et=n(mr,'"Hello", "there"'),mr.forEach(o),Oo.forEach(o),tr.forEach(o),$t=s(hl),U=l(hl,"TR",{});var c=r(U);he=l(c,"TD",{align:!0});var C=r(he);Yt=n(C,"Digits"),C.forEach(o),oo=s(c),fe=l(c,"TD",{align:!0});var bo=r(fe);ro=n(bo,"Splits the numbers from any other characters."),bo.forEach(o),Cl=s(c),b=l(c,"TD",{align:!0});var Ko=r(b);ao=n(Ko,"Input: "),ht=l(Ko,"CODE",{});var Sr=r(ht);It=n(Sr,'"Hello123there"'),Sr.forEach(o),no=s(Ko),ee=l(Ko,"BR",{}),me=n(Ko,"  Output: "),ft=l(Ko,"CODE",{});var No=r(ft);zt=n(No,'"Hello", "123", "there"'),No.forEach(o),Ko.forEach(o),c.forEach(o),ze=s(hl),de=l(hl,"TR",{});var ir=r(de);lt=l(ir,"TD",{align:!0});var br=r(lt);Se=n(br,"Split"),br.forEach(o),St=s(ir),Ee=l(ir,"TD",{align:!0});var Ao=r(Ee);Gt=n(Ao,"Versatile pre-tokenizer that splits on provided pattern and according to provided behavior. The pattern can be inverted if necessary. "),L=l(Ao,"UL",{});var sr=r(L);_t=l(sr,"LI",{});var Tr=r(_t);al=n(Tr,"pattern should be either a custom string or regexp."),Tr.forEach(o),mt=s(sr),$=l(sr,"LI",{});var To=r($);Rl=n(To,"behavior should be one of: "),w=l(To,"UL",{});var dr=r(w);k=l(dr,"LI",{});var Dr=r(k);Ft=n(Dr,"removed"),Dr.forEach(o),qt=l(dr,"LI",{});var Po=r(qt);$l=n(Po,"isolated"),Po.forEach(o),Fe=l(dr,"LI",{});var Hr=r(Fe);fo=n(Hr,"mergedWithPrevious"),Hr.forEach(o),G=l(dr,"LI",{});var wr=r(G);At=n(wr,"mergedWithNext"),wr.forEach(o),nl=l(dr,"LI",{});var Lr=r(nl);Il=n(Lr,"contiguous"),Lr.forEach(o),dr.forEach(o),To.forEach(o),qe=s(sr),Ht=l(sr,"LI",{});var Nr=r(Ht);zl=n(Nr,"invert should be a boolean flag."),Nr.forEach(o),sr.forEach(o),Ao.forEach(o),ot=s(ir),v=l(ir,"TD",{align:!0});var Do=r(v);il=n(Do,"Example with pattern = "),Oe=l(Do,"CODE",{});var lr=r(Oe);lr.forEach(o),uo=n(Do,", behavior = "),rt=l(Do,"CODE",{});var Me=r(rt);ut=n(Me,'"isolated"'),Me.forEach(o),po=n(Do,", invert = "),ke=l(Do,"CODE",{});var Fr=r(ke);Vt=n(Fr,"False"),Fr.forEach(o),Wt=n(Do,": "),io=l(Do,"BR",{}),sl=n(Do," Input: "),He=l(Do,"CODE",{});var Pr=r(He);vo=n(Pr,'"Hello, how are you?"'),Pr.forEach(o),jt=s(Do),pt=l(Do,"BR",{}),go=n(Do," Output: "),bt=l(Do,"CODE",{});var Mo=r(bt);at=n(Mo,'"Hello,", " ", "how", " ", "are", " ", "you?"'),Mo.forEach(o),Do.forEach(o),ir.forEach(o),Eo=s(hl),P=l(hl,"TR",{});var cr=r(P);be=l(cr,"TD",{align:!0});var Br=r(be);Sl=n(Br,"Sequence"),Br.forEach(o),_o=s(cr),ue=l(cr,"TD",{align:!0});var Bo=r(ue);nt=n(Bo,"Lets you compose multiple "),Jt=l(Bo,"CODE",{});var xr=r(Jt);Ut=n(xr,"PreTokenizer"),xr.forEach(o),it=n(Bo," that will be run in the given order"),Bo.forEach(o),Dl=s(cr),Ae=l(cr,"TD",{align:!0}),r(Ae).forEach(o),cr.forEach(o),hl.forEach(o),Qt.forEach(o),this.h()},h(){d(p,"align","left"),d(te,"align","left"),d(J,"align","left"),d(A,"align","left"),d(M,"align","left"),d(m,"align","left"),d(Pe,"align","left"),d(Y,"align","left"),d(I,"align","left"),d(Ve,"align","left"),d(je,"align","left"),d(T,"align","left"),d(ge,"align","left"),d(Ue,"align","left"),d(N,"align","left"),d(X,"align","left"),d(Ze,"align","left"),d(H,"align","left"),d($e,"align","left"),d(ye,"align","left"),d(_,"align","left"),d(he,"align","left"),d(fe,"align","left"),d(b,"align","left"),d(lt,"align","left"),d(Ee,"align","left"),d(v,"align","left"),d(be,"align","left"),d(ue,"align","left"),d(Ae,"align","left")},m(Tt,Qt){_e(Tt,u,Qt),e(u,g),e(g,f),e(f,p),e(p,V),e(f,Kt),e(f,te),e(te,ul),e(f,Hl),e(f,J),e(J,Xt),e(u,Ll),e(u,h),e(h,E),e(E,A),e(A,pl),e(E,Mt),e(E,M),e(M,vl),e(M,le),e(le,Q),e(Q,vt),e(Q,B),e(B,Le),e(Q,Nl),e(le,Pl),e(le,ce),e(ce,Bl),e(le,xl),e(le,Te),e(Te,Lt),e(E,oe),e(E,m),e(m,Fl),e(m,wt),e(wt,We),e(m,Nt),e(m,wl),e(m,Ce),e(m,Ne),e(Ne,j),e(h,De),e(h,re),e(re,Pe),e(Pe,Ye),e(re,yl),e(re,Y),e(Y,yt),e(Y,st),e(st,ae),e(re,Ge),e(re,I),e(I,ql),e(I,ve),e(ve,gl),e(I,Al),e(I,R),e(I,Ol),e(I,W),e(W,Wl),e(h,El),e(h,ne),e(ne,Ve),e(Ve,dt),e(ne,Ul),e(ne,je),e(je,_l),e(ne,ie),e(ne,T),e(T,ml),e(T,Ot),e(Ot,Je),e(T,kl),e(T,Pt),e(T,y),e(T,Re),e(Re,Be),e(h,bl),e(h,K),e(K,ge),e(ge,Tl),e(K,Kl),e(K,Ue),e(Ue,Zt),e(K,kt),e(K,N),e(N,Bt),e(N,z),e(z,we),e(N,el),e(N,Ml),e(N,Qe),e(N,Xe),e(Xe,Yl),e(h,x),e(h,S),e(S,X),e(X,tl),e(S,Gl),e(S,Ze),e(Ze,gt),e(S,Ct),e(S,H),e(H,Vl),e(H,F),e(F,xe),e(H,jl),e(H,Jl),e(H,et),e(H,Ke),e(Ke,ll),e(h,D),e(h,q),e(q,$e),e($e,Ql),e(q,Xl),e(q,ye),e(ye,tt),e(q,Zl),e(q,_),e(_,xt),e(_,Rt),e(Rt,ct),e(_,eo),e(_,to),e(_,se),e(_,Z),e(Z,ol),e(_,lo),e(_,Ie),e(_,rl),e(_,O),e(O,Et),e(h,$t),e(h,U),e(U,he),e(he,Yt),e(U,oo),e(U,fe),e(fe,ro),e(U,Cl),e(U,b),e(b,ao),e(b,ht),e(ht,It),e(b,no),e(b,ee),e(b,me),e(b,ft),e(ft,zt),e(h,ze),e(h,de),e(de,lt),e(lt,Se),e(de,St),e(de,Ee),e(Ee,Gt),e(Ee,L),e(L,_t),e(_t,al),e(L,mt),e(L,$),e($,Rl),e($,w),e(w,k),e(k,Ft),e(w,qt),e(qt,$l),e(w,Fe),e(Fe,fo),e(w,G),e(G,At),e(w,nl),e(nl,Il),e(L,qe),e(L,Ht),e(Ht,zl),e(de,ot),e(de,v),e(v,il),e(v,Oe),e(v,uo),e(v,rt),e(rt,ut),e(v,po),e(v,ke),e(ke,Vt),e(v,Wt),e(v,io),e(v,sl),e(v,He),e(He,vo),e(v,jt),e(v,pt),e(v,go),e(v,bt),e(bt,at),e(h,Eo),e(h,P),e(P,be),e(be,Sl),e(P,_o),e(P,ue),e(ue,nt),e(ue,Jt),e(Jt,Ut),e(ue,it),e(P,Dl),e(P,Ae)},d(Tt){Tt&&o(u)}}}function zn(ko){let u,g;return u=new Qr({props:{$$slots:{default:[In]},$$scope:{ctx:ko}}}),{c(){ur(u.$$.fragment)},l(f){pr(u.$$.fragment,f)},m(f,p){vr(u,f,p),g=!0},p(f,p){const V={};p&2&&(V.$$scope={dirty:p,ctx:f}),u.$set(V)},i(f){g||(gr(u.$$.fragment,f),g=!0)},o(f){Er(u.$$.fragment,f),g=!1},d(f){_r(u,f)}}}function Sn(ko){let u,g,f,p,V,Kt,te,ul,Hl,J,Xt,Ll,h,E,A,pl,Mt,M,vl,le,Q,vt,B,Le,Nl,Pl,ce,Bl,xl,Te,Lt,oe,m,Fl,wt,We,Nt,wl,Ce,Ne,j,De,re,Pe,Ye,yl,Y,yt,st,ae,Ge,I,ql,ve,gl,Al,R,Ol,W,Wl,El,ne,Ve,dt,Ul,je,_l,ie,T,ml,Ot,Je,kl,Pt,y,Re,Be,bl,K,ge,Tl,Kl,Ue,Zt,kt,N,Bt,z,we,el,Ml,Qe,Xe,Yl,x,S,X,tl,Gl,Ze,gt,Ct,H,Vl,F,xe,jl,Jl,et,Ke,ll,D,q,$e,Ql,Xl,ye,tt,Zl,_,xt,Rt,ct,eo,to,se,Z,ol,lo,Ie,rl,O,Et,$t,U,he,Yt,oo,fe,ro,Cl,b,ao,ht,It,no,ee,me,ft,zt,ze,de,lt,Se,St,Ee,Gt,L,_t,al,mt,$,Rl,w,k,Ft,qt,$l,Fe,fo,G,At,nl,Il,qe,Ht,zl,ot,v,il,Oe,uo,rt,ut,po,ke,Vt,Wt,io,sl,He,vo,jt,pt,go,bt,at,Eo,P,be,Sl,_o,ue,nt,Jt,Ut,it,Dl,Ae,Tt,Qt,dl,cl,Wo,Dt,or,hl,Vo,pe,wo,jo,Jo,Io,zo,hr,So,rr,Co,Qo,ar,Ho,Or,co,Xo,ho,Zo,kr,yo,Yo,Cr,so,Uo,Rr,xo,Ro,$r,mo,er,Ir,Fo,Lo,nr,$o,tr,Go,qo,Oo,zr,fl,mr;return Kt=new Jr({}),Mt=new Jr({}),Nt=new pn({props:{python:!0,rust:!0,node:!0,$$slots:{node:[On],rust:[wn],python:[Tn]},$$scope:{ctx:ko}}}),De=new Jr({}),Pt=new pn({props:{python:!0,rust:!0,node:!0,$$slots:{node:[zn],rust:[$n],python:[Cn]},$$scope:{ctx:ko}}}),K=new Jr({}),Yt=new Jr({}),Tt=new Jr({}),{c(){u=t("meta"),g=i(),f=t("h1"),p=t("a"),V=t("span"),ur(Kt.$$.fragment),te=i(),ul=t("span"),Hl=a("Components"),J=i(),Xt=t("p"),Ll=a(`When building a Tokenizer, you can attach various types of components to
this Tokenizer in order to customize its behavior. This page lists most
provided components.`),h=i(),E=t("h2"),A=t("a"),pl=t("span"),ur(Mt.$$.fragment),M=i(),vl=t("span"),le=a("Normalizers"),Q=i(),vt=t("p"),B=a("A "),Le=t("code"),Nl=a("Normalizer"),Pl=a(` is in charge of pre-processing the input string in order
to normalize it as relevant for a given use case. Some common examples
of normalization are the Unicode normalization algorithms (NFD, NFKD,
NFC & NFKC), lowercasing etc\u2026 The specificity of `),ce=t("code"),Bl=a("tokenizers"),xl=a(` is that
we keep track of the alignment while normalizing. This is essential to
allow mapping from the generated tokens back to the input text.`),Te=i(),Lt=t("p"),oe=a("The "),m=t("code"),Fl=a("Normalizer"),wt=a(" is optional."),We=i(),ur(Nt.$$.fragment),wl=i(),Ce=t("h2"),Ne=t("a"),j=t("span"),ur(De.$$.fragment),re=i(),Pe=t("span"),Ye=a("Pre-tokenizers"),yl=i(),Y=t("p"),yt=a("The "),st=t("code"),ae=a("PreTokenizer"),Ge=a(` takes care of splitting the input according to a set
of rules. This pre-processing lets you ensure that the underlying
`),I=t("code"),ql=a("Model"),ve=a(` does not build tokens across multiple \u201Csplits\u201D. For example if
you don\u2019t want to have whitespaces inside a token, then you can have a
`),gl=t("code"),Al=a("PreTokenizer"),R=a(" that splits on these whitespaces."),Ol=i(),W=t("p"),Wl=a("You can easily combine multiple "),El=t("code"),ne=a("PreTokenizer"),Ve=a(` together using a
`),dt=t("code"),Ul=a("Sequence"),je=a(" (see below). The "),_l=t("code"),ie=a("PreTokenizer"),T=a(` is also allowed to modify the
string, just like a `),ml=t("code"),Ot=a("Normalizer"),Je=a(` does. This is necessary to allow some
complicated algorithms that require to split before normalizing (e.g.
the ByteLevel)`),kl=i(),ur(Pt.$$.fragment),y=i(),Re=t("h2"),Be=t("a"),bl=t("span"),ur(K.$$.fragment),ge=i(),Tl=t("span"),Kl=a("Models"),Ue=i(),Zt=t("p"),kt=a(`Models are the core algorithms used to actually tokenize, and therefore,
they are the only mandatory component of a Tokenizer.`),N=i(),Bt=t("table"),z=t("thead"),we=t("tr"),el=t("th"),Ml=a("Name"),Qe=i(),Xe=t("th"),Yl=a("Description"),x=i(),S=t("tbody"),X=t("tr"),tl=t("td"),Gl=a("WordLevel"),Ze=i(),gt=t("td"),Ct=a("This is the \u201Cclassic\u201D tokenization algorithm. It let\u2019s you simply map words to IDs without anything fancy. This has the advantage of being really simple to use and understand, but it requires extremely large vocabularies for a good coverage. Using this "),H=t("code"),Vl=a("Model"),F=a(" requires the use of a "),xe=t("code"),jl=a("PreTokenizer"),Jl=a(". No choice will be made by this model directly, it simply maps input tokens to IDs."),et=i(),Ke=t("tr"),ll=t("td"),D=a("BPE"),q=i(),$e=t("td"),Ql=a("One of the most popular subword tokenization algorithm. The Byte-Pair-Encoding works by starting with characters, while merging those that are the most frequently seen together, thus creating new tokens. It then works iteratively to build new tokens out of the most frequent pairs it sees in a corpus. BPE is able to build words it has never seen by using multiple subword tokens, and thus requires smaller vocabularies, with less chances of having \u201Cunk\u201D (unknown) tokens."),Xl=i(),ye=t("tr"),tt=t("td"),Zl=a("WordPiece"),_=i(),xt=t("td"),Rt=a("This is a subword tokenization algorithm quite similar to BPE, used mainly by Google in models like BERT. It uses a greedy algorithm, that tries to build long words first, splitting in multiple tokens when entire words don\u2019t exist in the vocabulary. This is different from BPE that starts from characters, building bigger tokens as possible. It uses the famous "),ct=t("code"),eo=a("##"),to=a(" prefix to identify tokens that are part of a word (ie not starting a word)."),se=i(),Z=t("tr"),ol=t("td"),lo=a("Unigram"),Ie=i(),rl=t("td"),O=a("Unigram is also a subword tokenization algorithm, and works by trying to identify the best set of subword tokens to maximize the probability for a given sentence. This is different from BPE in the way that this is not deterministic based on a set of rules applied sequentially. Instead Unigram will be able to compute multiple ways of tokenizing, while choosing the most probable one."),Et=i(),$t=t("h2"),U=t("a"),he=t("span"),ur(Yt.$$.fragment),oo=i(),fe=t("span"),ro=a("Post-Processors"),Cl=i(),b=t("p"),ao=a(`After the whole pipeline, we sometimes want to insert some special
tokens before feed a tokenized string into a model like \u201D[CLS] My
horse is amazing [SEP]\u201D. The `),ht=t("code"),It=a("PostProcessor"),no=a(` is the component doing
just that.`),ee=i(),me=t("table"),ft=t("thead"),zt=t("tr"),ze=t("th"),de=a("Name"),lt=i(),Se=t("th"),St=a("Description"),Ee=i(),Gt=t("th"),L=a("Example"),_t=i(),al=t("tbody"),mt=t("tr"),$=t("td"),Rl=a("TemplateProcessing"),w=i(),k=t("td"),Ft=a("Let\u2019s you easily template the post processing, adding special tokens, and specifying the "),qt=t("code"),$l=a("type_id"),Fe=a(" for each sequence/special token. The template is given two strings representing the single sequence and the pair of sequences, as well as a set of special tokens to use."),fo=i(),G=t("td"),At=a("Example, when specifying a template with these values:"),nl=t("br"),Il=i(),qe=t("ul"),Ht=t("li"),zl=a("single: "),ot=t("code"),v=a('"[CLS] $A [SEP]"'),il=i(),Oe=t("li"),uo=a("pair: "),rt=t("code"),ut=a('"[CLS] $A [SEP] $B [SEP]"'),po=i(),ke=t("li"),Vt=a("special tokens: "),Wt=t("ul"),io=t("li"),sl=t("code"),He=a('"[CLS]"'),vo=i(),jt=t("li"),pt=t("code"),go=a('"[SEP]"'),bt=i(),at=t("br"),Eo=a(" Input: "),P=t("code"),be=a('("I like this", "but not this")'),Sl=i(),_o=t("br"),ue=a(" Output: "),nt=t("code"),Jt=a('"[CLS] I like this [SEP] but not this [SEP]"'),Ut=i(),it=t("h2"),Dl=t("a"),Ae=t("span"),ur(Tt.$$.fragment),Qt=i(),dl=t("span"),cl=a("Decoders"),Wo=i(),Dt=t("p"),or=a(`The Decoder knows how to go from the IDs used by the Tokenizer, back to
a readable piece of text. Some `),hl=t("code"),Vo=a("Normalizer"),pe=a(" and "),wo=t("code"),jo=a("PreTokenizer"),Jo=a(` use
special characters or identifiers that need to be reverted for example.`),Io=i(),zo=t("table"),hr=t("thead"),So=t("tr"),rr=t("th"),Co=a("Name"),Qo=i(),ar=t("th"),Ho=a("Description"),Or=i(),co=t("tbody"),Xo=t("tr"),ho=t("td"),Zo=a("ByteLevel"),kr=i(),yo=t("td"),Yo=a("Reverts the ByteLevel PreTokenizer. This PreTokenizer encodes at the byte-level, using a set of visible Unicode characters to represent each byte, so we need a Decoder to revert this process and get something readable again."),Cr=i(),so=t("tr"),Uo=t("td"),Rr=a("Metaspace"),xo=i(),Ro=t("td"),$r=a("Reverts the Metaspace PreTokenizer. This PreTokenizer uses a special identifer "),mo=t("code"),er=a("\u2581"),Ir=a(" to identify whitespaces, and so this Decoder helps with decoding these."),Fo=i(),Lo=t("tr"),nr=t("td"),$o=a("WordPiece"),tr=i(),Go=t("td"),qo=a("Reverts the WordPiece Model. This model uses a special identifier "),Oo=t("code"),zr=a("##"),fl=a(" for continuing subwords, and so this Decoder helps with decoding these."),this.h()},l(c){const C=_n('[data-svelte="svelte-1phssyn"]',document.head);u=l(C,"META",{name:!0,content:!0}),C.forEach(o),g=s(c),f=l(c,"H1",{class:!0});var bo=r(f);p=l(bo,"A",{id:!0,class:!0,href:!0});var Ko=r(p);V=l(Ko,"SPAN",{});var Sr=r(V);pr(Kt.$$.fragment,Sr),Sr.forEach(o),Ko.forEach(o),te=s(bo),ul=l(bo,"SPAN",{});var No=r(ul);Hl=n(No,"Components"),No.forEach(o),bo.forEach(o),J=s(c),Xt=l(c,"P",{});var ir=r(Xt);Ll=n(ir,`When building a Tokenizer, you can attach various types of components to
this Tokenizer in order to customize its behavior. This page lists most
provided components.`),ir.forEach(o),h=s(c),E=l(c,"H2",{class:!0});var br=r(E);A=l(br,"A",{id:!0,class:!0,href:!0});var Ao=r(A);pl=l(Ao,"SPAN",{});var sr=r(pl);pr(Mt.$$.fragment,sr),sr.forEach(o),Ao.forEach(o),M=s(br),vl=l(br,"SPAN",{});var Tr=r(vl);le=n(Tr,"Normalizers"),Tr.forEach(o),br.forEach(o),Q=s(c),vt=l(c,"P",{});var To=r(vt);B=n(To,"A "),Le=l(To,"CODE",{});var dr=r(Le);Nl=n(dr,"Normalizer"),dr.forEach(o),Pl=n(To,` is in charge of pre-processing the input string in order
to normalize it as relevant for a given use case. Some common examples
of normalization are the Unicode normalization algorithms (NFD, NFKD,
NFC & NFKC), lowercasing etc\u2026 The specificity of `),ce=l(To,"CODE",{});var Dr=r(ce);Bl=n(Dr,"tokenizers"),Dr.forEach(o),xl=n(To,` is that
we keep track of the alignment while normalizing. This is essential to
allow mapping from the generated tokens back to the input text.`),To.forEach(o),Te=s(c),Lt=l(c,"P",{});var Po=r(Lt);oe=n(Po,"The "),m=l(Po,"CODE",{});var Hr=r(m);Fl=n(Hr,"Normalizer"),Hr.forEach(o),wt=n(Po," is optional."),Po.forEach(o),We=s(c),pr(Nt.$$.fragment,c),wl=s(c),Ce=l(c,"H2",{class:!0});var wr=r(Ce);Ne=l(wr,"A",{id:!0,class:!0,href:!0});var Lr=r(Ne);j=l(Lr,"SPAN",{});var Nr=r(j);pr(De.$$.fragment,Nr),Nr.forEach(o),Lr.forEach(o),re=s(wr),Pe=l(wr,"SPAN",{});var Do=r(Pe);Ye=n(Do,"Pre-tokenizers"),Do.forEach(o),wr.forEach(o),yl=s(c),Y=l(c,"P",{});var lr=r(Y);yt=n(lr,"The "),st=l(lr,"CODE",{});var Me=r(st);ae=n(Me,"PreTokenizer"),Me.forEach(o),Ge=n(lr,` takes care of splitting the input according to a set
of rules. This pre-processing lets you ensure that the underlying
`),I=l(lr,"CODE",{});var Fr=r(I);ql=n(Fr,"Model"),Fr.forEach(o),ve=n(lr,` does not build tokens across multiple \u201Csplits\u201D. For example if
you don\u2019t want to have whitespaces inside a token, then you can have a
`),gl=l(lr,"CODE",{});var Pr=r(gl);Al=n(Pr,"PreTokenizer"),Pr.forEach(o),R=n(lr," that splits on these whitespaces."),lr.forEach(o),Ol=s(c),W=l(c,"P",{});var Mo=r(W);Wl=n(Mo,"You can easily combine multiple "),El=l(Mo,"CODE",{});var cr=r(El);ne=n(cr,"PreTokenizer"),cr.forEach(o),Ve=n(Mo,` together using a
`),dt=l(Mo,"CODE",{});var Br=r(dt);Ul=n(Br,"Sequence"),Br.forEach(o),je=n(Mo," (see below). The "),_l=l(Mo,"CODE",{});var Bo=r(_l);ie=n(Bo,"PreTokenizer"),Bo.forEach(o),T=n(Mo,` is also allowed to modify the
string, just like a `),ml=l(Mo,"CODE",{});var xr=r(ml);Ot=n(xr,"Normalizer"),xr.forEach(o),Je=n(Mo,` does. This is necessary to allow some
complicated algorithms that require to split before normalizing (e.g.
the ByteLevel)`),Mo.forEach(o),kl=s(c),pr(Pt.$$.fragment,c),y=s(c),Re=l(c,"H2",{class:!0});var fr=r(Re);Be=l(fr,"A",{id:!0,class:!0,href:!0});var qr=r(Be);bl=l(qr,"SPAN",{});var Ar=r(bl);pr(K.$$.fragment,Ar),Ar.forEach(o),qr.forEach(o),ge=s(fr),Tl=l(fr,"SPAN",{});var Wr=r(Tl);Kl=n(Wr,"Models"),Wr.forEach(o),fr.forEach(o),Ue=s(c),Zt=l(c,"P",{});var Ta=r(Zt);kt=n(Ta,`Models are the core algorithms used to actually tokenize, and therefore,
they are the only mandatory component of a Tokenizer.`),Ta.forEach(o),N=s(c),Bt=l(c,"TABLE",{});var Xr=r(Bt);z=l(Xr,"THEAD",{});var Da=r(z);we=l(Da,"TR",{});var Zr=r(we);el=l(Zr,"TH",{align:!0});var wa=r(el);Ml=n(wa,"Name"),wa.forEach(o),Qe=s(Zr),Xe=l(Zr,"TH",{align:!0});var ya=r(Xe);Yl=n(ya,"Description"),ya.forEach(o),Zr.forEach(o),Da.forEach(o),x=s(Xr),S=l(Xr,"TBODY",{});var Ur=r(S);X=l(Ur,"TR",{});var ea=r(X);tl=l(ea,"TD",{align:!0});var Oa=r(tl);Gl=n(Oa,"WordLevel"),Oa.forEach(o),Ze=s(ea),gt=l(ea,"TD",{align:!0});var Kr=r(gt);Ct=n(Kr,"This is the \u201Cclassic\u201D tokenization algorithm. It let\u2019s you simply map words to IDs without anything fancy. This has the advantage of being really simple to use and understand, but it requires extremely large vocabularies for a good coverage. Using this "),H=l(Kr,"CODE",{});var ka=r(H);Vl=n(ka,"Model"),ka.forEach(o),F=n(Kr," requires the use of a "),xe=l(Kr,"CODE",{});var Ca=r(xe);jl=n(Ca,"PreTokenizer"),Ca.forEach(o),Jl=n(Kr,". No choice will be made by this model directly, it simply maps input tokens to IDs."),Kr.forEach(o),ea.forEach(o),et=s(Ur),Ke=l(Ur,"TR",{});var ta=r(Ke);ll=l(ta,"TD",{align:!0});var Ra=r(ll);D=n(Ra,"BPE"),Ra.forEach(o),q=s(ta),$e=l(ta,"TD",{align:!0});var $a=r($e);Ql=n($a,"One of the most popular subword tokenization algorithm. The Byte-Pair-Encoding works by starting with characters, while merging those that are the most frequently seen together, thus creating new tokens. It then works iteratively to build new tokens out of the most frequent pairs it sees in a corpus. BPE is able to build words it has never seen by using multiple subword tokens, and thus requires smaller vocabularies, with less chances of having \u201Cunk\u201D (unknown) tokens."),$a.forEach(o),ta.forEach(o),Xl=s(Ur),ye=l(Ur,"TR",{});var la=r(ye);tt=l(la,"TD",{align:!0});var Ia=r(tt);Zl=n(Ia,"WordPiece"),Ia.forEach(o),_=s(la),xt=l(la,"TD",{align:!0});var oa=r(xt);Rt=n(oa,"This is a subword tokenization algorithm quite similar to BPE, used mainly by Google in models like BERT. It uses a greedy algorithm, that tries to build long words first, splitting in multiple tokens when entire words don\u2019t exist in the vocabulary. This is different from BPE that starts from characters, building bigger tokens as possible. It uses the famous "),ct=l(oa,"CODE",{});var za=r(ct);eo=n(za,"##"),za.forEach(o),to=n(oa," prefix to identify tokens that are part of a word (ie not starting a word)."),oa.forEach(o),la.forEach(o),se=s(Ur),Z=l(Ur,"TR",{});var ra=r(Z);ol=l(ra,"TD",{align:!0});var Sa=r(ol);lo=n(Sa,"Unigram"),Sa.forEach(o),Ie=s(ra),rl=l(ra,"TD",{align:!0});var Ha=r(rl);O=n(Ha,"Unigram is also a subword tokenization algorithm, and works by trying to identify the best set of subword tokens to maximize the probability for a given sentence. This is different from BPE in the way that this is not deterministic based on a set of rules applied sequentially. Instead Unigram will be able to compute multiple ways of tokenizing, while choosing the most probable one."),Ha.forEach(o),ra.forEach(o),Ur.forEach(o),Xr.forEach(o),Et=s(c),$t=l(c,"H2",{class:!0});var aa=r($t);U=l(aa,"A",{id:!0,class:!0,href:!0});var La=r(U);he=l(La,"SPAN",{});var Na=r(he);pr(Yt.$$.fragment,Na),Na.forEach(o),La.forEach(o),oo=s(aa),fe=l(aa,"SPAN",{});var Pa=r(fe);ro=n(Pa,"Post-Processors"),Pa.forEach(o),aa.forEach(o),Cl=s(c),b=l(c,"P",{});var na=r(b);ao=n(na,`After the whole pipeline, we sometimes want to insert some special
tokens before feed a tokenized string into a model like \u201D[CLS] My
horse is amazing [SEP]\u201D. The `),ht=l(na,"CODE",{});var Ba=r(ht);It=n(Ba,"PostProcessor"),Ba.forEach(o),no=n(na,` is the component doing
just that.`),na.forEach(o),ee=s(c),me=l(c,"TABLE",{});var ia=r(me);ft=l(ia,"THEAD",{});var xa=r(ft);zt=l(xa,"TR",{});var Mr=r(zt);ze=l(Mr,"TH",{align:!0});var Fa=r(ze);de=n(Fa,"Name"),Fa.forEach(o),lt=s(Mr),Se=l(Mr,"TH",{align:!0});var qa=r(Se);St=n(qa,"Description"),qa.forEach(o),Ee=s(Mr),Gt=l(Mr,"TH",{align:!0});var Aa=r(Gt);L=n(Aa,"Example"),Aa.forEach(o),Mr.forEach(o),xa.forEach(o),_t=s(ia),al=l(ia,"TBODY",{});var Wa=r(al);mt=l(Wa,"TR",{});var Yr=r(mt);$=l(Yr,"TD",{align:!0});var Ua=r($);Rl=n(Ua,"TemplateProcessing"),Ua.forEach(o),w=s(Yr),k=l(Yr,"TD",{align:!0});var sa=r(k);Ft=n(sa,"Let\u2019s you easily template the post processing, adding special tokens, and specifying the "),qt=l(sa,"CODE",{});var Ka=r(qt);$l=n(Ka,"type_id"),Ka.forEach(o),Fe=n(sa," for each sequence/special token. The template is given two strings representing the single sequence and the pair of sequences, as well as a set of special tokens to use."),sa.forEach(o),fo=s(Yr),G=l(Yr,"TD",{align:!0});var yr=r(G);At=n(yr,"Example, when specifying a template with these values:"),nl=l(yr,"BR",{}),Il=s(yr),qe=l(yr,"UL",{});var Gr=r(qe);Ht=l(Gr,"LI",{});var _a=r(Ht);zl=n(_a,"single: "),ot=l(_a,"CODE",{});var Ma=r(ot);v=n(Ma,'"[CLS] $A [SEP]"'),Ma.forEach(o),_a.forEach(o),il=s(Gr),Oe=l(Gr,"LI",{});var ma=r(Oe);uo=n(ma,"pair: "),rt=l(ma,"CODE",{});var Ya=r(rt);ut=n(Ya,'"[CLS] $A [SEP] $B [SEP]"'),Ya.forEach(o),ma.forEach(o),po=s(Gr),ke=l(Gr,"LI",{});var ba=r(ke);Vt=n(ba,"special tokens: "),Wt=l(ba,"UL",{});var da=r(Wt);io=l(da,"LI",{});var Ga=r(io);sl=l(Ga,"CODE",{});var Va=r(sl);He=n(Va,'"[CLS]"'),Va.forEach(o),Ga.forEach(o),vo=s(da),jt=l(da,"LI",{});var ja=r(jt);pt=l(ja,"CODE",{});var Ja=r(pt);go=n(Ja,'"[SEP]"'),Ja.forEach(o),ja.forEach(o),da.forEach(o),ba.forEach(o),Gr.forEach(o),bt=s(yr),at=l(yr,"BR",{}),Eo=n(yr," Input: "),P=l(yr,"CODE",{});var Qa=r(P);be=n(Qa,'("I like this", "but not this")'),Qa.forEach(o),Sl=s(yr),_o=l(yr,"BR",{}),ue=n(yr," Output: "),nt=l(yr,"CODE",{});var Xa=r(nt);Jt=n(Xa,'"[CLS] I like this [SEP] but not this [SEP]"'),Xa.forEach(o),yr.forEach(o),Yr.forEach(o),Wa.forEach(o),ia.forEach(o),Ut=s(c),it=l(c,"H2",{class:!0});var ca=r(it);Dl=l(ca,"A",{id:!0,class:!0,href:!0});var Za=r(Dl);Ae=l(Za,"SPAN",{});var en=r(Ae);pr(Tt.$$.fragment,en),en.forEach(o),Za.forEach(o),Qt=s(ca),dl=l(ca,"SPAN",{});var tn=r(dl);cl=n(tn,"Decoders"),tn.forEach(o),ca.forEach(o),Wo=s(c),Dt=l(c,"P",{});var Vr=r(Dt);or=n(Vr,`The Decoder knows how to go from the IDs used by the Tokenizer, back to
a readable piece of text. Some `),hl=l(Vr,"CODE",{});var ln=r(hl);Vo=n(ln,"Normalizer"),ln.forEach(o),pe=n(Vr," and "),wo=l(Vr,"CODE",{});var on=r(wo);jo=n(on,"PreTokenizer"),on.forEach(o),Jo=n(Vr,` use
special characters or identifiers that need to be reverted for example.`),Vr.forEach(o),Io=s(c),zo=l(c,"TABLE",{});var ha=r(zo);hr=l(ha,"THEAD",{});var rn=r(hr);So=l(rn,"TR",{});var fa=r(So);rr=l(fa,"TH",{align:!0});var an=r(rr);Co=n(an,"Name"),an.forEach(o),Qo=s(fa),ar=l(fa,"TH",{align:!0});var nn=r(ar);Ho=n(nn,"Description"),nn.forEach(o),fa.forEach(o),rn.forEach(o),Or=s(ha),co=l(ha,"TBODY",{});var jr=r(co);Xo=l(jr,"TR",{});var ua=r(Xo);ho=l(ua,"TD",{align:!0});var sn=r(ho);Zo=n(sn,"ByteLevel"),sn.forEach(o),kr=s(ua),yo=l(ua,"TD",{align:!0});var dn=r(yo);Yo=n(dn,"Reverts the ByteLevel PreTokenizer. This PreTokenizer encodes at the byte-level, using a set of visible Unicode characters to represent each byte, so we need a Decoder to revert this process and get something readable again."),dn.forEach(o),ua.forEach(o),Cr=s(jr),so=l(jr,"TR",{});var pa=r(so);Uo=l(pa,"TD",{align:!0});var cn=r(Uo);Rr=n(cn,"Metaspace"),cn.forEach(o),xo=s(pa),Ro=l(pa,"TD",{align:!0});var va=r(Ro);$r=n(va,"Reverts the Metaspace PreTokenizer. This PreTokenizer uses a special identifer "),mo=l(va,"CODE",{});var hn=r(mo);er=n(hn,"\u2581"),hn.forEach(o),Ir=n(va," to identify whitespaces, and so this Decoder helps with decoding these."),va.forEach(o),pa.forEach(o),Fo=s(jr),Lo=l(jr,"TR",{});var ga=r(Lo);nr=l(ga,"TD",{align:!0});var fn=r(nr);$o=n(fn,"WordPiece"),fn.forEach(o),tr=s(ga),Go=l(ga,"TD",{align:!0});var Ea=r(Go);qo=n(Ea,"Reverts the WordPiece Model. This model uses a special identifier "),Oo=l(Ea,"CODE",{});var un=r(Oo);zr=n(un,"##"),un.forEach(o),fl=n(Ea," for continuing subwords, and so this Decoder helps with decoding these."),Ea.forEach(o),ga.forEach(o),jr.forEach(o),ha.forEach(o),this.h()},h(){d(u,"name","hf:doc:metadata"),d(u,"content",JSON.stringify(Hn)),d(p,"id","components"),d(p,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p,"href","#components"),d(f,"class","relative group"),d(A,"id","normalizers"),d(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A,"href","#normalizers"),d(E,"class","relative group"),d(Ne,"id","pretokenizers"),d(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ne,"href","#pretokenizers"),d(Ce,"class","relative group"),d(Be,"id","models"),d(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Be,"href","#models"),d(Re,"class","relative group"),d(el,"align","left"),d(Xe,"align","left"),d(tl,"align","left"),d(gt,"align","left"),d(ll,"align","left"),d($e,"align","left"),d(tt,"align","left"),d(xt,"align","left"),d(ol,"align","left"),d(rl,"align","left"),d(U,"id","postprocessors"),d(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U,"href","#postprocessors"),d($t,"class","relative group"),d(ze,"align","left"),d(Se,"align","left"),d(Gt,"align","left"),d($,"align","left"),d(k,"align","left"),d(G,"align","left"),d(Dl,"id","decoders"),d(Dl,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Dl,"href","#decoders"),d(it,"class","relative group"),d(rr,"align","left"),d(ar,"align","left"),d(ho,"align","left"),d(yo,"align","left"),d(Uo,"align","left"),d(Ro,"align","left"),d(nr,"align","left"),d(Go,"align","left")},m(c,C){e(document.head,u),_e(c,g,C),_e(c,f,C),e(f,p),e(p,V),vr(Kt,V,null),e(f,te),e(f,ul),e(ul,Hl),_e(c,J,C),_e(c,Xt,C),e(Xt,Ll),_e(c,h,C),_e(c,E,C),e(E,A),e(A,pl),vr(Mt,pl,null),e(E,M),e(E,vl),e(vl,le),_e(c,Q,C),_e(c,vt,C),e(vt,B),e(vt,Le),e(Le,Nl),e(vt,Pl),e(vt,ce),e(ce,Bl),e(vt,xl),_e(c,Te,C),_e(c,Lt,C),e(Lt,oe),e(Lt,m),e(m,Fl),e(Lt,wt),_e(c,We,C),vr(Nt,c,C),_e(c,wl,C),_e(c,Ce,C),e(Ce,Ne),e(Ne,j),vr(De,j,null),e(Ce,re),e(Ce,Pe),e(Pe,Ye),_e(c,yl,C),_e(c,Y,C),e(Y,yt),e(Y,st),e(st,ae),e(Y,Ge),e(Y,I),e(I,ql),e(Y,ve),e(Y,gl),e(gl,Al),e(Y,R),_e(c,Ol,C),_e(c,W,C),e(W,Wl),e(W,El),e(El,ne),e(W,Ve),e(W,dt),e(dt,Ul),e(W,je),e(W,_l),e(_l,ie),e(W,T),e(W,ml),e(ml,Ot),e(W,Je),_e(c,kl,C),vr(Pt,c,C),_e(c,y,C),_e(c,Re,C),e(Re,Be),e(Be,bl),vr(K,bl,null),e(Re,ge),e(Re,Tl),e(Tl,Kl),_e(c,Ue,C),_e(c,Zt,C),e(Zt,kt),_e(c,N,C),_e(c,Bt,C),e(Bt,z),e(z,we),e(we,el),e(el,Ml),e(we,Qe),e(we,Xe),e(Xe,Yl),e(Bt,x),e(Bt,S),e(S,X),e(X,tl),e(tl,Gl),e(X,Ze),e(X,gt),e(gt,Ct),e(gt,H),e(H,Vl),e(gt,F),e(gt,xe),e(xe,jl),e(gt,Jl),e(S,et),e(S,Ke),e(Ke,ll),e(ll,D),e(Ke,q),e(Ke,$e),e($e,Ql),e(S,Xl),e(S,ye),e(ye,tt),e(tt,Zl),e(ye,_),e(ye,xt),e(xt,Rt),e(xt,ct),e(ct,eo),e(xt,to),e(S,se),e(S,Z),e(Z,ol),e(ol,lo),e(Z,Ie),e(Z,rl),e(rl,O),_e(c,Et,C),_e(c,$t,C),e($t,U),e(U,he),vr(Yt,he,null),e($t,oo),e($t,fe),e(fe,ro),_e(c,Cl,C),_e(c,b,C),e(b,ao),e(b,ht),e(ht,It),e(b,no),_e(c,ee,C),_e(c,me,C),e(me,ft),e(ft,zt),e(zt,ze),e(ze,de),e(zt,lt),e(zt,Se),e(Se,St),e(zt,Ee),e(zt,Gt),e(Gt,L),e(me,_t),e(me,al),e(al,mt),e(mt,$),e($,Rl),e(mt,w),e(mt,k),e(k,Ft),e(k,qt),e(qt,$l),e(k,Fe),e(mt,fo),e(mt,G),e(G,At),e(G,nl),e(G,Il),e(G,qe),e(qe,Ht),e(Ht,zl),e(Ht,ot),e(ot,v),e(qe,il),e(qe,Oe),e(Oe,uo),e(Oe,rt),e(rt,ut),e(qe,po),e(qe,ke),e(ke,Vt),e(ke,Wt),e(Wt,io),e(io,sl),e(sl,He),e(Wt,vo),e(Wt,jt),e(jt,pt),e(pt,go),e(G,bt),e(G,at),e(G,Eo),e(G,P),e(P,be),e(G,Sl),e(G,_o),e(G,ue),e(G,nt),e(nt,Jt),_e(c,Ut,C),_e(c,it,C),e(it,Dl),e(Dl,Ae),vr(Tt,Ae,null),e(it,Qt),e(it,dl),e(dl,cl),_e(c,Wo,C),_e(c,Dt,C),e(Dt,or),e(Dt,hl),e(hl,Vo),e(Dt,pe),e(Dt,wo),e(wo,jo),e(Dt,Jo),_e(c,Io,C),_e(c,zo,C),e(zo,hr),e(hr,So),e(So,rr),e(rr,Co),e(So,Qo),e(So,ar),e(ar,Ho),e(zo,Or),e(zo,co),e(co,Xo),e(Xo,ho),e(ho,Zo),e(Xo,kr),e(Xo,yo),e(yo,Yo),e(co,Cr),e(co,so),e(so,Uo),e(Uo,Rr),e(so,xo),e(so,Ro),e(Ro,$r),e(Ro,mo),e(mo,er),e(Ro,Ir),e(co,Fo),e(co,Lo),e(Lo,nr),e(nr,$o),e(Lo,tr),e(Lo,Go),e(Go,qo),e(Go,Oo),e(Oo,zr),e(Go,fl),mr=!0},p(c,[C]){const bo={};C&2&&(bo.$$scope={dirty:C,ctx:c}),Nt.$set(bo);const Ko={};C&2&&(Ko.$$scope={dirty:C,ctx:c}),Pt.$set(Ko)},i(c){mr||(gr(Kt.$$.fragment,c),gr(Mt.$$.fragment,c),gr(Nt.$$.fragment,c),gr(De.$$.fragment,c),gr(Pt.$$.fragment,c),gr(K.$$.fragment,c),gr(Yt.$$.fragment,c),gr(Tt.$$.fragment,c),mr=!0)},o(c){Er(Kt.$$.fragment,c),Er(Mt.$$.fragment,c),Er(Nt.$$.fragment,c),Er(De.$$.fragment,c),Er(Pt.$$.fragment,c),Er(K.$$.fragment,c),Er(Yt.$$.fragment,c),Er(Tt.$$.fragment,c),mr=!1},d(c){o(u),c&&o(g),c&&o(f),_r(Kt),c&&o(J),c&&o(Xt),c&&o(h),c&&o(E),_r(Mt),c&&o(Q),c&&o(vt),c&&o(Te),c&&o(Lt),c&&o(We),_r(Nt,c),c&&o(wl),c&&o(Ce),_r(De),c&&o(yl),c&&o(Y),c&&o(Ol),c&&o(W),c&&o(kl),_r(Pt,c),c&&o(y),c&&o(Re),_r(K),c&&o(Ue),c&&o(Zt),c&&o(N),c&&o(Bt),c&&o(Et),c&&o($t),_r(Yt),c&&o(Cl),c&&o(b),c&&o(ee),c&&o(me),c&&o(Ut),c&&o(it),_r(Tt),c&&o(Wo),c&&o(Dt),c&&o(Io),c&&o(zo)}}}const Hn={local:"components",sections:[{local:"normalizers",title:"Normalizers"},{local:"pretokenizers",title:"Pre-tokenizers"},{local:"models",title:"Models"},{local:"postprocessors",title:"Post-Processors"},{local:"decoders",title:"Decoders"}],title:"Components"};function Ln(ko){return mn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xn extends vn{constructor(u){super();gn(this,u,Ln,Sn,En,{})}}export{xn as default,Hn as metadata};
