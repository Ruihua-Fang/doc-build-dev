import{S as F,i as H,s as O,e as p,k as D,w as y,t as M,M as U,c as h,d as i,m as I,a as k,x as E,h as N,b as z,F as l,g as x,y as A,q as T,o as V,B as P,v as j,L as J}from"../../chunks/vendor-a667fb6e.js";import{D as B}from"../../chunks/Docstring-1fb72b09.js";import{I as W}from"../../chunks/IconCopyLink-3bc33587.js";import{T as G,M as C}from"../../chunks/TokenizersLanguageContent-c33e4dff.js";function K($){let t,o,e,n,r,c,u,_,L,m,f,w,a,d,g;return o=new B({props:{name:"class tokenizers.tools.Annotation",anchor:"tokenizers.tools.Annotation",parameters:[{name:"start",val:": int"},{name:"end",val:": int"},{name:"label",val:": str"}],source:"https://github.com/huggingface/tokenizers/blob/pr_1/src/tokenizers/tools/visualizer.py#L16"}}),r=new B({props:{name:"class tokenizers.tools.EncodingVisualizer",anchor:"tokenizers.tools.EncodingVisualizer",parameters:[{name:"tokenizer",val:": Tokenizer"},{name:"default_to_notebook",val:": bool = True"},{name:"annotation_converter",val:": typing.Union[typing.Callable[[typing.Any], tokenizers.tools.visualizer.Annotation], NoneType] = None"}],parametersDescription:[{anchor:"tokenizers.tools.EncodingVisualizer.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/tokenizers/pr_1/en/api/tokenizer#tokenizers.Tokenizer">Tokenizer</a>) &#x2014;
A tokenizer instance`,name:"tokenizer"},{anchor:"tokenizers.tools.EncodingVisualizer.default_to_notebook",description:`<strong>default_to_notebook</strong> (<code>bool</code>) &#x2014;
Whether to render html output in a notebook by default`,name:"default_to_notebook"},{anchor:"tokenizers.tools.EncodingVisualizer.annotation_converter",description:`<strong>annotation_converter</strong> (<code>Callable</code>, <em>optional</em>) &#x2014;
An optional (lambda) function that takes an annotation in any format and returns
an Annotation object`,name:"annotation_converter"}],source:"https://github.com/huggingface/tokenizers/blob/pr_1/src/tokenizers/tools/visualizer.py#L67"}}),f=new B({props:{name:"__call__",anchor:"tokenizers.tools.EncodingVisualizer.__call__",parameters:[{name:"text",val:": str"},{name:"annotations",val:": typing.List[tokenizers.tools.visualizer.Annotation] = []"},{name:"default_to_notebook",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"tokenizers.tools.EncodingVisualizer.__call__.text",description:`<strong>text</strong> (<code>str</code>) &#x2014;
The text to tokenize`,name:"text"},{anchor:"tokenizers.tools.EncodingVisualizer.__call__.annotations",description:`<strong>annotations</strong> (<code>List[Annotation]</code>, <em>optional</em>) &#x2014;
An optional list of annotations of the text. The can either be an annotation class
or anything else if you instantiated the visualizer with a converter function`,name:"annotations"},{anchor:"tokenizers.tools.EncodingVisualizer.__call__.default_to_notebook",description:`<strong>default_to_notebook</strong> (<code>bool</code>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
If True, will render the html in a notebook. Otherwise returns an html string.`,name:"default_to_notebook"}],source:"https://github.com/huggingface/tokenizers/blob/pr_1/src/tokenizers/tools/visualizer.py#L108",returnDescription:`
<p>The HTML string if default_to_notebook is False, otherwise (default) returns None and
renders the HTML in the notebook</p>
`}}),{c(){t=p("div"),y(o.$$.fragment),e=D(),n=p("div"),y(r.$$.fragment),c=D(),u=p("p"),_=M("Build an EncodingVisualizer"),L=D(),m=p("div"),y(f.$$.fragment),w=D(),a=p("p"),d=M("Build a visualization of the given text"),this.h()},l(s){t=h(s,"DIV",{class:!0});var v=k(t);E(o.$$.fragment,v),v.forEach(i),e=I(s),n=h(s,"DIV",{class:!0});var b=k(n);E(r.$$.fragment,b),c=I(b),u=h(b,"P",{});var R=k(u);_=N(R,"Build an EncodingVisualizer"),R.forEach(i),L=I(b),m=h(b,"DIV",{class:!0});var S=k(m);E(f.$$.fragment,S),w=I(S),a=h(S,"P",{});var q=k(a);d=N(q,"Build a visualization of the given text"),q.forEach(i),S.forEach(i),b.forEach(i),this.h()},h(){z(t,"class","docstring"),z(m,"class","docstring"),z(n,"class","docstring")},m(s,v){x(s,t,v),A(o,t,null),x(s,e,v),x(s,n,v),A(r,n,null),l(n,c),l(n,u),l(u,_),l(n,L),l(n,m),A(f,m,null),l(m,w),l(m,a),l(a,d),g=!0},p:J,i(s){g||(T(o.$$.fragment,s),T(r.$$.fragment,s),T(f.$$.fragment,s),g=!0)},o(s){V(o.$$.fragment,s),V(r.$$.fragment,s),V(f.$$.fragment,s),g=!1},d(s){s&&i(t),P(o),s&&i(e),s&&i(n),P(r),P(f)}}}function Q($){let t,o;return t=new C({props:{$$slots:{default:[K]},$$scope:{ctx:$}}}),{c(){y(t.$$.fragment)},l(e){E(t.$$.fragment,e)},m(e,n){A(t,e,n),o=!0},p(e,n){const r={};n&2&&(r.$$scope={dirty:n,ctx:e}),t.$set(r)},i(e){o||(T(t.$$.fragment,e),o=!0)},o(e){V(t.$$.fragment,e),o=!1},d(e){P(t,e)}}}function X($){let t,o,e,n,r;return{c(){t=p("p"),o=M("The Rust API Reference is available directly on the "),e=p("a"),n=M("Docs.rs"),r=M(" website."),this.h()},l(c){t=h(c,"P",{});var u=k(t);o=N(u,"The Rust API Reference is available directly on the "),e=h(u,"A",{href:!0,rel:!0});var _=k(e);n=N(_,"Docs.rs"),_.forEach(i),r=N(u," website."),u.forEach(i),this.h()},h(){z(e,"href","https://docs.rs/tokenizers/latest/tokenizers/"),z(e,"rel","nofollow")},m(c,u){x(c,t,u),l(t,o),l(t,e),l(e,n),l(t,r)},d(c){c&&i(t)}}}function Y($){let t,o;return t=new C({props:{$$slots:{default:[X]},$$scope:{ctx:$}}}),{c(){y(t.$$.fragment)},l(e){E(t.$$.fragment,e)},m(e,n){A(t,e,n),o=!0},p(e,n){const r={};n&2&&(r.$$scope={dirty:n,ctx:e}),t.$set(r)},i(e){o||(T(t.$$.fragment,e),o=!0)},o(e){V(t.$$.fragment,e),o=!1},d(e){P(t,e)}}}function Z($){let t,o;return{c(){t=p("p"),o=M("The node API has not been documented yet.")},l(e){t=h(e,"P",{});var n=k(t);o=N(n,"The node API has not been documented yet."),n.forEach(i)},m(e,n){x(e,t,n),l(t,o)},d(e){e&&i(t)}}}function ee($){let t,o;return t=new C({props:{$$slots:{default:[Z]},$$scope:{ctx:$}}}),{c(){y(t.$$.fragment)},l(e){E(t.$$.fragment,e)},m(e,n){A(t,e,n),o=!0},p(e,n){const r={};n&2&&(r.$$scope={dirty:n,ctx:e}),t.$set(r)},i(e){o||(T(t.$$.fragment,e),o=!0)},o(e){V(t.$$.fragment,e),o=!1},d(e){P(t,e)}}}function te($){let t,o,e,n,r,c,u,_,L,m,f,w;return c=new W({}),f=new G({props:{python:!0,rust:!0,node:!0,$$slots:{node:[ee],rust:[Y],python:[Q]},$$scope:{ctx:$}}}),{c(){t=p("meta"),o=D(),e=p("h1"),n=p("a"),r=p("span"),y(c.$$.fragment),u=D(),_=p("span"),L=M("Visualizer"),m=D(),y(f.$$.fragment),this.h()},l(a){const d=U('[data-svelte="svelte-1phssyn"]',document.head);t=h(d,"META",{name:!0,content:!0}),d.forEach(i),o=I(a),e=h(a,"H1",{class:!0});var g=k(e);n=h(g,"A",{id:!0,class:!0,href:!0});var s=k(n);r=h(s,"SPAN",{});var v=k(r);E(c.$$.fragment,v),v.forEach(i),s.forEach(i),u=I(g),_=h(g,"SPAN",{});var b=k(_);L=N(b,"Visualizer"),b.forEach(i),g.forEach(i),m=I(a),E(f.$$.fragment,a),this.h()},h(){z(t,"name","hf:doc:metadata"),z(t,"content",JSON.stringify(ne)),z(n,"id","tokenizers.tools.Annotation"),z(n,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),z(n,"href","#tokenizers.tools.Annotation"),z(e,"class","relative group")},m(a,d){l(document.head,t),x(a,o,d),x(a,e,d),l(e,n),l(n,r),A(c,r,null),l(e,u),l(e,_),l(_,L),x(a,m,d),A(f,a,d),w=!0},p(a,[d]){const g={};d&2&&(g.$$scope={dirty:d,ctx:a}),f.$set(g)},i(a){w||(T(c.$$.fragment,a),T(f.$$.fragment,a),w=!0)},o(a){V(c.$$.fragment,a),V(f.$$.fragment,a),w=!1},d(a){i(t),a&&i(o),a&&i(e),P(c),a&&i(m),P(f,a)}}}const ne={local:"tokenizers.tools.Annotation",title:"Visualizer"};function oe($){return j(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class le extends F{constructor(t){super();H(this,t,oe,te,O,{})}}export{le as default,ne as metadata};
