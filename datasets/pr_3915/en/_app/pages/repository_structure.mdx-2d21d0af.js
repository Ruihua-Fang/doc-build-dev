import{S as Da,i as Oa,s as Ha,e as r,k as f,w as y,t as i,M as Ia,c as l,d as e,m as h,a as n,x as $,h as o,b as c,F as s,g as p,y as E,q as w,o as g,B as x}from"../chunks/vendor-aa873a46.js";import{T as Ca}from"../chunks/Tip-f7f252ab.js";import{I as _t}from"../chunks/IconCopyLink-d0ca3106.js";import{C as nt}from"../chunks/CodeBlock-1f14baf3.js";function Ga(yt){let d,b;return{c(){d=r("p"),b=i("The following examples use CSV files, but you can use any supported format (text, JSON, JSON Lines, CSV, Parquet).")},l(u){d=l(u,"P",{});var m=n(d);b=o(m,"The following examples use CSV files, but you can use any supported format (text, JSON, JSON Lines, CSV, Parquet)."),m.forEach(e)},m(u,m){p(u,d,m),s(d,b)},d(u){u&&e(d)}}}function Fa(yt){let d,b,u,m,$t,Y,De,Et,Oe,zt,ot,He,Kt,O,Ie,wt,Ce,Ge,Qt,H,Xt,P,I,gt,W,Fe,xt,Je,Zt,A,Le,bt,qe,Ve,At,Ye,We,te,j,Be,jt,Ue,ze,pt,Ke,Qe,ee,B,se,N,C,St,U,Xe,kt,Ze,ae,G,ts,Mt,es,ss,re,F,z,as,Pt,rs,ls,is,K,ns,Nt,os,ps,le,J,fs,Rt,hs,cs,ie,Q,ne,R,L,Tt,X,us,Dt,ds,oe,S,ms,Ot,vs,_s,Ht,ys,$s,pe,Z,fe,v,Es,It,ws,gs,Ct,xs,bs,Gt,As,js,Ft,Ss,ks,he,ft,Ms,ce,tt,ue,T,q,Jt,et,Ps,Lt,Ns,de,_,Rs,qt,Ts,Ds,Vt,Os,Hs,Yt,Is,Cs,Wt,Gs,Fs,me,st,ve,D,V,Bt,at,Js,Ut,Ls,_e,ht,qs,ye,ct,Vs,$e,rt,Ee,ut,Ys,we,lt,ge;return Y=new _t({}),H=new Ca({props:{$$slots:{default:[Ga]},$$scope:{ctx:yt}}}),W=new _t({}),B=new nt({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train.csv
\u2514\u2500\u2500 test.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 test.<span class="hljs-built_in">csv</span>`}}),U=new _t({}),Q=new nt({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train.csv
    \u251C\u2500\u2500 test.csv
    \u2514\u2500\u2500 valid.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
    \u251C\u2500\u2500 test.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 valid.<span class="hljs-built_in">csv</span>`}}),X=new _t({}),Z=new nt({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train_0.csv
\u251C\u2500\u2500 train_1.csv
\u251C\u2500\u2500 train_2.csv
\u251C\u2500\u2500 train_3.csv
\u251C\u2500\u2500 test_0.csv
\u2514\u2500\u2500 test_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train_0.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_1.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_2.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_3.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 test_0.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 test_1.<span class="hljs-built_in">csv</span>`}}),tt=new nt({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.csv
    \u2502   \u251C\u2500\u2500 shard_1.csv
    \u2502   \u251C\u2500\u2500 shard_2.csv
    \u2502   \u2514\u2500\u2500 shard_3.csv
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.csv
        \u2514\u2500\u2500 shard_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.<span class="hljs-built_in">csv</span>
    \u2502   \u251C\u2500\u2500 shard_1.<span class="hljs-built_in">csv</span>
    \u2502   \u251C\u2500\u2500 shard_2.<span class="hljs-built_in">csv</span>
    \u2502   \u2514\u2500\u2500 shard_3.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.<span class="hljs-built_in">csv</span>
        \u2514\u2500\u2500 shard_1.<span class="hljs-built_in">csv</span>`}}),et=new _t({}),st=new nt({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train-00000-of-00003.csv
    \u251C\u2500\u2500 train-00001-of-00003.csv
    \u251C\u2500\u2500 train-00002-of-00003.csv
    \u251C\u2500\u2500 test-00000-of-00001.csv
    \u251C\u2500\u2500 random-00000-of-00003.csv
    \u251C\u2500\u2500 random-00001-of-00003.csv
    \u2514\u2500\u2500 random-00002-of-00003.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 train<span class="hljs-string">-00001</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 train<span class="hljs-string">-00002</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 test<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00001</span>.csv
    \u251C\u2500\u2500 random<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 random<span class="hljs-string">-00001</span>-of<span class="hljs-string">-00003</span>.csv
    \u2514\u2500\u2500 random<span class="hljs-string">-00002</span>-of<span class="hljs-string">-00003</span>.csv`}}),at=new _t({}),rt=new nt({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train.csv
\u2502   \u2514\u2500\u2500 test.csv
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train.csv
    \u2514\u2500\u2500 test.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
\u2502   \u2514\u2500\u2500 test.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 test.<span class="hljs-built_in">csv</span>`}}),lt=new nt({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train/
\u2502   \u2502   \u251C\u2500\u2500 shard_0.csv
\u2502   \u2502   \u2514\u2500\u2500 shard_1.csv
\u2502   \u2514\u2500\u2500 test/
\u2502       \u251C\u2500\u2500 shard_0.csv
\u2502       \u2514\u2500\u2500 shard_1.csv
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.csv
    \u2502   \u2514\u2500\u2500 shard_1.csv
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.csv
        \u2514\u2500\u2500 shard_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README<span class="hljs-selector-class">.md</span>
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train/
\u2502   \u2502   \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
\u2502   \u2502   \u2514\u2500\u2500 shard_1<span class="hljs-selector-class">.csv</span>
\u2502   \u2514\u2500\u2500 test/
\u2502       \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
\u2502       \u2514\u2500\u2500 shard_1<span class="hljs-selector-class">.csv</span>
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
    \u2502   \u2514\u2500\u2500 shard_1<span class="hljs-selector-class">.csv</span>
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
        \u2514\u2500\u2500 shard_1.csv`}}),{c(){d=r("meta"),b=f(),u=r("h1"),m=r("a"),$t=r("span"),y(Y.$$.fragment),De=f(),Et=r("span"),Oe=i("Structure your repository"),zt=f(),ot=r("p"),He=i("To host and share your dataset, you can create a dataset repository on the Hugging Face Dataset Hub and upload your data files."),Kt=f(),O=r("p"),Ie=i(`This guide will show you how to structure your dataset repository when you upload it.
A dataset with a supported structure can be loaded automatically with `),wt=r("code"),Ce=i("load_dataset"),Ge=i(", and it will have a preview on its dataset page on the Hub."),Qt=f(),y(H.$$.fragment),Xt=f(),P=r("h2"),I=r("a"),gt=r("span"),y(W.$$.fragment),Fe=f(),xt=r("span"),Je=i("Main use-case"),Zt=f(),A=r("p"),Le=i("The simplest dataset structure has two files: "),bt=r("em"),qe=i("train.csv"),Ve=i(" and "),At=r("em"),Ye=i("test.csv"),We=i("."),te=f(),j=r("p"),Be=i("Your repository will also contain a "),jt=r("em"),Ue=i("README.md"),ze=i(" file, the "),pt=r("a"),Ke=i("dataset card"),Qe=i(" displayed on your dataset page."),ee=f(),y(B.$$.fragment),se=f(),N=r("h2"),C=r("a"),St=r("span"),y(U.$$.fragment),Xe=f(),kt=r("span"),Ze=i("Splits and file names"),ae=f(),G=r("p"),ts=i(`\u{1F917} Datasets automatically infers the train/validation/test splits of your dataset from the file names.
All the files that contain `),Mt=r("strong"),es=i("train"),ss=i(" in their names are considered part of the train split. The same idea applies to the test and validation split:"),re=f(),F=r("ul"),z=r("li"),as=i("All the files that contain "),Pt=r("strong"),rs=i("test"),ls=i(" in their names are considered part of the test split."),is=f(),K=r("li"),ns=i("All the files that contain "),Nt=r("strong"),os=i("valid"),ps=i(" in their names are considered part of the validation split."),le=f(),J=r("p"),fs=i("Here is an example where all the files are placed into a directory named "),Rt=r("em"),hs=i("data"),cs=i(":"),ie=f(),y(Q.$$.fragment),ne=f(),R=r("h2"),L=r("a"),Tt=r("span"),y(X.$$.fragment),us=f(),Dt=r("span"),ds=i("Multiple files per split"),oe=f(),S=r("p"),ms=i(`If one of your splits comprises several files, \u{1F917} Datasets can still infer whether it is the train/validation/ test split from the file name.
For example, if your `),Ot=r("strong"),vs=i("train"),_s=i(" and "),Ht=r("strong"),ys=i("test"),$s=i(" splits span several files:"),pe=f(),y(Z.$$.fragment),fe=f(),v=r("p"),Es=i("Just make sure that all the files of your "),It=r("strong"),ws=i("train"),gs=i(" set have "),Ct=r("strong"),xs=i("train"),bs=i(` in their names (same for test and validation).
It doesn\u2019t matter if you add a prefix or suffix to `),Gt=r("strong"),As=i("train"),js=i(" in the file name (like "),Ft=r("em"),Ss=i("my_train_file_00001.csv"),ks=i(`, for example).
\u{1F917} Datasets can still infer the appropriate split.`),he=f(),ft=r("p"),Ms=i("For convenience, you can also place your data files into different directories. In this case, the split name is inferred from the directory name."),ce=f(),y(tt.$$.fragment),ue=f(),T=r("h2"),q=r("a"),Jt=r("span"),y(et.$$.fragment),Ps=f(),Lt=r("span"),Ns=i("Custom split names"),de=f(),_=r("p"),Rs=i(`If you have other data files in addition to the traditional train/validation/test sets, you must use the following structure.
Follow the file name format exactly for this type of structure: `),qt=r("em"),Ts=i("data/<split_name>-xxxxx-of-xxxxx.csv"),Ds=i(`.
Here is an example with three splits: `),Vt=r("strong"),Os=i("train"),Hs=i(", "),Yt=r("strong"),Is=i("test"),Cs=i(", and "),Wt=r("strong"),Gs=i("random"),Fs=i(":"),me=f(),y(st.$$.fragment),ve=f(),D=r("h2"),V=r("a"),Bt=r("span"),y(at.$$.fragment),Js=f(),Ut=r("span"),Ls=i("Multiple configuration (WIP)"),_e=f(),ht=r("p"),qs=i("You can specify different configurations of your dataset (for example, if a dataset contains different languages) with one directory per configuration."),ye=f(),ct=r("p"),Vs=i("These structures are not supported yet, but are a work in progress:"),$e=f(),y(rt.$$.fragment),Ee=f(),ut=r("p"),Ys=i("Or with one directory per split:"),we=f(),y(lt.$$.fragment),this.h()},l(t){const a=Ia('[data-svelte="svelte-1phssyn"]',document.head);d=l(a,"META",{name:!0,content:!0}),a.forEach(e),b=h(t),u=l(t,"H1",{class:!0});var it=n(u);m=l(it,"A",{id:!0,class:!0,href:!0});var Ws=n(m);$t=l(Ws,"SPAN",{});var Bs=n($t);$(Y.$$.fragment,Bs),Bs.forEach(e),Ws.forEach(e),De=h(it),Et=l(it,"SPAN",{});var Us=n(Et);Oe=o(Us,"Structure your repository"),Us.forEach(e),it.forEach(e),zt=h(t),ot=l(t,"P",{});var zs=n(ot);He=o(zs,"To host and share your dataset, you can create a dataset repository on the Hugging Face Dataset Hub and upload your data files."),zs.forEach(e),Kt=h(t),O=l(t,"P",{});var xe=n(O);Ie=o(xe,`This guide will show you how to structure your dataset repository when you upload it.
A dataset with a supported structure can be loaded automatically with `),wt=l(xe,"CODE",{});var Ks=n(wt);Ce=o(Ks,"load_dataset"),Ks.forEach(e),Ge=o(xe,", and it will have a preview on its dataset page on the Hub."),xe.forEach(e),Qt=h(t),$(H.$$.fragment,t),Xt=h(t),P=l(t,"H2",{class:!0});var be=n(P);I=l(be,"A",{id:!0,class:!0,href:!0});var Qs=n(I);gt=l(Qs,"SPAN",{});var Xs=n(gt);$(W.$$.fragment,Xs),Xs.forEach(e),Qs.forEach(e),Fe=h(be),xt=l(be,"SPAN",{});var Zs=n(xt);Je=o(Zs,"Main use-case"),Zs.forEach(e),be.forEach(e),Zt=h(t),A=l(t,"P",{});var dt=n(A);Le=o(dt,"The simplest dataset structure has two files: "),bt=l(dt,"EM",{});var ta=n(bt);qe=o(ta,"train.csv"),ta.forEach(e),Ve=o(dt," and "),At=l(dt,"EM",{});var ea=n(At);Ye=o(ea,"test.csv"),ea.forEach(e),We=o(dt,"."),dt.forEach(e),te=h(t),j=l(t,"P",{});var mt=n(j);Be=o(mt,"Your repository will also contain a "),jt=l(mt,"EM",{});var sa=n(jt);Ue=o(sa,"README.md"),sa.forEach(e),ze=o(mt," file, the "),pt=l(mt,"A",{href:!0});var aa=n(pt);Ke=o(aa,"dataset card"),aa.forEach(e),Qe=o(mt," displayed on your dataset page."),mt.forEach(e),ee=h(t),$(B.$$.fragment,t),se=h(t),N=l(t,"H2",{class:!0});var Ae=n(N);C=l(Ae,"A",{id:!0,class:!0,href:!0});var ra=n(C);St=l(ra,"SPAN",{});var la=n(St);$(U.$$.fragment,la),la.forEach(e),ra.forEach(e),Xe=h(Ae),kt=l(Ae,"SPAN",{});var ia=n(kt);Ze=o(ia,"Splits and file names"),ia.forEach(e),Ae.forEach(e),ae=h(t),G=l(t,"P",{});var je=n(G);ts=o(je,`\u{1F917} Datasets automatically infers the train/validation/test splits of your dataset from the file names.
All the files that contain `),Mt=l(je,"STRONG",{});var na=n(Mt);es=o(na,"train"),na.forEach(e),ss=o(je," in their names are considered part of the train split. The same idea applies to the test and validation split:"),je.forEach(e),re=h(t),F=l(t,"UL",{});var Se=n(F);z=l(Se,"LI",{});var ke=n(z);as=o(ke,"All the files that contain "),Pt=l(ke,"STRONG",{});var oa=n(Pt);rs=o(oa,"test"),oa.forEach(e),ls=o(ke," in their names are considered part of the test split."),ke.forEach(e),is=h(Se),K=l(Se,"LI",{});var Me=n(K);ns=o(Me,"All the files that contain "),Nt=l(Me,"STRONG",{});var pa=n(Nt);os=o(pa,"valid"),pa.forEach(e),ps=o(Me," in their names are considered part of the validation split."),Me.forEach(e),Se.forEach(e),le=h(t),J=l(t,"P",{});var Pe=n(J);fs=o(Pe,"Here is an example where all the files are placed into a directory named "),Rt=l(Pe,"EM",{});var fa=n(Rt);hs=o(fa,"data"),fa.forEach(e),cs=o(Pe,":"),Pe.forEach(e),ie=h(t),$(Q.$$.fragment,t),ne=h(t),R=l(t,"H2",{class:!0});var Ne=n(R);L=l(Ne,"A",{id:!0,class:!0,href:!0});var ha=n(L);Tt=l(ha,"SPAN",{});var ca=n(Tt);$(X.$$.fragment,ca),ca.forEach(e),ha.forEach(e),us=h(Ne),Dt=l(Ne,"SPAN",{});var ua=n(Dt);ds=o(ua,"Multiple files per split"),ua.forEach(e),Ne.forEach(e),oe=h(t),S=l(t,"P",{});var vt=n(S);ms=o(vt,`If one of your splits comprises several files, \u{1F917} Datasets can still infer whether it is the train/validation/ test split from the file name.
For example, if your `),Ot=l(vt,"STRONG",{});var da=n(Ot);vs=o(da,"train"),da.forEach(e),_s=o(vt," and "),Ht=l(vt,"STRONG",{});var ma=n(Ht);ys=o(ma,"test"),ma.forEach(e),$s=o(vt," splits span several files:"),vt.forEach(e),pe=h(t),$(Z.$$.fragment,t),fe=h(t),v=l(t,"P",{});var k=n(v);Es=o(k,"Just make sure that all the files of your "),It=l(k,"STRONG",{});var va=n(It);ws=o(va,"train"),va.forEach(e),gs=o(k," set have "),Ct=l(k,"STRONG",{});var _a=n(Ct);xs=o(_a,"train"),_a.forEach(e),bs=o(k,` in their names (same for test and validation).
It doesn\u2019t matter if you add a prefix or suffix to `),Gt=l(k,"STRONG",{});var ya=n(Gt);As=o(ya,"train"),ya.forEach(e),js=o(k," in the file name (like "),Ft=l(k,"EM",{});var $a=n(Ft);Ss=o($a,"my_train_file_00001.csv"),$a.forEach(e),ks=o(k,`, for example).
\u{1F917} Datasets can still infer the appropriate split.`),k.forEach(e),he=h(t),ft=l(t,"P",{});var Ea=n(ft);Ms=o(Ea,"For convenience, you can also place your data files into different directories. In this case, the split name is inferred from the directory name."),Ea.forEach(e),ce=h(t),$(tt.$$.fragment,t),ue=h(t),T=l(t,"H2",{class:!0});var Re=n(T);q=l(Re,"A",{id:!0,class:!0,href:!0});var wa=n(q);Jt=l(wa,"SPAN",{});var ga=n(Jt);$(et.$$.fragment,ga),ga.forEach(e),wa.forEach(e),Ps=h(Re),Lt=l(Re,"SPAN",{});var xa=n(Lt);Ns=o(xa,"Custom split names"),xa.forEach(e),Re.forEach(e),de=h(t),_=l(t,"P",{});var M=n(_);Rs=o(M,`If you have other data files in addition to the traditional train/validation/test sets, you must use the following structure.
Follow the file name format exactly for this type of structure: `),qt=l(M,"EM",{});var ba=n(qt);Ts=o(ba,"data/<split_name>-xxxxx-of-xxxxx.csv"),ba.forEach(e),Ds=o(M,`.
Here is an example with three splits: `),Vt=l(M,"STRONG",{});var Aa=n(Vt);Os=o(Aa,"train"),Aa.forEach(e),Hs=o(M,", "),Yt=l(M,"STRONG",{});var ja=n(Yt);Is=o(ja,"test"),ja.forEach(e),Cs=o(M,", and "),Wt=l(M,"STRONG",{});var Sa=n(Wt);Gs=o(Sa,"random"),Sa.forEach(e),Fs=o(M,":"),M.forEach(e),me=h(t),$(st.$$.fragment,t),ve=h(t),D=l(t,"H2",{class:!0});var Te=n(D);V=l(Te,"A",{id:!0,class:!0,href:!0});var ka=n(V);Bt=l(ka,"SPAN",{});var Ma=n(Bt);$(at.$$.fragment,Ma),Ma.forEach(e),ka.forEach(e),Js=h(Te),Ut=l(Te,"SPAN",{});var Pa=n(Ut);Ls=o(Pa,"Multiple configuration (WIP)"),Pa.forEach(e),Te.forEach(e),_e=h(t),ht=l(t,"P",{});var Na=n(ht);qs=o(Na,"You can specify different configurations of your dataset (for example, if a dataset contains different languages) with one directory per configuration."),Na.forEach(e),ye=h(t),ct=l(t,"P",{});var Ra=n(ct);Vs=o(Ra,"These structures are not supported yet, but are a work in progress:"),Ra.forEach(e),$e=h(t),$(rt.$$.fragment,t),Ee=h(t),ut=l(t,"P",{});var Ta=n(ut);Ys=o(Ta,"Or with one directory per split:"),Ta.forEach(e),we=h(t),$(lt.$$.fragment,t),this.h()},h(){c(d,"name","hf:doc:metadata"),c(d,"content",JSON.stringify(Ja)),c(m,"id","structure-your-repository"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#structure-your-repository"),c(u,"class","relative group"),c(I,"id","main-usecase"),c(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I,"href","#main-usecase"),c(P,"class","relative group"),c(pt,"href","dataset_card.html"),c(C,"id","splits-and-file-names"),c(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C,"href","#splits-and-file-names"),c(N,"class","relative group"),c(L,"id","multiple-files-per-split"),c(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L,"href","#multiple-files-per-split"),c(R,"class","relative group"),c(q,"id","custom-split-names"),c(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q,"href","#custom-split-names"),c(T,"class","relative group"),c(V,"id","multiple-configuration-wip"),c(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V,"href","#multiple-configuration-wip"),c(D,"class","relative group")},m(t,a){s(document.head,d),p(t,b,a),p(t,u,a),s(u,m),s(m,$t),E(Y,$t,null),s(u,De),s(u,Et),s(Et,Oe),p(t,zt,a),p(t,ot,a),s(ot,He),p(t,Kt,a),p(t,O,a),s(O,Ie),s(O,wt),s(wt,Ce),s(O,Ge),p(t,Qt,a),E(H,t,a),p(t,Xt,a),p(t,P,a),s(P,I),s(I,gt),E(W,gt,null),s(P,Fe),s(P,xt),s(xt,Je),p(t,Zt,a),p(t,A,a),s(A,Le),s(A,bt),s(bt,qe),s(A,Ve),s(A,At),s(At,Ye),s(A,We),p(t,te,a),p(t,j,a),s(j,Be),s(j,jt),s(jt,Ue),s(j,ze),s(j,pt),s(pt,Ke),s(j,Qe),p(t,ee,a),E(B,t,a),p(t,se,a),p(t,N,a),s(N,C),s(C,St),E(U,St,null),s(N,Xe),s(N,kt),s(kt,Ze),p(t,ae,a),p(t,G,a),s(G,ts),s(G,Mt),s(Mt,es),s(G,ss),p(t,re,a),p(t,F,a),s(F,z),s(z,as),s(z,Pt),s(Pt,rs),s(z,ls),s(F,is),s(F,K),s(K,ns),s(K,Nt),s(Nt,os),s(K,ps),p(t,le,a),p(t,J,a),s(J,fs),s(J,Rt),s(Rt,hs),s(J,cs),p(t,ie,a),E(Q,t,a),p(t,ne,a),p(t,R,a),s(R,L),s(L,Tt),E(X,Tt,null),s(R,us),s(R,Dt),s(Dt,ds),p(t,oe,a),p(t,S,a),s(S,ms),s(S,Ot),s(Ot,vs),s(S,_s),s(S,Ht),s(Ht,ys),s(S,$s),p(t,pe,a),E(Z,t,a),p(t,fe,a),p(t,v,a),s(v,Es),s(v,It),s(It,ws),s(v,gs),s(v,Ct),s(Ct,xs),s(v,bs),s(v,Gt),s(Gt,As),s(v,js),s(v,Ft),s(Ft,Ss),s(v,ks),p(t,he,a),p(t,ft,a),s(ft,Ms),p(t,ce,a),E(tt,t,a),p(t,ue,a),p(t,T,a),s(T,q),s(q,Jt),E(et,Jt,null),s(T,Ps),s(T,Lt),s(Lt,Ns),p(t,de,a),p(t,_,a),s(_,Rs),s(_,qt),s(qt,Ts),s(_,Ds),s(_,Vt),s(Vt,Os),s(_,Hs),s(_,Yt),s(Yt,Is),s(_,Cs),s(_,Wt),s(Wt,Gs),s(_,Fs),p(t,me,a),E(st,t,a),p(t,ve,a),p(t,D,a),s(D,V),s(V,Bt),E(at,Bt,null),s(D,Js),s(D,Ut),s(Ut,Ls),p(t,_e,a),p(t,ht,a),s(ht,qs),p(t,ye,a),p(t,ct,a),s(ct,Vs),p(t,$e,a),E(rt,t,a),p(t,Ee,a),p(t,ut,a),s(ut,Ys),p(t,we,a),E(lt,t,a),ge=!0},p(t,[a]){const it={};a&2&&(it.$$scope={dirty:a,ctx:t}),H.$set(it)},i(t){ge||(w(Y.$$.fragment,t),w(H.$$.fragment,t),w(W.$$.fragment,t),w(B.$$.fragment,t),w(U.$$.fragment,t),w(Q.$$.fragment,t),w(X.$$.fragment,t),w(Z.$$.fragment,t),w(tt.$$.fragment,t),w(et.$$.fragment,t),w(st.$$.fragment,t),w(at.$$.fragment,t),w(rt.$$.fragment,t),w(lt.$$.fragment,t),ge=!0)},o(t){g(Y.$$.fragment,t),g(H.$$.fragment,t),g(W.$$.fragment,t),g(B.$$.fragment,t),g(U.$$.fragment,t),g(Q.$$.fragment,t),g(X.$$.fragment,t),g(Z.$$.fragment,t),g(tt.$$.fragment,t),g(et.$$.fragment,t),g(st.$$.fragment,t),g(at.$$.fragment,t),g(rt.$$.fragment,t),g(lt.$$.fragment,t),ge=!1},d(t){e(d),t&&e(b),t&&e(u),x(Y),t&&e(zt),t&&e(ot),t&&e(Kt),t&&e(O),t&&e(Qt),x(H,t),t&&e(Xt),t&&e(P),x(W),t&&e(Zt),t&&e(A),t&&e(te),t&&e(j),t&&e(ee),x(B,t),t&&e(se),t&&e(N),x(U),t&&e(ae),t&&e(G),t&&e(re),t&&e(F),t&&e(le),t&&e(J),t&&e(ie),x(Q,t),t&&e(ne),t&&e(R),x(X),t&&e(oe),t&&e(S),t&&e(pe),x(Z,t),t&&e(fe),t&&e(v),t&&e(he),t&&e(ft),t&&e(ce),x(tt,t),t&&e(ue),t&&e(T),x(et),t&&e(de),t&&e(_),t&&e(me),x(st,t),t&&e(ve),t&&e(D),x(at),t&&e(_e),t&&e(ht),t&&e(ye),t&&e(ct),t&&e($e),x(rt,t),t&&e(Ee),t&&e(ut),t&&e(we),x(lt,t)}}}const Ja={local:"structure-your-repository",sections:[{local:"main-usecase",title:"Main use-case"},{local:"splits-and-file-names",title:"Splits and file names"},{local:"multiple-files-per-split",title:"Multiple files per split"},{local:"custom-split-names",title:"Custom split names"},{local:"multiple-configuration-wip",title:"Multiple configuration (WIP)"}],title:"Structure your repository"};function La(yt,d,b){let{fw:u}=d;return yt.$$set=m=>{"fw"in m&&b(0,u=m.fw)},[u]}class Ba extends Da{constructor(d){super();Oa(this,d,La,Fa,Ha,{fw:0})}}export{Ba as default,Ja as metadata};
