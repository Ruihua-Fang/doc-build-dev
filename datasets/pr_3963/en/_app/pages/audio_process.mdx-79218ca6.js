import{S as Cr,i as Or,s as Sr,e as l,k as d,w as h,t as s,M as Tr,c as r,d as t,m as u,a as n,x as m,h as o,b as c,N as Dr,F as a,g as p,y as _,q as g,o as v,B as w,v as Lr}from"../chunks/vendor-aa873a46.js";import{T as Fr}from"../chunks/Tip-f7f252ab.js";import{I as ka}from"../chunks/IconCopyLink-d0ca3106.js";import{C as b}from"../chunks/CodeBlock-1f14baf3.js";function Ir(rt){let f,Z,$,E,I,j,ve,N,H,ee,z,V,P,we;return{c(){f=l("p"),Z=s("torchaudio\u2019s "),$=l("code"),E=s("sox_io"),I=d(),j=l("a"),ve=s("backend"),N=s(" supports decoding "),H=l("code"),ee=s("mp3"),z=s(" files. Unfortunately, the "),V=l("code"),P=s("sox_io"),we=s(" backend is only available on Linux/macOS, and is not supported by Windows."),this.h()},l(W){f=r(W,"P",{});var y=n(f);Z=o(y,"torchaudio\u2019s "),$=r(y,"CODE",{});var k=n($);E=o(k,"sox_io"),k.forEach(t),I=u(y),j=r(y,"A",{href:!0,rel:!0});var ae=n(j);ve=o(ae,"backend"),ae.forEach(t),N=o(y," supports decoding "),H=r(y,"CODE",{});var ea=n(H);ee=o(ea,"mp3"),ea.forEach(t),z=o(y," files. Unfortunately, the "),V=r(y,"CODE",{});var aa=n(V);P=o(aa,"sox_io"),aa.forEach(t),we=o(y," backend is only available on Linux/macOS, and is not supported by Windows."),y.forEach(t),this.h()},h(){c(j,"href","https://pytorch.org/audio/stable/backend.html#"),c(j,"rel","nofollow")},m(W,y){p(W,f,y),a(f,Z),a(f,$),a($,E),a(f,I),a(f,j),a(j,ve),a(f,N),a(f,H),a(H,ee),a(f,z),a(f,V),a(V,P),a(f,we)},d(W){W&&t(f)}}}function Nr(rt){let f,Z,$,E,I,j,ve,N,H,ee,z,V,P,we,W,y,k,ae,ea,aa,Ea,fs,hs,ye,ms,ta,_s,gs,nt,M,te,za,be,vs,xa,ws,it,D,ys,sa,bs,$s,oa,js,ks,pt,$e,ct,C,Es,je,zs,xs,ke,As,qs,dt,Ee,ut,se,ft,oe,Ps,ze,Ds,Cs,ht,xe,mt,U,le,Aa,Ae,Os,qa,Ss,_t,x,Ts,Pa,Ls,Fs,Da,Is,Ns,Ca,Hs,Vs,gt,qe,Oa,Ws,Ms,vt,Pe,wt,A,Us,Sa,Rs,Ys,Ta,Gs,Js,La,Bs,Ks,yt,R,Fa,Xs,Qs,Ia,Zs,eo,bt,De,$t,O,ao,Na,to,so,la,oo,lo,jt,Ce,kt,Y,re,Ha,Oe,ro,Va,no,Et,S,io,Wa,po,co,Ma,uo,fo,zt,Se,xt,ne,ho,Ua,mo,_o,At,Te,qt,ra,go,Pt,Le,Dt,T,vo,Ra,wo,yo,Ya,bo,$o,Ct,Fe,Ot,ie,jo,Ga,ko,Eo,St,Ie,Tt,pe,zo,Ja,xo,Ao,Lt,G,ce,Ba,Ne,qo,Ka,Po,Ft,L,Do,He,Co,Oo,na,So,To,It,Ve,Nt,de,Lo,ia,Fo,Io,Ht,We,Vt,J,pa,bl,No,ca,$l,Wt,B,ue,Xa,Me,Ho,Qa,Vo,Mt,q,Wo,da,Mo,Uo,Ue,Ro,Yo,Za,Go,Jo,Ut,fe,et,K,Bo,Re,Ko,Xo,at,Qo,Zo,el,Ye,X,al,Ge,tl,sl,tt,ol,ll,rl,Q,nl,Je,il,pl,Be,cl,dl,Rt,Ke,Yt,he,ul,st,fl,hl,Gt,Xe,Jt,F,ml,ot,_l,gl,ua,vl,wl,Bt,Qe,Kt;return j=new ka({}),be=new ka({}),$e=new b({props:{code:"pip install datasets[audio]",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pip install datasets[audio]'}}),Ee=new b({props:{code:`pip install librosa
pip install torchaudio`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pip install librosa
<span class="hljs-meta">&gt;&gt;&gt; </span>pip install torchaudio`}}),se=new Fr({props:{warning:!0,$$slots:{default:[Ir]},$$scope:{ctx:rt}}}),xe=new b({props:{code:`from datasets import load_dataset, load_metric, Audio
common_voice = load_dataset("common_voice", "tr", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric, Audio
<span class="hljs-meta">&gt;&gt;&gt; </span>common_voice = load_dataset(<span class="hljs-string">&quot;common_voice&quot;</span>, <span class="hljs-string">&quot;tr&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Ae=new ka({}),Pe=new b({props:{code:'common_voice[0]["audio"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>common_voice[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.0000000e+00</span>,  <span class="hljs-number">0.0000000e+00</span>,  <span class="hljs-number">0.0000000e+00</span>, ...,
    -<span class="hljs-number">8.8930130e-05</span>, -<span class="hljs-number">3.8027763e-05</span>, -<span class="hljs-number">2.9146671e-05</span>], dtype=float32),
<span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/05be0c29807a73c9b099873d2f5975dae6d05e9f7d577458a2466ecb9a2b0c6b/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_21921195.mp3&#x27;</span>,
<span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">48000</span>}`}}),De=new b({props:{code:'common_voice[0]["path"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>common_voice[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;path&quot;</span>]
/root/.cache/huggingface/datasets/downloads/extracted/05be0c29807a73c9b099873d2f5975dae6d05e9f7d577458a2466ecb9a2b0c6b/cv-corpus-<span class="hljs-number">6.1</span>-<span class="hljs-number">2020</span>-<span class="hljs-number">12</span>-<span class="hljs-number">11</span>/tr/clips/common_voice_tr_21921195.mp3`}}),Ce=new b({props:{code:'my_audio_dataset = my_audio_dataset.cast_column("paths_to_my_audio_files", Audio())',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_audio_dataset = my_audio_dataset.cast_column(<span class="hljs-string">&quot;paths_to_my_audio_files&quot;</span>, Audio())'}}),Oe=new ka({}),Se=new b({props:{code:`audio/1889_1447_000071.flac
audio/1889_1447_000096.flac
audio/1889_1447_000063.flac
audio/1889_1447_000097.flac
...
transcripts.txt`,highlighted:`<span class="hljs-selector-tag">audio</span>/<span class="hljs-number">1889</span>_1447_000071<span class="hljs-selector-class">.flac</span>
<span class="hljs-selector-tag">audio</span>/<span class="hljs-number">1889</span>_1447_000096<span class="hljs-selector-class">.flac</span>
<span class="hljs-selector-tag">audio</span>/<span class="hljs-number">1889</span>_1447_000063<span class="hljs-selector-class">.flac</span>
<span class="hljs-selector-tag">audio</span>/<span class="hljs-number">1889</span>_1447_000097<span class="hljs-selector-class">.flac</span>
...
transcripts<span class="hljs-selector-class">.txt</span>`}}),Te=new b({props:{code:`1889_1447_000071	stali\u015Bmy wszyscy bezradni wobec tej szalej\u0105cej furii z\u0142o\u015Bci kt\xF3ra sama siebie trawi\u0142a i po\u017Cera\u0142a z ubolewaniem patrzyli\u015Bmy na smutny przebieg tego paroksyzmu i z pewn\u0105 ulg\u0105 wr\xF3cili\u015Bmy do naszych zaj\u0119\u0107 gdy \u017Ca\u0142osny ten proces dobieg\u0142 swego naturalnego ko\u0144ca
1889_1447_000096	nawet w obecno\u015Bci matki le\u017C\u0105cej z zawi\u0105zan\u0105 g\u0142ow\u0105 na sofie nie mog\u0142y si\u0119 powstrzyma\u0107 robi\u0142y perskie oczko dawa\u0142y sobie znaki m\xF3wi\u0142y niemym kolorowym alfabetem pe\u0142nym sekretnych znacze\u0144 irytowa\u0142o mnie to szydercze porozumienie ta migotliwa zmowa poza mymi plecami
1889_1447_000063	stali\u015Bmy pod drzwiami i nas\u0142uchiwali w lamentach wichru dawa\u0142y si\u0119 s\u0142ysze\u0107 wszelkie g\u0142osy perswazje nawo\u0142ywania i gaw\u0119dy zdawa\u0142o si\u0119 nam \u017Ce s\u0142yszymy wo\u0142anie o pomoc ojca zb\u0142\u0105kanego w wichurze to znowu \u017Ce brat z teodorem gwarz\u0105 beztrosko pod drzwiami
1889_1447_000097	owego dnia by\u0142 ci\u0119\u017Cki dzie\u0144 zimowy i od rana ju\u017C sypa\u0142 si\u0119 mi\u0119kki puch zmierzchu matka mia\u0142a migren\u0119 i le\u017Ca\u0142a na sofie samotnie w salonie
...`,highlighted:`<span class="hljs-number">1889</span>_1447_000071	stali\u015Bmy wszyscy bezradni wobec tej szalej\u0105cej furii z\u0142o\u015Bci kt\xF3ra sama siebie trawi\u0142<span class="hljs-selector-tag">a</span> <span class="hljs-selector-tag">i</span> po\u017Cera\u0142<span class="hljs-selector-tag">a</span> z ubolewaniem patrzyli\u015Bmy na smutny przebieg tego paroksyzmu <span class="hljs-selector-tag">i</span> z pewn\u0105 ulg\u0105 wr\xF3cili\u015Bmy do naszych zaj\u0119\u0107 gdy \u017C<span class="hljs-selector-tag">a</span>\u0142osny ten proces dobieg\u0142 swego naturalnego ko\u0144ca
<span class="hljs-number">1889</span>_1447_000096	nawet w obecno\u015Bci matki le\u017C\u0105cej z zawi\u0105zan\u0105 g\u0142ow\u0105 na sofie nie mog\u0142y si\u0119 powstrzyma\u0107 robi\u0142y perskie oczko dawa\u0142y sobie znaki m\xF3wi\u0142y niemym kolorowym alfabetem pe\u0142nym sekretnych znacze\u0144 irytowa\u0142o mnie <span class="hljs-selector-tag">to</span> szydercze porozumienie ta migotliwa zmowa poza mymi plecami
<span class="hljs-number">1889</span>_1447_000063	stali\u015Bmy pod drzwiami <span class="hljs-selector-tag">i</span> nas\u0142uchiwali w lamentach wichru dawa\u0142y si\u0119 s\u0142ysze\u0107 wszelkie g\u0142osy perswazje nawo\u0142ywania <span class="hljs-selector-tag">i</span> gaw\u0119dy zdawa\u0142o si\u0119 nam \u017Ce s\u0142yszymy wo\u0142anie o pomoc ojca zb\u0142\u0105kanego w wichurze <span class="hljs-selector-tag">to</span> znowu \u017Ce brat z teodorem gwarz\u0105 beztrosko pod drzwiami
<span class="hljs-number">1889</span>_1447_000097	owego dnia by\u0142 ci\u0119\u017Cki dzie\u0144 zimowy <span class="hljs-selector-tag">i</span> od rana ju\u017C sypa\u0142 si\u0119 mi\u0119kki puch zmierzchu matka mia\u0142<span class="hljs-selector-tag">a</span> migren\u0119 <span class="hljs-selector-tag">i</span> le\u017C<span class="hljs-selector-tag">a</span>\u0142<span class="hljs-selector-tag">a</span> na sofie samotnie w salonie
...`}}),Le=new b({props:{code:`from datasets import load_dataset
dataset = load_dataset("audiofolder", data_dir="/path/to/audiofolder", sampling_rate=16_000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;audiofolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/audiofolder&quot;</span>, sampling_rate=<span class="hljs-number">16_000</span>)`}}),Fe=new b({props:{code:`from datasets import load_dataset
dataset = load_dataset("audiofolder", data_files="/path/to/audioarchive.zip", sampling_rate=16_000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;audiofolder&quot;</span>, data_files=<span class="hljs-string">&quot;/path/to/audioarchive.zip&quot;</span>, sampling_rate=<span class="hljs-number">16_000</span>)`}}),Ie=new b({props:{code:'dataset = load_dataset("audiofolder", data_files="https://huggingface.co/datasets/polinaeterna/test_audiofolder/resolve/main/MLSPolishSample.zip", sampling_rate=16_000)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;audiofolder&quot;</span>, data_files=<span class="hljs-string">&quot;https://huggingface.co/datasets/polinaeterna/test_audiofolder/resolve/main/MLSPolishSample.zip&quot;</span>, sampling_rate=<span class="hljs-number">16_000</span>)'}}),Ne=new ka({}),Ve=new b({props:{code:'common_voice = common_voice.cast_column("audio", Audio(sampling_rate=16_000))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>common_voice = common_voice.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))'}}),We=new b({props:{code:'common_voice_train[0]["audio"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>common_voice_train[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.0000000e+00</span>,  <span class="hljs-number">0.0000000e+00</span>,  <span class="hljs-number">0.0000000e+00</span>, ...,
-<span class="hljs-number">7.4556941e-05</span>, -<span class="hljs-number">1.4621433e-05</span>, -<span class="hljs-number">5.7861507e-05</span>], dtype=float32),
<span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/05be0c29807a73c9b099873d2f5975dae6d05e9f7d577458a2466ecb9a2b0c6b/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_21921195.mp3&#x27;</span>,
<span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`}}),Me=new ka({}),Ke=new b({props:{code:`from transformers import AutoTokenizer, AutoFeatureExtractor, Wav2Vec2Processor
model_checkpoint = "facebook/wav2vec2-large-xlsr-53"
# after defining a vocab.json file you can instantiate a tokenizer object:
tokenizer = AutoTokenizer("./vocab.json", unk_token="[UNK]", pad_token="[PAD]", word_delimiter_token="|")
feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)
processor = Wav2Vec2Processor.from_pretrained(feature_extractor=feature_extractor, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoFeatureExtractor, Wav2Vec2Processor
<span class="hljs-meta">&gt;&gt;&gt; </span>model_checkpoint = <span class="hljs-string">&quot;facebook/wav2vec2-large-xlsr-53&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># after defining a vocab.json file you can instantiate a tokenizer object:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer(<span class="hljs-string">&quot;./vocab.json&quot;</span>, unk_token=<span class="hljs-string">&quot;[UNK]&quot;</span>, pad_token=<span class="hljs-string">&quot;[PAD]&quot;</span>, word_delimiter_token=<span class="hljs-string">&quot;|&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor.from_pretrained(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),Xe=new b({props:{code:`from transformers import Wav2Vec2Processor
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),Qe=new b({props:{code:`def prepare_dataset(batch):
    audio = batch["audio"]
    batch["input_values"] = processor(audio["array"], sampling_rate=audio["sampling_rate"]).input_values[0]
    batch["input_length"] = len(batch["input_values"])
    with processor.as_target_processor():
        batch["labels"] = processor(batch["sentence"]).input_ids
    return batch
common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataset</span>(<span class="hljs-params">batch</span>):
<span class="hljs-meta">... </span>    audio = batch[<span class="hljs-string">&quot;audio&quot;</span>]
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;input_values&quot;</span>] = processor(audio[<span class="hljs-string">&quot;array&quot;</span>], sampling_rate=audio[<span class="hljs-string">&quot;sampling_rate&quot;</span>]).input_values[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;input_length&quot;</span>] = <span class="hljs-built_in">len</span>(batch[<span class="hljs-string">&quot;input_values&quot;</span>])
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> processor.as_target_processor():
<span class="hljs-meta">... </span>        batch[<span class="hljs-string">&quot;labels&quot;</span>] = processor(batch[<span class="hljs-string">&quot;sentence&quot;</span>]).input_ids
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> batch
<span class="hljs-meta">&gt;&gt;&gt; </span>common_voice_train = common_voice_train.<span class="hljs-built_in">map</span>(prepare_dataset, remove_columns=common_voice_train.column_names)`}}),{c(){f=l("meta"),Z=d(),$=l("h1"),E=l("a"),I=l("span"),h(j.$$.fragment),ve=d(),N=l("span"),H=s("Process audio data"),ee=d(),z=l("p"),V=s("\u{1F917} Datasets supports an "),P=l("a"),we=s("Audio"),W=s(" feature, enabling users to load and process raw audio files for training. This guide will show you how to:"),y=d(),k=l("ul"),ae=l("li"),ea=s("Load your own custom audio dataset."),aa=d(),Ea=l("li"),fs=s("Resample audio files."),hs=d(),ye=l("li"),ms=s("Use "),ta=l("a"),_s=s("Dataset.map()"),gs=s(" with audio files."),nt=d(),M=l("h2"),te=l("a"),za=l("span"),h(be.$$.fragment),vs=d(),xa=l("span"),ws=s("Installation"),it=d(),D=l("p"),ys=s("The "),sa=l("a"),bs=s("Audio"),$s=s(" feature is an experimental feature and should be installed as an extra dependency in \u{1F917} Datasets. Install the "),oa=l("a"),js=s("Audio"),ks=s(" feature with pip:"),pt=d(),h($e.$$.fragment),ct=d(),C=l("p"),Es=s("Users should also install "),je=l("a"),zs=s("torchaudio"),xs=s(" and "),ke=l("a"),As=s("librosa"),qs=s(", two common libraries used by \u{1F917} Datasets for handling audio data."),dt=d(),h(Ee.$$.fragment),ut=d(),h(se.$$.fragment),ft=d(),oe=l("p"),Ps=s("Then you can load an audio dataset the same way you would load a text dataset. For example, load the "),ze=l("a"),Ds=s("Common Voice"),Cs=s(" dataset with the Turkish configuration:"),ht=d(),h(xe.$$.fragment),mt=d(),U=l("h2"),le=l("a"),Aa=l("span"),h(Ae.$$.fragment),Os=d(),qa=l("span"),Ss=s("Audio datasets"),_t=d(),x=l("p"),Ts=s("Audio datasets commonly have an "),Pa=l("code"),Ls=s("audio"),Fs=s(" and "),Da=l("code"),Is=s("path"),Ns=s(" or "),Ca=l("code"),Hs=s("file"),Vs=s(" column."),gt=d(),qe=l("p"),Oa=l("code"),Ws=s("audio"),Ms=s(" is the actual audio file that is loaded and resampled on-the-fly upon calling it."),vt=d(),h(Pe.$$.fragment),wt=d(),A=l("p"),Us=s("When you access an audio file, it is automatically decoded and resampled. Generally, you should query an audio file like: "),Sa=l("code"),Rs=s('common_voice[0]["audio"]'),Ys=s(". If you query an audio file with "),Ta=l("code"),Gs=s('common_voice["audio"][0]'),Js=s(" instead, "),La=l("strong"),Bs=s("all"),Ks=s(" the audio files in your dataset will be decoded and resampled. This process can take a long time if you have a large dataset."),yt=d(),R=l("p"),Fa=l("code"),Xs=s("path"),Qs=s(" or "),Ia=l("code"),Zs=s("file"),eo=s(" is an absolute path to an audio file."),bt=d(),h(De.$$.fragment),$t=d(),O=l("p"),ao=s("The "),Na=l("code"),to=s("path"),so=s(" is useful if you want to load your own audio dataset. In this case, provide a column of audio file paths to "),la=l("a"),oo=s("Dataset.cast_column()"),lo=s(":"),jt=d(),h(Ce.$$.fragment),kt=d(),Y=l("h2"),re=l("a"),Ha=l("span"),h(Oe.$$.fragment),ro=d(),Va=l("span"),no=s("AudioFolder"),Et=d(),S=l("p"),io=s("You can load your audio dataset with an "),Wa=l("code"),po=s("AudioFolder"),co=s(` dataset. Your dataset folder / archive should contain audio files and
file with transcriptions (default filename is `),Ma=l("code"),uo=s("transcripts.txt"),fo=s("), for example like this:"),zt=d(),h(Se.$$.fragment),xt=d(),ne=l("p"),ho=s("Transcripts file should contain audio id and corresponding text transcription, separated by "),Ua=l("code"),mo=s('"\\t"'),_o=s(" at each line:"),At=d(),h(Te.$$.fragment),qt=d(),ra=l("p"),go=s("Load a directory:"),Pt=d(),h(Le.$$.fragment),Dt=d(),T=l("p"),vo=s("Load a local "),Ra=l("code"),wo=s(".zip"),yo=s(" archive with the "),Ya=l("code"),bo=s("data_files"),$o=s(" parameter:"),Ct=d(),h(Fe.$$.fragment),Ot=d(),ie=l("p"),jo=s("Load remote datasets from their URLs with the "),Ga=l("code"),ko=s("data_files"),Eo=s(" parameter:"),St=d(),h(Ie.$$.fragment),Tt=d(),pe=l("p"),zo=s("Note that "),Ja=l("code"),xo=s("sampling_rate"),Ao=s(" is a required argument."),Lt=d(),G=l("h2"),ce=l("a"),Ba=l("span"),h(Ne.$$.fragment),qo=d(),Ka=l("span"),Po=s("Resample"),Ft=d(),L=l("p"),Do=s("Some models expect the audio data to have a certain sampling rate due to how the model was pretrained. For example, the "),He=l("a"),Co=s("XLSR-Wav2Vec2"),Oo=s(" model expects the input to have a sampling rate of 16kHz, but an audio file from the Common Voice dataset has a sampling rate of 48kHz. You can use "),na=l("a"),So=s("Dataset.cast_column()"),To=s(" to downsample the sampling rate to 16kHz:"),It=d(),h(Ve.$$.fragment),Nt=d(),de=l("p"),Lo=s("The next time you load the audio file, the "),ia=l("a"),Fo=s("Audio"),Io=s(" feature will load and resample it to 16kHz:"),Ht=d(),h(We.$$.fragment),Vt=d(),J=l("div"),pa=l("img"),No=d(),ca=l("img"),Wt=d(),B=l("h2"),ue=l("a"),Xa=l("span"),h(Me.$$.fragment),Ho=d(),Qa=l("span"),Vo=s("Map"),Mt=d(),q=l("p"),Wo=s("Just like text datasets, you can apply a preprocessing function over an entire dataset with "),da=l("a"),Mo=s("Dataset.map()"),Uo=s(", which is useful for preprocessing all of your audio data at once. Start with a "),Ue=l("a"),Ro=s("speech recognition model"),Yo=s(" of your choice, and load a "),Za=l("code"),Go=s("processor"),Jo=s(" object that contains:"),Ut=d(),fe=l("ol"),et=l("li"),K=l("p"),Bo=s("A feature extractor to convert the speech signal to the model\u2019s input format. Every speech recognition model on the \u{1F917} "),Re=l("a"),Ko=s("Hub"),Xo=s(" contains a predefined feature extractor that can be easily loaded with "),at=l("code"),Qo=s("AutoFeatureExtractor.from_pretrained(...)"),Zo=s("."),el=d(),Ye=l("li"),X=l("p"),al=s("A tokenizer to convert the model\u2019s output format to text. Fine-tuned speech recognition models, such as "),Ge=l("a"),tl=s("facebook/wav2vec2-base-960h"),sl=s(", contain a predefined tokenizer that can be easily loaded with "),tt=l("code"),ol=s("AutoTokenizer.from_pretrained(...)"),ll=s("."),rl=d(),Q=l("p"),nl=s("For pretrained speech recognition models, such as "),Je=l("a"),il=s("facebook/wav2vec2-large-xlsr-53"),pl=s(", a tokenizer needs to be created from the target text as explained "),Be=l("a"),cl=s("here"),dl=s(". The following example demonstrates how to load a feature extractor, tokenizer and processor for a pretrained speech recognition model:"),Rt=d(),h(Ke.$$.fragment),Yt=d(),he=l("p"),ul=s("For fine-tuned speech recognition models, you can simply load a predefined "),st=l("code"),fl=s("processor"),hl=s(" object with:"),Gt=d(),h(Xe.$$.fragment),Jt=d(),F=l("p"),ml=s("Make sure to include the "),ot=l("code"),_l=s("audio"),gl=s(" key in your preprocessing function when you call "),ua=l("a"),vl=s("Dataset.map()"),wl=s(" so that you are actually resampling the audio data:"),Bt=d(),h(Qe.$$.fragment),this.h()},l(e){const i=Tr('[data-svelte="svelte-1phssyn"]',document.head);f=r(i,"META",{name:!0,content:!0}),i.forEach(t),Z=u(e),$=r(e,"H1",{class:!0});var Ze=n($);E=r(Ze,"A",{id:!0,class:!0,href:!0});var jl=n(E);I=r(jl,"SPAN",{});var kl=n(I);m(j.$$.fragment,kl),kl.forEach(t),jl.forEach(t),ve=u(Ze),N=r(Ze,"SPAN",{});var El=n(N);H=o(El,"Process audio data"),El.forEach(t),Ze.forEach(t),ee=u(e),z=r(e,"P",{});var Xt=n(z);V=o(Xt,"\u{1F917} Datasets supports an "),P=r(Xt,"A",{href:!0});var zl=n(P);we=o(zl,"Audio"),zl.forEach(t),W=o(Xt," feature, enabling users to load and process raw audio files for training. This guide will show you how to:"),Xt.forEach(t),y=u(e),k=r(e,"UL",{});var fa=n(k);ae=r(fa,"LI",{});var xl=n(ae);ea=o(xl,"Load your own custom audio dataset."),xl.forEach(t),aa=u(fa),Ea=r(fa,"LI",{});var Al=n(Ea);fs=o(Al,"Resample audio files."),Al.forEach(t),hs=u(fa),ye=r(fa,"LI",{});var Qt=n(ye);ms=o(Qt,"Use "),ta=r(Qt,"A",{href:!0});var ql=n(ta);_s=o(ql,"Dataset.map()"),ql.forEach(t),gs=o(Qt," with audio files."),Qt.forEach(t),fa.forEach(t),nt=u(e),M=r(e,"H2",{class:!0});var Zt=n(M);te=r(Zt,"A",{id:!0,class:!0,href:!0});var Pl=n(te);za=r(Pl,"SPAN",{});var Dl=n(za);m(be.$$.fragment,Dl),Dl.forEach(t),Pl.forEach(t),vs=u(Zt),xa=r(Zt,"SPAN",{});var Cl=n(xa);ws=o(Cl,"Installation"),Cl.forEach(t),Zt.forEach(t),it=u(e),D=r(e,"P",{});var ha=n(D);ys=o(ha,"The "),sa=r(ha,"A",{href:!0});var Ol=n(sa);bs=o(Ol,"Audio"),Ol.forEach(t),$s=o(ha," feature is an experimental feature and should be installed as an extra dependency in \u{1F917} Datasets. Install the "),oa=r(ha,"A",{href:!0});var Sl=n(oa);js=o(Sl,"Audio"),Sl.forEach(t),ks=o(ha," feature with pip:"),ha.forEach(t),pt=u(e),m($e.$$.fragment,e),ct=u(e),C=r(e,"P",{});var ma=n(C);Es=o(ma,"Users should also install "),je=r(ma,"A",{href:!0,rel:!0});var Tl=n(je);zs=o(Tl,"torchaudio"),Tl.forEach(t),xs=o(ma," and "),ke=r(ma,"A",{href:!0,rel:!0});var Ll=n(ke);As=o(Ll,"librosa"),Ll.forEach(t),qs=o(ma,", two common libraries used by \u{1F917} Datasets for handling audio data."),ma.forEach(t),dt=u(e),m(Ee.$$.fragment,e),ut=u(e),m(se.$$.fragment,e),ft=u(e),oe=r(e,"P",{});var es=n(oe);Ps=o(es,"Then you can load an audio dataset the same way you would load a text dataset. For example, load the "),ze=r(es,"A",{href:!0,rel:!0});var Fl=n(ze);Ds=o(Fl,"Common Voice"),Fl.forEach(t),Cs=o(es," dataset with the Turkish configuration:"),es.forEach(t),ht=u(e),m(xe.$$.fragment,e),mt=u(e),U=r(e,"H2",{class:!0});var as=n(U);le=r(as,"A",{id:!0,class:!0,href:!0});var Il=n(le);Aa=r(Il,"SPAN",{});var Nl=n(Aa);m(Ae.$$.fragment,Nl),Nl.forEach(t),Il.forEach(t),Os=u(as),qa=r(as,"SPAN",{});var Hl=n(qa);Ss=o(Hl,"Audio datasets"),Hl.forEach(t),as.forEach(t),_t=u(e),x=r(e,"P",{});var me=n(x);Ts=o(me,"Audio datasets commonly have an "),Pa=r(me,"CODE",{});var Vl=n(Pa);Ls=o(Vl,"audio"),Vl.forEach(t),Fs=o(me," and "),Da=r(me,"CODE",{});var Wl=n(Da);Is=o(Wl,"path"),Wl.forEach(t),Ns=o(me," or "),Ca=r(me,"CODE",{});var Ml=n(Ca);Hs=o(Ml,"file"),Ml.forEach(t),Vs=o(me," column."),me.forEach(t),gt=u(e),qe=r(e,"P",{});var yl=n(qe);Oa=r(yl,"CODE",{});var Ul=n(Oa);Ws=o(Ul,"audio"),Ul.forEach(t),Ms=o(yl," is the actual audio file that is loaded and resampled on-the-fly upon calling it."),yl.forEach(t),vt=u(e),m(Pe.$$.fragment,e),wt=u(e),A=r(e,"P",{});var _e=n(A);Us=o(_e,"When you access an audio file, it is automatically decoded and resampled. Generally, you should query an audio file like: "),Sa=r(_e,"CODE",{});var Rl=n(Sa);Rs=o(Rl,'common_voice[0]["audio"]'),Rl.forEach(t),Ys=o(_e,". If you query an audio file with "),Ta=r(_e,"CODE",{});var Yl=n(Ta);Gs=o(Yl,'common_voice["audio"][0]'),Yl.forEach(t),Js=o(_e," instead, "),La=r(_e,"STRONG",{});var Gl=n(La);Bs=o(Gl,"all"),Gl.forEach(t),Ks=o(_e," the audio files in your dataset will be decoded and resampled. This process can take a long time if you have a large dataset."),_e.forEach(t),yt=u(e),R=r(e,"P",{});var lt=n(R);Fa=r(lt,"CODE",{});var Jl=n(Fa);Xs=o(Jl,"path"),Jl.forEach(t),Qs=o(lt," or "),Ia=r(lt,"CODE",{});var Bl=n(Ia);Zs=o(Bl,"file"),Bl.forEach(t),eo=o(lt," is an absolute path to an audio file."),lt.forEach(t),bt=u(e),m(De.$$.fragment,e),$t=u(e),O=r(e,"P",{});var _a=n(O);ao=o(_a,"The "),Na=r(_a,"CODE",{});var Kl=n(Na);to=o(Kl,"path"),Kl.forEach(t),so=o(_a," is useful if you want to load your own audio dataset. In this case, provide a column of audio file paths to "),la=r(_a,"A",{href:!0});var Xl=n(la);oo=o(Xl,"Dataset.cast_column()"),Xl.forEach(t),lo=o(_a,":"),_a.forEach(t),jt=u(e),m(Ce.$$.fragment,e),kt=u(e),Y=r(e,"H2",{class:!0});var ts=n(Y);re=r(ts,"A",{id:!0,class:!0,href:!0});var Ql=n(re);Ha=r(Ql,"SPAN",{});var Zl=n(Ha);m(Oe.$$.fragment,Zl),Zl.forEach(t),Ql.forEach(t),ro=u(ts),Va=r(ts,"SPAN",{});var er=n(Va);no=o(er,"AudioFolder"),er.forEach(t),ts.forEach(t),Et=u(e),S=r(e,"P",{});var ga=n(S);io=o(ga,"You can load your audio dataset with an "),Wa=r(ga,"CODE",{});var ar=n(Wa);po=o(ar,"AudioFolder"),ar.forEach(t),co=o(ga,` dataset. Your dataset folder / archive should contain audio files and
file with transcriptions (default filename is `),Ma=r(ga,"CODE",{});var tr=n(Ma);uo=o(tr,"transcripts.txt"),tr.forEach(t),fo=o(ga,"), for example like this:"),ga.forEach(t),zt=u(e),m(Se.$$.fragment,e),xt=u(e),ne=r(e,"P",{});var ss=n(ne);ho=o(ss,"Transcripts file should contain audio id and corresponding text transcription, separated by "),Ua=r(ss,"CODE",{});var sr=n(Ua);mo=o(sr,'"\\t"'),sr.forEach(t),_o=o(ss," at each line:"),ss.forEach(t),At=u(e),m(Te.$$.fragment,e),qt=u(e),ra=r(e,"P",{});var or=n(ra);go=o(or,"Load a directory:"),or.forEach(t),Pt=u(e),m(Le.$$.fragment,e),Dt=u(e),T=r(e,"P",{});var va=n(T);vo=o(va,"Load a local "),Ra=r(va,"CODE",{});var lr=n(Ra);wo=o(lr,".zip"),lr.forEach(t),yo=o(va," archive with the "),Ya=r(va,"CODE",{});var rr=n(Ya);bo=o(rr,"data_files"),rr.forEach(t),$o=o(va," parameter:"),va.forEach(t),Ct=u(e),m(Fe.$$.fragment,e),Ot=u(e),ie=r(e,"P",{});var os=n(ie);jo=o(os,"Load remote datasets from their URLs with the "),Ga=r(os,"CODE",{});var nr=n(Ga);ko=o(nr,"data_files"),nr.forEach(t),Eo=o(os," parameter:"),os.forEach(t),St=u(e),m(Ie.$$.fragment,e),Tt=u(e),pe=r(e,"P",{});var ls=n(pe);zo=o(ls,"Note that "),Ja=r(ls,"CODE",{});var ir=n(Ja);xo=o(ir,"sampling_rate"),ir.forEach(t),Ao=o(ls," is a required argument."),ls.forEach(t),Lt=u(e),G=r(e,"H2",{class:!0});var rs=n(G);ce=r(rs,"A",{id:!0,class:!0,href:!0});var pr=n(ce);Ba=r(pr,"SPAN",{});var cr=n(Ba);m(Ne.$$.fragment,cr),cr.forEach(t),pr.forEach(t),qo=u(rs),Ka=r(rs,"SPAN",{});var dr=n(Ka);Po=o(dr,"Resample"),dr.forEach(t),rs.forEach(t),Ft=u(e),L=r(e,"P",{});var wa=n(L);Do=o(wa,"Some models expect the audio data to have a certain sampling rate due to how the model was pretrained. For example, the "),He=r(wa,"A",{href:!0,rel:!0});var ur=n(He);Co=o(ur,"XLSR-Wav2Vec2"),ur.forEach(t),Oo=o(wa," model expects the input to have a sampling rate of 16kHz, but an audio file from the Common Voice dataset has a sampling rate of 48kHz. You can use "),na=r(wa,"A",{href:!0});var fr=n(na);So=o(fr,"Dataset.cast_column()"),fr.forEach(t),To=o(wa," to downsample the sampling rate to 16kHz:"),wa.forEach(t),It=u(e),m(Ve.$$.fragment,e),Nt=u(e),de=r(e,"P",{});var ns=n(de);Lo=o(ns,"The next time you load the audio file, the "),ia=r(ns,"A",{href:!0});var hr=n(ia);Fo=o(hr,"Audio"),hr.forEach(t),Io=o(ns," feature will load and resample it to 16kHz:"),ns.forEach(t),Ht=u(e),m(We.$$.fragment,e),Vt=u(e),J=r(e,"DIV",{class:!0});var is=n(J);pa=r(is,"IMG",{class:!0,src:!0}),No=u(is),ca=r(is,"IMG",{class:!0,src:!0}),is.forEach(t),Wt=u(e),B=r(e,"H2",{class:!0});var ps=n(B);ue=r(ps,"A",{id:!0,class:!0,href:!0});var mr=n(ue);Xa=r(mr,"SPAN",{});var _r=n(Xa);m(Me.$$.fragment,_r),_r.forEach(t),mr.forEach(t),Ho=u(ps),Qa=r(ps,"SPAN",{});var gr=n(Qa);Vo=o(gr,"Map"),gr.forEach(t),ps.forEach(t),Mt=u(e),q=r(e,"P",{});var ge=n(q);Wo=o(ge,"Just like text datasets, you can apply a preprocessing function over an entire dataset with "),da=r(ge,"A",{href:!0});var vr=n(da);Mo=o(vr,"Dataset.map()"),vr.forEach(t),Uo=o(ge,", which is useful for preprocessing all of your audio data at once. Start with a "),Ue=r(ge,"A",{href:!0,rel:!0});var wr=n(Ue);Ro=o(wr,"speech recognition model"),wr.forEach(t),Yo=o(ge," of your choice, and load a "),Za=r(ge,"CODE",{});var yr=n(Za);Go=o(yr,"processor"),yr.forEach(t),Jo=o(ge," object that contains:"),ge.forEach(t),Ut=u(e),fe=r(e,"OL",{});var cs=n(fe);et=r(cs,"LI",{});var br=n(et);K=r(br,"P",{});var ya=n(K);Bo=o(ya,"A feature extractor to convert the speech signal to the model\u2019s input format. Every speech recognition model on the \u{1F917} "),Re=r(ya,"A",{href:!0,rel:!0});var $r=n(Re);Ko=o($r,"Hub"),$r.forEach(t),Xo=o(ya," contains a predefined feature extractor that can be easily loaded with "),at=r(ya,"CODE",{});var jr=n(at);Qo=o(jr,"AutoFeatureExtractor.from_pretrained(...)"),jr.forEach(t),Zo=o(ya,"."),ya.forEach(t),br.forEach(t),el=u(cs),Ye=r(cs,"LI",{});var ds=n(Ye);X=r(ds,"P",{});var ba=n(X);al=o(ba,"A tokenizer to convert the model\u2019s output format to text. Fine-tuned speech recognition models, such as "),Ge=r(ba,"A",{href:!0,rel:!0});var kr=n(Ge);tl=o(kr,"facebook/wav2vec2-base-960h"),kr.forEach(t),sl=o(ba,", contain a predefined tokenizer that can be easily loaded with "),tt=r(ba,"CODE",{});var Er=n(tt);ol=o(Er,"AutoTokenizer.from_pretrained(...)"),Er.forEach(t),ll=o(ba,"."),ba.forEach(t),rl=u(ds),Q=r(ds,"P",{});var $a=n(Q);nl=o($a,"For pretrained speech recognition models, such as "),Je=r($a,"A",{href:!0,rel:!0});var zr=n(Je);il=o(zr,"facebook/wav2vec2-large-xlsr-53"),zr.forEach(t),pl=o($a,", a tokenizer needs to be created from the target text as explained "),Be=r($a,"A",{href:!0,rel:!0});var xr=n(Be);cl=o(xr,"here"),xr.forEach(t),dl=o($a,". The following example demonstrates how to load a feature extractor, tokenizer and processor for a pretrained speech recognition model:"),$a.forEach(t),ds.forEach(t),cs.forEach(t),Rt=u(e),m(Ke.$$.fragment,e),Yt=u(e),he=r(e,"P",{});var us=n(he);ul=o(us,"For fine-tuned speech recognition models, you can simply load a predefined "),st=r(us,"CODE",{});var Ar=n(st);fl=o(Ar,"processor"),Ar.forEach(t),hl=o(us," object with:"),us.forEach(t),Gt=u(e),m(Xe.$$.fragment,e),Jt=u(e),F=r(e,"P",{});var ja=n(F);ml=o(ja,"Make sure to include the "),ot=r(ja,"CODE",{});var qr=n(ot);_l=o(qr,"audio"),qr.forEach(t),gl=o(ja," key in your preprocessing function when you call "),ua=r(ja,"A",{href:!0});var Pr=n(ua);vl=o(Pr,"Dataset.map()"),Pr.forEach(t),wl=o(ja," so that you are actually resampling the audio data:"),ja.forEach(t),Bt=u(e),m(Qe.$$.fragment,e),this.h()},h(){c(f,"name","hf:doc:metadata"),c(f,"content",JSON.stringify(Hr)),c(E,"id","process-audio-data"),c(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E,"href","#process-audio-data"),c($,"class","relative group"),c(P,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Audio"),c(ta,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Dataset.map"),c(te,"id","installation"),c(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(te,"href","#installation"),c(M,"class","relative group"),c(sa,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Audio"),c(oa,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Audio"),c(je,"href","https://pytorch.org/audio/stable/index.html"),c(je,"rel","nofollow"),c(ke,"href","https://librosa.org/doc/latest/index.html"),c(ke,"rel","nofollow"),c(ze,"href","https://huggingface.co/datasets/common_voice"),c(ze,"rel","nofollow"),c(le,"id","audio-datasets"),c(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(le,"href","#audio-datasets"),c(U,"class","relative group"),c(la,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Dataset.cast_column"),c(re,"id","audiofolder"),c(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(re,"href","#audiofolder"),c(Y,"class","relative group"),c(ce,"id","resample"),c(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ce,"href","#resample"),c(G,"class","relative group"),c(He,"href","https://huggingface.co/facebook/wav2vec2-large-xlsr-53"),c(He,"rel","nofollow"),c(na,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Dataset.cast_column"),c(ia,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Audio"),c(pa,"class","block dark:hidden"),Dr(pa.src,bl="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/resample.gif")||c(pa,"src",bl),c(ca,"class","hidden dark:block"),Dr(ca.src,$l="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/resample-dark.gif")||c(ca,"src",$l),c(J,"class","flex justify-center"),c(ue,"id","map"),c(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ue,"href","#map"),c(B,"class","relative group"),c(da,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Dataset.map"),c(Ue,"href","https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads"),c(Ue,"rel","nofollow"),c(Re,"href","https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads"),c(Re,"rel","nofollow"),c(Ge,"href","https://huggingface.co/facebook/wav2vec2-base-960h"),c(Ge,"rel","nofollow"),c(Je,"href","https://huggingface.co/facebook/wav2vec2-large-xlsr-53"),c(Je,"rel","nofollow"),c(Be,"href","https://huggingface.co/blog/fine-tune-wav2vec2-english"),c(Be,"rel","nofollow"),c(ua,"href","/docs/datasets/pr_3963/en/package_reference/main_classes#datasets.Dataset.map")},m(e,i){a(document.head,f),p(e,Z,i),p(e,$,i),a($,E),a(E,I),_(j,I,null),a($,ve),a($,N),a(N,H),p(e,ee,i),p(e,z,i),a(z,V),a(z,P),a(P,we),a(z,W),p(e,y,i),p(e,k,i),a(k,ae),a(ae,ea),a(k,aa),a(k,Ea),a(Ea,fs),a(k,hs),a(k,ye),a(ye,ms),a(ye,ta),a(ta,_s),a(ye,gs),p(e,nt,i),p(e,M,i),a(M,te),a(te,za),_(be,za,null),a(M,vs),a(M,xa),a(xa,ws),p(e,it,i),p(e,D,i),a(D,ys),a(D,sa),a(sa,bs),a(D,$s),a(D,oa),a(oa,js),a(D,ks),p(e,pt,i),_($e,e,i),p(e,ct,i),p(e,C,i),a(C,Es),a(C,je),a(je,zs),a(C,xs),a(C,ke),a(ke,As),a(C,qs),p(e,dt,i),_(Ee,e,i),p(e,ut,i),_(se,e,i),p(e,ft,i),p(e,oe,i),a(oe,Ps),a(oe,ze),a(ze,Ds),a(oe,Cs),p(e,ht,i),_(xe,e,i),p(e,mt,i),p(e,U,i),a(U,le),a(le,Aa),_(Ae,Aa,null),a(U,Os),a(U,qa),a(qa,Ss),p(e,_t,i),p(e,x,i),a(x,Ts),a(x,Pa),a(Pa,Ls),a(x,Fs),a(x,Da),a(Da,Is),a(x,Ns),a(x,Ca),a(Ca,Hs),a(x,Vs),p(e,gt,i),p(e,qe,i),a(qe,Oa),a(Oa,Ws),a(qe,Ms),p(e,vt,i),_(Pe,e,i),p(e,wt,i),p(e,A,i),a(A,Us),a(A,Sa),a(Sa,Rs),a(A,Ys),a(A,Ta),a(Ta,Gs),a(A,Js),a(A,La),a(La,Bs),a(A,Ks),p(e,yt,i),p(e,R,i),a(R,Fa),a(Fa,Xs),a(R,Qs),a(R,Ia),a(Ia,Zs),a(R,eo),p(e,bt,i),_(De,e,i),p(e,$t,i),p(e,O,i),a(O,ao),a(O,Na),a(Na,to),a(O,so),a(O,la),a(la,oo),a(O,lo),p(e,jt,i),_(Ce,e,i),p(e,kt,i),p(e,Y,i),a(Y,re),a(re,Ha),_(Oe,Ha,null),a(Y,ro),a(Y,Va),a(Va,no),p(e,Et,i),p(e,S,i),a(S,io),a(S,Wa),a(Wa,po),a(S,co),a(S,Ma),a(Ma,uo),a(S,fo),p(e,zt,i),_(Se,e,i),p(e,xt,i),p(e,ne,i),a(ne,ho),a(ne,Ua),a(Ua,mo),a(ne,_o),p(e,At,i),_(Te,e,i),p(e,qt,i),p(e,ra,i),a(ra,go),p(e,Pt,i),_(Le,e,i),p(e,Dt,i),p(e,T,i),a(T,vo),a(T,Ra),a(Ra,wo),a(T,yo),a(T,Ya),a(Ya,bo),a(T,$o),p(e,Ct,i),_(Fe,e,i),p(e,Ot,i),p(e,ie,i),a(ie,jo),a(ie,Ga),a(Ga,ko),a(ie,Eo),p(e,St,i),_(Ie,e,i),p(e,Tt,i),p(e,pe,i),a(pe,zo),a(pe,Ja),a(Ja,xo),a(pe,Ao),p(e,Lt,i),p(e,G,i),a(G,ce),a(ce,Ba),_(Ne,Ba,null),a(G,qo),a(G,Ka),a(Ka,Po),p(e,Ft,i),p(e,L,i),a(L,Do),a(L,He),a(He,Co),a(L,Oo),a(L,na),a(na,So),a(L,To),p(e,It,i),_(Ve,e,i),p(e,Nt,i),p(e,de,i),a(de,Lo),a(de,ia),a(ia,Fo),a(de,Io),p(e,Ht,i),_(We,e,i),p(e,Vt,i),p(e,J,i),a(J,pa),a(J,No),a(J,ca),p(e,Wt,i),p(e,B,i),a(B,ue),a(ue,Xa),_(Me,Xa,null),a(B,Ho),a(B,Qa),a(Qa,Vo),p(e,Mt,i),p(e,q,i),a(q,Wo),a(q,da),a(da,Mo),a(q,Uo),a(q,Ue),a(Ue,Ro),a(q,Yo),a(q,Za),a(Za,Go),a(q,Jo),p(e,Ut,i),p(e,fe,i),a(fe,et),a(et,K),a(K,Bo),a(K,Re),a(Re,Ko),a(K,Xo),a(K,at),a(at,Qo),a(K,Zo),a(fe,el),a(fe,Ye),a(Ye,X),a(X,al),a(X,Ge),a(Ge,tl),a(X,sl),a(X,tt),a(tt,ol),a(X,ll),a(Ye,rl),a(Ye,Q),a(Q,nl),a(Q,Je),a(Je,il),a(Q,pl),a(Q,Be),a(Be,cl),a(Q,dl),p(e,Rt,i),_(Ke,e,i),p(e,Yt,i),p(e,he,i),a(he,ul),a(he,st),a(st,fl),a(he,hl),p(e,Gt,i),_(Xe,e,i),p(e,Jt,i),p(e,F,i),a(F,ml),a(F,ot),a(ot,_l),a(F,gl),a(F,ua),a(ua,vl),a(F,wl),p(e,Bt,i),_(Qe,e,i),Kt=!0},p(e,[i]){const Ze={};i&2&&(Ze.$$scope={dirty:i,ctx:e}),se.$set(Ze)},i(e){Kt||(g(j.$$.fragment,e),g(be.$$.fragment,e),g($e.$$.fragment,e),g(Ee.$$.fragment,e),g(se.$$.fragment,e),g(xe.$$.fragment,e),g(Ae.$$.fragment,e),g(Pe.$$.fragment,e),g(De.$$.fragment,e),g(Ce.$$.fragment,e),g(Oe.$$.fragment,e),g(Se.$$.fragment,e),g(Te.$$.fragment,e),g(Le.$$.fragment,e),g(Fe.$$.fragment,e),g(Ie.$$.fragment,e),g(Ne.$$.fragment,e),g(Ve.$$.fragment,e),g(We.$$.fragment,e),g(Me.$$.fragment,e),g(Ke.$$.fragment,e),g(Xe.$$.fragment,e),g(Qe.$$.fragment,e),Kt=!0)},o(e){v(j.$$.fragment,e),v(be.$$.fragment,e),v($e.$$.fragment,e),v(Ee.$$.fragment,e),v(se.$$.fragment,e),v(xe.$$.fragment,e),v(Ae.$$.fragment,e),v(Pe.$$.fragment,e),v(De.$$.fragment,e),v(Ce.$$.fragment,e),v(Oe.$$.fragment,e),v(Se.$$.fragment,e),v(Te.$$.fragment,e),v(Le.$$.fragment,e),v(Fe.$$.fragment,e),v(Ie.$$.fragment,e),v(Ne.$$.fragment,e),v(Ve.$$.fragment,e),v(We.$$.fragment,e),v(Me.$$.fragment,e),v(Ke.$$.fragment,e),v(Xe.$$.fragment,e),v(Qe.$$.fragment,e),Kt=!1},d(e){t(f),e&&t(Z),e&&t($),w(j),e&&t(ee),e&&t(z),e&&t(y),e&&t(k),e&&t(nt),e&&t(M),w(be),e&&t(it),e&&t(D),e&&t(pt),w($e,e),e&&t(ct),e&&t(C),e&&t(dt),w(Ee,e),e&&t(ut),w(se,e),e&&t(ft),e&&t(oe),e&&t(ht),w(xe,e),e&&t(mt),e&&t(U),w(Ae),e&&t(_t),e&&t(x),e&&t(gt),e&&t(qe),e&&t(vt),w(Pe,e),e&&t(wt),e&&t(A),e&&t(yt),e&&t(R),e&&t(bt),w(De,e),e&&t($t),e&&t(O),e&&t(jt),w(Ce,e),e&&t(kt),e&&t(Y),w(Oe),e&&t(Et),e&&t(S),e&&t(zt),w(Se,e),e&&t(xt),e&&t(ne),e&&t(At),w(Te,e),e&&t(qt),e&&t(ra),e&&t(Pt),w(Le,e),e&&t(Dt),e&&t(T),e&&t(Ct),w(Fe,e),e&&t(Ot),e&&t(ie),e&&t(St),w(Ie,e),e&&t(Tt),e&&t(pe),e&&t(Lt),e&&t(G),w(Ne),e&&t(Ft),e&&t(L),e&&t(It),w(Ve,e),e&&t(Nt),e&&t(de),e&&t(Ht),w(We,e),e&&t(Vt),e&&t(J),e&&t(Wt),e&&t(B),w(Me),e&&t(Mt),e&&t(q),e&&t(Ut),e&&t(fe),e&&t(Rt),w(Ke,e),e&&t(Yt),e&&t(he),e&&t(Gt),w(Xe,e),e&&t(Jt),e&&t(F),e&&t(Bt),w(Qe,e)}}}const Hr={local:"process-audio-data",sections:[{local:"installation",title:"Installation"},{local:"audio-datasets",title:"Audio datasets"},{local:"audiofolder",title:"AudioFolder"},{local:"resample",title:"Resample"},{local:"map",title:"Map"}],title:"Process audio data"};function Vr(rt){return Lr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Yr extends Cr{constructor(f){super();Or(this,f,Vr,Nr,Sr,{})}}export{Yr as default,Hr as metadata};
