import{S as Di,i as Ai,s as Ii,e as t,k as c,w as v,t as n,M as Ti,c as l,d as a,m as d,a as p,x as b,h as r,b as h,N as Ei,F as e,g as i,y as $,q as x,o as w,B as y,L as Pi}from"../chunks/vendor-aa873a46.js";import{T as ut}from"../chunks/Tip-f7f252ab.js";import{I as z}from"../chunks/IconCopyLink-d0ca3106.js";import{C as I}from"../chunks/CodeBlock-1f14baf3.js";import{F as qi,M as Si}from"../chunks/Markdown-28d14b5b.js";import"../chunks/IconTensorflow-b9816778.js";function Ci(P){let f,_,m,j,k,g,E,u;return{c(){f=t("p"),_=n("An "),m=t("a"),j=n("datasets.IterableDataset"),k=n(" is useful for iterative jobs like training a model. You shouldn\u2019t use a "),g=t("a"),E=n("datasets.IterableDataset"),u=n(" for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),this.h()},l(D){f=l(D,"P",{});var A=p(f);_=r(A,"An "),m=l(A,"A",{href:!0});var T=p(m);j=r(T,"datasets.IterableDataset"),T.forEach(a),k=r(A," is useful for iterative jobs like training a model. You shouldn\u2019t use a "),g=l(A,"A",{href:!0});var N=p(g);E=r(N,"datasets.IterableDataset"),N.forEach(a),u=r(A," for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),A.forEach(a),this.h()},h(){h(m,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset"),h(g,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset")},m(D,A){i(D,f,A),e(f,_),e(f,m),e(m,j),e(f,k),e(f,g),e(g,E),e(f,u)},d(D){D&&a(f)}}}function zi(P){let f,_,m,j;return{c(){f=t("p"),_=t("a"),m=n("datasets.IterableDataset.shuffle()"),j=n(" will also shuffle the order of the shards if the dataset is sharded into multiple sets."),this.h()},l(k){f=l(k,"P",{});var g=p(f);_=l(g,"A",{href:!0});var E=p(_);m=r(E,"datasets.IterableDataset.shuffle()"),E.forEach(a),j=r(g," will also shuffle the order of the shards if the dataset is sharded into multiple sets."),g.forEach(a),this.h()},h(){h(_,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.shuffle")},m(k,g){i(k,f,g),e(f,_),e(_,m),e(f,j)},d(k){k&&a(f)}}}function Ni(P){let f,_,m,j,k,g,E,u,D,A,T,N,hs;return{c(){f=t("p"),_=t("code"),m=n("take"),j=n(" and "),k=t("code"),g=n("skip"),E=n(" prevent future calls to "),u=t("code"),D=n("shuffle"),A=n(" because they lock in the order of the shards. You should "),T=t("code"),N=n("shuffle"),hs=n(" your dataset before splitting it.")},l(C){f=l(C,"P",{});var q=p(f);_=l(q,"CODE",{});var Da=p(_);m=r(Da,"take"),Da.forEach(a),j=r(q," and "),k=l(q,"CODE",{});var Aa=p(k);g=r(Aa,"skip"),Aa.forEach(a),E=r(q," prevent future calls to "),u=l(q,"CODE",{});var cs=p(u);D=r(cs,"shuffle"),cs.forEach(a),A=r(q," because they lock in the order of the shards. You should "),T=l(q,"CODE",{});var Ia=p(T);N=r(Ia,"shuffle"),Ia.forEach(a),hs=r(q," your dataset before splitting it."),q.forEach(a)},m(C,q){i(C,f,q),e(f,_),e(_,m),e(f,j),e(f,k),e(k,g),e(f,E),e(f,u),e(u,D),e(f,A),e(f,T),e(T,N),e(f,hs)},d(C){C&&a(f)}}}function Mi(P){let f,_,m,j,k,g,E,u;return{c(){f=t("p"),_=n("Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=t("code"),j=n("Value('int32')"),k=n(" to "),g=t("code"),E=n("Value('bool')"),u=n(" if the original column only contains ones and zeros.")},l(D){f=l(D,"P",{});var A=p(f);_=r(A,"Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=l(A,"CODE",{});var T=p(m);j=r(T,"Value('int32')"),T.forEach(a),k=r(A," to "),g=l(A,"CODE",{});var N=p(g);E=r(N,"Value('bool')"),N.forEach(a),u=r(A," if the original column only contains ones and zeros."),A.forEach(a)},m(D,A){i(D,f,A),e(f,_),e(f,m),e(m,j),e(f,k),e(f,g),e(g,E),e(f,u)},d(D){D&&a(f)}}}function Li(P){let f,_,m,j,k;return{c(){f=t("p"),_=n("See other examples of batch processing in the "),m=t("a"),j=n("batched map processing"),k=n(" documentation. They work the same for iterable datasets."),this.h()},l(g){f=l(g,"P",{});var E=p(f);_=r(E,"See other examples of batch processing in the "),m=l(E,"A",{href:!0});var u=p(m);j=r(u,"batched map processing"),u.forEach(a),k=r(E," documentation. They work the same for iterable datasets."),E.forEach(a),this.h()},h(){h(m,"href","./process#batch-processing")},m(g,E){i(g,f,E),e(f,_),e(f,m),e(m,j),e(f,k)},d(g){g&&a(f)}}}function Oi(P){let f,_,m,j,k,g,E;return f=new I({props:{code:`seed, buffer_size = 42, 10_000
dataset = dataset.shuffle(seed, buffer_size=buffer_size)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>seed, buffer_size = <span class="hljs-number">42</span>, <span class="hljs-number">10_000</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.shuffle(seed, buffer_size=buffer_size)`}}),g=new I({props:{code:`import torch
from torch.utils.data import DataLoader
from transformers import AutoModelForMaskedLM, DataCollatorForLanguageModeling
from tqdm import tqdm
dataset = dataset.with_format("torch")
dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
device = 'cuda' if torch.cuda.is_available() else 'cpu' 
model = AutoModelForMaskedLM.from_pretrained("distilbert-base-uncased")
model.train().to(device)
optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)
for epoch in range(3):
    dataset.set_epoch(epoch)
    for i, batch in enumerate(tqdm(dataloader, total=5)):
        if i == 5:
            break
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs[0]
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        if i % 10 == 0:
            print(f"loss: {loss}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM, DataCollatorForLanguageModeling
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
<span class="hljs-meta">&gt;&gt;&gt; </span>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span> 
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.train().to(device)
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = torch.optim.AdamW(params=model.parameters(), lr=<span class="hljs-number">1e-5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):
<span class="hljs-meta">... </span>    dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(dataloader, total=<span class="hljs-number">5</span>)):
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">5</span>:
<span class="hljs-meta">... </span>            <span class="hljs-keyword">break</span>
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>        loss.backward()
<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:
<span class="hljs-meta">... </span>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss: <span class="hljs-subst">{loss}</span>&quot;</span>)`}}),{c(){v(f.$$.fragment),_=c(),m=t("p"),j=n("Lastly, create a simple training loop and start training:"),k=c(),v(g.$$.fragment)},l(u){b(f.$$.fragment,u),_=d(u),m=l(u,"P",{});var D=p(m);j=r(D,"Lastly, create a simple training loop and start training:"),D.forEach(a),k=d(u),b(g.$$.fragment,u)},m(u,D){$(f,u,D),i(u,_,D),i(u,m,D),e(m,j),i(u,k,D),$(g,u,D),E=!0},p:Pi,i(u){E||(x(f.$$.fragment,u),x(g.$$.fragment,u),E=!0)},o(u){w(f.$$.fragment,u),w(g.$$.fragment,u),E=!1},d(u){y(f,u),u&&a(_),u&&a(m),u&&a(k),y(g,u)}}}function Vi(P){let f,_;return f=new Si({props:{$$slots:{default:[Oi]},$$scope:{ctx:P}}}),{c(){v(f.$$.fragment)},l(m){b(f.$$.fragment,m)},m(m,j){$(f,m,j),_=!0},p(m,j){const k={};j&2&&(k.$$scope={dirty:j,ctx:m}),f.$set(k)},i(m){_||(x(f.$$.fragment,m),_=!0)},o(m){w(f.$$.fragment,m),_=!1},d(m){y(f,m)}}}function Fi(P){let f,_,m,j,k,g,E,u,D,A,T,N,hs,C,q,Da,Aa,cs,Ia,gt,J,Ta,Mp,Zl,Pa,Lp,_t,L,sn,Bs,an,en,me,tn,ln,qa,nn,rn,jt,Js,vt,H,pn,Sa,on,hn,Ca,cn,dn,bt,ds,$t,W,fs,ue,Ws,fn,ge,mn,xt,O,un,za,gn,_n,Na,jn,vn,Ma,bn,$n,wt,V,xn,_e,wn,yn,je,kn,En,La,Dn,An,yt,Gs,kt,ms,Et,G,us,ve,Ks,In,be,Tn,Dt,gs,Pn,$e,qn,Sn,At,_s,Cn,xe,zn,Nn,It,Qs,Tt,K,js,we,Xs,Mn,ye,Ln,Pt,Oa,On,qt,Va,vs,Fa,Vn,Fn,ke,Rn,Hn,St,Zs,Ct,Ra,bs,Ha,Yn,Un,Ee,Bn,Jn,zt,sa,Nt,$s,Mt,Ya,Lt,Q,xs,De,aa,Wn,Ae,Gn,Ot,X,Ua,Kn,Qn,Ba,Xn,Zn,Vt,ea,Ft,ws,sr,Ie,ar,er,Rt,ta,Ht,Y,tr,Te,lr,nr,Pe,rr,pr,Yt,Z,ys,qe,la,or,Se,ir,Ut,Ja,hr,Bt,ss,ks,Ce,na,cr,ze,dr,Jt,Es,fr,Ne,mr,ur,Wt,Ds,gr,Me,_r,jr,Gt,ra,Kt,as,As,Le,pa,vr,Oe,br,Qt,Is,$r,Wa,xr,wr,Xt,oa,Zt,es,Ts,Ve,ia,yr,Fe,kr,sl,M,Re,Er,Dr,He,Ar,Ir,Ye,Tr,Pr,Ue,qr,Sr,al,ha,el,Ps,tl,qs,Cr,Ga,zr,Nr,ll,ca,nl,ts,Ss,Be,da,Mr,Je,Lr,rl,S,Or,Ka,Vr,Fr,Qa,Rr,Hr,Xa,Yr,Ur,Za,Br,Jr,se,Wr,Gr,pl,ae,Kr,ol,U,Qr,ee,Xr,Zr,We,sp,ap,il,fa,hl,Cs,ep,te,tp,lp,cl,ma,dl,zs,np,le,rp,pp,fl,B,op,Ge,ip,hp,ne,cp,dp,ml,ua,ul,ls,Ns,Ke,ga,fp,Qe,mp,gl,R,re,up,gp,Xe,_p,jp,Ze,vp,bp,_l,ns,Ms,st,_a,$p,at,xp,jl,ja,vl,Ls,bl,rs,Os,et,va,wp,tt,yp,$l,Vs,kp,pe,Ep,Dp,xl,ba,wl,ps,oe,Ap,Ip,lt,Tp,Pp,yl,$a,kl,os,Fs,nt,xa,qp,rt,Sp,El,wa,ie,Cp,zp,Dl,Rs,Al;return g=new z({}),Js=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
print(next(iter(dataset)))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset)))
{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, which he shared with John Blanchard during his first visit to Malawi. Chief Napoleon conveyed the desperate need for a program to intervene and care for the orphans and vulnerable children (OVC) in Malawi, and John committed to help...</span>`}}),ds=new ut({props:{$$slots:{default:[Ci]},$$scope:{ctx:P}}}),Ws=new z({}),Gs=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
shuffled_dataset = dataset.shuffle(seed=42, buffer_size=10_000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>shuffled_dataset = dataset.shuffle(seed=<span class="hljs-number">42</span>, buffer_size=<span class="hljs-number">10_000</span>)`}}),ms=new ut({props:{$$slots:{default:[zi]},$$scope:{ctx:P}}}),Ks=new z({}),Qs=new I({props:{code:`for epoch in range(epochs):
    shuffled_dataset.set_epoch(epoch)
    for example in shuffled_dataset:
        ...`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):
<span class="hljs-meta">... </span>    shuffled_dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> shuffled_dataset:
<span class="hljs-meta">... </span>        ...`}}),Xs=new z({}),Zs=new I({props:{code:`dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
dataset_head = dataset.take(2)
list(dataset_head)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset_head = dataset.take(<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(dataset_head)
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was...&#x27;</span>}, {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),sa=new I({props:{code:"train_dataset = shuffled_dataset.skip(1000)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataset = shuffled_dataset.skip(<span class="hljs-number">1000</span>)'}}),$s=new ut({props:{warning:"&lcub;true}",$$slots:{default:[Ni]},$$scope:{ctx:P}}}),aa=new z({}),ea=new I({props:{code:`from datasets import interleave_datasets
en_dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
fr_dataset = load_dataset('oscar', "unshuffled_deduplicated_fr", split='train', streaming=True)

multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
list(multilingual_dataset.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> interleave_datasets
<span class="hljs-meta">&gt;&gt;&gt; </span>en_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>fr_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_fr&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&quot;M\xE9dia de d\xE9bat d&#x27;id\xE9es, de culture et de litt\xE9rature...&quot;</span>}]`}}),ta=new I({props:{code:`multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[0.8, 0.2], seed=42)
list(multilingual_dataset_with_oversampling.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[<span class="hljs-number">0.8</span>, <span class="hljs-number">0.2</span>], seed=<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset_with_oversampling.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),la=new z({}),na=new z({}),ra=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.rename_column("text", "content")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.rename_column(<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>)`}}),pa=new z({}),oa=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.remove_columns('timestamp')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.remove_columns(<span class="hljs-string">&#x27;timestamp&#x27;</span>)`}}),ia=new z({}),ha=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('glue', 'mrpc', split='train')features

from datasets import ClassLabel, Value
new_features = dataset.features.copy()
new_features["label"] = ClassLabel(names=['negative', 'positive'])
new_features["idx"] = Value('int64')
dataset = dataset.cast(new_features)
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;glue&#x27;</span>, <span class="hljs-string">&#x27;mrpc&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;not_equivalent&#x27;</span>, <span class="hljs-string">&#x27;equivalent&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> ClassLabel, Value
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features = dataset.features.copy()
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;label&quot;</span>] = ClassLabel(names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;idx&quot;</span>] = Value(<span class="hljs-string">&#x27;int64&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast(new_features)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int64&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),Ps=new ut({props:{$$slots:{default:[Mi]},$$scope:{ctx:P}}}),ca=new I({props:{code:`dataset.features

dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">44100</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">16000</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),da=new z({}),fa=new I({props:{code:`def add_prefix(example):
    example['text'] = 'My text: ' + example['text']
    return example`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_prefix</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    example[<span class="hljs-string">&#x27;text&#x27;</span>] = <span class="hljs-string">&#x27;My text: &#x27;</span> + example[<span class="hljs-string">&#x27;text&#x27;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example`}}),ma=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train')
updated_dataset = dataset.map(add_prefix)
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&#x27;unshuffled_deduplicated_en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),ua=new I({props:{code:`updated_dataset = dataset.map(add_prefix, remove_columns=["id"])
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix, remove_columns=[<span class="hljs-string">&quot;id&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),ga=new z({}),_a=new z({}),ja=new I({props:{code:`from datasets import load_dataset
from transformers import AutoTokenizer
dataset = load_dataset("mc4", "en", streaming=True, split="train")
tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')
def encode(examples):
    return tokenizer(examples['text'], truncation=True, padding='max_length')
dataset = dataset.map(encode, batched=True, remove_columns=["text", "timestamp", "url"])
next(iter(dataset))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;mc4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&#x27;text&#x27;</span>], truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-string">&#x27;max_length&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(encode, batched=<span class="hljs-literal">True</span>, remove_columns=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;timestamp&quot;</span>, <span class="hljs-string">&quot;url&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: <span class="hljs-number">101</span>, <span class="hljs-number">8466</span>, <span class="hljs-number">1018</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">4029</span>, <span class="hljs-number">2475</span>, <span class="hljs-number">2062</span>, <span class="hljs-number">18558</span>, <span class="hljs-number">3100</span>, <span class="hljs-number">2061</span>, ...,<span class="hljs-number">1106</span>, <span class="hljs-number">3739</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, ..., <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Ls=new ut({props:{$$slots:{default:[Li]},$$scope:{ctx:P}}}),va=new z({}),ba=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train')
start_with_ar = dataset.filter(lambda example: example['text'].startswith('Ar'))
next(iter(start_with_ar))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&#x27;unshuffled_deduplicated_en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>start_with_ar = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> example: example[<span class="hljs-string">&#x27;text&#x27;</span>].startswith(<span class="hljs-string">&#x27;Ar&#x27;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(start_with_ar))
{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Are you looking for Number the Stars (Essential Modern Classics)?...&#x27;</span>}`}}),$a=new I({props:{code:`even_dataset = dataset.filter(lambda example, idx: idx % 2 == 0, with_indices=True)
list(even_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>even_dataset = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> example, idx: idx % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>, with_indices=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(even_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, ...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;&quot;I\\&#x27;d love to help kickstart continued development! And 0 EUR/month...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Are you looking for Number the Stars (Essential Modern Classics)? Normally, ...&#x27;</span>}]`}}),xa=new z({}),Rs=new qi({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[Vi]},$$scope:{ctx:P}}}),{c(){f=t("meta"),_=c(),m=t("h1"),j=t("a"),k=t("span"),v(g.$$.fragment),E=c(),u=t("span"),D=n("Stream"),A=c(),T=t("p"),N=n("Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),hs=c(),C=t("ul"),q=t("li"),Da=n("You don\u2019t want to wait for an extremely large dataset to download."),Aa=c(),cs=t("li"),Ia=n("The dataset size exceeds the amount of disk space on your computer."),gt=c(),J=t("div"),Ta=t("img"),Zl=c(),Pa=t("img"),_t=c(),L=t("p"),sn=n("For example, the English split of the "),Bs=t("a"),an=n("OSCAR"),en=n(" dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),me=t("code"),tn=n("streaming=True"),ln=n(" in "),qa=t("a"),nn=n("datasets.load_dataset()"),rn=n(" as shown below:"),jt=c(),v(Js.$$.fragment),vt=c(),H=t("p"),pn=n("Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Sa=t("a"),on=n("datasets.Dataset"),hn=n(" object), known as an "),Ca=t("a"),cn=n("datasets.IterableDataset"),dn=n(". This special type of dataset has its own set of processing methods shown below."),bt=c(),v(ds.$$.fragment),$t=c(),W=t("h2"),fs=t("a"),ue=t("span"),v(Ws.$$.fragment),fn=c(),ge=t("span"),mn=n("Shuffle"),xt=c(),O=t("p"),un=n("Like a regular "),za=t("a"),gn=n("datasets.Dataset"),_n=n(" object, you can also shuffle a "),Na=t("a"),jn=n("datasets.IterableDataset"),vn=n(" with "),Ma=t("a"),bn=n("datasets.IterableDataset.shuffle()"),$n=n("."),wt=c(),V=t("p"),xn=n("The "),_e=t("code"),wn=n("buffer_size"),yn=n(" argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),je=t("code"),kn=n("buffer_size"),En=n(" to ten thousand. "),La=t("a"),Dn=n("datasets.IterableDataset.shuffle()"),An=n(" will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),yt=c(),v(Gs.$$.fragment),kt=c(),v(ms.$$.fragment),Et=c(),G=t("h2"),us=t("a"),ve=t("span"),v(Ks.$$.fragment),In=c(),be=t("span"),Tn=n("Reshuffle"),Dt=c(),gs=t("p"),Pn=n("Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),$e=t("code"),qn=n("datasets.IterableDataset.set_epoch()"),Sn=n("in between epochs to tell the dataset what epoch you\u2019re on."),At=c(),_s=t("p"),Cn=n("Your seed effectively becomes: "),xe=t("code"),zn=n("initial seed + current epoch"),Nn=n("."),It=c(),v(Qs.$$.fragment),Tt=c(),K=t("h2"),js=t("a"),we=t("span"),v(Xs.$$.fragment),Mn=c(),ye=t("span"),Ln=n("Split dataset"),Pt=c(),Oa=t("p"),On=n("You can split your dataset one of two ways:"),qt=c(),Va=t("ul"),vs=t("li"),Fa=t("a"),Vn=n("datasets.IterableDataset.take()"),Fn=n(" returns the first "),ke=t("code"),Rn=n("n"),Hn=n(" examples in a dataset:"),St=c(),v(Zs.$$.fragment),Ct=c(),Ra=t("ul"),bs=t("li"),Ha=t("a"),Yn=n("datasets.IterableDataset.skip()"),Un=n(" omits the first "),Ee=t("code"),Bn=n("n"),Jn=n(" examples in a dataset and returns the remaining examples:"),zt=c(),v(sa.$$.fragment),Nt=c(),v($s.$$.fragment),Mt=c(),Ya=t("a"),Lt=c(),Q=t("h2"),xs=t("a"),De=t("span"),v(aa.$$.fragment),Wn=c(),Ae=t("span"),Gn=n("Interleave"),Ot=c(),X=t("p"),Ua=t("a"),Kn=n("datasets.interleave_datasets()"),Qn=n(" can combine an "),Ba=t("a"),Xn=n("datasets.IterableDataset"),Zn=n(" with other datasets. The combined dataset returns alternating examples from each of the original datasets."),Vt=c(),v(ea.$$.fragment),Ft=c(),ws=t("p"),sr=n("Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),Ie=t("code"),ar=n("probabilities"),er=n(" argument with your desired sampling probabilities:"),Rt=c(),v(ta.$$.fragment),Ht=c(),Y=t("p"),tr=n("Around 80% of the final dataset is made of the "),Te=t("code"),lr=n("en_dataset"),nr=n(", and 20% of the "),Pe=t("code"),rr=n("fr_dataset"),pr=n("."),Yt=c(),Z=t("h2"),ys=t("a"),qe=t("span"),v(la.$$.fragment),or=c(),Se=t("span"),ir=n("Rename, remove, and cast"),Ut=c(),Ja=t("p"),hr=n("The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),Bt=c(),ss=t("h3"),ks=t("a"),Ce=t("span"),v(na.$$.fragment),cr=c(),ze=t("span"),dr=n("Rename"),Jt=c(),Es=t("p"),fr=n("Use "),Ne=t("code"),mr=n("datasets.IterableDataset.rename_column()"),ur=n("when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),Wt=c(),Ds=t("p"),gr=n("Provide "),Me=t("code"),_r=n("datasets.IterableDataset.rename_column()"),jr=n("with the name of the original column, and the new column name:"),Gt=c(),v(ra.$$.fragment),Kt=c(),as=t("h3"),As=t("a"),Le=t("span"),v(pa.$$.fragment),vr=c(),Oe=t("span"),br=n("Remove"),Qt=c(),Is=t("p"),$r=n("When you need to remove one or more columns, give "),Wa=t("a"),xr=n("datasets.IterableDataset.remove_columns()"),wr=n(" the name of the column to remove. Remove more than one column by providing a list of column names:"),Xt=c(),v(oa.$$.fragment),Zt=c(),es=t("h3"),Ts=t("a"),Ve=t("span"),v(ia.$$.fragment),yr=c(),Fe=t("span"),kr=n("Cast"),sl=c(),M=t("p"),Re=t("code"),Er=n("datasets.IterableDataset.cast()"),Dr=n("changes the feature type of one or more columns. This method takes your new "),He=t("code"),Ar=n("datasets.Features"),Ir=n(" as its argument. The following sample code shows how to change the feature types of "),Ye=t("code"),Tr=n("datasets.ClassLabel"),Pr=n(" and "),Ue=t("code"),qr=n("datasets.Value"),Sr=n(":"),al=c(),v(ha.$$.fragment),el=c(),v(Ps.$$.fragment),tl=c(),qs=t("p"),Cr=n("Use "),Ga=t("a"),zr=n("datasets.Dataset.cast_column()"),Nr=n(" to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),ll=c(),v(ca.$$.fragment),nl=c(),ts=t("h2"),Ss=t("a"),Be=t("span"),v(da.$$.fragment),Mr=c(),Je=t("span"),Lr=n("Map"),rl=c(),S=t("p"),Or=n("Similar to the "),Ka=t("a"),Vr=n("datasets.Dataset.map()"),Fr=n(" function for a regular "),Qa=t("a"),Rr=n("datasets.Dataset"),Hr=n(", \u{1F917}  Datasets features "),Xa=t("a"),Yr=n("datasets.IterableDataset.map()"),Ur=n(" for processing an "),Za=t("a"),Br=n("datasets.IterableDataset"),Jr=n(`.
`),se=t("a"),Wr=n("datasets.IterableDataset.map()"),Gr=n(" applies processing on-the-fly when examples are streamed."),pl=c(),ae=t("p"),Kr=n("It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),ol=c(),U=t("p"),Qr=n("The following example demonstrates how to tokenize a "),ee=t("a"),Xr=n("datasets.IterableDataset"),Zr=n(". The function needs to accept and output a "),We=t("code"),sp=n("dict"),ap=n(":"),il=c(),v(fa.$$.fragment),hl=c(),Cs=t("p"),ep=n("Next, apply this function to the dataset with "),te=t("a"),tp=n("datasets.IterableDataset.map()"),lp=n(":"),cl=c(),v(ma.$$.fragment),dl=c(),zs=t("p"),np=n("Let\u2019s take a look at another example, except this time, you will remove a column with "),le=t("a"),rp=n("datasets.IterableDataset.map()"),pp=n(". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),fl=c(),B=t("p"),op=n("Specify the column to remove with the "),Ge=t("code"),ip=n("remove_columns"),hp=n(" argument in "),ne=t("a"),cp=n("datasets.IterableDataset.map()"),dp=n(":"),ml=c(),v(ua.$$.fragment),ul=c(),ls=t("h3"),Ns=t("a"),Ke=t("span"),v(ga.$$.fragment),fp=c(),Qe=t("span"),mp=n("Batch processing"),gl=c(),R=t("p"),re=t("a"),up=n("datasets.IterableDataset.map()"),gp=n(" also supports working with batches of examples. Operate on batches by setting "),Xe=t("code"),_p=n("batched=True"),jp=n(". The default batch size is 1000, but you can adjust it with the "),Ze=t("code"),vp=n("batch_size"),bp=n(" argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),_l=c(),ns=t("h4"),Ms=t("a"),st=t("span"),v(_a.$$.fragment),$p=c(),at=t("span"),xp=n("Tokenization"),jl=c(),v(ja.$$.fragment),vl=c(),v(Ls.$$.fragment),bl=c(),rs=t("h3"),Os=t("a"),et=t("span"),v(va.$$.fragment),wp=c(),tt=t("span"),yp=n("Filter"),$l=c(),Vs=t("p"),kp=n("You can filter rows in the dataset based on a predicate function using "),pe=t("a"),Ep=n("datasets.Dataset.filter()"),Dp=n(". It returns rows that match a specified condition:"),xl=c(),v(ba.$$.fragment),wl=c(),ps=t("p"),oe=t("a"),Ap=n("datasets.Dataset.filter()"),Ip=n(" can also filter by indices if you set "),lt=t("code"),Tp=n("with_indices=True"),Pp=n(":"),yl=c(),v($a.$$.fragment),kl=c(),os=t("h2"),Fs=t("a"),nt=t("span"),v(xa.$$.fragment),qp=c(),rt=t("span"),Sp=n("Stream in a training loop"),El=c(),wa=t("p"),ie=t("a"),Cp=n("datasets.IterableDataset"),zp=n(" can be integrated into a training loop. First, shuffle the dataset:"),Dl=c(),v(Rs.$$.fragment),this.h()},l(s){const o=Ti('[data-svelte="svelte-1phssyn"]',document.head);f=l(o,"META",{name:!0,content:!0}),o.forEach(a),_=d(s),m=l(s,"H1",{class:!0});var ya=p(m);j=l(ya,"A",{id:!0,class:!0,href:!0});var pt=p(j);k=l(pt,"SPAN",{});var ot=p(k);b(g.$$.fragment,ot),ot.forEach(a),pt.forEach(a),E=d(ya),u=l(ya,"SPAN",{});var it=p(u);D=r(it,"Stream"),it.forEach(a),ya.forEach(a),A=d(s),T=l(s,"P",{});var ht=p(T);N=r(ht,"Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),ht.forEach(a),hs=d(s),C=l(s,"UL",{});var ka=p(C);q=l(ka,"LI",{});var Op=p(q);Da=r(Op,"You don\u2019t want to wait for an extremely large dataset to download."),Op.forEach(a),Aa=d(ka),cs=l(ka,"LI",{});var Vp=p(cs);Ia=r(Vp,"The dataset size exceeds the amount of disk space on your computer."),Vp.forEach(a),ka.forEach(a),gt=d(s),J=l(s,"DIV",{class:!0});var Il=p(J);Ta=l(Il,"IMG",{class:!0,src:!0}),Zl=d(Il),Pa=l(Il,"IMG",{class:!0,src:!0}),Il.forEach(a),_t=d(s),L=l(s,"P",{});var Hs=p(L);sn=r(Hs,"For example, the English split of the "),Bs=l(Hs,"A",{href:!0,rel:!0});var Fp=p(Bs);an=r(Fp,"OSCAR"),Fp.forEach(a),en=r(Hs," dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),me=l(Hs,"CODE",{});var Rp=p(me);tn=r(Rp,"streaming=True"),Rp.forEach(a),ln=r(Hs," in "),qa=l(Hs,"A",{href:!0});var Hp=p(qa);nn=r(Hp,"datasets.load_dataset()"),Hp.forEach(a),rn=r(Hs," as shown below:"),Hs.forEach(a),jt=d(s),b(Js.$$.fragment,s),vt=d(s),H=l(s,"P",{});var he=p(H);pn=r(he,"Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Sa=l(he,"A",{href:!0});var Yp=p(Sa);on=r(Yp,"datasets.Dataset"),Yp.forEach(a),hn=r(he," object), known as an "),Ca=l(he,"A",{href:!0});var Up=p(Ca);cn=r(Up,"datasets.IterableDataset"),Up.forEach(a),dn=r(he,". This special type of dataset has its own set of processing methods shown below."),he.forEach(a),bt=d(s),b(ds.$$.fragment,s),$t=d(s),W=l(s,"H2",{class:!0});var Tl=p(W);fs=l(Tl,"A",{id:!0,class:!0,href:!0});var Bp=p(fs);ue=l(Bp,"SPAN",{});var Jp=p(ue);b(Ws.$$.fragment,Jp),Jp.forEach(a),Bp.forEach(a),fn=d(Tl),ge=l(Tl,"SPAN",{});var Wp=p(ge);mn=r(Wp,"Shuffle"),Wp.forEach(a),Tl.forEach(a),xt=d(s),O=l(s,"P",{});var Ys=p(O);un=r(Ys,"Like a regular "),za=l(Ys,"A",{href:!0});var Gp=p(za);gn=r(Gp,"datasets.Dataset"),Gp.forEach(a),_n=r(Ys," object, you can also shuffle a "),Na=l(Ys,"A",{href:!0});var Kp=p(Na);jn=r(Kp,"datasets.IterableDataset"),Kp.forEach(a),vn=r(Ys," with "),Ma=l(Ys,"A",{href:!0});var Qp=p(Ma);bn=r(Qp,"datasets.IterableDataset.shuffle()"),Qp.forEach(a),$n=r(Ys,"."),Ys.forEach(a),wt=d(s),V=l(s,"P",{});var Us=p(V);xn=r(Us,"The "),_e=l(Us,"CODE",{});var Xp=p(_e);wn=r(Xp,"buffer_size"),Xp.forEach(a),yn=r(Us," argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),je=l(Us,"CODE",{});var Zp=p(je);kn=r(Zp,"buffer_size"),Zp.forEach(a),En=r(Us," to ten thousand. "),La=l(Us,"A",{href:!0});var so=p(La);Dn=r(so,"datasets.IterableDataset.shuffle()"),so.forEach(a),An=r(Us," will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),Us.forEach(a),yt=d(s),b(Gs.$$.fragment,s),kt=d(s),b(ms.$$.fragment,s),Et=d(s),G=l(s,"H2",{class:!0});var Pl=p(G);us=l(Pl,"A",{id:!0,class:!0,href:!0});var ao=p(us);ve=l(ao,"SPAN",{});var eo=p(ve);b(Ks.$$.fragment,eo),eo.forEach(a),ao.forEach(a),In=d(Pl),be=l(Pl,"SPAN",{});var to=p(be);Tn=r(to,"Reshuffle"),to.forEach(a),Pl.forEach(a),Dt=d(s),gs=l(s,"P",{});var ql=p(gs);Pn=r(ql,"Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),$e=l(ql,"CODE",{});var lo=p($e);qn=r(lo,"datasets.IterableDataset.set_epoch()"),lo.forEach(a),Sn=r(ql,"in between epochs to tell the dataset what epoch you\u2019re on."),ql.forEach(a),At=d(s),_s=l(s,"P",{});var Sl=p(_s);Cn=r(Sl,"Your seed effectively becomes: "),xe=l(Sl,"CODE",{});var no=p(xe);zn=r(no,"initial seed + current epoch"),no.forEach(a),Nn=r(Sl,"."),Sl.forEach(a),It=d(s),b(Qs.$$.fragment,s),Tt=d(s),K=l(s,"H2",{class:!0});var Cl=p(K);js=l(Cl,"A",{id:!0,class:!0,href:!0});var ro=p(js);we=l(ro,"SPAN",{});var po=p(we);b(Xs.$$.fragment,po),po.forEach(a),ro.forEach(a),Mn=d(Cl),ye=l(Cl,"SPAN",{});var oo=p(ye);Ln=r(oo,"Split dataset"),oo.forEach(a),Cl.forEach(a),Pt=d(s),Oa=l(s,"P",{});var io=p(Oa);On=r(io,"You can split your dataset one of two ways:"),io.forEach(a),qt=d(s),Va=l(s,"UL",{});var ho=p(Va);vs=l(ho,"LI",{});var ct=p(vs);Fa=l(ct,"A",{href:!0});var co=p(Fa);Vn=r(co,"datasets.IterableDataset.take()"),co.forEach(a),Fn=r(ct," returns the first "),ke=l(ct,"CODE",{});var fo=p(ke);Rn=r(fo,"n"),fo.forEach(a),Hn=r(ct," examples in a dataset:"),ct.forEach(a),ho.forEach(a),St=d(s),b(Zs.$$.fragment,s),Ct=d(s),Ra=l(s,"UL",{});var mo=p(Ra);bs=l(mo,"LI",{});var dt=p(bs);Ha=l(dt,"A",{href:!0});var uo=p(Ha);Yn=r(uo,"datasets.IterableDataset.skip()"),uo.forEach(a),Un=r(dt," omits the first "),Ee=l(dt,"CODE",{});var go=p(Ee);Bn=r(go,"n"),go.forEach(a),Jn=r(dt," examples in a dataset and returns the remaining examples:"),dt.forEach(a),mo.forEach(a),zt=d(s),b(sa.$$.fragment,s),Nt=d(s),b($s.$$.fragment,s),Mt=d(s),Ya=l(s,"A",{id:!0}),p(Ya).forEach(a),Lt=d(s),Q=l(s,"H2",{class:!0});var zl=p(Q);xs=l(zl,"A",{id:!0,class:!0,href:!0});var _o=p(xs);De=l(_o,"SPAN",{});var jo=p(De);b(aa.$$.fragment,jo),jo.forEach(a),_o.forEach(a),Wn=d(zl),Ae=l(zl,"SPAN",{});var vo=p(Ae);Gn=r(vo,"Interleave"),vo.forEach(a),zl.forEach(a),Ot=d(s),X=l(s,"P",{});var ft=p(X);Ua=l(ft,"A",{href:!0});var bo=p(Ua);Kn=r(bo,"datasets.interleave_datasets()"),bo.forEach(a),Qn=r(ft," can combine an "),Ba=l(ft,"A",{href:!0});var $o=p(Ba);Xn=r($o,"datasets.IterableDataset"),$o.forEach(a),Zn=r(ft," with other datasets. The combined dataset returns alternating examples from each of the original datasets."),ft.forEach(a),Vt=d(s),b(ea.$$.fragment,s),Ft=d(s),ws=l(s,"P",{});var Nl=p(ws);sr=r(Nl,"Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),Ie=l(Nl,"CODE",{});var xo=p(Ie);ar=r(xo,"probabilities"),xo.forEach(a),er=r(Nl," argument with your desired sampling probabilities:"),Nl.forEach(a),Rt=d(s),b(ta.$$.fragment,s),Ht=d(s),Y=l(s,"P",{});var ce=p(Y);tr=r(ce,"Around 80% of the final dataset is made of the "),Te=l(ce,"CODE",{});var wo=p(Te);lr=r(wo,"en_dataset"),wo.forEach(a),nr=r(ce,", and 20% of the "),Pe=l(ce,"CODE",{});var yo=p(Pe);rr=r(yo,"fr_dataset"),yo.forEach(a),pr=r(ce,"."),ce.forEach(a),Yt=d(s),Z=l(s,"H2",{class:!0});var Ml=p(Z);ys=l(Ml,"A",{id:!0,class:!0,href:!0});var ko=p(ys);qe=l(ko,"SPAN",{});var Eo=p(qe);b(la.$$.fragment,Eo),Eo.forEach(a),ko.forEach(a),or=d(Ml),Se=l(Ml,"SPAN",{});var Do=p(Se);ir=r(Do,"Rename, remove, and cast"),Do.forEach(a),Ml.forEach(a),Ut=d(s),Ja=l(s,"P",{});var Ao=p(Ja);hr=r(Ao,"The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),Ao.forEach(a),Bt=d(s),ss=l(s,"H3",{class:!0});var Ll=p(ss);ks=l(Ll,"A",{id:!0,class:!0,href:!0});var Io=p(ks);Ce=l(Io,"SPAN",{});var To=p(Ce);b(na.$$.fragment,To),To.forEach(a),Io.forEach(a),cr=d(Ll),ze=l(Ll,"SPAN",{});var Po=p(ze);dr=r(Po,"Rename"),Po.forEach(a),Ll.forEach(a),Jt=d(s),Es=l(s,"P",{});var Ol=p(Es);fr=r(Ol,"Use "),Ne=l(Ol,"CODE",{});var qo=p(Ne);mr=r(qo,"datasets.IterableDataset.rename_column()"),qo.forEach(a),ur=r(Ol,"when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),Ol.forEach(a),Wt=d(s),Ds=l(s,"P",{});var Vl=p(Ds);gr=r(Vl,"Provide "),Me=l(Vl,"CODE",{});var So=p(Me);_r=r(So,"datasets.IterableDataset.rename_column()"),So.forEach(a),jr=r(Vl,"with the name of the original column, and the new column name:"),Vl.forEach(a),Gt=d(s),b(ra.$$.fragment,s),Kt=d(s),as=l(s,"H3",{class:!0});var Fl=p(as);As=l(Fl,"A",{id:!0,class:!0,href:!0});var Co=p(As);Le=l(Co,"SPAN",{});var zo=p(Le);b(pa.$$.fragment,zo),zo.forEach(a),Co.forEach(a),vr=d(Fl),Oe=l(Fl,"SPAN",{});var No=p(Oe);br=r(No,"Remove"),No.forEach(a),Fl.forEach(a),Qt=d(s),Is=l(s,"P",{});var Rl=p(Is);$r=r(Rl,"When you need to remove one or more columns, give "),Wa=l(Rl,"A",{href:!0});var Mo=p(Wa);xr=r(Mo,"datasets.IterableDataset.remove_columns()"),Mo.forEach(a),wr=r(Rl," the name of the column to remove. Remove more than one column by providing a list of column names:"),Rl.forEach(a),Xt=d(s),b(oa.$$.fragment,s),Zt=d(s),es=l(s,"H3",{class:!0});var Hl=p(es);Ts=l(Hl,"A",{id:!0,class:!0,href:!0});var Lo=p(Ts);Ve=l(Lo,"SPAN",{});var Oo=p(Ve);b(ia.$$.fragment,Oo),Oo.forEach(a),Lo.forEach(a),yr=d(Hl),Fe=l(Hl,"SPAN",{});var Vo=p(Fe);kr=r(Vo,"Cast"),Vo.forEach(a),Hl.forEach(a),sl=d(s),M=l(s,"P",{});var is=p(M);Re=l(is,"CODE",{});var Fo=p(Re);Er=r(Fo,"datasets.IterableDataset.cast()"),Fo.forEach(a),Dr=r(is,"changes the feature type of one or more columns. This method takes your new "),He=l(is,"CODE",{});var Ro=p(He);Ar=r(Ro,"datasets.Features"),Ro.forEach(a),Ir=r(is," as its argument. The following sample code shows how to change the feature types of "),Ye=l(is,"CODE",{});var Ho=p(Ye);Tr=r(Ho,"datasets.ClassLabel"),Ho.forEach(a),Pr=r(is," and "),Ue=l(is,"CODE",{});var Yo=p(Ue);qr=r(Yo,"datasets.Value"),Yo.forEach(a),Sr=r(is,":"),is.forEach(a),al=d(s),b(ha.$$.fragment,s),el=d(s),b(Ps.$$.fragment,s),tl=d(s),qs=l(s,"P",{});var Yl=p(qs);Cr=r(Yl,"Use "),Ga=l(Yl,"A",{href:!0});var Uo=p(Ga);zr=r(Uo,"datasets.Dataset.cast_column()"),Uo.forEach(a),Nr=r(Yl," to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),Yl.forEach(a),ll=d(s),b(ca.$$.fragment,s),nl=d(s),ts=l(s,"H2",{class:!0});var Ul=p(ts);Ss=l(Ul,"A",{id:!0,class:!0,href:!0});var Bo=p(Ss);Be=l(Bo,"SPAN",{});var Jo=p(Be);b(da.$$.fragment,Jo),Jo.forEach(a),Bo.forEach(a),Mr=d(Ul),Je=l(Ul,"SPAN",{});var Wo=p(Je);Lr=r(Wo,"Map"),Wo.forEach(a),Ul.forEach(a),rl=d(s),S=l(s,"P",{});var F=p(S);Or=r(F,"Similar to the "),Ka=l(F,"A",{href:!0});var Go=p(Ka);Vr=r(Go,"datasets.Dataset.map()"),Go.forEach(a),Fr=r(F," function for a regular "),Qa=l(F,"A",{href:!0});var Ko=p(Qa);Rr=r(Ko,"datasets.Dataset"),Ko.forEach(a),Hr=r(F,", \u{1F917}  Datasets features "),Xa=l(F,"A",{href:!0});var Qo=p(Xa);Yr=r(Qo,"datasets.IterableDataset.map()"),Qo.forEach(a),Ur=r(F," for processing an "),Za=l(F,"A",{href:!0});var Xo=p(Za);Br=r(Xo,"datasets.IterableDataset"),Xo.forEach(a),Jr=r(F,`.
`),se=l(F,"A",{href:!0});var Zo=p(se);Wr=r(Zo,"datasets.IterableDataset.map()"),Zo.forEach(a),Gr=r(F," applies processing on-the-fly when examples are streamed."),F.forEach(a),pl=d(s),ae=l(s,"P",{});var si=p(ae);Kr=r(si,"It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),si.forEach(a),ol=d(s),U=l(s,"P",{});var de=p(U);Qr=r(de,"The following example demonstrates how to tokenize a "),ee=l(de,"A",{href:!0});var ai=p(ee);Xr=r(ai,"datasets.IterableDataset"),ai.forEach(a),Zr=r(de,". The function needs to accept and output a "),We=l(de,"CODE",{});var ei=p(We);sp=r(ei,"dict"),ei.forEach(a),ap=r(de,":"),de.forEach(a),il=d(s),b(fa.$$.fragment,s),hl=d(s),Cs=l(s,"P",{});var Bl=p(Cs);ep=r(Bl,"Next, apply this function to the dataset with "),te=l(Bl,"A",{href:!0});var ti=p(te);tp=r(ti,"datasets.IterableDataset.map()"),ti.forEach(a),lp=r(Bl,":"),Bl.forEach(a),cl=d(s),b(ma.$$.fragment,s),dl=d(s),zs=l(s,"P",{});var Jl=p(zs);np=r(Jl,"Let\u2019s take a look at another example, except this time, you will remove a column with "),le=l(Jl,"A",{href:!0});var li=p(le);rp=r(li,"datasets.IterableDataset.map()"),li.forEach(a),pp=r(Jl,". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),Jl.forEach(a),fl=d(s),B=l(s,"P",{});var fe=p(B);op=r(fe,"Specify the column to remove with the "),Ge=l(fe,"CODE",{});var ni=p(Ge);ip=r(ni,"remove_columns"),ni.forEach(a),hp=r(fe," argument in "),ne=l(fe,"A",{href:!0});var ri=p(ne);cp=r(ri,"datasets.IterableDataset.map()"),ri.forEach(a),dp=r(fe,":"),fe.forEach(a),ml=d(s),b(ua.$$.fragment,s),ul=d(s),ls=l(s,"H3",{class:!0});var Wl=p(ls);Ns=l(Wl,"A",{id:!0,class:!0,href:!0});var pi=p(Ns);Ke=l(pi,"SPAN",{});var oi=p(Ke);b(ga.$$.fragment,oi),oi.forEach(a),pi.forEach(a),fp=d(Wl),Qe=l(Wl,"SPAN",{});var ii=p(Qe);mp=r(ii,"Batch processing"),ii.forEach(a),Wl.forEach(a),gl=d(s),R=l(s,"P",{});var Ea=p(R);re=l(Ea,"A",{href:!0});var hi=p(re);up=r(hi,"datasets.IterableDataset.map()"),hi.forEach(a),gp=r(Ea," also supports working with batches of examples. Operate on batches by setting "),Xe=l(Ea,"CODE",{});var ci=p(Xe);_p=r(ci,"batched=True"),ci.forEach(a),jp=r(Ea,". The default batch size is 1000, but you can adjust it with the "),Ze=l(Ea,"CODE",{});var di=p(Ze);vp=r(di,"batch_size"),di.forEach(a),bp=r(Ea," argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),Ea.forEach(a),_l=d(s),ns=l(s,"H4",{class:!0});var Gl=p(ns);Ms=l(Gl,"A",{id:!0,class:!0,href:!0});var fi=p(Ms);st=l(fi,"SPAN",{});var mi=p(st);b(_a.$$.fragment,mi),mi.forEach(a),fi.forEach(a),$p=d(Gl),at=l(Gl,"SPAN",{});var ui=p(at);xp=r(ui,"Tokenization"),ui.forEach(a),Gl.forEach(a),jl=d(s),b(ja.$$.fragment,s),vl=d(s),b(Ls.$$.fragment,s),bl=d(s),rs=l(s,"H3",{class:!0});var Kl=p(rs);Os=l(Kl,"A",{id:!0,class:!0,href:!0});var gi=p(Os);et=l(gi,"SPAN",{});var _i=p(et);b(va.$$.fragment,_i),_i.forEach(a),gi.forEach(a),wp=d(Kl),tt=l(Kl,"SPAN",{});var ji=p(tt);yp=r(ji,"Filter"),ji.forEach(a),Kl.forEach(a),$l=d(s),Vs=l(s,"P",{});var Ql=p(Vs);kp=r(Ql,"You can filter rows in the dataset based on a predicate function using "),pe=l(Ql,"A",{href:!0});var vi=p(pe);Ep=r(vi,"datasets.Dataset.filter()"),vi.forEach(a),Dp=r(Ql,". It returns rows that match a specified condition:"),Ql.forEach(a),xl=d(s),b(ba.$$.fragment,s),wl=d(s),ps=l(s,"P",{});var mt=p(ps);oe=l(mt,"A",{href:!0});var bi=p(oe);Ap=r(bi,"datasets.Dataset.filter()"),bi.forEach(a),Ip=r(mt," can also filter by indices if you set "),lt=l(mt,"CODE",{});var $i=p(lt);Tp=r($i,"with_indices=True"),$i.forEach(a),Pp=r(mt,":"),mt.forEach(a),yl=d(s),b($a.$$.fragment,s),kl=d(s),os=l(s,"H2",{class:!0});var Xl=p(os);Fs=l(Xl,"A",{id:!0,class:!0,href:!0});var xi=p(Fs);nt=l(xi,"SPAN",{});var wi=p(nt);b(xa.$$.fragment,wi),wi.forEach(a),xi.forEach(a),qp=d(Xl),rt=l(Xl,"SPAN",{});var yi=p(rt);Sp=r(yi,"Stream in a training loop"),yi.forEach(a),Xl.forEach(a),El=d(s),wa=l(s,"P",{});var Np=p(wa);ie=l(Np,"A",{href:!0});var ki=p(ie);Cp=r(ki,"datasets.IterableDataset"),ki.forEach(a),zp=r(Np," can be integrated into a training loop. First, shuffle the dataset:"),Np.forEach(a),Dl=d(s),b(Rs.$$.fragment,s),this.h()},h(){h(f,"name","hf:doc:metadata"),h(f,"content",JSON.stringify(Ri)),h(j,"id","stream"),h(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(j,"href","#stream"),h(m,"class","relative group"),h(Ta,"class","block dark:hidden"),Ei(Ta.src,Mp="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming.gif")||h(Ta,"src",Mp),h(Pa,"class","hidden dark:block"),Ei(Pa.src,Lp="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming-dark.gif")||h(Pa,"src",Lp),h(J,"class","flex justify-center"),h(Bs,"href","https://huggingface.co/datasets/oscar"),h(Bs,"rel","nofollow"),h(qa,"href","/docs/datasets/pr_3926/en/package_reference/loading_methods#datasets.load_dataset"),h(Sa,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.Dataset"),h(Ca,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset"),h(fs,"id","shuffle"),h(fs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(fs,"href","#shuffle"),h(W,"class","relative group"),h(za,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.Dataset"),h(Na,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset"),h(Ma,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(La,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(us,"id","reshuffle"),h(us,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(us,"href","#reshuffle"),h(G,"class","relative group"),h(js,"id","split-dataset"),h(js,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(js,"href","#split-dataset"),h(K,"class","relative group"),h(Fa,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.take"),h(Ha,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.skip"),h(Ya,"id","interleave_datasets"),h(xs,"id","interleave"),h(xs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(xs,"href","#interleave"),h(Q,"class","relative group"),h(Ua,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.interleave_datasets"),h(Ba,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset"),h(ys,"id","rename-remove-and-cast"),h(ys,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ys,"href","#rename-remove-and-cast"),h(Z,"class","relative group"),h(ks,"id","rename"),h(ks,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ks,"href","#rename"),h(ss,"class","relative group"),h(As,"id","remove"),h(As,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(As,"href","#remove"),h(as,"class","relative group"),h(Wa,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.remove_columns"),h(Ts,"id","cast"),h(Ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ts,"href","#cast"),h(es,"class","relative group"),h(Ga,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.Dataset.cast_column"),h(Ss,"id","map"),h(Ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ss,"href","#map"),h(ts,"class","relative group"),h(Ka,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.Dataset.map"),h(Qa,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.Dataset"),h(Xa,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Za,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset"),h(se,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.map"),h(ee,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset"),h(te,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.map"),h(le,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.map"),h(ne,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Ns,"id","batch-processing"),h(Ns,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ns,"href","#batch-processing"),h(ls,"class","relative group"),h(re,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Ms,"id","tokenization"),h(Ms,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ms,"href","#tokenization"),h(ns,"class","relative group"),h(Os,"id","filter"),h(Os,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Os,"href","#filter"),h(rs,"class","relative group"),h(pe,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.Dataset.filter"),h(oe,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.Dataset.filter"),h(Fs,"id","stream-in-a-training-loop"),h(Fs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Fs,"href","#stream-in-a-training-loop"),h(os,"class","relative group"),h(ie,"href","/docs/datasets/pr_3926/en/package_reference/main_classes#datasets.IterableDataset")},m(s,o){e(document.head,f),i(s,_,o),i(s,m,o),e(m,j),e(j,k),$(g,k,null),e(m,E),e(m,u),e(u,D),i(s,A,o),i(s,T,o),e(T,N),i(s,hs,o),i(s,C,o),e(C,q),e(q,Da),e(C,Aa),e(C,cs),e(cs,Ia),i(s,gt,o),i(s,J,o),e(J,Ta),e(J,Zl),e(J,Pa),i(s,_t,o),i(s,L,o),e(L,sn),e(L,Bs),e(Bs,an),e(L,en),e(L,me),e(me,tn),e(L,ln),e(L,qa),e(qa,nn),e(L,rn),i(s,jt,o),$(Js,s,o),i(s,vt,o),i(s,H,o),e(H,pn),e(H,Sa),e(Sa,on),e(H,hn),e(H,Ca),e(Ca,cn),e(H,dn),i(s,bt,o),$(ds,s,o),i(s,$t,o),i(s,W,o),e(W,fs),e(fs,ue),$(Ws,ue,null),e(W,fn),e(W,ge),e(ge,mn),i(s,xt,o),i(s,O,o),e(O,un),e(O,za),e(za,gn),e(O,_n),e(O,Na),e(Na,jn),e(O,vn),e(O,Ma),e(Ma,bn),e(O,$n),i(s,wt,o),i(s,V,o),e(V,xn),e(V,_e),e(_e,wn),e(V,yn),e(V,je),e(je,kn),e(V,En),e(V,La),e(La,Dn),e(V,An),i(s,yt,o),$(Gs,s,o),i(s,kt,o),$(ms,s,o),i(s,Et,o),i(s,G,o),e(G,us),e(us,ve),$(Ks,ve,null),e(G,In),e(G,be),e(be,Tn),i(s,Dt,o),i(s,gs,o),e(gs,Pn),e(gs,$e),e($e,qn),e(gs,Sn),i(s,At,o),i(s,_s,o),e(_s,Cn),e(_s,xe),e(xe,zn),e(_s,Nn),i(s,It,o),$(Qs,s,o),i(s,Tt,o),i(s,K,o),e(K,js),e(js,we),$(Xs,we,null),e(K,Mn),e(K,ye),e(ye,Ln),i(s,Pt,o),i(s,Oa,o),e(Oa,On),i(s,qt,o),i(s,Va,o),e(Va,vs),e(vs,Fa),e(Fa,Vn),e(vs,Fn),e(vs,ke),e(ke,Rn),e(vs,Hn),i(s,St,o),$(Zs,s,o),i(s,Ct,o),i(s,Ra,o),e(Ra,bs),e(bs,Ha),e(Ha,Yn),e(bs,Un),e(bs,Ee),e(Ee,Bn),e(bs,Jn),i(s,zt,o),$(sa,s,o),i(s,Nt,o),$($s,s,o),i(s,Mt,o),i(s,Ya,o),i(s,Lt,o),i(s,Q,o),e(Q,xs),e(xs,De),$(aa,De,null),e(Q,Wn),e(Q,Ae),e(Ae,Gn),i(s,Ot,o),i(s,X,o),e(X,Ua),e(Ua,Kn),e(X,Qn),e(X,Ba),e(Ba,Xn),e(X,Zn),i(s,Vt,o),$(ea,s,o),i(s,Ft,o),i(s,ws,o),e(ws,sr),e(ws,Ie),e(Ie,ar),e(ws,er),i(s,Rt,o),$(ta,s,o),i(s,Ht,o),i(s,Y,o),e(Y,tr),e(Y,Te),e(Te,lr),e(Y,nr),e(Y,Pe),e(Pe,rr),e(Y,pr),i(s,Yt,o),i(s,Z,o),e(Z,ys),e(ys,qe),$(la,qe,null),e(Z,or),e(Z,Se),e(Se,ir),i(s,Ut,o),i(s,Ja,o),e(Ja,hr),i(s,Bt,o),i(s,ss,o),e(ss,ks),e(ks,Ce),$(na,Ce,null),e(ss,cr),e(ss,ze),e(ze,dr),i(s,Jt,o),i(s,Es,o),e(Es,fr),e(Es,Ne),e(Ne,mr),e(Es,ur),i(s,Wt,o),i(s,Ds,o),e(Ds,gr),e(Ds,Me),e(Me,_r),e(Ds,jr),i(s,Gt,o),$(ra,s,o),i(s,Kt,o),i(s,as,o),e(as,As),e(As,Le),$(pa,Le,null),e(as,vr),e(as,Oe),e(Oe,br),i(s,Qt,o),i(s,Is,o),e(Is,$r),e(Is,Wa),e(Wa,xr),e(Is,wr),i(s,Xt,o),$(oa,s,o),i(s,Zt,o),i(s,es,o),e(es,Ts),e(Ts,Ve),$(ia,Ve,null),e(es,yr),e(es,Fe),e(Fe,kr),i(s,sl,o),i(s,M,o),e(M,Re),e(Re,Er),e(M,Dr),e(M,He),e(He,Ar),e(M,Ir),e(M,Ye),e(Ye,Tr),e(M,Pr),e(M,Ue),e(Ue,qr),e(M,Sr),i(s,al,o),$(ha,s,o),i(s,el,o),$(Ps,s,o),i(s,tl,o),i(s,qs,o),e(qs,Cr),e(qs,Ga),e(Ga,zr),e(qs,Nr),i(s,ll,o),$(ca,s,o),i(s,nl,o),i(s,ts,o),e(ts,Ss),e(Ss,Be),$(da,Be,null),e(ts,Mr),e(ts,Je),e(Je,Lr),i(s,rl,o),i(s,S,o),e(S,Or),e(S,Ka),e(Ka,Vr),e(S,Fr),e(S,Qa),e(Qa,Rr),e(S,Hr),e(S,Xa),e(Xa,Yr),e(S,Ur),e(S,Za),e(Za,Br),e(S,Jr),e(S,se),e(se,Wr),e(S,Gr),i(s,pl,o),i(s,ae,o),e(ae,Kr),i(s,ol,o),i(s,U,o),e(U,Qr),e(U,ee),e(ee,Xr),e(U,Zr),e(U,We),e(We,sp),e(U,ap),i(s,il,o),$(fa,s,o),i(s,hl,o),i(s,Cs,o),e(Cs,ep),e(Cs,te),e(te,tp),e(Cs,lp),i(s,cl,o),$(ma,s,o),i(s,dl,o),i(s,zs,o),e(zs,np),e(zs,le),e(le,rp),e(zs,pp),i(s,fl,o),i(s,B,o),e(B,op),e(B,Ge),e(Ge,ip),e(B,hp),e(B,ne),e(ne,cp),e(B,dp),i(s,ml,o),$(ua,s,o),i(s,ul,o),i(s,ls,o),e(ls,Ns),e(Ns,Ke),$(ga,Ke,null),e(ls,fp),e(ls,Qe),e(Qe,mp),i(s,gl,o),i(s,R,o),e(R,re),e(re,up),e(R,gp),e(R,Xe),e(Xe,_p),e(R,jp),e(R,Ze),e(Ze,vp),e(R,bp),i(s,_l,o),i(s,ns,o),e(ns,Ms),e(Ms,st),$(_a,st,null),e(ns,$p),e(ns,at),e(at,xp),i(s,jl,o),$(ja,s,o),i(s,vl,o),$(Ls,s,o),i(s,bl,o),i(s,rs,o),e(rs,Os),e(Os,et),$(va,et,null),e(rs,wp),e(rs,tt),e(tt,yp),i(s,$l,o),i(s,Vs,o),e(Vs,kp),e(Vs,pe),e(pe,Ep),e(Vs,Dp),i(s,xl,o),$(ba,s,o),i(s,wl,o),i(s,ps,o),e(ps,oe),e(oe,Ap),e(ps,Ip),e(ps,lt),e(lt,Tp),e(ps,Pp),i(s,yl,o),$($a,s,o),i(s,kl,o),i(s,os,o),e(os,Fs),e(Fs,nt),$(xa,nt,null),e(os,qp),e(os,rt),e(rt,Sp),i(s,El,o),i(s,wa,o),e(wa,ie),e(ie,Cp),e(wa,zp),i(s,Dl,o),$(Rs,s,o),Al=!0},p(s,[o]){const ya={};o&2&&(ya.$$scope={dirty:o,ctx:s}),ds.$set(ya);const pt={};o&2&&(pt.$$scope={dirty:o,ctx:s}),ms.$set(pt);const ot={};o&2&&(ot.$$scope={dirty:o,ctx:s}),$s.$set(ot);const it={};o&2&&(it.$$scope={dirty:o,ctx:s}),Ps.$set(it);const ht={};o&2&&(ht.$$scope={dirty:o,ctx:s}),Ls.$set(ht);const ka={};o&2&&(ka.$$scope={dirty:o,ctx:s}),Rs.$set(ka)},i(s){Al||(x(g.$$.fragment,s),x(Js.$$.fragment,s),x(ds.$$.fragment,s),x(Ws.$$.fragment,s),x(Gs.$$.fragment,s),x(ms.$$.fragment,s),x(Ks.$$.fragment,s),x(Qs.$$.fragment,s),x(Xs.$$.fragment,s),x(Zs.$$.fragment,s),x(sa.$$.fragment,s),x($s.$$.fragment,s),x(aa.$$.fragment,s),x(ea.$$.fragment,s),x(ta.$$.fragment,s),x(la.$$.fragment,s),x(na.$$.fragment,s),x(ra.$$.fragment,s),x(pa.$$.fragment,s),x(oa.$$.fragment,s),x(ia.$$.fragment,s),x(ha.$$.fragment,s),x(Ps.$$.fragment,s),x(ca.$$.fragment,s),x(da.$$.fragment,s),x(fa.$$.fragment,s),x(ma.$$.fragment,s),x(ua.$$.fragment,s),x(ga.$$.fragment,s),x(_a.$$.fragment,s),x(ja.$$.fragment,s),x(Ls.$$.fragment,s),x(va.$$.fragment,s),x(ba.$$.fragment,s),x($a.$$.fragment,s),x(xa.$$.fragment,s),x(Rs.$$.fragment,s),Al=!0)},o(s){w(g.$$.fragment,s),w(Js.$$.fragment,s),w(ds.$$.fragment,s),w(Ws.$$.fragment,s),w(Gs.$$.fragment,s),w(ms.$$.fragment,s),w(Ks.$$.fragment,s),w(Qs.$$.fragment,s),w(Xs.$$.fragment,s),w(Zs.$$.fragment,s),w(sa.$$.fragment,s),w($s.$$.fragment,s),w(aa.$$.fragment,s),w(ea.$$.fragment,s),w(ta.$$.fragment,s),w(la.$$.fragment,s),w(na.$$.fragment,s),w(ra.$$.fragment,s),w(pa.$$.fragment,s),w(oa.$$.fragment,s),w(ia.$$.fragment,s),w(ha.$$.fragment,s),w(Ps.$$.fragment,s),w(ca.$$.fragment,s),w(da.$$.fragment,s),w(fa.$$.fragment,s),w(ma.$$.fragment,s),w(ua.$$.fragment,s),w(ga.$$.fragment,s),w(_a.$$.fragment,s),w(ja.$$.fragment,s),w(Ls.$$.fragment,s),w(va.$$.fragment,s),w(ba.$$.fragment,s),w($a.$$.fragment,s),w(xa.$$.fragment,s),w(Rs.$$.fragment,s),Al=!1},d(s){a(f),s&&a(_),s&&a(m),y(g),s&&a(A),s&&a(T),s&&a(hs),s&&a(C),s&&a(gt),s&&a(J),s&&a(_t),s&&a(L),s&&a(jt),y(Js,s),s&&a(vt),s&&a(H),s&&a(bt),y(ds,s),s&&a($t),s&&a(W),y(Ws),s&&a(xt),s&&a(O),s&&a(wt),s&&a(V),s&&a(yt),y(Gs,s),s&&a(kt),y(ms,s),s&&a(Et),s&&a(G),y(Ks),s&&a(Dt),s&&a(gs),s&&a(At),s&&a(_s),s&&a(It),y(Qs,s),s&&a(Tt),s&&a(K),y(Xs),s&&a(Pt),s&&a(Oa),s&&a(qt),s&&a(Va),s&&a(St),y(Zs,s),s&&a(Ct),s&&a(Ra),s&&a(zt),y(sa,s),s&&a(Nt),y($s,s),s&&a(Mt),s&&a(Ya),s&&a(Lt),s&&a(Q),y(aa),s&&a(Ot),s&&a(X),s&&a(Vt),y(ea,s),s&&a(Ft),s&&a(ws),s&&a(Rt),y(ta,s),s&&a(Ht),s&&a(Y),s&&a(Yt),s&&a(Z),y(la),s&&a(Ut),s&&a(Ja),s&&a(Bt),s&&a(ss),y(na),s&&a(Jt),s&&a(Es),s&&a(Wt),s&&a(Ds),s&&a(Gt),y(ra,s),s&&a(Kt),s&&a(as),y(pa),s&&a(Qt),s&&a(Is),s&&a(Xt),y(oa,s),s&&a(Zt),s&&a(es),y(ia),s&&a(sl),s&&a(M),s&&a(al),y(ha,s),s&&a(el),y(Ps,s),s&&a(tl),s&&a(qs),s&&a(ll),y(ca,s),s&&a(nl),s&&a(ts),y(da),s&&a(rl),s&&a(S),s&&a(pl),s&&a(ae),s&&a(ol),s&&a(U),s&&a(il),y(fa,s),s&&a(hl),s&&a(Cs),s&&a(cl),y(ma,s),s&&a(dl),s&&a(zs),s&&a(fl),s&&a(B),s&&a(ml),y(ua,s),s&&a(ul),s&&a(ls),y(ga),s&&a(gl),s&&a(R),s&&a(_l),s&&a(ns),y(_a),s&&a(jl),y(ja,s),s&&a(vl),y(Ls,s),s&&a(bl),s&&a(rs),y(va),s&&a($l),s&&a(Vs),s&&a(xl),y(ba,s),s&&a(wl),s&&a(ps),s&&a(yl),y($a,s),s&&a(kl),s&&a(os),y(xa),s&&a(El),s&&a(wa),s&&a(Dl),y(Rs,s)}}}const Ri={local:"stream",sections:[{local:"shuffle",title:"Shuffle"},{local:"reshuffle",title:"Reshuffle"},{local:"split-dataset",title:"Split dataset"},{local:"interleave",title:"Interleave"},{local:"rename-remove-and-cast",sections:[{local:"rename",title:"Rename"},{local:"remove",title:"Remove"},{local:"cast",title:"Cast"}],title:"Rename, remove, and cast"},{local:"map",sections:[{local:"batch-processing",sections:[{local:"tokenization",title:"Tokenization"}],title:"Batch processing"},{local:"filter",title:"Filter"}],title:"Map"},{local:"stream-in-a-training-loop",title:"Stream in a training loop"}],title:"Stream"};function Hi(P,f,_){let{fw:m}=f;return P.$$set=j=>{"fw"in j&&_(0,m=j.fw)},[m]}class Ki extends Di{constructor(f){super();Ai(this,f,Hi,Fi,Ii,{fw:0})}}export{Ki as default,Ri as metadata};
