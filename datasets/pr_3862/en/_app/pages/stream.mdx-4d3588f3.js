import{S as Xp,i as Zp,s as si,e as t,k as c,w as g,t as n,M as ei,c as l,d as a,m as d,a as o,x as _,h as r,b as h,N as Qp,F as e,g as i,y as v,q as j,o as b,B as $}from"../chunks/vendor-e67aec41.js";import{T as tt}from"../chunks/Tip-76459d1c.js";import{I as L}from"../chunks/IconCopyLink-ffd7f84e.js";import{C as q}from"../chunks/CodeBlock-e2bcf023.js";import{C as ai}from"../chunks/CodeBlockFw-1e02e2ba.js";function ti(C){let f,w,m,x,y,u,E,D;return{c(){f=t("p"),w=n("An "),m=t("a"),x=n("datasets.IterableDataset"),y=n(" is useful for iterative jobs like training a model. You shouldn\u2019t use a "),u=t("a"),E=n("datasets.IterableDataset"),D=n(" for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),this.h()},l(A){f=l(A,"P",{});var k=o(f);w=r(k,"An "),m=l(k,"A",{href:!0});var I=o(m);x=r(I,"datasets.IterableDataset"),I.forEach(a),y=r(k," is useful for iterative jobs like training a model. You shouldn\u2019t use a "),u=l(k,"A",{href:!0});var z=o(u);E=r(z,"datasets.IterableDataset"),z.forEach(a),D=r(k," for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),k.forEach(a),this.h()},h(){h(m,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset"),h(u,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset")},m(A,k){i(A,f,k),e(f,w),e(f,m),e(m,x),e(f,y),e(f,u),e(u,E),e(f,D)},d(A){A&&a(f)}}}function li(C){let f,w,m,x;return{c(){f=t("p"),w=t("a"),m=n("datasets.IterableDataset.shuffle()"),x=n(" will also shuffle the order of the shards if the dataset is sharded into multiple sets."),this.h()},l(y){f=l(y,"P",{});var u=o(f);w=l(u,"A",{href:!0});var E=o(w);m=r(E,"datasets.IterableDataset.shuffle()"),E.forEach(a),x=r(u," will also shuffle the order of the shards if the dataset is sharded into multiple sets."),u.forEach(a),this.h()},h(){h(w,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.shuffle")},m(y,u){i(y,f,u),e(f,w),e(w,m),e(f,x)},d(y){y&&a(f)}}}function ni(C){let f,w,m,x,y,u,E,D,A,k,I,z,ps;return{c(){f=t("p"),w=t("code"),m=n("take"),x=n(" and "),y=t("code"),u=n("skip"),E=n(" prevent future calls to "),D=t("code"),A=n("shuffle"),k=n(" because they lock in the order of the shards. You should "),I=t("code"),z=n("shuffle"),ps=n(" your dataset before splitting it.")},l(S){f=l(S,"P",{});var T=o(f);w=l(T,"CODE",{});var be=o(w);m=r(be,"take"),be.forEach(a),x=r(T," and "),y=l(T,"CODE",{});var $e=o(y);u=r($e,"skip"),$e.forEach(a),E=r(T," prevent future calls to "),D=l(T,"CODE",{});var is=o(D);A=r(is,"shuffle"),is.forEach(a),k=r(T," because they lock in the order of the shards. You should "),I=l(T,"CODE",{});var we=o(I);z=r(we,"shuffle"),we.forEach(a),ps=r(T," your dataset before splitting it."),T.forEach(a)},m(S,T){i(S,f,T),e(f,w),e(w,m),e(f,x),e(f,y),e(y,u),e(f,E),e(f,D),e(D,A),e(f,k),e(f,I),e(I,z),e(f,ps)},d(S){S&&a(f)}}}function ri(C){let f,w,m,x,y,u,E,D;return{c(){f=t("p"),w=n("Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=t("code"),x=n("Value('int32')"),y=n(" to "),u=t("code"),E=n("Value('bool')"),D=n(" if the original column only contains ones and zeros.")},l(A){f=l(A,"P",{});var k=o(f);w=r(k,"Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=l(k,"CODE",{});var I=o(m);x=r(I,"Value('int32')"),I.forEach(a),y=r(k," to "),u=l(k,"CODE",{});var z=o(u);E=r(z,"Value('bool')"),z.forEach(a),D=r(k," if the original column only contains ones and zeros."),k.forEach(a)},m(A,k){i(A,f,k),e(f,w),e(f,m),e(m,x),e(f,y),e(f,u),e(u,E),e(f,D)},d(A){A&&a(f)}}}function oi(C){let f,w,m,x,y;return{c(){f=t("p"),w=n("See other examples of batch processing in "),m=t("a"),x=n("the batched map processing documentation"),y=n(". They work the same for iterable datasets."),this.h()},l(u){f=l(u,"P",{});var E=o(f);w=r(E,"See other examples of batch processing in "),m=l(E,"A",{href:!0});var D=o(m);x=r(D,"the batched map processing documentation"),D.forEach(a),y=r(E,". They work the same for iterable datasets."),E.forEach(a),this.h()},h(){h(m,"href","./process#batch-processing")},m(u,E){i(u,f,E),e(f,w),e(f,m),e(m,x),e(f,y)},d(u){u&&a(f)}}}function pi(C){let f,w,m,x,y,u,E,D,A,k,I,z,ps,S,T,be,$e,is,we,lt,W,xe,mo,Ll,ye,uo,nt,M,Ml,Fs,Ol,Vl,ra,Fl,Rl,ke,Hl,Yl,rt,Rs,ot,H,Bl,Ee,Ul,Wl,De,Jl,Gl,pt,hs,it,J,cs,oa,Hs,Kl,pa,Ql,ht,O,Xl,Ae,Zl,sn,Ie,en,an,Te,tn,ln,ct,V,nn,ia,rn,on,ha,pn,hn,Pe,cn,dn,dt,Ys,ft,ds,mt,G,fs,ca,Bs,fn,da,mn,ut,ms,un,fa,gn,_n,gt,us,vn,ma,jn,bn,_t,Us,vt,K,gs,ua,Ws,$n,ga,wn,jt,qe,xn,bt,Se,_s,Ce,yn,kn,_a,En,Dn,$t,Js,wt,ze,vs,Ne,An,In,va,Tn,Pn,xt,Gs,yt,js,kt,Le,Et,Q,bs,ja,Ks,qn,ba,Sn,Dt,X,Me,Cn,zn,Oe,Nn,Ln,At,Qs,It,$s,Mn,$a,On,Vn,Tt,Xs,Pt,Y,Fn,wa,Rn,Hn,xa,Yn,Bn,qt,Z,ws,ya,Zs,Un,ka,Wn,St,Ve,Jn,Ct,ss,xs,Ea,se,Gn,Da,Kn,zt,ys,Qn,Aa,Xn,Zn,Nt,ks,sr,Ia,er,ar,Lt,ee,Mt,es,Es,Ta,ae,tr,Pa,lr,Ot,Ds,nr,Fe,rr,or,Vt,te,Ft,as,As,qa,le,pr,Sa,ir,Rt,N,Ca,hr,cr,za,dr,fr,Na,mr,ur,La,gr,_r,Ht,ne,Yt,Is,Bt,Ts,vr,Re,jr,br,Ut,re,Wt,ts,Ps,Ma,oe,$r,Oa,wr,Jt,P,xr,He,yr,kr,Ye,Er,Dr,Be,Ar,Ir,Ue,Tr,Pr,We,qr,Sr,Gt,Je,Cr,Kt,B,zr,Ge,Nr,Lr,Va,Mr,Or,Qt,pe,Xt,qs,Vr,Ke,Fr,Rr,Zt,ie,sl,Ss,Hr,Qe,Yr,Br,el,U,Ur,Fa,Wr,Jr,Xe,Gr,Kr,al,he,tl,ls,Cs,Ra,ce,Qr,Ha,Xr,ll,R,Ze,Zr,so,Ya,eo,ao,Ba,to,lo,nl,ns,zs,Ua,de,no,Wa,ro,rl,fe,ol,Ns,pl,rs,Ls,Ja,me,oo,Ga,po,il,ue,sa,io,ho,hl,ge,cl,ea,co,dl,_e,fl;return u=new L({}),Rs=new q({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
print(next(iter(dataset)))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset)))
{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, which he shared with John Blanchard during his first visit to Malawi. Chief Napoleon conveyed the desperate need for a program to intervene and care for the orphans and vulnerable children (OVC) in Malawi, and John committed to help...</span>`}}),hs=new tt({props:{$$slots:{default:[ti]},$$scope:{ctx:C}}}),Hs=new L({}),Ys=new q({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
shuffled_dataset = dataset.shuffle(seed=42, buffer_size=10_000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>shuffled_dataset = dataset.shuffle(seed=<span class="hljs-number">42</span>, buffer_size=<span class="hljs-number">10_000</span>)`}}),ds=new tt({props:{$$slots:{default:[li]},$$scope:{ctx:C}}}),Bs=new L({}),Us=new q({props:{code:`for epoch in range(epochs):
    shuffled_dataset.set_epoch(epoch)
    for example in shuffled_dataset:
        ...`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):
<span class="hljs-meta">... </span>    shuffled_dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> shuffled_dataset:
<span class="hljs-meta">... </span>        ...`}}),Ws=new L({}),Js=new q({props:{code:`dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
dataset_head = dataset.take(2)
list(dataset_head)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset_head = dataset.take(<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(dataset_head)
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was...&#x27;</span>}, {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),Gs=new q({props:{code:"train_dataset = shuffled_dataset.skip(1000)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataset = shuffled_dataset.skip(<span class="hljs-number">1000</span>)'}}),js=new tt({props:{warning:"&lcub;true}",$$slots:{default:[ni]},$$scope:{ctx:C}}}),Ks=new L({}),Qs=new q({props:{code:`from datasets import interleave_datasets
en_dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
fr_dataset = load_dataset('oscar', "unshuffled_deduplicated_fr", split='train', streaming=True)

multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
list(multilingual_dataset.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> interleave_datasets
<span class="hljs-meta">&gt;&gt;&gt; </span>en_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>fr_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_fr&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&quot;M\xE9dia de d\xE9bat d&#x27;id\xE9es, de culture et de litt\xE9rature...&quot;</span>}]`}}),Xs=new q({props:{code:`multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[0.8, 0.2], seed=42)
list(multilingual_dataset_with_oversampling.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[<span class="hljs-number">0.8</span>, <span class="hljs-number">0.2</span>], seed=<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset_with_oversampling.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),Zs=new L({}),se=new L({}),ee=new q({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.rename_column("text", "content")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.rename_column(<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>)`}}),ae=new L({}),te=new q({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.remove_columns('timestamp')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.remove_columns(<span class="hljs-string">&#x27;timestamp&#x27;</span>)`}}),le=new L({}),ne=new q({props:{code:`from datasets import load_dataset
dataset = load_dataset('glue', 'mrpc', split='train')features

from datasets import ClassLabel, Value
new_features = dataset.features.copy()
new_features["label"] = ClassLabel(names=['negative', 'positive'])
new_features["idx"] = Value('int64')
dataset = dataset.cast(new_features)
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;glue&#x27;</span>, <span class="hljs-string">&#x27;mrpc&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;not_equivalent&#x27;</span>, <span class="hljs-string">&#x27;equivalent&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> ClassLabel, Value
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features = dataset.features.copy()
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;label&quot;</span>] = ClassLabel(names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;idx&quot;</span>] = Value(<span class="hljs-string">&#x27;int64&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast(new_features)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int64&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),Is=new tt({props:{$$slots:{default:[ri]},$$scope:{ctx:C}}}),re=new q({props:{code:`dataset.features

dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">44100</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">16000</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),oe=new L({}),pe=new q({props:{code:`def add_prefix(example):
    example['text'] = 'My text: ' + example['text']
    return example`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_prefix</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    example[<span class="hljs-string">&#x27;text&#x27;</span>] = <span class="hljs-string">&#x27;My text: &#x27;</span> + example[<span class="hljs-string">&#x27;text&#x27;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example`}}),ie=new q({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train')
updated_dataset = dataset.map(add_prefix)
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&#x27;unshuffled_deduplicated_en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),he=new q({props:{code:`updated_dataset = dataset.map(add_prefix, remove_columns=["id"])
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix, remove_columns=[<span class="hljs-string">&quot;id&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),ce=new L({}),de=new L({}),fe=new q({props:{code:`from datasets import load_dataset
from transformers import AutoTokenizer
dataset = load_dataset("mc4", "en", streaming=True, split="train")
tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')
def encode(examples):
    return tokenizer(examples['text'], truncation=True, padding='max_length')
dataset = dataset.map(encode, batched=True, remove_columns=["text", "timestamp", "url"])
next(iter(dataset))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;mc4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&#x27;text&#x27;</span>], truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-string">&#x27;max_length&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(encode, batched=<span class="hljs-literal">True</span>, remove_columns=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;timestamp&quot;</span>, <span class="hljs-string">&quot;url&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: <span class="hljs-number">101</span>, <span class="hljs-number">8466</span>, <span class="hljs-number">1018</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">4029</span>, <span class="hljs-number">2475</span>, <span class="hljs-number">2062</span>, <span class="hljs-number">18558</span>, <span class="hljs-number">3100</span>, <span class="hljs-number">2061</span>, ...,<span class="hljs-number">1106</span>, <span class="hljs-number">3739</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, ..., <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Ns=new tt({props:{$$slots:{default:[oi]},$$scope:{ctx:C}}}),me=new L({}),ge=new q({props:{code:`buffer_size, seed = 10_000, 42
dataset = dataset.shuffle(buffer_size, seed)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>buffer_size, seed = <span class="hljs-number">10_000</span>, <span class="hljs-number">42</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.shuffle(buffer_size, seed)`}}),_e=new ai({props:{group1:{id:"pt",code:`import torch
from torch.utils.data import DataLoader
from transformers import AutoModelForMaskedLM, DataCollatorForLanguageModeling
from tqdm import tqdm
dataset = dataset.with_format("torch")
dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
device = 'cuda' if torch.cuda.is_available() else 'cpu' 
model = AutoModelForMaskedLM.from_pretrained("distilbert-base-uncased")
model.train().to(device)
optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)
for epoch in range(3):
    dataset.set_epoch(epoch)
    for i, batch in enumerate(tqdm(dataloader, total=5)):
        if i == 5:
            break
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs[0]
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        if i % 10 == 0:
            print(f"loss: {loss}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM, DataCollatorForLanguageModeling
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
<span class="hljs-meta">&gt;&gt;&gt; </span>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span> 
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.train().to(device)
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = torch.optim.AdamW(params=model.parameters(), lr=<span class="hljs-number">1e-5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):
<span class="hljs-meta">... </span>    dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(dataloader, total=<span class="hljs-number">5</span>)):
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">5</span>:
<span class="hljs-meta">... </span>            <span class="hljs-keyword">break</span>
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>        loss.backward()
<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:
<span class="hljs-meta">... </span>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss: <span class="hljs-subst">{loss}</span>&quot;</span>)`},group2:{id:"tf",code:"# WIP",highlighted:'<span class="hljs-comment"># WIP</span>'}}}),{c(){f=t("meta"),w=c(),m=t("h1"),x=t("a"),y=t("span"),g(u.$$.fragment),E=c(),D=t("span"),A=n("Stream"),k=c(),I=t("p"),z=n("Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),ps=c(),S=t("ul"),T=t("li"),be=n("You don\u2019t want to wait for an extremely large dataset to download."),$e=c(),is=t("li"),we=n("The dataset size exceeds the amount of disk space on your computer."),lt=c(),W=t("div"),xe=t("img"),Ll=c(),ye=t("img"),nt=c(),M=t("p"),Ml=n("For example, the English split of the "),Fs=t("a"),Ol=n("OSCAR"),Vl=n(" dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),ra=t("code"),Fl=n("streaming=True"),Rl=n(" in "),ke=t("a"),Hl=n("datasets.load_dataset()"),Yl=n(" as shown below:"),rt=c(),g(Rs.$$.fragment),ot=c(),H=t("p"),Bl=n("Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Ee=t("a"),Ul=n("datasets.Dataset"),Wl=n(" object), known as an "),De=t("a"),Jl=n("datasets.IterableDataset"),Gl=n(". This special type of dataset has its own set of processing methods shown below."),pt=c(),g(hs.$$.fragment),it=c(),J=t("h2"),cs=t("a"),oa=t("span"),g(Hs.$$.fragment),Kl=c(),pa=t("span"),Ql=n("Shuffle"),ht=c(),O=t("p"),Xl=n("Like a regular "),Ae=t("a"),Zl=n("datasets.Dataset"),sn=n(" object, you can also shuffle a "),Ie=t("a"),en=n("datasets.IterableDataset"),an=n(" with "),Te=t("a"),tn=n("datasets.IterableDataset.shuffle()"),ln=n("."),ct=c(),V=t("p"),nn=n("The "),ia=t("code"),rn=n("buffer_size"),on=n(" argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),ha=t("code"),pn=n("buffer_size"),hn=n(" to ten thousand. "),Pe=t("a"),cn=n("datasets.IterableDataset.shuffle()"),dn=n(" will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),dt=c(),g(Ys.$$.fragment),ft=c(),g(ds.$$.fragment),mt=c(),G=t("h2"),fs=t("a"),ca=t("span"),g(Bs.$$.fragment),fn=c(),da=t("span"),mn=n("Reshuffle"),ut=c(),ms=t("p"),un=n("Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),fa=t("code"),gn=n("datasets.IterableDataset.set_epoch()"),_n=n("in between epochs to tell the dataset what epoch you\u2019re on."),gt=c(),us=t("p"),vn=n("Your seed effectively becomes: "),ma=t("code"),jn=n("initial seed + current epoch"),bn=n("."),_t=c(),g(Us.$$.fragment),vt=c(),K=t("h2"),gs=t("a"),ua=t("span"),g(Ws.$$.fragment),$n=c(),ga=t("span"),wn=n("Split dataset"),jt=c(),qe=t("p"),xn=n("You can split your dataset one of two ways:"),bt=c(),Se=t("ul"),_s=t("li"),Ce=t("a"),yn=n("datasets.IterableDataset.take()"),kn=n(" returns the first "),_a=t("code"),En=n("n"),Dn=n(" examples in a dataset:"),$t=c(),g(Js.$$.fragment),wt=c(),ze=t("ul"),vs=t("li"),Ne=t("a"),An=n("datasets.IterableDataset.skip()"),In=n(" omits the first "),va=t("code"),Tn=n("n"),Pn=n(" examples in a dataset and returns the remaining examples:"),xt=c(),g(Gs.$$.fragment),yt=c(),g(js.$$.fragment),kt=c(),Le=t("a"),Et=c(),Q=t("h2"),bs=t("a"),ja=t("span"),g(Ks.$$.fragment),qn=c(),ba=t("span"),Sn=n("Interleave"),Dt=c(),X=t("p"),Me=t("a"),Cn=n("datasets.interleave_datasets()"),zn=n(" can combine an "),Oe=t("a"),Nn=n("datasets.IterableDataset"),Ln=n(" with other datasets. The combined dataset returns alternating examples from each of the original datasets."),At=c(),g(Qs.$$.fragment),It=c(),$s=t("p"),Mn=n("Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),$a=t("code"),On=n("probabilities"),Vn=n(" argument with your desired sampling probabilities:"),Tt=c(),g(Xs.$$.fragment),Pt=c(),Y=t("p"),Fn=n("Around 80% of the final dataset is made of the "),wa=t("code"),Rn=n("en_dataset"),Hn=n(", and 20% of the "),xa=t("code"),Yn=n("fr_dataset"),Bn=n("."),qt=c(),Z=t("h2"),ws=t("a"),ya=t("span"),g(Zs.$$.fragment),Un=c(),ka=t("span"),Wn=n("Rename, remove, and cast"),St=c(),Ve=t("p"),Jn=n("The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),Ct=c(),ss=t("h3"),xs=t("a"),Ea=t("span"),g(se.$$.fragment),Gn=c(),Da=t("span"),Kn=n("Rename"),zt=c(),ys=t("p"),Qn=n("Use "),Aa=t("code"),Xn=n("datasets.IterableDataset.rename_column()"),Zn=n("when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),Nt=c(),ks=t("p"),sr=n("Provide "),Ia=t("code"),er=n("datasets.IterableDataset.rename_column()"),ar=n("with the name of the original column, and the new column name:"),Lt=c(),g(ee.$$.fragment),Mt=c(),es=t("h3"),Es=t("a"),Ta=t("span"),g(ae.$$.fragment),tr=c(),Pa=t("span"),lr=n("Remove"),Ot=c(),Ds=t("p"),nr=n("When you need to remove one or more columns, give "),Fe=t("a"),rr=n("datasets.IterableDataset.remove_columns()"),or=n(" the name of the column to remove. Remove more than one column by providing a list of column names:"),Vt=c(),g(te.$$.fragment),Ft=c(),as=t("h3"),As=t("a"),qa=t("span"),g(le.$$.fragment),pr=c(),Sa=t("span"),ir=n("Cast"),Rt=c(),N=t("p"),Ca=t("code"),hr=n("datasets.IterableDataset.cast()"),cr=n("changes the feature type of one or more columns. This method takes your new "),za=t("code"),dr=n("datasets.Features"),fr=n(" as its argument. The following sample code shows how to change the feature types of "),Na=t("code"),mr=n("datasets.ClassLabel"),ur=n(" and "),La=t("code"),gr=n("datasets.Value"),_r=n(":"),Ht=c(),g(ne.$$.fragment),Yt=c(),g(Is.$$.fragment),Bt=c(),Ts=t("p"),vr=n("Use "),Re=t("a"),jr=n("datasets.Dataset.cast_column()"),br=n(" to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),Ut=c(),g(re.$$.fragment),Wt=c(),ts=t("h2"),Ps=t("a"),Ma=t("span"),g(oe.$$.fragment),$r=c(),Oa=t("span"),wr=n("Map"),Jt=c(),P=t("p"),xr=n("Similar to the "),He=t("a"),yr=n("datasets.Dataset.map()"),kr=n(" function for a regular "),Ye=t("a"),Er=n("datasets.Dataset"),Dr=n(", \u{1F917}  Datasets features "),Be=t("a"),Ar=n("datasets.IterableDataset.map()"),Ir=n(" for processing "),Ue=t("a"),Tr=n("datasets.IterableDataset"),Pr=n(`\\s.
`),We=t("a"),qr=n("datasets.IterableDataset.map()"),Sr=n(" applies processing on-the-fly when examples are streamed."),Gt=c(),Je=t("p"),Cr=n("It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),Kt=c(),B=t("p"),zr=n("The following example demonstrates how to tokenize a "),Ge=t("a"),Nr=n("datasets.IterableDataset"),Lr=n(". The function needs to accept and output a "),Va=t("code"),Mr=n("dict"),Or=n(":"),Qt=c(),g(pe.$$.fragment),Xt=c(),qs=t("p"),Vr=n("Next, apply this function to the dataset with "),Ke=t("a"),Fr=n("datasets.IterableDataset.map()"),Rr=n(":"),Zt=c(),g(ie.$$.fragment),sl=c(),Ss=t("p"),Hr=n("Let\u2019s take a look at another example, except this time, you will remove a column with "),Qe=t("a"),Yr=n("datasets.IterableDataset.map()"),Br=n(". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),el=c(),U=t("p"),Ur=n("Specify the column to remove with the "),Fa=t("code"),Wr=n("remove_columns"),Jr=n(" argument in "),Xe=t("a"),Gr=n("datasets.IterableDataset.map()"),Kr=n(":"),al=c(),g(he.$$.fragment),tl=c(),ls=t("h3"),Cs=t("a"),Ra=t("span"),g(ce.$$.fragment),Qr=c(),Ha=t("span"),Xr=n("Batch processing"),ll=c(),R=t("p"),Ze=t("a"),Zr=n("datasets.IterableDataset.map()"),so=n(" also supports working with batches of examples. Operate on batches by setting "),Ya=t("code"),eo=n("batched=True"),ao=n(". The default batch size is 1000, but you can adjust it with the "),Ba=t("code"),to=n("batch_size"),lo=n(" argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),nl=c(),ns=t("h4"),zs=t("a"),Ua=t("span"),g(de.$$.fragment),no=c(),Wa=t("span"),ro=n("Tokenization"),rl=c(),g(fe.$$.fragment),ol=c(),g(Ns.$$.fragment),pl=c(),rs=t("h2"),Ls=t("a"),Ja=t("span"),g(me.$$.fragment),oo=c(),Ga=t("span"),po=n("Stream in a training loop"),il=c(),ue=t("p"),sa=t("a"),io=n("datasets.IterableDataset"),ho=n(" can be integrated into a training loop. First, shuffle the dataset:"),hl=c(),g(ge.$$.fragment),cl=c(),ea=t("p"),co=n("Lastly, create a simple training loop and start training:"),dl=c(),g(_e.$$.fragment),this.h()},l(s){const p=ei('[data-svelte="svelte-1phssyn"]',document.head);f=l(p,"META",{name:!0,content:!0}),p.forEach(a),w=d(s),m=l(s,"H1",{class:!0});var ve=o(m);x=l(ve,"A",{id:!0,class:!0,href:!0});var Ka=o(x);y=l(Ka,"SPAN",{});var Qa=o(y);_(u.$$.fragment,Qa),Qa.forEach(a),Ka.forEach(a),E=d(ve),D=l(ve,"SPAN",{});var Xa=o(D);A=r(Xa,"Stream"),Xa.forEach(a),ve.forEach(a),k=d(s),I=l(s,"P",{});var Za=o(I);z=r(Za,"Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),Za.forEach(a),ps=d(s),S=l(s,"UL",{});var ml=o(S);T=l(ml,"LI",{});var go=o(T);be=r(go,"You don\u2019t want to wait for an extremely large dataset to download."),go.forEach(a),$e=d(ml),is=l(ml,"LI",{});var _o=o(is);we=r(_o,"The dataset size exceeds the amount of disk space on your computer."),_o.forEach(a),ml.forEach(a),lt=d(s),W=l(s,"DIV",{class:!0});var ul=o(W);xe=l(ul,"IMG",{class:!0,src:!0}),Ll=d(ul),ye=l(ul,"IMG",{class:!0,src:!0}),ul.forEach(a),nt=d(s),M=l(s,"P",{});var Ms=o(M);Ml=r(Ms,"For example, the English split of the "),Fs=l(Ms,"A",{href:!0,rel:!0});var vo=o(Fs);Ol=r(vo,"OSCAR"),vo.forEach(a),Vl=r(Ms," dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),ra=l(Ms,"CODE",{});var jo=o(ra);Fl=r(jo,"streaming=True"),jo.forEach(a),Rl=r(Ms," in "),ke=l(Ms,"A",{href:!0});var bo=o(ke);Hl=r(bo,"datasets.load_dataset()"),bo.forEach(a),Yl=r(Ms," as shown below:"),Ms.forEach(a),rt=d(s),_(Rs.$$.fragment,s),ot=d(s),H=l(s,"P",{});var aa=o(H);Bl=r(aa,"Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Ee=l(aa,"A",{href:!0});var $o=o(Ee);Ul=r($o,"datasets.Dataset"),$o.forEach(a),Wl=r(aa," object), known as an "),De=l(aa,"A",{href:!0});var wo=o(De);Jl=r(wo,"datasets.IterableDataset"),wo.forEach(a),Gl=r(aa,". This special type of dataset has its own set of processing methods shown below."),aa.forEach(a),pt=d(s),_(hs.$$.fragment,s),it=d(s),J=l(s,"H2",{class:!0});var gl=o(J);cs=l(gl,"A",{id:!0,class:!0,href:!0});var xo=o(cs);oa=l(xo,"SPAN",{});var yo=o(oa);_(Hs.$$.fragment,yo),yo.forEach(a),xo.forEach(a),Kl=d(gl),pa=l(gl,"SPAN",{});var ko=o(pa);Ql=r(ko,"Shuffle"),ko.forEach(a),gl.forEach(a),ht=d(s),O=l(s,"P",{});var Os=o(O);Xl=r(Os,"Like a regular "),Ae=l(Os,"A",{href:!0});var Eo=o(Ae);Zl=r(Eo,"datasets.Dataset"),Eo.forEach(a),sn=r(Os," object, you can also shuffle a "),Ie=l(Os,"A",{href:!0});var Do=o(Ie);en=r(Do,"datasets.IterableDataset"),Do.forEach(a),an=r(Os," with "),Te=l(Os,"A",{href:!0});var Ao=o(Te);tn=r(Ao,"datasets.IterableDataset.shuffle()"),Ao.forEach(a),ln=r(Os,"."),Os.forEach(a),ct=d(s),V=l(s,"P",{});var Vs=o(V);nn=r(Vs,"The "),ia=l(Vs,"CODE",{});var Io=o(ia);rn=r(Io,"buffer_size"),Io.forEach(a),on=r(Vs," argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),ha=l(Vs,"CODE",{});var To=o(ha);pn=r(To,"buffer_size"),To.forEach(a),hn=r(Vs," to ten thousand. "),Pe=l(Vs,"A",{href:!0});var Po=o(Pe);cn=r(Po,"datasets.IterableDataset.shuffle()"),Po.forEach(a),dn=r(Vs," will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),Vs.forEach(a),dt=d(s),_(Ys.$$.fragment,s),ft=d(s),_(ds.$$.fragment,s),mt=d(s),G=l(s,"H2",{class:!0});var _l=o(G);fs=l(_l,"A",{id:!0,class:!0,href:!0});var qo=o(fs);ca=l(qo,"SPAN",{});var So=o(ca);_(Bs.$$.fragment,So),So.forEach(a),qo.forEach(a),fn=d(_l),da=l(_l,"SPAN",{});var Co=o(da);mn=r(Co,"Reshuffle"),Co.forEach(a),_l.forEach(a),ut=d(s),ms=l(s,"P",{});var vl=o(ms);un=r(vl,"Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),fa=l(vl,"CODE",{});var zo=o(fa);gn=r(zo,"datasets.IterableDataset.set_epoch()"),zo.forEach(a),_n=r(vl,"in between epochs to tell the dataset what epoch you\u2019re on."),vl.forEach(a),gt=d(s),us=l(s,"P",{});var jl=o(us);vn=r(jl,"Your seed effectively becomes: "),ma=l(jl,"CODE",{});var No=o(ma);jn=r(No,"initial seed + current epoch"),No.forEach(a),bn=r(jl,"."),jl.forEach(a),_t=d(s),_(Us.$$.fragment,s),vt=d(s),K=l(s,"H2",{class:!0});var bl=o(K);gs=l(bl,"A",{id:!0,class:!0,href:!0});var Lo=o(gs);ua=l(Lo,"SPAN",{});var Mo=o(ua);_(Ws.$$.fragment,Mo),Mo.forEach(a),Lo.forEach(a),$n=d(bl),ga=l(bl,"SPAN",{});var Oo=o(ga);wn=r(Oo,"Split dataset"),Oo.forEach(a),bl.forEach(a),jt=d(s),qe=l(s,"P",{});var Vo=o(qe);xn=r(Vo,"You can split your dataset one of two ways:"),Vo.forEach(a),bt=d(s),Se=l(s,"UL",{});var Fo=o(Se);_s=l(Fo,"LI",{});var st=o(_s);Ce=l(st,"A",{href:!0});var Ro=o(Ce);yn=r(Ro,"datasets.IterableDataset.take()"),Ro.forEach(a),kn=r(st," returns the first "),_a=l(st,"CODE",{});var Ho=o(_a);En=r(Ho,"n"),Ho.forEach(a),Dn=r(st," examples in a dataset:"),st.forEach(a),Fo.forEach(a),$t=d(s),_(Js.$$.fragment,s),wt=d(s),ze=l(s,"UL",{});var Yo=o(ze);vs=l(Yo,"LI",{});var et=o(vs);Ne=l(et,"A",{href:!0});var Bo=o(Ne);An=r(Bo,"datasets.IterableDataset.skip()"),Bo.forEach(a),In=r(et," omits the first "),va=l(et,"CODE",{});var Uo=o(va);Tn=r(Uo,"n"),Uo.forEach(a),Pn=r(et," examples in a dataset and returns the remaining examples:"),et.forEach(a),Yo.forEach(a),xt=d(s),_(Gs.$$.fragment,s),yt=d(s),_(js.$$.fragment,s),kt=d(s),Le=l(s,"A",{id:!0}),o(Le).forEach(a),Et=d(s),Q=l(s,"H2",{class:!0});var $l=o(Q);bs=l($l,"A",{id:!0,class:!0,href:!0});var Wo=o(bs);ja=l(Wo,"SPAN",{});var Jo=o(ja);_(Ks.$$.fragment,Jo),Jo.forEach(a),Wo.forEach(a),qn=d($l),ba=l($l,"SPAN",{});var Go=o(ba);Sn=r(Go,"Interleave"),Go.forEach(a),$l.forEach(a),Dt=d(s),X=l(s,"P",{});var at=o(X);Me=l(at,"A",{href:!0});var Ko=o(Me);Cn=r(Ko,"datasets.interleave_datasets()"),Ko.forEach(a),zn=r(at," can combine an "),Oe=l(at,"A",{href:!0});var Qo=o(Oe);Nn=r(Qo,"datasets.IterableDataset"),Qo.forEach(a),Ln=r(at," with other datasets. The combined dataset returns alternating examples from each of the original datasets."),at.forEach(a),At=d(s),_(Qs.$$.fragment,s),It=d(s),$s=l(s,"P",{});var wl=o($s);Mn=r(wl,"Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),$a=l(wl,"CODE",{});var Xo=o($a);On=r(Xo,"probabilities"),Xo.forEach(a),Vn=r(wl," argument with your desired sampling probabilities:"),wl.forEach(a),Tt=d(s),_(Xs.$$.fragment,s),Pt=d(s),Y=l(s,"P",{});var ta=o(Y);Fn=r(ta,"Around 80% of the final dataset is made of the "),wa=l(ta,"CODE",{});var Zo=o(wa);Rn=r(Zo,"en_dataset"),Zo.forEach(a),Hn=r(ta,", and 20% of the "),xa=l(ta,"CODE",{});var sp=o(xa);Yn=r(sp,"fr_dataset"),sp.forEach(a),Bn=r(ta,"."),ta.forEach(a),qt=d(s),Z=l(s,"H2",{class:!0});var xl=o(Z);ws=l(xl,"A",{id:!0,class:!0,href:!0});var ep=o(ws);ya=l(ep,"SPAN",{});var ap=o(ya);_(Zs.$$.fragment,ap),ap.forEach(a),ep.forEach(a),Un=d(xl),ka=l(xl,"SPAN",{});var tp=o(ka);Wn=r(tp,"Rename, remove, and cast"),tp.forEach(a),xl.forEach(a),St=d(s),Ve=l(s,"P",{});var lp=o(Ve);Jn=r(lp,"The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),lp.forEach(a),Ct=d(s),ss=l(s,"H3",{class:!0});var yl=o(ss);xs=l(yl,"A",{id:!0,class:!0,href:!0});var np=o(xs);Ea=l(np,"SPAN",{});var rp=o(Ea);_(se.$$.fragment,rp),rp.forEach(a),np.forEach(a),Gn=d(yl),Da=l(yl,"SPAN",{});var op=o(Da);Kn=r(op,"Rename"),op.forEach(a),yl.forEach(a),zt=d(s),ys=l(s,"P",{});var kl=o(ys);Qn=r(kl,"Use "),Aa=l(kl,"CODE",{});var pp=o(Aa);Xn=r(pp,"datasets.IterableDataset.rename_column()"),pp.forEach(a),Zn=r(kl,"when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),kl.forEach(a),Nt=d(s),ks=l(s,"P",{});var El=o(ks);sr=r(El,"Provide "),Ia=l(El,"CODE",{});var ip=o(Ia);er=r(ip,"datasets.IterableDataset.rename_column()"),ip.forEach(a),ar=r(El,"with the name of the original column, and the new column name:"),El.forEach(a),Lt=d(s),_(ee.$$.fragment,s),Mt=d(s),es=l(s,"H3",{class:!0});var Dl=o(es);Es=l(Dl,"A",{id:!0,class:!0,href:!0});var hp=o(Es);Ta=l(hp,"SPAN",{});var cp=o(Ta);_(ae.$$.fragment,cp),cp.forEach(a),hp.forEach(a),tr=d(Dl),Pa=l(Dl,"SPAN",{});var dp=o(Pa);lr=r(dp,"Remove"),dp.forEach(a),Dl.forEach(a),Ot=d(s),Ds=l(s,"P",{});var Al=o(Ds);nr=r(Al,"When you need to remove one or more columns, give "),Fe=l(Al,"A",{href:!0});var fp=o(Fe);rr=r(fp,"datasets.IterableDataset.remove_columns()"),fp.forEach(a),or=r(Al," the name of the column to remove. Remove more than one column by providing a list of column names:"),Al.forEach(a),Vt=d(s),_(te.$$.fragment,s),Ft=d(s),as=l(s,"H3",{class:!0});var Il=o(as);As=l(Il,"A",{id:!0,class:!0,href:!0});var mp=o(As);qa=l(mp,"SPAN",{});var up=o(qa);_(le.$$.fragment,up),up.forEach(a),mp.forEach(a),pr=d(Il),Sa=l(Il,"SPAN",{});var gp=o(Sa);ir=r(gp,"Cast"),gp.forEach(a),Il.forEach(a),Rt=d(s),N=l(s,"P",{});var os=o(N);Ca=l(os,"CODE",{});var _p=o(Ca);hr=r(_p,"datasets.IterableDataset.cast()"),_p.forEach(a),cr=r(os,"changes the feature type of one or more columns. This method takes your new "),za=l(os,"CODE",{});var vp=o(za);dr=r(vp,"datasets.Features"),vp.forEach(a),fr=r(os," as its argument. The following sample code shows how to change the feature types of "),Na=l(os,"CODE",{});var jp=o(Na);mr=r(jp,"datasets.ClassLabel"),jp.forEach(a),ur=r(os," and "),La=l(os,"CODE",{});var bp=o(La);gr=r(bp,"datasets.Value"),bp.forEach(a),_r=r(os,":"),os.forEach(a),Ht=d(s),_(ne.$$.fragment,s),Yt=d(s),_(Is.$$.fragment,s),Bt=d(s),Ts=l(s,"P",{});var Tl=o(Ts);vr=r(Tl,"Use "),Re=l(Tl,"A",{href:!0});var $p=o(Re);jr=r($p,"datasets.Dataset.cast_column()"),$p.forEach(a),br=r(Tl," to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),Tl.forEach(a),Ut=d(s),_(re.$$.fragment,s),Wt=d(s),ts=l(s,"H2",{class:!0});var Pl=o(ts);Ps=l(Pl,"A",{id:!0,class:!0,href:!0});var wp=o(Ps);Ma=l(wp,"SPAN",{});var xp=o(Ma);_(oe.$$.fragment,xp),xp.forEach(a),wp.forEach(a),$r=d(Pl),Oa=l(Pl,"SPAN",{});var yp=o(Oa);wr=r(yp,"Map"),yp.forEach(a),Pl.forEach(a),Jt=d(s),P=l(s,"P",{});var F=o(P);xr=r(F,"Similar to the "),He=l(F,"A",{href:!0});var kp=o(He);yr=r(kp,"datasets.Dataset.map()"),kp.forEach(a),kr=r(F," function for a regular "),Ye=l(F,"A",{href:!0});var Ep=o(Ye);Er=r(Ep,"datasets.Dataset"),Ep.forEach(a),Dr=r(F,", \u{1F917}  Datasets features "),Be=l(F,"A",{href:!0});var Dp=o(Be);Ar=r(Dp,"datasets.IterableDataset.map()"),Dp.forEach(a),Ir=r(F," for processing "),Ue=l(F,"A",{href:!0});var Ap=o(Ue);Tr=r(Ap,"datasets.IterableDataset"),Ap.forEach(a),Pr=r(F,`\\s.
`),We=l(F,"A",{href:!0});var Ip=o(We);qr=r(Ip,"datasets.IterableDataset.map()"),Ip.forEach(a),Sr=r(F," applies processing on-the-fly when examples are streamed."),F.forEach(a),Gt=d(s),Je=l(s,"P",{});var Tp=o(Je);Cr=r(Tp,"It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),Tp.forEach(a),Kt=d(s),B=l(s,"P",{});var la=o(B);zr=r(la,"The following example demonstrates how to tokenize a "),Ge=l(la,"A",{href:!0});var Pp=o(Ge);Nr=r(Pp,"datasets.IterableDataset"),Pp.forEach(a),Lr=r(la,". The function needs to accept and output a "),Va=l(la,"CODE",{});var qp=o(Va);Mr=r(qp,"dict"),qp.forEach(a),Or=r(la,":"),la.forEach(a),Qt=d(s),_(pe.$$.fragment,s),Xt=d(s),qs=l(s,"P",{});var ql=o(qs);Vr=r(ql,"Next, apply this function to the dataset with "),Ke=l(ql,"A",{href:!0});var Sp=o(Ke);Fr=r(Sp,"datasets.IterableDataset.map()"),Sp.forEach(a),Rr=r(ql,":"),ql.forEach(a),Zt=d(s),_(ie.$$.fragment,s),sl=d(s),Ss=l(s,"P",{});var Sl=o(Ss);Hr=r(Sl,"Let\u2019s take a look at another example, except this time, you will remove a column with "),Qe=l(Sl,"A",{href:!0});var Cp=o(Qe);Yr=r(Cp,"datasets.IterableDataset.map()"),Cp.forEach(a),Br=r(Sl,". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),Sl.forEach(a),el=d(s),U=l(s,"P",{});var na=o(U);Ur=r(na,"Specify the column to remove with the "),Fa=l(na,"CODE",{});var zp=o(Fa);Wr=r(zp,"remove_columns"),zp.forEach(a),Jr=r(na," argument in "),Xe=l(na,"A",{href:!0});var Np=o(Xe);Gr=r(Np,"datasets.IterableDataset.map()"),Np.forEach(a),Kr=r(na,":"),na.forEach(a),al=d(s),_(he.$$.fragment,s),tl=d(s),ls=l(s,"H3",{class:!0});var Cl=o(ls);Cs=l(Cl,"A",{id:!0,class:!0,href:!0});var Lp=o(Cs);Ra=l(Lp,"SPAN",{});var Mp=o(Ra);_(ce.$$.fragment,Mp),Mp.forEach(a),Lp.forEach(a),Qr=d(Cl),Ha=l(Cl,"SPAN",{});var Op=o(Ha);Xr=r(Op,"Batch processing"),Op.forEach(a),Cl.forEach(a),ll=d(s),R=l(s,"P",{});var je=o(R);Ze=l(je,"A",{href:!0});var Vp=o(Ze);Zr=r(Vp,"datasets.IterableDataset.map()"),Vp.forEach(a),so=r(je," also supports working with batches of examples. Operate on batches by setting "),Ya=l(je,"CODE",{});var Fp=o(Ya);eo=r(Fp,"batched=True"),Fp.forEach(a),ao=r(je,". The default batch size is 1000, but you can adjust it with the "),Ba=l(je,"CODE",{});var Rp=o(Ba);to=r(Rp,"batch_size"),Rp.forEach(a),lo=r(je," argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),je.forEach(a),nl=d(s),ns=l(s,"H4",{class:!0});var zl=o(ns);zs=l(zl,"A",{id:!0,class:!0,href:!0});var Hp=o(zs);Ua=l(Hp,"SPAN",{});var Yp=o(Ua);_(de.$$.fragment,Yp),Yp.forEach(a),Hp.forEach(a),no=d(zl),Wa=l(zl,"SPAN",{});var Bp=o(Wa);ro=r(Bp,"Tokenization"),Bp.forEach(a),zl.forEach(a),rl=d(s),_(fe.$$.fragment,s),ol=d(s),_(Ns.$$.fragment,s),pl=d(s),rs=l(s,"H2",{class:!0});var Nl=o(rs);Ls=l(Nl,"A",{id:!0,class:!0,href:!0});var Up=o(Ls);Ja=l(Up,"SPAN",{});var Wp=o(Ja);_(me.$$.fragment,Wp),Wp.forEach(a),Up.forEach(a),oo=d(Nl),Ga=l(Nl,"SPAN",{});var Jp=o(Ga);po=r(Jp,"Stream in a training loop"),Jp.forEach(a),Nl.forEach(a),il=d(s),ue=l(s,"P",{});var fo=o(ue);sa=l(fo,"A",{href:!0});var Gp=o(sa);io=r(Gp,"datasets.IterableDataset"),Gp.forEach(a),ho=r(fo," can be integrated into a training loop. First, shuffle the dataset:"),fo.forEach(a),hl=d(s),_(ge.$$.fragment,s),cl=d(s),ea=l(s,"P",{});var Kp=o(ea);co=r(Kp,"Lastly, create a simple training loop and start training:"),Kp.forEach(a),dl=d(s),_(_e.$$.fragment,s),this.h()},h(){h(f,"name","hf:doc:metadata"),h(f,"content",JSON.stringify(ii)),h(x,"id","stream"),h(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(x,"href","#stream"),h(m,"class","relative group"),h(xe,"class","block dark:hidden"),Qp(xe.src,mo="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming.gif")||h(xe,"src",mo),h(ye,"class","hidden dark:block"),Qp(ye.src,uo="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming-dark.gif")||h(ye,"src",uo),h(W,"class","flex justify-center"),h(Fs,"href","https://huggingface.co/datasets/oscar"),h(Fs,"rel","nofollow"),h(ke,"href","/docs/datasets/pr_3862/en/package_reference/loading_methods#datasets.load_dataset"),h(Ee,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.Dataset"),h(De,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset"),h(cs,"id","shuffle"),h(cs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(cs,"href","#shuffle"),h(J,"class","relative group"),h(Ae,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.Dataset"),h(Ie,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset"),h(Te,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(Pe,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(fs,"id","reshuffle"),h(fs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(fs,"href","#reshuffle"),h(G,"class","relative group"),h(gs,"id","split-dataset"),h(gs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(gs,"href","#split-dataset"),h(K,"class","relative group"),h(Ce,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.take"),h(Ne,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.skip"),h(Le,"id","interleave_datasets"),h(bs,"id","interleave"),h(bs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(bs,"href","#interleave"),h(Q,"class","relative group"),h(Me,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.interleave_datasets"),h(Oe,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset"),h(ws,"id","rename-remove-and-cast"),h(ws,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ws,"href","#rename-remove-and-cast"),h(Z,"class","relative group"),h(xs,"id","rename"),h(xs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(xs,"href","#rename"),h(ss,"class","relative group"),h(Es,"id","remove"),h(Es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Es,"href","#remove"),h(es,"class","relative group"),h(Fe,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.remove_columns"),h(As,"id","cast"),h(As,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(As,"href","#cast"),h(as,"class","relative group"),h(Re,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.Dataset.cast_column"),h(Ps,"id","map"),h(Ps,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ps,"href","#map"),h(ts,"class","relative group"),h(He,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.Dataset.map"),h(Ye,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.Dataset"),h(Be,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Ue,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset"),h(We,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Ge,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset"),h(Ke,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Qe,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Xe,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Cs,"id","batch-processing"),h(Cs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Cs,"href","#batch-processing"),h(ls,"class","relative group"),h(Ze,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset.map"),h(zs,"id","tokenization"),h(zs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(zs,"href","#tokenization"),h(ns,"class","relative group"),h(Ls,"id","stream-in-a-training-loop"),h(Ls,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ls,"href","#stream-in-a-training-loop"),h(rs,"class","relative group"),h(sa,"href","/docs/datasets/pr_3862/en/package_reference/main_classes#datasets.IterableDataset")},m(s,p){e(document.head,f),i(s,w,p),i(s,m,p),e(m,x),e(x,y),v(u,y,null),e(m,E),e(m,D),e(D,A),i(s,k,p),i(s,I,p),e(I,z),i(s,ps,p),i(s,S,p),e(S,T),e(T,be),e(S,$e),e(S,is),e(is,we),i(s,lt,p),i(s,W,p),e(W,xe),e(W,Ll),e(W,ye),i(s,nt,p),i(s,M,p),e(M,Ml),e(M,Fs),e(Fs,Ol),e(M,Vl),e(M,ra),e(ra,Fl),e(M,Rl),e(M,ke),e(ke,Hl),e(M,Yl),i(s,rt,p),v(Rs,s,p),i(s,ot,p),i(s,H,p),e(H,Bl),e(H,Ee),e(Ee,Ul),e(H,Wl),e(H,De),e(De,Jl),e(H,Gl),i(s,pt,p),v(hs,s,p),i(s,it,p),i(s,J,p),e(J,cs),e(cs,oa),v(Hs,oa,null),e(J,Kl),e(J,pa),e(pa,Ql),i(s,ht,p),i(s,O,p),e(O,Xl),e(O,Ae),e(Ae,Zl),e(O,sn),e(O,Ie),e(Ie,en),e(O,an),e(O,Te),e(Te,tn),e(O,ln),i(s,ct,p),i(s,V,p),e(V,nn),e(V,ia),e(ia,rn),e(V,on),e(V,ha),e(ha,pn),e(V,hn),e(V,Pe),e(Pe,cn),e(V,dn),i(s,dt,p),v(Ys,s,p),i(s,ft,p),v(ds,s,p),i(s,mt,p),i(s,G,p),e(G,fs),e(fs,ca),v(Bs,ca,null),e(G,fn),e(G,da),e(da,mn),i(s,ut,p),i(s,ms,p),e(ms,un),e(ms,fa),e(fa,gn),e(ms,_n),i(s,gt,p),i(s,us,p),e(us,vn),e(us,ma),e(ma,jn),e(us,bn),i(s,_t,p),v(Us,s,p),i(s,vt,p),i(s,K,p),e(K,gs),e(gs,ua),v(Ws,ua,null),e(K,$n),e(K,ga),e(ga,wn),i(s,jt,p),i(s,qe,p),e(qe,xn),i(s,bt,p),i(s,Se,p),e(Se,_s),e(_s,Ce),e(Ce,yn),e(_s,kn),e(_s,_a),e(_a,En),e(_s,Dn),i(s,$t,p),v(Js,s,p),i(s,wt,p),i(s,ze,p),e(ze,vs),e(vs,Ne),e(Ne,An),e(vs,In),e(vs,va),e(va,Tn),e(vs,Pn),i(s,xt,p),v(Gs,s,p),i(s,yt,p),v(js,s,p),i(s,kt,p),i(s,Le,p),i(s,Et,p),i(s,Q,p),e(Q,bs),e(bs,ja),v(Ks,ja,null),e(Q,qn),e(Q,ba),e(ba,Sn),i(s,Dt,p),i(s,X,p),e(X,Me),e(Me,Cn),e(X,zn),e(X,Oe),e(Oe,Nn),e(X,Ln),i(s,At,p),v(Qs,s,p),i(s,It,p),i(s,$s,p),e($s,Mn),e($s,$a),e($a,On),e($s,Vn),i(s,Tt,p),v(Xs,s,p),i(s,Pt,p),i(s,Y,p),e(Y,Fn),e(Y,wa),e(wa,Rn),e(Y,Hn),e(Y,xa),e(xa,Yn),e(Y,Bn),i(s,qt,p),i(s,Z,p),e(Z,ws),e(ws,ya),v(Zs,ya,null),e(Z,Un),e(Z,ka),e(ka,Wn),i(s,St,p),i(s,Ve,p),e(Ve,Jn),i(s,Ct,p),i(s,ss,p),e(ss,xs),e(xs,Ea),v(se,Ea,null),e(ss,Gn),e(ss,Da),e(Da,Kn),i(s,zt,p),i(s,ys,p),e(ys,Qn),e(ys,Aa),e(Aa,Xn),e(ys,Zn),i(s,Nt,p),i(s,ks,p),e(ks,sr),e(ks,Ia),e(Ia,er),e(ks,ar),i(s,Lt,p),v(ee,s,p),i(s,Mt,p),i(s,es,p),e(es,Es),e(Es,Ta),v(ae,Ta,null),e(es,tr),e(es,Pa),e(Pa,lr),i(s,Ot,p),i(s,Ds,p),e(Ds,nr),e(Ds,Fe),e(Fe,rr),e(Ds,or),i(s,Vt,p),v(te,s,p),i(s,Ft,p),i(s,as,p),e(as,As),e(As,qa),v(le,qa,null),e(as,pr),e(as,Sa),e(Sa,ir),i(s,Rt,p),i(s,N,p),e(N,Ca),e(Ca,hr),e(N,cr),e(N,za),e(za,dr),e(N,fr),e(N,Na),e(Na,mr),e(N,ur),e(N,La),e(La,gr),e(N,_r),i(s,Ht,p),v(ne,s,p),i(s,Yt,p),v(Is,s,p),i(s,Bt,p),i(s,Ts,p),e(Ts,vr),e(Ts,Re),e(Re,jr),e(Ts,br),i(s,Ut,p),v(re,s,p),i(s,Wt,p),i(s,ts,p),e(ts,Ps),e(Ps,Ma),v(oe,Ma,null),e(ts,$r),e(ts,Oa),e(Oa,wr),i(s,Jt,p),i(s,P,p),e(P,xr),e(P,He),e(He,yr),e(P,kr),e(P,Ye),e(Ye,Er),e(P,Dr),e(P,Be),e(Be,Ar),e(P,Ir),e(P,Ue),e(Ue,Tr),e(P,Pr),e(P,We),e(We,qr),e(P,Sr),i(s,Gt,p),i(s,Je,p),e(Je,Cr),i(s,Kt,p),i(s,B,p),e(B,zr),e(B,Ge),e(Ge,Nr),e(B,Lr),e(B,Va),e(Va,Mr),e(B,Or),i(s,Qt,p),v(pe,s,p),i(s,Xt,p),i(s,qs,p),e(qs,Vr),e(qs,Ke),e(Ke,Fr),e(qs,Rr),i(s,Zt,p),v(ie,s,p),i(s,sl,p),i(s,Ss,p),e(Ss,Hr),e(Ss,Qe),e(Qe,Yr),e(Ss,Br),i(s,el,p),i(s,U,p),e(U,Ur),e(U,Fa),e(Fa,Wr),e(U,Jr),e(U,Xe),e(Xe,Gr),e(U,Kr),i(s,al,p),v(he,s,p),i(s,tl,p),i(s,ls,p),e(ls,Cs),e(Cs,Ra),v(ce,Ra,null),e(ls,Qr),e(ls,Ha),e(Ha,Xr),i(s,ll,p),i(s,R,p),e(R,Ze),e(Ze,Zr),e(R,so),e(R,Ya),e(Ya,eo),e(R,ao),e(R,Ba),e(Ba,to),e(R,lo),i(s,nl,p),i(s,ns,p),e(ns,zs),e(zs,Ua),v(de,Ua,null),e(ns,no),e(ns,Wa),e(Wa,ro),i(s,rl,p),v(fe,s,p),i(s,ol,p),v(Ns,s,p),i(s,pl,p),i(s,rs,p),e(rs,Ls),e(Ls,Ja),v(me,Ja,null),e(rs,oo),e(rs,Ga),e(Ga,po),i(s,il,p),i(s,ue,p),e(ue,sa),e(sa,io),e(ue,ho),i(s,hl,p),v(ge,s,p),i(s,cl,p),i(s,ea,p),e(ea,co),i(s,dl,p),v(_e,s,p),fl=!0},p(s,[p]){const ve={};p&2&&(ve.$$scope={dirty:p,ctx:s}),hs.$set(ve);const Ka={};p&2&&(Ka.$$scope={dirty:p,ctx:s}),ds.$set(Ka);const Qa={};p&2&&(Qa.$$scope={dirty:p,ctx:s}),js.$set(Qa);const Xa={};p&2&&(Xa.$$scope={dirty:p,ctx:s}),Is.$set(Xa);const Za={};p&2&&(Za.$$scope={dirty:p,ctx:s}),Ns.$set(Za)},i(s){fl||(j(u.$$.fragment,s),j(Rs.$$.fragment,s),j(hs.$$.fragment,s),j(Hs.$$.fragment,s),j(Ys.$$.fragment,s),j(ds.$$.fragment,s),j(Bs.$$.fragment,s),j(Us.$$.fragment,s),j(Ws.$$.fragment,s),j(Js.$$.fragment,s),j(Gs.$$.fragment,s),j(js.$$.fragment,s),j(Ks.$$.fragment,s),j(Qs.$$.fragment,s),j(Xs.$$.fragment,s),j(Zs.$$.fragment,s),j(se.$$.fragment,s),j(ee.$$.fragment,s),j(ae.$$.fragment,s),j(te.$$.fragment,s),j(le.$$.fragment,s),j(ne.$$.fragment,s),j(Is.$$.fragment,s),j(re.$$.fragment,s),j(oe.$$.fragment,s),j(pe.$$.fragment,s),j(ie.$$.fragment,s),j(he.$$.fragment,s),j(ce.$$.fragment,s),j(de.$$.fragment,s),j(fe.$$.fragment,s),j(Ns.$$.fragment,s),j(me.$$.fragment,s),j(ge.$$.fragment,s),j(_e.$$.fragment,s),fl=!0)},o(s){b(u.$$.fragment,s),b(Rs.$$.fragment,s),b(hs.$$.fragment,s),b(Hs.$$.fragment,s),b(Ys.$$.fragment,s),b(ds.$$.fragment,s),b(Bs.$$.fragment,s),b(Us.$$.fragment,s),b(Ws.$$.fragment,s),b(Js.$$.fragment,s),b(Gs.$$.fragment,s),b(js.$$.fragment,s),b(Ks.$$.fragment,s),b(Qs.$$.fragment,s),b(Xs.$$.fragment,s),b(Zs.$$.fragment,s),b(se.$$.fragment,s),b(ee.$$.fragment,s),b(ae.$$.fragment,s),b(te.$$.fragment,s),b(le.$$.fragment,s),b(ne.$$.fragment,s),b(Is.$$.fragment,s),b(re.$$.fragment,s),b(oe.$$.fragment,s),b(pe.$$.fragment,s),b(ie.$$.fragment,s),b(he.$$.fragment,s),b(ce.$$.fragment,s),b(de.$$.fragment,s),b(fe.$$.fragment,s),b(Ns.$$.fragment,s),b(me.$$.fragment,s),b(ge.$$.fragment,s),b(_e.$$.fragment,s),fl=!1},d(s){a(f),s&&a(w),s&&a(m),$(u),s&&a(k),s&&a(I),s&&a(ps),s&&a(S),s&&a(lt),s&&a(W),s&&a(nt),s&&a(M),s&&a(rt),$(Rs,s),s&&a(ot),s&&a(H),s&&a(pt),$(hs,s),s&&a(it),s&&a(J),$(Hs),s&&a(ht),s&&a(O),s&&a(ct),s&&a(V),s&&a(dt),$(Ys,s),s&&a(ft),$(ds,s),s&&a(mt),s&&a(G),$(Bs),s&&a(ut),s&&a(ms),s&&a(gt),s&&a(us),s&&a(_t),$(Us,s),s&&a(vt),s&&a(K),$(Ws),s&&a(jt),s&&a(qe),s&&a(bt),s&&a(Se),s&&a($t),$(Js,s),s&&a(wt),s&&a(ze),s&&a(xt),$(Gs,s),s&&a(yt),$(js,s),s&&a(kt),s&&a(Le),s&&a(Et),s&&a(Q),$(Ks),s&&a(Dt),s&&a(X),s&&a(At),$(Qs,s),s&&a(It),s&&a($s),s&&a(Tt),$(Xs,s),s&&a(Pt),s&&a(Y),s&&a(qt),s&&a(Z),$(Zs),s&&a(St),s&&a(Ve),s&&a(Ct),s&&a(ss),$(se),s&&a(zt),s&&a(ys),s&&a(Nt),s&&a(ks),s&&a(Lt),$(ee,s),s&&a(Mt),s&&a(es),$(ae),s&&a(Ot),s&&a(Ds),s&&a(Vt),$(te,s),s&&a(Ft),s&&a(as),$(le),s&&a(Rt),s&&a(N),s&&a(Ht),$(ne,s),s&&a(Yt),$(Is,s),s&&a(Bt),s&&a(Ts),s&&a(Ut),$(re,s),s&&a(Wt),s&&a(ts),$(oe),s&&a(Jt),s&&a(P),s&&a(Gt),s&&a(Je),s&&a(Kt),s&&a(B),s&&a(Qt),$(pe,s),s&&a(Xt),s&&a(qs),s&&a(Zt),$(ie,s),s&&a(sl),s&&a(Ss),s&&a(el),s&&a(U),s&&a(al),$(he,s),s&&a(tl),s&&a(ls),$(ce),s&&a(ll),s&&a(R),s&&a(nl),s&&a(ns),$(de),s&&a(rl),$(fe,s),s&&a(ol),$(Ns,s),s&&a(pl),s&&a(rs),$(me),s&&a(il),s&&a(ue),s&&a(hl),$(ge,s),s&&a(cl),s&&a(ea),s&&a(dl),$(_e,s)}}}const ii={local:"stream",sections:[{local:"shuffle",title:"Shuffle"},{local:"reshuffle",title:"Reshuffle"},{local:"split-dataset",title:"Split dataset"},{local:"interleave",title:"Interleave"},{local:"rename-remove-and-cast",sections:[{local:"rename",title:"Rename"},{local:"remove",title:"Remove"},{local:"cast",title:"Cast"}],title:"Rename, remove, and cast"},{local:"map",sections:[{local:"batch-processing",sections:[{local:"tokenization",title:"Tokenization"}],title:"Batch processing"}],title:"Map"},{local:"stream-in-a-training-loop",title:"Stream in a training loop"}],title:"Stream"};function hi(C,f,w){let{fw:m}=f;return C.$$set=x=>{"fw"in x&&w(0,m=x.fw)},[m]}class gi extends Xp{constructor(f){super();Zp(this,f,hi,pi,si,{fw:0})}}export{gi as default,ii as metadata};
