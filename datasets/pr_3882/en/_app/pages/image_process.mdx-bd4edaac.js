import{S as ll,i as rl,s as nl,e as l,k as m,w as h,t as s,M as pl,c as r,d as t,m as f,a as p,x as c,h as o,b as d,N as ol,F as e,g as i,y as u,L as il,q as g,o as _,B as v}from"../chunks/vendor-e67aec41.js";import{I as _e}from"../chunks/IconCopyLink-ffd7f84e.js";import{C as E}from"../chunks/CodeBlock-e2bcf023.js";function ml($t){let q,ja,$,k,Ua,V,yt,Ga,wt,ve,L,jt,Ea,Et,kt,$e,y,Ha,bt,qt,X,It,Ra,xt,Ct,At,Z,Dt,ka,Pt,Tt,Ft,aa,Lt,ba,Jt,Nt,ye,D,J,Wa,ea,Ot,Ka,St,we,qa,Bt,je,N,ta,Yt,Qa,zt,Mt,Ut,Va,Gt,Ee,O,Ht,sa,Rt,Wt,ke,oa,be,w,Kt,Ia,Qt,Vt,Xa,Xt,Zt,Za,as,es,qe,la,Ie,xa,Ca,lo,xe,I,ts,Aa,ss,os,Da,ls,rs,Ce,ra,Ae,x,ns,ae,ps,is,ee,ms,fs,De,na,Pe,P,S,te,pa,ds,se,hs,Te,B,cs,oe,us,gs,Fe,ia,Le,C,_s,le,vs,$s,re,ys,ws,Je,ma,Ne,Y,js,ne,Es,ks,Oe,fa,Se,T,z,pe,da,bs,ie,qs,Be,M,Is,ha,xs,Cs,Ye,U,As,ca,me,Ds,Ps,ze,ua,Me,G,Ts,fe,Fs,Ls,Ue,ga,Ge,A,Js,Pa,Ns,Os,Ta,Ss,Bs,He,_a,Re,H,Ys,de,zs,Ms,We,va,Ke,Fa,La,ro,Qe,F,R,he,$a,Us,ce,Gs,Ve,b,Ja,Hs,Rs,Na,Ws,Ks,Oa,Qs,Vs,Xe,j,Xs,ue,Zs,ao,Sa,eo,to,ge,so,oo,Ze,ya,at;return V=new _e({}),ea=new _e({}),oa=new E({props:{code:`from datasets import load_dataset, Image

dataset = load_dataset("food101", split="train[100:]")
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[100:]&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="hljs-number">0x7FC45AB5C590</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>}`}}),la=new E({props:{code:`from datasets import load_dataset, Image

dataset = load_dataset("food101", split="train[100:200]")
dataset[0]["image"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[100:200]&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]`}}),ra=new E({props:{code:`from datasets import load_dataset, Image

dataset = Dataset.from_dict({"image_file_path": ["path/to/image_1", "path/to/image_2", ..., "path/to/image_n"]}).cast_column("image_file_path", Image())
dataset[0]["image_file_path"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = Dataset.from_dict({<span class="hljs-string">&quot;image_file_path&quot;</span>: [<span class="hljs-string">&quot;path/to/image_1&quot;</span>, <span class="hljs-string">&quot;path/to/image_2&quot;</span>, ..., <span class="hljs-string">&quot;path/to/image_n&quot;</span>]}).cast_column(<span class="hljs-string">&quot;image_file_path&quot;</span>, Image())
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image_file_path&quot;</span>]`}}),na=new E({props:{code:`dataset = load_dataset("food101", split="train[100:]").cast_column('image', Image(decode=False))`,highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[100:]&quot;</span>).cast_column(<span class="hljs-string">&#x27;image&#x27;</span>, Image(decode=<span class="hljs-literal">False</span>))'}}),pa=new _e({}),ia=new E({props:{code:`folder/dog/golden_retriever.png
folder/dog/german_shepherd.png
folder/dog/chihuahua.png

folder/cat/maine_coon.png
folder/cat/bengal.png
folder/cat/birman.png`,highlighted:`folder<span class="hljs-regexp">/dog/g</span>olden_retriever.png
folder<span class="hljs-regexp">/dog/g</span>erman_shepherd.png
folder<span class="hljs-regexp">/dog/</span>chihuahua.png

folder<span class="hljs-regexp">/cat/m</span>aine_coon.png
folder<span class="hljs-regexp">/cat/</span>bengal.png
folder<span class="hljs-regexp">/cat/</span>birman.png`}}),ma=new E({props:{code:`from datasets import load_dataset
dataset = load_dataset("imagefolder", data_dir="/path/to/folder")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>)`}}),fa=new E({props:{code:'dataset = load_dataset("imagefolder", data_files="https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip", split="train")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_files=<span class="hljs-string">&quot;https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)'}}),da=new _e({}),ua=new E({props:{code:`from torchvision.transforms import Compose, ColorJitter, ToTensor

jitter = Compose(
[
 ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.7),
 ToTensor(),
 ]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = Compose(
<span class="hljs-meta">... </span>[
<span class="hljs-meta">... </span> ColorJitter(brightness=<span class="hljs-number">0.25</span>, contrast=<span class="hljs-number">0.25</span>, saturation=<span class="hljs-number">0.25</span>, hue=<span class="hljs-number">0.7</span>),
<span class="hljs-meta">... </span> ToTensor(),
<span class="hljs-meta">... </span> ]
<span class="hljs-meta">... </span>)`}}),ga=new E({props:{code:`def transforms(examples):
    examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),_a=new E({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),va=new E({props:{code:`import numpy as np
import matplotlib.pyplot as plt

img = dataset[0]["pixel_values"]
plt.imshow(img.permute(1, 2, 0))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))`}}),$a=new _e({}),ya=new E({props:{code:"processed_food = dataset.map(transforms, batched=True)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>processed_food = dataset.<span class="hljs-built_in">map</span>(transforms, batched=<span class="hljs-literal">True</span>)'}}),{c(){q=l("meta"),ja=m(),$=l("h1"),k=l("a"),Ua=l("span"),h(V.$$.fragment),yt=m(),Ga=l("span"),wt=s("Process image data"),ve=m(),L=l("p"),jt=s("\u{1F917} Datasets support loading and processing images with the "),Ea=l("a"),Et=s("Image"),kt=s(" feature. This guide will show you how to:"),$e=m(),y=l("ul"),Ha=l("li"),bt=s("Load an image dataset."),qt=m(),X=l("li"),It=s("Load a generic image dataset with "),Ra=l("code"),xt=s("ImageFolder"),Ct=s("."),At=m(),Z=l("li"),Dt=s("Add data augmentations to your images with "),ka=l("a"),Pt=s("Dataset.set_transform()"),Tt=s("."),Ft=m(),aa=l("li"),Lt=s("Use "),ba=l("a"),Jt=s("map()"),Nt=s(" to quickly apply transforms to an entire dataset."),ye=m(),D=l("h2"),J=l("a"),Wa=l("span"),h(ea.$$.fragment),Ot=m(),Ka=l("span"),St=s("Image datasets"),we=m(),qa=l("p"),Bt=s("The images in an image dataset are typically either a:"),je=m(),N=l("ul"),ta=l("li"),Yt=s("PIL "),Qa=l("code"),zt=s("image"),Mt=s("."),Ut=m(),Va=l("li"),Gt=s("Path to an image file that you can load."),Ee=m(),O=l("p"),Ht=s("For example, load the "),sa=l("a"),Rt=s("Food-101"),Wt=s(" dataset and take a look:"),ke=m(),h(oa.$$.fragment),be=m(),w=l("p"),Kt=s("The "),Ia=l("a"),Qt=s("Image"),Vt=s(" feature automatically decodes the data from the "),Xa=l("code"),Xt=s("image"),Zt=s(" column to return an image object. Now try and call the "),Za=l("code"),as=s("image"),es=s(" column to see what the image is:"),qe=m(),h(la.$$.fragment),Ie=m(),xa=l("p"),Ca=l("img"),xe=m(),I=l("p"),ts=s("To load an image from its path, use the "),Aa=l("a"),ss=s("cast_column()"),os=s(" method. The "),Da=l("a"),ls=s("Image"),rs=s(" feature will decode the data at the path to return an image object:"),Ce=m(),h(ra.$$.fragment),Ae=m(),x=l("p"),ns=s("You can also access the path and bytes of an image file by setting "),ae=l("code"),ps=s("decode=False"),is=s(" when you load a dataset. In this case, you will need to cast the "),ee=l("code"),ms=s("image"),fs=s(" column:"),De=m(),h(na.$$.fragment),Pe=m(),P=l("h2"),S=l("a"),te=l("span"),h(pa.$$.fragment),ds=m(),se=l("span"),hs=s("ImageFolder"),Te=m(),B=l("p"),cs=s("You can also load your image dataset with a "),oe=l("code"),us=s("ImageFolder"),gs=s(" dataset builder without writing a custom dataloader. Your image dataset structure should look like this:"),Fe=m(),h(ia.$$.fragment),Le=m(),C=l("p"),_s=s("Then you can load your dataset by specifying "),le=l("code"),vs=s("imagefolder"),$s=s(" and the directory of your dataset in "),re=l("code"),ys=s("data_dir"),ws=s(":"),Je=m(),h(ma.$$.fragment),Ne=m(),Y=l("p"),js=s("Load remote datasets from their URLs with the "),ne=l("code"),Es=s("data_files"),ks=s(" parameter:"),Oe=m(),h(fa.$$.fragment),Se=m(),T=l("h2"),z=l("a"),pe=l("span"),h(da.$$.fragment),bs=m(),ie=l("span"),qs=s("Data augmentation"),Be=m(),M=l("p"),Is=s("Adding data augmentations to a dataset is common to prevent overfitting and achieve better performance. You can use any library or package you want to apply the augmentations. This guide will use the transforms from "),ha=l("a"),xs=s("torchvision"),Cs=s("."),Ye=m(),U=l("p"),As=s("Add the "),ca=l("a"),me=l("code"),Ds=s("ColorJitter"),Ps=s(" transform to change the color properties of the image randomly:"),ze=m(),h(ua.$$.fragment),Me=m(),G=l("p"),Ts=s("Create a function to apply the "),fe=l("code"),Fs=s("ColorJitter"),Ls=s(" transform to an image:"),Ue=m(),h(ga.$$.fragment),Ge=m(),A=l("p"),Js=s("Then you can use the "),Pa=l("a"),Ns=s("set_transform()"),Os=s(" function to apply the transformation on-the-fly to consume less disk space. You should use "),Ta=l("a"),Ss=s("set_transform()"),Bs=s(" if you only need to access the examples once:"),He=m(),h(_a.$$.fragment),Re=m(),H=l("p"),Ys=s("Now visualize the results of the "),de=l("code"),zs=s("ColorJitter"),Ms=s(" transform:"),We=m(),h(va.$$.fragment),Ke=m(),Fa=l("p"),La=l("img"),Qe=m(),F=l("h2"),R=l("a"),he=l("span"),h($a.$$.fragment),Us=m(),ce=l("span"),Gs=s("Map"),Ve=m(),b=l("p"),Ja=l("a"),Hs=s("map()"),Rs=s(" can also apply transforms over an entire dataset. When you use "),Na=l("a"),Ws=s("map()"),Ks=s(" to apply transforms, it generates a cache file. This saves time because you don\u2019t have to execute the same transform twice. You should use "),Oa=l("a"),Qs=s("map()"),Vs=s(" for operations you only run once per training - like resizing an image - instead of using it for operations that are executed for each epoch, like data augmentations."),Xe=m(),j=l("p"),Xs=s("To apply the same "),ue=l("code"),Zs=s("ColorJitter"),ao=s(" transform from above with "),Sa=l("a"),eo=s("map()"),to=s(", you need to set "),ge=l("code"),so=s("batched=True"),oo=s(":"),Ze=m(),h(ya.$$.fragment),this.h()},l(a){const n=pl('[data-svelte="svelte-1phssyn"]',document.head);q=r(n,"META",{name:!0,content:!0}),n.forEach(t),ja=f(a),$=r(a,"H1",{class:!0});var et=p($);k=r(et,"A",{id:!0,class:!0,href:!0});var no=p(k);Ua=r(no,"SPAN",{});var po=p(Ua);c(V.$$.fragment,po),po.forEach(t),no.forEach(t),yt=f(et),Ga=r(et,"SPAN",{});var io=p(Ga);wt=o(io,"Process image data"),io.forEach(t),et.forEach(t),ve=f(a),L=r(a,"P",{});var tt=p(L);jt=o(tt,"\u{1F917} Datasets support loading and processing images with the "),Ea=r(tt,"A",{href:!0});var mo=p(Ea);Et=o(mo,"Image"),mo.forEach(t),kt=o(tt," feature. This guide will show you how to:"),tt.forEach(t),$e=f(a),y=r(a,"UL",{});var W=p(y);Ha=r(W,"LI",{});var fo=p(Ha);bt=o(fo,"Load an image dataset."),fo.forEach(t),qt=f(W),X=r(W,"LI",{});var st=p(X);It=o(st,"Load a generic image dataset with "),Ra=r(st,"CODE",{});var ho=p(Ra);xt=o(ho,"ImageFolder"),ho.forEach(t),Ct=o(st,"."),st.forEach(t),At=f(W),Z=r(W,"LI",{});var ot=p(Z);Dt=o(ot,"Add data augmentations to your images with "),ka=r(ot,"A",{href:!0});var co=p(ka);Pt=o(co,"Dataset.set_transform()"),co.forEach(t),Tt=o(ot,"."),ot.forEach(t),Ft=f(W),aa=r(W,"LI",{});var lt=p(aa);Lt=o(lt,"Use "),ba=r(lt,"A",{href:!0});var uo=p(ba);Jt=o(uo,"map()"),uo.forEach(t),Nt=o(lt," to quickly apply transforms to an entire dataset."),lt.forEach(t),W.forEach(t),ye=f(a),D=r(a,"H2",{class:!0});var rt=p(D);J=r(rt,"A",{id:!0,class:!0,href:!0});var go=p(J);Wa=r(go,"SPAN",{});var _o=p(Wa);c(ea.$$.fragment,_o),_o.forEach(t),go.forEach(t),Ot=f(rt),Ka=r(rt,"SPAN",{});var vo=p(Ka);St=o(vo,"Image datasets"),vo.forEach(t),rt.forEach(t),we=f(a),qa=r(a,"P",{});var $o=p(qa);Bt=o($o,"The images in an image dataset are typically either a:"),$o.forEach(t),je=f(a),N=r(a,"UL",{});var nt=p(N);ta=r(nt,"LI",{});var pt=p(ta);Yt=o(pt,"PIL "),Qa=r(pt,"CODE",{});var yo=p(Qa);zt=o(yo,"image"),yo.forEach(t),Mt=o(pt,"."),pt.forEach(t),Ut=f(nt),Va=r(nt,"LI",{});var wo=p(Va);Gt=o(wo,"Path to an image file that you can load."),wo.forEach(t),nt.forEach(t),Ee=f(a),O=r(a,"P",{});var it=p(O);Ht=o(it,"For example, load the "),sa=r(it,"A",{href:!0,rel:!0});var jo=p(sa);Rt=o(jo,"Food-101"),jo.forEach(t),Wt=o(it," dataset and take a look:"),it.forEach(t),ke=f(a),c(oa.$$.fragment,a),be=f(a),w=r(a,"P",{});var K=p(w);Kt=o(K,"The "),Ia=r(K,"A",{href:!0});var Eo=p(Ia);Qt=o(Eo,"Image"),Eo.forEach(t),Vt=o(K," feature automatically decodes the data from the "),Xa=r(K,"CODE",{});var ko=p(Xa);Xt=o(ko,"image"),ko.forEach(t),Zt=o(K," column to return an image object. Now try and call the "),Za=r(K,"CODE",{});var bo=p(Za);as=o(bo,"image"),bo.forEach(t),es=o(K," column to see what the image is:"),K.forEach(t),qe=f(a),c(la.$$.fragment,a),Ie=f(a),xa=r(a,"P",{});var qo=p(xa);Ca=r(qo,"IMG",{src:!0,alt:!0}),qo.forEach(t),xe=f(a),I=r(a,"P",{});var Ba=p(I);ts=o(Ba,"To load an image from its path, use the "),Aa=r(Ba,"A",{href:!0});var Io=p(Aa);ss=o(Io,"cast_column()"),Io.forEach(t),os=o(Ba," method. The "),Da=r(Ba,"A",{href:!0});var xo=p(Da);ls=o(xo,"Image"),xo.forEach(t),rs=o(Ba," feature will decode the data at the path to return an image object:"),Ba.forEach(t),Ce=f(a),c(ra.$$.fragment,a),Ae=f(a),x=r(a,"P",{});var Ya=p(x);ns=o(Ya,"You can also access the path and bytes of an image file by setting "),ae=r(Ya,"CODE",{});var Co=p(ae);ps=o(Co,"decode=False"),Co.forEach(t),is=o(Ya," when you load a dataset. In this case, you will need to cast the "),ee=r(Ya,"CODE",{});var Ao=p(ee);ms=o(Ao,"image"),Ao.forEach(t),fs=o(Ya," column:"),Ya.forEach(t),De=f(a),c(na.$$.fragment,a),Pe=f(a),P=r(a,"H2",{class:!0});var mt=p(P);S=r(mt,"A",{id:!0,class:!0,href:!0});var Do=p(S);te=r(Do,"SPAN",{});var Po=p(te);c(pa.$$.fragment,Po),Po.forEach(t),Do.forEach(t),ds=f(mt),se=r(mt,"SPAN",{});var To=p(se);hs=o(To,"ImageFolder"),To.forEach(t),mt.forEach(t),Te=f(a),B=r(a,"P",{});var ft=p(B);cs=o(ft,"You can also load your image dataset with a "),oe=r(ft,"CODE",{});var Fo=p(oe);us=o(Fo,"ImageFolder"),Fo.forEach(t),gs=o(ft," dataset builder without writing a custom dataloader. Your image dataset structure should look like this:"),ft.forEach(t),Fe=f(a),c(ia.$$.fragment,a),Le=f(a),C=r(a,"P",{});var za=p(C);_s=o(za,"Then you can load your dataset by specifying "),le=r(za,"CODE",{});var Lo=p(le);vs=o(Lo,"imagefolder"),Lo.forEach(t),$s=o(za," and the directory of your dataset in "),re=r(za,"CODE",{});var Jo=p(re);ys=o(Jo,"data_dir"),Jo.forEach(t),ws=o(za,":"),za.forEach(t),Je=f(a),c(ma.$$.fragment,a),Ne=f(a),Y=r(a,"P",{});var dt=p(Y);js=o(dt,"Load remote datasets from their URLs with the "),ne=r(dt,"CODE",{});var No=p(ne);Es=o(No,"data_files"),No.forEach(t),ks=o(dt," parameter:"),dt.forEach(t),Oe=f(a),c(fa.$$.fragment,a),Se=f(a),T=r(a,"H2",{class:!0});var ht=p(T);z=r(ht,"A",{id:!0,class:!0,href:!0});var Oo=p(z);pe=r(Oo,"SPAN",{});var So=p(pe);c(da.$$.fragment,So),So.forEach(t),Oo.forEach(t),bs=f(ht),ie=r(ht,"SPAN",{});var Bo=p(ie);qs=o(Bo,"Data augmentation"),Bo.forEach(t),ht.forEach(t),Be=f(a),M=r(a,"P",{});var ct=p(M);Is=o(ct,"Adding data augmentations to a dataset is common to prevent overfitting and achieve better performance. You can use any library or package you want to apply the augmentations. This guide will use the transforms from "),ha=r(ct,"A",{href:!0,rel:!0});var Yo=p(ha);xs=o(Yo,"torchvision"),Yo.forEach(t),Cs=o(ct,"."),ct.forEach(t),Ye=f(a),U=r(a,"P",{});var ut=p(U);As=o(ut,"Add the "),ca=r(ut,"A",{href:!0,rel:!0});var zo=p(ca);me=r(zo,"CODE",{});var Mo=p(me);Ds=o(Mo,"ColorJitter"),Mo.forEach(t),zo.forEach(t),Ps=o(ut," transform to change the color properties of the image randomly:"),ut.forEach(t),ze=f(a),c(ua.$$.fragment,a),Me=f(a),G=r(a,"P",{});var gt=p(G);Ts=o(gt,"Create a function to apply the "),fe=r(gt,"CODE",{});var Uo=p(fe);Fs=o(Uo,"ColorJitter"),Uo.forEach(t),Ls=o(gt," transform to an image:"),gt.forEach(t),Ue=f(a),c(ga.$$.fragment,a),Ge=f(a),A=r(a,"P",{});var Ma=p(A);Js=o(Ma,"Then you can use the "),Pa=r(Ma,"A",{href:!0});var Go=p(Pa);Ns=o(Go,"set_transform()"),Go.forEach(t),Os=o(Ma," function to apply the transformation on-the-fly to consume less disk space. You should use "),Ta=r(Ma,"A",{href:!0});var Ho=p(Ta);Ss=o(Ho,"set_transform()"),Ho.forEach(t),Bs=o(Ma," if you only need to access the examples once:"),Ma.forEach(t),He=f(a),c(_a.$$.fragment,a),Re=f(a),H=r(a,"P",{});var _t=p(H);Ys=o(_t,"Now visualize the results of the "),de=r(_t,"CODE",{});var Ro=p(de);zs=o(Ro,"ColorJitter"),Ro.forEach(t),Ms=o(_t," transform:"),_t.forEach(t),We=f(a),c(va.$$.fragment,a),Ke=f(a),Fa=r(a,"P",{});var Wo=p(Fa);La=r(Wo,"IMG",{src:!0,alt:!0}),Wo.forEach(t),Qe=f(a),F=r(a,"H2",{class:!0});var vt=p(F);R=r(vt,"A",{id:!0,class:!0,href:!0});var Ko=p(R);he=r(Ko,"SPAN",{});var Qo=p(he);c($a.$$.fragment,Qo),Qo.forEach(t),Ko.forEach(t),Us=f(vt),ce=r(vt,"SPAN",{});var Vo=p(ce);Gs=o(Vo,"Map"),Vo.forEach(t),vt.forEach(t),Ve=f(a),b=r(a,"P",{});var wa=p(b);Ja=r(wa,"A",{href:!0});var Xo=p(Ja);Hs=o(Xo,"map()"),Xo.forEach(t),Rs=o(wa," can also apply transforms over an entire dataset. When you use "),Na=r(wa,"A",{href:!0});var Zo=p(Na);Ws=o(Zo,"map()"),Zo.forEach(t),Ks=o(wa," to apply transforms, it generates a cache file. This saves time because you don\u2019t have to execute the same transform twice. You should use "),Oa=r(wa,"A",{href:!0});var al=p(Oa);Qs=o(al,"map()"),al.forEach(t),Vs=o(wa," for operations you only run once per training - like resizing an image - instead of using it for operations that are executed for each epoch, like data augmentations."),wa.forEach(t),Xe=f(a),j=r(a,"P",{});var Q=p(j);Xs=o(Q,"To apply the same "),ue=r(Q,"CODE",{});var el=p(ue);Zs=o(el,"ColorJitter"),el.forEach(t),ao=o(Q," transform from above with "),Sa=r(Q,"A",{href:!0});var tl=p(Sa);eo=o(tl,"map()"),tl.forEach(t),to=o(Q,", you need to set "),ge=r(Q,"CODE",{});var sl=p(ge);so=o(sl,"batched=True"),sl.forEach(t),oo=o(Q,":"),Q.forEach(t),Ze=f(a),c(ya.$$.fragment,a),this.h()},h(){d(q,"name","hf:doc:metadata"),d(q,"content",JSON.stringify(fl)),d(k,"id","process-image-data"),d(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(k,"href","#process-image-data"),d($,"class","relative group"),d(Ea,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Image"),d(ka,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.set_transform"),d(ba,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),d(J,"id","image-datasets"),d(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J,"href","#image-datasets"),d(D,"class","relative group"),d(sa,"href","https://huggingface.co/datasets/food101"),d(sa,"rel","nofollow"),d(Ia,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Image"),ol(Ca.src,lo="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_beignet.png")||d(Ca,"src",lo),d(Ca,"alt","image_process_beignet"),d(Aa,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.cast_column"),d(Da,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Image"),d(S,"id","imagefolder"),d(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S,"href","#imagefolder"),d(P,"class","relative group"),d(z,"id","data-augmentation"),d(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z,"href","#data-augmentation"),d(T,"class","relative group"),d(ha,"href","https://pytorch.org/vision/stable/transforms.html"),d(ha,"rel","nofollow"),d(ca,"href","https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ColorJitter"),d(ca,"rel","nofollow"),d(Pa,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.set_transform"),d(Ta,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.set_transform"),ol(La.src,ro="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_jitter.png")||d(La,"src",ro),d(La,"alt","image_process_jitter"),d(R,"id","map"),d(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(R,"href","#map"),d(F,"class","relative group"),d(Ja,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),d(Na,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),d(Oa,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),d(Sa,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map")},m(a,n){e(document.head,q),i(a,ja,n),i(a,$,n),e($,k),e(k,Ua),u(V,Ua,null),e($,yt),e($,Ga),e(Ga,wt),i(a,ve,n),i(a,L,n),e(L,jt),e(L,Ea),e(Ea,Et),e(L,kt),i(a,$e,n),i(a,y,n),e(y,Ha),e(Ha,bt),e(y,qt),e(y,X),e(X,It),e(X,Ra),e(Ra,xt),e(X,Ct),e(y,At),e(y,Z),e(Z,Dt),e(Z,ka),e(ka,Pt),e(Z,Tt),e(y,Ft),e(y,aa),e(aa,Lt),e(aa,ba),e(ba,Jt),e(aa,Nt),i(a,ye,n),i(a,D,n),e(D,J),e(J,Wa),u(ea,Wa,null),e(D,Ot),e(D,Ka),e(Ka,St),i(a,we,n),i(a,qa,n),e(qa,Bt),i(a,je,n),i(a,N,n),e(N,ta),e(ta,Yt),e(ta,Qa),e(Qa,zt),e(ta,Mt),e(N,Ut),e(N,Va),e(Va,Gt),i(a,Ee,n),i(a,O,n),e(O,Ht),e(O,sa),e(sa,Rt),e(O,Wt),i(a,ke,n),u(oa,a,n),i(a,be,n),i(a,w,n),e(w,Kt),e(w,Ia),e(Ia,Qt),e(w,Vt),e(w,Xa),e(Xa,Xt),e(w,Zt),e(w,Za),e(Za,as),e(w,es),i(a,qe,n),u(la,a,n),i(a,Ie,n),i(a,xa,n),e(xa,Ca),i(a,xe,n),i(a,I,n),e(I,ts),e(I,Aa),e(Aa,ss),e(I,os),e(I,Da),e(Da,ls),e(I,rs),i(a,Ce,n),u(ra,a,n),i(a,Ae,n),i(a,x,n),e(x,ns),e(x,ae),e(ae,ps),e(x,is),e(x,ee),e(ee,ms),e(x,fs),i(a,De,n),u(na,a,n),i(a,Pe,n),i(a,P,n),e(P,S),e(S,te),u(pa,te,null),e(P,ds),e(P,se),e(se,hs),i(a,Te,n),i(a,B,n),e(B,cs),e(B,oe),e(oe,us),e(B,gs),i(a,Fe,n),u(ia,a,n),i(a,Le,n),i(a,C,n),e(C,_s),e(C,le),e(le,vs),e(C,$s),e(C,re),e(re,ys),e(C,ws),i(a,Je,n),u(ma,a,n),i(a,Ne,n),i(a,Y,n),e(Y,js),e(Y,ne),e(ne,Es),e(Y,ks),i(a,Oe,n),u(fa,a,n),i(a,Se,n),i(a,T,n),e(T,z),e(z,pe),u(da,pe,null),e(T,bs),e(T,ie),e(ie,qs),i(a,Be,n),i(a,M,n),e(M,Is),e(M,ha),e(ha,xs),e(M,Cs),i(a,Ye,n),i(a,U,n),e(U,As),e(U,ca),e(ca,me),e(me,Ds),e(U,Ps),i(a,ze,n),u(ua,a,n),i(a,Me,n),i(a,G,n),e(G,Ts),e(G,fe),e(fe,Fs),e(G,Ls),i(a,Ue,n),u(ga,a,n),i(a,Ge,n),i(a,A,n),e(A,Js),e(A,Pa),e(Pa,Ns),e(A,Os),e(A,Ta),e(Ta,Ss),e(A,Bs),i(a,He,n),u(_a,a,n),i(a,Re,n),i(a,H,n),e(H,Ys),e(H,de),e(de,zs),e(H,Ms),i(a,We,n),u(va,a,n),i(a,Ke,n),i(a,Fa,n),e(Fa,La),i(a,Qe,n),i(a,F,n),e(F,R),e(R,he),u($a,he,null),e(F,Us),e(F,ce),e(ce,Gs),i(a,Ve,n),i(a,b,n),e(b,Ja),e(Ja,Hs),e(b,Rs),e(b,Na),e(Na,Ws),e(b,Ks),e(b,Oa),e(Oa,Qs),e(b,Vs),i(a,Xe,n),i(a,j,n),e(j,Xs),e(j,ue),e(ue,Zs),e(j,ao),e(j,Sa),e(Sa,eo),e(j,to),e(j,ge),e(ge,so),e(j,oo),i(a,Ze,n),u(ya,a,n),at=!0},p:il,i(a){at||(g(V.$$.fragment,a),g(ea.$$.fragment,a),g(oa.$$.fragment,a),g(la.$$.fragment,a),g(ra.$$.fragment,a),g(na.$$.fragment,a),g(pa.$$.fragment,a),g(ia.$$.fragment,a),g(ma.$$.fragment,a),g(fa.$$.fragment,a),g(da.$$.fragment,a),g(ua.$$.fragment,a),g(ga.$$.fragment,a),g(_a.$$.fragment,a),g(va.$$.fragment,a),g($a.$$.fragment,a),g(ya.$$.fragment,a),at=!0)},o(a){_(V.$$.fragment,a),_(ea.$$.fragment,a),_(oa.$$.fragment,a),_(la.$$.fragment,a),_(ra.$$.fragment,a),_(na.$$.fragment,a),_(pa.$$.fragment,a),_(ia.$$.fragment,a),_(ma.$$.fragment,a),_(fa.$$.fragment,a),_(da.$$.fragment,a),_(ua.$$.fragment,a),_(ga.$$.fragment,a),_(_a.$$.fragment,a),_(va.$$.fragment,a),_($a.$$.fragment,a),_(ya.$$.fragment,a),at=!1},d(a){t(q),a&&t(ja),a&&t($),v(V),a&&t(ve),a&&t(L),a&&t($e),a&&t(y),a&&t(ye),a&&t(D),v(ea),a&&t(we),a&&t(qa),a&&t(je),a&&t(N),a&&t(Ee),a&&t(O),a&&t(ke),v(oa,a),a&&t(be),a&&t(w),a&&t(qe),v(la,a),a&&t(Ie),a&&t(xa),a&&t(xe),a&&t(I),a&&t(Ce),v(ra,a),a&&t(Ae),a&&t(x),a&&t(De),v(na,a),a&&t(Pe),a&&t(P),v(pa),a&&t(Te),a&&t(B),a&&t(Fe),v(ia,a),a&&t(Le),a&&t(C),a&&t(Je),v(ma,a),a&&t(Ne),a&&t(Y),a&&t(Oe),v(fa,a),a&&t(Se),a&&t(T),v(da),a&&t(Be),a&&t(M),a&&t(Ye),a&&t(U),a&&t(ze),v(ua,a),a&&t(Me),a&&t(G),a&&t(Ue),v(ga,a),a&&t(Ge),a&&t(A),a&&t(He),v(_a,a),a&&t(Re),a&&t(H),a&&t(We),v(va,a),a&&t(Ke),a&&t(Fa),a&&t(Qe),a&&t(F),v($a),a&&t(Ve),a&&t(b),a&&t(Xe),a&&t(j),a&&t(Ze),v(ya,a)}}}const fl={local:"process-image-data",sections:[{local:"image-datasets",title:"Image datasets"},{local:"imagefolder",title:"ImageFolder"},{local:"data-augmentation",title:"Data augmentation"},{local:"map",title:"Map"}],title:"Process image data"};function dl($t,q,ja){let{fw:$}=q;return $t.$$set=k=>{"fw"in k&&ja(0,$=k.fw)},[$]}class gl extends ll{constructor(q){super();rl(this,q,dl,ml,nl,{fw:0})}}export{gl as default,fl as metadata};
