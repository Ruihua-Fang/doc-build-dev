import{S as Xo,i as Zo,s as er,e as o,k as m,w as h,t as s,M as ar,c as r,d as t,m as f,a as n,x as d,h as l,b as c,N as Wo,F as a,g as i,y as u,L as tr,q as g,o as _,B as v}from"../chunks/vendor-e67aec41.js";import{I as Pa}from"../chunks/IconCopyLink-ffd7f84e.js";import{C as y}from"../chunks/CodeBlock-e2bcf023.js";function sr(Gt){let k,qe,w,b,Ze,ee,Ut,ea,Yt,Da,L,Mt,Ce,Ht,Kt,Aa,j,aa,Qt,Vt,ae,Wt,ta,Xt,Zt,es,te,as,Pe,ts,ss,ls,se,os,De,rs,ns,Ta,P,F,sa,le,ps,la,is,La,Ae,ms,Fa,B,oe,fs,oa,cs,hs,ds,ra,us,Ba,z,gs,re,_s,vs,za,ne,Oa,E,$s,Te,ys,ws,na,js,Es,pa,bs,ks,Na,pe,Ja,Le,Fe,Yl,Sa,x,xs,Be,Is,qs,ze,Cs,Ps,Ra,ie,Ga,I,Ds,ia,As,Ts,ma,Ls,Fs,Ua,me,Ya,D,O,fa,fe,Bs,ca,zs,Ma,N,Os,ha,Ns,Js,Ha,ce,Ka,q,Ss,da,Rs,Gs,ua,Us,Ys,Qa,he,Va,J,Ms,ga,Hs,Ks,Wa,de,Xa,A,S,_a,ue,Qs,va,Vs,Za,R,Ws,ge,Xs,Zs,et,G,el,_e,$a,al,tl,at,ve,tt,U,sl,ya,ll,ol,st,$e,lt,Y,rl,Oe,nl,pl,ot,ye,rt,M,il,wa,ml,fl,nt,we,pt,Ne,Je,Ml,it,T,H,ja,je,cl,Ea,hl,mt,Ee,Se,dl,ul,ft,K,gl,be,ba,_l,vl,ct,ke,ht,$,$l,Re,yl,wl,ka,jl,El,xa,bl,kl,Ia,xl,Il,dt,xe,ut,Q,ql,Ge,Cl,Pl,gt,Ie,Ue,Dl,Al,_t,V,Ye,Me,qa,Tl,Ll,Fl,He,Ke,Ca,Bl,zl,vt,W,Ol,Qe,Nl,Jl,$t;return ee=new Pa({}),le=new Pa({}),ne=new y({props:{code:`from datasets import load_dataset, Image

dataset = load_dataset("food101", split="train[100:]")
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[100:]&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="hljs-number">0x7FC45AB5C590</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>}`}}),pe=new y({props:{code:`from datasets import load_dataset, Image

dataset = load_dataset("food101", split="train[100:200]")
dataset[0]["image"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[100:200]&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]`}}),ie=new y({props:{code:`from datasets import load_dataset, Image

dataset = Dataset.from_dict({"image_file_path": ["path/to/image_1", "path/to/image_2", ..., "path/to/image_n"]}).cast_column("image_file_path", Image())
dataset[0]["image_file_path"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = Dataset.from_dict({<span class="hljs-string">&quot;image_file_path&quot;</span>: [<span class="hljs-string">&quot;path/to/image_1&quot;</span>, <span class="hljs-string">&quot;path/to/image_2&quot;</span>, ..., <span class="hljs-string">&quot;path/to/image_n&quot;</span>]}).cast_column(<span class="hljs-string">&quot;image_file_path&quot;</span>, Image())
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image_file_path&quot;</span>]`}}),me=new y({props:{code:`dataset = load_dataset("food101", split="train[100:]").cast_column('image', Image(decode=False))`,highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[100:]&quot;</span>).cast_column(<span class="hljs-string">&#x27;image&#x27;</span>, Image(decode=<span class="hljs-literal">False</span>))'}}),fe=new Pa({}),ce=new y({props:{code:`folder/dog/golden_retriever.png
folder/dog/german_shepherd.png
folder/dog/chihuahua.png

folder/cat/maine_coon.png
folder/cat/bengal.png
folder/cat/birman.png`,highlighted:`folder<span class="hljs-regexp">/dog/g</span>olden_retriever.png
folder<span class="hljs-regexp">/dog/g</span>erman_shepherd.png
folder<span class="hljs-regexp">/dog/</span>chihuahua.png

folder<span class="hljs-regexp">/cat/m</span>aine_coon.png
folder<span class="hljs-regexp">/cat/</span>bengal.png
folder<span class="hljs-regexp">/cat/</span>birman.png`}}),he=new y({props:{code:`from datasets import load_dataset
dataset = load_dataset("imagefolder", data_dir="/path/to/folder")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>)`}}),de=new y({props:{code:'dataset = load_dataset("imagefolder", data_files="https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip", split="train")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_files=<span class="hljs-string">&quot;https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)'}}),ue=new Pa({}),ve=new y({props:{code:`from torchvision.transforms import Compose, ColorJitter, ToTensor

jitter = Compose(
    [
         ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.7),
         ToTensor(),
    ]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = Compose(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>         ColorJitter(brightness=<span class="hljs-number">0.25</span>, contrast=<span class="hljs-number">0.25</span>, saturation=<span class="hljs-number">0.25</span>, hue=<span class="hljs-number">0.7</span>),
<span class="hljs-meta">... </span>         ToTensor(),
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)`}}),$e=new y({props:{code:`def transforms(examples):
    examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),ye=new y({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),we=new y({props:{code:`import numpy as np
import matplotlib.pyplot as plt

img = dataset[0]["pixel_values"]
plt.imshow(img.permute(1, 2, 0))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))`}}),je=new Pa({}),ke=new y({props:{code:`def transforms(examples):
    examples["pixel_values"] = [image.convert("RGB").resize((100,100)) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [image.convert(<span class="hljs-string">&quot;RGB&quot;</span>).resize((<span class="hljs-number">100</span>,<span class="hljs-number">100</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),xe=new y({props:{code:`dataset = dataset.map(transforms, batched=True)
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(transforms, batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="hljs-number">0x7F058237BCD0</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>,
 <span class="hljs-string">&#x27;pixel_values&#x27;</span>: &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=100x100 at <span class="hljs-number">0x7F058237BB10</span>&gt;}`}}),{c(){k=o("meta"),qe=m(),w=o("h1"),b=o("a"),Ze=o("span"),h(ee.$$.fragment),Ut=m(),ea=o("span"),Yt=s("Process image data"),Da=m(),L=o("p"),Mt=s("\u{1F917} Datasets support loading and processing images with the "),Ce=o("a"),Ht=s("Image"),Kt=s(" feature. This guide will show you how to:"),Aa=m(),j=o("ul"),aa=o("li"),Qt=s("Load an image dataset."),Vt=m(),ae=o("li"),Wt=s("Load a generic image dataset with "),ta=o("code"),Xt=s("ImageFolder"),Zt=s("."),es=m(),te=o("li"),as=s("Add data augmentations to your images with "),Pe=o("a"),ts=s("Dataset.set_transform()"),ss=s("."),ls=m(),se=o("li"),os=s("Use "),De=o("a"),rs=s("map()"),ns=s(" to quickly apply transforms to an entire dataset."),Ta=m(),P=o("h2"),F=o("a"),sa=o("span"),h(le.$$.fragment),ps=m(),la=o("span"),is=s("Image datasets"),La=m(),Ae=o("p"),ms=s("The images in an image dataset are typically either a:"),Fa=m(),B=o("ul"),oe=o("li"),fs=s("PIL "),oa=o("code"),cs=s("image"),hs=s("."),ds=m(),ra=o("li"),us=s("Path to an image file you can load."),Ba=m(),z=o("p"),gs=s("For example, load the "),re=o("a"),_s=s("Food-101"),vs=s(" dataset and take a look:"),za=m(),h(ne.$$.fragment),Oa=m(),E=o("p"),$s=s("The "),Te=o("a"),ys=s("Image"),ws=s(" feature automatically decodes the data from the "),na=o("code"),js=s("image"),Es=s(" column to return an image object. Now try and call the "),pa=o("code"),bs=s("image"),ks=s(" column to see what the image is:"),Na=m(),h(pe.$$.fragment),Ja=m(),Le=o("p"),Fe=o("img"),Sa=m(),x=o("p"),xs=s("To load an image from its path, use the "),Be=o("a"),Is=s("cast_column()"),qs=s(" method. The "),ze=o("a"),Cs=s("Image"),Ps=s(" feature will decode the data at the path to return an image object:"),Ra=m(),h(ie.$$.fragment),Ga=m(),I=o("p"),Ds=s("You can also access the path and bytes of an image file by setting "),ia=o("code"),As=s("decode=False"),Ts=s(" when you load a dataset. In this case, you will need to cast the "),ma=o("code"),Ls=s("image"),Fs=s(" column:"),Ua=m(),h(me.$$.fragment),Ya=m(),D=o("h2"),O=o("a"),fa=o("span"),h(fe.$$.fragment),Bs=m(),ca=o("span"),zs=s("ImageFolder"),Ma=m(),N=o("p"),Os=s("You can also load your image dataset with a "),ha=o("code"),Ns=s("ImageFolder"),Js=s(" dataset builder without writing a custom dataloader. Your image dataset structure should look like this:"),Ha=m(),h(ce.$$.fragment),Ka=m(),q=o("p"),Ss=s("Then load your dataset by specifying "),da=o("code"),Rs=s("imagefolder"),Gs=s(" and the directory of your dataset in "),ua=o("code"),Us=s("data_dir"),Ys=s(":"),Qa=m(),h(he.$$.fragment),Va=m(),J=o("p"),Ms=s("Load remote datasets from their URLs with the "),ga=o("code"),Hs=s("data_files"),Ks=s(" parameter:"),Wa=m(),h(de.$$.fragment),Xa=m(),A=o("h2"),S=o("a"),_a=o("span"),h(ue.$$.fragment),Qs=m(),va=o("span"),Vs=s("Data augmentation"),Za=m(),R=o("p"),Ws=s("Adding data augmentations to a dataset is common to prevent overfitting and achieve better performance. You can use any library or package you want to apply the augmentations. This guide will use the transforms from "),ge=o("a"),Xs=s("torchvision"),Zs=s("."),et=m(),G=o("p"),el=s("Add the "),_e=o("a"),$a=o("code"),al=s("ColorJitter"),tl=s(" transform to change the color properties of the image randomly:"),at=m(),h(ve.$$.fragment),tt=m(),U=o("p"),sl=s("Create a function to apply the "),ya=o("code"),ll=s("ColorJitter"),ol=s(" transform to an image:"),st=m(),h($e.$$.fragment),lt=m(),Y=o("p"),rl=s("Then you can use the "),Oe=o("a"),nl=s("set_transform()"),pl=s(" function to apply the transform on-the-fly to consume less disk space. Use this function if you only need to access the examples once:"),ot=m(),h(ye.$$.fragment),rt=m(),M=o("p"),il=s("Now visualize the results of the "),wa=o("code"),ml=s("ColorJitter"),fl=s(" transform:"),nt=m(),h(we.$$.fragment),pt=m(),Ne=o("p"),Je=o("img"),it=m(),T=o("h2"),H=o("a"),ja=o("span"),h(je.$$.fragment),cl=m(),Ea=o("span"),hl=s("Map"),mt=m(),Ee=o("p"),Se=o("a"),dl=s("map()"),ul=s(" can also apply transforms over an entire dataset and it also generates a cache file."),ft=m(),K=o("p"),gl=s("Create a simple "),be=o("a"),ba=o("code"),_l=s("Resize"),vl=s(" function:"),ct=m(),h(ke.$$.fragment),ht=m(),$=o("p"),$l=s("Now "),Re=o("a"),yl=s("map()"),wl=s(" the function over the entire dataset and set "),ka=o("code"),jl=s("batched=True"),El=s(". The transform returns "),xa=o("code"),bl=s("pixel_values"),kl=s(" as a cacheable "),Ia=o("code"),xl=s("PIL.Image"),Il=s(" object:"),dt=m(),h(xe.$$.fragment),ut=m(),Q=o("p"),ql=s("This saves time because you don\u2019t have to execute the same transform twice. It is best to use "),Ge=o("a"),Cl=s("map()"),Pl=s(" for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),gt=m(),Ie=o("p"),Ue=o("a"),Dl=s("map()"),Al=s(" takes up some memory, but you can reduce its memory requirements with the following parameters:"),_t=m(),V=o("ul"),Ye=o("li"),Me=o("a"),qa=o("code"),Tl=s("batch_size"),Ll=s(" determines the number of examples that are processed in one call to the transform function."),Fl=m(),He=o("li"),Ke=o("a"),Ca=o("code"),Bl=s("writer_batch_size"),zl=s(" determines the number of processed examples that are kept in memory before they are stored away."),vt=m(),W=o("p"),Ol=s("Both parameter values default to 1000, which can be expensive if you are storing images. Lower the value to use less memory when calling "),Qe=o("a"),Nl=s("map()"),Jl=s("."),this.h()},l(e){const p=ar('[data-svelte="svelte-1phssyn"]',document.head);k=r(p,"META",{name:!0,content:!0}),p.forEach(t),qe=f(e),w=r(e,"H1",{class:!0});var yt=n(w);b=r(yt,"A",{id:!0,class:!0,href:!0});var Hl=n(b);Ze=r(Hl,"SPAN",{});var Kl=n(Ze);d(ee.$$.fragment,Kl),Kl.forEach(t),Hl.forEach(t),Ut=f(yt),ea=r(yt,"SPAN",{});var Ql=n(ea);Yt=l(Ql,"Process image data"),Ql.forEach(t),yt.forEach(t),Da=f(e),L=r(e,"P",{});var wt=n(L);Mt=l(wt,"\u{1F917} Datasets support loading and processing images with the "),Ce=r(wt,"A",{href:!0});var Vl=n(Ce);Ht=l(Vl,"Image"),Vl.forEach(t),Kt=l(wt," feature. This guide will show you how to:"),wt.forEach(t),Aa=f(e),j=r(e,"UL",{});var X=n(j);aa=r(X,"LI",{});var Wl=n(aa);Qt=l(Wl,"Load an image dataset."),Wl.forEach(t),Vt=f(X),ae=r(X,"LI",{});var jt=n(ae);Wt=l(jt,"Load a generic image dataset with "),ta=r(jt,"CODE",{});var Xl=n(ta);Xt=l(Xl,"ImageFolder"),Xl.forEach(t),Zt=l(jt,"."),jt.forEach(t),es=f(X),te=r(X,"LI",{});var Et=n(te);as=l(Et,"Add data augmentations to your images with "),Pe=r(Et,"A",{href:!0});var Zl=n(Pe);ts=l(Zl,"Dataset.set_transform()"),Zl.forEach(t),ss=l(Et,"."),Et.forEach(t),ls=f(X),se=r(X,"LI",{});var bt=n(se);os=l(bt,"Use "),De=r(bt,"A",{href:!0});var eo=n(De);rs=l(eo,"map()"),eo.forEach(t),ns=l(bt," to quickly apply transforms to an entire dataset."),bt.forEach(t),X.forEach(t),Ta=f(e),P=r(e,"H2",{class:!0});var kt=n(P);F=r(kt,"A",{id:!0,class:!0,href:!0});var ao=n(F);sa=r(ao,"SPAN",{});var to=n(sa);d(le.$$.fragment,to),to.forEach(t),ao.forEach(t),ps=f(kt),la=r(kt,"SPAN",{});var so=n(la);is=l(so,"Image datasets"),so.forEach(t),kt.forEach(t),La=f(e),Ae=r(e,"P",{});var lo=n(Ae);ms=l(lo,"The images in an image dataset are typically either a:"),lo.forEach(t),Fa=f(e),B=r(e,"UL",{});var xt=n(B);oe=r(xt,"LI",{});var It=n(oe);fs=l(It,"PIL "),oa=r(It,"CODE",{});var oo=n(oa);cs=l(oo,"image"),oo.forEach(t),hs=l(It,"."),It.forEach(t),ds=f(xt),ra=r(xt,"LI",{});var ro=n(ra);us=l(ro,"Path to an image file you can load."),ro.forEach(t),xt.forEach(t),Ba=f(e),z=r(e,"P",{});var qt=n(z);gs=l(qt,"For example, load the "),re=r(qt,"A",{href:!0,rel:!0});var no=n(re);_s=l(no,"Food-101"),no.forEach(t),vs=l(qt," dataset and take a look:"),qt.forEach(t),za=f(e),d(ne.$$.fragment,e),Oa=f(e),E=r(e,"P",{});var Z=n(E);$s=l(Z,"The "),Te=r(Z,"A",{href:!0});var po=n(Te);ys=l(po,"Image"),po.forEach(t),ws=l(Z," feature automatically decodes the data from the "),na=r(Z,"CODE",{});var io=n(na);js=l(io,"image"),io.forEach(t),Es=l(Z," column to return an image object. Now try and call the "),pa=r(Z,"CODE",{});var mo=n(pa);bs=l(mo,"image"),mo.forEach(t),ks=l(Z," column to see what the image is:"),Z.forEach(t),Na=f(e),d(pe.$$.fragment,e),Ja=f(e),Le=r(e,"P",{});var fo=n(Le);Fe=r(fo,"IMG",{src:!0,alt:!0}),fo.forEach(t),Sa=f(e),x=r(e,"P",{});var Ve=n(x);xs=l(Ve,"To load an image from its path, use the "),Be=r(Ve,"A",{href:!0});var co=n(Be);Is=l(co,"cast_column()"),co.forEach(t),qs=l(Ve," method. The "),ze=r(Ve,"A",{href:!0});var ho=n(ze);Cs=l(ho,"Image"),ho.forEach(t),Ps=l(Ve," feature will decode the data at the path to return an image object:"),Ve.forEach(t),Ra=f(e),d(ie.$$.fragment,e),Ga=f(e),I=r(e,"P",{});var We=n(I);Ds=l(We,"You can also access the path and bytes of an image file by setting "),ia=r(We,"CODE",{});var uo=n(ia);As=l(uo,"decode=False"),uo.forEach(t),Ts=l(We," when you load a dataset. In this case, you will need to cast the "),ma=r(We,"CODE",{});var go=n(ma);Ls=l(go,"image"),go.forEach(t),Fs=l(We," column:"),We.forEach(t),Ua=f(e),d(me.$$.fragment,e),Ya=f(e),D=r(e,"H2",{class:!0});var Ct=n(D);O=r(Ct,"A",{id:!0,class:!0,href:!0});var _o=n(O);fa=r(_o,"SPAN",{});var vo=n(fa);d(fe.$$.fragment,vo),vo.forEach(t),_o.forEach(t),Bs=f(Ct),ca=r(Ct,"SPAN",{});var $o=n(ca);zs=l($o,"ImageFolder"),$o.forEach(t),Ct.forEach(t),Ma=f(e),N=r(e,"P",{});var Pt=n(N);Os=l(Pt,"You can also load your image dataset with a "),ha=r(Pt,"CODE",{});var yo=n(ha);Ns=l(yo,"ImageFolder"),yo.forEach(t),Js=l(Pt," dataset builder without writing a custom dataloader. Your image dataset structure should look like this:"),Pt.forEach(t),Ha=f(e),d(ce.$$.fragment,e),Ka=f(e),q=r(e,"P",{});var Xe=n(q);Ss=l(Xe,"Then load your dataset by specifying "),da=r(Xe,"CODE",{});var wo=n(da);Rs=l(wo,"imagefolder"),wo.forEach(t),Gs=l(Xe," and the directory of your dataset in "),ua=r(Xe,"CODE",{});var jo=n(ua);Us=l(jo,"data_dir"),jo.forEach(t),Ys=l(Xe,":"),Xe.forEach(t),Qa=f(e),d(he.$$.fragment,e),Va=f(e),J=r(e,"P",{});var Dt=n(J);Ms=l(Dt,"Load remote datasets from their URLs with the "),ga=r(Dt,"CODE",{});var Eo=n(ga);Hs=l(Eo,"data_files"),Eo.forEach(t),Ks=l(Dt," parameter:"),Dt.forEach(t),Wa=f(e),d(de.$$.fragment,e),Xa=f(e),A=r(e,"H2",{class:!0});var At=n(A);S=r(At,"A",{id:!0,class:!0,href:!0});var bo=n(S);_a=r(bo,"SPAN",{});var ko=n(_a);d(ue.$$.fragment,ko),ko.forEach(t),bo.forEach(t),Qs=f(At),va=r(At,"SPAN",{});var xo=n(va);Vs=l(xo,"Data augmentation"),xo.forEach(t),At.forEach(t),Za=f(e),R=r(e,"P",{});var Tt=n(R);Ws=l(Tt,"Adding data augmentations to a dataset is common to prevent overfitting and achieve better performance. You can use any library or package you want to apply the augmentations. This guide will use the transforms from "),ge=r(Tt,"A",{href:!0,rel:!0});var Io=n(ge);Xs=l(Io,"torchvision"),Io.forEach(t),Zs=l(Tt,"."),Tt.forEach(t),et=f(e),G=r(e,"P",{});var Lt=n(G);el=l(Lt,"Add the "),_e=r(Lt,"A",{href:!0,rel:!0});var qo=n(_e);$a=r(qo,"CODE",{});var Co=n($a);al=l(Co,"ColorJitter"),Co.forEach(t),qo.forEach(t),tl=l(Lt," transform to change the color properties of the image randomly:"),Lt.forEach(t),at=f(e),d(ve.$$.fragment,e),tt=f(e),U=r(e,"P",{});var Ft=n(U);sl=l(Ft,"Create a function to apply the "),ya=r(Ft,"CODE",{});var Po=n(ya);ll=l(Po,"ColorJitter"),Po.forEach(t),ol=l(Ft," transform to an image:"),Ft.forEach(t),st=f(e),d($e.$$.fragment,e),lt=f(e),Y=r(e,"P",{});var Bt=n(Y);rl=l(Bt,"Then you can use the "),Oe=r(Bt,"A",{href:!0});var Do=n(Oe);nl=l(Do,"set_transform()"),Do.forEach(t),pl=l(Bt," function to apply the transform on-the-fly to consume less disk space. Use this function if you only need to access the examples once:"),Bt.forEach(t),ot=f(e),d(ye.$$.fragment,e),rt=f(e),M=r(e,"P",{});var zt=n(M);il=l(zt,"Now visualize the results of the "),wa=r(zt,"CODE",{});var Ao=n(wa);ml=l(Ao,"ColorJitter"),Ao.forEach(t),fl=l(zt," transform:"),zt.forEach(t),nt=f(e),d(we.$$.fragment,e),pt=f(e),Ne=r(e,"P",{});var To=n(Ne);Je=r(To,"IMG",{src:!0,alt:!0}),To.forEach(t),it=f(e),T=r(e,"H2",{class:!0});var Ot=n(T);H=r(Ot,"A",{id:!0,class:!0,href:!0});var Lo=n(H);ja=r(Lo,"SPAN",{});var Fo=n(ja);d(je.$$.fragment,Fo),Fo.forEach(t),Lo.forEach(t),cl=f(Ot),Ea=r(Ot,"SPAN",{});var Bo=n(Ea);hl=l(Bo,"Map"),Bo.forEach(t),Ot.forEach(t),mt=f(e),Ee=r(e,"P",{});var Sl=n(Ee);Se=r(Sl,"A",{href:!0});var zo=n(Se);dl=l(zo,"map()"),zo.forEach(t),ul=l(Sl," can also apply transforms over an entire dataset and it also generates a cache file."),Sl.forEach(t),ft=f(e),K=r(e,"P",{});var Nt=n(K);gl=l(Nt,"Create a simple "),be=r(Nt,"A",{href:!0,rel:!0});var Oo=n(be);ba=r(Oo,"CODE",{});var No=n(ba);_l=l(No,"Resize"),No.forEach(t),Oo.forEach(t),vl=l(Nt," function:"),Nt.forEach(t),ct=f(e),d(ke.$$.fragment,e),ht=f(e),$=r(e,"P",{});var C=n($);$l=l(C,"Now "),Re=r(C,"A",{href:!0});var Jo=n(Re);yl=l(Jo,"map()"),Jo.forEach(t),wl=l(C," the function over the entire dataset and set "),ka=r(C,"CODE",{});var So=n(ka);jl=l(So,"batched=True"),So.forEach(t),El=l(C,". The transform returns "),xa=r(C,"CODE",{});var Ro=n(xa);bl=l(Ro,"pixel_values"),Ro.forEach(t),kl=l(C," as a cacheable "),Ia=r(C,"CODE",{});var Go=n(Ia);xl=l(Go,"PIL.Image"),Go.forEach(t),Il=l(C," object:"),C.forEach(t),dt=f(e),d(xe.$$.fragment,e),ut=f(e),Q=r(e,"P",{});var Jt=n(Q);ql=l(Jt,"This saves time because you don\u2019t have to execute the same transform twice. It is best to use "),Ge=r(Jt,"A",{href:!0});var Uo=n(Ge);Cl=l(Uo,"map()"),Uo.forEach(t),Pl=l(Jt," for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),Jt.forEach(t),gt=f(e),Ie=r(e,"P",{});var Rl=n(Ie);Ue=r(Rl,"A",{href:!0});var Yo=n(Ue);Dl=l(Yo,"map()"),Yo.forEach(t),Al=l(Rl," takes up some memory, but you can reduce its memory requirements with the following parameters:"),Rl.forEach(t),_t=f(e),V=r(e,"UL",{});var St=n(V);Ye=r(St,"LI",{});var Gl=n(Ye);Me=r(Gl,"A",{href:!0});var Mo=n(Me);qa=r(Mo,"CODE",{});var Ho=n(qa);Tl=l(Ho,"batch_size"),Ho.forEach(t),Mo.forEach(t),Ll=l(Gl," determines the number of examples that are processed in one call to the transform function."),Gl.forEach(t),Fl=f(St),He=r(St,"LI",{});var Ul=n(He);Ke=r(Ul,"A",{href:!0});var Ko=n(Ke);Ca=r(Ko,"CODE",{});var Qo=n(Ca);Bl=l(Qo,"writer_batch_size"),Qo.forEach(t),Ko.forEach(t),zl=l(Ul," determines the number of processed examples that are kept in memory before they are stored away."),Ul.forEach(t),St.forEach(t),vt=f(e),W=r(e,"P",{});var Rt=n(W);Ol=l(Rt,"Both parameter values default to 1000, which can be expensive if you are storing images. Lower the value to use less memory when calling "),Qe=r(Rt,"A",{href:!0});var Vo=n(Qe);Nl=l(Vo,"map()"),Vo.forEach(t),Jl=l(Rt,"."),Rt.forEach(t),this.h()},h(){c(k,"name","hf:doc:metadata"),c(k,"content",JSON.stringify(lr)),c(b,"id","process-image-data"),c(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b,"href","#process-image-data"),c(w,"class","relative group"),c(Ce,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Image"),c(Pe,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.set_transform"),c(De,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),c(F,"id","image-datasets"),c(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F,"href","#image-datasets"),c(P,"class","relative group"),c(re,"href","https://huggingface.co/datasets/food101"),c(re,"rel","nofollow"),c(Te,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Image"),Wo(Fe.src,Yl="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_beignet.png")||c(Fe,"src",Yl),c(Fe,"alt","image_process_beignet"),c(Be,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.cast_column"),c(ze,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Image"),c(O,"id","imagefolder"),c(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O,"href","#imagefolder"),c(D,"class","relative group"),c(S,"id","data-augmentation"),c(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S,"href","#data-augmentation"),c(A,"class","relative group"),c(ge,"href","https://pytorch.org/vision/stable/transforms.html"),c(ge,"rel","nofollow"),c(_e,"href","https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ColorJitter"),c(_e,"rel","nofollow"),c(Oe,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.set_transform"),Wo(Je.src,Ml="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_jitter.png")||c(Je,"src",Ml),c(Je,"alt","image_process_jitter"),c(H,"id","map"),c(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H,"href","#map"),c(T,"class","relative group"),c(Se,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),c(be,"href","https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html"),c(be,"rel","nofollow"),c(Re,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),c(Ge,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),c(Ue,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map"),c(Me,"href","./package_reference/main_classes#datasets.DatasetDict.map.batch_size"),c(Ke,"href","./package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size"),c(Qe,"href","/docs/datasets/pr_3882/en/package_reference/main_classes#datasets.Dataset.map")},m(e,p){a(document.head,k),i(e,qe,p),i(e,w,p),a(w,b),a(b,Ze),u(ee,Ze,null),a(w,Ut),a(w,ea),a(ea,Yt),i(e,Da,p),i(e,L,p),a(L,Mt),a(L,Ce),a(Ce,Ht),a(L,Kt),i(e,Aa,p),i(e,j,p),a(j,aa),a(aa,Qt),a(j,Vt),a(j,ae),a(ae,Wt),a(ae,ta),a(ta,Xt),a(ae,Zt),a(j,es),a(j,te),a(te,as),a(te,Pe),a(Pe,ts),a(te,ss),a(j,ls),a(j,se),a(se,os),a(se,De),a(De,rs),a(se,ns),i(e,Ta,p),i(e,P,p),a(P,F),a(F,sa),u(le,sa,null),a(P,ps),a(P,la),a(la,is),i(e,La,p),i(e,Ae,p),a(Ae,ms),i(e,Fa,p),i(e,B,p),a(B,oe),a(oe,fs),a(oe,oa),a(oa,cs),a(oe,hs),a(B,ds),a(B,ra),a(ra,us),i(e,Ba,p),i(e,z,p),a(z,gs),a(z,re),a(re,_s),a(z,vs),i(e,za,p),u(ne,e,p),i(e,Oa,p),i(e,E,p),a(E,$s),a(E,Te),a(Te,ys),a(E,ws),a(E,na),a(na,js),a(E,Es),a(E,pa),a(pa,bs),a(E,ks),i(e,Na,p),u(pe,e,p),i(e,Ja,p),i(e,Le,p),a(Le,Fe),i(e,Sa,p),i(e,x,p),a(x,xs),a(x,Be),a(Be,Is),a(x,qs),a(x,ze),a(ze,Cs),a(x,Ps),i(e,Ra,p),u(ie,e,p),i(e,Ga,p),i(e,I,p),a(I,Ds),a(I,ia),a(ia,As),a(I,Ts),a(I,ma),a(ma,Ls),a(I,Fs),i(e,Ua,p),u(me,e,p),i(e,Ya,p),i(e,D,p),a(D,O),a(O,fa),u(fe,fa,null),a(D,Bs),a(D,ca),a(ca,zs),i(e,Ma,p),i(e,N,p),a(N,Os),a(N,ha),a(ha,Ns),a(N,Js),i(e,Ha,p),u(ce,e,p),i(e,Ka,p),i(e,q,p),a(q,Ss),a(q,da),a(da,Rs),a(q,Gs),a(q,ua),a(ua,Us),a(q,Ys),i(e,Qa,p),u(he,e,p),i(e,Va,p),i(e,J,p),a(J,Ms),a(J,ga),a(ga,Hs),a(J,Ks),i(e,Wa,p),u(de,e,p),i(e,Xa,p),i(e,A,p),a(A,S),a(S,_a),u(ue,_a,null),a(A,Qs),a(A,va),a(va,Vs),i(e,Za,p),i(e,R,p),a(R,Ws),a(R,ge),a(ge,Xs),a(R,Zs),i(e,et,p),i(e,G,p),a(G,el),a(G,_e),a(_e,$a),a($a,al),a(G,tl),i(e,at,p),u(ve,e,p),i(e,tt,p),i(e,U,p),a(U,sl),a(U,ya),a(ya,ll),a(U,ol),i(e,st,p),u($e,e,p),i(e,lt,p),i(e,Y,p),a(Y,rl),a(Y,Oe),a(Oe,nl),a(Y,pl),i(e,ot,p),u(ye,e,p),i(e,rt,p),i(e,M,p),a(M,il),a(M,wa),a(wa,ml),a(M,fl),i(e,nt,p),u(we,e,p),i(e,pt,p),i(e,Ne,p),a(Ne,Je),i(e,it,p),i(e,T,p),a(T,H),a(H,ja),u(je,ja,null),a(T,cl),a(T,Ea),a(Ea,hl),i(e,mt,p),i(e,Ee,p),a(Ee,Se),a(Se,dl),a(Ee,ul),i(e,ft,p),i(e,K,p),a(K,gl),a(K,be),a(be,ba),a(ba,_l),a(K,vl),i(e,ct,p),u(ke,e,p),i(e,ht,p),i(e,$,p),a($,$l),a($,Re),a(Re,yl),a($,wl),a($,ka),a(ka,jl),a($,El),a($,xa),a(xa,bl),a($,kl),a($,Ia),a(Ia,xl),a($,Il),i(e,dt,p),u(xe,e,p),i(e,ut,p),i(e,Q,p),a(Q,ql),a(Q,Ge),a(Ge,Cl),a(Q,Pl),i(e,gt,p),i(e,Ie,p),a(Ie,Ue),a(Ue,Dl),a(Ie,Al),i(e,_t,p),i(e,V,p),a(V,Ye),a(Ye,Me),a(Me,qa),a(qa,Tl),a(Ye,Ll),a(V,Fl),a(V,He),a(He,Ke),a(Ke,Ca),a(Ca,Bl),a(He,zl),i(e,vt,p),i(e,W,p),a(W,Ol),a(W,Qe),a(Qe,Nl),a(W,Jl),$t=!0},p:tr,i(e){$t||(g(ee.$$.fragment,e),g(le.$$.fragment,e),g(ne.$$.fragment,e),g(pe.$$.fragment,e),g(ie.$$.fragment,e),g(me.$$.fragment,e),g(fe.$$.fragment,e),g(ce.$$.fragment,e),g(he.$$.fragment,e),g(de.$$.fragment,e),g(ue.$$.fragment,e),g(ve.$$.fragment,e),g($e.$$.fragment,e),g(ye.$$.fragment,e),g(we.$$.fragment,e),g(je.$$.fragment,e),g(ke.$$.fragment,e),g(xe.$$.fragment,e),$t=!0)},o(e){_(ee.$$.fragment,e),_(le.$$.fragment,e),_(ne.$$.fragment,e),_(pe.$$.fragment,e),_(ie.$$.fragment,e),_(me.$$.fragment,e),_(fe.$$.fragment,e),_(ce.$$.fragment,e),_(he.$$.fragment,e),_(de.$$.fragment,e),_(ue.$$.fragment,e),_(ve.$$.fragment,e),_($e.$$.fragment,e),_(ye.$$.fragment,e),_(we.$$.fragment,e),_(je.$$.fragment,e),_(ke.$$.fragment,e),_(xe.$$.fragment,e),$t=!1},d(e){t(k),e&&t(qe),e&&t(w),v(ee),e&&t(Da),e&&t(L),e&&t(Aa),e&&t(j),e&&t(Ta),e&&t(P),v(le),e&&t(La),e&&t(Ae),e&&t(Fa),e&&t(B),e&&t(Ba),e&&t(z),e&&t(za),v(ne,e),e&&t(Oa),e&&t(E),e&&t(Na),v(pe,e),e&&t(Ja),e&&t(Le),e&&t(Sa),e&&t(x),e&&t(Ra),v(ie,e),e&&t(Ga),e&&t(I),e&&t(Ua),v(me,e),e&&t(Ya),e&&t(D),v(fe),e&&t(Ma),e&&t(N),e&&t(Ha),v(ce,e),e&&t(Ka),e&&t(q),e&&t(Qa),v(he,e),e&&t(Va),e&&t(J),e&&t(Wa),v(de,e),e&&t(Xa),e&&t(A),v(ue),e&&t(Za),e&&t(R),e&&t(et),e&&t(G),e&&t(at),v(ve,e),e&&t(tt),e&&t(U),e&&t(st),v($e,e),e&&t(lt),e&&t(Y),e&&t(ot),v(ye,e),e&&t(rt),e&&t(M),e&&t(nt),v(we,e),e&&t(pt),e&&t(Ne),e&&t(it),e&&t(T),v(je),e&&t(mt),e&&t(Ee),e&&t(ft),e&&t(K),e&&t(ct),v(ke,e),e&&t(ht),e&&t($),e&&t(dt),v(xe,e),e&&t(ut),e&&t(Q),e&&t(gt),e&&t(Ie),e&&t(_t),e&&t(V),e&&t(vt),e&&t(W)}}}const lr={local:"process-image-data",sections:[{local:"image-datasets",title:"Image datasets"},{local:"imagefolder",title:"ImageFolder"},{local:"data-augmentation",title:"Data augmentation"},{local:"map",title:"Map"}],title:"Process image data"};function or(Gt,k,qe){let{fw:w}=k;return Gt.$$set=b=>{"fw"in b&&qe(0,w=b.fw)},[w]}class ir extends Xo{constructor(k){super();Zo(this,k,or,sr,er,{fw:0})}}export{ir as default,lr as metadata};
