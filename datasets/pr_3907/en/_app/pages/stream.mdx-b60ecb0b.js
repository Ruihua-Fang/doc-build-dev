import{S as Si,i as Ci,s as zi,e as t,k as c,w as u,t as n,M as Ni,c as l,d as a,m as d,a as o,x as g,h as r,b as h,N as qi,F as e,g as i,y as _,q as j,o as v,B as b}from"../chunks/vendor-e67aec41.js";import{T as gt}from"../chunks/Tip-76459d1c.js";import{I as C}from"../chunks/IconCopyLink-ffd7f84e.js";import{C as T}from"../chunks/CodeBlock-e2bcf023.js";import{C as Mi}from"../chunks/CodeBlockFw-1e02e2ba.js";function Li(z){let f,$,m,w,y,x,E,D;return{c(){f=t("p"),$=n("An "),m=t("a"),w=n("datasets.IterableDataset"),y=n(" is useful for iterative jobs like training a model. You shouldn\u2019t use a "),x=t("a"),E=n("datasets.IterableDataset"),D=n(" for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),this.h()},l(A){f=l(A,"P",{});var k=o(f);$=r(k,"An "),m=l(k,"A",{href:!0});var I=o(m);w=r(I,"datasets.IterableDataset"),I.forEach(a),y=r(k," is useful for iterative jobs like training a model. You shouldn\u2019t use a "),x=l(k,"A",{href:!0});var N=o(x);E=r(N,"datasets.IterableDataset"),N.forEach(a),D=r(k," for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),k.forEach(a),this.h()},h(){h(m,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset"),h(x,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset")},m(A,k){i(A,f,k),e(f,$),e(f,m),e(m,w),e(f,y),e(f,x),e(x,E),e(f,D)},d(A){A&&a(f)}}}function Oi(z){let f,$,m,w;return{c(){f=t("p"),$=t("a"),m=n("datasets.IterableDataset.shuffle()"),w=n(" will also shuffle the order of the shards if the dataset is sharded into multiple sets."),this.h()},l(y){f=l(y,"P",{});var x=o(f);$=l(x,"A",{href:!0});var E=o($);m=r(E,"datasets.IterableDataset.shuffle()"),E.forEach(a),w=r(x," will also shuffle the order of the shards if the dataset is sharded into multiple sets."),x.forEach(a),this.h()},h(){h($,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.shuffle")},m(y,x){i(y,f,x),e(f,$),e($,m),e(f,w)},d(y){y&&a(f)}}}function Vi(z){let f,$,m,w,y,x,E,D,A,k,I,N,hs;return{c(){f=t("p"),$=t("code"),m=n("take"),w=n(" and "),y=t("code"),x=n("skip"),E=n(" prevent future calls to "),D=t("code"),A=n("shuffle"),k=n(" because they lock in the order of the shards. You should "),I=t("code"),N=n("shuffle"),hs=n(" your dataset before splitting it.")},l(S){f=l(S,"P",{});var P=o(f);$=l(P,"CODE",{});var Da=o($);m=r(Da,"take"),Da.forEach(a),w=r(P," and "),y=l(P,"CODE",{});var Aa=o(y);x=r(Aa,"skip"),Aa.forEach(a),E=r(P," prevent future calls to "),D=l(P,"CODE",{});var cs=o(D);A=r(cs,"shuffle"),cs.forEach(a),k=r(P," because they lock in the order of the shards. You should "),I=l(P,"CODE",{});var Ia=o(I);N=r(Ia,"shuffle"),Ia.forEach(a),hs=r(P," your dataset before splitting it."),P.forEach(a)},m(S,P){i(S,f,P),e(f,$),e($,m),e(f,w),e(f,y),e(y,x),e(f,E),e(f,D),e(D,A),e(f,k),e(f,I),e(I,N),e(f,hs)},d(S){S&&a(f)}}}function Fi(z){let f,$,m,w,y,x,E,D;return{c(){f=t("p"),$=n("Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=t("code"),w=n("Value('int32')"),y=n(" to "),x=t("code"),E=n("Value('bool')"),D=n(" if the original column only contains ones and zeros.")},l(A){f=l(A,"P",{});var k=o(f);$=r(k,"Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=l(k,"CODE",{});var I=o(m);w=r(I,"Value('int32')"),I.forEach(a),y=r(k," to "),x=l(k,"CODE",{});var N=o(x);E=r(N,"Value('bool')"),N.forEach(a),D=r(k," if the original column only contains ones and zeros."),k.forEach(a)},m(A,k){i(A,f,k),e(f,$),e(f,m),e(m,w),e(f,y),e(f,x),e(x,E),e(f,D)},d(A){A&&a(f)}}}function Ri(z){let f,$,m,w,y;return{c(){f=t("p"),$=n("See other examples of batch processing in "),m=t("a"),w=n("the batched map processing documentation"),y=n(". They work the same for iterable datasets."),this.h()},l(x){f=l(x,"P",{});var E=o(f);$=r(E,"See other examples of batch processing in "),m=l(E,"A",{href:!0});var D=o(m);w=r(D,"the batched map processing documentation"),D.forEach(a),y=r(E,". They work the same for iterable datasets."),E.forEach(a),this.h()},h(){h(m,"href","./process#batch-processing")},m(x,E){i(x,f,E),e(f,$),e(f,m),e(m,w),e(f,y)},d(x){x&&a(f)}}}function Hi(z){let f,$,m,w,y,x,E,D,A,k,I,N,hs,S,P,Da,Aa,cs,Ia,_t,W,Ta,Rp,tn,Pa,Hp,jt,L,ln,Us,nn,rn,ue,pn,on,qa,hn,cn,vt,Bs,bt,H,dn,Sa,fn,mn,Ca,un,gn,xt,ds,$t,J,fs,ge,Ws,_n,_e,jn,wt,O,vn,za,bn,xn,Na,$n,wn,Ma,yn,kn,yt,V,En,je,Dn,An,ve,In,Tn,La,Pn,qn,kt,Js,Et,ms,Dt,G,us,be,Gs,Sn,xe,Cn,At,gs,zn,$e,Nn,Mn,It,_s,Ln,we,On,Vn,Tt,Ks,Pt,K,js,ye,Qs,Fn,ke,Rn,qt,Oa,Hn,St,Va,vs,Fa,Yn,Un,Ee,Bn,Wn,Ct,Xs,zt,Ra,bs,Ha,Jn,Gn,De,Kn,Qn,Nt,Zs,Mt,xs,Lt,Ya,Ot,Q,$s,Ae,sa,Xn,Ie,Zn,Vt,X,Ua,sr,ar,Ba,er,tr,Ft,aa,Rt,ws,lr,Te,nr,rr,Ht,ea,Yt,Y,pr,Pe,or,ir,qe,hr,cr,Ut,Z,ys,Se,ta,dr,Ce,fr,Bt,Wa,mr,Wt,ss,ks,ze,la,ur,Ne,gr,Jt,Es,_r,Me,jr,vr,Gt,Ds,br,Le,xr,$r,Kt,na,Qt,as,As,Oe,ra,wr,Ve,yr,Xt,Is,kr,Ja,Er,Dr,Zt,pa,sl,es,Ts,Fe,oa,Ar,Re,Ir,al,M,He,Tr,Pr,Ye,qr,Sr,Ue,Cr,zr,Be,Nr,Mr,el,ia,tl,Ps,ll,qs,Lr,Ga,Or,Vr,nl,ha,rl,ts,Ss,We,ca,Fr,Je,Rr,pl,q,Hr,Ka,Yr,Ur,Qa,Br,Wr,Xa,Jr,Gr,Za,Kr,Qr,se,Xr,Zr,ol,ae,sp,il,U,ap,ee,ep,tp,Ge,lp,np,hl,da,cl,Cs,rp,te,pp,op,dl,fa,fl,zs,ip,le,hp,cp,ml,B,dp,Ke,fp,mp,ne,up,gp,ul,ma,gl,ls,Ns,Qe,ua,_p,Xe,jp,_l,R,re,vp,bp,Ze,xp,$p,st,wp,yp,jl,ns,Ms,at,ga,kp,et,Ep,vl,_a,bl,Ls,xl,rs,Os,tt,ja,Dp,lt,Ap,$l,Vs,Ip,pe,Tp,Pp,wl,va,yl,ps,oe,qp,Sp,nt,Cp,zp,kl,ba,El,os,Fs,rt,xa,Np,pt,Mp,Dl,$a,ie,Lp,Op,Al,wa,Il,he,Vp,Tl,ya,Pl;return x=new C({}),Bs=new T({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
print(next(iter(dataset)))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset)))
{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, which he shared with John Blanchard during his first visit to Malawi. Chief Napoleon conveyed the desperate need for a program to intervene and care for the orphans and vulnerable children (OVC) in Malawi, and John committed to help...</span>`}}),ds=new gt({props:{$$slots:{default:[Li]},$$scope:{ctx:z}}}),Ws=new C({}),Js=new T({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
shuffled_dataset = dataset.shuffle(seed=42, buffer_size=10_000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>shuffled_dataset = dataset.shuffle(seed=<span class="hljs-number">42</span>, buffer_size=<span class="hljs-number">10_000</span>)`}}),ms=new gt({props:{$$slots:{default:[Oi]},$$scope:{ctx:z}}}),Gs=new C({}),Ks=new T({props:{code:`for epoch in range(epochs):
    shuffled_dataset.set_epoch(epoch)
    for example in shuffled_dataset:
        ...`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):
<span class="hljs-meta">... </span>    shuffled_dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> shuffled_dataset:
<span class="hljs-meta">... </span>        ...`}}),Qs=new C({}),Xs=new T({props:{code:`dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
dataset_head = dataset.take(2)
list(dataset_head)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset_head = dataset.take(<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(dataset_head)
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was...&#x27;</span>}, {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),Zs=new T({props:{code:"train_dataset = shuffled_dataset.skip(1000)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataset = shuffled_dataset.skip(<span class="hljs-number">1000</span>)'}}),xs=new gt({props:{warning:"&lcub;true}",$$slots:{default:[Vi]},$$scope:{ctx:z}}}),sa=new C({}),aa=new T({props:{code:`from datasets import interleave_datasets
en_dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
fr_dataset = load_dataset('oscar', "unshuffled_deduplicated_fr", split='train', streaming=True)

multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
list(multilingual_dataset.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> interleave_datasets
<span class="hljs-meta">&gt;&gt;&gt; </span>en_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>fr_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_fr&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&quot;M\xE9dia de d\xE9bat d&#x27;id\xE9es, de culture et de litt\xE9rature...&quot;</span>}]`}}),ea=new T({props:{code:`multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[0.8, 0.2], seed=42)
list(multilingual_dataset_with_oversampling.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[<span class="hljs-number">0.8</span>, <span class="hljs-number">0.2</span>], seed=<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset_with_oversampling.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),ta=new C({}),la=new C({}),na=new T({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.rename_column("text", "content")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.rename_column(<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>)`}}),ra=new C({}),pa=new T({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.remove_columns('timestamp')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.remove_columns(<span class="hljs-string">&#x27;timestamp&#x27;</span>)`}}),oa=new C({}),ia=new T({props:{code:`from datasets import load_dataset
dataset = load_dataset('glue', 'mrpc', split='train')features

from datasets import ClassLabel, Value
new_features = dataset.features.copy()
new_features["label"] = ClassLabel(names=['negative', 'positive'])
new_features["idx"] = Value('int64')
dataset = dataset.cast(new_features)
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;glue&#x27;</span>, <span class="hljs-string">&#x27;mrpc&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;not_equivalent&#x27;</span>, <span class="hljs-string">&#x27;equivalent&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> ClassLabel, Value
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features = dataset.features.copy()
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;label&quot;</span>] = ClassLabel(names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;idx&quot;</span>] = Value(<span class="hljs-string">&#x27;int64&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast(new_features)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int64&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),Ps=new gt({props:{$$slots:{default:[Fi]},$$scope:{ctx:z}}}),ha=new T({props:{code:`dataset.features

dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">44100</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">16000</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),ca=new C({}),da=new T({props:{code:`def add_prefix(example):
    example['text'] = 'My text: ' + example['text']
    return example`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_prefix</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    example[<span class="hljs-string">&#x27;text&#x27;</span>] = <span class="hljs-string">&#x27;My text: &#x27;</span> + example[<span class="hljs-string">&#x27;text&#x27;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example`}}),fa=new T({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train')
updated_dataset = dataset.map(add_prefix)
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&#x27;unshuffled_deduplicated_en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),ma=new T({props:{code:`updated_dataset = dataset.map(add_prefix, remove_columns=["id"])
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix, remove_columns=[<span class="hljs-string">&quot;id&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),ua=new C({}),ga=new C({}),_a=new T({props:{code:`from datasets import load_dataset
from transformers import AutoTokenizer
dataset = load_dataset("mc4", "en", streaming=True, split="train")
tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')
def encode(examples):
    return tokenizer(examples['text'], truncation=True, padding='max_length')
dataset = dataset.map(encode, batched=True, remove_columns=["text", "timestamp", "url"])
next(iter(dataset))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;mc4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&#x27;text&#x27;</span>], truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-string">&#x27;max_length&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(encode, batched=<span class="hljs-literal">True</span>, remove_columns=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;timestamp&quot;</span>, <span class="hljs-string">&quot;url&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: <span class="hljs-number">101</span>, <span class="hljs-number">8466</span>, <span class="hljs-number">1018</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">4029</span>, <span class="hljs-number">2475</span>, <span class="hljs-number">2062</span>, <span class="hljs-number">18558</span>, <span class="hljs-number">3100</span>, <span class="hljs-number">2061</span>, ...,<span class="hljs-number">1106</span>, <span class="hljs-number">3739</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, ..., <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Ls=new gt({props:{$$slots:{default:[Ri]},$$scope:{ctx:z}}}),ja=new C({}),va=new T({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train')
start_with_ar = dataset.filter(lambda example: example['text'].startswith('Ar'))
next(iter(start_with_ar))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&#x27;unshuffled_deduplicated_en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>start_with_ar = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> example: example[<span class="hljs-string">&#x27;text&#x27;</span>].startswith(<span class="hljs-string">&#x27;Ar&#x27;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(start_with_ar))
{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Are you looking for Number the Stars (Essential Modern Classics)?...&#x27;</span>}`}}),ba=new T({props:{code:`even_dataset = dataset.filter(lambda example, idx: idx % 2 == 0, with_indices=True)
list(even_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>even_dataset = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> example, idx: idx % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>, with_indices=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(even_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, ...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;&quot;I\\&#x27;d love to help kickstart continued development! And 0 EUR/month...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Are you looking for Number the Stars (Essential Modern Classics)? Normally, ...&#x27;</span>}]`}}),xa=new C({}),wa=new T({props:{code:`seed, buffer_size = 42, 10_000
dataset = dataset.shuffle(seed, buffer_size=buffer_size)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>seed, buffer_size = <span class="hljs-number">42</span>, <span class="hljs-number">10_000</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.shuffle(seed, buffer_size=buffer_size)`}}),ya=new Mi({props:{group1:{id:"pt",code:`import torch
from torch.utils.data import DataLoader
from transformers import AutoModelForMaskedLM, DataCollatorForLanguageModeling
from tqdm import tqdm
dataset = dataset.with_format("torch")
dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
device = 'cuda' if torch.cuda.is_available() else 'cpu' 
model = AutoModelForMaskedLM.from_pretrained("distilbert-base-uncased")
model.train().to(device)
optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)
for epoch in range(3):
    dataset.set_epoch(epoch)
    for i, batch in enumerate(tqdm(dataloader, total=5)):
        if i == 5:
            break
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs[0]
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        if i % 10 == 0:
            print(f"loss: {loss}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM, DataCollatorForLanguageModeling
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
<span class="hljs-meta">&gt;&gt;&gt; </span>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span> 
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.train().to(device)
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = torch.optim.AdamW(params=model.parameters(), lr=<span class="hljs-number">1e-5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):
<span class="hljs-meta">... </span>    dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(dataloader, total=<span class="hljs-number">5</span>)):
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">5</span>:
<span class="hljs-meta">... </span>            <span class="hljs-keyword">break</span>
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>        loss.backward()
<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:
<span class="hljs-meta">... </span>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss: <span class="hljs-subst">{loss}</span>&quot;</span>)`},group2:{id:"tf",code:"# WIP",highlighted:'<span class="hljs-comment"># WIP</span>'}}}),{c(){f=t("meta"),$=c(),m=t("h1"),w=t("a"),y=t("span"),u(x.$$.fragment),E=c(),D=t("span"),A=n("Stream"),k=c(),I=t("p"),N=n("Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),hs=c(),S=t("ul"),P=t("li"),Da=n("You don\u2019t want to wait for an extremely large dataset to download."),Aa=c(),cs=t("li"),Ia=n("The dataset size exceeds the amount of disk space on your computer."),_t=c(),W=t("div"),Ta=t("img"),tn=c(),Pa=t("img"),jt=c(),L=t("p"),ln=n("For example, the English split of the "),Us=t("a"),nn=n("OSCAR"),rn=n(" dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),ue=t("code"),pn=n("streaming=True"),on=n(" in "),qa=t("a"),hn=n("datasets.load_dataset()"),cn=n(" as shown below:"),vt=c(),u(Bs.$$.fragment),bt=c(),H=t("p"),dn=n("Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Sa=t("a"),fn=n("datasets.Dataset"),mn=n(" object), known as an "),Ca=t("a"),un=n("datasets.IterableDataset"),gn=n(". This special type of dataset has its own set of processing methods shown below."),xt=c(),u(ds.$$.fragment),$t=c(),J=t("h2"),fs=t("a"),ge=t("span"),u(Ws.$$.fragment),_n=c(),_e=t("span"),jn=n("Shuffle"),wt=c(),O=t("p"),vn=n("Like a regular "),za=t("a"),bn=n("datasets.Dataset"),xn=n(" object, you can also shuffle a "),Na=t("a"),$n=n("datasets.IterableDataset"),wn=n(" with "),Ma=t("a"),yn=n("datasets.IterableDataset.shuffle()"),kn=n("."),yt=c(),V=t("p"),En=n("The "),je=t("code"),Dn=n("buffer_size"),An=n(" argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),ve=t("code"),In=n("buffer_size"),Tn=n(" to ten thousand. "),La=t("a"),Pn=n("datasets.IterableDataset.shuffle()"),qn=n(" will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),kt=c(),u(Js.$$.fragment),Et=c(),u(ms.$$.fragment),Dt=c(),G=t("h2"),us=t("a"),be=t("span"),u(Gs.$$.fragment),Sn=c(),xe=t("span"),Cn=n("Reshuffle"),At=c(),gs=t("p"),zn=n("Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),$e=t("code"),Nn=n("datasets.IterableDataset.set_epoch()"),Mn=n("in between epochs to tell the dataset what epoch you\u2019re on."),It=c(),_s=t("p"),Ln=n("Your seed effectively becomes: "),we=t("code"),On=n("initial seed + current epoch"),Vn=n("."),Tt=c(),u(Ks.$$.fragment),Pt=c(),K=t("h2"),js=t("a"),ye=t("span"),u(Qs.$$.fragment),Fn=c(),ke=t("span"),Rn=n("Split dataset"),qt=c(),Oa=t("p"),Hn=n("You can split your dataset one of two ways:"),St=c(),Va=t("ul"),vs=t("li"),Fa=t("a"),Yn=n("datasets.IterableDataset.take()"),Un=n(" returns the first "),Ee=t("code"),Bn=n("n"),Wn=n(" examples in a dataset:"),Ct=c(),u(Xs.$$.fragment),zt=c(),Ra=t("ul"),bs=t("li"),Ha=t("a"),Jn=n("datasets.IterableDataset.skip()"),Gn=n(" omits the first "),De=t("code"),Kn=n("n"),Qn=n(" examples in a dataset and returns the remaining examples:"),Nt=c(),u(Zs.$$.fragment),Mt=c(),u(xs.$$.fragment),Lt=c(),Ya=t("a"),Ot=c(),Q=t("h2"),$s=t("a"),Ae=t("span"),u(sa.$$.fragment),Xn=c(),Ie=t("span"),Zn=n("Interleave"),Vt=c(),X=t("p"),Ua=t("a"),sr=n("datasets.interleave_datasets()"),ar=n(" can combine an "),Ba=t("a"),er=n("datasets.IterableDataset"),tr=n(" with other datasets. The combined dataset returns alternating examples from each of the original datasets."),Ft=c(),u(aa.$$.fragment),Rt=c(),ws=t("p"),lr=n("Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),Te=t("code"),nr=n("probabilities"),rr=n(" argument with your desired sampling probabilities:"),Ht=c(),u(ea.$$.fragment),Yt=c(),Y=t("p"),pr=n("Around 80% of the final dataset is made of the "),Pe=t("code"),or=n("en_dataset"),ir=n(", and 20% of the "),qe=t("code"),hr=n("fr_dataset"),cr=n("."),Ut=c(),Z=t("h2"),ys=t("a"),Se=t("span"),u(ta.$$.fragment),dr=c(),Ce=t("span"),fr=n("Rename, remove, and cast"),Bt=c(),Wa=t("p"),mr=n("The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),Wt=c(),ss=t("h3"),ks=t("a"),ze=t("span"),u(la.$$.fragment),ur=c(),Ne=t("span"),gr=n("Rename"),Jt=c(),Es=t("p"),_r=n("Use "),Me=t("code"),jr=n("datasets.IterableDataset.rename_column()"),vr=n("when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),Gt=c(),Ds=t("p"),br=n("Provide "),Le=t("code"),xr=n("datasets.IterableDataset.rename_column()"),$r=n("with the name of the original column, and the new column name:"),Kt=c(),u(na.$$.fragment),Qt=c(),as=t("h3"),As=t("a"),Oe=t("span"),u(ra.$$.fragment),wr=c(),Ve=t("span"),yr=n("Remove"),Xt=c(),Is=t("p"),kr=n("When you need to remove one or more columns, give "),Ja=t("a"),Er=n("datasets.IterableDataset.remove_columns()"),Dr=n(" the name of the column to remove. Remove more than one column by providing a list of column names:"),Zt=c(),u(pa.$$.fragment),sl=c(),es=t("h3"),Ts=t("a"),Fe=t("span"),u(oa.$$.fragment),Ar=c(),Re=t("span"),Ir=n("Cast"),al=c(),M=t("p"),He=t("code"),Tr=n("datasets.IterableDataset.cast()"),Pr=n("changes the feature type of one or more columns. This method takes your new "),Ye=t("code"),qr=n("datasets.Features"),Sr=n(" as its argument. The following sample code shows how to change the feature types of "),Ue=t("code"),Cr=n("datasets.ClassLabel"),zr=n(" and "),Be=t("code"),Nr=n("datasets.Value"),Mr=n(":"),el=c(),u(ia.$$.fragment),tl=c(),u(Ps.$$.fragment),ll=c(),qs=t("p"),Lr=n("Use "),Ga=t("a"),Or=n("datasets.Dataset.cast_column()"),Vr=n(" to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),nl=c(),u(ha.$$.fragment),rl=c(),ts=t("h2"),Ss=t("a"),We=t("span"),u(ca.$$.fragment),Fr=c(),Je=t("span"),Rr=n("Map"),pl=c(),q=t("p"),Hr=n("Similar to the "),Ka=t("a"),Yr=n("datasets.Dataset.map()"),Ur=n(" function for a regular "),Qa=t("a"),Br=n("datasets.Dataset"),Wr=n(", \u{1F917}  Datasets features "),Xa=t("a"),Jr=n("datasets.IterableDataset.map()"),Gr=n(" for processing "),Za=t("a"),Kr=n("datasets.IterableDataset"),Qr=n(`\\s.
`),se=t("a"),Xr=n("datasets.IterableDataset.map()"),Zr=n(" applies processing on-the-fly when examples are streamed."),ol=c(),ae=t("p"),sp=n("It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),il=c(),U=t("p"),ap=n("The following example demonstrates how to tokenize a "),ee=t("a"),ep=n("datasets.IterableDataset"),tp=n(". The function needs to accept and output a "),Ge=t("code"),lp=n("dict"),np=n(":"),hl=c(),u(da.$$.fragment),cl=c(),Cs=t("p"),rp=n("Next, apply this function to the dataset with "),te=t("a"),pp=n("datasets.IterableDataset.map()"),op=n(":"),dl=c(),u(fa.$$.fragment),fl=c(),zs=t("p"),ip=n("Let\u2019s take a look at another example, except this time, you will remove a column with "),le=t("a"),hp=n("datasets.IterableDataset.map()"),cp=n(". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),ml=c(),B=t("p"),dp=n("Specify the column to remove with the "),Ke=t("code"),fp=n("remove_columns"),mp=n(" argument in "),ne=t("a"),up=n("datasets.IterableDataset.map()"),gp=n(":"),ul=c(),u(ma.$$.fragment),gl=c(),ls=t("h3"),Ns=t("a"),Qe=t("span"),u(ua.$$.fragment),_p=c(),Xe=t("span"),jp=n("Batch processing"),_l=c(),R=t("p"),re=t("a"),vp=n("datasets.IterableDataset.map()"),bp=n(" also supports working with batches of examples. Operate on batches by setting "),Ze=t("code"),xp=n("batched=True"),$p=n(". The default batch size is 1000, but you can adjust it with the "),st=t("code"),wp=n("batch_size"),yp=n(" argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),jl=c(),ns=t("h4"),Ms=t("a"),at=t("span"),u(ga.$$.fragment),kp=c(),et=t("span"),Ep=n("Tokenization"),vl=c(),u(_a.$$.fragment),bl=c(),u(Ls.$$.fragment),xl=c(),rs=t("h3"),Os=t("a"),tt=t("span"),u(ja.$$.fragment),Dp=c(),lt=t("span"),Ap=n("Filter"),$l=c(),Vs=t("p"),Ip=n("You can filter rows in the dataset based on a predicate function using "),pe=t("a"),Tp=n("datasets.Dataset.filter()"),Pp=n(". It returns rows that match a specified condition:"),wl=c(),u(va.$$.fragment),yl=c(),ps=t("p"),oe=t("a"),qp=n("datasets.Dataset.filter()"),Sp=n(" can also filter by indices if you set "),nt=t("code"),Cp=n("with_indices=True"),zp=n(":"),kl=c(),u(ba.$$.fragment),El=c(),os=t("h2"),Fs=t("a"),rt=t("span"),u(xa.$$.fragment),Np=c(),pt=t("span"),Mp=n("Stream in a training loop"),Dl=c(),$a=t("p"),ie=t("a"),Lp=n("datasets.IterableDataset"),Op=n(" can be integrated into a training loop. First, shuffle the dataset:"),Al=c(),u(wa.$$.fragment),Il=c(),he=t("p"),Vp=n("Lastly, create a simple training loop and start training:"),Tl=c(),u(ya.$$.fragment),this.h()},l(s){const p=Ni('[data-svelte="svelte-1phssyn"]',document.head);f=l(p,"META",{name:!0,content:!0}),p.forEach(a),$=d(s),m=l(s,"H1",{class:!0});var ka=o(m);w=l(ka,"A",{id:!0,class:!0,href:!0});var ot=o(w);y=l(ot,"SPAN",{});var it=o(y);g(x.$$.fragment,it),it.forEach(a),ot.forEach(a),E=d(ka),D=l(ka,"SPAN",{});var ht=o(D);A=r(ht,"Stream"),ht.forEach(a),ka.forEach(a),k=d(s),I=l(s,"P",{});var ct=o(I);N=r(ct,"Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),ct.forEach(a),hs=d(s),S=l(s,"UL",{});var ql=o(S);P=l(ql,"LI",{});var Yp=o(P);Da=r(Yp,"You don\u2019t want to wait for an extremely large dataset to download."),Yp.forEach(a),Aa=d(ql),cs=l(ql,"LI",{});var Up=o(cs);Ia=r(Up,"The dataset size exceeds the amount of disk space on your computer."),Up.forEach(a),ql.forEach(a),_t=d(s),W=l(s,"DIV",{class:!0});var Sl=o(W);Ta=l(Sl,"IMG",{class:!0,src:!0}),tn=d(Sl),Pa=l(Sl,"IMG",{class:!0,src:!0}),Sl.forEach(a),jt=d(s),L=l(s,"P",{});var Rs=o(L);ln=r(Rs,"For example, the English split of the "),Us=l(Rs,"A",{href:!0,rel:!0});var Bp=o(Us);nn=r(Bp,"OSCAR"),Bp.forEach(a),rn=r(Rs," dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),ue=l(Rs,"CODE",{});var Wp=o(ue);pn=r(Wp,"streaming=True"),Wp.forEach(a),on=r(Rs," in "),qa=l(Rs,"A",{href:!0});var Jp=o(qa);hn=r(Jp,"datasets.load_dataset()"),Jp.forEach(a),cn=r(Rs," as shown below:"),Rs.forEach(a),vt=d(s),g(Bs.$$.fragment,s),bt=d(s),H=l(s,"P",{});var ce=o(H);dn=r(ce,"Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Sa=l(ce,"A",{href:!0});var Gp=o(Sa);fn=r(Gp,"datasets.Dataset"),Gp.forEach(a),mn=r(ce," object), known as an "),Ca=l(ce,"A",{href:!0});var Kp=o(Ca);un=r(Kp,"datasets.IterableDataset"),Kp.forEach(a),gn=r(ce,". This special type of dataset has its own set of processing methods shown below."),ce.forEach(a),xt=d(s),g(ds.$$.fragment,s),$t=d(s),J=l(s,"H2",{class:!0});var Cl=o(J);fs=l(Cl,"A",{id:!0,class:!0,href:!0});var Qp=o(fs);ge=l(Qp,"SPAN",{});var Xp=o(ge);g(Ws.$$.fragment,Xp),Xp.forEach(a),Qp.forEach(a),_n=d(Cl),_e=l(Cl,"SPAN",{});var Zp=o(_e);jn=r(Zp,"Shuffle"),Zp.forEach(a),Cl.forEach(a),wt=d(s),O=l(s,"P",{});var Hs=o(O);vn=r(Hs,"Like a regular "),za=l(Hs,"A",{href:!0});var so=o(za);bn=r(so,"datasets.Dataset"),so.forEach(a),xn=r(Hs," object, you can also shuffle a "),Na=l(Hs,"A",{href:!0});var ao=o(Na);$n=r(ao,"datasets.IterableDataset"),ao.forEach(a),wn=r(Hs," with "),Ma=l(Hs,"A",{href:!0});var eo=o(Ma);yn=r(eo,"datasets.IterableDataset.shuffle()"),eo.forEach(a),kn=r(Hs,"."),Hs.forEach(a),yt=d(s),V=l(s,"P",{});var Ys=o(V);En=r(Ys,"The "),je=l(Ys,"CODE",{});var to=o(je);Dn=r(to,"buffer_size"),to.forEach(a),An=r(Ys," argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),ve=l(Ys,"CODE",{});var lo=o(ve);In=r(lo,"buffer_size"),lo.forEach(a),Tn=r(Ys," to ten thousand. "),La=l(Ys,"A",{href:!0});var no=o(La);Pn=r(no,"datasets.IterableDataset.shuffle()"),no.forEach(a),qn=r(Ys," will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),Ys.forEach(a),kt=d(s),g(Js.$$.fragment,s),Et=d(s),g(ms.$$.fragment,s),Dt=d(s),G=l(s,"H2",{class:!0});var zl=o(G);us=l(zl,"A",{id:!0,class:!0,href:!0});var ro=o(us);be=l(ro,"SPAN",{});var po=o(be);g(Gs.$$.fragment,po),po.forEach(a),ro.forEach(a),Sn=d(zl),xe=l(zl,"SPAN",{});var oo=o(xe);Cn=r(oo,"Reshuffle"),oo.forEach(a),zl.forEach(a),At=d(s),gs=l(s,"P",{});var Nl=o(gs);zn=r(Nl,"Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),$e=l(Nl,"CODE",{});var io=o($e);Nn=r(io,"datasets.IterableDataset.set_epoch()"),io.forEach(a),Mn=r(Nl,"in between epochs to tell the dataset what epoch you\u2019re on."),Nl.forEach(a),It=d(s),_s=l(s,"P",{});var Ml=o(_s);Ln=r(Ml,"Your seed effectively becomes: "),we=l(Ml,"CODE",{});var ho=o(we);On=r(ho,"initial seed + current epoch"),ho.forEach(a),Vn=r(Ml,"."),Ml.forEach(a),Tt=d(s),g(Ks.$$.fragment,s),Pt=d(s),K=l(s,"H2",{class:!0});var Ll=o(K);js=l(Ll,"A",{id:!0,class:!0,href:!0});var co=o(js);ye=l(co,"SPAN",{});var fo=o(ye);g(Qs.$$.fragment,fo),fo.forEach(a),co.forEach(a),Fn=d(Ll),ke=l(Ll,"SPAN",{});var mo=o(ke);Rn=r(mo,"Split dataset"),mo.forEach(a),Ll.forEach(a),qt=d(s),Oa=l(s,"P",{});var uo=o(Oa);Hn=r(uo,"You can split your dataset one of two ways:"),uo.forEach(a),St=d(s),Va=l(s,"UL",{});var go=o(Va);vs=l(go,"LI",{});var dt=o(vs);Fa=l(dt,"A",{href:!0});var _o=o(Fa);Yn=r(_o,"datasets.IterableDataset.take()"),_o.forEach(a),Un=r(dt," returns the first "),Ee=l(dt,"CODE",{});var jo=o(Ee);Bn=r(jo,"n"),jo.forEach(a),Wn=r(dt," examples in a dataset:"),dt.forEach(a),go.forEach(a),Ct=d(s),g(Xs.$$.fragment,s),zt=d(s),Ra=l(s,"UL",{});var vo=o(Ra);bs=l(vo,"LI",{});var ft=o(bs);Ha=l(ft,"A",{href:!0});var bo=o(Ha);Jn=r(bo,"datasets.IterableDataset.skip()"),bo.forEach(a),Gn=r(ft," omits the first "),De=l(ft,"CODE",{});var xo=o(De);Kn=r(xo,"n"),xo.forEach(a),Qn=r(ft," examples in a dataset and returns the remaining examples:"),ft.forEach(a),vo.forEach(a),Nt=d(s),g(Zs.$$.fragment,s),Mt=d(s),g(xs.$$.fragment,s),Lt=d(s),Ya=l(s,"A",{id:!0}),o(Ya).forEach(a),Ot=d(s),Q=l(s,"H2",{class:!0});var Ol=o(Q);$s=l(Ol,"A",{id:!0,class:!0,href:!0});var $o=o($s);Ae=l($o,"SPAN",{});var wo=o(Ae);g(sa.$$.fragment,wo),wo.forEach(a),$o.forEach(a),Xn=d(Ol),Ie=l(Ol,"SPAN",{});var yo=o(Ie);Zn=r(yo,"Interleave"),yo.forEach(a),Ol.forEach(a),Vt=d(s),X=l(s,"P",{});var mt=o(X);Ua=l(mt,"A",{href:!0});var ko=o(Ua);sr=r(ko,"datasets.interleave_datasets()"),ko.forEach(a),ar=r(mt," can combine an "),Ba=l(mt,"A",{href:!0});var Eo=o(Ba);er=r(Eo,"datasets.IterableDataset"),Eo.forEach(a),tr=r(mt," with other datasets. The combined dataset returns alternating examples from each of the original datasets."),mt.forEach(a),Ft=d(s),g(aa.$$.fragment,s),Rt=d(s),ws=l(s,"P",{});var Vl=o(ws);lr=r(Vl,"Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),Te=l(Vl,"CODE",{});var Do=o(Te);nr=r(Do,"probabilities"),Do.forEach(a),rr=r(Vl," argument with your desired sampling probabilities:"),Vl.forEach(a),Ht=d(s),g(ea.$$.fragment,s),Yt=d(s),Y=l(s,"P",{});var de=o(Y);pr=r(de,"Around 80% of the final dataset is made of the "),Pe=l(de,"CODE",{});var Ao=o(Pe);or=r(Ao,"en_dataset"),Ao.forEach(a),ir=r(de,", and 20% of the "),qe=l(de,"CODE",{});var Io=o(qe);hr=r(Io,"fr_dataset"),Io.forEach(a),cr=r(de,"."),de.forEach(a),Ut=d(s),Z=l(s,"H2",{class:!0});var Fl=o(Z);ys=l(Fl,"A",{id:!0,class:!0,href:!0});var To=o(ys);Se=l(To,"SPAN",{});var Po=o(Se);g(ta.$$.fragment,Po),Po.forEach(a),To.forEach(a),dr=d(Fl),Ce=l(Fl,"SPAN",{});var qo=o(Ce);fr=r(qo,"Rename, remove, and cast"),qo.forEach(a),Fl.forEach(a),Bt=d(s),Wa=l(s,"P",{});var So=o(Wa);mr=r(So,"The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),So.forEach(a),Wt=d(s),ss=l(s,"H3",{class:!0});var Rl=o(ss);ks=l(Rl,"A",{id:!0,class:!0,href:!0});var Co=o(ks);ze=l(Co,"SPAN",{});var zo=o(ze);g(la.$$.fragment,zo),zo.forEach(a),Co.forEach(a),ur=d(Rl),Ne=l(Rl,"SPAN",{});var No=o(Ne);gr=r(No,"Rename"),No.forEach(a),Rl.forEach(a),Jt=d(s),Es=l(s,"P",{});var Hl=o(Es);_r=r(Hl,"Use "),Me=l(Hl,"CODE",{});var Mo=o(Me);jr=r(Mo,"datasets.IterableDataset.rename_column()"),Mo.forEach(a),vr=r(Hl,"when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),Hl.forEach(a),Gt=d(s),Ds=l(s,"P",{});var Yl=o(Ds);br=r(Yl,"Provide "),Le=l(Yl,"CODE",{});var Lo=o(Le);xr=r(Lo,"datasets.IterableDataset.rename_column()"),Lo.forEach(a),$r=r(Yl,"with the name of the original column, and the new column name:"),Yl.forEach(a),Kt=d(s),g(na.$$.fragment,s),Qt=d(s),as=l(s,"H3",{class:!0});var Ul=o(as);As=l(Ul,"A",{id:!0,class:!0,href:!0});var Oo=o(As);Oe=l(Oo,"SPAN",{});var Vo=o(Oe);g(ra.$$.fragment,Vo),Vo.forEach(a),Oo.forEach(a),wr=d(Ul),Ve=l(Ul,"SPAN",{});var Fo=o(Ve);yr=r(Fo,"Remove"),Fo.forEach(a),Ul.forEach(a),Xt=d(s),Is=l(s,"P",{});var Bl=o(Is);kr=r(Bl,"When you need to remove one or more columns, give "),Ja=l(Bl,"A",{href:!0});var Ro=o(Ja);Er=r(Ro,"datasets.IterableDataset.remove_columns()"),Ro.forEach(a),Dr=r(Bl," the name of the column to remove. Remove more than one column by providing a list of column names:"),Bl.forEach(a),Zt=d(s),g(pa.$$.fragment,s),sl=d(s),es=l(s,"H3",{class:!0});var Wl=o(es);Ts=l(Wl,"A",{id:!0,class:!0,href:!0});var Ho=o(Ts);Fe=l(Ho,"SPAN",{});var Yo=o(Fe);g(oa.$$.fragment,Yo),Yo.forEach(a),Ho.forEach(a),Ar=d(Wl),Re=l(Wl,"SPAN",{});var Uo=o(Re);Ir=r(Uo,"Cast"),Uo.forEach(a),Wl.forEach(a),al=d(s),M=l(s,"P",{});var is=o(M);He=l(is,"CODE",{});var Bo=o(He);Tr=r(Bo,"datasets.IterableDataset.cast()"),Bo.forEach(a),Pr=r(is,"changes the feature type of one or more columns. This method takes your new "),Ye=l(is,"CODE",{});var Wo=o(Ye);qr=r(Wo,"datasets.Features"),Wo.forEach(a),Sr=r(is," as its argument. The following sample code shows how to change the feature types of "),Ue=l(is,"CODE",{});var Jo=o(Ue);Cr=r(Jo,"datasets.ClassLabel"),Jo.forEach(a),zr=r(is," and "),Be=l(is,"CODE",{});var Go=o(Be);Nr=r(Go,"datasets.Value"),Go.forEach(a),Mr=r(is,":"),is.forEach(a),el=d(s),g(ia.$$.fragment,s),tl=d(s),g(Ps.$$.fragment,s),ll=d(s),qs=l(s,"P",{});var Jl=o(qs);Lr=r(Jl,"Use "),Ga=l(Jl,"A",{href:!0});var Ko=o(Ga);Or=r(Ko,"datasets.Dataset.cast_column()"),Ko.forEach(a),Vr=r(Jl," to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),Jl.forEach(a),nl=d(s),g(ha.$$.fragment,s),rl=d(s),ts=l(s,"H2",{class:!0});var Gl=o(ts);Ss=l(Gl,"A",{id:!0,class:!0,href:!0});var Qo=o(Ss);We=l(Qo,"SPAN",{});var Xo=o(We);g(ca.$$.fragment,Xo),Xo.forEach(a),Qo.forEach(a),Fr=d(Gl),Je=l(Gl,"SPAN",{});var Zo=o(Je);Rr=r(Zo,"Map"),Zo.forEach(a),Gl.forEach(a),pl=d(s),q=l(s,"P",{});var F=o(q);Hr=r(F,"Similar to the "),Ka=l(F,"A",{href:!0});var si=o(Ka);Yr=r(si,"datasets.Dataset.map()"),si.forEach(a),Ur=r(F," function for a regular "),Qa=l(F,"A",{href:!0});var ai=o(Qa);Br=r(ai,"datasets.Dataset"),ai.forEach(a),Wr=r(F,", \u{1F917}  Datasets features "),Xa=l(F,"A",{href:!0});var ei=o(Xa);Jr=r(ei,"datasets.IterableDataset.map()"),ei.forEach(a),Gr=r(F," for processing "),Za=l(F,"A",{href:!0});var ti=o(Za);Kr=r(ti,"datasets.IterableDataset"),ti.forEach(a),Qr=r(F,`\\s.
`),se=l(F,"A",{href:!0});var li=o(se);Xr=r(li,"datasets.IterableDataset.map()"),li.forEach(a),Zr=r(F," applies processing on-the-fly when examples are streamed."),F.forEach(a),ol=d(s),ae=l(s,"P",{});var ni=o(ae);sp=r(ni,"It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),ni.forEach(a),il=d(s),U=l(s,"P",{});var fe=o(U);ap=r(fe,"The following example demonstrates how to tokenize a "),ee=l(fe,"A",{href:!0});var ri=o(ee);ep=r(ri,"datasets.IterableDataset"),ri.forEach(a),tp=r(fe,". The function needs to accept and output a "),Ge=l(fe,"CODE",{});var pi=o(Ge);lp=r(pi,"dict"),pi.forEach(a),np=r(fe,":"),fe.forEach(a),hl=d(s),g(da.$$.fragment,s),cl=d(s),Cs=l(s,"P",{});var Kl=o(Cs);rp=r(Kl,"Next, apply this function to the dataset with "),te=l(Kl,"A",{href:!0});var oi=o(te);pp=r(oi,"datasets.IterableDataset.map()"),oi.forEach(a),op=r(Kl,":"),Kl.forEach(a),dl=d(s),g(fa.$$.fragment,s),fl=d(s),zs=l(s,"P",{});var Ql=o(zs);ip=r(Ql,"Let\u2019s take a look at another example, except this time, you will remove a column with "),le=l(Ql,"A",{href:!0});var ii=o(le);hp=r(ii,"datasets.IterableDataset.map()"),ii.forEach(a),cp=r(Ql,". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),Ql.forEach(a),ml=d(s),B=l(s,"P",{});var me=o(B);dp=r(me,"Specify the column to remove with the "),Ke=l(me,"CODE",{});var hi=o(Ke);fp=r(hi,"remove_columns"),hi.forEach(a),mp=r(me," argument in "),ne=l(me,"A",{href:!0});var ci=o(ne);up=r(ci,"datasets.IterableDataset.map()"),ci.forEach(a),gp=r(me,":"),me.forEach(a),ul=d(s),g(ma.$$.fragment,s),gl=d(s),ls=l(s,"H3",{class:!0});var Xl=o(ls);Ns=l(Xl,"A",{id:!0,class:!0,href:!0});var di=o(Ns);Qe=l(di,"SPAN",{});var fi=o(Qe);g(ua.$$.fragment,fi),fi.forEach(a),di.forEach(a),_p=d(Xl),Xe=l(Xl,"SPAN",{});var mi=o(Xe);jp=r(mi,"Batch processing"),mi.forEach(a),Xl.forEach(a),_l=d(s),R=l(s,"P",{});var Ea=o(R);re=l(Ea,"A",{href:!0});var ui=o(re);vp=r(ui,"datasets.IterableDataset.map()"),ui.forEach(a),bp=r(Ea," also supports working with batches of examples. Operate on batches by setting "),Ze=l(Ea,"CODE",{});var gi=o(Ze);xp=r(gi,"batched=True"),gi.forEach(a),$p=r(Ea,". The default batch size is 1000, but you can adjust it with the "),st=l(Ea,"CODE",{});var _i=o(st);wp=r(_i,"batch_size"),_i.forEach(a),yp=r(Ea," argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),Ea.forEach(a),jl=d(s),ns=l(s,"H4",{class:!0});var Zl=o(ns);Ms=l(Zl,"A",{id:!0,class:!0,href:!0});var ji=o(Ms);at=l(ji,"SPAN",{});var vi=o(at);g(ga.$$.fragment,vi),vi.forEach(a),ji.forEach(a),kp=d(Zl),et=l(Zl,"SPAN",{});var bi=o(et);Ep=r(bi,"Tokenization"),bi.forEach(a),Zl.forEach(a),vl=d(s),g(_a.$$.fragment,s),bl=d(s),g(Ls.$$.fragment,s),xl=d(s),rs=l(s,"H3",{class:!0});var sn=o(rs);Os=l(sn,"A",{id:!0,class:!0,href:!0});var xi=o(Os);tt=l(xi,"SPAN",{});var $i=o(tt);g(ja.$$.fragment,$i),$i.forEach(a),xi.forEach(a),Dp=d(sn),lt=l(sn,"SPAN",{});var wi=o(lt);Ap=r(wi,"Filter"),wi.forEach(a),sn.forEach(a),$l=d(s),Vs=l(s,"P",{});var an=o(Vs);Ip=r(an,"You can filter rows in the dataset based on a predicate function using "),pe=l(an,"A",{href:!0});var yi=o(pe);Tp=r(yi,"datasets.Dataset.filter()"),yi.forEach(a),Pp=r(an,". It returns rows that match a specified condition:"),an.forEach(a),wl=d(s),g(va.$$.fragment,s),yl=d(s),ps=l(s,"P",{});var ut=o(ps);oe=l(ut,"A",{href:!0});var ki=o(oe);qp=r(ki,"datasets.Dataset.filter()"),ki.forEach(a),Sp=r(ut," can also filter by indices if you set "),nt=l(ut,"CODE",{});var Ei=o(nt);Cp=r(Ei,"with_indices=True"),Ei.forEach(a),zp=r(ut,":"),ut.forEach(a),kl=d(s),g(ba.$$.fragment,s),El=d(s),os=l(s,"H2",{class:!0});var en=o(os);Fs=l(en,"A",{id:!0,class:!0,href:!0});var Di=o(Fs);rt=l(Di,"SPAN",{});var Ai=o(rt);g(xa.$$.fragment,Ai),Ai.forEach(a),Di.forEach(a),Np=d(en),pt=l(en,"SPAN",{});var Ii=o(pt);Mp=r(Ii,"Stream in a training loop"),Ii.forEach(a),en.forEach(a),Dl=d(s),$a=l(s,"P",{});var Fp=o($a);ie=l(Fp,"A",{href:!0});var Ti=o(ie);Lp=r(Ti,"datasets.IterableDataset"),Ti.forEach(a),Op=r(Fp," can be integrated into a training loop. First, shuffle the dataset:"),Fp.forEach(a),Al=d(s),g(wa.$$.fragment,s),Il=d(s),he=l(s,"P",{});var Pi=o(he);Vp=r(Pi,"Lastly, create a simple training loop and start training:"),Pi.forEach(a),Tl=d(s),g(ya.$$.fragment,s),this.h()},h(){h(f,"name","hf:doc:metadata"),h(f,"content",JSON.stringify(Yi)),h(w,"id","stream"),h(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(w,"href","#stream"),h(m,"class","relative group"),h(Ta,"class","block dark:hidden"),qi(Ta.src,Rp="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming.gif")||h(Ta,"src",Rp),h(Pa,"class","hidden dark:block"),qi(Pa.src,Hp="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming-dark.gif")||h(Pa,"src",Hp),h(W,"class","flex justify-center"),h(Us,"href","https://huggingface.co/datasets/oscar"),h(Us,"rel","nofollow"),h(qa,"href","/docs/datasets/pr_3907/en/package_reference/loading_methods#datasets.load_dataset"),h(Sa,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.Dataset"),h(Ca,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset"),h(fs,"id","shuffle"),h(fs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(fs,"href","#shuffle"),h(J,"class","relative group"),h(za,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.Dataset"),h(Na,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset"),h(Ma,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(La,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(us,"id","reshuffle"),h(us,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(us,"href","#reshuffle"),h(G,"class","relative group"),h(js,"id","split-dataset"),h(js,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(js,"href","#split-dataset"),h(K,"class","relative group"),h(Fa,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.take"),h(Ha,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.skip"),h(Ya,"id","interleave_datasets"),h($s,"id","interleave"),h($s,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h($s,"href","#interleave"),h(Q,"class","relative group"),h(Ua,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.interleave_datasets"),h(Ba,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset"),h(ys,"id","rename-remove-and-cast"),h(ys,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ys,"href","#rename-remove-and-cast"),h(Z,"class","relative group"),h(ks,"id","rename"),h(ks,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ks,"href","#rename"),h(ss,"class","relative group"),h(As,"id","remove"),h(As,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(As,"href","#remove"),h(as,"class","relative group"),h(Ja,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.remove_columns"),h(Ts,"id","cast"),h(Ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ts,"href","#cast"),h(es,"class","relative group"),h(Ga,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.Dataset.cast_column"),h(Ss,"id","map"),h(Ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ss,"href","#map"),h(ts,"class","relative group"),h(Ka,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.Dataset.map"),h(Qa,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.Dataset"),h(Xa,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Za,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset"),h(se,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.map"),h(ee,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset"),h(te,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.map"),h(le,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.map"),h(ne,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Ns,"id","batch-processing"),h(Ns,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ns,"href","#batch-processing"),h(ls,"class","relative group"),h(re,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Ms,"id","tokenization"),h(Ms,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ms,"href","#tokenization"),h(ns,"class","relative group"),h(Os,"id","filter"),h(Os,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Os,"href","#filter"),h(rs,"class","relative group"),h(pe,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.Dataset.filter"),h(oe,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.Dataset.filter"),h(Fs,"id","stream-in-a-training-loop"),h(Fs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Fs,"href","#stream-in-a-training-loop"),h(os,"class","relative group"),h(ie,"href","/docs/datasets/pr_3907/en/package_reference/main_classes#datasets.IterableDataset")},m(s,p){e(document.head,f),i(s,$,p),i(s,m,p),e(m,w),e(w,y),_(x,y,null),e(m,E),e(m,D),e(D,A),i(s,k,p),i(s,I,p),e(I,N),i(s,hs,p),i(s,S,p),e(S,P),e(P,Da),e(S,Aa),e(S,cs),e(cs,Ia),i(s,_t,p),i(s,W,p),e(W,Ta),e(W,tn),e(W,Pa),i(s,jt,p),i(s,L,p),e(L,ln),e(L,Us),e(Us,nn),e(L,rn),e(L,ue),e(ue,pn),e(L,on),e(L,qa),e(qa,hn),e(L,cn),i(s,vt,p),_(Bs,s,p),i(s,bt,p),i(s,H,p),e(H,dn),e(H,Sa),e(Sa,fn),e(H,mn),e(H,Ca),e(Ca,un),e(H,gn),i(s,xt,p),_(ds,s,p),i(s,$t,p),i(s,J,p),e(J,fs),e(fs,ge),_(Ws,ge,null),e(J,_n),e(J,_e),e(_e,jn),i(s,wt,p),i(s,O,p),e(O,vn),e(O,za),e(za,bn),e(O,xn),e(O,Na),e(Na,$n),e(O,wn),e(O,Ma),e(Ma,yn),e(O,kn),i(s,yt,p),i(s,V,p),e(V,En),e(V,je),e(je,Dn),e(V,An),e(V,ve),e(ve,In),e(V,Tn),e(V,La),e(La,Pn),e(V,qn),i(s,kt,p),_(Js,s,p),i(s,Et,p),_(ms,s,p),i(s,Dt,p),i(s,G,p),e(G,us),e(us,be),_(Gs,be,null),e(G,Sn),e(G,xe),e(xe,Cn),i(s,At,p),i(s,gs,p),e(gs,zn),e(gs,$e),e($e,Nn),e(gs,Mn),i(s,It,p),i(s,_s,p),e(_s,Ln),e(_s,we),e(we,On),e(_s,Vn),i(s,Tt,p),_(Ks,s,p),i(s,Pt,p),i(s,K,p),e(K,js),e(js,ye),_(Qs,ye,null),e(K,Fn),e(K,ke),e(ke,Rn),i(s,qt,p),i(s,Oa,p),e(Oa,Hn),i(s,St,p),i(s,Va,p),e(Va,vs),e(vs,Fa),e(Fa,Yn),e(vs,Un),e(vs,Ee),e(Ee,Bn),e(vs,Wn),i(s,Ct,p),_(Xs,s,p),i(s,zt,p),i(s,Ra,p),e(Ra,bs),e(bs,Ha),e(Ha,Jn),e(bs,Gn),e(bs,De),e(De,Kn),e(bs,Qn),i(s,Nt,p),_(Zs,s,p),i(s,Mt,p),_(xs,s,p),i(s,Lt,p),i(s,Ya,p),i(s,Ot,p),i(s,Q,p),e(Q,$s),e($s,Ae),_(sa,Ae,null),e(Q,Xn),e(Q,Ie),e(Ie,Zn),i(s,Vt,p),i(s,X,p),e(X,Ua),e(Ua,sr),e(X,ar),e(X,Ba),e(Ba,er),e(X,tr),i(s,Ft,p),_(aa,s,p),i(s,Rt,p),i(s,ws,p),e(ws,lr),e(ws,Te),e(Te,nr),e(ws,rr),i(s,Ht,p),_(ea,s,p),i(s,Yt,p),i(s,Y,p),e(Y,pr),e(Y,Pe),e(Pe,or),e(Y,ir),e(Y,qe),e(qe,hr),e(Y,cr),i(s,Ut,p),i(s,Z,p),e(Z,ys),e(ys,Se),_(ta,Se,null),e(Z,dr),e(Z,Ce),e(Ce,fr),i(s,Bt,p),i(s,Wa,p),e(Wa,mr),i(s,Wt,p),i(s,ss,p),e(ss,ks),e(ks,ze),_(la,ze,null),e(ss,ur),e(ss,Ne),e(Ne,gr),i(s,Jt,p),i(s,Es,p),e(Es,_r),e(Es,Me),e(Me,jr),e(Es,vr),i(s,Gt,p),i(s,Ds,p),e(Ds,br),e(Ds,Le),e(Le,xr),e(Ds,$r),i(s,Kt,p),_(na,s,p),i(s,Qt,p),i(s,as,p),e(as,As),e(As,Oe),_(ra,Oe,null),e(as,wr),e(as,Ve),e(Ve,yr),i(s,Xt,p),i(s,Is,p),e(Is,kr),e(Is,Ja),e(Ja,Er),e(Is,Dr),i(s,Zt,p),_(pa,s,p),i(s,sl,p),i(s,es,p),e(es,Ts),e(Ts,Fe),_(oa,Fe,null),e(es,Ar),e(es,Re),e(Re,Ir),i(s,al,p),i(s,M,p),e(M,He),e(He,Tr),e(M,Pr),e(M,Ye),e(Ye,qr),e(M,Sr),e(M,Ue),e(Ue,Cr),e(M,zr),e(M,Be),e(Be,Nr),e(M,Mr),i(s,el,p),_(ia,s,p),i(s,tl,p),_(Ps,s,p),i(s,ll,p),i(s,qs,p),e(qs,Lr),e(qs,Ga),e(Ga,Or),e(qs,Vr),i(s,nl,p),_(ha,s,p),i(s,rl,p),i(s,ts,p),e(ts,Ss),e(Ss,We),_(ca,We,null),e(ts,Fr),e(ts,Je),e(Je,Rr),i(s,pl,p),i(s,q,p),e(q,Hr),e(q,Ka),e(Ka,Yr),e(q,Ur),e(q,Qa),e(Qa,Br),e(q,Wr),e(q,Xa),e(Xa,Jr),e(q,Gr),e(q,Za),e(Za,Kr),e(q,Qr),e(q,se),e(se,Xr),e(q,Zr),i(s,ol,p),i(s,ae,p),e(ae,sp),i(s,il,p),i(s,U,p),e(U,ap),e(U,ee),e(ee,ep),e(U,tp),e(U,Ge),e(Ge,lp),e(U,np),i(s,hl,p),_(da,s,p),i(s,cl,p),i(s,Cs,p),e(Cs,rp),e(Cs,te),e(te,pp),e(Cs,op),i(s,dl,p),_(fa,s,p),i(s,fl,p),i(s,zs,p),e(zs,ip),e(zs,le),e(le,hp),e(zs,cp),i(s,ml,p),i(s,B,p),e(B,dp),e(B,Ke),e(Ke,fp),e(B,mp),e(B,ne),e(ne,up),e(B,gp),i(s,ul,p),_(ma,s,p),i(s,gl,p),i(s,ls,p),e(ls,Ns),e(Ns,Qe),_(ua,Qe,null),e(ls,_p),e(ls,Xe),e(Xe,jp),i(s,_l,p),i(s,R,p),e(R,re),e(re,vp),e(R,bp),e(R,Ze),e(Ze,xp),e(R,$p),e(R,st),e(st,wp),e(R,yp),i(s,jl,p),i(s,ns,p),e(ns,Ms),e(Ms,at),_(ga,at,null),e(ns,kp),e(ns,et),e(et,Ep),i(s,vl,p),_(_a,s,p),i(s,bl,p),_(Ls,s,p),i(s,xl,p),i(s,rs,p),e(rs,Os),e(Os,tt),_(ja,tt,null),e(rs,Dp),e(rs,lt),e(lt,Ap),i(s,$l,p),i(s,Vs,p),e(Vs,Ip),e(Vs,pe),e(pe,Tp),e(Vs,Pp),i(s,wl,p),_(va,s,p),i(s,yl,p),i(s,ps,p),e(ps,oe),e(oe,qp),e(ps,Sp),e(ps,nt),e(nt,Cp),e(ps,zp),i(s,kl,p),_(ba,s,p),i(s,El,p),i(s,os,p),e(os,Fs),e(Fs,rt),_(xa,rt,null),e(os,Np),e(os,pt),e(pt,Mp),i(s,Dl,p),i(s,$a,p),e($a,ie),e(ie,Lp),e($a,Op),i(s,Al,p),_(wa,s,p),i(s,Il,p),i(s,he,p),e(he,Vp),i(s,Tl,p),_(ya,s,p),Pl=!0},p(s,[p]){const ka={};p&2&&(ka.$$scope={dirty:p,ctx:s}),ds.$set(ka);const ot={};p&2&&(ot.$$scope={dirty:p,ctx:s}),ms.$set(ot);const it={};p&2&&(it.$$scope={dirty:p,ctx:s}),xs.$set(it);const ht={};p&2&&(ht.$$scope={dirty:p,ctx:s}),Ps.$set(ht);const ct={};p&2&&(ct.$$scope={dirty:p,ctx:s}),Ls.$set(ct)},i(s){Pl||(j(x.$$.fragment,s),j(Bs.$$.fragment,s),j(ds.$$.fragment,s),j(Ws.$$.fragment,s),j(Js.$$.fragment,s),j(ms.$$.fragment,s),j(Gs.$$.fragment,s),j(Ks.$$.fragment,s),j(Qs.$$.fragment,s),j(Xs.$$.fragment,s),j(Zs.$$.fragment,s),j(xs.$$.fragment,s),j(sa.$$.fragment,s),j(aa.$$.fragment,s),j(ea.$$.fragment,s),j(ta.$$.fragment,s),j(la.$$.fragment,s),j(na.$$.fragment,s),j(ra.$$.fragment,s),j(pa.$$.fragment,s),j(oa.$$.fragment,s),j(ia.$$.fragment,s),j(Ps.$$.fragment,s),j(ha.$$.fragment,s),j(ca.$$.fragment,s),j(da.$$.fragment,s),j(fa.$$.fragment,s),j(ma.$$.fragment,s),j(ua.$$.fragment,s),j(ga.$$.fragment,s),j(_a.$$.fragment,s),j(Ls.$$.fragment,s),j(ja.$$.fragment,s),j(va.$$.fragment,s),j(ba.$$.fragment,s),j(xa.$$.fragment,s),j(wa.$$.fragment,s),j(ya.$$.fragment,s),Pl=!0)},o(s){v(x.$$.fragment,s),v(Bs.$$.fragment,s),v(ds.$$.fragment,s),v(Ws.$$.fragment,s),v(Js.$$.fragment,s),v(ms.$$.fragment,s),v(Gs.$$.fragment,s),v(Ks.$$.fragment,s),v(Qs.$$.fragment,s),v(Xs.$$.fragment,s),v(Zs.$$.fragment,s),v(xs.$$.fragment,s),v(sa.$$.fragment,s),v(aa.$$.fragment,s),v(ea.$$.fragment,s),v(ta.$$.fragment,s),v(la.$$.fragment,s),v(na.$$.fragment,s),v(ra.$$.fragment,s),v(pa.$$.fragment,s),v(oa.$$.fragment,s),v(ia.$$.fragment,s),v(Ps.$$.fragment,s),v(ha.$$.fragment,s),v(ca.$$.fragment,s),v(da.$$.fragment,s),v(fa.$$.fragment,s),v(ma.$$.fragment,s),v(ua.$$.fragment,s),v(ga.$$.fragment,s),v(_a.$$.fragment,s),v(Ls.$$.fragment,s),v(ja.$$.fragment,s),v(va.$$.fragment,s),v(ba.$$.fragment,s),v(xa.$$.fragment,s),v(wa.$$.fragment,s),v(ya.$$.fragment,s),Pl=!1},d(s){a(f),s&&a($),s&&a(m),b(x),s&&a(k),s&&a(I),s&&a(hs),s&&a(S),s&&a(_t),s&&a(W),s&&a(jt),s&&a(L),s&&a(vt),b(Bs,s),s&&a(bt),s&&a(H),s&&a(xt),b(ds,s),s&&a($t),s&&a(J),b(Ws),s&&a(wt),s&&a(O),s&&a(yt),s&&a(V),s&&a(kt),b(Js,s),s&&a(Et),b(ms,s),s&&a(Dt),s&&a(G),b(Gs),s&&a(At),s&&a(gs),s&&a(It),s&&a(_s),s&&a(Tt),b(Ks,s),s&&a(Pt),s&&a(K),b(Qs),s&&a(qt),s&&a(Oa),s&&a(St),s&&a(Va),s&&a(Ct),b(Xs,s),s&&a(zt),s&&a(Ra),s&&a(Nt),b(Zs,s),s&&a(Mt),b(xs,s),s&&a(Lt),s&&a(Ya),s&&a(Ot),s&&a(Q),b(sa),s&&a(Vt),s&&a(X),s&&a(Ft),b(aa,s),s&&a(Rt),s&&a(ws),s&&a(Ht),b(ea,s),s&&a(Yt),s&&a(Y),s&&a(Ut),s&&a(Z),b(ta),s&&a(Bt),s&&a(Wa),s&&a(Wt),s&&a(ss),b(la),s&&a(Jt),s&&a(Es),s&&a(Gt),s&&a(Ds),s&&a(Kt),b(na,s),s&&a(Qt),s&&a(as),b(ra),s&&a(Xt),s&&a(Is),s&&a(Zt),b(pa,s),s&&a(sl),s&&a(es),b(oa),s&&a(al),s&&a(M),s&&a(el),b(ia,s),s&&a(tl),b(Ps,s),s&&a(ll),s&&a(qs),s&&a(nl),b(ha,s),s&&a(rl),s&&a(ts),b(ca),s&&a(pl),s&&a(q),s&&a(ol),s&&a(ae),s&&a(il),s&&a(U),s&&a(hl),b(da,s),s&&a(cl),s&&a(Cs),s&&a(dl),b(fa,s),s&&a(fl),s&&a(zs),s&&a(ml),s&&a(B),s&&a(ul),b(ma,s),s&&a(gl),s&&a(ls),b(ua),s&&a(_l),s&&a(R),s&&a(jl),s&&a(ns),b(ga),s&&a(vl),b(_a,s),s&&a(bl),b(Ls,s),s&&a(xl),s&&a(rs),b(ja),s&&a($l),s&&a(Vs),s&&a(wl),b(va,s),s&&a(yl),s&&a(ps),s&&a(kl),b(ba,s),s&&a(El),s&&a(os),b(xa),s&&a(Dl),s&&a($a),s&&a(Al),b(wa,s),s&&a(Il),s&&a(he),s&&a(Tl),b(ya,s)}}}const Yi={local:"stream",sections:[{local:"shuffle",title:"Shuffle"},{local:"reshuffle",title:"Reshuffle"},{local:"split-dataset",title:"Split dataset"},{local:"interleave",title:"Interleave"},{local:"rename-remove-and-cast",sections:[{local:"rename",title:"Rename"},{local:"remove",title:"Remove"},{local:"cast",title:"Cast"}],title:"Rename, remove, and cast"},{local:"map",sections:[{local:"batch-processing",sections:[{local:"tokenization",title:"Tokenization"}],title:"Batch processing"},{local:"filter",title:"Filter"}],title:"Map"},{local:"stream-in-a-training-loop",title:"Stream in a training loop"}],title:"Stream"};function Ui(z,f,$){let{fw:m}=f;return z.$$set=w=>{"fw"in w&&$(0,m=w.fw)},[m]}class Qi extends Si{constructor(f){super();Ci(this,f,Ui,Hi,zi,{fw:0})}}export{Qi as default,Yi as metadata};
