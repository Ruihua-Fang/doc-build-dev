import{S as Jd,i as Wd,s as Xd,e as a,k as n,w as E,t as s,M as Yd,c as i,d as l,m as f,a as r,x as y,h as o,b as m,N as Rd,F as t,g as h,y as w,L as Zd,q as $,o as k,B as I}from"../chunks/vendor-7b1da053.js";import{I as Ta}from"../chunks/IconCopyLink-d24e9a6f.js";import{C as F}from"../chunks/CodeBlock-5f39b59e.js";function Gd(Yi){let j,Fe,A,P,ot,oe,Zi,rt,Gi,Fa,X,Qi,nt,Vi,es,Aa,U,Y,ft,re,ts,ct,ls,Ma,ne,ht,as,is,xa,fe,Pa,Z,ss,dt,os,rs,Da,ce,ja,Ae,ns,Sa,G,pt,_t,fs,cs,ut,mt,hs,Ca,Me,ds,Oa,M,gt,vt,ps,_s,bt,Et,us,ms,yt,wt,gs,vs,$t,bs,Na,x,Es,kt,ys,ws,It,$s,ks,Lt,Is,Ls,Ha,R,Q,Tt,he,Ts,Ft,Fs,qa,L,As,At,Ms,xs,Mt,Ps,Ds,xt,js,Ss,Pt,Cs,Os,za,de,Ka,S,Ns,Dt,Hs,qs,jt,zs,Ks,Ba,J,V,St,pe,Bs,Ct,Us,Ua,xe,Rs,Ra,Pe,_e,Js,Ot,Ws,Xs,Ja,ee,Ys,Nt,Zs,Gs,Wa,ue,Xa,De,Qs,Ya,b,Ht,Vs,eo,qt,to,lo,zt,ao,io,Kt,so,oo,Bt,ro,no,Ut,fo,co,Rt,ho,Za,C,po,Jt,_o,uo,Wt,mo,go,Ga,te,vo,Xt,bo,Eo,Qa,me,Va,je,yo,ei,_,Yt,wo,$o,Zt,ko,Io,Gt,Lo,To,Qt,Fo,Ao,Vt,Mo,xo,el,Po,Do,tl,jo,So,ll,Co,Oo,al,No,Ho,il,qo,zo,sl,Ko,Bo,ol,Uo,Ro,rl,Jo,Wo,nl,Xo,Yo,fl,Zo,Go,cl,Qo,Vo,hl,er,tr,dl,lr,ar,pl,ir,sr,_l,or,rr,ul,nr,fr,ml,cr,hr,gl,dr,pr,vl,_r,ur,bl,mr,ti,O,gr,El,vr,br,yl,Er,yr,li,ge,ai,Se,wr,ii,N,$r,wl,kr,Ir,$l,Lr,Tr,si,Ce,Oe,Zf,oi,Ne,He,Gf,ri,H,Fr,kl,Ar,Mr,Il,xr,Pr,ni,ve,fi,qe,Dr,ci,le,jr,Ll,Sr,Cr,hi,be,di,ze,Or,pi,W,ae,Tl,Ee,Nr,Fl,Hr,_i,Ke,qr,ui,Be,zr,mi,Ue,ye,Kr,Al,Br,Ur,gi,q,Rr,Ml,Jr,Wr,xl,Xr,Yr,vi,we,bi,Re,Zr,Ei,g,Pl,Gr,Qr,Dl,Vr,en,jl,tn,ln,Sl,an,sn,Cl,on,rn,Ol,nn,fn,Nl,cn,hn,Hl,dn,pn,ql,_n,un,zl,mn,yi,D,Kl,gn,vn,Bl,bn,En,Ul,yn,wn,wi,$e,$i,Je,$n,ki,d,Rl,kn,In,Jl,Ln,Tn,Wl,Fn,An,Xl,Mn,xn,Yl,Pn,Dn,Zl,jn,Sn,Gl,Cn,On,Ql,Nn,Hn,Vl,qn,zn,ea,Kn,Bn,ta,Un,Rn,la,Jn,Wn,aa,Xn,Yn,ia,Zn,Gn,sa,Qn,Vn,oa,ef,tf,ra,lf,af,na,sf,of,fa,rf,nf,ca,ff,cf,ha,hf,df,da,pf,_f,pa,uf,mf,_a,gf,vf,ua,bf,Ef,ma,yf,wf,ga,$f,kf,va,If,Lf,ba,Tf,Ff,Ea,Af,Mf,ya,xf,Pf,wa,Df,Ii,z,jf,$a,Sf,Cf,ka,Of,Nf,Li,K,Hf,Ia,qf,zf,La,Kf,Bf,Ti,ke,Fi,We,Uf,Ai,Xe,Rf,Mi,Ie,xi,Ye,Jf,Pi,Le,Di,Ze,Wf,ji,Ge,Xf,Si;return oe=new Ta({}),re=new Ta({}),fe=new F({props:{code:"pip install huggingface_hub",highlighted:"pip install huggingface_hub"}}),ce=new F({props:{code:`from huggingface_hub import HfApi
api = HfApi()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi
<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()`}}),he=new Ta({}),de=new F({props:{code:`from huggingface_hub import ModelSearchArguments, DatasetSearchArguments

model_args = ModelSearchArguments()
dataset_args = DatasetSearchArguments()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> ModelSearchArguments, DatasetSearchArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>model_args = ModelSearchArguments()
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset_args = DatasetSearchArguments()`}}),pe=new Ta({}),ue=new F({props:{code:"model_args",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_args'}}),me=new F({props:{code:"model_args.library",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_args.library'}}),ge=new F({props:{code:"model_args.library.PyTorch",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_args.library.PyTorch'}}),ve=new F({props:{code:`from huggingface_hub import ModelFilter, DatasetFilter

filt = ModelFilter(
    task=args.pipeline_tag.TextClassification, 
    trained_dataset=args.dataset.glue, 
    library=args.library.PyTorch
)
api.list_models(filter=filt)[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> ModelFilter, DatasetFilter

<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(
<span class="hljs-meta">&gt;&gt;&gt; </span>    task=args.pipeline_tag.TextClassification, 
<span class="hljs-meta">&gt;&gt;&gt; </span>    trained_dataset=args.dataset.glue, 
<span class="hljs-meta">&gt;&gt;&gt; </span>    library=args.library.PyTorch
<span class="hljs-meta">&gt;&gt;&gt; </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)[<span class="hljs-number">0</span>]`}}),be=new F({props:{code:`filt = ModelFilter(
    task=args.pipeline_tag.TextClassification, 
    library=[args.library.PyTorch, args.library.TensorFlow]
)
api.list_models(filter=filt)[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(
<span class="hljs-meta">&gt;&gt;&gt; </span>    task=args.pipeline_tag.TextClassification, 
<span class="hljs-meta">&gt;&gt;&gt; </span>    library=[args.library.PyTorch, args.library.TensorFlow]
<span class="hljs-meta">&gt;&gt;&gt; </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)[<span class="hljs-number">0</span>]`}}),Ee=new Ta({}),we=new F({props:{code:`dataset_args = DatasetSearchArguments()
dataset_args`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset_args = DatasetSearchArguments()
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset_args`}}),$e=new F({props:{code:"dataset_args.task_categories",highlighted:"dataset_args.task_categories"}}),ke=new F({props:{code:'"en" in dataset_args.languages',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-string">&quot;en&quot;</span> <span class="hljs-keyword">in</span> dataset_args.languages'}}),Ie=new F({props:{code:`filt = DatasetFilter(
   languages=dataset_args.languages.en,
   task_categories=dataset_args.task_categories.text_classification
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(
<span class="hljs-meta">&gt;&gt;&gt; </span>   languages=dataset_args.languages.en,
<span class="hljs-meta">&gt;&gt;&gt; </span>   task_categories=dataset_args.task_categories.text_classification
<span class="hljs-meta">&gt;&gt;&gt; </span>)`}}),Le=new F({props:{code:"api.list_datasets(filter=filt)[0]",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(<span class="hljs-built_in">filter</span>=filt)[<span class="hljs-number">0</span>]'}}),{c(){j=a("meta"),Fe=n(),A=a("h1"),P=a("a"),ot=a("span"),E(oe.$$.fragment),Zi=n(),rt=a("span"),Gi=s("Searching the Hub Efficiently with Python"),Fa=n(),X=a("p"),Qi=s("In this tutorial, we will explore how to interact and explore the Hugging Face Hub with the "),nt=a("code"),Vi=s("huggingface_hub"),es=s(" library to help find available models and datasets quickly."),Aa=n(),U=a("h2"),Y=a("a"),ft=a("span"),E(re.$$.fragment),ts=n(),ct=a("span"),ls=s("The Basics"),Ma=n(),ne=a("p"),ht=a("code"),as=s("huggingface_hub"),is=s(" is a Python library that allows anyone to freely extract useful information from the Hub, as well as downloading and publishing models. You can install it with:"),xa=n(),E(fe.$$.fragment),Pa=n(),Z=a("p"),ss=s("It comes packaged with an interface that can interact with the Hub in the "),dt=a("code"),os=s("HfApi"),rs=s(" class:"),Da=n(),E(ce.$$.fragment),ja=n(),Ae=a("p"),ns=s("This class lets you perform a variety of operations that interact with the raw Hub API. We\u2019ll be focusing on two specific functions:"),Sa=n(),G=a("ul"),pt=a("li"),_t=a("code"),fs=s("list_models"),cs=n(),ut=a("li"),mt=a("code"),hs=s("list_datasets"),Ca=n(),Me=a("p"),ds=s("If you look at what can be passed into each function, you will find the parameter list looks something like:"),Oa=n(),M=a("ul"),gt=a("li"),vt=a("code"),ps=s("filter"),_s=n(),bt=a("li"),Et=a("code"),us=s("author"),ms=n(),yt=a("li"),wt=a("code"),gs=s("search"),vs=n(),$t=a("li"),bs=s("\u2026"),Na=n(),x=a("p"),Es=s("Two of these parameters are intuitive ("),kt=a("code"),ys=s("author"),ws=s(" and "),It=a("code"),$s=s("search"),ks=s("), but what about that "),Lt=a("code"),Is=s("filter"),Ls=s("? \u{1F914} Let\u2019s dive into a few helpers quickly and revisit that question."),Ha=n(),R=a("h2"),Q=a("a"),Tt=a("span"),E(he.$$.fragment),Ts=n(),Ft=a("span"),Fs=s("Search Parameters"),qa=n(),L=a("p"),As=s("The "),At=a("code"),Ms=s("huggingface_hub"),xs=s(" provides a user-friendly interface to know what exactly can be passed into this "),Mt=a("code"),Ps=s("filter"),Ds=s(" parameter through the "),xt=a("code"),js=s("ModelSearchArguments"),Ss=s(" and "),Pt=a("code"),Cs=s("DatasetSearchArguments"),Os=s(" classes:"),za=n(),E(de.$$.fragment),Ka=n(),S=a("p"),Ns=s("These are nested namespace objects that have "),Dt=a("strong"),Hs=s("every single option"),qs=s(" available on the Hub and that will return what should be passed to "),jt=a("code"),zs=s("filter"),Ks=s(". The best of all is: it has tab completion \u{1F38A} ."),Ba=n(),J=a("h2"),V=a("a"),St=a("span"),E(pe.$$.fragment),Bs=n(),Ct=a("span"),Us=s("Searching for a Model"),Ua=n(),xe=a("p"),Rs=s("Let\u2019s pose a problem that would be complicated to solve without access to this information:"),Ra=n(),Pe=a("blockquote"),_e=a("p"),Js=s("I want to search the Hub for all PyTorch models trained on the "),Ot=a("code"),Ws=s("glue"),Xs=s(" dataset that can do Text Classification."),Ja=n(),ee=a("p"),Ys=s("If you check what is available in "),Nt=a("code"),Zs=s("model_args"),Gs=s(" by checking it\u2019s output, you will find:"),Wa=n(),E(ue.$$.fragment),Xa=n(),De=a("p"),Qs=s("Available Attributes or Keys:"),Ya=n(),b=a("ul"),Ht=a("li"),Vs=s("author"),eo=n(),qt=a("li"),to=s("dataset"),lo=n(),zt=a("li"),ao=s("language"),io=n(),Kt=a("li"),so=s("library"),oo=n(),Bt=a("li"),ro=s("license"),no=n(),Ut=a("li"),fo=s("model_name"),co=n(),Rt=a("li"),ho=s("pipeline_tag"),Za=n(),C=a("p"),po=s("It has a variety of attributes or keys available to you. This is because it is both an object and a dictionary, so you can either do "),Jt=a("code"),_o=s('model_args["author"]'),uo=s(" or "),Wt=a("code"),mo=s("model_args.author"),go=s(". For this tutorial, let\u2019s follow the latter format."),Ga=n(),te=a("p"),vo=s("The first criteria is getting all PyTorch models. This would be found under the "),Xt=a("code"),bo=s("library"),Eo=s(" attribute, so let\u2019s see if it is there:"),Qa=n(),E(me.$$.fragment),Va=n(),je=a("p"),yo=s("Available Attributes or Keys:"),ei=n(),_=a("ul"),Yt=a("li"),wo=s("AdapterTransformers"),$o=n(),Zt=a("li"),ko=s("Asteroid"),Io=n(),Gt=a("li"),Lo=s("ESPnet"),To=n(),Qt=a("li"),Fo=s("Flair"),Ao=n(),Vt=a("li"),Mo=s("JAX"),xo=n(),el=a("li"),Po=s("Joblib"),Do=n(),tl=a("li"),jo=s("Keras"),So=n(),ll=a("li"),Co=s("ONNX"),Oo=n(),al=a("li"),No=s("PyTorch"),Ho=n(),il=a("li"),qo=s("Pyannote"),zo=n(),sl=a("li"),Ko=s("Rust"),Bo=n(),ol=a("li"),Uo=s("Scikit_learn"),Ro=n(),rl=a("li"),Jo=s("SentenceTransformers"),Wo=n(),nl=a("li"),Xo=s("Stanza"),Yo=n(),fl=a("li"),Zo=s("TFLite"),Go=n(),cl=a("li"),Qo=s("TensorBoard"),Vo=n(),hl=a("li"),er=s("TensorFlow"),tr=n(),dl=a("li"),lr=s("TensorFlowTTS"),ar=n(),pl=a("li"),ir=s("Timm"),sr=n(),_l=a("li"),or=s("Transformers"),rr=n(),ul=a("li"),nr=s("allennlp"),fr=n(),ml=a("li"),cr=s("fastText"),hr=n(),gl=a("li"),dr=s("fastai"),pr=n(),vl=a("li"),_r=s("spaCy"),ur=n(),bl=a("li"),mr=s("speechbrain"),ti=n(),O=a("p"),gr=s("It is! The "),El=a("code"),vr=s("PyTorch"),br=s(" name is there, so you\u2019ll need to use "),yl=a("code"),Er=s("model_args.library.PyTorch"),yr=s(":"),li=n(),E(ge.$$.fragment),ai=n(),Se=a("p"),wr=s("\u2018pytorch\u2019"),ii=n(),N=a("p"),$r=s("Below is an animation repeating the process for finding both the "),wl=a("code"),kr=s("Text Classification"),Ir=s(" and "),$l=a("code"),Lr=s("glue"),Tr=s(" requirements:"),si=n(),Ce=a("p"),Oe=a("img"),oi=n(),Ne=a("p"),He=a("img"),ri=n(),H=a("p"),Fr=s("Now that all the pieces are there, the last step is to combine them all for something the API can use through the "),kl=a("code"),Ar=s("ModelFilter"),Mr=s(" and "),Il=a("code"),xr=s("DatasetFilter"),Pr=s(" classes. The classes transform the outputs of the previous step into something the API can use conveniently:"),ni=n(),E(ve.$$.fragment),fi=n(),qe=a("p"),Dr=s(`ModelInfo: {
modelId: 09panesara/distilbert-base-uncased-finetuned-cola
sha: f89a85cb8703676115912fffa55842f23eb981ab
lastModified: 2021-12-21T14:03:01.000Z
tags: [\u2018pytorch\u2019, \u2018tensorboard\u2019, \u2018distilbert\u2019, \u2018text-classification\u2019, \u2018dataset:glue\u2019, \u2018transformers\u2019, \u2018license:apache-2.0\u2019, \u2018generated_from_trainer\u2019, \u2018model-index\u2019, \u2018infinity_compatible\u2019]
pipeline_tag: text-classification
siblings: [ModelFile(rfilename=\u2019.gitattributes\u2019), ModelFile(rfilename=\u2019.gitignore\u2019), ModelFile(rfilename=\u2018README.md\u2019), ModelFile(rfilename=\u2018config.json\u2019), ModelFile(rfilename=\u2018pytorch_model.bin\u2019), ModelFile(rfilename=\u2018special_tokens_map.json\u2019), ModelFile(rfilename=\u2018tokenizer.json\u2019), ModelFile(rfilename=\u2018tokenizer_config.json\u2019), ModelFile(rfilename=\u2018training_args.bin\u2019), ModelFile(rfilename=\u2018vocab.txt\u2019), ModelFile(rfilename=\u2018runs/Dec21_13-51-40_bc62d5d57d92/events.out.tfevents.1640094759.bc62d5d57d92.77.0\u2019), ModelFile(rfilename=\u2018runs/Dec21_13-51-40_bc62d5d57d92/events.out.tfevents.1640095117.bc62d5d57d92.77.2\u2019), ModelFile(rfilename=\u2018runs/Dec21_13-51-40_bc62d5d57d92/1640094759.4067502/events.out.tfevents.1640094759.bc62d5d57d92.77.1\u2019)]
config: None
private: False
downloads: 6
library_name: transformers
likes: 0
}`),ci=n(),le=a("p"),jr=s("As you can see, it found the models that fit all the criteria. You can even take it further by passing in an array for each of the parameters from before. For example, let\u2019s take a look for the same configuration, but also include "),Ll=a("code"),Sr=s("TensorFlow"),Cr=s(" in the filter:"),hi=n(),E(be.$$.fragment),di=n(),ze=a("p"),Or=s(`ModelInfo: {
modelId: CAMeL-Lab/bert-base-arabic-camelbert-ca-poetry
sha: bc50b6dc1c97dc66998287efb6d044bdaa8f7057
lastModified: 2021-10-17T12:09:38.000Z
tags: [\u2018pytorch\u2019, \u2018tf\u2019, \u2018bert\u2019, \u2018text-classification\u2019, \u2018ar\u2019, \u2018arxiv:1905.05700\u2019, \u2018arxiv:2103.06678\u2019, \u2018transformers\u2019, \u2018license:apache-2.0\u2019, \u2018infinity_compatible\u2019]
pipeline_tag: text-classification
siblings: [ModelFile(rfilename=\u2019.gitattributes\u2019), ModelFile(rfilename=\u2018README.md\u2019), ModelFile(rfilename=\u2018config.json\u2019), ModelFile(rfilename=\u2018pytorch_model.bin\u2019), ModelFile(rfilename=\u2018special_tokens_map.json\u2019), ModelFile(rfilename=\u2018tf_model.h5\u2019), ModelFile(rfilename=\u2018tokenizer_config.json\u2019), ModelFile(rfilename=\u2018training_args.bin\u2019), ModelFile(rfilename=\u2018vocab.txt\u2019)]
config: None
private: False
downloads: 21
library_name: transformers
likes: 0
}`),pi=n(),W=a("h2"),ae=a("a"),Tl=a("span"),E(Ee.$$.fragment),Nr=n(),Fl=a("span"),Hr=s("Searching for a Dataset"),_i=n(),Ke=a("p"),qr=s("Similarly to finding a model, you can find a dataset easily by following the same steps."),ui=n(),Be=a("p"),zr=s("The new scenario will be:"),mi=n(),Ue=a("blockquote"),ye=a("p"),Kr=s("I want to search the Hub for all datasets that can be used for "),Al=a("code"),Br=s("text_classification"),Ur=s(" and are in English."),gi=n(),q=a("p"),Rr=s("First, you should look at what is available in the "),Ml=a("code"),Jr=s("DatasetSearchArguments"),Wr=s(", similar to the "),xl=a("code"),Xr=s("ModelSearchArguments"),Yr=s(":"),vi=n(),E(we.$$.fragment),bi=n(),Re=a("p"),Zr=s("Available Attributes or Keys:"),Ei=n(),g=a("ul"),Pl=a("li"),Gr=s("author"),Qr=n(),Dl=a("li"),Vr=s("benchmark"),en=n(),jl=a("li"),tn=s("dataset_name"),ln=n(),Sl=a("li"),an=s("language_creators"),sn=n(),Cl=a("li"),on=s("languages"),rn=n(),Ol=a("li"),nn=s("licenses"),fn=n(),Nl=a("li"),cn=s("multilinguality"),hn=n(),Hl=a("li"),dn=s("size_categories"),pn=n(),ql=a("li"),_n=s("task_categories"),un=n(),zl=a("li"),mn=s("task_ids"),yi=n(),D=a("p"),Kl=a("code"),gn=s("text_classification"),vn=s(" is a "),Bl=a("em"),bn=s("task"),En=s(", so first you should check "),Ul=a("code"),yn=s("task_categories"),wn=s(":"),wi=n(),E($e.$$.fragment),$i=n(),Je=a("p"),$n=s("Available Attributes or Keys:"),ki=n(),d=a("ul"),Rl=a("li"),kn=s("Summarization"),In=n(),Jl=a("li"),Ln=s("audio_classification"),Tn=n(),Wl=a("li"),Fn=s("automatic_speech_recognition"),An=n(),Xl=a("li"),Mn=s("code_generation"),xn=n(),Yl=a("li"),Pn=s("conditional_text_generation"),Dn=n(),Zl=a("li"),jn=s("cross_language_transcription"),Sn=n(),Gl=a("li"),Cn=s("dialogue_system"),On=n(),Ql=a("li"),Nn=s("grammaticalerrorcorrection"),Hn=n(),Vl=a("li"),qn=s("machine_translation"),zn=n(),ea=a("li"),Kn=s("named_entity_disambiguation"),Bn=n(),ta=a("li"),Un=s("named_entity_recognition"),Rn=n(),la=a("li"),Jn=s("natural_language_inference"),Wn=n(),aa=a("li"),Xn=s("news_classification"),Yn=n(),ia=a("li"),Zn=s("other"),Gn=n(),sa=a("li"),Qn=s("other_test"),Vn=n(),oa=a("li"),ef=s("other_text_search"),tf=n(),ra=a("li"),lf=s("paraphrase"),af=n(),na=a("li"),sf=s("paraphrasedetection"),of=n(),fa=a("li"),rf=s("query_paraphrasing"),nf=n(),ca=a("li"),ff=s("question_answering"),cf=n(),ha=a("li"),hf=s("question_generation"),df=n(),da=a("li"),pf=s("sentiment_analysis"),_f=n(),pa=a("li"),uf=s("sequence_modeling"),mf=n(),_a=a("li"),gf=s("speech_processing"),vf=n(),ua=a("li"),bf=s("structure_prediction"),Ef=n(),ma=a("li"),yf=s("summarization"),wf=n(),ga=a("li"),$f=s("text_classification"),kf=n(),va=a("li"),If=s("text_generation"),Lf=n(),ba=a("li"),Tf=s("text_retrieval"),Ff=n(),Ea=a("li"),Af=s("text_scoring"),Mf=n(),ya=a("li"),xf=s("textual_entailment"),Pf=n(),wa=a("li"),Df=s("translation"),Ii=n(),z=a("p"),jf=s("There you will find "),$a=a("code"),Sf=s("text_classification"),Cf=s(", so you should use "),ka=a("code"),Of=s("dataset_args.task_categories.text_classification"),Nf=s("."),Li=n(),K=a("p"),Hf=s("Next we need to find the proper language. There is a "),Ia=a("code"),qf=s("languages"),zf=s(" property we can check. These are two-letter language codes, so you should check if it has "),La=a("code"),Kf=s("en"),Bf=s(":"),Ti=n(),E(ke.$$.fragment),Fi=n(),We=a("p"),Uf=s("True"),Ai=n(),Xe=a("p"),Rf=s("Now that the pieces are found, you can write a filter:"),Mi=n(),E(Ie.$$.fragment),xi=n(),Ye=a("p"),Jf=s("And search the API!"),Pi=n(),E(Le.$$.fragment),Di=n(),Ze=a("p"),Wf=s(`DatasetInfo: {
id: Abirate/english_quotes
lastModified: None
tags: [\u2018annotations_creators:expert-generated\u2019, \u2018language_creators:expert-generated\u2019, \u2018language_creators:crowdsourced\u2019, \u2018languages:en\u2019, \u2018multilinguality:monolingual\u2019, \u2018source_datasets:original\u2019, \u2018task_categories:text-classification\u2019, \u2018task_ids:multi-label-classification\u2019]
private: False
author: Abirate
description: None
citation: None
cardData: None
siblings: None
gated: False
}`),ji=n(),Ge=a("p"),Xf=s("With these two functionalities combined, you can search for all available parameters and tags within the Hub to search for with ease for both Datasets and Models!"),this.h()},l(e){const c=Yd('[data-svelte="svelte-1phssyn"]',document.head);j=i(c,"META",{name:!0,content:!0}),c.forEach(l),Fe=f(e),A=i(e,"H1",{class:!0});var Ci=r(A);P=i(Ci,"A",{id:!0,class:!0,href:!0});var Qf=r(P);ot=i(Qf,"SPAN",{});var Vf=r(ot);y(oe.$$.fragment,Vf),Vf.forEach(l),Qf.forEach(l),Zi=f(Ci),rt=i(Ci,"SPAN",{});var ec=r(rt);Gi=o(ec,"Searching the Hub Efficiently with Python"),ec.forEach(l),Ci.forEach(l),Fa=f(e),X=i(e,"P",{});var Oi=r(X);Qi=o(Oi,"In this tutorial, we will explore how to interact and explore the Hugging Face Hub with the "),nt=i(Oi,"CODE",{});var tc=r(nt);Vi=o(tc,"huggingface_hub"),tc.forEach(l),es=o(Oi," library to help find available models and datasets quickly."),Oi.forEach(l),Aa=f(e),U=i(e,"H2",{class:!0});var Ni=r(U);Y=i(Ni,"A",{id:!0,class:!0,href:!0});var lc=r(Y);ft=i(lc,"SPAN",{});var ac=r(ft);y(re.$$.fragment,ac),ac.forEach(l),lc.forEach(l),ts=f(Ni),ct=i(Ni,"SPAN",{});var ic=r(ct);ls=o(ic,"The Basics"),ic.forEach(l),Ni.forEach(l),Ma=f(e),ne=i(e,"P",{});var Yf=r(ne);ht=i(Yf,"CODE",{});var sc=r(ht);as=o(sc,"huggingface_hub"),sc.forEach(l),is=o(Yf," is a Python library that allows anyone to freely extract useful information from the Hub, as well as downloading and publishing models. You can install it with:"),Yf.forEach(l),xa=f(e),y(fe.$$.fragment,e),Pa=f(e),Z=i(e,"P",{});var Hi=r(Z);ss=o(Hi,"It comes packaged with an interface that can interact with the Hub in the "),dt=i(Hi,"CODE",{});var oc=r(dt);os=o(oc,"HfApi"),oc.forEach(l),rs=o(Hi," class:"),Hi.forEach(l),Da=f(e),y(ce.$$.fragment,e),ja=f(e),Ae=i(e,"P",{});var rc=r(Ae);ns=o(rc,"This class lets you perform a variety of operations that interact with the raw Hub API. We\u2019ll be focusing on two specific functions:"),rc.forEach(l),Sa=f(e),G=i(e,"UL",{});var qi=r(G);pt=i(qi,"LI",{});var nc=r(pt);_t=i(nc,"CODE",{});var fc=r(_t);fs=o(fc,"list_models"),fc.forEach(l),nc.forEach(l),cs=f(qi),ut=i(qi,"LI",{});var cc=r(ut);mt=i(cc,"CODE",{});var hc=r(mt);hs=o(hc,"list_datasets"),hc.forEach(l),cc.forEach(l),qi.forEach(l),Ca=f(e),Me=i(e,"P",{});var dc=r(Me);ds=o(dc,"If you look at what can be passed into each function, you will find the parameter list looks something like:"),dc.forEach(l),Oa=f(e),M=i(e,"UL",{});var ie=r(M);gt=i(ie,"LI",{});var pc=r(gt);vt=i(pc,"CODE",{});var _c=r(vt);ps=o(_c,"filter"),_c.forEach(l),pc.forEach(l),_s=f(ie),bt=i(ie,"LI",{});var uc=r(bt);Et=i(uc,"CODE",{});var mc=r(Et);us=o(mc,"author"),mc.forEach(l),uc.forEach(l),ms=f(ie),yt=i(ie,"LI",{});var gc=r(yt);wt=i(gc,"CODE",{});var vc=r(wt);gs=o(vc,"search"),vc.forEach(l),gc.forEach(l),vs=f(ie),$t=i(ie,"LI",{});var bc=r($t);bs=o(bc,"\u2026"),bc.forEach(l),ie.forEach(l),Na=f(e),x=i(e,"P",{});var se=r(x);Es=o(se,"Two of these parameters are intuitive ("),kt=i(se,"CODE",{});var Ec=r(kt);ys=o(Ec,"author"),Ec.forEach(l),ws=o(se," and "),It=i(se,"CODE",{});var yc=r(It);$s=o(yc,"search"),yc.forEach(l),ks=o(se,"), but what about that "),Lt=i(se,"CODE",{});var wc=r(Lt);Is=o(wc,"filter"),wc.forEach(l),Ls=o(se,"? \u{1F914} Let\u2019s dive into a few helpers quickly and revisit that question."),se.forEach(l),Ha=f(e),R=i(e,"H2",{class:!0});var zi=r(R);Q=i(zi,"A",{id:!0,class:!0,href:!0});var $c=r(Q);Tt=i($c,"SPAN",{});var kc=r(Tt);y(he.$$.fragment,kc),kc.forEach(l),$c.forEach(l),Ts=f(zi),Ft=i(zi,"SPAN",{});var Ic=r(Ft);Fs=o(Ic,"Search Parameters"),Ic.forEach(l),zi.forEach(l),qa=f(e),L=i(e,"P",{});var B=r(L);As=o(B,"The "),At=i(B,"CODE",{});var Lc=r(At);Ms=o(Lc,"huggingface_hub"),Lc.forEach(l),xs=o(B," provides a user-friendly interface to know what exactly can be passed into this "),Mt=i(B,"CODE",{});var Tc=r(Mt);Ps=o(Tc,"filter"),Tc.forEach(l),Ds=o(B," parameter through the "),xt=i(B,"CODE",{});var Fc=r(xt);js=o(Fc,"ModelSearchArguments"),Fc.forEach(l),Ss=o(B," and "),Pt=i(B,"CODE",{});var Ac=r(Pt);Cs=o(Ac,"DatasetSearchArguments"),Ac.forEach(l),Os=o(B," classes:"),B.forEach(l),za=f(e),y(de.$$.fragment,e),Ka=f(e),S=i(e,"P",{});var Qe=r(S);Ns=o(Qe,"These are nested namespace objects that have "),Dt=i(Qe,"STRONG",{});var Mc=r(Dt);Hs=o(Mc,"every single option"),Mc.forEach(l),qs=o(Qe," available on the Hub and that will return what should be passed to "),jt=i(Qe,"CODE",{});var xc=r(jt);zs=o(xc,"filter"),xc.forEach(l),Ks=o(Qe,". The best of all is: it has tab completion \u{1F38A} ."),Qe.forEach(l),Ba=f(e),J=i(e,"H2",{class:!0});var Ki=r(J);V=i(Ki,"A",{id:!0,class:!0,href:!0});var Pc=r(V);St=i(Pc,"SPAN",{});var Dc=r(St);y(pe.$$.fragment,Dc),Dc.forEach(l),Pc.forEach(l),Bs=f(Ki),Ct=i(Ki,"SPAN",{});var jc=r(Ct);Us=o(jc,"Searching for a Model"),jc.forEach(l),Ki.forEach(l),Ua=f(e),xe=i(e,"P",{});var Sc=r(xe);Rs=o(Sc,"Let\u2019s pose a problem that would be complicated to solve without access to this information:"),Sc.forEach(l),Ra=f(e),Pe=i(e,"BLOCKQUOTE",{});var Cc=r(Pe);_e=i(Cc,"P",{});var Bi=r(_e);Js=o(Bi,"I want to search the Hub for all PyTorch models trained on the "),Ot=i(Bi,"CODE",{});var Oc=r(Ot);Ws=o(Oc,"glue"),Oc.forEach(l),Xs=o(Bi," dataset that can do Text Classification."),Bi.forEach(l),Cc.forEach(l),Ja=f(e),ee=i(e,"P",{});var Ui=r(ee);Ys=o(Ui,"If you check what is available in "),Nt=i(Ui,"CODE",{});var Nc=r(Nt);Zs=o(Nc,"model_args"),Nc.forEach(l),Gs=o(Ui," by checking it\u2019s output, you will find:"),Ui.forEach(l),Wa=f(e),y(ue.$$.fragment,e),Xa=f(e),De=i(e,"P",{});var Hc=r(De);Qs=o(Hc,"Available Attributes or Keys:"),Hc.forEach(l),Ya=f(e),b=i(e,"UL",{});var T=r(b);Ht=i(T,"LI",{});var qc=r(Ht);Vs=o(qc,"author"),qc.forEach(l),eo=f(T),qt=i(T,"LI",{});var zc=r(qt);to=o(zc,"dataset"),zc.forEach(l),lo=f(T),zt=i(T,"LI",{});var Kc=r(zt);ao=o(Kc,"language"),Kc.forEach(l),io=f(T),Kt=i(T,"LI",{});var Bc=r(Kt);so=o(Bc,"library"),Bc.forEach(l),oo=f(T),Bt=i(T,"LI",{});var Uc=r(Bt);ro=o(Uc,"license"),Uc.forEach(l),no=f(T),Ut=i(T,"LI",{});var Rc=r(Ut);fo=o(Rc,"model_name"),Rc.forEach(l),co=f(T),Rt=i(T,"LI",{});var Jc=r(Rt);ho=o(Jc,"pipeline_tag"),Jc.forEach(l),T.forEach(l),Za=f(e),C=i(e,"P",{});var Ve=r(C);po=o(Ve,"It has a variety of attributes or keys available to you. This is because it is both an object and a dictionary, so you can either do "),Jt=i(Ve,"CODE",{});var Wc=r(Jt);_o=o(Wc,'model_args["author"]'),Wc.forEach(l),uo=o(Ve," or "),Wt=i(Ve,"CODE",{});var Xc=r(Wt);mo=o(Xc,"model_args.author"),Xc.forEach(l),go=o(Ve,". For this tutorial, let\u2019s follow the latter format."),Ve.forEach(l),Ga=f(e),te=i(e,"P",{});var Ri=r(te);vo=o(Ri,"The first criteria is getting all PyTorch models. This would be found under the "),Xt=i(Ri,"CODE",{});var Yc=r(Xt);bo=o(Yc,"library"),Yc.forEach(l),Eo=o(Ri," attribute, so let\u2019s see if it is there:"),Ri.forEach(l),Qa=f(e),y(me.$$.fragment,e),Va=f(e),je=i(e,"P",{});var Zc=r(je);yo=o(Zc,"Available Attributes or Keys:"),Zc.forEach(l),ei=f(e),_=i(e,"UL",{});var u=r(_);Yt=i(u,"LI",{});var Gc=r(Yt);wo=o(Gc,"AdapterTransformers"),Gc.forEach(l),$o=f(u),Zt=i(u,"LI",{});var Qc=r(Zt);ko=o(Qc,"Asteroid"),Qc.forEach(l),Io=f(u),Gt=i(u,"LI",{});var Vc=r(Gt);Lo=o(Vc,"ESPnet"),Vc.forEach(l),To=f(u),Qt=i(u,"LI",{});var eh=r(Qt);Fo=o(eh,"Flair"),eh.forEach(l),Ao=f(u),Vt=i(u,"LI",{});var th=r(Vt);Mo=o(th,"JAX"),th.forEach(l),xo=f(u),el=i(u,"LI",{});var lh=r(el);Po=o(lh,"Joblib"),lh.forEach(l),Do=f(u),tl=i(u,"LI",{});var ah=r(tl);jo=o(ah,"Keras"),ah.forEach(l),So=f(u),ll=i(u,"LI",{});var ih=r(ll);Co=o(ih,"ONNX"),ih.forEach(l),Oo=f(u),al=i(u,"LI",{});var sh=r(al);No=o(sh,"PyTorch"),sh.forEach(l),Ho=f(u),il=i(u,"LI",{});var oh=r(il);qo=o(oh,"Pyannote"),oh.forEach(l),zo=f(u),sl=i(u,"LI",{});var rh=r(sl);Ko=o(rh,"Rust"),rh.forEach(l),Bo=f(u),ol=i(u,"LI",{});var nh=r(ol);Uo=o(nh,"Scikit_learn"),nh.forEach(l),Ro=f(u),rl=i(u,"LI",{});var fh=r(rl);Jo=o(fh,"SentenceTransformers"),fh.forEach(l),Wo=f(u),nl=i(u,"LI",{});var ch=r(nl);Xo=o(ch,"Stanza"),ch.forEach(l),Yo=f(u),fl=i(u,"LI",{});var hh=r(fl);Zo=o(hh,"TFLite"),hh.forEach(l),Go=f(u),cl=i(u,"LI",{});var dh=r(cl);Qo=o(dh,"TensorBoard"),dh.forEach(l),Vo=f(u),hl=i(u,"LI",{});var ph=r(hl);er=o(ph,"TensorFlow"),ph.forEach(l),tr=f(u),dl=i(u,"LI",{});var _h=r(dl);lr=o(_h,"TensorFlowTTS"),_h.forEach(l),ar=f(u),pl=i(u,"LI",{});var uh=r(pl);ir=o(uh,"Timm"),uh.forEach(l),sr=f(u),_l=i(u,"LI",{});var mh=r(_l);or=o(mh,"Transformers"),mh.forEach(l),rr=f(u),ul=i(u,"LI",{});var gh=r(ul);nr=o(gh,"allennlp"),gh.forEach(l),fr=f(u),ml=i(u,"LI",{});var vh=r(ml);cr=o(vh,"fastText"),vh.forEach(l),hr=f(u),gl=i(u,"LI",{});var bh=r(gl);dr=o(bh,"fastai"),bh.forEach(l),pr=f(u),vl=i(u,"LI",{});var Eh=r(vl);_r=o(Eh,"spaCy"),Eh.forEach(l),ur=f(u),bl=i(u,"LI",{});var yh=r(bl);mr=o(yh,"speechbrain"),yh.forEach(l),u.forEach(l),ti=f(e),O=i(e,"P",{});var et=r(O);gr=o(et,"It is! The "),El=i(et,"CODE",{});var wh=r(El);vr=o(wh,"PyTorch"),wh.forEach(l),br=o(et," name is there, so you\u2019ll need to use "),yl=i(et,"CODE",{});var $h=r(yl);Er=o($h,"model_args.library.PyTorch"),$h.forEach(l),yr=o(et,":"),et.forEach(l),li=f(e),y(ge.$$.fragment,e),ai=f(e),Se=i(e,"P",{});var kh=r(Se);wr=o(kh,"\u2018pytorch\u2019"),kh.forEach(l),ii=f(e),N=i(e,"P",{});var tt=r(N);$r=o(tt,"Below is an animation repeating the process for finding both the "),wl=i(tt,"CODE",{});var Ih=r(wl);kr=o(Ih,"Text Classification"),Ih.forEach(l),Ir=o(tt," and "),$l=i(tt,"CODE",{});var Lh=r($l);Lr=o(Lh,"glue"),Lh.forEach(l),Tr=o(tt," requirements:"),tt.forEach(l),si=f(e),Ce=i(e,"P",{});var Th=r(Ce);Oe=i(Th,"IMG",{src:!0,alt:!0}),Th.forEach(l),oi=f(e),Ne=i(e,"P",{});var Fh=r(Ne);He=i(Fh,"IMG",{src:!0,alt:!0}),Fh.forEach(l),ri=f(e),H=i(e,"P",{});var lt=r(H);Fr=o(lt,"Now that all the pieces are there, the last step is to combine them all for something the API can use through the "),kl=i(lt,"CODE",{});var Ah=r(kl);Ar=o(Ah,"ModelFilter"),Ah.forEach(l),Mr=o(lt," and "),Il=i(lt,"CODE",{});var Mh=r(Il);xr=o(Mh,"DatasetFilter"),Mh.forEach(l),Pr=o(lt," classes. The classes transform the outputs of the previous step into something the API can use conveniently:"),lt.forEach(l),ni=f(e),y(ve.$$.fragment,e),fi=f(e),qe=i(e,"P",{});var xh=r(qe);Dr=o(xh,`ModelInfo: {
modelId: 09panesara/distilbert-base-uncased-finetuned-cola
sha: f89a85cb8703676115912fffa55842f23eb981ab
lastModified: 2021-12-21T14:03:01.000Z
tags: [\u2018pytorch\u2019, \u2018tensorboard\u2019, \u2018distilbert\u2019, \u2018text-classification\u2019, \u2018dataset:glue\u2019, \u2018transformers\u2019, \u2018license:apache-2.0\u2019, \u2018generated_from_trainer\u2019, \u2018model-index\u2019, \u2018infinity_compatible\u2019]
pipeline_tag: text-classification
siblings: [ModelFile(rfilename=\u2019.gitattributes\u2019), ModelFile(rfilename=\u2019.gitignore\u2019), ModelFile(rfilename=\u2018README.md\u2019), ModelFile(rfilename=\u2018config.json\u2019), ModelFile(rfilename=\u2018pytorch_model.bin\u2019), ModelFile(rfilename=\u2018special_tokens_map.json\u2019), ModelFile(rfilename=\u2018tokenizer.json\u2019), ModelFile(rfilename=\u2018tokenizer_config.json\u2019), ModelFile(rfilename=\u2018training_args.bin\u2019), ModelFile(rfilename=\u2018vocab.txt\u2019), ModelFile(rfilename=\u2018runs/Dec21_13-51-40_bc62d5d57d92/events.out.tfevents.1640094759.bc62d5d57d92.77.0\u2019), ModelFile(rfilename=\u2018runs/Dec21_13-51-40_bc62d5d57d92/events.out.tfevents.1640095117.bc62d5d57d92.77.2\u2019), ModelFile(rfilename=\u2018runs/Dec21_13-51-40_bc62d5d57d92/1640094759.4067502/events.out.tfevents.1640094759.bc62d5d57d92.77.1\u2019)]
config: None
private: False
downloads: 6
library_name: transformers
likes: 0
}`),xh.forEach(l),ci=f(e),le=i(e,"P",{});var Ji=r(le);jr=o(Ji,"As you can see, it found the models that fit all the criteria. You can even take it further by passing in an array for each of the parameters from before. For example, let\u2019s take a look for the same configuration, but also include "),Ll=i(Ji,"CODE",{});var Ph=r(Ll);Sr=o(Ph,"TensorFlow"),Ph.forEach(l),Cr=o(Ji," in the filter:"),Ji.forEach(l),hi=f(e),y(be.$$.fragment,e),di=f(e),ze=i(e,"P",{});var Dh=r(ze);Or=o(Dh,`ModelInfo: {
modelId: CAMeL-Lab/bert-base-arabic-camelbert-ca-poetry
sha: bc50b6dc1c97dc66998287efb6d044bdaa8f7057
lastModified: 2021-10-17T12:09:38.000Z
tags: [\u2018pytorch\u2019, \u2018tf\u2019, \u2018bert\u2019, \u2018text-classification\u2019, \u2018ar\u2019, \u2018arxiv:1905.05700\u2019, \u2018arxiv:2103.06678\u2019, \u2018transformers\u2019, \u2018license:apache-2.0\u2019, \u2018infinity_compatible\u2019]
pipeline_tag: text-classification
siblings: [ModelFile(rfilename=\u2019.gitattributes\u2019), ModelFile(rfilename=\u2018README.md\u2019), ModelFile(rfilename=\u2018config.json\u2019), ModelFile(rfilename=\u2018pytorch_model.bin\u2019), ModelFile(rfilename=\u2018special_tokens_map.json\u2019), ModelFile(rfilename=\u2018tf_model.h5\u2019), ModelFile(rfilename=\u2018tokenizer_config.json\u2019), ModelFile(rfilename=\u2018training_args.bin\u2019), ModelFile(rfilename=\u2018vocab.txt\u2019)]
config: None
private: False
downloads: 21
library_name: transformers
likes: 0
}`),Dh.forEach(l),pi=f(e),W=i(e,"H2",{class:!0});var Wi=r(W);ae=i(Wi,"A",{id:!0,class:!0,href:!0});var jh=r(ae);Tl=i(jh,"SPAN",{});var Sh=r(Tl);y(Ee.$$.fragment,Sh),Sh.forEach(l),jh.forEach(l),Nr=f(Wi),Fl=i(Wi,"SPAN",{});var Ch=r(Fl);Hr=o(Ch,"Searching for a Dataset"),Ch.forEach(l),Wi.forEach(l),_i=f(e),Ke=i(e,"P",{});var Oh=r(Ke);qr=o(Oh,"Similarly to finding a model, you can find a dataset easily by following the same steps."),Oh.forEach(l),ui=f(e),Be=i(e,"P",{});var Nh=r(Be);zr=o(Nh,"The new scenario will be:"),Nh.forEach(l),mi=f(e),Ue=i(e,"BLOCKQUOTE",{});var Hh=r(Ue);ye=i(Hh,"P",{});var Xi=r(ye);Kr=o(Xi,"I want to search the Hub for all datasets that can be used for "),Al=i(Xi,"CODE",{});var qh=r(Al);Br=o(qh,"text_classification"),qh.forEach(l),Ur=o(Xi," and are in English."),Xi.forEach(l),Hh.forEach(l),gi=f(e),q=i(e,"P",{});var at=r(q);Rr=o(at,"First, you should look at what is available in the "),Ml=i(at,"CODE",{});var zh=r(Ml);Jr=o(zh,"DatasetSearchArguments"),zh.forEach(l),Wr=o(at,", similar to the "),xl=i(at,"CODE",{});var Kh=r(xl);Xr=o(Kh,"ModelSearchArguments"),Kh.forEach(l),Yr=o(at,":"),at.forEach(l),vi=f(e),y(we.$$.fragment,e),bi=f(e),Re=i(e,"P",{});var Bh=r(Re);Zr=o(Bh,"Available Attributes or Keys:"),Bh.forEach(l),Ei=f(e),g=i(e,"UL",{});var v=r(g);Pl=i(v,"LI",{});var Uh=r(Pl);Gr=o(Uh,"author"),Uh.forEach(l),Qr=f(v),Dl=i(v,"LI",{});var Rh=r(Dl);Vr=o(Rh,"benchmark"),Rh.forEach(l),en=f(v),jl=i(v,"LI",{});var Jh=r(jl);tn=o(Jh,"dataset_name"),Jh.forEach(l),ln=f(v),Sl=i(v,"LI",{});var Wh=r(Sl);an=o(Wh,"language_creators"),Wh.forEach(l),sn=f(v),Cl=i(v,"LI",{});var Xh=r(Cl);on=o(Xh,"languages"),Xh.forEach(l),rn=f(v),Ol=i(v,"LI",{});var Yh=r(Ol);nn=o(Yh,"licenses"),Yh.forEach(l),fn=f(v),Nl=i(v,"LI",{});var Zh=r(Nl);cn=o(Zh,"multilinguality"),Zh.forEach(l),hn=f(v),Hl=i(v,"LI",{});var Gh=r(Hl);dn=o(Gh,"size_categories"),Gh.forEach(l),pn=f(v),ql=i(v,"LI",{});var Qh=r(ql);_n=o(Qh,"task_categories"),Qh.forEach(l),un=f(v),zl=i(v,"LI",{});var Vh=r(zl);mn=o(Vh,"task_ids"),Vh.forEach(l),v.forEach(l),yi=f(e),D=i(e,"P",{});var Te=r(D);Kl=i(Te,"CODE",{});var ed=r(Kl);gn=o(ed,"text_classification"),ed.forEach(l),vn=o(Te," is a "),Bl=i(Te,"EM",{});var td=r(Bl);bn=o(td,"task"),td.forEach(l),En=o(Te,", so first you should check "),Ul=i(Te,"CODE",{});var ld=r(Ul);yn=o(ld,"task_categories"),ld.forEach(l),wn=o(Te,":"),Te.forEach(l),wi=f(e),y($e.$$.fragment,e),$i=f(e),Je=i(e,"P",{});var ad=r(Je);$n=o(ad,"Available Attributes or Keys:"),ad.forEach(l),ki=f(e),d=i(e,"UL",{});var p=r(d);Rl=i(p,"LI",{});var id=r(Rl);kn=o(id,"Summarization"),id.forEach(l),In=f(p),Jl=i(p,"LI",{});var sd=r(Jl);Ln=o(sd,"audio_classification"),sd.forEach(l),Tn=f(p),Wl=i(p,"LI",{});var od=r(Wl);Fn=o(od,"automatic_speech_recognition"),od.forEach(l),An=f(p),Xl=i(p,"LI",{});var rd=r(Xl);Mn=o(rd,"code_generation"),rd.forEach(l),xn=f(p),Yl=i(p,"LI",{});var nd=r(Yl);Pn=o(nd,"conditional_text_generation"),nd.forEach(l),Dn=f(p),Zl=i(p,"LI",{});var fd=r(Zl);jn=o(fd,"cross_language_transcription"),fd.forEach(l),Sn=f(p),Gl=i(p,"LI",{});var cd=r(Gl);Cn=o(cd,"dialogue_system"),cd.forEach(l),On=f(p),Ql=i(p,"LI",{});var hd=r(Ql);Nn=o(hd,"grammaticalerrorcorrection"),hd.forEach(l),Hn=f(p),Vl=i(p,"LI",{});var dd=r(Vl);qn=o(dd,"machine_translation"),dd.forEach(l),zn=f(p),ea=i(p,"LI",{});var pd=r(ea);Kn=o(pd,"named_entity_disambiguation"),pd.forEach(l),Bn=f(p),ta=i(p,"LI",{});var _d=r(ta);Un=o(_d,"named_entity_recognition"),_d.forEach(l),Rn=f(p),la=i(p,"LI",{});var ud=r(la);Jn=o(ud,"natural_language_inference"),ud.forEach(l),Wn=f(p),aa=i(p,"LI",{});var md=r(aa);Xn=o(md,"news_classification"),md.forEach(l),Yn=f(p),ia=i(p,"LI",{});var gd=r(ia);Zn=o(gd,"other"),gd.forEach(l),Gn=f(p),sa=i(p,"LI",{});var vd=r(sa);Qn=o(vd,"other_test"),vd.forEach(l),Vn=f(p),oa=i(p,"LI",{});var bd=r(oa);ef=o(bd,"other_text_search"),bd.forEach(l),tf=f(p),ra=i(p,"LI",{});var Ed=r(ra);lf=o(Ed,"paraphrase"),Ed.forEach(l),af=f(p),na=i(p,"LI",{});var yd=r(na);sf=o(yd,"paraphrasedetection"),yd.forEach(l),of=f(p),fa=i(p,"LI",{});var wd=r(fa);rf=o(wd,"query_paraphrasing"),wd.forEach(l),nf=f(p),ca=i(p,"LI",{});var $d=r(ca);ff=o($d,"question_answering"),$d.forEach(l),cf=f(p),ha=i(p,"LI",{});var kd=r(ha);hf=o(kd,"question_generation"),kd.forEach(l),df=f(p),da=i(p,"LI",{});var Id=r(da);pf=o(Id,"sentiment_analysis"),Id.forEach(l),_f=f(p),pa=i(p,"LI",{});var Ld=r(pa);uf=o(Ld,"sequence_modeling"),Ld.forEach(l),mf=f(p),_a=i(p,"LI",{});var Td=r(_a);gf=o(Td,"speech_processing"),Td.forEach(l),vf=f(p),ua=i(p,"LI",{});var Fd=r(ua);bf=o(Fd,"structure_prediction"),Fd.forEach(l),Ef=f(p),ma=i(p,"LI",{});var Ad=r(ma);yf=o(Ad,"summarization"),Ad.forEach(l),wf=f(p),ga=i(p,"LI",{});var Md=r(ga);$f=o(Md,"text_classification"),Md.forEach(l),kf=f(p),va=i(p,"LI",{});var xd=r(va);If=o(xd,"text_generation"),xd.forEach(l),Lf=f(p),ba=i(p,"LI",{});var Pd=r(ba);Tf=o(Pd,"text_retrieval"),Pd.forEach(l),Ff=f(p),Ea=i(p,"LI",{});var Dd=r(Ea);Af=o(Dd,"text_scoring"),Dd.forEach(l),Mf=f(p),ya=i(p,"LI",{});var jd=r(ya);xf=o(jd,"textual_entailment"),jd.forEach(l),Pf=f(p),wa=i(p,"LI",{});var Sd=r(wa);Df=o(Sd,"translation"),Sd.forEach(l),p.forEach(l),Ii=f(e),z=i(e,"P",{});var it=r(z);jf=o(it,"There you will find "),$a=i(it,"CODE",{});var Cd=r($a);Sf=o(Cd,"text_classification"),Cd.forEach(l),Cf=o(it,", so you should use "),ka=i(it,"CODE",{});var Od=r(ka);Of=o(Od,"dataset_args.task_categories.text_classification"),Od.forEach(l),Nf=o(it,"."),it.forEach(l),Li=f(e),K=i(e,"P",{});var st=r(K);Hf=o(st,"Next we need to find the proper language. There is a "),Ia=i(st,"CODE",{});var Nd=r(Ia);qf=o(Nd,"languages"),Nd.forEach(l),zf=o(st," property we can check. These are two-letter language codes, so you should check if it has "),La=i(st,"CODE",{});var Hd=r(La);Kf=o(Hd,"en"),Hd.forEach(l),Bf=o(st,":"),st.forEach(l),Ti=f(e),y(ke.$$.fragment,e),Fi=f(e),We=i(e,"P",{});var qd=r(We);Uf=o(qd,"True"),qd.forEach(l),Ai=f(e),Xe=i(e,"P",{});var zd=r(Xe);Rf=o(zd,"Now that the pieces are found, you can write a filter:"),zd.forEach(l),Mi=f(e),y(Ie.$$.fragment,e),xi=f(e),Ye=i(e,"P",{});var Kd=r(Ye);Jf=o(Kd,"And search the API!"),Kd.forEach(l),Pi=f(e),y(Le.$$.fragment,e),Di=f(e),Ze=i(e,"P",{});var Bd=r(Ze);Wf=o(Bd,`DatasetInfo: {
id: Abirate/english_quotes
lastModified: None
tags: [\u2018annotations_creators:expert-generated\u2019, \u2018language_creators:expert-generated\u2019, \u2018language_creators:crowdsourced\u2019, \u2018languages:en\u2019, \u2018multilinguality:monolingual\u2019, \u2018source_datasets:original\u2019, \u2018task_categories:text-classification\u2019, \u2018task_ids:multi-label-classification\u2019]
private: False
author: Abirate
description: None
citation: None
cardData: None
siblings: None
gated: False
}`),Bd.forEach(l),ji=f(e),Ge=i(e,"P",{});var Ud=r(Ge);Xf=o(Ud,"With these two functionalities combined, you can search for all available parameters and tags within the Hub to search for with ease for both Datasets and Models!"),Ud.forEach(l),this.h()},h(){m(j,"name","hf:doc:metadata"),m(j,"content",JSON.stringify(Qd)),m(P,"id","searching-the-hub-efficiently-with-python"),m(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(P,"href","#searching-the-hub-efficiently-with-python"),m(A,"class","relative group"),m(Y,"id","the-basics"),m(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Y,"href","#the-basics"),m(U,"class","relative group"),m(Q,"id","search-parameters"),m(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Q,"href","#search-parameters"),m(R,"class","relative group"),m(V,"id","searching-for-a-model"),m(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(V,"href","#searching-for-a-model"),m(J,"class","relative group"),Rd(Oe.src,Zf="../assets/hub/search_text_classification.gif")||m(Oe,"src",Zf),m(Oe,"alt","Animation exploring `model_args.pipeline_tag`"),Rd(He.src,Gf="../assets/hub/search_glue.gif")||m(He,"src",Gf),m(He,"alt","Animation exploring `model_args.dataset`"),m(ae,"id","searching-for-a-dataset"),m(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ae,"href","#searching-for-a-dataset"),m(W,"class","relative group")},m(e,c){t(document.head,j),h(e,Fe,c),h(e,A,c),t(A,P),t(P,ot),w(oe,ot,null),t(A,Zi),t(A,rt),t(rt,Gi),h(e,Fa,c),h(e,X,c),t(X,Qi),t(X,nt),t(nt,Vi),t(X,es),h(e,Aa,c),h(e,U,c),t(U,Y),t(Y,ft),w(re,ft,null),t(U,ts),t(U,ct),t(ct,ls),h(e,Ma,c),h(e,ne,c),t(ne,ht),t(ht,as),t(ne,is),h(e,xa,c),w(fe,e,c),h(e,Pa,c),h(e,Z,c),t(Z,ss),t(Z,dt),t(dt,os),t(Z,rs),h(e,Da,c),w(ce,e,c),h(e,ja,c),h(e,Ae,c),t(Ae,ns),h(e,Sa,c),h(e,G,c),t(G,pt),t(pt,_t),t(_t,fs),t(G,cs),t(G,ut),t(ut,mt),t(mt,hs),h(e,Ca,c),h(e,Me,c),t(Me,ds),h(e,Oa,c),h(e,M,c),t(M,gt),t(gt,vt),t(vt,ps),t(M,_s),t(M,bt),t(bt,Et),t(Et,us),t(M,ms),t(M,yt),t(yt,wt),t(wt,gs),t(M,vs),t(M,$t),t($t,bs),h(e,Na,c),h(e,x,c),t(x,Es),t(x,kt),t(kt,ys),t(x,ws),t(x,It),t(It,$s),t(x,ks),t(x,Lt),t(Lt,Is),t(x,Ls),h(e,Ha,c),h(e,R,c),t(R,Q),t(Q,Tt),w(he,Tt,null),t(R,Ts),t(R,Ft),t(Ft,Fs),h(e,qa,c),h(e,L,c),t(L,As),t(L,At),t(At,Ms),t(L,xs),t(L,Mt),t(Mt,Ps),t(L,Ds),t(L,xt),t(xt,js),t(L,Ss),t(L,Pt),t(Pt,Cs),t(L,Os),h(e,za,c),w(de,e,c),h(e,Ka,c),h(e,S,c),t(S,Ns),t(S,Dt),t(Dt,Hs),t(S,qs),t(S,jt),t(jt,zs),t(S,Ks),h(e,Ba,c),h(e,J,c),t(J,V),t(V,St),w(pe,St,null),t(J,Bs),t(J,Ct),t(Ct,Us),h(e,Ua,c),h(e,xe,c),t(xe,Rs),h(e,Ra,c),h(e,Pe,c),t(Pe,_e),t(_e,Js),t(_e,Ot),t(Ot,Ws),t(_e,Xs),h(e,Ja,c),h(e,ee,c),t(ee,Ys),t(ee,Nt),t(Nt,Zs),t(ee,Gs),h(e,Wa,c),w(ue,e,c),h(e,Xa,c),h(e,De,c),t(De,Qs),h(e,Ya,c),h(e,b,c),t(b,Ht),t(Ht,Vs),t(b,eo),t(b,qt),t(qt,to),t(b,lo),t(b,zt),t(zt,ao),t(b,io),t(b,Kt),t(Kt,so),t(b,oo),t(b,Bt),t(Bt,ro),t(b,no),t(b,Ut),t(Ut,fo),t(b,co),t(b,Rt),t(Rt,ho),h(e,Za,c),h(e,C,c),t(C,po),t(C,Jt),t(Jt,_o),t(C,uo),t(C,Wt),t(Wt,mo),t(C,go),h(e,Ga,c),h(e,te,c),t(te,vo),t(te,Xt),t(Xt,bo),t(te,Eo),h(e,Qa,c),w(me,e,c),h(e,Va,c),h(e,je,c),t(je,yo),h(e,ei,c),h(e,_,c),t(_,Yt),t(Yt,wo),t(_,$o),t(_,Zt),t(Zt,ko),t(_,Io),t(_,Gt),t(Gt,Lo),t(_,To),t(_,Qt),t(Qt,Fo),t(_,Ao),t(_,Vt),t(Vt,Mo),t(_,xo),t(_,el),t(el,Po),t(_,Do),t(_,tl),t(tl,jo),t(_,So),t(_,ll),t(ll,Co),t(_,Oo),t(_,al),t(al,No),t(_,Ho),t(_,il),t(il,qo),t(_,zo),t(_,sl),t(sl,Ko),t(_,Bo),t(_,ol),t(ol,Uo),t(_,Ro),t(_,rl),t(rl,Jo),t(_,Wo),t(_,nl),t(nl,Xo),t(_,Yo),t(_,fl),t(fl,Zo),t(_,Go),t(_,cl),t(cl,Qo),t(_,Vo),t(_,hl),t(hl,er),t(_,tr),t(_,dl),t(dl,lr),t(_,ar),t(_,pl),t(pl,ir),t(_,sr),t(_,_l),t(_l,or),t(_,rr),t(_,ul),t(ul,nr),t(_,fr),t(_,ml),t(ml,cr),t(_,hr),t(_,gl),t(gl,dr),t(_,pr),t(_,vl),t(vl,_r),t(_,ur),t(_,bl),t(bl,mr),h(e,ti,c),h(e,O,c),t(O,gr),t(O,El),t(El,vr),t(O,br),t(O,yl),t(yl,Er),t(O,yr),h(e,li,c),w(ge,e,c),h(e,ai,c),h(e,Se,c),t(Se,wr),h(e,ii,c),h(e,N,c),t(N,$r),t(N,wl),t(wl,kr),t(N,Ir),t(N,$l),t($l,Lr),t(N,Tr),h(e,si,c),h(e,Ce,c),t(Ce,Oe),h(e,oi,c),h(e,Ne,c),t(Ne,He),h(e,ri,c),h(e,H,c),t(H,Fr),t(H,kl),t(kl,Ar),t(H,Mr),t(H,Il),t(Il,xr),t(H,Pr),h(e,ni,c),w(ve,e,c),h(e,fi,c),h(e,qe,c),t(qe,Dr),h(e,ci,c),h(e,le,c),t(le,jr),t(le,Ll),t(Ll,Sr),t(le,Cr),h(e,hi,c),w(be,e,c),h(e,di,c),h(e,ze,c),t(ze,Or),h(e,pi,c),h(e,W,c),t(W,ae),t(ae,Tl),w(Ee,Tl,null),t(W,Nr),t(W,Fl),t(Fl,Hr),h(e,_i,c),h(e,Ke,c),t(Ke,qr),h(e,ui,c),h(e,Be,c),t(Be,zr),h(e,mi,c),h(e,Ue,c),t(Ue,ye),t(ye,Kr),t(ye,Al),t(Al,Br),t(ye,Ur),h(e,gi,c),h(e,q,c),t(q,Rr),t(q,Ml),t(Ml,Jr),t(q,Wr),t(q,xl),t(xl,Xr),t(q,Yr),h(e,vi,c),w(we,e,c),h(e,bi,c),h(e,Re,c),t(Re,Zr),h(e,Ei,c),h(e,g,c),t(g,Pl),t(Pl,Gr),t(g,Qr),t(g,Dl),t(Dl,Vr),t(g,en),t(g,jl),t(jl,tn),t(g,ln),t(g,Sl),t(Sl,an),t(g,sn),t(g,Cl),t(Cl,on),t(g,rn),t(g,Ol),t(Ol,nn),t(g,fn),t(g,Nl),t(Nl,cn),t(g,hn),t(g,Hl),t(Hl,dn),t(g,pn),t(g,ql),t(ql,_n),t(g,un),t(g,zl),t(zl,mn),h(e,yi,c),h(e,D,c),t(D,Kl),t(Kl,gn),t(D,vn),t(D,Bl),t(Bl,bn),t(D,En),t(D,Ul),t(Ul,yn),t(D,wn),h(e,wi,c),w($e,e,c),h(e,$i,c),h(e,Je,c),t(Je,$n),h(e,ki,c),h(e,d,c),t(d,Rl),t(Rl,kn),t(d,In),t(d,Jl),t(Jl,Ln),t(d,Tn),t(d,Wl),t(Wl,Fn),t(d,An),t(d,Xl),t(Xl,Mn),t(d,xn),t(d,Yl),t(Yl,Pn),t(d,Dn),t(d,Zl),t(Zl,jn),t(d,Sn),t(d,Gl),t(Gl,Cn),t(d,On),t(d,Ql),t(Ql,Nn),t(d,Hn),t(d,Vl),t(Vl,qn),t(d,zn),t(d,ea),t(ea,Kn),t(d,Bn),t(d,ta),t(ta,Un),t(d,Rn),t(d,la),t(la,Jn),t(d,Wn),t(d,aa),t(aa,Xn),t(d,Yn),t(d,ia),t(ia,Zn),t(d,Gn),t(d,sa),t(sa,Qn),t(d,Vn),t(d,oa),t(oa,ef),t(d,tf),t(d,ra),t(ra,lf),t(d,af),t(d,na),t(na,sf),t(d,of),t(d,fa),t(fa,rf),t(d,nf),t(d,ca),t(ca,ff),t(d,cf),t(d,ha),t(ha,hf),t(d,df),t(d,da),t(da,pf),t(d,_f),t(d,pa),t(pa,uf),t(d,mf),t(d,_a),t(_a,gf),t(d,vf),t(d,ua),t(ua,bf),t(d,Ef),t(d,ma),t(ma,yf),t(d,wf),t(d,ga),t(ga,$f),t(d,kf),t(d,va),t(va,If),t(d,Lf),t(d,ba),t(ba,Tf),t(d,Ff),t(d,Ea),t(Ea,Af),t(d,Mf),t(d,ya),t(ya,xf),t(d,Pf),t(d,wa),t(wa,Df),h(e,Ii,c),h(e,z,c),t(z,jf),t(z,$a),t($a,Sf),t(z,Cf),t(z,ka),t(ka,Of),t(z,Nf),h(e,Li,c),h(e,K,c),t(K,Hf),t(K,Ia),t(Ia,qf),t(K,zf),t(K,La),t(La,Kf),t(K,Bf),h(e,Ti,c),w(ke,e,c),h(e,Fi,c),h(e,We,c),t(We,Uf),h(e,Ai,c),h(e,Xe,c),t(Xe,Rf),h(e,Mi,c),w(Ie,e,c),h(e,xi,c),h(e,Ye,c),t(Ye,Jf),h(e,Pi,c),w(Le,e,c),h(e,Di,c),h(e,Ze,c),t(Ze,Wf),h(e,ji,c),h(e,Ge,c),t(Ge,Xf),Si=!0},p:Zd,i(e){Si||($(oe.$$.fragment,e),$(re.$$.fragment,e),$(fe.$$.fragment,e),$(ce.$$.fragment,e),$(he.$$.fragment,e),$(de.$$.fragment,e),$(pe.$$.fragment,e),$(ue.$$.fragment,e),$(me.$$.fragment,e),$(ge.$$.fragment,e),$(ve.$$.fragment,e),$(be.$$.fragment,e),$(Ee.$$.fragment,e),$(we.$$.fragment,e),$($e.$$.fragment,e),$(ke.$$.fragment,e),$(Ie.$$.fragment,e),$(Le.$$.fragment,e),Si=!0)},o(e){k(oe.$$.fragment,e),k(re.$$.fragment,e),k(fe.$$.fragment,e),k(ce.$$.fragment,e),k(he.$$.fragment,e),k(de.$$.fragment,e),k(pe.$$.fragment,e),k(ue.$$.fragment,e),k(me.$$.fragment,e),k(ge.$$.fragment,e),k(ve.$$.fragment,e),k(be.$$.fragment,e),k(Ee.$$.fragment,e),k(we.$$.fragment,e),k($e.$$.fragment,e),k(ke.$$.fragment,e),k(Ie.$$.fragment,e),k(Le.$$.fragment,e),Si=!1},d(e){l(j),e&&l(Fe),e&&l(A),I(oe),e&&l(Fa),e&&l(X),e&&l(Aa),e&&l(U),I(re),e&&l(Ma),e&&l(ne),e&&l(xa),I(fe,e),e&&l(Pa),e&&l(Z),e&&l(Da),I(ce,e),e&&l(ja),e&&l(Ae),e&&l(Sa),e&&l(G),e&&l(Ca),e&&l(Me),e&&l(Oa),e&&l(M),e&&l(Na),e&&l(x),e&&l(Ha),e&&l(R),I(he),e&&l(qa),e&&l(L),e&&l(za),I(de,e),e&&l(Ka),e&&l(S),e&&l(Ba),e&&l(J),I(pe),e&&l(Ua),e&&l(xe),e&&l(Ra),e&&l(Pe),e&&l(Ja),e&&l(ee),e&&l(Wa),I(ue,e),e&&l(Xa),e&&l(De),e&&l(Ya),e&&l(b),e&&l(Za),e&&l(C),e&&l(Ga),e&&l(te),e&&l(Qa),I(me,e),e&&l(Va),e&&l(je),e&&l(ei),e&&l(_),e&&l(ti),e&&l(O),e&&l(li),I(ge,e),e&&l(ai),e&&l(Se),e&&l(ii),e&&l(N),e&&l(si),e&&l(Ce),e&&l(oi),e&&l(Ne),e&&l(ri),e&&l(H),e&&l(ni),I(ve,e),e&&l(fi),e&&l(qe),e&&l(ci),e&&l(le),e&&l(hi),I(be,e),e&&l(di),e&&l(ze),e&&l(pi),e&&l(W),I(Ee),e&&l(_i),e&&l(Ke),e&&l(ui),e&&l(Be),e&&l(mi),e&&l(Ue),e&&l(gi),e&&l(q),e&&l(vi),I(we,e),e&&l(bi),e&&l(Re),e&&l(Ei),e&&l(g),e&&l(yi),e&&l(D),e&&l(wi),I($e,e),e&&l($i),e&&l(Je),e&&l(ki),e&&l(d),e&&l(Ii),e&&l(z),e&&l(Li),e&&l(K),e&&l(Ti),I(ke,e),e&&l(Fi),e&&l(We),e&&l(Ai),e&&l(Xe),e&&l(Mi),I(Ie,e),e&&l(xi),e&&l(Ye),e&&l(Pi),I(Le,e),e&&l(Di),e&&l(Ze),e&&l(ji),e&&l(Ge)}}}const Qd={local:"searching-the-hub-efficiently-with-python",sections:[{local:"the-basics",title:"The Basics"},{local:"search-parameters",title:"Search Parameters"},{local:"searching-for-a-model",title:"Searching for a Model"},{local:"searching-for-a-dataset",title:"Searching for a Dataset"}],title:"Searching the Hub Efficiently with Python"};function Vd(Yi,j,Fe){let{fw:A}=j;return Yi.$$set=P=>{"fw"in P&&Fe(0,A=P.fw)},[A]}class ap extends Jd{constructor(j){super();Wd(this,j,Vd,Gd,Xd,{fw:0})}}export{ap as default,Qd as metadata};
