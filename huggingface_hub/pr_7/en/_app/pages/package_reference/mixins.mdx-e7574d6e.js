import{S as _n,i as fn,s as bn,e as i,k as h,w as b,t as n,M as vn,c as r,d as t,m as g,a as s,x as v,h as a,b as u,F as e,g as m,y,q as w,o as x,B as k}from"../../chunks/vendor-7b1da053.js";import{T as yn}from"../../chunks/Tip-41a95816.js";import{D as P}from"../../chunks/Docstring-f1352b16.js";import{I as Dt}from"../../chunks/IconCopyLink-d24e9a6f.js";function wn(ce){let p;return{c(){p=n("Passing `use_auth_token=True` is required when you want to use a private model.")},l($){p=a($,"Passing `use_auth_token=True` is required when you want to use a private model.")},m($,f){m($,p,f)},d($){$&&t(p)}}}function xn(ce){let p,$,f,M,he,W,ho,ge,go,We,H,C,ue,j,uo,me,mo,je,A,po,pe,_o,fo,Ue,_,U,bo,V,vo,_e,yo,wo,xo,z,B,ko,O,$o,fe,Mo,Eo,be,zo,To,Ho,I,Oo,q,R,Do,G,No,ve,So,Po,Co,F,J,Ao,ye,Io,Ve,Y,Q,Be,D,X,qo,we,Fo,Re,N,K,xe,Z,Ko,ke,Lo,Ge,L,Wo,$e,jo,Uo,Je,ee,oe,Ye,S,te,Vo,ne,Bo,Me,Ro,Go,Qe,E,ae,Jo,Ee,Yo,Qo,l,Xo,ze,Zo,et,Te,ot,tt,He,nt,at,Oe,it,rt,De,st,lt,Ne,dt,ct,Se,ht,gt,Pe,ut,mt,Ce,pt,_t,Ae,ft,bt,Ie,vt,yt,qe,wt,xt,Fe,kt,$t,ie,Mt,Et,Ke,zt,Tt,Le,Ht,Ot,Xe;return W=new Dt({}),j=new Dt({}),U=new P({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/hub_mixin.py#L22"}}),B=new P({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/hub_mixin.py#L70",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under
a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id simply like this: <code>dbmdz/bert-base-german-cased@main</code>
Revision is the specific model version to use. It can be a branch name, a tag name, or a commit id,
since we use a git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state dictionary (resp. with keyword
arguments <code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:"<strong>proxies</strong> (<code>Dict[str, str], *optional*) -- A dictionary of proxy servers to use by protocol or endpoint, e.g., </code>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;,\n&#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}`. The proxies are used on each request.",name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}]}}),I=new yn({props:{$$slots:{default:[wn]},$$scope:{ctx:ce}}}),R=new P({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/hub_mixin.py#L183",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the Hub or a path to a local folder (in
which case the repository will have the name of that local folder). If not specified, will default to
the name given by <code>repo_url</code> and a local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;add config&quot;</code>, <code>&quot;add tokenizer&quot;</code> or
<code>&quot;add model&quot;</code> depending on the type of the class.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you must be a member of this
organization).`,name:"organization"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to
<code>True</code> if <code>repo_url</code> is not specified.`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),J=new P({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/hub_mixin.py#L29",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
specify config (must be dict) in case you want to save it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set it to <code>True</code> in case you want to push your weights to huggingface_hub`,name:"push_to_hub"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
kwargs will be passed to <code>push_to_hub</code>`,name:"kwargs"}]}}),Q=new P({props:{name:"class huggingface_hub.PyTorchModelHubMixin",anchor:"huggingface_hub.PyTorchModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/hub_mixin.py#L287"}}),X=new P({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/keras_mixin.py#L335"}}),Z=new Dt({}),oe=new P({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/keras_mixin.py#L200"}}),te=new P({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/keras_mixin.py#L204",parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The Keras model you&#x2019;d like to push to the hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the Hub or a path to a local folder (in
which case the repository will have the name of that local folder). If not specified, will default to
the name given by <code>repo_url</code> and a local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.push_to_hub_keras.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically hosts
and displays a TensorBoard instance if log files are included in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you must be a member of this
organization).`,name:"organization"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to
<code>True</code>.`,name:"use_auth_token"},{anchor:"huggingface_hub.push_to_hub_keras.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.push_to_hub_keras.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. See the available tasks at <a href="https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts</a>.`,name:"task_name"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to tf.keras.models.save_model().`,name:"model_save_kwargs(dict,"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),ae=new P({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_7/src/huggingface_hub/keras_mixin.py#L146"}}),{c(){p=i("meta"),$=h(),f=i("h1"),M=i("a"),he=i("span"),b(W.$$.fragment),ho=h(),ge=i("span"),go=n("Mixins & serialization methods"),We=h(),H=i("h2"),C=i("a"),ue=i("span"),b(j.$$.fragment),uo=h(),me=i("span"),mo=n("Mixins"),je=h(),A=i("p"),po=n("The "),pe=i("code"),_o=n("huggingface_hub"),fo=n(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Ue=h(),_=i("div"),b(U.$$.fragment),bo=h(),V=i("p"),vo=n(`A Generic Base Model Hub Mixin. Define your own mixin for anything by inheriting from this class
and overwriting _from_pretrained and _save_pretrained to define custom logic for saving/loading
your classes. See `),_e=i("code"),yo=n("huggingface_hub.PyTorchModelHubMixin"),wo=n(" for an example."),xo=h(),z=i("div"),b(B.$$.fragment),ko=h(),O=i("p"),$o=n(`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),fe=i("code"),Mo=n("model.eval()"),Eo=n(` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),be=i("code"),zo=n("model.train()"),To=n("."),Ho=h(),b(I.$$.fragment),Oo=h(),q=i("div"),b(R.$$.fragment),Do=h(),G=i("p"),No=n(`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),ve=i("code"),So=n("repo_path_or_name"),Po=n("."),Co=h(),F=i("div"),b(J.$$.fragment),Ao=h(),ye=i("p"),Io=n("Saving weights in local directory."),Ve=h(),Y=i("div"),b(Q.$$.fragment),Be=h(),D=i("div"),b(X.$$.fragment),qo=h(),we=i("p"),Fo=n("Mixin to provide model hub upload/download capabilities to Keras models."),Re=h(),N=i("h2"),K=i("a"),xe=i("span"),b(Z.$$.fragment),Ko=h(),ke=i("span"),Lo=n("Serialization methods"),Ge=h(),L=i("p"),Wo=n("Alongside mixins, "),$e=i("code"),jo=n("huggingface_hub"),Uo=n(" offers some simple serialization and deserialization methods."),Je=h(),ee=i("div"),b(oe.$$.fragment),Ye=h(),S=i("div"),b(te.$$.fragment),Vo=h(),ne=i("p"),Bo=n(`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),Me=i("code"),Ro=n("repo_path_or_name"),Go=n("."),Qe=h(),E=i("div"),b(ae.$$.fragment),Jo=h(),Ee=i("p"),Yo=n("Saves a Keras model to save_directory in SavedModel format. Use this if you\u2019re using the Functional or Sequential APIs."),Qo=h(),l=i("p"),Xo=n("model ("),ze=i("code"),Zo=n("Keras.Model"),et=n(`):
The Keras model you\u2019d like to save. The model must be compiled and built.
save_directory (`),Te=i("code"),ot=n("str"),tt=n(`):
Specify directory in which you want to save the Keras model.
config (`),He=i("code"),nt=n("dict"),at=n(", "),Oe=i("em"),it=n("optional"),rt=n(`):
Configuration object to be saved alongside the model weights.
include_optimizer(`),De=i("code"),st=n("bool"),lt=n(", "),Ne=i("em"),dt=n("optional"),ct=n(", defaults to "),Se=i("code"),ht=n("False"),gt=n(`):
Whether or not to include optimizer in serialization.
plot_model (`),Pe=i("code"),ut=n("bool"),mt=n(", "),Ce=i("em"),pt=n("optional"),_t=n(", defaults to "),Ae=i("code"),ft=n("True"),bt=n(`):
Setting this to `),Ie=i("code"),vt=n("True"),yt=n(` will plot the model and put it in the model card. Requires graphviz and pydot to be installed.
task_name (`),qe=i("code"),wt=n("str"),xt=n(", "),Fe=i("em"),kt=n("optional"),$t=n(`):
Name of the task the model was trained on. See the available tasks at `),ie=i("a"),Mt=n("https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts"),Et=n(`.
model_save_kwargs(`),Ke=i("code"),zt=n("dict"),Tt=n(", "),Le=i("em"),Ht=n("optional"),Ot=n(`):
model_save_kwargs will be passed to tf.keras.models.save_model().`),this.h()},l(o){const c=vn('[data-svelte="svelte-1phssyn"]',document.head);p=r(c,"META",{name:!0,content:!0}),c.forEach(t),$=g(o),f=r(o,"H1",{class:!0});var re=s(f);M=r(re,"A",{id:!0,class:!0,href:!0});var Nt=s(M);he=r(Nt,"SPAN",{});var St=s(he);v(W.$$.fragment,St),St.forEach(t),Nt.forEach(t),ho=g(re),ge=r(re,"SPAN",{});var Pt=s(ge);go=a(Pt,"Mixins & serialization methods"),Pt.forEach(t),re.forEach(t),We=g(o),H=r(o,"H2",{class:!0});var Ze=s(H);C=r(Ze,"A",{id:!0,class:!0,href:!0});var Ct=s(C);ue=r(Ct,"SPAN",{});var At=s(ue);v(j.$$.fragment,At),At.forEach(t),Ct.forEach(t),uo=g(Ze),me=r(Ze,"SPAN",{});var It=s(me);mo=a(It,"Mixins"),It.forEach(t),Ze.forEach(t),je=g(o),A=r(o,"P",{});var eo=s(A);po=a(eo,"The "),pe=r(eo,"CODE",{});var qt=s(pe);_o=a(qt,"huggingface_hub"),qt.forEach(t),fo=a(eo,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),eo.forEach(t),Ue=g(o),_=r(o,"DIV",{class:!0});var T=s(_);v(U.$$.fragment,T),bo=g(T),V=r(T,"P",{});var oo=s(V);vo=a(oo,`A Generic Base Model Hub Mixin. Define your own mixin for anything by inheriting from this class
and overwriting _from_pretrained and _save_pretrained to define custom logic for saving/loading
your classes. See `),_e=r(oo,"CODE",{});var Ft=s(_e);yo=a(Ft,"huggingface_hub.PyTorchModelHubMixin"),Ft.forEach(t),wo=a(oo," for an example."),oo.forEach(t),xo=g(T),z=r(T,"DIV",{class:!0});var se=s(z);v(B.$$.fragment,se),ko=g(se),O=r(se,"P",{});var le=s(O);$o=a(le,`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),fe=r(le,"CODE",{});var Kt=s(fe);Mo=a(Kt,"model.eval()"),Kt.forEach(t),Eo=a(le,` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),be=r(le,"CODE",{});var Lt=s(be);zo=a(Lt,"model.train()"),Lt.forEach(t),To=a(le,"."),le.forEach(t),Ho=g(se),v(I.$$.fragment,se),se.forEach(t),Oo=g(T),q=r(T,"DIV",{class:!0});var to=s(q);v(R.$$.fragment,to),Do=g(to),G=r(to,"P",{});var no=s(G);No=a(no,`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),ve=r(no,"CODE",{});var Wt=s(ve);So=a(Wt,"repo_path_or_name"),Wt.forEach(t),Po=a(no,"."),no.forEach(t),to.forEach(t),Co=g(T),F=r(T,"DIV",{class:!0});var ao=s(F);v(J.$$.fragment,ao),Ao=g(ao),ye=r(ao,"P",{});var jt=s(ye);Io=a(jt,"Saving weights in local directory."),jt.forEach(t),ao.forEach(t),T.forEach(t),Ve=g(o),Y=r(o,"DIV",{class:!0});var Ut=s(Y);v(Q.$$.fragment,Ut),Ut.forEach(t),Be=g(o),D=r(o,"DIV",{class:!0});var io=s(D);v(X.$$.fragment,io),qo=g(io),we=r(io,"P",{});var Vt=s(we);Fo=a(Vt,"Mixin to provide model hub upload/download capabilities to Keras models."),Vt.forEach(t),io.forEach(t),Re=g(o),N=r(o,"H2",{class:!0});var ro=s(N);K=r(ro,"A",{id:!0,class:!0,href:!0});var Bt=s(K);xe=r(Bt,"SPAN",{});var Rt=s(xe);v(Z.$$.fragment,Rt),Rt.forEach(t),Bt.forEach(t),Ko=g(ro),ke=r(ro,"SPAN",{});var Gt=s(ke);Lo=a(Gt,"Serialization methods"),Gt.forEach(t),ro.forEach(t),Ge=g(o),L=r(o,"P",{});var so=s(L);Wo=a(so,"Alongside mixins, "),$e=r(so,"CODE",{});var Jt=s($e);jo=a(Jt,"huggingface_hub"),Jt.forEach(t),Uo=a(so," offers some simple serialization and deserialization methods."),so.forEach(t),Je=g(o),ee=r(o,"DIV",{class:!0});var Yt=s(ee);v(oe.$$.fragment,Yt),Yt.forEach(t),Ye=g(o),S=r(o,"DIV",{class:!0});var lo=s(S);v(te.$$.fragment,lo),Vo=g(lo),ne=r(lo,"P",{});var co=s(ne);Bo=a(co,`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),Me=r(co,"CODE",{});var Qt=s(Me);Ro=a(Qt,"repo_path_or_name"),Qt.forEach(t),Go=a(co,"."),co.forEach(t),lo.forEach(t),Qe=g(o),E=r(o,"DIV",{class:!0});var de=s(E);v(ae.$$.fragment,de),Jo=g(de),Ee=r(de,"P",{});var Xt=s(Ee);Yo=a(Xt,"Saves a Keras model to save_directory in SavedModel format. Use this if you\u2019re using the Functional or Sequential APIs."),Xt.forEach(t),Qo=g(de),l=r(de,"P",{});var d=s(l);Xo=a(d,"model ("),ze=r(d,"CODE",{});var Zt=s(ze);Zo=a(Zt,"Keras.Model"),Zt.forEach(t),et=a(d,`):
The Keras model you\u2019d like to save. The model must be compiled and built.
save_directory (`),Te=r(d,"CODE",{});var en=s(Te);ot=a(en,"str"),en.forEach(t),tt=a(d,`):
Specify directory in which you want to save the Keras model.
config (`),He=r(d,"CODE",{});var on=s(He);nt=a(on,"dict"),on.forEach(t),at=a(d,", "),Oe=r(d,"EM",{});var tn=s(Oe);it=a(tn,"optional"),tn.forEach(t),rt=a(d,`):
Configuration object to be saved alongside the model weights.
include_optimizer(`),De=r(d,"CODE",{});var nn=s(De);st=a(nn,"bool"),nn.forEach(t),lt=a(d,", "),Ne=r(d,"EM",{});var an=s(Ne);dt=a(an,"optional"),an.forEach(t),ct=a(d,", defaults to "),Se=r(d,"CODE",{});var rn=s(Se);ht=a(rn,"False"),rn.forEach(t),gt=a(d,`):
Whether or not to include optimizer in serialization.
plot_model (`),Pe=r(d,"CODE",{});var sn=s(Pe);ut=a(sn,"bool"),sn.forEach(t),mt=a(d,", "),Ce=r(d,"EM",{});var ln=s(Ce);pt=a(ln,"optional"),ln.forEach(t),_t=a(d,", defaults to "),Ae=r(d,"CODE",{});var dn=s(Ae);ft=a(dn,"True"),dn.forEach(t),bt=a(d,`):
Setting this to `),Ie=r(d,"CODE",{});var cn=s(Ie);vt=a(cn,"True"),cn.forEach(t),yt=a(d,` will plot the model and put it in the model card. Requires graphviz and pydot to be installed.
task_name (`),qe=r(d,"CODE",{});var hn=s(qe);wt=a(hn,"str"),hn.forEach(t),xt=a(d,", "),Fe=r(d,"EM",{});var gn=s(Fe);kt=a(gn,"optional"),gn.forEach(t),$t=a(d,`):
Name of the task the model was trained on. See the available tasks at `),ie=r(d,"A",{href:!0,rel:!0});var un=s(ie);Mt=a(un,"https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts"),un.forEach(t),Et=a(d,`.
model_save_kwargs(`),Ke=r(d,"CODE",{});var mn=s(Ke);zt=a(mn,"dict"),mn.forEach(t),Tt=a(d,", "),Le=r(d,"EM",{});var pn=s(Le);Ht=a(pn,"optional"),pn.forEach(t),Ot=a(d,`):
model_save_kwargs will be passed to tf.keras.models.save_model().`),d.forEach(t),de.forEach(t),this.h()},h(){u(p,"name","hf:doc:metadata"),u(p,"content",JSON.stringify(kn)),u(M,"id","mixins-serialization-methods"),u(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(M,"href","#mixins-serialization-methods"),u(f,"class","relative group"),u(C,"id","huggingface_hub.ModelHubMixin"),u(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(C,"href","#huggingface_hub.ModelHubMixin"),u(H,"class","relative group"),u(z,"class","docstring"),u(q,"class","docstring"),u(F,"class","docstring"),u(_,"class","docstring"),u(Y,"class","docstring"),u(D,"class","docstring"),u(K,"id","huggingface_hub.from_pretrained_keras"),u(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(K,"href","#huggingface_hub.from_pretrained_keras"),u(N,"class","relative group"),u(ee,"class","docstring"),u(S,"class","docstring"),u(ie,"href","https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts"),u(ie,"rel","nofollow"),u(E,"class","docstring")},m(o,c){e(document.head,p),m(o,$,c),m(o,f,c),e(f,M),e(M,he),y(W,he,null),e(f,ho),e(f,ge),e(ge,go),m(o,We,c),m(o,H,c),e(H,C),e(C,ue),y(j,ue,null),e(H,uo),e(H,me),e(me,mo),m(o,je,c),m(o,A,c),e(A,po),e(A,pe),e(pe,_o),e(A,fo),m(o,Ue,c),m(o,_,c),y(U,_,null),e(_,bo),e(_,V),e(V,vo),e(V,_e),e(_e,yo),e(V,wo),e(_,xo),e(_,z),y(B,z,null),e(z,ko),e(z,O),e(O,$o),e(O,fe),e(fe,Mo),e(O,Eo),e(O,be),e(be,zo),e(O,To),e(z,Ho),y(I,z,null),e(_,Oo),e(_,q),y(R,q,null),e(q,Do),e(q,G),e(G,No),e(G,ve),e(ve,So),e(G,Po),e(_,Co),e(_,F),y(J,F,null),e(F,Ao),e(F,ye),e(ye,Io),m(o,Ve,c),m(o,Y,c),y(Q,Y,null),m(o,Be,c),m(o,D,c),y(X,D,null),e(D,qo),e(D,we),e(we,Fo),m(o,Re,c),m(o,N,c),e(N,K),e(K,xe),y(Z,xe,null),e(N,Ko),e(N,ke),e(ke,Lo),m(o,Ge,c),m(o,L,c),e(L,Wo),e(L,$e),e($e,jo),e(L,Uo),m(o,Je,c),m(o,ee,c),y(oe,ee,null),m(o,Ye,c),m(o,S,c),y(te,S,null),e(S,Vo),e(S,ne),e(ne,Bo),e(ne,Me),e(Me,Ro),e(ne,Go),m(o,Qe,c),m(o,E,c),y(ae,E,null),e(E,Jo),e(E,Ee),e(Ee,Yo),e(E,Qo),e(E,l),e(l,Xo),e(l,ze),e(ze,Zo),e(l,et),e(l,Te),e(Te,ot),e(l,tt),e(l,He),e(He,nt),e(l,at),e(l,Oe),e(Oe,it),e(l,rt),e(l,De),e(De,st),e(l,lt),e(l,Ne),e(Ne,dt),e(l,ct),e(l,Se),e(Se,ht),e(l,gt),e(l,Pe),e(Pe,ut),e(l,mt),e(l,Ce),e(Ce,pt),e(l,_t),e(l,Ae),e(Ae,ft),e(l,bt),e(l,Ie),e(Ie,vt),e(l,yt),e(l,qe),e(qe,wt),e(l,xt),e(l,Fe),e(Fe,kt),e(l,$t),e(l,ie),e(ie,Mt),e(l,Et),e(l,Ke),e(Ke,zt),e(l,Tt),e(l,Le),e(Le,Ht),e(l,Ot),Xe=!0},p(o,[c]){const re={};c&2&&(re.$$scope={dirty:c,ctx:o}),I.$set(re)},i(o){Xe||(w(W.$$.fragment,o),w(j.$$.fragment,o),w(U.$$.fragment,o),w(B.$$.fragment,o),w(I.$$.fragment,o),w(R.$$.fragment,o),w(J.$$.fragment,o),w(Q.$$.fragment,o),w(X.$$.fragment,o),w(Z.$$.fragment,o),w(oe.$$.fragment,o),w(te.$$.fragment,o),w(ae.$$.fragment,o),Xe=!0)},o(o){x(W.$$.fragment,o),x(j.$$.fragment,o),x(U.$$.fragment,o),x(B.$$.fragment,o),x(I.$$.fragment,o),x(R.$$.fragment,o),x(J.$$.fragment,o),x(Q.$$.fragment,o),x(X.$$.fragment,o),x(Z.$$.fragment,o),x(oe.$$.fragment,o),x(te.$$.fragment,o),x(ae.$$.fragment,o),Xe=!1},d(o){t(p),o&&t($),o&&t(f),k(W),o&&t(We),o&&t(H),k(j),o&&t(je),o&&t(A),o&&t(Ue),o&&t(_),k(U),k(B),k(I),k(R),k(J),o&&t(Ve),o&&t(Y),k(Q),o&&t(Be),o&&t(D),k(X),o&&t(Re),o&&t(N),k(Z),o&&t(Ge),o&&t(L),o&&t(Je),o&&t(ee),k(oe),o&&t(Ye),o&&t(S),k(te),o&&t(Qe),o&&t(E),k(ae)}}}const kn={local:"mixins-serialization-methods",sections:[{local:"huggingface_hub.ModelHubMixin",title:"Mixins"},{local:"huggingface_hub.from_pretrained_keras",title:"Serialization methods"}],title:"Mixins & serialization methods"};function $n(ce,p,$){let{fw:f}=p;return ce.$$set=M=>{"fw"in M&&$(0,f=M.fw)},[f]}class Hn extends _n{constructor(p){super();fn(this,p,$n,xn,bn,{fw:0})}}export{Hn as default,kn as metadata};
