import{S as _n,i as fn,s as bn,e as i,k as h,w as f,t as n,M as vn,c as r,d as t,m as g,a as s,x as b,h as a,b as u,F as e,g as m,y as v,q as y,o as w,B as x,v as yn}from"../../chunks/vendor-7b1da053.js";import{T as wn}from"../../chunks/Tip-41a95816.js";import{D as P}from"../../chunks/Docstring-f1352b16.js";import{I as Dt}from"../../chunks/IconCopyLink-d24e9a6f.js";function xn(Le){let _;return{c(){_=n("Passing `use_auth_token=True` is required when you want to use a private model.")},l(M){_=a(M,"Passing `use_auth_token=True` is required when you want to use a private model.")},m(M,k){m(M,_,k)},d(M){M&&t(_)}}}function kn(Le){let _,M,k,S,ce,W,ho,he,go,We,T,C,ge,j,uo,ue,mo,je,A,po,me,_o,fo,Ue,p,U,bo,V,vo,pe,yo,wo,xo,E,B,ko,H,$o,_e,Mo,Eo,fe,zo,To,Ho,I,Oo,q,R,Do,G,No,be,Po,So,Co,F,J,Ao,ve,Io,Ve,Y,Q,Be,O,X,qo,ye,Fo,Re,D,K,we,Z,Ko,xe,Lo,Ge,L,Wo,ke,jo,Uo,Je,ee,oe,Ye,N,te,Vo,ne,Bo,$e,Ro,Go,Qe,$,ae,Jo,Me,Yo,Qo,l,Xo,Ee,Zo,et,ze,ot,tt,Te,nt,at,He,it,rt,Oe,st,lt,De,dt,ct,Ne,ht,gt,Pe,ut,mt,Se,pt,_t,Ce,ft,bt,Ae,vt,yt,Ie,wt,xt,qe,kt,$t,ie,Mt,Et,Fe,zt,Tt,Ke,Ht,Ot,Xe;return W=new Dt({}),j=new Dt({}),U=new P({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/hub_mixin.py#L22"}}),B=new P({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/hub_mixin.py#L70",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under
a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id simply like this: <code>dbmdz/bert-base-german-cased@main</code>
Revision is the specific model version to use. It can be a branch name, a tag name, or a commit id,
since we use a git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state dictionary (resp. with keyword
arguments <code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:"<strong>proxies</strong> (<code>Dict[str, str], *optional*) -- A dictionary of proxy servers to use by protocol or endpoint, e.g., </code>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;,\n&#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}`. The proxies are used on each request.",name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}]}}),I=new wn({props:{$$slots:{default:[xn]},$$scope:{ctx:Le}}}),R=new P({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/hub_mixin.py#L183",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the Hub or a path to a local folder (in
which case the repository will have the name of that local folder). If not specified, will default to
the name given by <code>repo_url</code> and a local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;add config&quot;</code>, <code>&quot;add tokenizer&quot;</code> or
<code>&quot;add model&quot;</code> depending on the type of the class.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you must be a member of this
organization).`,name:"organization"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to
<code>True</code> if <code>repo_url</code> is not specified.`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),J=new P({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/hub_mixin.py#L29",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
specify config (must be dict) in case you want to save it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set it to <code>True</code> in case you want to push your weights to huggingface_hub`,name:"push_to_hub"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
kwargs will be passed to <code>push_to_hub</code>`,name:"kwargs"}]}}),Q=new P({props:{name:"class huggingface_hub.PyTorchModelHubMixin",anchor:"huggingface_hub.PyTorchModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/hub_mixin.py#L287"}}),X=new P({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/keras_mixin.py#L335"}}),Z=new Dt({}),oe=new P({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/keras_mixin.py#L200"}}),te=new P({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/keras_mixin.py#L204",parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The Keras model you&#x2019;d like to push to the hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the Hub or a path to a local folder (in
which case the repository will have the name of that local folder). If not specified, will default to
the name given by <code>repo_url</code> and a local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.push_to_hub_keras.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically hosts
and displays a TensorBoard instance if log files are included in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you must be a member of this
organization).`,name:"organization"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to
<code>True</code>.`,name:"use_auth_token"},{anchor:"huggingface_hub.push_to_hub_keras.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.push_to_hub_keras.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. See the available tasks at <a href="https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts</a>.`,name:"task_name"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to tf.keras.models.save_model().`,name:"model_save_kwargs(dict,"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),ae=new P({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_782/src/huggingface_hub/keras_mixin.py#L146"}}),{c(){_=i("meta"),M=h(),k=i("h1"),S=i("a"),ce=i("span"),f(W.$$.fragment),ho=h(),he=i("span"),go=n("Mixins & serialization methods"),We=h(),T=i("h2"),C=i("a"),ge=i("span"),f(j.$$.fragment),uo=h(),ue=i("span"),mo=n("Mixins"),je=h(),A=i("p"),po=n("The "),me=i("code"),_o=n("huggingface_hub"),fo=n(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Ue=h(),p=i("div"),f(U.$$.fragment),bo=h(),V=i("p"),vo=n(`A Generic Base Model Hub Mixin. Define your own mixin for anything by inheriting from this class
and overwriting _from_pretrained and _save_pretrained to define custom logic for saving/loading
your classes. See `),pe=i("code"),yo=n("huggingface_hub.PyTorchModelHubMixin"),wo=n(" for an example."),xo=h(),E=i("div"),f(B.$$.fragment),ko=h(),H=i("p"),$o=n(`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),_e=i("code"),Mo=n("model.eval()"),Eo=n(` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),fe=i("code"),zo=n("model.train()"),To=n("."),Ho=h(),f(I.$$.fragment),Oo=h(),q=i("div"),f(R.$$.fragment),Do=h(),G=i("p"),No=n(`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),be=i("code"),Po=n("repo_path_or_name"),So=n("."),Co=h(),F=i("div"),f(J.$$.fragment),Ao=h(),ve=i("p"),Io=n("Saving weights in local directory."),Ve=h(),Y=i("div"),f(Q.$$.fragment),Be=h(),O=i("div"),f(X.$$.fragment),qo=h(),ye=i("p"),Fo=n("Mixin to provide model hub upload/download capabilities to Keras models."),Re=h(),D=i("h2"),K=i("a"),we=i("span"),f(Z.$$.fragment),Ko=h(),xe=i("span"),Lo=n("Serialization methods"),Ge=h(),L=i("p"),Wo=n("Alongside mixins, "),ke=i("code"),jo=n("huggingface_hub"),Uo=n(" offers some simple serialization and deserialization methods."),Je=h(),ee=i("div"),f(oe.$$.fragment),Ye=h(),N=i("div"),f(te.$$.fragment),Vo=h(),ne=i("p"),Bo=n(`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),$e=i("code"),Ro=n("repo_path_or_name"),Go=n("."),Qe=h(),$=i("div"),f(ae.$$.fragment),Jo=h(),Me=i("p"),Yo=n("Saves a Keras model to save_directory in SavedModel format. Use this if you\u2019re using the Functional or Sequential APIs."),Qo=h(),l=i("p"),Xo=n("model ("),Ee=i("code"),Zo=n("Keras.Model"),et=n(`):
The Keras model you\u2019d like to save. The model must be compiled and built.
save_directory (`),ze=i("code"),ot=n("str"),tt=n(`):
Specify directory in which you want to save the Keras model.
config (`),Te=i("code"),nt=n("dict"),at=n(", "),He=i("em"),it=n("optional"),rt=n(`):
Configuration object to be saved alongside the model weights.
include_optimizer(`),Oe=i("code"),st=n("bool"),lt=n(", "),De=i("em"),dt=n("optional"),ct=n(", defaults to "),Ne=i("code"),ht=n("False"),gt=n(`):
Whether or not to include optimizer in serialization.
plot_model (`),Pe=i("code"),ut=n("bool"),mt=n(", "),Se=i("em"),pt=n("optional"),_t=n(", defaults to "),Ce=i("code"),ft=n("True"),bt=n(`):
Setting this to `),Ae=i("code"),vt=n("True"),yt=n(` will plot the model and put it in the model card. Requires graphviz and pydot to be installed.
task_name (`),Ie=i("code"),wt=n("str"),xt=n(", "),qe=i("em"),kt=n("optional"),$t=n(`):
Name of the task the model was trained on. See the available tasks at `),ie=i("a"),Mt=n("https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts"),Et=n(`.
model_save_kwargs(`),Fe=i("code"),zt=n("dict"),Tt=n(", "),Ke=i("em"),Ht=n("optional"),Ot=n(`):
model_save_kwargs will be passed to tf.keras.models.save_model().`),this.h()},l(o){const c=vn('[data-svelte="svelte-1phssyn"]',document.head);_=r(c,"META",{name:!0,content:!0}),c.forEach(t),M=g(o),k=r(o,"H1",{class:!0});var re=s(k);S=r(re,"A",{id:!0,class:!0,href:!0});var Nt=s(S);ce=r(Nt,"SPAN",{});var Pt=s(ce);b(W.$$.fragment,Pt),Pt.forEach(t),Nt.forEach(t),ho=g(re),he=r(re,"SPAN",{});var St=s(he);go=a(St,"Mixins & serialization methods"),St.forEach(t),re.forEach(t),We=g(o),T=r(o,"H2",{class:!0});var Ze=s(T);C=r(Ze,"A",{id:!0,class:!0,href:!0});var Ct=s(C);ge=r(Ct,"SPAN",{});var At=s(ge);b(j.$$.fragment,At),At.forEach(t),Ct.forEach(t),uo=g(Ze),ue=r(Ze,"SPAN",{});var It=s(ue);mo=a(It,"Mixins"),It.forEach(t),Ze.forEach(t),je=g(o),A=r(o,"P",{});var eo=s(A);po=a(eo,"The "),me=r(eo,"CODE",{});var qt=s(me);_o=a(qt,"huggingface_hub"),qt.forEach(t),fo=a(eo,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),eo.forEach(t),Ue=g(o),p=r(o,"DIV",{class:!0});var z=s(p);b(U.$$.fragment,z),bo=g(z),V=r(z,"P",{});var oo=s(V);vo=a(oo,`A Generic Base Model Hub Mixin. Define your own mixin for anything by inheriting from this class
and overwriting _from_pretrained and _save_pretrained to define custom logic for saving/loading
your classes. See `),pe=r(oo,"CODE",{});var Ft=s(pe);yo=a(Ft,"huggingface_hub.PyTorchModelHubMixin"),Ft.forEach(t),wo=a(oo," for an example."),oo.forEach(t),xo=g(z),E=r(z,"DIV",{class:!0});var se=s(E);b(B.$$.fragment,se),ko=g(se),H=r(se,"P",{});var le=s(H);$o=a(le,`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),_e=r(le,"CODE",{});var Kt=s(_e);Mo=a(Kt,"model.eval()"),Kt.forEach(t),Eo=a(le,` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),fe=r(le,"CODE",{});var Lt=s(fe);zo=a(Lt,"model.train()"),Lt.forEach(t),To=a(le,"."),le.forEach(t),Ho=g(se),b(I.$$.fragment,se),se.forEach(t),Oo=g(z),q=r(z,"DIV",{class:!0});var to=s(q);b(R.$$.fragment,to),Do=g(to),G=r(to,"P",{});var no=s(G);No=a(no,`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),be=r(no,"CODE",{});var Wt=s(be);Po=a(Wt,"repo_path_or_name"),Wt.forEach(t),So=a(no,"."),no.forEach(t),to.forEach(t),Co=g(z),F=r(z,"DIV",{class:!0});var ao=s(F);b(J.$$.fragment,ao),Ao=g(ao),ve=r(ao,"P",{});var jt=s(ve);Io=a(jt,"Saving weights in local directory."),jt.forEach(t),ao.forEach(t),z.forEach(t),Ve=g(o),Y=r(o,"DIV",{class:!0});var Ut=s(Y);b(Q.$$.fragment,Ut),Ut.forEach(t),Be=g(o),O=r(o,"DIV",{class:!0});var io=s(O);b(X.$$.fragment,io),qo=g(io),ye=r(io,"P",{});var Vt=s(ye);Fo=a(Vt,"Mixin to provide model hub upload/download capabilities to Keras models."),Vt.forEach(t),io.forEach(t),Re=g(o),D=r(o,"H2",{class:!0});var ro=s(D);K=r(ro,"A",{id:!0,class:!0,href:!0});var Bt=s(K);we=r(Bt,"SPAN",{});var Rt=s(we);b(Z.$$.fragment,Rt),Rt.forEach(t),Bt.forEach(t),Ko=g(ro),xe=r(ro,"SPAN",{});var Gt=s(xe);Lo=a(Gt,"Serialization methods"),Gt.forEach(t),ro.forEach(t),Ge=g(o),L=r(o,"P",{});var so=s(L);Wo=a(so,"Alongside mixins, "),ke=r(so,"CODE",{});var Jt=s(ke);jo=a(Jt,"huggingface_hub"),Jt.forEach(t),Uo=a(so," offers some simple serialization and deserialization methods."),so.forEach(t),Je=g(o),ee=r(o,"DIV",{class:!0});var Yt=s(ee);b(oe.$$.fragment,Yt),Yt.forEach(t),Ye=g(o),N=r(o,"DIV",{class:!0});var lo=s(N);b(te.$$.fragment,lo),Vo=g(lo),ne=r(lo,"P",{});var co=s(ne);Bo=a(co,`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),$e=r(co,"CODE",{});var Qt=s($e);Ro=a(Qt,"repo_path_or_name"),Qt.forEach(t),Go=a(co,"."),co.forEach(t),lo.forEach(t),Qe=g(o),$=r(o,"DIV",{class:!0});var de=s($);b(ae.$$.fragment,de),Jo=g(de),Me=r(de,"P",{});var Xt=s(Me);Yo=a(Xt,"Saves a Keras model to save_directory in SavedModel format. Use this if you\u2019re using the Functional or Sequential APIs."),Xt.forEach(t),Qo=g(de),l=r(de,"P",{});var d=s(l);Xo=a(d,"model ("),Ee=r(d,"CODE",{});var Zt=s(Ee);Zo=a(Zt,"Keras.Model"),Zt.forEach(t),et=a(d,`):
The Keras model you\u2019d like to save. The model must be compiled and built.
save_directory (`),ze=r(d,"CODE",{});var en=s(ze);ot=a(en,"str"),en.forEach(t),tt=a(d,`):
Specify directory in which you want to save the Keras model.
config (`),Te=r(d,"CODE",{});var on=s(Te);nt=a(on,"dict"),on.forEach(t),at=a(d,", "),He=r(d,"EM",{});var tn=s(He);it=a(tn,"optional"),tn.forEach(t),rt=a(d,`):
Configuration object to be saved alongside the model weights.
include_optimizer(`),Oe=r(d,"CODE",{});var nn=s(Oe);st=a(nn,"bool"),nn.forEach(t),lt=a(d,", "),De=r(d,"EM",{});var an=s(De);dt=a(an,"optional"),an.forEach(t),ct=a(d,", defaults to "),Ne=r(d,"CODE",{});var rn=s(Ne);ht=a(rn,"False"),rn.forEach(t),gt=a(d,`):
Whether or not to include optimizer in serialization.
plot_model (`),Pe=r(d,"CODE",{});var sn=s(Pe);ut=a(sn,"bool"),sn.forEach(t),mt=a(d,", "),Se=r(d,"EM",{});var ln=s(Se);pt=a(ln,"optional"),ln.forEach(t),_t=a(d,", defaults to "),Ce=r(d,"CODE",{});var dn=s(Ce);ft=a(dn,"True"),dn.forEach(t),bt=a(d,`):
Setting this to `),Ae=r(d,"CODE",{});var cn=s(Ae);vt=a(cn,"True"),cn.forEach(t),yt=a(d,` will plot the model and put it in the model card. Requires graphviz and pydot to be installed.
task_name (`),Ie=r(d,"CODE",{});var hn=s(Ie);wt=a(hn,"str"),hn.forEach(t),xt=a(d,", "),qe=r(d,"EM",{});var gn=s(qe);kt=a(gn,"optional"),gn.forEach(t),$t=a(d,`):
Name of the task the model was trained on. See the available tasks at `),ie=r(d,"A",{href:!0,rel:!0});var un=s(ie);Mt=a(un,"https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts"),un.forEach(t),Et=a(d,`.
model_save_kwargs(`),Fe=r(d,"CODE",{});var mn=s(Fe);zt=a(mn,"dict"),mn.forEach(t),Tt=a(d,", "),Ke=r(d,"EM",{});var pn=s(Ke);Ht=a(pn,"optional"),pn.forEach(t),Ot=a(d,`):
model_save_kwargs will be passed to tf.keras.models.save_model().`),d.forEach(t),de.forEach(t),this.h()},h(){u(_,"name","hf:doc:metadata"),u(_,"content",JSON.stringify($n)),u(S,"id","mixins-serialization-methods"),u(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(S,"href","#mixins-serialization-methods"),u(k,"class","relative group"),u(C,"id","huggingface_hub.ModelHubMixin"),u(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(C,"href","#huggingface_hub.ModelHubMixin"),u(T,"class","relative group"),u(E,"class","docstring"),u(q,"class","docstring"),u(F,"class","docstring"),u(p,"class","docstring"),u(Y,"class","docstring"),u(O,"class","docstring"),u(K,"id","huggingface_hub.from_pretrained_keras"),u(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(K,"href","#huggingface_hub.from_pretrained_keras"),u(D,"class","relative group"),u(ee,"class","docstring"),u(N,"class","docstring"),u(ie,"href","https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts"),u(ie,"rel","nofollow"),u($,"class","docstring")},m(o,c){e(document.head,_),m(o,M,c),m(o,k,c),e(k,S),e(S,ce),v(W,ce,null),e(k,ho),e(k,he),e(he,go),m(o,We,c),m(o,T,c),e(T,C),e(C,ge),v(j,ge,null),e(T,uo),e(T,ue),e(ue,mo),m(o,je,c),m(o,A,c),e(A,po),e(A,me),e(me,_o),e(A,fo),m(o,Ue,c),m(o,p,c),v(U,p,null),e(p,bo),e(p,V),e(V,vo),e(V,pe),e(pe,yo),e(V,wo),e(p,xo),e(p,E),v(B,E,null),e(E,ko),e(E,H),e(H,$o),e(H,_e),e(_e,Mo),e(H,Eo),e(H,fe),e(fe,zo),e(H,To),e(E,Ho),v(I,E,null),e(p,Oo),e(p,q),v(R,q,null),e(q,Do),e(q,G),e(G,No),e(G,be),e(be,Po),e(G,So),e(p,Co),e(p,F),v(J,F,null),e(F,Ao),e(F,ve),e(ve,Io),m(o,Ve,c),m(o,Y,c),v(Q,Y,null),m(o,Be,c),m(o,O,c),v(X,O,null),e(O,qo),e(O,ye),e(ye,Fo),m(o,Re,c),m(o,D,c),e(D,K),e(K,we),v(Z,we,null),e(D,Ko),e(D,xe),e(xe,Lo),m(o,Ge,c),m(o,L,c),e(L,Wo),e(L,ke),e(ke,jo),e(L,Uo),m(o,Je,c),m(o,ee,c),v(oe,ee,null),m(o,Ye,c),m(o,N,c),v(te,N,null),e(N,Vo),e(N,ne),e(ne,Bo),e(ne,$e),e($e,Ro),e(ne,Go),m(o,Qe,c),m(o,$,c),v(ae,$,null),e($,Jo),e($,Me),e(Me,Yo),e($,Qo),e($,l),e(l,Xo),e(l,Ee),e(Ee,Zo),e(l,et),e(l,ze),e(ze,ot),e(l,tt),e(l,Te),e(Te,nt),e(l,at),e(l,He),e(He,it),e(l,rt),e(l,Oe),e(Oe,st),e(l,lt),e(l,De),e(De,dt),e(l,ct),e(l,Ne),e(Ne,ht),e(l,gt),e(l,Pe),e(Pe,ut),e(l,mt),e(l,Se),e(Se,pt),e(l,_t),e(l,Ce),e(Ce,ft),e(l,bt),e(l,Ae),e(Ae,vt),e(l,yt),e(l,Ie),e(Ie,wt),e(l,xt),e(l,qe),e(qe,kt),e(l,$t),e(l,ie),e(ie,Mt),e(l,Et),e(l,Fe),e(Fe,zt),e(l,Tt),e(l,Ke),e(Ke,Ht),e(l,Ot),Xe=!0},p(o,[c]){const re={};c&2&&(re.$$scope={dirty:c,ctx:o}),I.$set(re)},i(o){Xe||(y(W.$$.fragment,o),y(j.$$.fragment,o),y(U.$$.fragment,o),y(B.$$.fragment,o),y(I.$$.fragment,o),y(R.$$.fragment,o),y(J.$$.fragment,o),y(Q.$$.fragment,o),y(X.$$.fragment,o),y(Z.$$.fragment,o),y(oe.$$.fragment,o),y(te.$$.fragment,o),y(ae.$$.fragment,o),Xe=!0)},o(o){w(W.$$.fragment,o),w(j.$$.fragment,o),w(U.$$.fragment,o),w(B.$$.fragment,o),w(I.$$.fragment,o),w(R.$$.fragment,o),w(J.$$.fragment,o),w(Q.$$.fragment,o),w(X.$$.fragment,o),w(Z.$$.fragment,o),w(oe.$$.fragment,o),w(te.$$.fragment,o),w(ae.$$.fragment,o),Xe=!1},d(o){t(_),o&&t(M),o&&t(k),x(W),o&&t(We),o&&t(T),x(j),o&&t(je),o&&t(A),o&&t(Ue),o&&t(p),x(U),x(B),x(I),x(R),x(J),o&&t(Ve),o&&t(Y),x(Q),o&&t(Be),o&&t(O),x(X),o&&t(Re),o&&t(D),x(Z),o&&t(Ge),o&&t(L),o&&t(Je),o&&t(ee),x(oe),o&&t(Ye),o&&t(N),x(te),o&&t(Qe),o&&t($),x(ae)}}}const $n={local:"mixins-serialization-methods",sections:[{local:"huggingface_hub.ModelHubMixin",title:"Mixins"},{local:"huggingface_hub.from_pretrained_keras",title:"Serialization methods"}],title:"Mixins & serialization methods"};function Mn(Le){return yn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class On extends _n{constructor(_){super();fn(this,_,Mn,kn,bn,{})}}export{On as default,$n as metadata};
