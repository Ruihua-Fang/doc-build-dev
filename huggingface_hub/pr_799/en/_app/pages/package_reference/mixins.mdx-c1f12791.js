import{S as dt,i as ct,s as lt,e as n,k as c,w as f,t as r,M as ht,c as a,d as t,m as l,a as i,x as b,h as s,b as h,F as o,g,y as v,q as y,o as w,B as k,v as gt}from"../../chunks/vendor-7b1da053.js";import{T as st}from"../../chunks/Tip-41a95816.js";import{D as ne}from"../../chunks/Docstring-f1352b16.js";import{I as Ge}from"../../chunks/IconCopyLink-d24e9a6f.js";function ut(ae){let u;return{c(){u=r("Passing `use_auth_token=True` is required when you want to use a private model.")},l(m){u=s(m,"Passing `use_auth_token=True` is required when you want to use a private model.")},m(m,_){g(m,u,_)},d(m){m&&t(u)}}}function mt(ae){let u;return{c(){u=r("Passing `use_auth_token=True` is required when you want to use a private model.")},l(m){u=s(m,"Passing `use_auth_token=True` is required when you want to use a private model.")},m(m,_){g(m,u,_)},d(m){m&&t(u)}}}function pt(ae){let u,m,_,O,ce,U,Ye,le,Je,Ee,T,S,he,K,Qe,ge,Xe,He,A,Ze,ue,eo,oo,Pe,z,I,me,j,to,pe,no,Ne,p,V,ao,B,io,_e,ro,so,co,$,R,lo,E,ho,fe,go,uo,be,mo,po,_o,q,fo,C,G,bo,Y,vo,ve,yo,wo,ko,F,J,xo,ye,$o,De,H,W,we,Q,Mo,ke,To,Oe,x,X,zo,P,Eo,xe,Ho,Po,$e,No,Do,Oo,L,Se,N,Z,So,ee,Ao,Me,Io,qo,Ae,D,oe,Co,Te,Fo,Ie;return U=new Ge({}),K=new Ge({}),j=new Ge({}),V=new ne({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/pr_799/src/huggingface_hub/hub_mixin.py#L22"}}),R=new ne({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_799/src/huggingface_hub/hub_mixin.py#L70",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under
a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id simply like this: <code>dbmdz/bert-base-german-cased@main</code>
Revision is the specific model version to use. It can be a branch name, a tag name, or a commit id,
since we use a git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state dictionary (resp. with keyword
arguments <code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}]}}),q=new st({props:{$$slots:{default:[ut]},$$scope:{ctx:ae}}}),G=new ne({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_799/src/huggingface_hub/hub_mixin.py#L183",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the Hub or a path to a local folder (in
which case the repository will have the name of that local folder). If not specified, will default to
the name given by <code>repo_url</code> and a local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;add config&quot;</code>, <code>&quot;add tokenizer&quot;</code> or
<code>&quot;add model&quot;</code> depending on the type of the class.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you must be a member of this
organization).`,name:"organization"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to
<code>True</code> if <code>repo_url</code> is not specified.`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),J=new ne({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_799/src/huggingface_hub/hub_mixin.py#L29",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
specify config (must be dict) in case you want to save it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set it to <code>True</code> in case you want to push your weights to huggingface_hub`,name:"push_to_hub"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
kwargs will be passed to <code>push_to_hub</code>`,name:"kwargs"}]}}),Q=new Ge({}),X=new ne({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_799/src/huggingface_hub/keras_mixin.py#L202",parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under
a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id simply like this: <code>dbmdz/bert-base-german-cased@main</code>
Revision is the specific model version to use. It can be a branch name, a tag name, or a commit id,
since we use a git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state dictionary (resp. with keyword
arguments <code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}]}}),L=new st({props:{$$slots:{default:[mt]},$$scope:{ctx:ae}}}),Z=new ne({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_799/src/huggingface_hub/keras_mixin.py#L248",parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The Keras model you&#x2019;d like to push to the hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the Hub or a path to a local folder (in
which case the repository will have the name of that local folder). If not specified, will default to
the name given by <code>repo_url</code> and a local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.push_to_hub_keras.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically hosts
and displays a TensorBoard instance if log files are included in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you must be a member of this
organization).`,name:"organization"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token
generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to
<code>True</code>.`,name:"use_auth_token"},{anchor:"huggingface_hub.push_to_hub_keras.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.push_to_hub_keras.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. See the available tasks at <a href="https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts</a>.`,name:"task_name"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to tf.keras.models.save_model().`,name:"model_save_kwargs(dict,"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),oe=new ne({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_799/src/huggingface_hub/keras_mixin.py#L146",parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The Keras model you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. See the available tasks at <a href="https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts</a>.`,name:"task_name"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to tf.keras.models.save_model().`,name:"model_save_kwargs(dict,"}]}}),{c(){u=n("meta"),m=c(),_=n("h1"),O=n("a"),ce=n("span"),f(U.$$.fragment),Ye=c(),le=n("span"),Je=r("Mixins & serialization methods"),Ee=c(),T=n("h2"),S=n("a"),he=n("span"),f(K.$$.fragment),Qe=c(),ge=n("span"),Xe=r("Mixins"),He=c(),A=n("p"),Ze=r("The "),ue=n("code"),eo=r("huggingface_hub"),oo=r(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Pe=c(),z=n("h3"),I=n("a"),me=n("span"),f(j.$$.fragment),to=c(),pe=n("span"),no=r("PyTorch"),Ne=c(),p=n("div"),f(V.$$.fragment),ao=c(),B=n("p"),io=r(`A Generic Base Model Hub Mixin. Define your own mixin for anything by inheriting from this class
and overwriting _from_pretrained and _save_pretrained to define custom logic for saving/loading
your classes. See `),_e=n("code"),ro=r("huggingface_hub.PyTorchModelHubMixin"),so=r(" for an example."),co=c(),$=n("div"),f(R.$$.fragment),lo=c(),E=n("p"),ho=r(`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),fe=n("code"),go=r("model.eval()"),uo=r(` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),be=n("code"),mo=r("model.train()"),po=r("."),_o=c(),f(q.$$.fragment),fo=c(),C=n("div"),f(G.$$.fragment),bo=c(),Y=n("p"),vo=r(`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),ve=n("code"),yo=r("repo_path_or_name"),wo=r("."),ko=c(),F=n("div"),f(J.$$.fragment),xo=c(),ye=n("p"),$o=r("Saving weights in local directory."),De=c(),H=n("h3"),W=n("a"),we=n("span"),f(Q.$$.fragment),Mo=c(),ke=n("span"),To=r("Keras"),Oe=c(),x=n("div"),f(X.$$.fragment),zo=c(),P=n("p"),Eo=r(`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),xe=n("code"),Ho=r("model.eval()"),Po=r(` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),$e=n("code"),No=r("model.train()"),Do=r("."),Oo=c(),f(L.$$.fragment),Se=c(),N=n("div"),f(Z.$$.fragment),So=c(),ee=n("p"),Ao=r(`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),Me=n("code"),Io=r("repo_path_or_name"),qo=r("."),Ae=c(),D=n("div"),f(oe.$$.fragment),Co=c(),Te=n("p"),Fo=r("Saves a Keras model to save_directory in SavedModel format. Use this if you\u2019re using the Functional or Sequential APIs."),this.h()},l(e){const d=ht('[data-svelte="svelte-1phssyn"]',document.head);u=a(d,"META",{name:!0,content:!0}),d.forEach(t),m=l(e),_=a(e,"H1",{class:!0});var te=i(_);O=a(te,"A",{id:!0,class:!0,href:!0});var ze=i(O);ce=a(ze,"SPAN",{});var Wo=i(ce);b(U.$$.fragment,Wo),Wo.forEach(t),ze.forEach(t),Ye=l(te),le=a(te,"SPAN",{});var Lo=i(le);Je=s(Lo,"Mixins & serialization methods"),Lo.forEach(t),te.forEach(t),Ee=l(e),T=a(e,"H2",{class:!0});var qe=i(T);S=a(qe,"A",{id:!0,class:!0,href:!0});var Uo=i(S);he=a(Uo,"SPAN",{});var Ko=i(he);b(K.$$.fragment,Ko),Ko.forEach(t),Uo.forEach(t),Qe=l(qe),ge=a(qe,"SPAN",{});var jo=i(ge);Xe=s(jo,"Mixins"),jo.forEach(t),qe.forEach(t),He=l(e),A=a(e,"P",{});var Ce=i(A);Ze=s(Ce,"The "),ue=a(Ce,"CODE",{});var Vo=i(ue);eo=s(Vo,"huggingface_hub"),Vo.forEach(t),oo=s(Ce,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Ce.forEach(t),Pe=l(e),z=a(e,"H3",{class:!0});var Fe=i(z);I=a(Fe,"A",{id:!0,class:!0,href:!0});var Bo=i(I);me=a(Bo,"SPAN",{});var Ro=i(me);b(j.$$.fragment,Ro),Ro.forEach(t),Bo.forEach(t),to=l(Fe),pe=a(Fe,"SPAN",{});var Go=i(pe);no=s(Go,"PyTorch"),Go.forEach(t),Fe.forEach(t),Ne=l(e),p=a(e,"DIV",{class:!0});var M=i(p);b(V.$$.fragment,M),ao=l(M),B=a(M,"P",{});var We=i(B);io=s(We,`A Generic Base Model Hub Mixin. Define your own mixin for anything by inheriting from this class
and overwriting _from_pretrained and _save_pretrained to define custom logic for saving/loading
your classes. See `),_e=a(We,"CODE",{});var Yo=i(_e);ro=s(Yo,"huggingface_hub.PyTorchModelHubMixin"),Yo.forEach(t),so=s(We," for an example."),We.forEach(t),co=l(M),$=a(M,"DIV",{class:!0});var ie=i($);b(R.$$.fragment,ie),lo=l(ie),E=a(ie,"P",{});var re=i(E);ho=s(re,`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),fe=a(re,"CODE",{});var Jo=i(fe);go=s(Jo,"model.eval()"),Jo.forEach(t),uo=s(re,` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),be=a(re,"CODE",{});var Qo=i(be);mo=s(Qo,"model.train()"),Qo.forEach(t),po=s(re,"."),re.forEach(t),_o=l(ie),b(q.$$.fragment,ie),ie.forEach(t),fo=l(M),C=a(M,"DIV",{class:!0});var Le=i(C);b(G.$$.fragment,Le),bo=l(Le),Y=a(Le,"P",{});var Ue=i(Y);vo=s(Ue,`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),ve=a(Ue,"CODE",{});var Xo=i(ve);yo=s(Xo,"repo_path_or_name"),Xo.forEach(t),wo=s(Ue,"."),Ue.forEach(t),Le.forEach(t),ko=l(M),F=a(M,"DIV",{class:!0});var Ke=i(F);b(J.$$.fragment,Ke),xo=l(Ke),ye=a(Ke,"P",{});var Zo=i(ye);$o=s(Zo,"Saving weights in local directory."),Zo.forEach(t),Ke.forEach(t),M.forEach(t),De=l(e),H=a(e,"H3",{class:!0});var je=i(H);W=a(je,"A",{id:!0,class:!0,href:!0});var et=i(W);we=a(et,"SPAN",{});var ot=i(we);b(Q.$$.fragment,ot),ot.forEach(t),et.forEach(t),Mo=l(je),ke=a(je,"SPAN",{});var tt=i(ke);To=s(tt,"Keras"),tt.forEach(t),je.forEach(t),Oe=l(e),x=a(e,"DIV",{class:!0});var se=i(x);b(X.$$.fragment,se),zo=l(se),P=a(se,"P",{});var de=i(P);Eo=s(de,`Instantiate a pretrained pytorch model from a pre-trained model configuration from huggingface-hub.
The model is set in evaluation mode by default using `),xe=a(de,"CODE",{});var nt=i(xe);Ho=s(nt,"model.eval()"),nt.forEach(t),Po=s(de,` (Dropout modules are deactivated). To
train the model, you should first set it back in training mode with `),$e=a(de,"CODE",{});var at=i($e);No=s(at,"model.train()"),at.forEach(t),Do=s(de,"."),de.forEach(t),Oo=l(se),b(L.$$.fragment,se),se.forEach(t),Se=l(e),N=a(e,"DIV",{class:!0});var Ve=i(N);b(Z.$$.fragment,Ve),So=l(Ve),ee=a(Ve,"P",{});var Be=i(ee);Ao=s(Be,`Upload model checkpoint or tokenizer files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),Me=a(Be,"CODE",{});var it=i(Me);Io=s(it,"repo_path_or_name"),it.forEach(t),qo=s(Be,"."),Be.forEach(t),Ve.forEach(t),Ae=l(e),D=a(e,"DIV",{class:!0});var Re=i(D);b(oe.$$.fragment,Re),Co=l(Re),Te=a(Re,"P",{});var rt=i(Te);Fo=s(rt,"Saves a Keras model to save_directory in SavedModel format. Use this if you\u2019re using the Functional or Sequential APIs."),rt.forEach(t),Re.forEach(t),this.h()},h(){h(u,"name","hf:doc:metadata"),h(u,"content",JSON.stringify(_t)),h(O,"id","mixins-serialization-methods"),h(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(O,"href","#mixins-serialization-methods"),h(_,"class","relative group"),h(S,"id","mixins"),h(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(S,"href","#mixins"),h(T,"class","relative group"),h(I,"id","huggingface_hub.ModelHubMixin"),h(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(I,"href","#huggingface_hub.ModelHubMixin"),h(z,"class","relative group"),h($,"class","docstring"),h(C,"class","docstring"),h(F,"class","docstring"),h(p,"class","docstring"),h(W,"id","huggingface_hub.from_pretrained_keras"),h(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(W,"href","#huggingface_hub.from_pretrained_keras"),h(H,"class","relative group"),h(x,"class","docstring"),h(N,"class","docstring"),h(D,"class","docstring")},m(e,d){o(document.head,u),g(e,m,d),g(e,_,d),o(_,O),o(O,ce),v(U,ce,null),o(_,Ye),o(_,le),o(le,Je),g(e,Ee,d),g(e,T,d),o(T,S),o(S,he),v(K,he,null),o(T,Qe),o(T,ge),o(ge,Xe),g(e,He,d),g(e,A,d),o(A,Ze),o(A,ue),o(ue,eo),o(A,oo),g(e,Pe,d),g(e,z,d),o(z,I),o(I,me),v(j,me,null),o(z,to),o(z,pe),o(pe,no),g(e,Ne,d),g(e,p,d),v(V,p,null),o(p,ao),o(p,B),o(B,io),o(B,_e),o(_e,ro),o(B,so),o(p,co),o(p,$),v(R,$,null),o($,lo),o($,E),o(E,ho),o(E,fe),o(fe,go),o(E,uo),o(E,be),o(be,mo),o(E,po),o($,_o),v(q,$,null),o(p,fo),o(p,C),v(G,C,null),o(C,bo),o(C,Y),o(Y,vo),o(Y,ve),o(ve,yo),o(Y,wo),o(p,ko),o(p,F),v(J,F,null),o(F,xo),o(F,ye),o(ye,$o),g(e,De,d),g(e,H,d),o(H,W),o(W,we),v(Q,we,null),o(H,Mo),o(H,ke),o(ke,To),g(e,Oe,d),g(e,x,d),v(X,x,null),o(x,zo),o(x,P),o(P,Eo),o(P,xe),o(xe,Ho),o(P,Po),o(P,$e),o($e,No),o(P,Do),o(x,Oo),v(L,x,null),g(e,Se,d),g(e,N,d),v(Z,N,null),o(N,So),o(N,ee),o(ee,Ao),o(ee,Me),o(Me,Io),o(ee,qo),g(e,Ae,d),g(e,D,d),v(oe,D,null),o(D,Co),o(D,Te),o(Te,Fo),Ie=!0},p(e,[d]){const te={};d&2&&(te.$$scope={dirty:d,ctx:e}),q.$set(te);const ze={};d&2&&(ze.$$scope={dirty:d,ctx:e}),L.$set(ze)},i(e){Ie||(y(U.$$.fragment,e),y(K.$$.fragment,e),y(j.$$.fragment,e),y(V.$$.fragment,e),y(R.$$.fragment,e),y(q.$$.fragment,e),y(G.$$.fragment,e),y(J.$$.fragment,e),y(Q.$$.fragment,e),y(X.$$.fragment,e),y(L.$$.fragment,e),y(Z.$$.fragment,e),y(oe.$$.fragment,e),Ie=!0)},o(e){w(U.$$.fragment,e),w(K.$$.fragment,e),w(j.$$.fragment,e),w(V.$$.fragment,e),w(R.$$.fragment,e),w(q.$$.fragment,e),w(G.$$.fragment,e),w(J.$$.fragment,e),w(Q.$$.fragment,e),w(X.$$.fragment,e),w(L.$$.fragment,e),w(Z.$$.fragment,e),w(oe.$$.fragment,e),Ie=!1},d(e){t(u),e&&t(m),e&&t(_),k(U),e&&t(Ee),e&&t(T),k(K),e&&t(He),e&&t(A),e&&t(Pe),e&&t(z),k(j),e&&t(Ne),e&&t(p),k(V),k(R),k(q),k(G),k(J),e&&t(De),e&&t(H),k(Q),e&&t(Oe),e&&t(x),k(X),k(L),e&&t(Se),e&&t(N),k(Z),e&&t(Ae),e&&t(D),k(oe)}}}const _t={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"}],title:"Mixins"}],title:"Mixins & serialization methods"};function ft(ae){return gt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class kt extends dt{constructor(u){super();ct(this,u,ft,pt,lt,{})}}export{kt as default,_t as metadata};
