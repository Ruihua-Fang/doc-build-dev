import{S as Zn,i as ea,s as oa,e as n,k as d,w,t as r,M as ta,c as a,d as t,m as l,a as i,x as k,h as s,b as g,F as e,g as u,y as x,q as $,o as E,B as M,v as na}from"../../chunks/vendor-d3924577.js";import{T as mn}from"../../chunks/Tip-4377bed8.js";import{D as q}from"../../chunks/Docstring-8a91f8bd.js";import{I as po}from"../../chunks/IconCopyLink-f94c3d80.js";function aa(G){let h,H,p,_,v;return{c(){h=n("p"),H=r("Passing "),p=n("code"),_=r("use_auth_token=True"),v=r(` is required when you want to use a
private model.`)},l(m){h=a(m,"P",{});var f=i(h);H=s(f,"Passing "),p=a(f,"CODE",{});var P=i(p);_=s(P,"use_auth_token=True"),P.forEach(t),v=s(f,` is required when you want to use a
private model.`),f.forEach(t)},m(m,f){u(m,h,f),e(h,H),e(h,p),e(p,_),e(h,v)},d(m){m&&t(h)}}}function ia(G){let h,H,p,_,v;return{c(){h=n("p"),H=r("Passing "),p=n("code"),_=r("use_auth_token=True"),v=r(` is required when you want to use a private
model.`)},l(m){h=a(m,"P",{});var f=i(h);H=s(f,"Passing "),p=a(f,"CODE",{});var P=i(p);_=s(P,"use_auth_token=True"),P.forEach(t),v=s(f,` is required when you want to use a private
model.`),f.forEach(t)},m(m,f){u(m,h,f),e(h,H),e(h,p),e(p,_),e(h,v)},d(m){m&&t(h)}}}function ra(G){let h,H,p,_,v,m,f,P,de;return{c(){h=n("p"),H=r("Raises the following error:"),p=d(),_=n("ul"),v=n("li"),m=n("a"),f=n("em"),P=r("ValueError"),de=r(`
if the user is not log on to the Hugging Face Hub.`),this.h()},l(T){h=a(T,"P",{});var z=i(h);H=s(z,"Raises the following error:"),z.forEach(t),p=l(T),_=a(T,"UL",{});var N=i(_);v=a(N,"LI",{});var W=i(v);m=a(W,"A",{href:!0,rel:!0});var L=i(m);f=a(L,"EM",{});var He=i(f);P=s(He,"ValueError"),He.forEach(t),L.forEach(t),de=s(W,`
if the user is not log on to the Hugging Face Hub.`),W.forEach(t),N.forEach(t),this.h()},h(){g(m,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),g(m,"rel","nofollow")},m(T,z){u(T,h,z),e(h,H),u(T,p,z),u(T,_,z),e(_,v),e(v,m),e(m,f),e(f,P),e(v,de)},d(T){T&&t(h),T&&t(p),T&&t(_)}}}function sa(G){let h,H,p,_,v,m,f,P,de,T,z,N,W,L,He,Ne,Ko,_o,J,Uo,Ae,Vo,jo,fo,K,Q,Ie,le,Ro,Se,Bo,bo,O,ce,Yo,A,Go,Le,Jo,Qo,Ce,Xo,Zo,Fe,et,ot,tt,C,he,nt,U,at,qe,it,rt,We,st,dt,lt,X,ct,Z,ge,ht,ue,gt,Ke,ut,mt,pt,ee,me,_t,Ue,ft,vo,V,oe,Ve,pe,bt,je,vt,yo,I,_e,yt,Re,wt,kt,te,wo,j,fe,xt,be,$t,Be,Et,Mt,ko,R,ve,Ht,Ye,Tt,xo,S,ye,zt,Ge,Pt,Ot,we,Te,Je,Dt,Nt,At,ne,Qe,It,St,Xe,Lt,Ct,$o,B,ae,Ze,ke,Ft,eo,qt,Eo,Y,xe,Wt,oo,Kt,Mo,D,$e,Ut,Ee,Vt,to,jt,Rt,Bt,b,Yt,no,Gt,Jt,ao,Qt,Xt,io,Zt,en,ro,on,tn,so,nn,an,lo,rn,sn,co,dn,ln,ho,cn,hn,gn,ie,Ho;return m=new po({}),L=new po({}),le=new po({}),ce=new q({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/hub_mixin.py#L22"}}),he=new q({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/hub_mixin.py#L73",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model
hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level,
like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end
of model_id simply like this:
<code>dbmdz/bert-base-german-cased@main</code> Revision is
the specific model version to use. It can be a
branch name, a tag name, or a commit id, since we
use a git-based system for storing models and
other artifacts on huggingface.co, so <code>revision</code>
can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights
saved using
<code>save_pretrained</code>,
e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration
and state dictionary (resp. with keyword arguments
<code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights
and configuration files, overriding the cached versions
if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will
attempt to resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or
endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are
used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote
files. If <code>True</code>, will use the token generated when
running <code>transformers-cli login</code> (stored in
<code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained
model configuration should be cached if the standard
cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to
download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during
initialization`,name:"model_kwargs"}]}}),X=new mn({props:{$$slots:{default:[aa]},$$scope:{ctx:G}}}),ge=new q({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/hub_mixin.py#L211",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in
the Hub or a path to a local folder (in which case the
repository will have the name of that local folder). If not
specified, will default to the name given by <code>repo_url</code> and a
local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository
in the hub. If unspecified, a new repository will be created in
your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;add config&quot;</code>,
<code>&quot;add tokenizer&quot;</code> or <code>&quot;add model&quot;</code> depending on the type of the
class.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer
(you must be a member of this organization).`,name:"organization"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files.
If <code>True</code>, will use the token generated when running
<code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will
default to <code>True</code> if <code>repo_url</code> is not specified.`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and
pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and
pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),me=new q({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/hub_mixin.py#L30",parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
specify config (must be dict) in case you want to save
it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set it to <code>True</code> in case you want to push your weights
to huggingface_hub`,name:"push_to_hub"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
kwargs will be passed to <code>push_to_hub</code>`,name:"kwargs"}]}}),pe=new po({}),_e=new q({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/keras_mixin.py#L208",parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a
model repo on huggingface.co. Valid model ids can be located
at the root-level, like <code>bert-base-uncased</code>, or namespaced
under a user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id
simply like this: <code>dbmdz/bert-base-german-cased@main</code> Revision
is the specific model version to use. It can be a branch name,
a tag name, or a commit id, since we use a git-based system
for storing models and other artifacts on huggingface.co, so
<code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g.,
<code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state
dictionary (resp. with keyword arguments <code>config</code> and
<code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and
configuration files, overriding the cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to
resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g.,
<code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The
proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model
configuration should be cached if the standard cache should not be
used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download
the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}]}}),te=new mn({props:{$$slots:{default:[ia]},$$scope:{ctx:G}}}),fe=new q({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/keras_mixin.py#L267",parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="%60https://www.tensorflow.org/api_docs/python/tf/keras/Model%60">Keras
model</a>
you&#x2019;d like to push to the Hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the
Hub or a path to a local folder (in which case the repository will
have the name of that local folder). If not specified, will default
to the name given by <code>repo_url</code> and a local directory with that name
will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.push_to_hub_keras.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in
the Hub. If unspecified, a new repository will be created in your
namespace (unless you specify an <code>organization</code>) with <code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically
hosts and displays a TensorBoard instance if log files are included
in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you
must be a member of this organization).`,name:"organization"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to <code>True</code>.`,name:"use_auth_token"},{anchor:"huggingface_hub.push_to_hub_keras.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing
files to the Hub.`,name:"git_user"},{anchor:"huggingface_hub.push_to_hub_keras.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing
files to the Hub.`,name:"git_email"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. Available tasks
<a href="https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">here</a>.`,name:"task_name"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),ve=new q({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"**model_save_kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/keras_mixin.py#L146",parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">Keras
model</a>
you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. Available tasks
<a href="https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">here</a>.`,name:"task_name"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}]}}),ye=new q({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/keras_mixin.py#L408"}}),ke=new po({}),xe=new q({props:{name:"huggingface_hub.from_pretrained_fastai",anchor:"huggingface_hub.from_pretrained_fastai",parameters:[{name:"model_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/fastai_utils.py#L289",parametersDescription:[{anchor:"huggingface_hub.from_pretrained_fastai.model_id",description:`<strong>model_id</strong> (<code>str</code>) &#x2014;
The location where the pickled fastai.Learner is. It can be either of the two:<ul>
<li>Hosted on the Hugging Face Hub. E.g.: &#x2018;espejelomar/fatai-pet-breeds-classification&#x2019;, &#x2018;distilgpt2&#x2019;.
You can add a <code>revision</code> by appending <code>@</code> at the end of <code>model_id</code>. E.g.: <code>dbmdz/bert-base-german-cased@main</code>.
Revision is the specific model version to use. Since we use a git-based system for storing models and other
artifacts on the Hugging Face Hub, it can be a branch name, a tag name, or a commit id.</li>
<li>Hosted locally. <code>model_id</code> would be a directory containing the pickle and a pyproject.toml
indicating the fastai and fastcore versions used to build the <code>fastai.Learner</code>. E.g.: <code>./my_model_directory/</code>.</li>
</ul>`,name:"model_id"},{anchor:"huggingface_hub.from_pretrained_fastai.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Revision at which the repo&#x2019;s files are downloaded. See documentation of <code>snapshot_download</code>.`,name:"revision"}],returnDescription:`
<p>The <code>fastai.Learner</code> model in the <code>model_id</code> repo.</p>
`}}),$e=new q({props:{name:"huggingface_hub.push_to_hub_fastai",anchor:"huggingface_hub.push_to_hub_fastai",parameters:[{name:"learner",val:""},{name:"model_id",val:": str"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"private",val:": typing.Optional[bool] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_678/src/huggingface_hub/fastai_utils.py#L329",parametersDescription:[{anchor:"huggingface_hub.push_to_hub_fastai.learner",description:`<strong>learner</strong> (<em>Learner</em>) &#x2014;
The *fastai.Learner&#x2019; you&#x2019;d like to push to the Hub.`,name:"learner"},{anchor:"huggingface_hub.push_to_hub_fastai.model_id",description:`<strong>model_id</strong> (<em>str</em>) &#x2014;
The name of the repository for your model in the Hub. The user can be your individual account (e.g. &#x2018;espejelomar/sentece-embeddings-BETO&#x2019;) or an organization to which you have write access (e.g. &#x2018;stanfordnlp/stanza-de&#x2019;).`,name:"model_id"},{anchor:"huggingface_hub.push_to_hub_fastai.commit_message",description:"<strong>commit_message</strong> (<em>str`, </em>optional*) &#x2014; Message to commit while pushing. Will default to <code>&quot;add model&quot;</code>.",name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_fastai.private",description:`<strong>private</strong> (<em>bool</em>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private (requires a paying subscription).`,name:"private"},{anchor:"huggingface_hub.push_to_hub_fastai.token",description:`<strong>token</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The Hugging Face account token to use as HTTP bearer authorization for remote files. If <code>None</code>, the token will be asked by a prompt.`,name:"token"},{anchor:"huggingface_hub.push_to_hub_fastai.config",description:`<strong>config</strong> (<em>dict</em>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),ie=new mn({props:{$$slots:{default:[ra]},$$scope:{ctx:G}}}),{c(){h=n("meta"),H=d(),p=n("h1"),_=n("a"),v=n("span"),w(m.$$.fragment),f=d(),P=n("span"),de=r("Mixins & serialization methods"),T=d(),z=n("h2"),N=n("a"),W=n("span"),w(L.$$.fragment),He=d(),Ne=n("span"),Ko=r("Mixins"),_o=d(),J=n("p"),Uo=r("The "),Ae=n("code"),Vo=r("huggingface_hub"),jo=r(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),fo=d(),K=n("h3"),Q=n("a"),Ie=n("span"),w(le.$$.fragment),Ro=d(),Se=n("span"),Bo=r("PyTorch"),bo=d(),O=n("div"),w(ce.$$.fragment),Yo=d(),A=n("p"),Go=r(`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Le=n("code"),Jo=r("_from_pretrained"),Qo=r(` and
`),Ce=n("code"),Xo=r("_save_pretrained"),Zo=r(` to define custom logic for saving/loading your classes.
See `),Fe=n("code"),et=r("huggingface_hub.PyTorchModelHubMixin"),ot=r(" for an example."),tt=d(),C=n("div"),w(he.$$.fragment),nt=d(),U=n("p"),at=r(`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),qe=n("code"),it=r("model.eval()"),rt=r(` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),We=n("code"),st=r("model.train()"),dt=r("."),lt=d(),w(X.$$.fragment),ct=d(),Z=n("div"),w(ge.$$.fragment),ht=d(),ue=n("p"),gt=r(`Upload model checkpoint or tokenizer files to the Hub while
synchronizing a local clone of the repo in `),Ke=n("code"),ut=r("repo_path_or_name"),mt=r("."),pt=d(),ee=n("div"),w(me.$$.fragment),_t=d(),Ue=n("p"),ft=r("Save weights in local directory."),vo=d(),V=n("h3"),oe=n("a"),Ve=n("span"),w(pe.$$.fragment),bt=d(),je=n("span"),vt=r("Keras"),yo=d(),I=n("div"),w(_e.$$.fragment),yt=d(),Re=n("p"),wt=r("Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),kt=d(),w(te.$$.fragment),wo=d(),j=n("div"),w(fe.$$.fragment),xt=d(),be=n("p"),$t=r(`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),Be=n("code"),Et=r("repo_path_or_name"),Mt=r("."),ko=d(),R=n("div"),w(ve.$$.fragment),Ht=d(),Ye=n("p"),Tt=r(`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),xo=d(),S=n("div"),w(ye.$$.fragment),zt=d(),Ge=n("p"),Pt=r(`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Ot=d(),we=n("ul"),Te=n("li"),Je=n("code"),Dt=r("_from_pretrained"),Nt=r(", to load a model from the Hub or from local files."),At=d(),ne=n("li"),Qe=n("code"),It=r("_save_pretrained"),St=r(", to save a model in the "),Xe=n("code"),Lt=r("SavedModel"),Ct=r(" format."),$o=d(),B=n("h3"),ae=n("a"),Ze=n("span"),w(ke.$$.fragment),Ft=d(),eo=n("span"),qt=r("Fastai"),Eo=d(),Y=n("div"),w(xe.$$.fragment),Wt=d(),oo=n("p"),Kt=r("Load pretrained fastai model from the Hub or from a local directory."),Mo=d(),D=n("div"),w($e.$$.fragment),Ut=d(),Ee=n("p"),Vt=r(`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),to=n("code"),jt=r("model_id"),Rt=r("."),Bt=d(),b=n("p"),Yt=r(`Keyword Args:
api_endpoint (`),no=n("em"),Gt=r("str"),Jt=r(", "),ao=n("em"),Qt=r("optional"),Xt=r(`):
The API endpoint to use when pushing the model to the hub.
git_user (`),io=n("em"),Zt=r("str"),en=r(", "),ro=n("em"),on=r("optional"),tn=r(`):
Will override the `),so=n("code"),nn=r("git config user.name"),an=r(` for committing and pushing files to the hub.
git_email (`),lo=n("em"),rn=r("str"),sn=r(", "),co=n("em"),dn=r("optional"),ln=r(`):
Will override the `),ho=n("code"),cn=r("git config user.email"),hn=r(" for committing and pushing files to the hub."),gn=d(),w(ie.$$.fragment),this.h()},l(o){const c=ta('[data-svelte="svelte-1phssyn"]',document.head);h=a(c,"META",{name:!0,content:!0}),c.forEach(t),H=l(o),p=a(o,"H1",{class:!0});var Me=i(p);_=a(Me,"A",{id:!0,class:!0,href:!0});var go=i(_);v=a(go,"SPAN",{});var uo=i(v);k(m.$$.fragment,uo),uo.forEach(t),go.forEach(t),f=l(Me),P=a(Me,"SPAN",{});var pn=i(P);de=s(pn,"Mixins & serialization methods"),pn.forEach(t),Me.forEach(t),T=l(o),z=a(o,"H2",{class:!0});var To=i(z);N=a(To,"A",{id:!0,class:!0,href:!0});var _n=i(N);W=a(_n,"SPAN",{});var fn=i(W);k(L.$$.fragment,fn),fn.forEach(t),_n.forEach(t),He=l(To),Ne=a(To,"SPAN",{});var bn=i(Ne);Ko=s(bn,"Mixins"),bn.forEach(t),To.forEach(t),_o=l(o),J=a(o,"P",{});var zo=i(J);Uo=s(zo,"The "),Ae=a(zo,"CODE",{});var vn=i(Ae);Vo=s(vn,"huggingface_hub"),vn.forEach(t),jo=s(zo,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),zo.forEach(t),fo=l(o),K=a(o,"H3",{class:!0});var Po=i(K);Q=a(Po,"A",{id:!0,class:!0,href:!0});var yn=i(Q);Ie=a(yn,"SPAN",{});var wn=i(Ie);k(le.$$.fragment,wn),wn.forEach(t),yn.forEach(t),Ro=l(Po),Se=a(Po,"SPAN",{});var kn=i(Se);Bo=s(kn,"PyTorch"),kn.forEach(t),Po.forEach(t),bo=l(o),O=a(o,"DIV",{class:!0});var F=i(O);k(ce.$$.fragment,F),Yo=l(F),A=a(F,"P",{});var re=i(A);Go=s(re,`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Le=a(re,"CODE",{});var xn=i(Le);Jo=s(xn,"_from_pretrained"),xn.forEach(t),Qo=s(re,` and
`),Ce=a(re,"CODE",{});var $n=i(Ce);Xo=s($n,"_save_pretrained"),$n.forEach(t),Zo=s(re,` to define custom logic for saving/loading your classes.
See `),Fe=a(re,"CODE",{});var En=i(Fe);et=s(En,"huggingface_hub.PyTorchModelHubMixin"),En.forEach(t),ot=s(re," for an example."),re.forEach(t),tt=l(F),C=a(F,"DIV",{class:!0});var ze=i(C);k(he.$$.fragment,ze),nt=l(ze),U=a(ze,"P",{});var Pe=i(U);at=s(Pe,`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),qe=a(Pe,"CODE",{});var Mn=i(qe);it=s(Mn,"model.eval()"),Mn.forEach(t),rt=s(Pe,` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),We=a(Pe,"CODE",{});var Hn=i(We);st=s(Hn,"model.train()"),Hn.forEach(t),dt=s(Pe,"."),Pe.forEach(t),lt=l(ze),k(X.$$.fragment,ze),ze.forEach(t),ct=l(F),Z=a(F,"DIV",{class:!0});var Oo=i(Z);k(ge.$$.fragment,Oo),ht=l(Oo),ue=a(Oo,"P",{});var Do=i(ue);gt=s(Do,`Upload model checkpoint or tokenizer files to the Hub while
synchronizing a local clone of the repo in `),Ke=a(Do,"CODE",{});var Tn=i(Ke);ut=s(Tn,"repo_path_or_name"),Tn.forEach(t),mt=s(Do,"."),Do.forEach(t),Oo.forEach(t),pt=l(F),ee=a(F,"DIV",{class:!0});var No=i(ee);k(me.$$.fragment,No),_t=l(No),Ue=a(No,"P",{});var zn=i(Ue);ft=s(zn,"Save weights in local directory."),zn.forEach(t),No.forEach(t),F.forEach(t),vo=l(o),V=a(o,"H3",{class:!0});var Ao=i(V);oe=a(Ao,"A",{id:!0,class:!0,href:!0});var Pn=i(oe);Ve=a(Pn,"SPAN",{});var On=i(Ve);k(pe.$$.fragment,On),On.forEach(t),Pn.forEach(t),bt=l(Ao),je=a(Ao,"SPAN",{});var Dn=i(je);vt=s(Dn,"Keras"),Dn.forEach(t),Ao.forEach(t),yo=l(o),I=a(o,"DIV",{class:!0});var Oe=i(I);k(_e.$$.fragment,Oe),yt=l(Oe),Re=a(Oe,"P",{});var Nn=i(Re);wt=s(Nn,"Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),Nn.forEach(t),kt=l(Oe),k(te.$$.fragment,Oe),Oe.forEach(t),wo=l(o),j=a(o,"DIV",{class:!0});var Io=i(j);k(fe.$$.fragment,Io),xt=l(Io),be=a(Io,"P",{});var So=i(be);$t=s(So,`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),Be=a(So,"CODE",{});var An=i(Be);Et=s(An,"repo_path_or_name"),An.forEach(t),Mt=s(So,"."),So.forEach(t),Io.forEach(t),ko=l(o),R=a(o,"DIV",{class:!0});var Lo=i(R);k(ve.$$.fragment,Lo),Ht=l(Lo),Ye=a(Lo,"P",{});var In=i(Ye);Tt=s(In,`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),In.forEach(t),Lo.forEach(t),xo=l(o),S=a(o,"DIV",{class:!0});var De=i(S);k(ye.$$.fragment,De),zt=l(De),Ge=a(De,"P",{});var Sn=i(Ge);Pt=s(Sn,`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Sn.forEach(t),Ot=l(De),we=a(De,"UL",{});var Co=i(we);Te=a(Co,"LI",{});var un=i(Te);Je=a(un,"CODE",{});var Ln=i(Je);Dt=s(Ln,"_from_pretrained"),Ln.forEach(t),Nt=s(un,", to load a model from the Hub or from local files."),un.forEach(t),At=l(Co),ne=a(Co,"LI",{});var mo=i(ne);Qe=a(mo,"CODE",{});var Cn=i(Qe);It=s(Cn,"_save_pretrained"),Cn.forEach(t),St=s(mo,", to save a model in the "),Xe=a(mo,"CODE",{});var Fn=i(Xe);Lt=s(Fn,"SavedModel"),Fn.forEach(t),Ct=s(mo," format."),mo.forEach(t),Co.forEach(t),De.forEach(t),$o=l(o),B=a(o,"H3",{class:!0});var Fo=i(B);ae=a(Fo,"A",{id:!0,class:!0,href:!0});var qn=i(ae);Ze=a(qn,"SPAN",{});var Wn=i(Ze);k(ke.$$.fragment,Wn),Wn.forEach(t),qn.forEach(t),Ft=l(Fo),eo=a(Fo,"SPAN",{});var Kn=i(eo);qt=s(Kn,"Fastai"),Kn.forEach(t),Fo.forEach(t),Eo=l(o),Y=a(o,"DIV",{class:!0});var qo=i(Y);k(xe.$$.fragment,qo),Wt=l(qo),oo=a(qo,"P",{});var Un=i(oo);Kt=s(Un,"Load pretrained fastai model from the Hub or from a local directory."),Un.forEach(t),qo.forEach(t),Mo=l(o),D=a(o,"DIV",{class:!0});var se=i(D);k($e.$$.fragment,se),Ut=l(se),Ee=a(se,"P",{});var Wo=i(Ee);Vt=s(Wo,`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),to=a(Wo,"CODE",{});var Vn=i(to);jt=s(Vn,"model_id"),Vn.forEach(t),Rt=s(Wo,"."),Wo.forEach(t),Bt=l(se),b=a(se,"P",{});var y=i(b);Yt=s(y,`Keyword Args:
api_endpoint (`),no=a(y,"EM",{});var jn=i(no);Gt=s(jn,"str"),jn.forEach(t),Jt=s(y,", "),ao=a(y,"EM",{});var Rn=i(ao);Qt=s(Rn,"optional"),Rn.forEach(t),Xt=s(y,`):
The API endpoint to use when pushing the model to the hub.
git_user (`),io=a(y,"EM",{});var Bn=i(io);Zt=s(Bn,"str"),Bn.forEach(t),en=s(y,", "),ro=a(y,"EM",{});var Yn=i(ro);on=s(Yn,"optional"),Yn.forEach(t),tn=s(y,`):
Will override the `),so=a(y,"CODE",{});var Gn=i(so);nn=s(Gn,"git config user.name"),Gn.forEach(t),an=s(y,` for committing and pushing files to the hub.
git_email (`),lo=a(y,"EM",{});var Jn=i(lo);rn=s(Jn,"str"),Jn.forEach(t),sn=s(y,", "),co=a(y,"EM",{});var Qn=i(co);dn=s(Qn,"optional"),Qn.forEach(t),ln=s(y,`):
Will override the `),ho=a(y,"CODE",{});var Xn=i(ho);cn=s(Xn,"git config user.email"),Xn.forEach(t),hn=s(y," for committing and pushing files to the hub."),y.forEach(t),gn=l(se),k(ie.$$.fragment,se),se.forEach(t),this.h()},h(){g(h,"name","hf:doc:metadata"),g(h,"content",JSON.stringify(da)),g(_,"id","mixins-serialization-methods"),g(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(_,"href","#mixins-serialization-methods"),g(p,"class","relative group"),g(N,"id","mixins"),g(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(N,"href","#mixins"),g(z,"class","relative group"),g(Q,"id","huggingface_hub.ModelHubMixin"),g(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(Q,"href","#huggingface_hub.ModelHubMixin"),g(K,"class","relative group"),g(C,"class","docstring"),g(Z,"class","docstring"),g(ee,"class","docstring"),g(O,"class","docstring"),g(oe,"id","huggingface_hub.from_pretrained_keras"),g(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(oe,"href","#huggingface_hub.from_pretrained_keras"),g(V,"class","relative group"),g(I,"class","docstring"),g(j,"class","docstring"),g(R,"class","docstring"),g(S,"class","docstring"),g(ae,"id","huggingface_hub.from_pretrained_fastai"),g(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(ae,"href","#huggingface_hub.from_pretrained_fastai"),g(B,"class","relative group"),g(Y,"class","docstring"),g(D,"class","docstring")},m(o,c){e(document.head,h),u(o,H,c),u(o,p,c),e(p,_),e(_,v),x(m,v,null),e(p,f),e(p,P),e(P,de),u(o,T,c),u(o,z,c),e(z,N),e(N,W),x(L,W,null),e(z,He),e(z,Ne),e(Ne,Ko),u(o,_o,c),u(o,J,c),e(J,Uo),e(J,Ae),e(Ae,Vo),e(J,jo),u(o,fo,c),u(o,K,c),e(K,Q),e(Q,Ie),x(le,Ie,null),e(K,Ro),e(K,Se),e(Se,Bo),u(o,bo,c),u(o,O,c),x(ce,O,null),e(O,Yo),e(O,A),e(A,Go),e(A,Le),e(Le,Jo),e(A,Qo),e(A,Ce),e(Ce,Xo),e(A,Zo),e(A,Fe),e(Fe,et),e(A,ot),e(O,tt),e(O,C),x(he,C,null),e(C,nt),e(C,U),e(U,at),e(U,qe),e(qe,it),e(U,rt),e(U,We),e(We,st),e(U,dt),e(C,lt),x(X,C,null),e(O,ct),e(O,Z),x(ge,Z,null),e(Z,ht),e(Z,ue),e(ue,gt),e(ue,Ke),e(Ke,ut),e(ue,mt),e(O,pt),e(O,ee),x(me,ee,null),e(ee,_t),e(ee,Ue),e(Ue,ft),u(o,vo,c),u(o,V,c),e(V,oe),e(oe,Ve),x(pe,Ve,null),e(V,bt),e(V,je),e(je,vt),u(o,yo,c),u(o,I,c),x(_e,I,null),e(I,yt),e(I,Re),e(Re,wt),e(I,kt),x(te,I,null),u(o,wo,c),u(o,j,c),x(fe,j,null),e(j,xt),e(j,be),e(be,$t),e(be,Be),e(Be,Et),e(be,Mt),u(o,ko,c),u(o,R,c),x(ve,R,null),e(R,Ht),e(R,Ye),e(Ye,Tt),u(o,xo,c),u(o,S,c),x(ye,S,null),e(S,zt),e(S,Ge),e(Ge,Pt),e(S,Ot),e(S,we),e(we,Te),e(Te,Je),e(Je,Dt),e(Te,Nt),e(we,At),e(we,ne),e(ne,Qe),e(Qe,It),e(ne,St),e(ne,Xe),e(Xe,Lt),e(ne,Ct),u(o,$o,c),u(o,B,c),e(B,ae),e(ae,Ze),x(ke,Ze,null),e(B,Ft),e(B,eo),e(eo,qt),u(o,Eo,c),u(o,Y,c),x(xe,Y,null),e(Y,Wt),e(Y,oo),e(oo,Kt),u(o,Mo,c),u(o,D,c),x($e,D,null),e(D,Ut),e(D,Ee),e(Ee,Vt),e(Ee,to),e(to,jt),e(Ee,Rt),e(D,Bt),e(D,b),e(b,Yt),e(b,no),e(no,Gt),e(b,Jt),e(b,ao),e(ao,Qt),e(b,Xt),e(b,io),e(io,Zt),e(b,en),e(b,ro),e(ro,on),e(b,tn),e(b,so),e(so,nn),e(b,an),e(b,lo),e(lo,rn),e(b,sn),e(b,co),e(co,dn),e(b,ln),e(b,ho),e(ho,cn),e(b,hn),e(D,gn),x(ie,D,null),Ho=!0},p(o,[c]){const Me={};c&2&&(Me.$$scope={dirty:c,ctx:o}),X.$set(Me);const go={};c&2&&(go.$$scope={dirty:c,ctx:o}),te.$set(go);const uo={};c&2&&(uo.$$scope={dirty:c,ctx:o}),ie.$set(uo)},i(o){Ho||($(m.$$.fragment,o),$(L.$$.fragment,o),$(le.$$.fragment,o),$(ce.$$.fragment,o),$(he.$$.fragment,o),$(X.$$.fragment,o),$(ge.$$.fragment,o),$(me.$$.fragment,o),$(pe.$$.fragment,o),$(_e.$$.fragment,o),$(te.$$.fragment,o),$(fe.$$.fragment,o),$(ve.$$.fragment,o),$(ye.$$.fragment,o),$(ke.$$.fragment,o),$(xe.$$.fragment,o),$($e.$$.fragment,o),$(ie.$$.fragment,o),Ho=!0)},o(o){E(m.$$.fragment,o),E(L.$$.fragment,o),E(le.$$.fragment,o),E(ce.$$.fragment,o),E(he.$$.fragment,o),E(X.$$.fragment,o),E(ge.$$.fragment,o),E(me.$$.fragment,o),E(pe.$$.fragment,o),E(_e.$$.fragment,o),E(te.$$.fragment,o),E(fe.$$.fragment,o),E(ve.$$.fragment,o),E(ye.$$.fragment,o),E(ke.$$.fragment,o),E(xe.$$.fragment,o),E($e.$$.fragment,o),E(ie.$$.fragment,o),Ho=!1},d(o){t(h),o&&t(H),o&&t(p),M(m),o&&t(T),o&&t(z),M(L),o&&t(_o),o&&t(J),o&&t(fo),o&&t(K),M(le),o&&t(bo),o&&t(O),M(ce),M(he),M(X),M(ge),M(me),o&&t(vo),o&&t(V),M(pe),o&&t(yo),o&&t(I),M(_e),M(te),o&&t(wo),o&&t(j),M(fe),o&&t(ko),o&&t(R),M(ve),o&&t(xo),o&&t(S),M(ye),o&&t($o),o&&t(B),M(ke),o&&t(Eo),o&&t(Y),M(xe),o&&t(Mo),o&&t(D),M($e),M(ie)}}}const da={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"},{local:"huggingface_hub.from_pretrained_fastai",title:"Fastai"}],title:"Mixins"}],title:"Mixins & serialization methods"};function la(G){return na(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ma extends Zn{constructor(h){super();ea(this,h,la,sa,oa,{})}}export{ma as default,da as metadata};
