import{S as cs,i as ps,s as fs,e as r,k as f,w as M,t as a,M as hs,c as o,d as s,m as h,a as l,x as Y,h as n,b as p,N as us,F as t,g as c,y as L,L as ms,q as R,o as z,B as G,v as ds}from"../chunks/vendor-d3924577.js";import{I as is}from"../chunks/IconCopyLink-f94c3d80.js";import{C as ge}from"../chunks/CodeBlock-ff545b14.js";function gs(Nt){let b,_e,ye,we,I,k,V,$,Ke,X,Fe,be,v,A,Z,P,Be,ee,Me,Ie,y,Ye,te,Le,Re,se,ze,Ge,ve,W,T,We,O,Je,Ue,ke,J,U,Ht,Ae,m,Qe,ae,Ve,Xe,ne,Ze,et,re,tt,st,Ee,N,xe,d,at,H,nt,rt,S,ot,lt,oe,it,ct,je,C,qe,g,pt,le,ft,ht,ie,ut,mt,ce,dt,gt,$e,D,Pe,_,_t,K,yt,wt,pe,bt,It,fe,vt,kt,Te,F,Oe,u,At,he,Et,xt,ue,jt,qt,me,$t,Pt,de,Tt,Ot,Ne,B,He;return $=new is({}),P=new is({}),N=new ge({props:{code:`from huggingface_hub.inference_api import InferenceApi
inference = InferenceApi(repo_id="bert-base-uncased", token=API_TOKEN)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub.inference_api <span class="hljs-keyword">import</span> InferenceApi
<span class="hljs-meta">&gt;&gt;&gt; </span>inference = InferenceApi(repo_id=<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, token=API_TOKEN)`}}),C=new ge({props:{code:`from huggingface_hub.inference_api import InferenceApi
inference = InferenceApi(repo_id="bert-base-uncased", token=API_TOKEN)
inference(inputs="The goal of life is [MASK].")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub.inference_api <span class="hljs-keyword">import</span> InferenceApi
<span class="hljs-meta">&gt;&gt;&gt; </span>inference = InferenceApi(repo_id=<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, token=API_TOKEN)
<span class="hljs-meta">&gt;&gt;&gt; </span>inference(inputs=<span class="hljs-string">&quot;The goal of life is [MASK].&quot;</span>)
[{<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;the goal of life is life.&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.10933292657136917</span>, <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">2166</span>, <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27;life&#x27;</span>}]`}}),D=new ge({props:{code:`inference = InferenceApi(repo_id="deepset/roberta-base-squad2", token=API_TOKEN)
inputs = {"question":"Where is Hugging Face headquarters?", "context":"Hugging Face is based in Brooklyn, New York. There is also an office in Paris, France."}
inference(inputs)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>inference = InferenceApi(repo_id=<span class="hljs-string">&quot;deepset/roberta-base-squad2&quot;</span>, token=API_TOKEN)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = {<span class="hljs-string">&quot;question&quot;</span>:<span class="hljs-string">&quot;Where is Hugging Face headquarters?&quot;</span>, <span class="hljs-string">&quot;context&quot;</span>:<span class="hljs-string">&quot;Hugging Face is based in Brooklyn, New York. There is also an office in Paris, France.&quot;</span>}
<span class="hljs-meta">&gt;&gt;&gt; </span>inference(inputs)
{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.94622403383255</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">25</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">43</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;Brooklyn, New York&#x27;</span>}`}}),F=new ge({props:{code:`inference = InferenceApi(repo_id="typeform/distilbert-base-uncased-mnli", token=API_TOKEN)
inputs = "Hi, I recently bought a device from your company but it is not working as advertised and I would like to get reimbursed!"
params = {"candidate_labels":["refund", "legal", "faq"]}
inference(inputs, params)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>inference = InferenceApi(repo_id=<span class="hljs-string">&quot;typeform/distilbert-base-uncased-mnli&quot;</span>, token=API_TOKEN)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = <span class="hljs-string">&quot;Hi, I recently bought a device from your company but it is not working as advertised and I would like to get reimbursed!&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>params = {<span class="hljs-string">&quot;candidate_labels&quot;</span>:[<span class="hljs-string">&quot;refund&quot;</span>, <span class="hljs-string">&quot;legal&quot;</span>, <span class="hljs-string">&quot;faq&quot;</span>]}
<span class="hljs-meta">&gt;&gt;&gt; </span>inference(inputs, params)
{<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;Hi, I recently bought a device from your company but it is not working as advertised and I would like to get reimbursed!&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-string">&#x27;refund&#x27;</span>, <span class="hljs-string">&#x27;faq&#x27;</span>, <span class="hljs-string">&#x27;legal&#x27;</span>], <span class="hljs-string">&#x27;scores&#x27;</span>: [<span class="hljs-number">0.9378499388694763</span>, <span class="hljs-number">0.04914155602455139</span>, <span class="hljs-number">0.013008488342165947</span>]}`}}),B=new ge({props:{code:'inference = InferenceApi(repo_id="paraphrase-xlm-r-multilingual-v1", task="feature-extraction", token=API_TOKEN)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>inference = InferenceApi(repo_id=<span class="hljs-string">&quot;paraphrase-xlm-r-multilingual-v1&quot;</span>, task=<span class="hljs-string">&quot;feature-extraction&quot;</span>, token=API_TOKEN)'}}),{c(){b=r("meta"),_e=f(),ye=r("hr"),we=f(),I=r("h2"),k=r("a"),V=r("span"),M($.$$.fragment),Ke=f(),X=r("span"),Fe=a("title: How to programmatically access the Inference API"),be=f(),v=r("h1"),A=r("a"),Z=r("span"),M(P.$$.fragment),Be=f(),ee=r("span"),Me=a("How to programmatically access the Inference API"),Ie=f(),y=r("p"),Ye=a("The Inference API provides fast inference for your hosted models. The Inference API can be accessed via usual HTTP requests with your favorite programming languages, but the "),te=r("code"),Le=a("huggingface_hub"),Re=a(" library has a client wrapper to access the Inference API programmatically. This guide will show you how to make calls to the Inference API with the "),se=r("code"),ze=a("huggingface_hub"),Ge=a(" library."),ve=f(),W=r("p"),T=r("strong"),We=a("If you want to make the HTTP calls directly, please refer to "),O=r("a"),Je=a("Accelerated Inference API Documentation"),Ue=a(" or to the sample snippets visible on every supported model page."),ke=f(),J=r("p"),U=r("img"),Ae=f(),m=r("p"),Qe=a("Begin by creating an instance of the "),ae=r("code"),Ve=a("InferenceApi"),Xe=a(" with a specific model repository ID. You can find your "),ne=r("code"),Ze=a("API_TOKEN"),et=a(" under Settings from your Hugging Face account. The "),re=r("code"),tt=a("API_TOKEN"),st=a(" will allow you to send requests to the Inference API."),Ee=f(),M(N.$$.fragment),xe=f(),d=r("p"),at=a("The pipeline is determined from the metadata in the model card and configuration files (see "),H=r("a"),nt=a("here"),rt=a(" for more details). For example, when using the "),S=r("a"),ot=a("bert-base-uncased"),lt=a(" model, the Inference API can automatically infer that this model should be used for a "),oe=r("code"),it=a("fill-mask"),ct=a(" task."),je=f(),M(C.$$.fragment),qe=f(),g=r("p"),pt=a("Each task requires a different type of input. A "),le=r("code"),ft=a("question-answering"),ht=a(" task expects a dictionary with the "),ie=r("code"),ut=a("question"),mt=a(" and "),ce=r("code"),dt=a("context"),gt=a(" keys as the input:"),$e=f(),M(D.$$.fragment),Pe=f(),_=r("p"),_t=a("Some tasks may require additional parameters (see "),K=r("a"),yt=a("here"),wt=a(" for a detailed list of all parameters for each task). As an example, for "),pe=r("code"),bt=a("zero-shot-classification"),It=a(" tasks, the model needs candidate labels that can be supplied to "),fe=r("code"),vt=a("params"),kt=a(":"),Te=f(),M(F.$$.fragment),Oe=f(),u=r("p"),At=a("Some models may support multiple tasks. The "),he=r("code"),Et=a("sentence-transformers"),xt=a(" models can complete both "),ue=r("code"),jt=a("sentence-similarity"),qt=a(" and "),me=r("code"),$t=a("feature-extraction"),Pt=a(" tasks. Specify which task you want to perform with the "),de=r("code"),Tt=a("task"),Ot=a(" parameter:"),Ne=f(),M(B.$$.fragment),this.h()},l(e){const i=hs('[data-svelte="svelte-1phssyn"]',document.head);b=o(i,"META",{name:!0,content:!0}),i.forEach(s),_e=h(e),ye=o(e,"HR",{}),we=h(e),I=o(e,"H2",{class:!0});var Se=l(I);k=o(Se,"A",{id:!0,class:!0,href:!0});var St=l(k);V=o(St,"SPAN",{});var Ct=l(V);Y($.$$.fragment,Ct),Ct.forEach(s),St.forEach(s),Ke=h(Se),X=o(Se,"SPAN",{});var Dt=l(X);Fe=n(Dt,"title: How to programmatically access the Inference API"),Dt.forEach(s),Se.forEach(s),be=h(e),v=o(e,"H1",{class:!0});var Ce=l(v);A=o(Ce,"A",{id:!0,class:!0,href:!0});var Kt=l(A);Z=o(Kt,"SPAN",{});var Ft=l(Z);Y(P.$$.fragment,Ft),Ft.forEach(s),Kt.forEach(s),Be=h(Ce),ee=o(Ce,"SPAN",{});var Bt=l(ee);Me=n(Bt,"How to programmatically access the Inference API"),Bt.forEach(s),Ce.forEach(s),Ie=h(e),y=o(e,"P",{});var Q=l(y);Ye=n(Q,"The Inference API provides fast inference for your hosted models. The Inference API can be accessed via usual HTTP requests with your favorite programming languages, but the "),te=o(Q,"CODE",{});var Mt=l(te);Le=n(Mt,"huggingface_hub"),Mt.forEach(s),Re=n(Q," library has a client wrapper to access the Inference API programmatically. This guide will show you how to make calls to the Inference API with the "),se=o(Q,"CODE",{});var Yt=l(se);ze=n(Yt,"huggingface_hub"),Yt.forEach(s),Ge=n(Q," library."),Q.forEach(s),ve=h(e),W=o(e,"P",{});var Lt=l(W);T=o(Lt,"STRONG",{});var De=l(T);We=n(De,"If you want to make the HTTP calls directly, please refer to "),O=o(De,"A",{href:!0,rel:!0});var Rt=l(O);Je=n(Rt,"Accelerated Inference API Documentation"),Rt.forEach(s),Ue=n(De," or to the sample snippets visible on every supported model page."),De.forEach(s),Lt.forEach(s),ke=h(e),J=o(e,"P",{});var zt=l(J);U=o(zt,"IMG",{src:!0,alt:!0}),zt.forEach(s),Ae=h(e),m=o(e,"P",{});var E=l(m);Qe=n(E,"Begin by creating an instance of the "),ae=o(E,"CODE",{});var Gt=l(ae);Ve=n(Gt,"InferenceApi"),Gt.forEach(s),Xe=n(E," with a specific model repository ID. You can find your "),ne=o(E,"CODE",{});var Wt=l(ne);Ze=n(Wt,"API_TOKEN"),Wt.forEach(s),et=n(E," under Settings from your Hugging Face account. The "),re=o(E,"CODE",{});var Jt=l(re);tt=n(Jt,"API_TOKEN"),Jt.forEach(s),st=n(E," will allow you to send requests to the Inference API."),E.forEach(s),Ee=h(e),Y(N.$$.fragment,e),xe=h(e),d=o(e,"P",{});var x=l(d);at=n(x,"The pipeline is determined from the metadata in the model card and configuration files (see "),H=o(x,"A",{href:!0,rel:!0});var Ut=l(H);nt=n(Ut,"here"),Ut.forEach(s),rt=n(x," for more details). For example, when using the "),S=o(x,"A",{href:!0,rel:!0});var Qt=l(S);ot=n(Qt,"bert-base-uncased"),Qt.forEach(s),lt=n(x," model, the Inference API can automatically infer that this model should be used for a "),oe=o(x,"CODE",{});var Vt=l(oe);it=n(Vt,"fill-mask"),Vt.forEach(s),ct=n(x," task."),x.forEach(s),je=h(e),Y(C.$$.fragment,e),qe=h(e),g=o(e,"P",{});var j=l(g);pt=n(j,"Each task requires a different type of input. A "),le=o(j,"CODE",{});var Xt=l(le);ft=n(Xt,"question-answering"),Xt.forEach(s),ht=n(j," task expects a dictionary with the "),ie=o(j,"CODE",{});var Zt=l(ie);ut=n(Zt,"question"),Zt.forEach(s),mt=n(j," and "),ce=o(j,"CODE",{});var es=l(ce);dt=n(es,"context"),es.forEach(s),gt=n(j," keys as the input:"),j.forEach(s),$e=h(e),Y(D.$$.fragment,e),Pe=h(e),_=o(e,"P",{});var q=l(_);_t=n(q,"Some tasks may require additional parameters (see "),K=o(q,"A",{href:!0,rel:!0});var ts=l(K);yt=n(ts,"here"),ts.forEach(s),wt=n(q," for a detailed list of all parameters for each task). As an example, for "),pe=o(q,"CODE",{});var ss=l(pe);bt=n(ss,"zero-shot-classification"),ss.forEach(s),It=n(q," tasks, the model needs candidate labels that can be supplied to "),fe=o(q,"CODE",{});var as=l(fe);vt=n(as,"params"),as.forEach(s),kt=n(q,":"),q.forEach(s),Te=h(e),Y(F.$$.fragment,e),Oe=h(e),u=o(e,"P",{});var w=l(u);At=n(w,"Some models may support multiple tasks. The "),he=o(w,"CODE",{});var ns=l(he);Et=n(ns,"sentence-transformers"),ns.forEach(s),xt=n(w," models can complete both "),ue=o(w,"CODE",{});var rs=l(ue);jt=n(rs,"sentence-similarity"),rs.forEach(s),qt=n(w," and "),me=o(w,"CODE",{});var os=l(me);$t=n(os,"feature-extraction"),os.forEach(s),Pt=n(w," tasks. Specify which task you want to perform with the "),de=o(w,"CODE",{});var ls=l(de);Tt=n(ls,"task"),ls.forEach(s),Ot=n(w," parameter:"),w.forEach(s),Ne=h(e),Y(B.$$.fragment,e),this.h()},h(){p(b,"name","hf:doc:metadata"),p(b,"content",JSON.stringify(_s)),p(k,"id","title:-how-to-programmatically-access-the-inference-api"),p(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(k,"href","#title:-how-to-programmatically-access-the-inference-api"),p(I,"class","relative group"),p(A,"id","how-to-programmatically-access-the-inference-api"),p(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(A,"href","#how-to-programmatically-access-the-inference-api"),p(v,"class","relative group"),p(O,"href","https://api-inference.huggingface.co/docs/python/html/index.html"),p(O,"rel","nofollow"),us(U.src,Ht="/docs/assets/hub/inference_api_snippet.png")||p(U,"src",Ht),p(U,"alt","Snippet of code to make calls to the Inference API"),p(H,"href","https://huggingface.co/docs/hub/main#how-is-a-models-type-of-inference-api-and-widget-determined"),p(H,"rel","nofollow"),p(S,"href","https://huggingface.co/bert-base-uncased"),p(S,"rel","nofollow"),p(K,"href","https://api-inference.huggingface.co/docs/python/html/detailed_parameters.html"),p(K,"rel","nofollow")},m(e,i){t(document.head,b),c(e,_e,i),c(e,ye,i),c(e,we,i),c(e,I,i),t(I,k),t(k,V),L($,V,null),t(I,Ke),t(I,X),t(X,Fe),c(e,be,i),c(e,v,i),t(v,A),t(A,Z),L(P,Z,null),t(v,Be),t(v,ee),t(ee,Me),c(e,Ie,i),c(e,y,i),t(y,Ye),t(y,te),t(te,Le),t(y,Re),t(y,se),t(se,ze),t(y,Ge),c(e,ve,i),c(e,W,i),t(W,T),t(T,We),t(T,O),t(O,Je),t(T,Ue),c(e,ke,i),c(e,J,i),t(J,U),c(e,Ae,i),c(e,m,i),t(m,Qe),t(m,ae),t(ae,Ve),t(m,Xe),t(m,ne),t(ne,Ze),t(m,et),t(m,re),t(re,tt),t(m,st),c(e,Ee,i),L(N,e,i),c(e,xe,i),c(e,d,i),t(d,at),t(d,H),t(H,nt),t(d,rt),t(d,S),t(S,ot),t(d,lt),t(d,oe),t(oe,it),t(d,ct),c(e,je,i),L(C,e,i),c(e,qe,i),c(e,g,i),t(g,pt),t(g,le),t(le,ft),t(g,ht),t(g,ie),t(ie,ut),t(g,mt),t(g,ce),t(ce,dt),t(g,gt),c(e,$e,i),L(D,e,i),c(e,Pe,i),c(e,_,i),t(_,_t),t(_,K),t(K,yt),t(_,wt),t(_,pe),t(pe,bt),t(_,It),t(_,fe),t(fe,vt),t(_,kt),c(e,Te,i),L(F,e,i),c(e,Oe,i),c(e,u,i),t(u,At),t(u,he),t(he,Et),t(u,xt),t(u,ue),t(ue,jt),t(u,qt),t(u,me),t(me,$t),t(u,Pt),t(u,de),t(de,Tt),t(u,Ot),c(e,Ne,i),L(B,e,i),He=!0},p:ms,i(e){He||(R($.$$.fragment,e),R(P.$$.fragment,e),R(N.$$.fragment,e),R(C.$$.fragment,e),R(D.$$.fragment,e),R(F.$$.fragment,e),R(B.$$.fragment,e),He=!0)},o(e){z($.$$.fragment,e),z(P.$$.fragment,e),z(N.$$.fragment,e),z(C.$$.fragment,e),z(D.$$.fragment,e),z(F.$$.fragment,e),z(B.$$.fragment,e),He=!1},d(e){s(b),e&&s(_e),e&&s(ye),e&&s(we),e&&s(I),G($),e&&s(be),e&&s(v),G(P),e&&s(Ie),e&&s(y),e&&s(ve),e&&s(W),e&&s(ke),e&&s(J),e&&s(Ae),e&&s(m),e&&s(Ee),G(N,e),e&&s(xe),e&&s(d),e&&s(je),G(C,e),e&&s(qe),e&&s(g),e&&s($e),G(D,e),e&&s(Pe),e&&s(_),e&&s(Te),G(F,e),e&&s(Oe),e&&s(u),e&&s(Ne),G(B,e)}}}const _s={local:"how-to-programmatically-access-the-inference-api",title:"How to programmatically access the Inference API"};function ys(Nt){return ds(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class vs extends cs{constructor(b){super();ps(this,b,ys,gs,fs,{})}}export{vs as default,_s as metadata};
