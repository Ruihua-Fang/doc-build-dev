import{S as zt,i as At,s as St,e as n,k as d,w as v,t as i,M as Nt,c as a,d as t,m as l,a as r,x as w,h as s,b as g,F as e,g as m,y,q as k,o as x,B as $,v as It}from"../../chunks/vendor-d3924577.js";import{T as Ot}from"../../chunks/Tip-4377bed8.js";import{D as Y}from"../../chunks/Docstring-6e765b82.js";import{I as ro}from"../../chunks/IconCopyLink-f94c3d80.js";function Ct(ce){let h,E,u,f,M;return{c(){h=n("p"),E=i("Passing "),u=n("code"),f=i("use_auth_token=True"),M=i(` is required when you want to use a
private model.`)},l(p){h=a(p,"P",{});var _=r(h);E=s(_,"Passing "),u=a(_,"CODE",{});var T=r(u);f=s(T,"use_auth_token=True"),T.forEach(t),M=s(_,` is required when you want to use a
private model.`),_.forEach(t)},m(p,_){m(p,h,_),e(h,E),e(h,u),e(u,f),e(h,M)},d(p){p&&t(h)}}}function Ft(ce){let h,E,u,f,M;return{c(){h=n("p"),E=i("Passing "),u=n("code"),f=i("use_auth_token=True"),M=i(` is required when you want to use a private
model.`)},l(p){h=a(p,"P",{});var _=r(h);E=s(_,"Passing "),u=a(_,"CODE",{});var T=r(u);f=s(T,"use_auth_token=True"),T.forEach(t),M=s(_,` is required when you want to use a private
model.`),_.forEach(t)},m(p,_){m(p,h,_),e(h,E),e(h,u),e(u,f),e(h,M)},d(p){p&&t(h)}}}function Lt(ce){let h,E,u,f,M,p,_,T,io,Le,A,L,_e,J,so,fe,lo,Ke,K,co,be,ho,go,qe,S,q,ve,Q,mo,we,uo,We,b,X,po,H,_o,ye,fo,bo,ke,vo,wo,xe,yo,ko,xo,O,Z,$o,N,Mo,$e,Eo,To,Me,Ho,Po,Do,W,Oo,U,ee,zo,Ee,Ao,So,V,oe,No,Te,Io,Ue,I,j,He,te,Co,Pe,Fo,Ve,P,ne,Lo,De,Ko,qo,R,je,C,ae,Wo,re,Uo,Oe,Vo,jo,Re,F,ie,Ro,ze,Bo,Be,D,se,Go,Ae,Yo,Jo,de,he,Se,Qo,Xo,Zo,B,Ne,et,ot,Ie,tt,nt,Ge;return p=new ro({}),J=new ro({}),Q=new ro({}),X=new Y({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/hub_mixin.py#L24"}}),Z=new Y({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model
hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level,
like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end
of model_id simply like this:
<code>dbmdz/bert-base-german-cased@main</code> Revision is
the specific model version to use. It can be a
branch name, a tag name, or a commit id, since we
use a git-based system for storing models and
other artifacts on huggingface.co, so <code>revision</code>
can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights
saved using
<code>save_pretrained</code>,
e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration
and state dictionary (resp. with keyword arguments
<code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights
and configuration files, overriding the cached versions
if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will
attempt to resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or
endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are
used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote
files. If <code>True</code>, will use the token generated when
running <code>transformers-cli login</code> (stored in
<code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained
model configuration should be cached if the standard
cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to
download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during
initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/hub_mixin.py#L79"}}),W=new Ot({props:{$$slots:{default:[Ct]},$$scope:{ctx:ce}}}),ee=new Y({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_id",val:": str"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<em>str</em>, <em>optional</em>) &#x2014;
Repository name to which push`,name:"repo_id"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<em>str</em>, <em>optional</em>) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<em>bool</em>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.token",description:`<strong>token</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files.
If not set, will use the token set when logging in with
<em>transformers-cli login</em> (stored in <em>~/.huggingface</em>).`,name:"token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.branch",description:`<strong>branch</strong> (Optional <code>str</code>) &#x2014;
The git branch on which to push the dataset. This defaults to
the default branch as specified in your repository, which
defaults to <em>&#x201C;main&#x201D;</em>.`,name:"branch"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<em>dict</em>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/hub_mixin.py#L217",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),oe=new Y({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
specify config (must be dict) in case you want to save
it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set it to <code>True</code> in case you want to push your weights
to huggingface_hub`,name:"push_to_hub"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
kwargs will be passed to <code>push_to_hub</code>`,name:"kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/hub_mixin.py#L32"}}),te=new ro({}),ne=new Y({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a
model repo on huggingface.co. Valid model ids can be located
at the root-level, like <code>bert-base-uncased</code>, or namespaced
under a user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id
simply like this: <code>dbmdz/bert-base-german-cased@main</code> Revision
is the specific model version to use. It can be a branch name,
a tag name, or a commit id, since we use a git-based system
for storing models and other artifacts on huggingface.co, so
<code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g.,
<code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state
dictionary (resp. with keyword arguments <code>config</code> and
<code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and
configuration files, overriding the cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to
resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g.,
<code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The
proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model
configuration should be cached if the standard cache should not be
used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download
the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/keras_mixin.py#L211"}}),R=new Ot({props:{$$slots:{default:[Ft]},$$scope:{ctx:ce}}}),ae=new Y({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_id",val:": str"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = True"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="%60https://www.tensorflow.org/api_docs/python/tf/keras/Model%60">Keras
model</a>
you&#x2019;d like to push to the Hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_id",description:`<strong>repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Repository name to which push`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically
hosts and displays a TensorBoard instance if log files are included
in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
not set, will use the token set when logging in with
<code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. Available tasks
<a href="https://github.com/huggingface/huggingface_hub/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">here</a>.`,name:"task_name"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/keras_mixin.py#L270",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),ie=new Y({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"task_name",val:": typing.Optional[str] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">Keras
model</a>
you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.task_name",description:`<strong>task_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the task the model was trained on. Available tasks
<a href="https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts" rel="nofollow">here</a>.`,name:"task_name"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/keras_mixin.py#L147"}}),se=new Y({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/pr_847/src/huggingface_hub/keras_mixin.py#L372"}}),{c(){h=n("meta"),E=d(),u=n("h1"),f=n("a"),M=n("span"),v(p.$$.fragment),_=d(),T=n("span"),io=i("Mixins & serialization methods"),Le=d(),A=n("h2"),L=n("a"),_e=n("span"),v(J.$$.fragment),so=d(),fe=n("span"),lo=i("Mixins"),Ke=d(),K=n("p"),co=i("The "),be=n("code"),ho=i("huggingface_hub"),go=i(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),qe=d(),S=n("h3"),q=n("a"),ve=n("span"),v(Q.$$.fragment),mo=d(),we=n("span"),uo=i("PyTorch"),We=d(),b=n("div"),v(X.$$.fragment),po=d(),H=n("p"),_o=i(`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),ye=n("code"),fo=i("_from_pretrained"),bo=i(` and
`),ke=n("code"),vo=i("_save_pretrained"),wo=i(` to define custom logic for saving/loading your classes.
See `),xe=n("code"),yo=i("huggingface_hub.PyTorchModelHubMixin"),ko=i(" for an example."),xo=d(),O=n("div"),v(Z.$$.fragment),$o=d(),N=n("p"),Mo=i(`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),$e=n("code"),Eo=i("model.eval()"),To=i(` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Me=n("code"),Ho=i("model.train()"),Po=i("."),Do=d(),v(W.$$.fragment),Oo=d(),U=n("div"),v(ee.$$.fragment),zo=d(),Ee=n("p"),Ao=i("Upload model checkpoint to the Hub."),So=d(),V=n("div"),v(oe.$$.fragment),No=d(),Te=n("p"),Io=i("Save weights in local directory."),Ue=d(),I=n("h3"),j=n("a"),He=n("span"),v(te.$$.fragment),Co=d(),Pe=n("span"),Fo=i("Keras"),Ve=d(),P=n("div"),v(ne.$$.fragment),Lo=d(),De=n("p"),Ko=i("Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),qo=d(),v(R.$$.fragment),je=d(),C=n("div"),v(ae.$$.fragment),Wo=d(),re=n("p"),Uo=i(`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),Oe=n("code"),Vo=i("repo_path_or_name"),jo=i("."),Re=d(),F=n("div"),v(ie.$$.fragment),Ro=d(),ze=n("p"),Bo=i(`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Be=d(),D=n("div"),v(se.$$.fragment),Go=d(),Ae=n("p"),Yo=i(`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Jo=d(),de=n("ul"),he=n("li"),Se=n("code"),Qo=i("_from_pretrained"),Xo=i(", to load a model from the Hub or from local files."),Zo=d(),B=n("li"),Ne=n("code"),et=i("_save_pretrained"),ot=i(", to save a model in the "),Ie=n("code"),tt=i("SavedModel"),nt=i(" format."),this.h()},l(o){const c=Nt('[data-svelte="svelte-1phssyn"]',document.head);h=a(c,"META",{name:!0,content:!0}),c.forEach(t),E=l(o),u=a(o,"H1",{class:!0});var le=r(u);f=a(le,"A",{id:!0,class:!0,href:!0});var Ce=r(f);M=a(Ce,"SPAN",{});var rt=r(M);w(p.$$.fragment,rt),rt.forEach(t),Ce.forEach(t),_=l(le),T=a(le,"SPAN",{});var it=r(T);io=s(it,"Mixins & serialization methods"),it.forEach(t),le.forEach(t),Le=l(o),A=a(o,"H2",{class:!0});var Ye=r(A);L=a(Ye,"A",{id:!0,class:!0,href:!0});var st=r(L);_e=a(st,"SPAN",{});var dt=r(_e);w(J.$$.fragment,dt),dt.forEach(t),st.forEach(t),so=l(Ye),fe=a(Ye,"SPAN",{});var lt=r(fe);lo=s(lt,"Mixins"),lt.forEach(t),Ye.forEach(t),Ke=l(o),K=a(o,"P",{});var Je=r(K);co=s(Je,"The "),be=a(Je,"CODE",{});var ct=r(be);ho=s(ct,"huggingface_hub"),ct.forEach(t),go=s(Je,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Je.forEach(t),qe=l(o),S=a(o,"H3",{class:!0});var Qe=r(S);q=a(Qe,"A",{id:!0,class:!0,href:!0});var ht=r(q);ve=a(ht,"SPAN",{});var gt=r(ve);w(Q.$$.fragment,gt),gt.forEach(t),ht.forEach(t),mo=l(Qe),we=a(Qe,"SPAN",{});var mt=r(we);uo=s(mt,"PyTorch"),mt.forEach(t),Qe.forEach(t),We=l(o),b=a(o,"DIV",{class:!0});var z=r(b);w(X.$$.fragment,z),po=l(z),H=a(z,"P",{});var G=r(H);_o=s(G,`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),ye=a(G,"CODE",{});var ut=r(ye);fo=s(ut,"_from_pretrained"),ut.forEach(t),bo=s(G,` and
`),ke=a(G,"CODE",{});var pt=r(ke);vo=s(pt,"_save_pretrained"),pt.forEach(t),wo=s(G,` to define custom logic for saving/loading your classes.
See `),xe=a(G,"CODE",{});var _t=r(xe);yo=s(_t,"huggingface_hub.PyTorchModelHubMixin"),_t.forEach(t),ko=s(G," for an example."),G.forEach(t),xo=l(z),O=a(z,"DIV",{class:!0});var ge=r(O);w(Z.$$.fragment,ge),$o=l(ge),N=a(ge,"P",{});var me=r(N);Mo=s(me,`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),$e=a(me,"CODE",{});var ft=r($e);Eo=s(ft,"model.eval()"),ft.forEach(t),To=s(me,` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Me=a(me,"CODE",{});var bt=r(Me);Ho=s(bt,"model.train()"),bt.forEach(t),Po=s(me,"."),me.forEach(t),Do=l(ge),w(W.$$.fragment,ge),ge.forEach(t),Oo=l(z),U=a(z,"DIV",{class:!0});var Xe=r(U);w(ee.$$.fragment,Xe),zo=l(Xe),Ee=a(Xe,"P",{});var vt=r(Ee);Ao=s(vt,"Upload model checkpoint to the Hub."),vt.forEach(t),Xe.forEach(t),So=l(z),V=a(z,"DIV",{class:!0});var Ze=r(V);w(oe.$$.fragment,Ze),No=l(Ze),Te=a(Ze,"P",{});var wt=r(Te);Io=s(wt,"Save weights in local directory."),wt.forEach(t),Ze.forEach(t),z.forEach(t),Ue=l(o),I=a(o,"H3",{class:!0});var eo=r(I);j=a(eo,"A",{id:!0,class:!0,href:!0});var yt=r(j);He=a(yt,"SPAN",{});var kt=r(He);w(te.$$.fragment,kt),kt.forEach(t),yt.forEach(t),Co=l(eo),Pe=a(eo,"SPAN",{});var xt=r(Pe);Fo=s(xt,"Keras"),xt.forEach(t),eo.forEach(t),Ve=l(o),P=a(o,"DIV",{class:!0});var ue=r(P);w(ne.$$.fragment,ue),Lo=l(ue),De=a(ue,"P",{});var $t=r(De);Ko=s($t,"Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),$t.forEach(t),qo=l(ue),w(R.$$.fragment,ue),ue.forEach(t),je=l(o),C=a(o,"DIV",{class:!0});var oo=r(C);w(ae.$$.fragment,oo),Wo=l(oo),re=a(oo,"P",{});var to=r(re);Uo=s(to,`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),Oe=a(to,"CODE",{});var Mt=r(Oe);Vo=s(Mt,"repo_path_or_name"),Mt.forEach(t),jo=s(to,"."),to.forEach(t),oo.forEach(t),Re=l(o),F=a(o,"DIV",{class:!0});var no=r(F);w(ie.$$.fragment,no),Ro=l(no),ze=a(no,"P",{});var Et=r(ze);Bo=s(Et,`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Et.forEach(t),no.forEach(t),Be=l(o),D=a(o,"DIV",{class:!0});var pe=r(D);w(se.$$.fragment,pe),Go=l(pe),Ae=a(pe,"P",{});var Tt=r(Ae);Yo=s(Tt,`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Tt.forEach(t),Jo=l(pe),de=a(pe,"UL",{});var ao=r(de);he=a(ao,"LI",{});var at=r(he);Se=a(at,"CODE",{});var Ht=r(Se);Qo=s(Ht,"_from_pretrained"),Ht.forEach(t),Xo=s(at,", to load a model from the Hub or from local files."),at.forEach(t),Zo=l(ao),B=a(ao,"LI",{});var Fe=r(B);Ne=a(Fe,"CODE",{});var Pt=r(Ne);et=s(Pt,"_save_pretrained"),Pt.forEach(t),ot=s(Fe,", to save a model in the "),Ie=a(Fe,"CODE",{});var Dt=r(Ie);tt=s(Dt,"SavedModel"),Dt.forEach(t),nt=s(Fe," format."),Fe.forEach(t),ao.forEach(t),pe.forEach(t),this.h()},h(){g(h,"name","hf:doc:metadata"),g(h,"content",JSON.stringify(Kt)),g(f,"id","mixins-serialization-methods"),g(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(f,"href","#mixins-serialization-methods"),g(u,"class","relative group"),g(L,"id","mixins"),g(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(L,"href","#mixins"),g(A,"class","relative group"),g(q,"id","huggingface_hub.ModelHubMixin"),g(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(q,"href","#huggingface_hub.ModelHubMixin"),g(S,"class","relative group"),g(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(b,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(j,"id","huggingface_hub.from_pretrained_keras"),g(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(j,"href","#huggingface_hub.from_pretrained_keras"),g(I,"class","relative group"),g(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(o,c){e(document.head,h),m(o,E,c),m(o,u,c),e(u,f),e(f,M),y(p,M,null),e(u,_),e(u,T),e(T,io),m(o,Le,c),m(o,A,c),e(A,L),e(L,_e),y(J,_e,null),e(A,so),e(A,fe),e(fe,lo),m(o,Ke,c),m(o,K,c),e(K,co),e(K,be),e(be,ho),e(K,go),m(o,qe,c),m(o,S,c),e(S,q),e(q,ve),y(Q,ve,null),e(S,mo),e(S,we),e(we,uo),m(o,We,c),m(o,b,c),y(X,b,null),e(b,po),e(b,H),e(H,_o),e(H,ye),e(ye,fo),e(H,bo),e(H,ke),e(ke,vo),e(H,wo),e(H,xe),e(xe,yo),e(H,ko),e(b,xo),e(b,O),y(Z,O,null),e(O,$o),e(O,N),e(N,Mo),e(N,$e),e($e,Eo),e(N,To),e(N,Me),e(Me,Ho),e(N,Po),e(O,Do),y(W,O,null),e(b,Oo),e(b,U),y(ee,U,null),e(U,zo),e(U,Ee),e(Ee,Ao),e(b,So),e(b,V),y(oe,V,null),e(V,No),e(V,Te),e(Te,Io),m(o,Ue,c),m(o,I,c),e(I,j),e(j,He),y(te,He,null),e(I,Co),e(I,Pe),e(Pe,Fo),m(o,Ve,c),m(o,P,c),y(ne,P,null),e(P,Lo),e(P,De),e(De,Ko),e(P,qo),y(R,P,null),m(o,je,c),m(o,C,c),y(ae,C,null),e(C,Wo),e(C,re),e(re,Uo),e(re,Oe),e(Oe,Vo),e(re,jo),m(o,Re,c),m(o,F,c),y(ie,F,null),e(F,Ro),e(F,ze),e(ze,Bo),m(o,Be,c),m(o,D,c),y(se,D,null),e(D,Go),e(D,Ae),e(Ae,Yo),e(D,Jo),e(D,de),e(de,he),e(he,Se),e(Se,Qo),e(he,Xo),e(de,Zo),e(de,B),e(B,Ne),e(Ne,et),e(B,ot),e(B,Ie),e(Ie,tt),e(B,nt),Ge=!0},p(o,[c]){const le={};c&2&&(le.$$scope={dirty:c,ctx:o}),W.$set(le);const Ce={};c&2&&(Ce.$$scope={dirty:c,ctx:o}),R.$set(Ce)},i(o){Ge||(k(p.$$.fragment,o),k(J.$$.fragment,o),k(Q.$$.fragment,o),k(X.$$.fragment,o),k(Z.$$.fragment,o),k(W.$$.fragment,o),k(ee.$$.fragment,o),k(oe.$$.fragment,o),k(te.$$.fragment,o),k(ne.$$.fragment,o),k(R.$$.fragment,o),k(ae.$$.fragment,o),k(ie.$$.fragment,o),k(se.$$.fragment,o),Ge=!0)},o(o){x(p.$$.fragment,o),x(J.$$.fragment,o),x(Q.$$.fragment,o),x(X.$$.fragment,o),x(Z.$$.fragment,o),x(W.$$.fragment,o),x(ee.$$.fragment,o),x(oe.$$.fragment,o),x(te.$$.fragment,o),x(ne.$$.fragment,o),x(R.$$.fragment,o),x(ae.$$.fragment,o),x(ie.$$.fragment,o),x(se.$$.fragment,o),Ge=!1},d(o){t(h),o&&t(E),o&&t(u),$(p),o&&t(Le),o&&t(A),$(J),o&&t(Ke),o&&t(K),o&&t(qe),o&&t(S),$(Q),o&&t(We),o&&t(b),$(X),$(Z),$(W),$(ee),$(oe),o&&t(Ue),o&&t(I),$(te),o&&t(Ve),o&&t(P),$(ne),$(R),o&&t(je),o&&t(C),$(ae),o&&t(Re),o&&t(F),$(ie),o&&t(Be),o&&t(D),$(se)}}}const Kt={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"}],title:"Mixins"}],title:"Mixins & serialization methods"};function qt(ce){return It(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Rt extends zt{constructor(h){super();At(this,h,qt,Lt,St,{})}}export{Rt as default,Kt as metadata};
