import{S as Ya,i as Ja,s as Ka,e as r,k as m,w as c,t as l,M as Wa,c as a,d as t,m as f,a as n,x as v,h as i,b as u,F as s,g as p,y as g,q as _,o as w,B as $}from"../chunks/vendor-6b77c823.js";import{T as Va}from"../chunks/Tip-39098574.js";import{Y as Ra}from"../chunks/Youtube-5c6e11e6.js";import{I as Be}from"../chunks/IconCopyLink-7a11ce68.js";import{C as T}from"../chunks/CodeBlock-3a8b25a8.js";function Qa(ne){let h,j,d,b,A;return{c(){h=r("p"),j=l("Refer to the Performance "),d=r("a"),b=l("guide"),A=l(" for more details about memory-saving techniques."),this.h()},l(y){h=a(y,"P",{});var k=n(h);j=i(k,"Refer to the Performance "),d=a(k,"A",{href:!0});var C=n(d);b=i(C,"guide"),C.forEach(t),A=i(k," for more details about memory-saving techniques."),k.forEach(t),this.h()},h(){u(d,"href","performance")},m(y,k){p(y,h,k),s(h,j),s(h,d),s(d,b),s(h,A)},d(y){y&&t(h)}}}function Xa(ne){let h,j,d,b,A;return{c(){h=r("p"),j=l("By default, the tokenizer creates an "),d=r("code"),b=l("attention_mask"),A=l(" for you based on your specific tokenizer\u2019s defaults.")},l(y){h=a(y,"P",{});var k=n(h);j=i(k,"By default, the tokenizer creates an "),d=a(k,"CODE",{});var C=n(d);b=i(C,"attention_mask"),C.forEach(t),A=i(k," for you based on your specific tokenizer\u2019s defaults."),k.forEach(t)},m(y,k){p(y,h,k),s(h,j),s(h,d),s(d,b),s(h,A)},d(y){y&&t(h)}}}function Za(ne){let h,j,d,b,A,y,k,C,Ks,Nt,Ne,Ws,Lt,le,Gt,Le,I,Qs,ie,Xs,Zs,pe,eo,to,me,so,oo,Ht,fe,Ot,S,pt,ue,ro,he,ao,no,lo,mt,de,io,Ge,po,mo,zt,H,fo,ce,uo,ho,Vt,U,O,ft,ve,co,ut,vo,Rt,He,go,Yt,ge,Jt,z,_o,Oe,wo,$o,Kt,q,V,ht,_e,bo,dt,yo,Wt,ze,ko,Qt,we,Xt,Ve,Eo,Zt,R,D,jo,Re,ct,Ao,To,Ye,Po,Co,Io,x,Fo,Je,vt,So,Uo,Ke,qo,Do,es,Y,ts,M,J,gt,$e,xo,_t,Mo,ss,K,Bo,be,No,Lo,os,We,F,Go,wt,Ho,Oo,ye,$t,zo,Vo,Qe,Ro,Yo,rs,ke,as,Xe,B,Jo,bt,Ko,Wo,Ze,Qo,Xo,ns,Ee,ls,N,W,yt,je,Zo,kt,er,is,Q,tr,Et,sr,or,ps,Ae,ms,et,rr,fs,Te,us,L,X,jt,Pe,ar,At,nr,hs,tt,lr,ds,Ce,cs,st,ir,vs,Ie,gs,ot,pr,_s,Fe,ws,G,Z,Tt,Se,mr,Pt,fr,$s,E,ur,Ct,hr,dr,It,cr,vr,Ft,gr,_r,St,wr,$r,Ut,br,yr,bs,Ue,ys,rt,kr,ks,qe,Es,at,Er,js,De,As,ee,jr,qt,Ar,Tr,Ts,te,Ps,xe,Cs,se,Pr,Dt,Cr,Ir,Is,oe,xt,Fr,Sr,Mt,Ur,Fs;return y=new Be({}),le=new Ra({props:{id:"S2EEG3JIt2A"}}),fe=new Ra({props:{id:"_PAli-V4wj0"}}),ve=new Be({}),ge=new T({props:{code:`ValueError: Connection error, and we cannot find the requested files in the cached path.
Please try again or make sure your Internet connection is on.`,highlighted:`ValueError: Connection error, <span class="hljs-built_in">and</span> we cannot <span class="hljs-keyword">find</span> the requested <span class="hljs-keyword">files</span> in the cached path.
Please <span class="hljs-keyword">try</span> again <span class="hljs-built_in">or</span> <span class="hljs-keyword">make</span> sure your Internet connection <span class="hljs-keyword">is</span> <span class="hljs-keyword">on</span>.`}}),_e=new Be({}),we=new T({props:{code:"CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)",highlighted:'<span class="hljs-attribute">CUDA</span> out of memory. Tried to allocate <span class="hljs-number">256</span>.<span class="hljs-number">00</span> MiB (GPU <span class="hljs-number">0</span>; <span class="hljs-number">11</span>.<span class="hljs-number">17</span> GiB total capacity; <span class="hljs-number">9</span>.<span class="hljs-number">70</span> GiB already allocated; <span class="hljs-number">179</span>.<span class="hljs-number">81</span> MiB free; <span class="hljs-number">9</span>.<span class="hljs-number">85</span> GiB reserved in total by PyTorch)'}}),Y=new Va({props:{$$slots:{default:[Qa]},$$scope:{ctx:ne}}}),$e=new Be({}),ke=new T({props:{code:`from transformers import TFPreTrainedModel
from tensorflow import keras

model.save_weights("some_folder/tf_model.h5")
model = TFPreTrainedModel.from_pretrained("some_folder")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFPreTrainedModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras

<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_weights(<span class="hljs-string">&quot;some_folder/tf_model.h5&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFPreTrainedModel.from_pretrained(<span class="hljs-string">&quot;some_folder&quot;</span>)`}}),Ee=new T({props:{code:`from transformers import TFPreTrainedModel

model.save_pretrained("path_to/model")
model = TFPreTrainedModel.from_pretrained("path_to/model")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFPreTrainedModel

<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_pretrained(<span class="hljs-string">&quot;path_to/model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFPreTrainedModel.from_pretrained(<span class="hljs-string">&quot;path_to/model&quot;</span>)`}}),je=new Be({}),Ae=new T({props:{code:"ImportError: cannot import name 'ImageGPTFeatureExtractor' from 'transformers' (unknown location)",highlighted:'ImportError: cannot <span class="hljs-keyword">import</span> <span class="hljs-type">name</span> <span class="hljs-string">&#x27;ImageGPTFeatureExtractor&#x27;</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;transformers&#x27;</span> (<span class="hljs-type">unknown</span> <span class="hljs-keyword">location</span>)'}}),Te=new T({props:{code:"pip install transformers --upgrade",highlighted:"pip install transformers --upgrade"}}),Pe=new Be({}),Ce=new T({props:{code:"RuntimeError: CUDA error: device-side assert triggered",highlighted:'RuntimeError: CUDA <span class="hljs-literal">error</span>: device-<span class="hljs-literal">side</span> <span class="hljs-keyword">assert</span> triggered'}}),Ie=new T({props:{code:`import os

os.environ["CUDA_VISIBLE_DEVICES"] = ""`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os

<span class="hljs-meta">&gt;&gt;&gt; </span>os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="hljs-string">&quot;&quot;</span>`}}),Fe=new T({props:{code:`import os

os.environ["CUDA_LAUNCH_BLOCKING"] = "1"`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os

<span class="hljs-meta">&gt;&gt;&gt; </span>os.environ[<span class="hljs-string">&quot;CUDA_LAUNCH_BLOCKING&quot;</span>] = <span class="hljs-string">&quot;1&quot;</span>`}}),Se=new Be({}),Ue=new T({props:{code:`from transformers import AutoModelForSequenceClassification
import torch

model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
model.config.pad_token_id`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.pad_token_id
<span class="hljs-number">0</span>`}}),qe=new T({props:{code:`input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])
output = model(input_ids)
print(output.logits)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([[<span class="hljs-number">7592</span>, <span class="hljs-number">2057</span>, <span class="hljs-number">2097</span>, <span class="hljs-number">2393</span>, <span class="hljs-number">9611</span>, <span class="hljs-number">2115</span>], [<span class="hljs-number">7592</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[ <span class="hljs-number">0.0082</span>, -<span class="hljs-number">0.2307</span>],
        [ <span class="hljs-number">0.1317</span>, -<span class="hljs-number">0.1683</span>]], grad_fn=&lt;AddmmBackward0&gt;)`}}),De=new T({props:{code:`input_ids = torch.tensor([[7592]])
output = model(input_ids)
print(output.logits)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([[<span class="hljs-number">7592</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[-<span class="hljs-number">0.1008</span>, -<span class="hljs-number">0.4061</span>]], grad_fn=&lt;AddmmBackward0&gt;)`}}),te=new Va({props:{$$slots:{default:[Xa]},$$scope:{ctx:ne}}}),xe=new T({props:{code:`attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])
output = model(input_ids, attention_mask=attention_mask)
print(output.logits)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>attention_mask = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids, attention_mask=attention_mask)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[ <span class="hljs-number">0.0082</span>, -<span class="hljs-number">0.2307</span>],
        [-<span class="hljs-number">0.1008</span>, -<span class="hljs-number">0.4061</span>]], grad_fn=&lt;AddmmBackward0&gt;)`}}),{c(){h=r("meta"),j=m(),d=r("h1"),b=r("a"),A=r("span"),c(y.$$.fragment),k=m(),C=r("span"),Ks=l("Troubleshoot"),Nt=m(),Ne=r("p"),Ws=l("Sometimes errors occur, but we are here to help! This guide covers some of the most common issues we\u2019ve seen and how you can resolve them. However, this guide isn\u2019t meant to be a comprehensive collection of every \u{1F917} Transformers issue. For more help with troubleshooting your issue, try:"),Lt=m(),c(le.$$.fragment),Gt=m(),Le=r("ol"),I=r("li"),Qs=l("Asking for help on the "),ie=r("a"),Xs=l("forums"),Zs=l(". There are specific categories you can post your question to, like "),pe=r("a"),eo=l("Beginners"),to=l(" or "),me=r("a"),so=l("\u{1F917} Transformers"),oo=l(". Make sure you write a good descriptive forum post with some reproducible code to maximize the likelihood that your problem is solved!"),Ht=m(),c(fe.$$.fragment),Ot=m(),S=r("ol"),pt=r("li"),ue=r("p"),ro=l("Create an "),he=r("a"),ao=l("Issue"),no=l(" on the \u{1F917} Transformers repository if it is a bug related to the library. Try to include as much information describing the bug as possible to help us better figure out what\u2019s wrong and how we can fix it."),lo=m(),mt=r("li"),de=r("p"),io=l("Check the "),Ge=r("a"),po=l("Migration"),mo=l(" guide if you use an older version of \u{1F917} Transformers since some important changes have been introduced between versions."),zt=m(),H=r("p"),fo=l("For more details about troubleshooting and getting help, take a look at "),ce=r("a"),uo=l("Chapter 8"),ho=l(" of the Hugging Face course."),Vt=m(),U=r("h2"),O=r("a"),ft=r("span"),c(ve.$$.fragment),co=m(),ut=r("span"),vo=l("Firewalled environments"),Rt=m(),He=r("p"),go=l("Some GPU instances on cloud and intranet setups are firewalled to external connections, resulting in a connection error. When your script attempts to download model weights or datasets, the download will hang and then timeout with the following message:"),Yt=m(),c(ge.$$.fragment),Jt=m(),z=r("p"),_o=l("In this case, you should try to run \u{1F917} Transformers on "),Oe=r("a"),wo=l("offline mode"),$o=l(" to avoid the connection error."),Kt=m(),q=r("h2"),V=r("a"),ht=r("span"),c(_e.$$.fragment),bo=m(),dt=r("span"),yo=l("CUDA out of memory"),Wt=m(),ze=r("p"),ko=l("Training large models with millions of parameters can be challenging without the appropriate hardware. A common error you may encounter when the GPU runs out of memory is:"),Qt=m(),c(we.$$.fragment),Xt=m(),Ve=r("p"),Eo=l("Here are some potential solutions you can try to lessen memory use:"),Zt=m(),R=r("ul"),D=r("li"),jo=l("Reduce the "),Re=r("a"),ct=r("code"),Ao=l("per_device_train_batch_size"),To=l(" value in "),Ye=r("a"),Po=l("TrainingArguments"),Co=l("."),Io=m(),x=r("li"),Fo=l("Try using "),Je=r("a"),vt=r("code"),So=l("gradient_accumulation_steps"),Uo=l(" in "),Ke=r("a"),qo=l("TrainingArguments"),Do=l(" to effectively increase overall batch size."),es=m(),c(Y.$$.fragment),ts=m(),M=r("h2"),J=r("a"),gt=r("span"),c($e.$$.fragment),xo=m(),_t=r("span"),Mo=l("Unable to load a saved TensorFlow model"),ss=m(),K=r("p"),Bo=l("TensorFlow\u2019s "),be=r("a"),No=l("model.save"),Lo=l(" method will save the entire model - architecture, weights, training configuration - in a single file. However, when you load the model file again, you may run into an error because \u{1F917} Transformers may not load all the TensorFlow-related objects in the model file. To avoid issues with saving and loading TensorFlow models, we recommend you:"),os=m(),We=r("ul"),F=r("li"),Go=l("Save the model weights as a "),wt=r("code"),Ho=l("h5"),Oo=l(" file extension with "),ye=r("a"),$t=r("code"),zo=l("model.save_weights"),Vo=l(" and then reload the model with "),Qe=r("a"),Ro=l("from_pretrained()"),Yo=l(":"),rs=m(),c(ke.$$.fragment),as=m(),Xe=r("ul"),B=r("li"),Jo=l("Save the model with "),bt=r("code"),Ko=l("save_pretrained"),Wo=l(" and load it again with "),Ze=r("a"),Qo=l("from_pretrained()"),Xo=l(":"),ns=m(),c(Ee.$$.fragment),ls=m(),N=r("h2"),W=r("a"),yt=r("span"),c(je.$$.fragment),Zo=m(),kt=r("span"),er=l("ImportError"),is=m(),Q=r("p"),tr=l("Another common error you may encounter, especially if it is a newly released model, is "),Et=r("code"),sr=l("ImportError"),or=l(":"),ps=m(),c(Ae.$$.fragment),ms=m(),et=r("p"),rr=l("For these error types, check to make sure you have the latest version of \u{1F917} Transformers installed to access the most recent models:"),fs=m(),c(Te.$$.fragment),us=m(),L=r("h2"),X=r("a"),jt=r("span"),c(Pe.$$.fragment),ar=m(),At=r("span"),nr=l("CUDA error: device-side assert triggered"),hs=m(),tt=r("p"),lr=l("Sometimes you may run into a generic CUDA error about an error in the device code."),ds=m(),c(Ce.$$.fragment),cs=m(),st=r("p"),ir=l("You should try to run the code on a CPU first to get a more descriptive error message. Add the following environment variable to the beginning of your code to switch to a CPU:"),vs=m(),c(Ie.$$.fragment),gs=m(),ot=r("p"),pr=l("Another option is to get a better traceback from the GPU. Add the following environment variable to the beginning of your code to get the traceback to point to the source of the error:"),_s=m(),c(Fe.$$.fragment),ws=m(),G=r("h2"),Z=r("a"),Tt=r("span"),c(Se.$$.fragment),mr=m(),Pt=r("span"),fr=l("Incorrect output when padding tokens aren't masked"),$s=m(),E=r("p"),ur=l("In some cases, the output "),Ct=r("code"),hr=l("hidden_state"),dr=l(" may be incorrect if the "),It=r("code"),cr=l("input_ids"),vr=l(" include padding tokens. To demonstrate, load a model and tokenizer. You can access a model\u2019s "),Ft=r("code"),gr=l("pad_token_id"),_r=l(" to see its value. The "),St=r("code"),wr=l("pad_token_id"),$r=l(" may be "),Ut=r("code"),br=l("None"),yr=l(" for some models, but you can always manually set it."),bs=m(),c(Ue.$$.fragment),ys=m(),rt=r("p"),kr=l("The following example shows the output without masking the padding tokens:"),ks=m(),c(qe.$$.fragment),Es=m(),at=r("p"),Er=l("Here is the actual output of the second sequence:"),js=m(),c(De.$$.fragment),As=m(),ee=r("p"),jr=l("Most of the time, you should provide an "),qt=r("code"),Ar=l("attention_mask"),Tr=l(" to your model to ignore the padding tokens to avoid this silent error. Now the output of the second sequence matches its actual output:"),Ts=m(),c(te.$$.fragment),Ps=m(),c(xe.$$.fragment),Cs=m(),se=r("p"),Pr=l("\u{1F917} Transformers doesn\u2019t automatically create an "),Dt=r("code"),Cr=l("attention_mask"),Ir=l(" to mask a padding token if it is provided because:"),Is=m(),oe=r("ul"),xt=r("li"),Fr=l("Some models don\u2019t have a padding token."),Sr=m(),Mt=r("li"),Ur=l("For some use-cases, users want a model to attend to a padding token."),this.h()},l(e){const o=Wa('[data-svelte="svelte-1phssyn"]',document.head);h=a(o,"META",{name:!0,content:!0}),o.forEach(t),j=f(e),d=a(e,"H1",{class:!0});var Me=n(d);b=a(Me,"A",{id:!0,class:!0,href:!0});var Bt=n(b);A=a(Bt,"SPAN",{});var qr=n(A);v(y.$$.fragment,qr),qr.forEach(t),Bt.forEach(t),k=f(Me),C=a(Me,"SPAN",{});var Dr=n(C);Ks=i(Dr,"Troubleshoot"),Dr.forEach(t),Me.forEach(t),Nt=f(e),Ne=a(e,"P",{});var xr=n(Ne);Ws=i(xr,"Sometimes errors occur, but we are here to help! This guide covers some of the most common issues we\u2019ve seen and how you can resolve them. However, this guide isn\u2019t meant to be a comprehensive collection of every \u{1F917} Transformers issue. For more help with troubleshooting your issue, try:"),xr.forEach(t),Lt=f(e),v(le.$$.fragment,e),Gt=f(e),Le=a(e,"OL",{});var Mr=n(Le);I=a(Mr,"LI",{});var re=n(I);Qs=i(re,"Asking for help on the "),ie=a(re,"A",{href:!0,rel:!0});var Br=n(ie);Xs=i(Br,"forums"),Br.forEach(t),Zs=i(re,". There are specific categories you can post your question to, like "),pe=a(re,"A",{href:!0,rel:!0});var Nr=n(pe);eo=i(Nr,"Beginners"),Nr.forEach(t),to=i(re," or "),me=a(re,"A",{href:!0,rel:!0});var Lr=n(me);so=i(Lr,"\u{1F917} Transformers"),Lr.forEach(t),oo=i(re,". Make sure you write a good descriptive forum post with some reproducible code to maximize the likelihood that your problem is solved!"),re.forEach(t),Mr.forEach(t),Ht=f(e),v(fe.$$.fragment,e),Ot=f(e),S=a(e,"OL",{start:!0});var Ss=n(S);pt=a(Ss,"LI",{});var Gr=n(pt);ue=a(Gr,"P",{});var Us=n(ue);ro=i(Us,"Create an "),he=a(Us,"A",{href:!0,rel:!0});var Hr=n(he);ao=i(Hr,"Issue"),Hr.forEach(t),no=i(Us," on the \u{1F917} Transformers repository if it is a bug related to the library. Try to include as much information describing the bug as possible to help us better figure out what\u2019s wrong and how we can fix it."),Us.forEach(t),Gr.forEach(t),lo=f(Ss),mt=a(Ss,"LI",{});var Or=n(mt);de=a(Or,"P",{});var qs=n(de);io=i(qs,"Check the "),Ge=a(qs,"A",{href:!0});var zr=n(Ge);po=i(zr,"Migration"),zr.forEach(t),mo=i(qs," guide if you use an older version of \u{1F917} Transformers since some important changes have been introduced between versions."),qs.forEach(t),Or.forEach(t),Ss.forEach(t),zt=f(e),H=a(e,"P",{});var Ds=n(H);fo=i(Ds,"For more details about troubleshooting and getting help, take a look at "),ce=a(Ds,"A",{href:!0,rel:!0});var Vr=n(ce);uo=i(Vr,"Chapter 8"),Vr.forEach(t),ho=i(Ds," of the Hugging Face course."),Ds.forEach(t),Vt=f(e),U=a(e,"H2",{class:!0});var xs=n(U);O=a(xs,"A",{id:!0,class:!0,href:!0});var Rr=n(O);ft=a(Rr,"SPAN",{});var Yr=n(ft);v(ve.$$.fragment,Yr),Yr.forEach(t),Rr.forEach(t),co=f(xs),ut=a(xs,"SPAN",{});var Jr=n(ut);vo=i(Jr,"Firewalled environments"),Jr.forEach(t),xs.forEach(t),Rt=f(e),He=a(e,"P",{});var Kr=n(He);go=i(Kr,"Some GPU instances on cloud and intranet setups are firewalled to external connections, resulting in a connection error. When your script attempts to download model weights or datasets, the download will hang and then timeout with the following message:"),Kr.forEach(t),Yt=f(e),v(ge.$$.fragment,e),Jt=f(e),z=a(e,"P",{});var Ms=n(z);_o=i(Ms,"In this case, you should try to run \u{1F917} Transformers on "),Oe=a(Ms,"A",{href:!0});var Wr=n(Oe);wo=i(Wr,"offline mode"),Wr.forEach(t),$o=i(Ms," to avoid the connection error."),Ms.forEach(t),Kt=f(e),q=a(e,"H2",{class:!0});var Bs=n(q);V=a(Bs,"A",{id:!0,class:!0,href:!0});var Qr=n(V);ht=a(Qr,"SPAN",{});var Xr=n(ht);v(_e.$$.fragment,Xr),Xr.forEach(t),Qr.forEach(t),bo=f(Bs),dt=a(Bs,"SPAN",{});var Zr=n(dt);yo=i(Zr,"CUDA out of memory"),Zr.forEach(t),Bs.forEach(t),Wt=f(e),ze=a(e,"P",{});var ea=n(ze);ko=i(ea,"Training large models with millions of parameters can be challenging without the appropriate hardware. A common error you may encounter when the GPU runs out of memory is:"),ea.forEach(t),Qt=f(e),v(we.$$.fragment,e),Xt=f(e),Ve=a(e,"P",{});var ta=n(Ve);Eo=i(ta,"Here are some potential solutions you can try to lessen memory use:"),ta.forEach(t),Zt=f(e),R=a(e,"UL",{});var Ns=n(R);D=a(Ns,"LI",{});var nt=n(D);jo=i(nt,"Reduce the "),Re=a(nt,"A",{href:!0});var sa=n(Re);ct=a(sa,"CODE",{});var oa=n(ct);Ao=i(oa,"per_device_train_batch_size"),oa.forEach(t),sa.forEach(t),To=i(nt," value in "),Ye=a(nt,"A",{href:!0});var ra=n(Ye);Po=i(ra,"TrainingArguments"),ra.forEach(t),Co=i(nt,"."),nt.forEach(t),Io=f(Ns),x=a(Ns,"LI",{});var lt=n(x);Fo=i(lt,"Try using "),Je=a(lt,"A",{href:!0});var aa=n(Je);vt=a(aa,"CODE",{});var na=n(vt);So=i(na,"gradient_accumulation_steps"),na.forEach(t),aa.forEach(t),Uo=i(lt," in "),Ke=a(lt,"A",{href:!0});var la=n(Ke);qo=i(la,"TrainingArguments"),la.forEach(t),Do=i(lt," to effectively increase overall batch size."),lt.forEach(t),Ns.forEach(t),es=f(e),v(Y.$$.fragment,e),ts=f(e),M=a(e,"H2",{class:!0});var Ls=n(M);J=a(Ls,"A",{id:!0,class:!0,href:!0});var ia=n(J);gt=a(ia,"SPAN",{});var pa=n(gt);v($e.$$.fragment,pa),pa.forEach(t),ia.forEach(t),xo=f(Ls),_t=a(Ls,"SPAN",{});var ma=n(_t);Mo=i(ma,"Unable to load a saved TensorFlow model"),ma.forEach(t),Ls.forEach(t),ss=f(e),K=a(e,"P",{});var Gs=n(K);Bo=i(Gs,"TensorFlow\u2019s "),be=a(Gs,"A",{href:!0,rel:!0});var fa=n(be);No=i(fa,"model.save"),fa.forEach(t),Lo=i(Gs," method will save the entire model - architecture, weights, training configuration - in a single file. However, when you load the model file again, you may run into an error because \u{1F917} Transformers may not load all the TensorFlow-related objects in the model file. To avoid issues with saving and loading TensorFlow models, we recommend you:"),Gs.forEach(t),os=f(e),We=a(e,"UL",{});var ua=n(We);F=a(ua,"LI",{});var ae=n(F);Go=i(ae,"Save the model weights as a "),wt=a(ae,"CODE",{});var ha=n(wt);Ho=i(ha,"h5"),ha.forEach(t),Oo=i(ae," file extension with "),ye=a(ae,"A",{href:!0,rel:!0});var da=n(ye);$t=a(da,"CODE",{});var ca=n($t);zo=i(ca,"model.save_weights"),ca.forEach(t),da.forEach(t),Vo=i(ae," and then reload the model with "),Qe=a(ae,"A",{href:!0});var va=n(Qe);Ro=i(va,"from_pretrained()"),va.forEach(t),Yo=i(ae,":"),ae.forEach(t),ua.forEach(t),rs=f(e),v(ke.$$.fragment,e),as=f(e),Xe=a(e,"UL",{});var ga=n(Xe);B=a(ga,"LI",{});var it=n(B);Jo=i(it,"Save the model with "),bt=a(it,"CODE",{});var _a=n(bt);Ko=i(_a,"save_pretrained"),_a.forEach(t),Wo=i(it," and load it again with "),Ze=a(it,"A",{href:!0});var wa=n(Ze);Qo=i(wa,"from_pretrained()"),wa.forEach(t),Xo=i(it,":"),it.forEach(t),ga.forEach(t),ns=f(e),v(Ee.$$.fragment,e),ls=f(e),N=a(e,"H2",{class:!0});var Hs=n(N);W=a(Hs,"A",{id:!0,class:!0,href:!0});var $a=n(W);yt=a($a,"SPAN",{});var ba=n(yt);v(je.$$.fragment,ba),ba.forEach(t),$a.forEach(t),Zo=f(Hs),kt=a(Hs,"SPAN",{});var ya=n(kt);er=i(ya,"ImportError"),ya.forEach(t),Hs.forEach(t),is=f(e),Q=a(e,"P",{});var Os=n(Q);tr=i(Os,"Another common error you may encounter, especially if it is a newly released model, is "),Et=a(Os,"CODE",{});var ka=n(Et);sr=i(ka,"ImportError"),ka.forEach(t),or=i(Os,":"),Os.forEach(t),ps=f(e),v(Ae.$$.fragment,e),ms=f(e),et=a(e,"P",{});var Ea=n(et);rr=i(Ea,"For these error types, check to make sure you have the latest version of \u{1F917} Transformers installed to access the most recent models:"),Ea.forEach(t),fs=f(e),v(Te.$$.fragment,e),us=f(e),L=a(e,"H2",{class:!0});var zs=n(L);X=a(zs,"A",{id:!0,class:!0,href:!0});var ja=n(X);jt=a(ja,"SPAN",{});var Aa=n(jt);v(Pe.$$.fragment,Aa),Aa.forEach(t),ja.forEach(t),ar=f(zs),At=a(zs,"SPAN",{});var Ta=n(At);nr=i(Ta,"CUDA error: device-side assert triggered"),Ta.forEach(t),zs.forEach(t),hs=f(e),tt=a(e,"P",{});var Pa=n(tt);lr=i(Pa,"Sometimes you may run into a generic CUDA error about an error in the device code."),Pa.forEach(t),ds=f(e),v(Ce.$$.fragment,e),cs=f(e),st=a(e,"P",{});var Ca=n(st);ir=i(Ca,"You should try to run the code on a CPU first to get a more descriptive error message. Add the following environment variable to the beginning of your code to switch to a CPU:"),Ca.forEach(t),vs=f(e),v(Ie.$$.fragment,e),gs=f(e),ot=a(e,"P",{});var Ia=n(ot);pr=i(Ia,"Another option is to get a better traceback from the GPU. Add the following environment variable to the beginning of your code to get the traceback to point to the source of the error:"),Ia.forEach(t),_s=f(e),v(Fe.$$.fragment,e),ws=f(e),G=a(e,"H2",{class:!0});var Vs=n(G);Z=a(Vs,"A",{id:!0,class:!0,href:!0});var Fa=n(Z);Tt=a(Fa,"SPAN",{});var Sa=n(Tt);v(Se.$$.fragment,Sa),Sa.forEach(t),Fa.forEach(t),mr=f(Vs),Pt=a(Vs,"SPAN",{});var Ua=n(Pt);fr=i(Ua,"Incorrect output when padding tokens aren't masked"),Ua.forEach(t),Vs.forEach(t),$s=f(e),E=a(e,"P",{});var P=n(E);ur=i(P,"In some cases, the output "),Ct=a(P,"CODE",{});var qa=n(Ct);hr=i(qa,"hidden_state"),qa.forEach(t),dr=i(P," may be incorrect if the "),It=a(P,"CODE",{});var Da=n(It);cr=i(Da,"input_ids"),Da.forEach(t),vr=i(P," include padding tokens. To demonstrate, load a model and tokenizer. You can access a model\u2019s "),Ft=a(P,"CODE",{});var xa=n(Ft);gr=i(xa,"pad_token_id"),xa.forEach(t),_r=i(P," to see its value. The "),St=a(P,"CODE",{});var Ma=n(St);wr=i(Ma,"pad_token_id"),Ma.forEach(t),$r=i(P," may be "),Ut=a(P,"CODE",{});var Ba=n(Ut);br=i(Ba,"None"),Ba.forEach(t),yr=i(P," for some models, but you can always manually set it."),P.forEach(t),bs=f(e),v(Ue.$$.fragment,e),ys=f(e),rt=a(e,"P",{});var Na=n(rt);kr=i(Na,"The following example shows the output without masking the padding tokens:"),Na.forEach(t),ks=f(e),v(qe.$$.fragment,e),Es=f(e),at=a(e,"P",{});var La=n(at);Er=i(La,"Here is the actual output of the second sequence:"),La.forEach(t),js=f(e),v(De.$$.fragment,e),As=f(e),ee=a(e,"P",{});var Rs=n(ee);jr=i(Rs,"Most of the time, you should provide an "),qt=a(Rs,"CODE",{});var Ga=n(qt);Ar=i(Ga,"attention_mask"),Ga.forEach(t),Tr=i(Rs," to your model to ignore the padding tokens to avoid this silent error. Now the output of the second sequence matches its actual output:"),Rs.forEach(t),Ts=f(e),v(te.$$.fragment,e),Ps=f(e),v(xe.$$.fragment,e),Cs=f(e),se=a(e,"P",{});var Ys=n(se);Pr=i(Ys,"\u{1F917} Transformers doesn\u2019t automatically create an "),Dt=a(Ys,"CODE",{});var Ha=n(Dt);Cr=i(Ha,"attention_mask"),Ha.forEach(t),Ir=i(Ys," to mask a padding token if it is provided because:"),Ys.forEach(t),Is=f(e),oe=a(e,"UL",{});var Js=n(oe);xt=a(Js,"LI",{});var Oa=n(xt);Fr=i(Oa,"Some models don\u2019t have a padding token."),Oa.forEach(t),Sr=f(Js),Mt=a(Js,"LI",{});var za=n(Mt);Ur=i(za,"For some use-cases, users want a model to attend to a padding token."),za.forEach(t),Js.forEach(t),this.h()},h(){u(h,"name","hf:doc:metadata"),u(h,"content",JSON.stringify(en)),u(b,"id","troubleshoot"),u(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(b,"href","#troubleshoot"),u(d,"class","relative group"),u(ie,"href","https://discuss.huggingface.co/"),u(ie,"rel","nofollow"),u(pe,"href","https://discuss.huggingface.co/c/beginners/5"),u(pe,"rel","nofollow"),u(me,"href","https://discuss.huggingface.co/c/transformers/9"),u(me,"rel","nofollow"),u(he,"href","https://github.com/huggingface/transformers/issues/new/choose"),u(he,"rel","nofollow"),u(Ge,"href","migration"),u(S,"start","2"),u(ce,"href","https://huggingface.co/course/chapter8/1?fw=pt"),u(ce,"rel","nofollow"),u(O,"id","firewalled-environments"),u(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(O,"href","#firewalled-environments"),u(U,"class","relative group"),u(Oe,"href","installation#offline-mode"),u(V,"id","cuda-out-of-memory"),u(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(V,"href","#cuda-out-of-memory"),u(q,"class","relative group"),u(Re,"href","main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size"),u(Ye,"href","/docs/transformers/pr_16318/en/main_classes/trainer#transformers.TrainingArguments"),u(Je,"href","main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps"),u(Ke,"href","/docs/transformers/pr_16318/en/main_classes/trainer#transformers.TrainingArguments"),u(J,"id","unable-to-load-a-saved-tensorflow-model"),u(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(J,"href","#unable-to-load-a-saved-tensorflow-model"),u(M,"class","relative group"),u(be,"href","https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model"),u(be,"rel","nofollow"),u(ye,"href","https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model"),u(ye,"rel","nofollow"),u(Qe,"href","/docs/transformers/pr_16318/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained"),u(Ze,"href","/docs/transformers/pr_16318/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained"),u(W,"id","importerror"),u(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(W,"href","#importerror"),u(N,"class","relative group"),u(X,"id","cuda-error-deviceside-assert-triggered"),u(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(X,"href","#cuda-error-deviceside-assert-triggered"),u(L,"class","relative group"),u(Z,"id","incorrect-output-when-padding-tokens-arent-masked"),u(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Z,"href","#incorrect-output-when-padding-tokens-arent-masked"),u(G,"class","relative group")},m(e,o){s(document.head,h),p(e,j,o),p(e,d,o),s(d,b),s(b,A),g(y,A,null),s(d,k),s(d,C),s(C,Ks),p(e,Nt,o),p(e,Ne,o),s(Ne,Ws),p(e,Lt,o),g(le,e,o),p(e,Gt,o),p(e,Le,o),s(Le,I),s(I,Qs),s(I,ie),s(ie,Xs),s(I,Zs),s(I,pe),s(pe,eo),s(I,to),s(I,me),s(me,so),s(I,oo),p(e,Ht,o),g(fe,e,o),p(e,Ot,o),p(e,S,o),s(S,pt),s(pt,ue),s(ue,ro),s(ue,he),s(he,ao),s(ue,no),s(S,lo),s(S,mt),s(mt,de),s(de,io),s(de,Ge),s(Ge,po),s(de,mo),p(e,zt,o),p(e,H,o),s(H,fo),s(H,ce),s(ce,uo),s(H,ho),p(e,Vt,o),p(e,U,o),s(U,O),s(O,ft),g(ve,ft,null),s(U,co),s(U,ut),s(ut,vo),p(e,Rt,o),p(e,He,o),s(He,go),p(e,Yt,o),g(ge,e,o),p(e,Jt,o),p(e,z,o),s(z,_o),s(z,Oe),s(Oe,wo),s(z,$o),p(e,Kt,o),p(e,q,o),s(q,V),s(V,ht),g(_e,ht,null),s(q,bo),s(q,dt),s(dt,yo),p(e,Wt,o),p(e,ze,o),s(ze,ko),p(e,Qt,o),g(we,e,o),p(e,Xt,o),p(e,Ve,o),s(Ve,Eo),p(e,Zt,o),p(e,R,o),s(R,D),s(D,jo),s(D,Re),s(Re,ct),s(ct,Ao),s(D,To),s(D,Ye),s(Ye,Po),s(D,Co),s(R,Io),s(R,x),s(x,Fo),s(x,Je),s(Je,vt),s(vt,So),s(x,Uo),s(x,Ke),s(Ke,qo),s(x,Do),p(e,es,o),g(Y,e,o),p(e,ts,o),p(e,M,o),s(M,J),s(J,gt),g($e,gt,null),s(M,xo),s(M,_t),s(_t,Mo),p(e,ss,o),p(e,K,o),s(K,Bo),s(K,be),s(be,No),s(K,Lo),p(e,os,o),p(e,We,o),s(We,F),s(F,Go),s(F,wt),s(wt,Ho),s(F,Oo),s(F,ye),s(ye,$t),s($t,zo),s(F,Vo),s(F,Qe),s(Qe,Ro),s(F,Yo),p(e,rs,o),g(ke,e,o),p(e,as,o),p(e,Xe,o),s(Xe,B),s(B,Jo),s(B,bt),s(bt,Ko),s(B,Wo),s(B,Ze),s(Ze,Qo),s(B,Xo),p(e,ns,o),g(Ee,e,o),p(e,ls,o),p(e,N,o),s(N,W),s(W,yt),g(je,yt,null),s(N,Zo),s(N,kt),s(kt,er),p(e,is,o),p(e,Q,o),s(Q,tr),s(Q,Et),s(Et,sr),s(Q,or),p(e,ps,o),g(Ae,e,o),p(e,ms,o),p(e,et,o),s(et,rr),p(e,fs,o),g(Te,e,o),p(e,us,o),p(e,L,o),s(L,X),s(X,jt),g(Pe,jt,null),s(L,ar),s(L,At),s(At,nr),p(e,hs,o),p(e,tt,o),s(tt,lr),p(e,ds,o),g(Ce,e,o),p(e,cs,o),p(e,st,o),s(st,ir),p(e,vs,o),g(Ie,e,o),p(e,gs,o),p(e,ot,o),s(ot,pr),p(e,_s,o),g(Fe,e,o),p(e,ws,o),p(e,G,o),s(G,Z),s(Z,Tt),g(Se,Tt,null),s(G,mr),s(G,Pt),s(Pt,fr),p(e,$s,o),p(e,E,o),s(E,ur),s(E,Ct),s(Ct,hr),s(E,dr),s(E,It),s(It,cr),s(E,vr),s(E,Ft),s(Ft,gr),s(E,_r),s(E,St),s(St,wr),s(E,$r),s(E,Ut),s(Ut,br),s(E,yr),p(e,bs,o),g(Ue,e,o),p(e,ys,o),p(e,rt,o),s(rt,kr),p(e,ks,o),g(qe,e,o),p(e,Es,o),p(e,at,o),s(at,Er),p(e,js,o),g(De,e,o),p(e,As,o),p(e,ee,o),s(ee,jr),s(ee,qt),s(qt,Ar),s(ee,Tr),p(e,Ts,o),g(te,e,o),p(e,Ps,o),g(xe,e,o),p(e,Cs,o),p(e,se,o),s(se,Pr),s(se,Dt),s(Dt,Cr),s(se,Ir),p(e,Is,o),p(e,oe,o),s(oe,xt),s(xt,Fr),s(oe,Sr),s(oe,Mt),s(Mt,Ur),Fs=!0},p(e,[o]){const Me={};o&2&&(Me.$$scope={dirty:o,ctx:e}),Y.$set(Me);const Bt={};o&2&&(Bt.$$scope={dirty:o,ctx:e}),te.$set(Bt)},i(e){Fs||(_(y.$$.fragment,e),_(le.$$.fragment,e),_(fe.$$.fragment,e),_(ve.$$.fragment,e),_(ge.$$.fragment,e),_(_e.$$.fragment,e),_(we.$$.fragment,e),_(Y.$$.fragment,e),_($e.$$.fragment,e),_(ke.$$.fragment,e),_(Ee.$$.fragment,e),_(je.$$.fragment,e),_(Ae.$$.fragment,e),_(Te.$$.fragment,e),_(Pe.$$.fragment,e),_(Ce.$$.fragment,e),_(Ie.$$.fragment,e),_(Fe.$$.fragment,e),_(Se.$$.fragment,e),_(Ue.$$.fragment,e),_(qe.$$.fragment,e),_(De.$$.fragment,e),_(te.$$.fragment,e),_(xe.$$.fragment,e),Fs=!0)},o(e){w(y.$$.fragment,e),w(le.$$.fragment,e),w(fe.$$.fragment,e),w(ve.$$.fragment,e),w(ge.$$.fragment,e),w(_e.$$.fragment,e),w(we.$$.fragment,e),w(Y.$$.fragment,e),w($e.$$.fragment,e),w(ke.$$.fragment,e),w(Ee.$$.fragment,e),w(je.$$.fragment,e),w(Ae.$$.fragment,e),w(Te.$$.fragment,e),w(Pe.$$.fragment,e),w(Ce.$$.fragment,e),w(Ie.$$.fragment,e),w(Fe.$$.fragment,e),w(Se.$$.fragment,e),w(Ue.$$.fragment,e),w(qe.$$.fragment,e),w(De.$$.fragment,e),w(te.$$.fragment,e),w(xe.$$.fragment,e),Fs=!1},d(e){t(h),e&&t(j),e&&t(d),$(y),e&&t(Nt),e&&t(Ne),e&&t(Lt),$(le,e),e&&t(Gt),e&&t(Le),e&&t(Ht),$(fe,e),e&&t(Ot),e&&t(S),e&&t(zt),e&&t(H),e&&t(Vt),e&&t(U),$(ve),e&&t(Rt),e&&t(He),e&&t(Yt),$(ge,e),e&&t(Jt),e&&t(z),e&&t(Kt),e&&t(q),$(_e),e&&t(Wt),e&&t(ze),e&&t(Qt),$(we,e),e&&t(Xt),e&&t(Ve),e&&t(Zt),e&&t(R),e&&t(es),$(Y,e),e&&t(ts),e&&t(M),$($e),e&&t(ss),e&&t(K),e&&t(os),e&&t(We),e&&t(rs),$(ke,e),e&&t(as),e&&t(Xe),e&&t(ns),$(Ee,e),e&&t(ls),e&&t(N),$(je),e&&t(is),e&&t(Q),e&&t(ps),$(Ae,e),e&&t(ms),e&&t(et),e&&t(fs),$(Te,e),e&&t(us),e&&t(L),$(Pe),e&&t(hs),e&&t(tt),e&&t(ds),$(Ce,e),e&&t(cs),e&&t(st),e&&t(vs),$(Ie,e),e&&t(gs),e&&t(ot),e&&t(_s),$(Fe,e),e&&t(ws),e&&t(G),$(Se),e&&t($s),e&&t(E),e&&t(bs),$(Ue,e),e&&t(ys),e&&t(rt),e&&t(ks),$(qe,e),e&&t(Es),e&&t(at),e&&t(js),$(De,e),e&&t(As),e&&t(ee),e&&t(Ts),$(te,e),e&&t(Ps),$(xe,e),e&&t(Cs),e&&t(se),e&&t(Is),e&&t(oe)}}}const en={local:"troubleshoot",sections:[{local:"firewalled-environments",title:"Firewalled environments"},{local:"cuda-out-of-memory",title:"CUDA out of memory"},{local:"unable-to-load-a-saved-tensorflow-model",title:"Unable to load a saved TensorFlow model"},{local:"importerror",title:"ImportError"},{local:"cuda-error-deviceside-assert-triggered",title:"CUDA error: device-side assert triggered"},{local:"incorrect-output-when-padding-tokens-arent-masked",title:"Incorrect output when padding tokens aren't masked"}],title:"Troubleshoot"};function tn(ne,h,j){let{fw:d}=h;return ne.$$set=b=>{"fw"in b&&j(0,d=b.fw)},[d]}class ln extends Ya{constructor(h){super();Ja(this,h,tn,Za,Ka,{fw:0})}}export{ln as default,en as metadata};
