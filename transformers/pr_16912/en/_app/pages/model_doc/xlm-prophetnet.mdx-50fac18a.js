import{S as Sn,i as In,s as Fn,e as r,k as p,w as m,t as i,M as Gn,c as o,d as s,m as d,a as n,x as u,h as l,b as a,F as t,g as c,y as f,L as Bn,q as g,o as _,B as k,v as Rn}from"../../chunks/vendor-6b77c823.js";import{D as y}from"../../chunks/Docstring-1088f2fb.js";import{C as Gt}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as B}from"../../chunks/IconCopyLink-7a11ce68.js";function On(zo){let x,Bt,E,R,pt,pe,Ts,dt,Ds,Rt,X,ht,Cs,As,de,Ss,Is,Ot,j,O,ct,he,Fs,mt,Gs,Ht,H,Bs,ce,Rs,Os,Vt,We,Hs,Wt,Ue,Vs,Ut,Ye,ut,Ws,Yt,V,Us,me,Ys,Js,Jt,z,W,ft,ue,Qs,gt,Zs,Qt,T,fe,Ks,D,er,Je,tr,sr,ge,rr,or,Zt,C,U,_t,_e,nr,kt,ar,Kt,v,ke,ir,M,lr,Qe,pr,dr,Ze,hr,cr,ve,mr,ur,fr,be,gr,Ke,_r,kr,vr,q,Pe,br,vt,Pr,wr,we,et,Nr,bt,Lr,$r,tt,Mr,Pt,yr,qr,Y,Ne,xr,wt,Er,Xr,J,Le,jr,Nt,zr,Tr,Q,$e,Dr,Me,Cr,Lt,Ar,Sr,es,A,Z,$t,ye,Ir,Mt,Fr,ts,P,qe,Gr,xe,Br,st,Rr,Or,Hr,yt,Vr,Wr,Ee,ss,S,K,qt,Xe,Ur,xt,Yr,rs,w,je,Jr,ze,Qr,rt,Zr,Kr,eo,Et,to,so,Te,os,I,ee,Xt,De,ro,jt,oo,ns,N,Ce,no,Ae,ao,ot,io,lo,po,zt,ho,co,Se,as,F,te,Tt,Ie,mo,Dt,uo,is,L,Fe,fo,Ge,go,nt,_o,ko,vo,Ct,bo,Po,Be,ls,G,se,At,Re,wo,St,No,ps,$,Oe,Lo,He,$o,at,Mo,yo,qo,It,xo,Eo,Ve,ds;return pe=new B({}),he=new B({}),ue=new B({}),fe=new y({props:{name:"class transformers.XLMProphetNetConfig",anchor:"transformers.XLMProphetNetConfig",parameters:[{name:"activation_dropout",val:" = 0.1"},{name:"activation_function",val:" = 'gelu'"},{name:"vocab_size",val:" = 30522"},{name:"hidden_size",val:" = 1024"},{name:"encoder_ffn_dim",val:" = 4096"},{name:"num_encoder_layers",val:" = 12"},{name:"num_encoder_attention_heads",val:" = 16"},{name:"decoder_ffn_dim",val:" = 4096"},{name:"num_decoder_layers",val:" = 12"},{name:"num_decoder_attention_heads",val:" = 16"},{name:"attention_dropout",val:" = 0.1"},{name:"dropout",val:" = 0.1"},{name:"max_position_embeddings",val:" = 512"},{name:"init_std",val:" = 0.02"},{name:"is_encoder_decoder",val:" = True"},{name:"add_cross_attention",val:" = True"},{name:"decoder_start_token_id",val:" = 0"},{name:"ngram",val:" = 2"},{name:"num_buckets",val:" = 32"},{name:"relative_max_distance",val:" = 128"},{name:"disable_ngram_loss",val:" = False"},{name:"eps",val:" = 0.0"},{name:"use_cache",val:" = True"},{name:"pad_token_id",val:" = 0"},{name:"bos_token_id",val:" = 1"},{name:"eos_token_id",val:" = 2"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/configuration_xlm_prophetnet.py#L29"}}),_e=new B({}),ke=new y({props:{name:"class transformers.XLMProphetNetTokenizer",anchor:"transformers.XLMProphetNetTokenizer",parameters:[{name:"vocab_file",val:""},{name:"bos_token",val:" = '[SEP]'"},{name:"eos_token",val:" = '[SEP]'"},{name:"sep_token",val:" = '[SEP]'"},{name:"unk_token",val:" = '[UNK]'"},{name:"pad_token",val:" = '[PAD]'"},{name:"cls_token",val:" = '[CLS]'"},{name:"mask_token",val:" = '[MASK]'"},{name:"sp_model_kwargs",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.vocab_file",description:`<strong>vocab_file</strong> (<code>str</code>) &#x2014;
Path to the vocabulary file.`,name:"vocab_file"},{anchor:"transformers.XLMProphetNetTokenizer.bos_token",description:`<strong>bos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The beginning of sequence token that was used during pretraining. Can be used a sequence classifier token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the beginning of
sequence. The token used is the <code>cls_token</code>.</p>

					</div>`,name:"bos_token"},{anchor:"transformers.XLMProphetNetTokenizer.eos_token",description:`<strong>eos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The end of sequence token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the end of sequence.
The token used is the <code>sep_token</code>.</p>

					</div>`,name:"eos_token"},{anchor:"transformers.XLMProphetNetTokenizer.sep_token",description:`<strong>sep_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for
sequence classification or for a text and a question for question answering. It is also used as the last
token of a sequence built with special tokens.`,name:"sep_token"},{anchor:"transformers.XLMProphetNetTokenizer.cls_token",description:`<strong>cls_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The classifier token which is used when doing sequence classification (classification of the whole sequence
instead of per-token classification). It is the first token of the sequence when built with special tokens.`,name:"cls_token"},{anchor:"transformers.XLMProphetNetTokenizer.unk_token",description:`<strong>unk_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;unk&gt;&quot;</code>) &#x2014;
The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
token instead.`,name:"unk_token"},{anchor:"transformers.XLMProphetNetTokenizer.pad_token",description:`<strong>pad_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;pad&gt;&quot;</code>) &#x2014;
The token used for padding, for example when batching sequences of different lengths.`,name:"pad_token"},{anchor:"transformers.XLMProphetNetTokenizer.mask_token",description:`<strong>mask_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;mask&gt;&quot;</code>) &#x2014;
The token used for masking values. This is the token used when training this model with masked language
modeling. This is the token which the model will try to predict.`,name:"mask_token"},{anchor:"transformers.XLMProphetNetTokenizer.additional_special_tokens",description:`<strong>additional_special_tokens</strong> (<code>List[str]</code>, <em>optional</em>, defaults to <code>[&quot;&lt;s&gt;NOTUSED&quot;, &quot;&lt;/s&gt;NOTUSED&quot;]</code>) &#x2014;
Additional special tokens used by the tokenizer.`,name:"additional_special_tokens"},{anchor:"transformers.XLMProphetNetTokenizer.sp_model_kwargs",description:`<strong>sp_model_kwargs</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Will be passed to the <code>SentencePieceProcessor.__init__()</code> method. The <a href="https://github.com/google/sentencepiece/tree/master/python" rel="nofollow">Python wrapper for
SentencePiece</a> can be used, among other things,
to set:</p>
<ul>
<li>
<p><code>enable_sampling</code>: Enable subword regularization.</p>
</li>
<li>
<p><code>nbest_size</code>: Sampling parameters for unigram. Invalid for BPE-Dropout.</p>
<ul>
<li><code>nbest_size = {0,1}</code>: No sampling is performed.</li>
<li><code>nbest_size &gt; 1</code>: samples from the nbest_size results.</li>
<li><code>nbest_size &lt; 0</code>: assuming that nbest_size is infinite and samples from the all hypothesis (lattice)
using forward-filtering-and-backward-sampling algorithm.</li>
</ul>
</li>
<li>
<p><code>alpha</code>: Smoothing parameter for unigram sampling, and dropout probability of merge operations for
BPE-dropout.</p>
</li>
</ul>`,name:"sp_model_kwargs"},{anchor:"transformers.XLMProphetNetTokenizer.sp_model",description:`<strong>sp_model</strong> (<code>SentencePieceProcessor</code>) &#x2014;
The <em>SentencePiece</em> processor that is used for every conversion (string, tokens and IDs).`,name:"sp_model"}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L57"}}),Pe=new y({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.XLMProphetNetTokenizer.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added`,name:"token_ids_0"},{anchor:"transformers.XLMProphetNetTokenizer.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L314",returnDescription:`
<p>list of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Ne=new y({props:{name:"convert_tokens_to_string",anchor:"transformers.XLMProphetNetTokenizer.convert_tokens_to_string",parameters:[{name:"tokens",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L292"}}),Le=new y({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.XLMProphetNetTokenizer.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.XLMProphetNetTokenizer.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L241",returnDescription:`
<p>List of zeros.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),$e=new y({props:{name:"get_special_tokens_mask",anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"},{name:"already_has_special_tokens",val:": bool = False"}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"},{anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask.already_has_special_tokens",description:`<strong>already_has_special_tokens</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the token list is already formatted with special tokens for the model.`,name:"already_has_special_tokens"}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L213",returnDescription:`
<p>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),ye=new B({}),qe=new y({props:{name:"class transformers.XLMProphetNetModel",anchor:"transformers.XLMProphetNetModel",parameters:[{name:"config",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L86"}}),Ee=new Gt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetModel

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetModel.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")

input_ids = tokenizer(
    "Studies have been shown that owning a dog is good for you", return_tensors="pt"
).input_ids  # Batch size 1
decoder_input_ids = tokenizer("Studies show that", return_tensors="pt").input_ids  # Batch size 1
outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

last_hidden_states = outputs.last_hidden_state  # main stream hidden states
last_hidden_states_ngram = outputs.last_hidden_state_ngram  # predict hidden states`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetModel.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = tokenizer(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Studies have been shown that owning a dog is good for you&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>decoder_input_ids = tokenizer(<span class="hljs-string">&quot;Studies show that&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state  <span class="hljs-comment"># main stream hidden states</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states_ngram = outputs.last_hidden_state_ngram  <span class="hljs-comment"># predict hidden states</span>`}}),Xe=new B({}),je=new y({props:{name:"class transformers.XLMProphetNetEncoder",anchor:"transformers.XLMProphetNetEncoder",parameters:[{name:"config",val:": ProphetNetConfig"},{name:"word_embeddings",val:": Embedding = None"}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L38"}}),Te=new Gt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetEncoder
import torch

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetEncoder.from_pretrained("patrickvonplaten/xprophetnet-large-uncased-standalone")
assert model.config.is_decoder, f"{model.__class__} has to be configured as a decoder."
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetEncoder
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetEncoder.from_pretrained(<span class="hljs-string">&quot;patrickvonplaten/xprophetnet-large-uncased-standalone&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">assert</span> model.config.is_decoder, <span class="hljs-string">f&quot;<span class="hljs-subst">{model.__class__}</span> has to be configured as a decoder.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),De=new B({}),Ce=new y({props:{name:"class transformers.XLMProphetNetDecoder",anchor:"transformers.XLMProphetNetDecoder",parameters:[{name:"config",val:": ProphetNetConfig"},{name:"word_embeddings",val:": Embedding = None"}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L61"}}),Se=new Gt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetDecoder
import torch

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetDecoder.from_pretrained(
    "patrickvonplaten/xprophetnet-large-uncased-standalone", add_cross_attention=False
)
assert model.config.is_decoder, f"{model.__class__} has to be configured as a decoder."
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetDecoder
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetDecoder.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;patrickvonplaten/xprophetnet-large-uncased-standalone&quot;</span>, add_cross_attention=<span class="hljs-literal">False</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">assert</span> model.config.is_decoder, <span class="hljs-string">f&quot;<span class="hljs-subst">{model.__class__}</span> has to be configured as a decoder.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),Ie=new B({}),Fe=new y({props:{name:"class transformers.XLMProphetNetForConditionalGeneration",anchor:"transformers.XLMProphetNetForConditionalGeneration",parameters:[{name:"config",val:": ProphetNetConfig"}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L112"}}),Be=new Gt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetForConditionalGeneration

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetForConditionalGeneration.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")

input_ids = tokenizer(
    "Studies have been shown that owning a dog is good for you", return_tensors="pt"
).input_ids  # Batch size 1
decoder_input_ids = tokenizer("Studies show that", return_tensors="pt").input_ids  # Batch size 1
outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

logits_next_token = outputs.logits  # logits to predict next token as usual
logits_ngram_next_tokens = outputs.logits_ngram  # logits to predict 2nd, 3rd, ... next tokens`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetForConditionalGeneration

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetForConditionalGeneration.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = tokenizer(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Studies have been shown that owning a dog is good for you&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>decoder_input_ids = tokenizer(<span class="hljs-string">&quot;Studies show that&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

<span class="hljs-meta">&gt;&gt;&gt; </span>logits_next_token = outputs.logits  <span class="hljs-comment"># logits to predict next token as usual</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>logits_ngram_next_tokens = outputs.logits_ngram  <span class="hljs-comment"># logits to predict 2nd, 3rd, ... next tokens</span>`}}),Re=new B({}),Oe=new y({props:{name:"class transformers.XLMProphetNetForCausalLM",anchor:"transformers.XLMProphetNetForCausalLM",parameters:[{name:"config",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16912/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L138"}}),Ve=new Gt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetForCausalLM
import torch

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetForCausalLM.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
assert model.config.is_decoder, f"{model.__class__} has to be configured as a decoder."
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

logits = outputs.logits

# Model can also be used with EncoderDecoder framework
from transformers import EncoderDecoderModel, XLMProphetNetTokenizer, XLMRobertaTokenizer
import torch

tokenizer_enc = XLMRobertaTokenizer.from_pretrained("xlm-roberta-large")
tokenizer_dec = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = EncoderDecoderModel.from_encoder_decoder_pretrained(
    "xlm-roberta-large", "microsoft/xprophetnet-large-wiki100-cased"
)

ARTICLE = (
    "the us state department said wednesday it had received no "
    "formal word from bolivia that it was expelling the us ambassador there "
    "but said the charges made against him are \`\` baseless ."
)
input_ids = tokenizer_enc(ARTICLE, return_tensors="pt").input_ids
labels = tokenizer_dec("us rejects charges against its ambassador in bolivia", return_tensors="pt").input_ids
outputs = model(input_ids=input_ids, decoder_input_ids=labels[:, :-1], labels=labels[:, 1:])

loss = outputs.loss`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetForCausalLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetForCausalLM.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">assert</span> model.config.is_decoder, <span class="hljs-string">f&quot;<span class="hljs-subst">{model.__class__}</span> has to be configured as a decoder.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Model can also be used with EncoderDecoder framework</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> EncoderDecoderModel, XLMProphetNetTokenizer, XLMRobertaTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer_enc = XLMRobertaTokenizer.from_pretrained(<span class="hljs-string">&quot;xlm-roberta-large&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer_dec = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = EncoderDecoderModel.from_encoder_decoder_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;xlm-roberta-large&quot;</span>, <span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>ARTICLE = (
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;the us state department said wednesday it had received no &quot;</span>
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;formal word from bolivia that it was expelling the us ambassador there &quot;</span>
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;but said the charges made against him are \`\` baseless .&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = tokenizer_enc(ARTICLE, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = tokenizer_dec(<span class="hljs-string">&quot;us rejects charges against its ambassador in bolivia&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, decoder_input_ids=labels[:, :-<span class="hljs-number">1</span>], labels=labels[:, <span class="hljs-number">1</span>:])

<span class="hljs-meta">&gt;&gt;&gt; </span>loss = outputs.loss`}}),{c(){x=r("meta"),Bt=p(),E=r("h1"),R=r("a"),pt=r("span"),m(pe.$$.fragment),Ts=p(),dt=r("span"),Ds=i("XLM-ProphetNet"),Rt=p(),X=r("p"),ht=r("strong"),Cs=i("DISCLAIMER:"),As=i(" If you see something strange, file a "),de=r("a"),Ss=i("Github Issue"),Is=i(` and assign
@patrickvonplaten`),Ot=p(),j=r("h2"),O=r("a"),ct=r("span"),m(he.$$.fragment),Fs=p(),mt=r("span"),Gs=i("Overview"),Ht=p(),H=r("p"),Bs=i("The XLM-ProphetNet model was proposed in "),ce=r("a"),Rs=i("ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training,"),Os=i(` by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei
Zhang, Ming Zhou on 13 Jan, 2020.`),Vt=p(),We=r("p"),Hs=i(`XLM-ProphetNet is an encoder-decoder model and can predict n-future tokens for \u201Cngram\u201D language modeling instead of
just the next token. Its architecture is identical to ProhpetNet, but the model was trained on the multi-lingual
\u201Cwiki100\u201D Wikipedia dump.`),Wt=p(),Ue=r("p"),Vs=i("The abstract from the paper is the following:"),Ut=p(),Ye=r("p"),ut=r("em"),Ws=i(`In this paper, we present a new sequence-to-sequence pretraining model called ProphetNet, which introduces a novel
self-supervised objective named future n-gram prediction and the proposed n-stream self-attention mechanism. Instead of
the optimization of one-step ahead prediction in traditional sequence-to-sequence model, the ProphetNet is optimized by
n-step ahead prediction which predicts the next n tokens simultaneously based on previous context tokens at each time
step. The future n-gram prediction explicitly encourages the model to plan for the future tokens and prevent
overfitting on strong local correlations. We pre-train ProphetNet using a base scale dataset (16GB) and a large scale
dataset (160GB) respectively. Then we conduct experiments on CNN/DailyMail, Gigaword, and SQuAD 1.1 benchmarks for
abstractive summarization and question generation tasks. Experimental results show that ProphetNet achieves new
state-of-the-art results on all these datasets compared to the models using the same scale pretraining corpus.`),Yt=p(),V=r("p"),Us=i("The Authors\u2019 code can be found "),me=r("a"),Ys=i("here"),Js=i("."),Jt=p(),z=r("h2"),W=r("a"),ft=r("span"),m(ue.$$.fragment),Qs=p(),gt=r("span"),Zs=i("XLMProphetNetConfig"),Qt=p(),T=r("div"),m(fe.$$.fragment),Ks=p(),D=r("p"),er=i("This class overrides "),Je=r("a"),tr=i("ProphetNetConfig"),sr=i(`. Please check the superclass for the appropriate documentation alongside
usage examples. Instantiating a configuration with the defaults will yield a similar configuration to that of the
XLMProphetNet
`),ge=r("a"),rr=i("microsoft/xprophetnet-large-wiki100-cased"),or=i(`
architecture.`),Zt=p(),C=r("h2"),U=r("a"),_t=r("span"),m(_e.$$.fragment),nr=p(),kt=r("span"),ar=i("XLMProphetNetTokenizer"),Kt=p(),v=r("div"),m(ke.$$.fragment),ir=p(),M=r("p"),lr=i("Adapted from "),Qe=r("a"),pr=i("RobertaTokenizer"),dr=i(" and "),Ze=r("a"),hr=i("XLNetTokenizer"),cr=i(`. Based on
`),ve=r("a"),mr=i("SentencePiece"),ur=i("."),fr=p(),be=r("p"),gr=i("This tokenizer inherits from "),Ke=r("a"),_r=i("PreTrainedTokenizer"),kr=i(` which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.`),vr=p(),q=r("div"),m(Pe.$$.fragment),br=p(),vt=r("p"),Pr=i(`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A XLMProphetNet sequence has the following format:`),wr=p(),we=r("ul"),et=r("li"),Nr=i("single sequence: "),bt=r("code"),Lr=i("X [SEP]"),$r=p(),tt=r("li"),Mr=i("pair of sequences: "),Pt=r("code"),yr=i("A [SEP] B [SEP]"),qr=p(),Y=r("div"),m(Ne.$$.fragment),xr=p(),wt=r("p"),Er=i("Converts a sequence of tokens (strings for sub-words) in a single string."),Xr=p(),J=r("div"),m(Le.$$.fragment),jr=p(),Nt=r("p"),zr=i(`Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLMProphetNet
does not make use of token type ids, therefore a list of zeros is returned.`),Tr=p(),Q=r("div"),m($e.$$.fragment),Dr=p(),Me=r("p"),Cr=i(`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),Lt=r("code"),Ar=i("prepare_for_model"),Sr=i(" method."),es=p(),A=r("h2"),Z=r("a"),$t=r("span"),m(ye.$$.fragment),Ir=p(),Mt=r("span"),Fr=i("XLMProphetNetModel"),ts=p(),P=r("div"),m(qe.$$.fragment),Gr=p(),xe=r("p"),Br=i("This class overrides "),st=r("a"),Rr=i("ProphetNetModel"),Or=i(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),Hr=p(),yt=r("p"),Vr=i("Example:"),Wr=p(),m(Ee.$$.fragment),ss=p(),S=r("h2"),K=r("a"),qt=r("span"),m(Xe.$$.fragment),Ur=p(),xt=r("span"),Yr=i("XLMProphetNetEncoder"),rs=p(),w=r("div"),m(je.$$.fragment),Jr=p(),ze=r("p"),Qr=i("This class overrides "),rt=r("a"),Zr=i("ProphetNetEncoder"),Kr=i(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),eo=p(),Et=r("p"),to=i("Example:"),so=p(),m(Te.$$.fragment),os=p(),I=r("h2"),ee=r("a"),Xt=r("span"),m(De.$$.fragment),ro=p(),jt=r("span"),oo=i("XLMProphetNetDecoder"),ns=p(),N=r("div"),m(Ce.$$.fragment),no=p(),Ae=r("p"),ao=i("This class overrides "),ot=r("a"),io=i("ProphetNetDecoder"),lo=i(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),po=p(),zt=r("p"),ho=i("Example:"),co=p(),m(Se.$$.fragment),as=p(),F=r("h2"),te=r("a"),Tt=r("span"),m(Ie.$$.fragment),mo=p(),Dt=r("span"),uo=i("XLMProphetNetForConditionalGeneration"),is=p(),L=r("div"),m(Fe.$$.fragment),fo=p(),Ge=r("p"),go=i("This class overrides "),nt=r("a"),_o=i("ProphetNetForConditionalGeneration"),ko=i(`. Please check the superclass for the appropriate
documentation alongside usage examples.`),vo=p(),Ct=r("p"),bo=i("Example:"),Po=p(),m(Be.$$.fragment),ls=p(),G=r("h2"),se=r("a"),At=r("span"),m(Re.$$.fragment),wo=p(),St=r("span"),No=i("XLMProphetNetForCausalLM"),ps=p(),$=r("div"),m(Oe.$$.fragment),Lo=p(),He=r("p"),$o=i("This class overrides "),at=r("a"),Mo=i("ProphetNetForCausalLM"),yo=i(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),qo=p(),It=r("p"),xo=i("Example:"),Eo=p(),m(Ve.$$.fragment),this.h()},l(e){const h=Gn('[data-svelte="svelte-1phssyn"]',document.head);x=o(h,"META",{name:!0,content:!0}),h.forEach(s),Bt=d(e),E=o(e,"H1",{class:!0});var hs=n(E);R=o(hs,"A",{id:!0,class:!0,href:!0});var To=n(R);pt=o(To,"SPAN",{});var Do=n(pt);u(pe.$$.fragment,Do),Do.forEach(s),To.forEach(s),Ts=d(hs),dt=o(hs,"SPAN",{});var Co=n(dt);Ds=l(Co,"XLM-ProphetNet"),Co.forEach(s),hs.forEach(s),Rt=d(e),X=o(e,"P",{});var Ft=n(X);ht=o(Ft,"STRONG",{});var Ao=n(ht);Cs=l(Ao,"DISCLAIMER:"),Ao.forEach(s),As=l(Ft," If you see something strange, file a "),de=o(Ft,"A",{href:!0,rel:!0});var So=n(de);Ss=l(So,"Github Issue"),So.forEach(s),Is=l(Ft,` and assign
@patrickvonplaten`),Ft.forEach(s),Ot=d(e),j=o(e,"H2",{class:!0});var cs=n(j);O=o(cs,"A",{id:!0,class:!0,href:!0});var Io=n(O);ct=o(Io,"SPAN",{});var Fo=n(ct);u(he.$$.fragment,Fo),Fo.forEach(s),Io.forEach(s),Fs=d(cs),mt=o(cs,"SPAN",{});var Go=n(mt);Gs=l(Go,"Overview"),Go.forEach(s),cs.forEach(s),Ht=d(e),H=o(e,"P",{});var ms=n(H);Bs=l(ms,"The XLM-ProphetNet model was proposed in "),ce=o(ms,"A",{href:!0,rel:!0});var Bo=n(ce);Rs=l(Bo,"ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training,"),Bo.forEach(s),Os=l(ms,` by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei
Zhang, Ming Zhou on 13 Jan, 2020.`),ms.forEach(s),Vt=d(e),We=o(e,"P",{});var Ro=n(We);Hs=l(Ro,`XLM-ProphetNet is an encoder-decoder model and can predict n-future tokens for \u201Cngram\u201D language modeling instead of
just the next token. Its architecture is identical to ProhpetNet, but the model was trained on the multi-lingual
\u201Cwiki100\u201D Wikipedia dump.`),Ro.forEach(s),Wt=d(e),Ue=o(e,"P",{});var Oo=n(Ue);Vs=l(Oo,"The abstract from the paper is the following:"),Oo.forEach(s),Ut=d(e),Ye=o(e,"P",{});var Ho=n(Ye);ut=o(Ho,"EM",{});var Vo=n(ut);Ws=l(Vo,`In this paper, we present a new sequence-to-sequence pretraining model called ProphetNet, which introduces a novel
self-supervised objective named future n-gram prediction and the proposed n-stream self-attention mechanism. Instead of
the optimization of one-step ahead prediction in traditional sequence-to-sequence model, the ProphetNet is optimized by
n-step ahead prediction which predicts the next n tokens simultaneously based on previous context tokens at each time
step. The future n-gram prediction explicitly encourages the model to plan for the future tokens and prevent
overfitting on strong local correlations. We pre-train ProphetNet using a base scale dataset (16GB) and a large scale
dataset (160GB) respectively. Then we conduct experiments on CNN/DailyMail, Gigaword, and SQuAD 1.1 benchmarks for
abstractive summarization and question generation tasks. Experimental results show that ProphetNet achieves new
state-of-the-art results on all these datasets compared to the models using the same scale pretraining corpus.`),Vo.forEach(s),Ho.forEach(s),Yt=d(e),V=o(e,"P",{});var us=n(V);Us=l(us,"The Authors\u2019 code can be found "),me=o(us,"A",{href:!0,rel:!0});var Wo=n(me);Ys=l(Wo,"here"),Wo.forEach(s),Js=l(us,"."),us.forEach(s),Jt=d(e),z=o(e,"H2",{class:!0});var fs=n(z);W=o(fs,"A",{id:!0,class:!0,href:!0});var Uo=n(W);ft=o(Uo,"SPAN",{});var Yo=n(ft);u(ue.$$.fragment,Yo),Yo.forEach(s),Uo.forEach(s),Qs=d(fs),gt=o(fs,"SPAN",{});var Jo=n(gt);Zs=l(Jo,"XLMProphetNetConfig"),Jo.forEach(s),fs.forEach(s),Qt=d(e),T=o(e,"DIV",{class:!0});var gs=n(T);u(fe.$$.fragment,gs),Ks=d(gs),D=o(gs,"P",{});var it=n(D);er=l(it,"This class overrides "),Je=o(it,"A",{href:!0});var Qo=n(Je);tr=l(Qo,"ProphetNetConfig"),Qo.forEach(s),sr=l(it,`. Please check the superclass for the appropriate documentation alongside
usage examples. Instantiating a configuration with the defaults will yield a similar configuration to that of the
XLMProphetNet
`),ge=o(it,"A",{href:!0,rel:!0});var Zo=n(ge);rr=l(Zo,"microsoft/xprophetnet-large-wiki100-cased"),Zo.forEach(s),or=l(it,`
architecture.`),it.forEach(s),gs.forEach(s),Zt=d(e),C=o(e,"H2",{class:!0});var _s=n(C);U=o(_s,"A",{id:!0,class:!0,href:!0});var Ko=n(U);_t=o(Ko,"SPAN",{});var en=n(_t);u(_e.$$.fragment,en),en.forEach(s),Ko.forEach(s),nr=d(_s),kt=o(_s,"SPAN",{});var tn=n(kt);ar=l(tn,"XLMProphetNetTokenizer"),tn.forEach(s),_s.forEach(s),Kt=d(e),v=o(e,"DIV",{class:!0});var b=n(v);u(ke.$$.fragment,b),ir=d(b),M=o(b,"P",{});var re=n(M);lr=l(re,"Adapted from "),Qe=o(re,"A",{href:!0});var sn=n(Qe);pr=l(sn,"RobertaTokenizer"),sn.forEach(s),dr=l(re," and "),Ze=o(re,"A",{href:!0});var rn=n(Ze);hr=l(rn,"XLNetTokenizer"),rn.forEach(s),cr=l(re,`. Based on
`),ve=o(re,"A",{href:!0,rel:!0});var on=n(ve);mr=l(on,"SentencePiece"),on.forEach(s),ur=l(re,"."),re.forEach(s),fr=d(b),be=o(b,"P",{});var ks=n(be);gr=l(ks,"This tokenizer inherits from "),Ke=o(ks,"A",{href:!0});var nn=n(Ke);_r=l(nn,"PreTrainedTokenizer"),nn.forEach(s),kr=l(ks,` which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.`),ks.forEach(s),vr=d(b),q=o(b,"DIV",{class:!0});var lt=n(q);u(Pe.$$.fragment,lt),br=d(lt),vt=o(lt,"P",{});var an=n(vt);Pr=l(an,`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A XLMProphetNet sequence has the following format:`),an.forEach(s),wr=d(lt),we=o(lt,"UL",{});var vs=n(we);et=o(vs,"LI",{});var Xo=n(et);Nr=l(Xo,"single sequence: "),bt=o(Xo,"CODE",{});var ln=n(bt);Lr=l(ln,"X [SEP]"),ln.forEach(s),Xo.forEach(s),$r=d(vs),tt=o(vs,"LI",{});var jo=n(tt);Mr=l(jo,"pair of sequences: "),Pt=o(jo,"CODE",{});var pn=n(Pt);yr=l(pn,"A [SEP] B [SEP]"),pn.forEach(s),jo.forEach(s),vs.forEach(s),lt.forEach(s),qr=d(b),Y=o(b,"DIV",{class:!0});var bs=n(Y);u(Ne.$$.fragment,bs),xr=d(bs),wt=o(bs,"P",{});var dn=n(wt);Er=l(dn,"Converts a sequence of tokens (strings for sub-words) in a single string."),dn.forEach(s),bs.forEach(s),Xr=d(b),J=o(b,"DIV",{class:!0});var Ps=n(J);u(Le.$$.fragment,Ps),jr=d(Ps),Nt=o(Ps,"P",{});var hn=n(Nt);zr=l(hn,`Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLMProphetNet
does not make use of token type ids, therefore a list of zeros is returned.`),hn.forEach(s),Ps.forEach(s),Tr=d(b),Q=o(b,"DIV",{class:!0});var ws=n(Q);u($e.$$.fragment,ws),Dr=d(ws),Me=o(ws,"P",{});var Ns=n(Me);Cr=l(Ns,`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),Lt=o(Ns,"CODE",{});var cn=n(Lt);Ar=l(cn,"prepare_for_model"),cn.forEach(s),Sr=l(Ns," method."),Ns.forEach(s),ws.forEach(s),b.forEach(s),es=d(e),A=o(e,"H2",{class:!0});var Ls=n(A);Z=o(Ls,"A",{id:!0,class:!0,href:!0});var mn=n(Z);$t=o(mn,"SPAN",{});var un=n($t);u(ye.$$.fragment,un),un.forEach(s),mn.forEach(s),Ir=d(Ls),Mt=o(Ls,"SPAN",{});var fn=n(Mt);Fr=l(fn,"XLMProphetNetModel"),fn.forEach(s),Ls.forEach(s),ts=d(e),P=o(e,"DIV",{class:!0});var oe=n(P);u(qe.$$.fragment,oe),Gr=d(oe),xe=o(oe,"P",{});var $s=n(xe);Br=l($s,"This class overrides "),st=o($s,"A",{href:!0});var gn=n(st);Rr=l(gn,"ProphetNetModel"),gn.forEach(s),Or=l($s,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),$s.forEach(s),Hr=d(oe),yt=o(oe,"P",{});var _n=n(yt);Vr=l(_n,"Example:"),_n.forEach(s),Wr=d(oe),u(Ee.$$.fragment,oe),oe.forEach(s),ss=d(e),S=o(e,"H2",{class:!0});var Ms=n(S);K=o(Ms,"A",{id:!0,class:!0,href:!0});var kn=n(K);qt=o(kn,"SPAN",{});var vn=n(qt);u(Xe.$$.fragment,vn),vn.forEach(s),kn.forEach(s),Ur=d(Ms),xt=o(Ms,"SPAN",{});var bn=n(xt);Yr=l(bn,"XLMProphetNetEncoder"),bn.forEach(s),Ms.forEach(s),rs=d(e),w=o(e,"DIV",{class:!0});var ne=n(w);u(je.$$.fragment,ne),Jr=d(ne),ze=o(ne,"P",{});var ys=n(ze);Qr=l(ys,"This class overrides "),rt=o(ys,"A",{href:!0});var Pn=n(rt);Zr=l(Pn,"ProphetNetEncoder"),Pn.forEach(s),Kr=l(ys,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),ys.forEach(s),eo=d(ne),Et=o(ne,"P",{});var wn=n(Et);to=l(wn,"Example:"),wn.forEach(s),so=d(ne),u(Te.$$.fragment,ne),ne.forEach(s),os=d(e),I=o(e,"H2",{class:!0});var qs=n(I);ee=o(qs,"A",{id:!0,class:!0,href:!0});var Nn=n(ee);Xt=o(Nn,"SPAN",{});var Ln=n(Xt);u(De.$$.fragment,Ln),Ln.forEach(s),Nn.forEach(s),ro=d(qs),jt=o(qs,"SPAN",{});var $n=n(jt);oo=l($n,"XLMProphetNetDecoder"),$n.forEach(s),qs.forEach(s),ns=d(e),N=o(e,"DIV",{class:!0});var ae=n(N);u(Ce.$$.fragment,ae),no=d(ae),Ae=o(ae,"P",{});var xs=n(Ae);ao=l(xs,"This class overrides "),ot=o(xs,"A",{href:!0});var Mn=n(ot);io=l(Mn,"ProphetNetDecoder"),Mn.forEach(s),lo=l(xs,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),xs.forEach(s),po=d(ae),zt=o(ae,"P",{});var yn=n(zt);ho=l(yn,"Example:"),yn.forEach(s),co=d(ae),u(Se.$$.fragment,ae),ae.forEach(s),as=d(e),F=o(e,"H2",{class:!0});var Es=n(F);te=o(Es,"A",{id:!0,class:!0,href:!0});var qn=n(te);Tt=o(qn,"SPAN",{});var xn=n(Tt);u(Ie.$$.fragment,xn),xn.forEach(s),qn.forEach(s),mo=d(Es),Dt=o(Es,"SPAN",{});var En=n(Dt);uo=l(En,"XLMProphetNetForConditionalGeneration"),En.forEach(s),Es.forEach(s),is=d(e),L=o(e,"DIV",{class:!0});var ie=n(L);u(Fe.$$.fragment,ie),fo=d(ie),Ge=o(ie,"P",{});var Xs=n(Ge);go=l(Xs,"This class overrides "),nt=o(Xs,"A",{href:!0});var Xn=n(nt);_o=l(Xn,"ProphetNetForConditionalGeneration"),Xn.forEach(s),ko=l(Xs,`. Please check the superclass for the appropriate
documentation alongside usage examples.`),Xs.forEach(s),vo=d(ie),Ct=o(ie,"P",{});var jn=n(Ct);bo=l(jn,"Example:"),jn.forEach(s),Po=d(ie),u(Be.$$.fragment,ie),ie.forEach(s),ls=d(e),G=o(e,"H2",{class:!0});var js=n(G);se=o(js,"A",{id:!0,class:!0,href:!0});var zn=n(se);At=o(zn,"SPAN",{});var Tn=n(At);u(Re.$$.fragment,Tn),Tn.forEach(s),zn.forEach(s),wo=d(js),St=o(js,"SPAN",{});var Dn=n(St);No=l(Dn,"XLMProphetNetForCausalLM"),Dn.forEach(s),js.forEach(s),ps=d(e),$=o(e,"DIV",{class:!0});var le=n($);u(Oe.$$.fragment,le),Lo=d(le),He=o(le,"P",{});var zs=n(He);$o=l(zs,"This class overrides "),at=o(zs,"A",{href:!0});var Cn=n(at);Mo=l(Cn,"ProphetNetForCausalLM"),Cn.forEach(s),yo=l(zs,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),zs.forEach(s),qo=d(le),It=o(le,"P",{});var An=n(It);xo=l(An,"Example:"),An.forEach(s),Eo=d(le),u(Ve.$$.fragment,le),le.forEach(s),this.h()},h(){a(x,"name","hf:doc:metadata"),a(x,"content",JSON.stringify(Hn)),a(R,"id","xlmprophetnet"),a(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(R,"href","#xlmprophetnet"),a(E,"class","relative group"),a(de,"href","https://github.com/huggingface/transformers/issues/new?assignees=&labels=&template=bug-report.md&title"),a(de,"rel","nofollow"),a(O,"id","overview"),a(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(O,"href","#overview"),a(j,"class","relative group"),a(ce,"href","https://arxiv.org/abs/2001.04063"),a(ce,"rel","nofollow"),a(me,"href","https://github.com/microsoft/ProphetNet"),a(me,"rel","nofollow"),a(W,"id","transformers.XLMProphetNetConfig"),a(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(W,"href","#transformers.XLMProphetNetConfig"),a(z,"class","relative group"),a(Je,"href","/docs/transformers/pr_16912/en/model_doc/prophetnet#transformers.ProphetNetConfig"),a(ge,"href","https://huggingface.co/microsoft/xprophetnet-large-wiki100-cased"),a(ge,"rel","nofollow"),a(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(U,"id","transformers.XLMProphetNetTokenizer"),a(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(U,"href","#transformers.XLMProphetNetTokenizer"),a(C,"class","relative group"),a(Qe,"href","/docs/transformers/pr_16912/en/model_doc/roberta#transformers.RobertaTokenizer"),a(Ze,"href","/docs/transformers/pr_16912/en/model_doc/xlnet#transformers.XLNetTokenizer"),a(ve,"href","https://github.com/google/sentencepiece"),a(ve,"rel","nofollow"),a(Ke,"href","/docs/transformers/pr_16912/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"),a(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(v,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(Z,"id","transformers.XLMProphetNetModel"),a(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(Z,"href","#transformers.XLMProphetNetModel"),a(A,"class","relative group"),a(st,"href","/docs/transformers/pr_16912/en/model_doc/prophetnet#transformers.ProphetNetModel"),a(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(K,"id","transformers.XLMProphetNetEncoder"),a(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(K,"href","#transformers.XLMProphetNetEncoder"),a(S,"class","relative group"),a(rt,"href","/docs/transformers/pr_16912/en/model_doc/prophetnet#transformers.ProphetNetEncoder"),a(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(ee,"id","transformers.XLMProphetNetDecoder"),a(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(ee,"href","#transformers.XLMProphetNetDecoder"),a(I,"class","relative group"),a(ot,"href","/docs/transformers/pr_16912/en/model_doc/prophetnet#transformers.ProphetNetDecoder"),a(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(te,"id","transformers.XLMProphetNetForConditionalGeneration"),a(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(te,"href","#transformers.XLMProphetNetForConditionalGeneration"),a(F,"class","relative group"),a(nt,"href","/docs/transformers/pr_16912/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),a(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),a(se,"id","transformers.XLMProphetNetForCausalLM"),a(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(se,"href","#transformers.XLMProphetNetForCausalLM"),a(G,"class","relative group"),a(at,"href","/docs/transformers/pr_16912/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),a($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,h){t(document.head,x),c(e,Bt,h),c(e,E,h),t(E,R),t(R,pt),f(pe,pt,null),t(E,Ts),t(E,dt),t(dt,Ds),c(e,Rt,h),c(e,X,h),t(X,ht),t(ht,Cs),t(X,As),t(X,de),t(de,Ss),t(X,Is),c(e,Ot,h),c(e,j,h),t(j,O),t(O,ct),f(he,ct,null),t(j,Fs),t(j,mt),t(mt,Gs),c(e,Ht,h),c(e,H,h),t(H,Bs),t(H,ce),t(ce,Rs),t(H,Os),c(e,Vt,h),c(e,We,h),t(We,Hs),c(e,Wt,h),c(e,Ue,h),t(Ue,Vs),c(e,Ut,h),c(e,Ye,h),t(Ye,ut),t(ut,Ws),c(e,Yt,h),c(e,V,h),t(V,Us),t(V,me),t(me,Ys),t(V,Js),c(e,Jt,h),c(e,z,h),t(z,W),t(W,ft),f(ue,ft,null),t(z,Qs),t(z,gt),t(gt,Zs),c(e,Qt,h),c(e,T,h),f(fe,T,null),t(T,Ks),t(T,D),t(D,er),t(D,Je),t(Je,tr),t(D,sr),t(D,ge),t(ge,rr),t(D,or),c(e,Zt,h),c(e,C,h),t(C,U),t(U,_t),f(_e,_t,null),t(C,nr),t(C,kt),t(kt,ar),c(e,Kt,h),c(e,v,h),f(ke,v,null),t(v,ir),t(v,M),t(M,lr),t(M,Qe),t(Qe,pr),t(M,dr),t(M,Ze),t(Ze,hr),t(M,cr),t(M,ve),t(ve,mr),t(M,ur),t(v,fr),t(v,be),t(be,gr),t(be,Ke),t(Ke,_r),t(be,kr),t(v,vr),t(v,q),f(Pe,q,null),t(q,br),t(q,vt),t(vt,Pr),t(q,wr),t(q,we),t(we,et),t(et,Nr),t(et,bt),t(bt,Lr),t(we,$r),t(we,tt),t(tt,Mr),t(tt,Pt),t(Pt,yr),t(v,qr),t(v,Y),f(Ne,Y,null),t(Y,xr),t(Y,wt),t(wt,Er),t(v,Xr),t(v,J),f(Le,J,null),t(J,jr),t(J,Nt),t(Nt,zr),t(v,Tr),t(v,Q),f($e,Q,null),t(Q,Dr),t(Q,Me),t(Me,Cr),t(Me,Lt),t(Lt,Ar),t(Me,Sr),c(e,es,h),c(e,A,h),t(A,Z),t(Z,$t),f(ye,$t,null),t(A,Ir),t(A,Mt),t(Mt,Fr),c(e,ts,h),c(e,P,h),f(qe,P,null),t(P,Gr),t(P,xe),t(xe,Br),t(xe,st),t(st,Rr),t(xe,Or),t(P,Hr),t(P,yt),t(yt,Vr),t(P,Wr),f(Ee,P,null),c(e,ss,h),c(e,S,h),t(S,K),t(K,qt),f(Xe,qt,null),t(S,Ur),t(S,xt),t(xt,Yr),c(e,rs,h),c(e,w,h),f(je,w,null),t(w,Jr),t(w,ze),t(ze,Qr),t(ze,rt),t(rt,Zr),t(ze,Kr),t(w,eo),t(w,Et),t(Et,to),t(w,so),f(Te,w,null),c(e,os,h),c(e,I,h),t(I,ee),t(ee,Xt),f(De,Xt,null),t(I,ro),t(I,jt),t(jt,oo),c(e,ns,h),c(e,N,h),f(Ce,N,null),t(N,no),t(N,Ae),t(Ae,ao),t(Ae,ot),t(ot,io),t(Ae,lo),t(N,po),t(N,zt),t(zt,ho),t(N,co),f(Se,N,null),c(e,as,h),c(e,F,h),t(F,te),t(te,Tt),f(Ie,Tt,null),t(F,mo),t(F,Dt),t(Dt,uo),c(e,is,h),c(e,L,h),f(Fe,L,null),t(L,fo),t(L,Ge),t(Ge,go),t(Ge,nt),t(nt,_o),t(Ge,ko),t(L,vo),t(L,Ct),t(Ct,bo),t(L,Po),f(Be,L,null),c(e,ls,h),c(e,G,h),t(G,se),t(se,At),f(Re,At,null),t(G,wo),t(G,St),t(St,No),c(e,ps,h),c(e,$,h),f(Oe,$,null),t($,Lo),t($,He),t(He,$o),t(He,at),t(at,Mo),t(He,yo),t($,qo),t($,It),t(It,xo),t($,Eo),f(Ve,$,null),ds=!0},p:Bn,i(e){ds||(g(pe.$$.fragment,e),g(he.$$.fragment,e),g(ue.$$.fragment,e),g(fe.$$.fragment,e),g(_e.$$.fragment,e),g(ke.$$.fragment,e),g(Pe.$$.fragment,e),g(Ne.$$.fragment,e),g(Le.$$.fragment,e),g($e.$$.fragment,e),g(ye.$$.fragment,e),g(qe.$$.fragment,e),g(Ee.$$.fragment,e),g(Xe.$$.fragment,e),g(je.$$.fragment,e),g(Te.$$.fragment,e),g(De.$$.fragment,e),g(Ce.$$.fragment,e),g(Se.$$.fragment,e),g(Ie.$$.fragment,e),g(Fe.$$.fragment,e),g(Be.$$.fragment,e),g(Re.$$.fragment,e),g(Oe.$$.fragment,e),g(Ve.$$.fragment,e),ds=!0)},o(e){_(pe.$$.fragment,e),_(he.$$.fragment,e),_(ue.$$.fragment,e),_(fe.$$.fragment,e),_(_e.$$.fragment,e),_(ke.$$.fragment,e),_(Pe.$$.fragment,e),_(Ne.$$.fragment,e),_(Le.$$.fragment,e),_($e.$$.fragment,e),_(ye.$$.fragment,e),_(qe.$$.fragment,e),_(Ee.$$.fragment,e),_(Xe.$$.fragment,e),_(je.$$.fragment,e),_(Te.$$.fragment,e),_(De.$$.fragment,e),_(Ce.$$.fragment,e),_(Se.$$.fragment,e),_(Ie.$$.fragment,e),_(Fe.$$.fragment,e),_(Be.$$.fragment,e),_(Re.$$.fragment,e),_(Oe.$$.fragment,e),_(Ve.$$.fragment,e),ds=!1},d(e){s(x),e&&s(Bt),e&&s(E),k(pe),e&&s(Rt),e&&s(X),e&&s(Ot),e&&s(j),k(he),e&&s(Ht),e&&s(H),e&&s(Vt),e&&s(We),e&&s(Wt),e&&s(Ue),e&&s(Ut),e&&s(Ye),e&&s(Yt),e&&s(V),e&&s(Jt),e&&s(z),k(ue),e&&s(Qt),e&&s(T),k(fe),e&&s(Zt),e&&s(C),k(_e),e&&s(Kt),e&&s(v),k(ke),k(Pe),k(Ne),k(Le),k($e),e&&s(es),e&&s(A),k(ye),e&&s(ts),e&&s(P),k(qe),k(Ee),e&&s(ss),e&&s(S),k(Xe),e&&s(rs),e&&s(w),k(je),k(Te),e&&s(os),e&&s(I),k(De),e&&s(ns),e&&s(N),k(Ce),k(Se),e&&s(as),e&&s(F),k(Ie),e&&s(is),e&&s(L),k(Fe),k(Be),e&&s(ls),e&&s(G),k(Re),e&&s(ps),e&&s($),k(Oe),k(Ve)}}}const Hn={local:"xlmprophetnet",sections:[{local:"overview",title:"Overview"},{local:"transformers.XLMProphetNetConfig",title:"XLMProphetNetConfig"},{local:"transformers.XLMProphetNetTokenizer",title:"XLMProphetNetTokenizer"},{local:"transformers.XLMProphetNetModel",title:"XLMProphetNetModel"},{local:"transformers.XLMProphetNetEncoder",title:"XLMProphetNetEncoder"},{local:"transformers.XLMProphetNetDecoder",title:"XLMProphetNetDecoder"},{local:"transformers.XLMProphetNetForConditionalGeneration",title:"XLMProphetNetForConditionalGeneration"},{local:"transformers.XLMProphetNetForCausalLM",title:"XLMProphetNetForCausalLM"}],title:"XLM-ProphetNet"};function Vn(zo){return Rn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Qn extends Sn{constructor(x){super();In(this,x,Vn,On,Fn,{})}}export{Qn as default,Hn as metadata};
