import{S as AMt,i as LMt,s as BMt,e as a,k as l,w as f,t as o,M as xMt,c as n,d as t,m as i,a as s,x as m,h as r,b as d,F as e,g as b,y as g,q as h,o as p,B as _,v as kMt}from"../../chunks/vendor-6b77c823.js";import{T as wkr}from"../../chunks/Tip-39098574.js";import{D as M}from"../../chunks/Docstring-abef54e3.js";import{C as w}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as X}from"../../chunks/IconCopyLink-7a11ce68.js";function RMt($f){let K,io,de,Ee,lo,fe,Ce,Vo,Ii,If,fa,Ni,Di,l3,Nf,Be,co,ji,Gn,i3,On,Xn,d3,qi,Vn,c3,Gi,Df,qa;return{c(){K=a("p"),io=o("If your "),de=a("code"),Ee=o("NewModelConfig"),lo=o(" is a subclass of "),fe=a("code"),Ce=o("PretrainedConfig"),Vo=o(`, make sure its
`),Ii=a("code"),If=o("model_type"),fa=o(" attribute is set to the same key you use when registering the config (here "),Ni=a("code"),Di=o('"new-model"'),l3=o(")."),Nf=l(),Be=a("p"),co=o("Likewise, if your "),ji=a("code"),Gn=o("NewModel"),i3=o(" is a subclass of "),On=a("a"),Xn=o("PreTrainedModel"),d3=o(`, make sure its
`),qi=a("code"),Vn=o("config_class"),c3=o(` attribute is set to the same class you use when registering the model (here
`),Gi=a("code"),Df=o("NewModelConfig"),qa=o(")."),this.h()},l(fo){K=n(fo,"P",{});var pe=s(K);io=r(pe,"If your "),de=n(pe,"CODE",{});var e9=s(de);Ee=r(e9,"NewModelConfig"),e9.forEach(t),lo=r(pe," is a subclass of "),fe=n(pe,"CODE",{});var Oi=s(fe);Ce=r(Oi,"PretrainedConfig"),Oi.forEach(t),Vo=r(pe,`, make sure its
`),Ii=n(pe,"CODE",{});var o9=s(Ii);If=r(o9,"model_type"),o9.forEach(t),fa=r(pe," attribute is set to the same key you use when registering the config (here "),Ni=n(pe,"CODE",{});var r9=s(Ni);Di=r(r9,'"new-model"'),r9.forEach(t),l3=r(pe,")."),pe.forEach(t),Nf=i(fo),Be=n(fo,"P",{});var zo=s(Be);co=r(zo,"Likewise, if your "),ji=n(zo,"CODE",{});var Ga=s(ji);Gn=r(Ga,"NewModel"),Ga.forEach(t),i3=r(zo," is a subclass of "),On=n(zo,"A",{href:!0});var t9=s(On);Xn=r(t9,"PreTrainedModel"),t9.forEach(t),d3=r(zo,`, make sure its
`),qi=n(zo,"CODE",{});var jf=s(qi);Vn=r(jf,"config_class"),jf.forEach(t),c3=r(zo,` attribute is set to the same class you use when registering the model (here
`),Gi=n(zo,"CODE",{});var a9=s(Gi);Df=r(a9,"NewModelConfig"),a9.forEach(t),qa=r(zo,")."),zo.forEach(t),this.h()},h(){d(On,"href","/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel")},m(fo,pe){b(fo,K,pe),e(K,io),e(K,de),e(de,Ee),e(K,lo),e(K,fe),e(fe,Ce),e(K,Vo),e(K,Ii),e(Ii,If),e(K,fa),e(K,Ni),e(Ni,Di),e(K,l3),b(fo,Nf,pe),b(fo,Be,pe),e(Be,co),e(Be,ji),e(ji,Gn),e(Be,i3),e(Be,On),e(On,Xn),e(Be,d3),e(Be,qi),e(qi,Vn),e(Be,c3),e(Be,Gi),e(Gi,Df),e(Be,qa)},d(fo){fo&&t(K),fo&&t(Nf),fo&&t(Be)}}}function SMt($f){let K,io,de,Ee,lo;return{c(){K=a("p"),io=o("Passing "),de=a("code"),Ee=o("use_auth_token=True"),lo=o(" is required when you want to use a private model.")},l(fe){K=n(fe,"P",{});var Ce=s(K);io=r(Ce,"Passing "),de=n(Ce,"CODE",{});var Vo=s(de);Ee=r(Vo,"use_auth_token=True"),Vo.forEach(t),lo=r(Ce," is required when you want to use a private model."),Ce.forEach(t)},m(fe,Ce){b(fe,K,Ce),e(K,io),e(K,de),e(de,Ee),e(K,lo)},d(fe){fe&&t(K)}}}function PMt($f){let K,io,de,Ee,lo;return{c(){K=a("p"),io=o("Passing "),de=a("code"),Ee=o("use_auth_token=True"),lo=o(" is required when you want to use a private model.")},l(fe){K=n(fe,"P",{});var Ce=s(K);io=r(Ce,"Passing "),de=n(Ce,"CODE",{});var Vo=s(de);Ee=r(Vo,"use_auth_token=True"),Vo.forEach(t),lo=r(Ce," is required when you want to use a private model."),Ce.forEach(t)},m(fe,Ce){b(fe,K,Ce),e(K,io),e(K,de),e(de,Ee),e(K,lo)},d(fe){fe&&t(K)}}}function $Mt($f){let K,io,de,Ee,lo,fe,Ce,Vo,Ii,If,fa,Ni,Di,l3,Nf,Be,co,ji,Gn,i3,On,Xn,d3,qi,Vn,c3,Gi,Df,qa,fo,pe,e9,Oi,o9,r9,zo,Ga,t9,jf,a9,C$e,ike,Xi,qf,OQ,f3,M$e,XQ,E$e,dke,zn,y$e,VQ,w$e,A$e,zQ,L$e,B$e,cke,m3,fke,n9,x$e,mke,Gf,gke,Vi,Of,WQ,g3,k$e,QQ,R$e,hke,Wo,h3,S$e,p3,P$e,s9,$$e,I$e,N$e,_3,D$e,HQ,j$e,q$e,G$e,mo,u3,O$e,UQ,X$e,V$e,zi,z$e,JQ,W$e,Q$e,YQ,H$e,U$e,J$e,v,Xf,KQ,Y$e,K$e,l9,Z$e,eIe,oIe,Vf,ZQ,rIe,tIe,i9,aIe,nIe,sIe,zf,eH,lIe,iIe,d9,dIe,cIe,fIe,Wf,oH,mIe,gIe,c9,hIe,pIe,_Ie,Qf,rH,uIe,bIe,f9,vIe,TIe,FIe,Hf,tH,CIe,MIe,m9,EIe,yIe,wIe,Uf,aH,AIe,LIe,g9,BIe,xIe,kIe,Jf,nH,RIe,SIe,h9,PIe,$Ie,IIe,Yf,sH,NIe,DIe,p9,jIe,qIe,GIe,Kf,lH,OIe,XIe,_9,VIe,zIe,WIe,Zf,iH,QIe,HIe,u9,UIe,JIe,YIe,em,dH,KIe,ZIe,b9,eNe,oNe,rNe,om,cH,tNe,aNe,v9,nNe,sNe,lNe,rm,fH,iNe,dNe,T9,cNe,fNe,mNe,tm,mH,gNe,hNe,F9,pNe,_Ne,uNe,am,gH,bNe,vNe,C9,TNe,FNe,CNe,nm,hH,MNe,ENe,M9,yNe,wNe,ANe,sm,pH,LNe,BNe,E9,xNe,kNe,RNe,lm,_H,SNe,PNe,y9,$Ne,INe,NNe,im,uH,DNe,jNe,w9,qNe,GNe,ONe,dm,bH,XNe,VNe,A9,zNe,WNe,QNe,cm,vH,HNe,UNe,L9,JNe,YNe,KNe,fm,TH,ZNe,eDe,B9,oDe,rDe,tDe,mm,FH,aDe,nDe,x9,sDe,lDe,iDe,gm,CH,dDe,cDe,k9,fDe,mDe,gDe,hm,MH,hDe,pDe,R9,_De,uDe,bDe,pm,EH,vDe,TDe,S9,FDe,CDe,MDe,_m,yH,EDe,yDe,P9,wDe,ADe,LDe,um,wH,BDe,xDe,$9,kDe,RDe,SDe,bm,AH,PDe,$De,I9,IDe,NDe,DDe,vm,LH,jDe,qDe,N9,GDe,ODe,XDe,Tm,BH,VDe,zDe,D9,WDe,QDe,HDe,Fm,xH,UDe,JDe,j9,YDe,KDe,ZDe,Cm,kH,eje,oje,q9,rje,tje,aje,Mm,RH,nje,sje,G9,lje,ije,dje,Em,SH,cje,fje,O9,mje,gje,hje,ym,PH,pje,_je,X9,uje,bje,vje,wm,$H,Tje,Fje,V9,Cje,Mje,Eje,Am,IH,yje,wje,z9,Aje,Lje,Bje,Lm,NH,xje,kje,W9,Rje,Sje,Pje,Bm,DH,$je,Ije,Q9,Nje,Dje,jje,xm,jH,qje,Gje,H9,Oje,Xje,Vje,km,qH,zje,Wje,U9,Qje,Hje,Uje,Rm,GH,Jje,Yje,J9,Kje,Zje,eqe,Sm,OH,oqe,rqe,Y9,tqe,aqe,nqe,Pm,XH,sqe,lqe,K9,iqe,dqe,cqe,$m,VH,fqe,mqe,Z9,gqe,hqe,pqe,Im,zH,_qe,uqe,eB,bqe,vqe,Tqe,Nm,WH,Fqe,Cqe,oB,Mqe,Eqe,yqe,Dm,QH,wqe,Aqe,rB,Lqe,Bqe,xqe,jm,HH,kqe,Rqe,tB,Sqe,Pqe,$qe,qm,UH,Iqe,Nqe,aB,Dqe,jqe,qqe,Gm,JH,Gqe,Oqe,nB,Xqe,Vqe,zqe,Om,YH,Wqe,Qqe,sB,Hqe,Uqe,Jqe,Xm,KH,Yqe,Kqe,lB,Zqe,eGe,oGe,Vm,ZH,rGe,tGe,iB,aGe,nGe,sGe,zm,eU,lGe,iGe,dB,dGe,cGe,fGe,Wm,oU,mGe,gGe,cB,hGe,pGe,_Ge,Qm,rU,uGe,bGe,fB,vGe,TGe,FGe,Hm,tU,CGe,MGe,mB,EGe,yGe,wGe,Um,aU,AGe,LGe,gB,BGe,xGe,kGe,Jm,nU,RGe,SGe,hB,PGe,$Ge,IGe,Ym,sU,NGe,DGe,pB,jGe,qGe,GGe,Km,lU,OGe,XGe,_B,VGe,zGe,WGe,Zm,iU,QGe,HGe,uB,UGe,JGe,YGe,eg,dU,KGe,ZGe,bB,eOe,oOe,rOe,og,cU,tOe,aOe,vB,nOe,sOe,lOe,rg,fU,iOe,dOe,TB,cOe,fOe,mOe,tg,mU,gOe,hOe,FB,pOe,_Oe,uOe,ag,gU,bOe,vOe,CB,TOe,FOe,COe,ng,hU,MOe,EOe,MB,yOe,wOe,AOe,sg,pU,LOe,BOe,EB,xOe,kOe,ROe,lg,_U,SOe,POe,yB,$Oe,IOe,NOe,ig,uU,DOe,jOe,wB,qOe,GOe,OOe,dg,bU,XOe,VOe,AB,zOe,WOe,QOe,cg,vU,HOe,UOe,LB,JOe,YOe,KOe,fg,TU,ZOe,eXe,BB,oXe,rXe,tXe,mg,FU,aXe,nXe,xB,sXe,lXe,iXe,gg,CU,dXe,cXe,kB,fXe,mXe,gXe,hg,MU,hXe,pXe,RB,_Xe,uXe,bXe,pg,EU,vXe,TXe,SB,FXe,CXe,MXe,_g,yU,EXe,yXe,PB,wXe,AXe,LXe,ug,wU,BXe,xXe,$B,kXe,RXe,SXe,bg,AU,PXe,$Xe,IB,IXe,NXe,DXe,vg,LU,jXe,qXe,NB,GXe,OXe,XXe,Tg,BU,VXe,zXe,DB,WXe,QXe,HXe,Fg,xU,UXe,JXe,jB,YXe,KXe,ZXe,Cg,kU,eVe,oVe,qB,rVe,tVe,aVe,Mg,RU,nVe,sVe,GB,lVe,iVe,dVe,Eg,SU,cVe,fVe,OB,mVe,gVe,hVe,yg,PU,pVe,_Ve,XB,uVe,bVe,vVe,wg,$U,TVe,FVe,VB,CVe,MVe,EVe,Ag,IU,yVe,wVe,zB,AVe,LVe,BVe,Lg,NU,xVe,kVe,WB,RVe,SVe,PVe,Bg,DU,$Ve,IVe,QB,NVe,DVe,jVe,xg,jU,qVe,GVe,HB,OVe,XVe,VVe,kg,qU,zVe,WVe,UB,QVe,HVe,UVe,Rg,GU,JVe,YVe,JB,KVe,ZVe,eze,OU,oze,rze,b3,tze,Sg,v3,aze,XU,nze,pke,Wi,Pg,VU,T3,sze,zU,lze,_ke,Qo,F3,ize,C3,dze,YB,cze,fze,mze,M3,gze,WU,hze,pze,_ze,go,E3,uze,QU,bze,vze,Oa,Tze,HU,Fze,Cze,UU,Mze,Eze,JU,yze,wze,Aze,E,Wn,YU,Lze,Bze,KB,xze,kze,ZB,Rze,Sze,Pze,Qn,KU,$ze,Ize,ex,Nze,Dze,ox,jze,qze,Gze,Hn,ZU,Oze,Xze,rx,Vze,zze,tx,Wze,Qze,Hze,$g,eJ,Uze,Jze,ax,Yze,Kze,Zze,Un,oJ,eWe,oWe,nx,rWe,tWe,sx,aWe,nWe,sWe,Ig,rJ,lWe,iWe,lx,dWe,cWe,fWe,Ng,tJ,mWe,gWe,ix,hWe,pWe,_We,Dg,aJ,uWe,bWe,dx,vWe,TWe,FWe,Jn,nJ,CWe,MWe,cx,EWe,yWe,fx,wWe,AWe,LWe,Yn,sJ,BWe,xWe,mx,kWe,RWe,gx,SWe,PWe,$We,Kn,lJ,IWe,NWe,hx,DWe,jWe,px,qWe,GWe,OWe,jg,iJ,XWe,VWe,_x,zWe,WWe,QWe,qg,dJ,HWe,UWe,ux,JWe,YWe,KWe,Zn,cJ,ZWe,eQe,bx,oQe,rQe,vx,tQe,aQe,nQe,Gg,fJ,sQe,lQe,Tx,iQe,dQe,cQe,es,mJ,fQe,mQe,Fx,gQe,hQe,Cx,pQe,_Qe,uQe,os,gJ,bQe,vQe,Mx,TQe,FQe,Ex,CQe,MQe,EQe,rs,hJ,yQe,wQe,yx,AQe,LQe,pJ,BQe,xQe,kQe,Og,_J,RQe,SQe,wx,PQe,$Qe,IQe,ts,uJ,NQe,DQe,Ax,jQe,qQe,Lx,GQe,OQe,XQe,Xg,bJ,VQe,zQe,Bx,WQe,QQe,HQe,as,vJ,UQe,JQe,xx,YQe,KQe,kx,ZQe,eHe,oHe,ns,TJ,rHe,tHe,Rx,aHe,nHe,Sx,sHe,lHe,iHe,ss,FJ,dHe,cHe,Px,fHe,mHe,$x,gHe,hHe,pHe,Vg,CJ,_He,uHe,Ix,bHe,vHe,THe,ls,MJ,FHe,CHe,Nx,MHe,EHe,Dx,yHe,wHe,AHe,zg,EJ,LHe,BHe,jx,xHe,kHe,RHe,is,yJ,SHe,PHe,qx,$He,IHe,Gx,NHe,DHe,jHe,ds,wJ,qHe,GHe,Ox,OHe,XHe,Xx,VHe,zHe,WHe,cs,AJ,QHe,HHe,Vx,UHe,JHe,zx,YHe,KHe,ZHe,fs,LJ,eUe,oUe,Wx,rUe,tUe,Qx,aUe,nUe,sUe,Wg,BJ,lUe,iUe,Hx,dUe,cUe,fUe,ms,xJ,mUe,gUe,Ux,hUe,pUe,Jx,_Ue,uUe,bUe,gs,kJ,vUe,TUe,Yx,FUe,CUe,Kx,MUe,EUe,yUe,hs,RJ,wUe,AUe,Zx,LUe,BUe,ek,xUe,kUe,RUe,ps,SJ,SUe,PUe,ok,$Ue,IUe,rk,NUe,DUe,jUe,_s,PJ,qUe,GUe,tk,OUe,XUe,ak,VUe,zUe,WUe,us,$J,QUe,HUe,nk,UUe,JUe,sk,YUe,KUe,ZUe,Qg,IJ,eJe,oJe,lk,rJe,tJe,aJe,bs,NJ,nJe,sJe,ik,lJe,iJe,dk,dJe,cJe,fJe,Hg,DJ,mJe,gJe,ck,hJe,pJe,_Je,Ug,jJ,uJe,bJe,fk,vJe,TJe,FJe,vs,qJ,CJe,MJe,mk,EJe,yJe,gk,wJe,AJe,LJe,Ts,GJ,BJe,xJe,hk,kJe,RJe,pk,SJe,PJe,$Je,Jg,OJ,IJe,NJe,_k,DJe,jJe,qJe,Fs,XJ,GJe,OJe,uk,XJe,VJe,bk,zJe,WJe,QJe,Cs,VJ,HJe,UJe,vk,JJe,YJe,Tk,KJe,ZJe,eYe,Ms,zJ,oYe,rYe,Fk,tYe,aYe,Ck,nYe,sYe,lYe,Es,WJ,iYe,dYe,Mk,cYe,fYe,Ek,mYe,gYe,hYe,ys,QJ,pYe,_Ye,yk,uYe,bYe,wk,vYe,TYe,FYe,Yg,HJ,CYe,MYe,Ak,EYe,yYe,wYe,Kg,UJ,AYe,LYe,Lk,BYe,xYe,kYe,Zg,JJ,RYe,SYe,Bk,PYe,$Ye,IYe,eh,YJ,NYe,DYe,xk,jYe,qYe,GYe,ws,KJ,OYe,XYe,kk,VYe,zYe,Rk,WYe,QYe,HYe,oh,ZJ,UYe,JYe,Sk,YYe,KYe,ZYe,As,eY,eKe,oKe,Pk,rKe,tKe,$k,aKe,nKe,sKe,Ls,oY,lKe,iKe,Ik,dKe,cKe,Nk,fKe,mKe,gKe,Bs,rY,hKe,pKe,Dk,_Ke,uKe,jk,bKe,vKe,TKe,xs,tY,FKe,CKe,qk,MKe,EKe,Gk,yKe,wKe,AKe,ks,aY,LKe,BKe,Ok,xKe,kKe,Xk,RKe,SKe,PKe,Rs,nY,$Ke,IKe,Vk,NKe,DKe,zk,jKe,qKe,GKe,rh,sY,OKe,XKe,Wk,VKe,zKe,WKe,th,lY,QKe,HKe,Qk,UKe,JKe,YKe,Ss,iY,KKe,ZKe,Hk,eZe,oZe,Uk,rZe,tZe,aZe,Ps,dY,nZe,sZe,Jk,lZe,iZe,Yk,dZe,cZe,fZe,$s,cY,mZe,gZe,Kk,hZe,pZe,Zk,_Ze,uZe,bZe,ah,fY,vZe,TZe,eR,FZe,CZe,MZe,nh,mY,EZe,yZe,oR,wZe,AZe,LZe,sh,gY,BZe,xZe,rR,kZe,RZe,SZe,lh,hY,PZe,$Ze,tR,IZe,NZe,DZe,Is,pY,jZe,qZe,aR,GZe,OZe,nR,XZe,VZe,zZe,ih,_Y,WZe,QZe,sR,HZe,UZe,JZe,dh,uY,YZe,KZe,lR,ZZe,eeo,oeo,Ns,bY,reo,teo,iR,aeo,neo,dR,seo,leo,ieo,Ds,vY,deo,ceo,cR,feo,meo,fR,geo,heo,peo,TY,_eo,ueo,y3,beo,ch,w3,veo,FY,Teo,uke,Qi,fh,CY,A3,Feo,MY,Ceo,bke,Ho,L3,Meo,B3,Eeo,mR,yeo,weo,Aeo,x3,Leo,EY,Beo,xeo,keo,$e,k3,Reo,yY,Seo,Peo,Xa,$eo,wY,Ieo,Neo,AY,Deo,jeo,LY,qeo,Geo,Oeo,re,mh,BY,Xeo,Veo,gR,zeo,Weo,Qeo,gh,xY,Heo,Ueo,hR,Jeo,Yeo,Keo,hh,kY,Zeo,eoo,pR,ooo,roo,too,ph,RY,aoo,noo,_R,soo,loo,ioo,_h,SY,doo,coo,uR,foo,moo,goo,uh,PY,hoo,poo,bR,_oo,uoo,boo,bh,$Y,voo,Too,vR,Foo,Coo,Moo,vh,IY,Eoo,yoo,TR,woo,Aoo,Loo,Th,NY,Boo,xoo,FR,koo,Roo,Soo,Fh,DY,Poo,$oo,CR,Ioo,Noo,Doo,Ch,jY,joo,qoo,MR,Goo,Ooo,Xoo,Mh,qY,Voo,zoo,ER,Woo,Qoo,Hoo,Eh,GY,Uoo,Joo,yR,Yoo,Koo,Zoo,yh,OY,ero,oro,wR,rro,tro,aro,wh,XY,nro,sro,AR,lro,iro,dro,Ah,VY,cro,fro,LR,mro,gro,hro,Lh,zY,pro,_ro,BR,uro,bro,vro,Bh,WY,Tro,Fro,xR,Cro,Mro,Ero,xh,yro,QY,wro,Aro,R3,Lro,kh,S3,Bro,HY,xro,vke,Hi,Rh,UY,P3,kro,JY,Rro,Tke,Uo,$3,Sro,I3,Pro,kR,$ro,Iro,Nro,N3,Dro,YY,jro,qro,Gro,Ie,D3,Oro,KY,Xro,Vro,Ui,zro,ZY,Wro,Qro,eK,Hro,Uro,Jro,xe,Sh,oK,Yro,Kro,RR,Zro,eto,oto,Ph,rK,rto,tto,SR,ato,nto,sto,$h,tK,lto,ito,PR,dto,cto,fto,Ih,aK,mto,gto,$R,hto,pto,_to,Nh,nK,uto,bto,IR,vto,Tto,Fto,Dh,sK,Cto,Mto,NR,Eto,yto,wto,jh,lK,Ato,Lto,DR,Bto,xto,kto,qh,iK,Rto,Sto,jR,Pto,$to,Ito,Gh,Nto,dK,Dto,jto,j3,qto,Oh,q3,Gto,cK,Oto,Fke,Ji,Xh,fK,G3,Xto,mK,Vto,Cke,Jo,O3,zto,Yi,Wto,gK,Qto,Hto,hK,Uto,Jto,Yto,X3,Kto,pK,Zto,eao,oao,Vr,V3,rao,_K,tao,aao,Ki,nao,uK,sao,lao,bK,iao,dao,cao,vK,fao,mao,z3,gao,Ne,W3,hao,TK,pao,_ao,Va,uao,FK,bao,vao,CK,Tao,Fao,MK,Cao,Mao,Eao,F,Vh,EK,yao,wao,qR,Aao,Lao,Bao,zh,yK,xao,kao,GR,Rao,Sao,Pao,Wh,wK,$ao,Iao,OR,Nao,Dao,jao,Qh,AK,qao,Gao,XR,Oao,Xao,Vao,Hh,LK,zao,Wao,VR,Qao,Hao,Uao,Uh,BK,Jao,Yao,zR,Kao,Zao,eno,Jh,xK,ono,rno,WR,tno,ano,nno,Yh,kK,sno,lno,QR,ino,dno,cno,Kh,RK,fno,mno,HR,gno,hno,pno,Zh,SK,_no,uno,UR,bno,vno,Tno,ep,PK,Fno,Cno,JR,Mno,Eno,yno,op,$K,wno,Ano,YR,Lno,Bno,xno,rp,IK,kno,Rno,KR,Sno,Pno,$no,tp,NK,Ino,Nno,ZR,Dno,jno,qno,ap,DK,Gno,Ono,eS,Xno,Vno,zno,np,jK,Wno,Qno,oS,Hno,Uno,Jno,sp,qK,Yno,Kno,rS,Zno,eso,oso,lp,GK,rso,tso,tS,aso,nso,sso,ip,OK,lso,iso,aS,dso,cso,fso,dp,XK,mso,gso,nS,hso,pso,_so,cp,VK,uso,bso,sS,vso,Tso,Fso,fp,zK,Cso,Mso,lS,Eso,yso,wso,mp,WK,Aso,Lso,iS,Bso,xso,kso,gp,QK,Rso,Sso,dS,Pso,$so,Iso,hp,HK,Nso,Dso,cS,jso,qso,Gso,pp,UK,Oso,Xso,fS,Vso,zso,Wso,_p,JK,Qso,Hso,mS,Uso,Jso,Yso,up,YK,Kso,Zso,gS,elo,olo,rlo,js,KK,tlo,alo,hS,nlo,slo,pS,llo,ilo,dlo,bp,ZK,clo,flo,_S,mlo,glo,hlo,vp,eZ,plo,_lo,uS,ulo,blo,vlo,Tp,oZ,Tlo,Flo,bS,Clo,Mlo,Elo,Fp,rZ,ylo,wlo,vS,Alo,Llo,Blo,Cp,tZ,xlo,klo,TS,Rlo,Slo,Plo,Mp,aZ,$lo,Ilo,FS,Nlo,Dlo,jlo,Ep,nZ,qlo,Glo,CS,Olo,Xlo,Vlo,yp,sZ,zlo,Wlo,MS,Qlo,Hlo,Ulo,wp,lZ,Jlo,Ylo,ES,Klo,Zlo,eio,Ap,iZ,oio,rio,yS,tio,aio,nio,Lp,dZ,sio,lio,wS,iio,dio,cio,Bp,cZ,fio,mio,AS,gio,hio,pio,xp,fZ,_io,uio,LS,bio,vio,Tio,kp,mZ,Fio,Cio,BS,Mio,Eio,yio,Rp,gZ,wio,Aio,xS,Lio,Bio,xio,Sp,hZ,kio,Rio,kS,Sio,Pio,$io,Pp,pZ,Iio,Nio,RS,Dio,jio,qio,$p,_Z,Gio,Oio,SS,Xio,Vio,zio,Ip,uZ,Wio,Qio,PS,Hio,Uio,Jio,Np,bZ,Yio,Kio,$S,Zio,edo,odo,Dp,vZ,rdo,tdo,IS,ado,ndo,sdo,jp,TZ,ldo,ido,NS,ddo,cdo,fdo,qp,FZ,mdo,gdo,DS,hdo,pdo,_do,Gp,CZ,udo,bdo,jS,vdo,Tdo,Fdo,Op,MZ,Cdo,Mdo,qS,Edo,ydo,wdo,Xp,EZ,Ado,Ldo,GS,Bdo,xdo,kdo,Vp,yZ,Rdo,Sdo,OS,Pdo,$do,Ido,zp,wZ,Ndo,Ddo,XS,jdo,qdo,Gdo,Wp,AZ,Odo,Xdo,VS,Vdo,zdo,Wdo,Qp,LZ,Qdo,Hdo,zS,Udo,Jdo,Ydo,Hp,BZ,Kdo,Zdo,WS,eco,oco,rco,Up,xZ,tco,aco,QS,nco,sco,lco,Jp,kZ,ico,dco,HS,cco,fco,mco,Yp,RZ,gco,hco,US,pco,_co,uco,Kp,SZ,bco,vco,JS,Tco,Fco,Cco,Zp,PZ,Mco,Eco,YS,yco,wco,Aco,e_,$Z,Lco,Bco,KS,xco,kco,Rco,o_,IZ,Sco,Pco,ZS,$co,Ico,Nco,r_,NZ,Dco,jco,eP,qco,Gco,Oco,t_,DZ,Xco,Vco,oP,zco,Wco,Qco,a_,jZ,Hco,Uco,rP,Jco,Yco,Kco,n_,qZ,Zco,efo,tP,ofo,rfo,tfo,s_,GZ,afo,nfo,aP,sfo,lfo,ifo,l_,OZ,dfo,cfo,nP,ffo,mfo,gfo,i_,XZ,hfo,pfo,sP,_fo,ufo,bfo,d_,VZ,vfo,Tfo,lP,Ffo,Cfo,Mfo,c_,zZ,Efo,yfo,iP,wfo,Afo,Lfo,f_,WZ,Bfo,xfo,dP,kfo,Rfo,Sfo,m_,QZ,Pfo,$fo,cP,Ifo,Nfo,Dfo,g_,HZ,jfo,qfo,fP,Gfo,Ofo,Xfo,h_,UZ,Vfo,zfo,mP,Wfo,Qfo,Hfo,p_,JZ,Ufo,Jfo,gP,Yfo,Kfo,Zfo,__,YZ,emo,omo,hP,rmo,tmo,amo,u_,KZ,nmo,smo,pP,lmo,imo,dmo,b_,ZZ,cmo,fmo,_P,mmo,gmo,hmo,v_,eee,pmo,_mo,uP,umo,bmo,vmo,T_,oee,Tmo,Fmo,bP,Cmo,Mmo,Emo,F_,ree,ymo,wmo,vP,Amo,Lmo,Bmo,C_,tee,xmo,kmo,TP,Rmo,Smo,Pmo,M_,aee,$mo,Imo,FP,Nmo,Dmo,jmo,E_,nee,qmo,Gmo,CP,Omo,Xmo,Vmo,y_,see,zmo,Wmo,MP,Qmo,Hmo,Umo,w_,Jmo,lee,Ymo,Kmo,iee,Zmo,ego,dee,ogo,rgo,Q3,Mke,Zi,A_,cee,H3,tgo,fee,ago,Eke,Yo,U3,ngo,ed,sgo,mee,lgo,igo,gee,dgo,cgo,fgo,J3,mgo,hee,ggo,hgo,pgo,zr,Y3,_go,pee,ugo,bgo,od,vgo,_ee,Tgo,Fgo,uee,Cgo,Mgo,Ego,bee,ygo,wgo,K3,Ago,De,Z3,Lgo,vee,Bgo,xgo,za,kgo,Tee,Rgo,Sgo,Fee,Pgo,$go,Cee,Igo,Ngo,Dgo,k,L_,Mee,jgo,qgo,EP,Ggo,Ogo,Xgo,B_,Eee,Vgo,zgo,yP,Wgo,Qgo,Hgo,x_,yee,Ugo,Jgo,wP,Ygo,Kgo,Zgo,k_,wee,eho,oho,AP,rho,tho,aho,R_,Aee,nho,sho,LP,lho,iho,dho,S_,Lee,cho,fho,BP,mho,gho,hho,P_,Bee,pho,_ho,xP,uho,bho,vho,$_,xee,Tho,Fho,kP,Cho,Mho,Eho,I_,kee,yho,who,RP,Aho,Lho,Bho,N_,Ree,xho,kho,SP,Rho,Sho,Pho,D_,See,$ho,Iho,PP,Nho,Dho,jho,j_,Pee,qho,Gho,$P,Oho,Xho,Vho,q_,$ee,zho,Who,IP,Qho,Hho,Uho,G_,Iee,Jho,Yho,NP,Kho,Zho,epo,O_,Nee,opo,rpo,DP,tpo,apo,npo,X_,Dee,spo,lpo,jP,ipo,dpo,cpo,V_,jee,fpo,mpo,qP,gpo,hpo,ppo,z_,qee,_po,upo,GP,bpo,vpo,Tpo,W_,Gee,Fpo,Cpo,OP,Mpo,Epo,ypo,Q_,Oee,wpo,Apo,XP,Lpo,Bpo,xpo,H_,Xee,kpo,Rpo,VP,Spo,Ppo,$po,U_,Vee,Ipo,Npo,zP,Dpo,jpo,qpo,J_,zee,Gpo,Opo,WP,Xpo,Vpo,zpo,Y_,Wee,Wpo,Qpo,QP,Hpo,Upo,Jpo,K_,Qee,Ypo,Kpo,HP,Zpo,e_o,o_o,Z_,Hee,r_o,t_o,UP,a_o,n_o,s_o,eu,Uee,l_o,i_o,JP,d_o,c_o,f_o,ou,Jee,m_o,g_o,YP,h_o,p_o,__o,ru,Yee,u_o,b_o,KP,v_o,T_o,F_o,tu,Kee,C_o,M_o,ZP,E_o,y_o,w_o,au,Zee,A_o,L_o,e$,B_o,x_o,k_o,nu,eoe,R_o,S_o,o$,P_o,$_o,I_o,su,ooe,N_o,D_o,r$,j_o,q_o,G_o,lu,roe,O_o,X_o,t$,V_o,z_o,W_o,iu,toe,Q_o,H_o,a$,U_o,J_o,Y_o,du,aoe,K_o,Z_o,n$,euo,ouo,ruo,cu,noe,tuo,auo,s$,nuo,suo,luo,fu,soe,iuo,duo,l$,cuo,fuo,muo,mu,loe,guo,huo,i$,puo,_uo,uuo,gu,buo,ioe,vuo,Tuo,doe,Fuo,Cuo,coe,Muo,Euo,ey,yke,rd,hu,foe,oy,yuo,moe,wuo,wke,Ko,ry,Auo,td,Luo,goe,Buo,xuo,hoe,kuo,Ruo,Suo,ty,Puo,poe,$uo,Iuo,Nuo,Wr,ay,Duo,_oe,juo,quo,ad,Guo,uoe,Ouo,Xuo,boe,Vuo,zuo,Wuo,voe,Quo,Huo,ny,Uuo,je,sy,Juo,Toe,Yuo,Kuo,Wa,Zuo,Foe,e5o,o5o,Coe,r5o,t5o,Moe,a5o,n5o,s5o,$,pu,Eoe,l5o,i5o,d$,d5o,c5o,f5o,_u,yoe,m5o,g5o,c$,h5o,p5o,_5o,uu,woe,u5o,b5o,f$,v5o,T5o,F5o,bu,Aoe,C5o,M5o,m$,E5o,y5o,w5o,vu,Loe,A5o,L5o,g$,B5o,x5o,k5o,Tu,Boe,R5o,S5o,h$,P5o,$5o,I5o,Fu,xoe,N5o,D5o,p$,j5o,q5o,G5o,Cu,koe,O5o,X5o,_$,V5o,z5o,W5o,Mu,Roe,Q5o,H5o,u$,U5o,J5o,Y5o,Eu,Soe,K5o,Z5o,b$,e2o,o2o,r2o,yu,Poe,t2o,a2o,v$,n2o,s2o,l2o,wu,$oe,i2o,d2o,T$,c2o,f2o,m2o,Au,Ioe,g2o,h2o,F$,p2o,_2o,u2o,Lu,Noe,b2o,v2o,C$,T2o,F2o,C2o,Bu,Doe,M2o,E2o,M$,y2o,w2o,A2o,xu,joe,L2o,B2o,E$,x2o,k2o,R2o,ku,qoe,S2o,P2o,y$,$2o,I2o,N2o,Ru,Goe,D2o,j2o,w$,q2o,G2o,O2o,Su,Ooe,X2o,V2o,A$,z2o,W2o,Q2o,Pu,Xoe,H2o,U2o,L$,J2o,Y2o,K2o,$u,Voe,Z2o,e1o,B$,o1o,r1o,t1o,Iu,zoe,a1o,n1o,x$,s1o,l1o,i1o,Nu,Woe,d1o,c1o,k$,f1o,m1o,g1o,Du,Qoe,h1o,p1o,R$,_1o,u1o,b1o,ju,Hoe,v1o,T1o,S$,F1o,C1o,M1o,qu,Uoe,E1o,y1o,P$,w1o,A1o,L1o,Gu,Joe,B1o,x1o,$$,k1o,R1o,S1o,Ou,Yoe,P1o,$1o,I$,I1o,N1o,D1o,Xu,Koe,j1o,q1o,N$,G1o,O1o,X1o,Vu,Zoe,V1o,z1o,D$,W1o,Q1o,H1o,zu,ere,U1o,J1o,j$,Y1o,K1o,Z1o,Wu,ore,ebo,obo,q$,rbo,tbo,abo,Qu,rre,nbo,sbo,G$,lbo,ibo,dbo,Hu,tre,cbo,fbo,O$,mbo,gbo,hbo,Uu,are,pbo,_bo,X$,ubo,bbo,vbo,Ju,Tbo,nre,Fbo,Cbo,sre,Mbo,Ebo,lre,ybo,wbo,ly,Ake,nd,Yu,ire,iy,Abo,dre,Lbo,Lke,Zo,dy,Bbo,sd,xbo,cre,kbo,Rbo,fre,Sbo,Pbo,$bo,cy,Ibo,mre,Nbo,Dbo,jbo,Qr,fy,qbo,gre,Gbo,Obo,ld,Xbo,hre,Vbo,zbo,pre,Wbo,Qbo,Hbo,_re,Ubo,Jbo,my,Ybo,qe,gy,Kbo,ure,Zbo,evo,Qa,ovo,bre,rvo,tvo,vre,avo,nvo,Tre,svo,lvo,ivo,I,Ku,Fre,dvo,cvo,V$,fvo,mvo,gvo,Zu,Cre,hvo,pvo,z$,_vo,uvo,bvo,e5,Mre,vvo,Tvo,W$,Fvo,Cvo,Mvo,o5,Ere,Evo,yvo,Q$,wvo,Avo,Lvo,r5,yre,Bvo,xvo,H$,kvo,Rvo,Svo,t5,wre,Pvo,$vo,U$,Ivo,Nvo,Dvo,a5,Are,jvo,qvo,J$,Gvo,Ovo,Xvo,n5,Lre,Vvo,zvo,Y$,Wvo,Qvo,Hvo,s5,Bre,Uvo,Jvo,K$,Yvo,Kvo,Zvo,l5,xre,e6o,o6o,Z$,r6o,t6o,a6o,i5,kre,n6o,s6o,eI,l6o,i6o,d6o,d5,Rre,c6o,f6o,oI,m6o,g6o,h6o,c5,Sre,p6o,_6o,rI,u6o,b6o,v6o,f5,Pre,T6o,F6o,tI,C6o,M6o,E6o,m5,$re,y6o,w6o,aI,A6o,L6o,B6o,g5,Ire,x6o,k6o,nI,R6o,S6o,P6o,h5,Nre,$6o,I6o,sI,N6o,D6o,j6o,p5,Dre,q6o,G6o,lI,O6o,X6o,V6o,_5,jre,z6o,W6o,iI,Q6o,H6o,U6o,u5,qre,J6o,Y6o,dI,K6o,Z6o,eTo,b5,Gre,oTo,rTo,cI,tTo,aTo,nTo,v5,Ore,sTo,lTo,fI,iTo,dTo,cTo,T5,Xre,fTo,mTo,mI,gTo,hTo,pTo,F5,Vre,_To,uTo,gI,bTo,vTo,TTo,C5,zre,FTo,CTo,hI,MTo,ETo,yTo,M5,Wre,wTo,ATo,pI,LTo,BTo,xTo,E5,Qre,kTo,RTo,_I,STo,PTo,$To,y5,Hre,ITo,NTo,uI,DTo,jTo,qTo,w5,Ure,GTo,OTo,bI,XTo,VTo,zTo,A5,Jre,WTo,QTo,vI,HTo,UTo,JTo,L5,Yre,YTo,KTo,Kre,ZTo,eFo,oFo,B5,Zre,rFo,tFo,TI,aFo,nFo,sFo,x5,ete,lFo,iFo,FI,dFo,cFo,fFo,k5,ote,mFo,gFo,CI,hFo,pFo,_Fo,R5,rte,uFo,bFo,MI,vFo,TFo,FFo,S5,CFo,tte,MFo,EFo,ate,yFo,wFo,nte,AFo,LFo,hy,Bke,id,P5,ste,py,BFo,lte,xFo,xke,er,_y,kFo,dd,RFo,ite,SFo,PFo,dte,$Fo,IFo,NFo,uy,DFo,cte,jFo,qFo,GFo,Hr,by,OFo,fte,XFo,VFo,cd,zFo,mte,WFo,QFo,gte,HFo,UFo,JFo,hte,YFo,KFo,vy,ZFo,Ge,Ty,eCo,pte,oCo,rCo,Ha,tCo,_te,aCo,nCo,ute,sCo,lCo,bte,iCo,dCo,cCo,se,$5,vte,fCo,mCo,EI,gCo,hCo,pCo,I5,Tte,_Co,uCo,yI,bCo,vCo,TCo,N5,Fte,FCo,CCo,wI,MCo,ECo,yCo,D5,Cte,wCo,ACo,AI,LCo,BCo,xCo,j5,Mte,kCo,RCo,LI,SCo,PCo,$Co,q5,Ete,ICo,NCo,BI,DCo,jCo,qCo,G5,yte,GCo,OCo,xI,XCo,VCo,zCo,O5,wte,WCo,QCo,kI,HCo,UCo,JCo,X5,Ate,YCo,KCo,RI,ZCo,eMo,oMo,V5,Lte,rMo,tMo,SI,aMo,nMo,sMo,z5,Bte,lMo,iMo,PI,dMo,cMo,fMo,W5,xte,mMo,gMo,$I,hMo,pMo,_Mo,Q5,kte,uMo,bMo,II,vMo,TMo,FMo,H5,Rte,CMo,MMo,NI,EMo,yMo,wMo,U5,Ste,AMo,LMo,DI,BMo,xMo,kMo,J5,Pte,RMo,SMo,jI,PMo,$Mo,IMo,Y5,NMo,$te,DMo,jMo,Ite,qMo,GMo,Nte,OMo,XMo,Fy,kke,fd,K5,Dte,Cy,VMo,jte,zMo,Rke,or,My,WMo,md,QMo,qte,HMo,UMo,Gte,JMo,YMo,KMo,Ey,ZMo,Ote,e4o,o4o,r4o,Ur,yy,t4o,Xte,a4o,n4o,gd,s4o,Vte,l4o,i4o,zte,d4o,c4o,f4o,Wte,m4o,g4o,wy,h4o,Oe,Ay,p4o,Qte,_4o,u4o,Ua,b4o,Hte,v4o,T4o,Ute,F4o,C4o,Jte,M4o,E4o,y4o,A,Z5,Yte,w4o,A4o,qI,L4o,B4o,x4o,e2,Kte,k4o,R4o,GI,S4o,P4o,$4o,o2,Zte,I4o,N4o,OI,D4o,j4o,q4o,r2,eae,G4o,O4o,XI,X4o,V4o,z4o,t2,oae,W4o,Q4o,VI,H4o,U4o,J4o,a2,rae,Y4o,K4o,zI,Z4o,eEo,oEo,n2,tae,rEo,tEo,WI,aEo,nEo,sEo,s2,aae,lEo,iEo,QI,dEo,cEo,fEo,l2,nae,mEo,gEo,HI,hEo,pEo,_Eo,i2,sae,uEo,bEo,UI,vEo,TEo,FEo,d2,lae,CEo,MEo,JI,EEo,yEo,wEo,c2,iae,AEo,LEo,YI,BEo,xEo,kEo,f2,dae,REo,SEo,KI,PEo,$Eo,IEo,m2,cae,NEo,DEo,ZI,jEo,qEo,GEo,g2,fae,OEo,XEo,eN,VEo,zEo,WEo,h2,mae,QEo,HEo,oN,UEo,JEo,YEo,p2,gae,KEo,ZEo,rN,e3o,o3o,r3o,_2,hae,t3o,a3o,tN,n3o,s3o,l3o,u2,pae,i3o,d3o,aN,c3o,f3o,m3o,b2,_ae,g3o,h3o,nN,p3o,_3o,u3o,v2,uae,b3o,v3o,sN,T3o,F3o,C3o,T2,bae,M3o,E3o,lN,y3o,w3o,A3o,F2,vae,L3o,B3o,iN,x3o,k3o,R3o,C2,Tae,S3o,P3o,dN,$3o,I3o,N3o,M2,Fae,D3o,j3o,cN,q3o,G3o,O3o,E2,Cae,X3o,V3o,fN,z3o,W3o,Q3o,y2,Mae,H3o,U3o,mN,J3o,Y3o,K3o,w2,Eae,Z3o,eyo,gN,oyo,ryo,tyo,A2,yae,ayo,nyo,hN,syo,lyo,iyo,L2,wae,dyo,cyo,pN,fyo,myo,gyo,B2,Aae,hyo,pyo,_N,_yo,uyo,byo,x2,Lae,vyo,Tyo,uN,Fyo,Cyo,Myo,k2,Bae,Eyo,yyo,bN,wyo,Ayo,Lyo,R2,xae,Byo,xyo,vN,kyo,Ryo,Syo,S2,kae,Pyo,$yo,TN,Iyo,Nyo,Dyo,P2,Rae,jyo,qyo,FN,Gyo,Oyo,Xyo,$2,Sae,Vyo,zyo,CN,Wyo,Qyo,Hyo,I2,Pae,Uyo,Jyo,MN,Yyo,Kyo,Zyo,N2,$ae,ewo,owo,EN,rwo,two,awo,D2,Iae,nwo,swo,yN,lwo,iwo,dwo,j2,Nae,cwo,fwo,wN,mwo,gwo,hwo,q2,Dae,pwo,_wo,AN,uwo,bwo,vwo,G2,jae,Two,Fwo,LN,Cwo,Mwo,Ewo,O2,qae,ywo,wwo,BN,Awo,Lwo,Bwo,X2,Gae,xwo,kwo,xN,Rwo,Swo,Pwo,V2,Oae,$wo,Iwo,kN,Nwo,Dwo,jwo,z2,qwo,Xae,Gwo,Owo,Vae,Xwo,Vwo,zae,zwo,Wwo,Ly,Ske,hd,W2,Wae,By,Qwo,Qae,Hwo,Pke,rr,xy,Uwo,pd,Jwo,Hae,Ywo,Kwo,Uae,Zwo,eAo,oAo,ky,rAo,Jae,tAo,aAo,nAo,Jr,Ry,sAo,Yae,lAo,iAo,_d,dAo,Kae,cAo,fAo,Zae,mAo,gAo,hAo,ene,pAo,_Ao,Sy,uAo,Xe,Py,bAo,one,vAo,TAo,Ja,FAo,rne,CAo,MAo,tne,EAo,yAo,ane,wAo,AAo,LAo,G,Q2,nne,BAo,xAo,RN,kAo,RAo,SAo,H2,sne,PAo,$Ao,SN,IAo,NAo,DAo,U2,lne,jAo,qAo,PN,GAo,OAo,XAo,J2,ine,VAo,zAo,$N,WAo,QAo,HAo,Y2,dne,UAo,JAo,IN,YAo,KAo,ZAo,K2,cne,e0o,o0o,NN,r0o,t0o,a0o,Z2,fne,n0o,s0o,DN,l0o,i0o,d0o,e1,mne,c0o,f0o,jN,m0o,g0o,h0o,o1,gne,p0o,_0o,qN,u0o,b0o,v0o,r1,hne,T0o,F0o,GN,C0o,M0o,E0o,t1,pne,y0o,w0o,ON,A0o,L0o,B0o,a1,_ne,x0o,k0o,XN,R0o,S0o,P0o,n1,une,$0o,I0o,VN,N0o,D0o,j0o,s1,bne,q0o,G0o,zN,O0o,X0o,V0o,l1,vne,z0o,W0o,WN,Q0o,H0o,U0o,i1,Tne,J0o,Y0o,QN,K0o,Z0o,eLo,d1,Fne,oLo,rLo,HN,tLo,aLo,nLo,c1,Cne,sLo,lLo,UN,iLo,dLo,cLo,f1,Mne,fLo,mLo,JN,gLo,hLo,pLo,m1,Ene,_Lo,uLo,YN,bLo,vLo,TLo,g1,yne,FLo,CLo,KN,MLo,ELo,yLo,h1,wne,wLo,ALo,ZN,LLo,BLo,xLo,p1,Ane,kLo,RLo,eD,SLo,PLo,$Lo,_1,Lne,ILo,NLo,oD,DLo,jLo,qLo,u1,Bne,GLo,OLo,rD,XLo,VLo,zLo,b1,xne,WLo,QLo,tD,HLo,ULo,JLo,v1,kne,YLo,KLo,aD,ZLo,e7o,o7o,T1,Rne,r7o,t7o,nD,a7o,n7o,s7o,F1,l7o,Sne,i7o,d7o,Pne,c7o,f7o,$ne,m7o,g7o,$y,$ke,ud,C1,Ine,Iy,h7o,Nne,p7o,Ike,tr,Ny,_7o,bd,u7o,Dne,b7o,v7o,jne,T7o,F7o,C7o,Dy,M7o,qne,E7o,y7o,w7o,Yr,jy,A7o,Gne,L7o,B7o,vd,x7o,One,k7o,R7o,Xne,S7o,P7o,$7o,Vne,I7o,N7o,qy,D7o,Ve,Gy,j7o,zne,q7o,G7o,Ya,O7o,Wne,X7o,V7o,Qne,z7o,W7o,Hne,Q7o,H7o,U7o,da,M1,Une,J7o,Y7o,sD,K7o,Z7o,e8o,E1,Jne,o8o,r8o,lD,t8o,a8o,n8o,y1,Yne,s8o,l8o,iD,i8o,d8o,c8o,w1,Kne,f8o,m8o,dD,g8o,h8o,p8o,A1,Zne,_8o,u8o,cD,b8o,v8o,T8o,L1,F8o,ese,C8o,M8o,ose,E8o,y8o,rse,w8o,A8o,Oy,Nke,Td,B1,tse,Xy,L8o,ase,B8o,Dke,ar,Vy,x8o,Fd,k8o,nse,R8o,S8o,sse,P8o,$8o,I8o,zy,N8o,lse,D8o,j8o,q8o,Kr,Wy,G8o,ise,O8o,X8o,Cd,V8o,dse,z8o,W8o,cse,Q8o,H8o,U8o,fse,J8o,Y8o,Qy,K8o,ze,Hy,Z8o,mse,e9o,o9o,Ka,r9o,gse,t9o,a9o,hse,n9o,s9o,pse,l9o,i9o,d9o,j,x1,_se,c9o,f9o,fD,m9o,g9o,h9o,k1,use,p9o,_9o,mD,u9o,b9o,v9o,R1,bse,T9o,F9o,gD,C9o,M9o,E9o,S1,vse,y9o,w9o,hD,A9o,L9o,B9o,P1,Tse,x9o,k9o,pD,R9o,S9o,P9o,$1,Fse,$9o,I9o,_D,N9o,D9o,j9o,I1,Cse,q9o,G9o,uD,O9o,X9o,V9o,N1,Mse,z9o,W9o,bD,Q9o,H9o,U9o,D1,Ese,J9o,Y9o,vD,K9o,Z9o,eBo,j1,yse,oBo,rBo,TD,tBo,aBo,nBo,q1,wse,sBo,lBo,FD,iBo,dBo,cBo,G1,Ase,fBo,mBo,CD,gBo,hBo,pBo,O1,Lse,_Bo,uBo,MD,bBo,vBo,TBo,X1,Bse,FBo,CBo,ED,MBo,EBo,yBo,V1,xse,wBo,ABo,yD,LBo,BBo,xBo,z1,kse,kBo,RBo,wD,SBo,PBo,$Bo,W1,Rse,IBo,NBo,AD,DBo,jBo,qBo,Q1,Sse,GBo,OBo,LD,XBo,VBo,zBo,H1,Pse,WBo,QBo,BD,HBo,UBo,JBo,U1,$se,YBo,KBo,xD,ZBo,exo,oxo,J1,Ise,rxo,txo,kD,axo,nxo,sxo,Y1,Nse,lxo,ixo,RD,dxo,cxo,fxo,K1,Dse,mxo,gxo,SD,hxo,pxo,_xo,Z1,jse,uxo,bxo,PD,vxo,Txo,Fxo,eb,qse,Cxo,Mxo,$D,Exo,yxo,wxo,ob,Gse,Axo,Lxo,ID,Bxo,xxo,kxo,rb,Ose,Rxo,Sxo,ND,Pxo,$xo,Ixo,tb,Xse,Nxo,Dxo,DD,jxo,qxo,Gxo,ab,Vse,Oxo,Xxo,jD,Vxo,zxo,Wxo,nb,zse,Qxo,Hxo,qD,Uxo,Jxo,Yxo,sb,Wse,Kxo,Zxo,GD,eko,oko,rko,lb,Qse,tko,ako,OD,nko,sko,lko,ib,Hse,iko,dko,XD,cko,fko,mko,db,gko,Use,hko,pko,Jse,_ko,uko,Yse,bko,vko,Uy,jke,Md,cb,Kse,Jy,Tko,Zse,Fko,qke,nr,Yy,Cko,Ed,Mko,ele,Eko,yko,ole,wko,Ako,Lko,Ky,Bko,rle,xko,kko,Rko,Zr,Zy,Sko,tle,Pko,$ko,yd,Iko,ale,Nko,Dko,nle,jko,qko,Gko,sle,Oko,Xko,ew,Vko,We,ow,zko,lle,Wko,Qko,Za,Hko,ile,Uko,Jko,dle,Yko,Kko,cle,Zko,eRo,oRo,R,fb,fle,rRo,tRo,VD,aRo,nRo,sRo,mb,mle,lRo,iRo,zD,dRo,cRo,fRo,gb,gle,mRo,gRo,WD,hRo,pRo,_Ro,hb,hle,uRo,bRo,QD,vRo,TRo,FRo,pb,ple,CRo,MRo,HD,ERo,yRo,wRo,_b,_le,ARo,LRo,UD,BRo,xRo,kRo,ub,ule,RRo,SRo,JD,PRo,$Ro,IRo,bb,ble,NRo,DRo,YD,jRo,qRo,GRo,vb,vle,ORo,XRo,KD,VRo,zRo,WRo,Tb,Tle,QRo,HRo,ZD,URo,JRo,YRo,Fb,Fle,KRo,ZRo,ej,eSo,oSo,rSo,Cb,Cle,tSo,aSo,oj,nSo,sSo,lSo,Mb,Mle,iSo,dSo,rj,cSo,fSo,mSo,Eb,Ele,gSo,hSo,tj,pSo,_So,uSo,yb,yle,bSo,vSo,aj,TSo,FSo,CSo,wb,wle,MSo,ESo,nj,ySo,wSo,ASo,Ab,Ale,LSo,BSo,sj,xSo,kSo,RSo,Lb,Lle,SSo,PSo,lj,$So,ISo,NSo,Bb,Ble,DSo,jSo,ij,qSo,GSo,OSo,xb,xle,XSo,VSo,dj,zSo,WSo,QSo,kb,kle,HSo,USo,cj,JSo,YSo,KSo,Rb,Rle,ZSo,ePo,fj,oPo,rPo,tPo,Sb,Sle,aPo,nPo,mj,sPo,lPo,iPo,Pb,Ple,dPo,cPo,gj,fPo,mPo,gPo,$b,$le,hPo,pPo,hj,_Po,uPo,bPo,Ib,Ile,vPo,TPo,pj,FPo,CPo,MPo,Nb,Nle,EPo,yPo,_j,wPo,APo,LPo,Db,Dle,BPo,xPo,uj,kPo,RPo,SPo,jb,jle,PPo,$Po,bj,IPo,NPo,DPo,qb,qle,jPo,qPo,vj,GPo,OPo,XPo,Gb,Gle,VPo,zPo,Tj,WPo,QPo,HPo,Ob,Ole,UPo,JPo,Fj,YPo,KPo,ZPo,Xb,Xle,e$o,o$o,Cj,r$o,t$o,a$o,Vb,Vle,n$o,s$o,Mj,l$o,i$o,d$o,zb,zle,c$o,f$o,Ej,m$o,g$o,h$o,Wb,Wle,p$o,_$o,yj,u$o,b$o,v$o,Qb,Qle,T$o,F$o,wj,C$o,M$o,E$o,Hb,Hle,y$o,w$o,Aj,A$o,L$o,B$o,Ub,Ule,x$o,k$o,Lj,R$o,S$o,P$o,Jb,$$o,Jle,I$o,N$o,Yle,D$o,j$o,Kle,q$o,G$o,rw,Gke,wd,Yb,Zle,tw,O$o,eie,X$o,Oke,sr,aw,V$o,Ad,z$o,oie,W$o,Q$o,rie,H$o,U$o,J$o,nw,Y$o,tie,K$o,Z$o,eIo,et,sw,oIo,aie,rIo,tIo,Ld,aIo,nie,nIo,sIo,sie,lIo,iIo,dIo,lie,cIo,fIo,lw,mIo,Qe,iw,gIo,iie,hIo,pIo,en,_Io,die,uIo,bIo,cie,vIo,TIo,fie,FIo,CIo,MIo,mie,Kb,gie,EIo,yIo,Bj,wIo,AIo,LIo,Zb,BIo,hie,xIo,kIo,pie,RIo,SIo,_ie,PIo,$Io,dw,Xke,Bd,ev,uie,cw,IIo,bie,NIo,Vke,lr,fw,DIo,xd,jIo,vie,qIo,GIo,Tie,OIo,XIo,VIo,mw,zIo,Fie,WIo,QIo,HIo,ot,gw,UIo,Cie,JIo,YIo,kd,KIo,Mie,ZIo,eNo,Eie,oNo,rNo,tNo,yie,aNo,nNo,hw,sNo,He,pw,lNo,wie,iNo,dNo,on,cNo,Aie,fNo,mNo,Lie,gNo,hNo,Bie,pNo,_No,uNo,me,ov,xie,bNo,vNo,xj,TNo,FNo,CNo,rv,kie,MNo,ENo,kj,yNo,wNo,ANo,qs,Rie,LNo,BNo,Rj,xNo,kNo,Sj,RNo,SNo,PNo,tv,Sie,$No,INo,Pj,NNo,DNo,jNo,ma,Pie,qNo,GNo,$j,ONo,XNo,Ij,VNo,zNo,Nj,WNo,QNo,HNo,av,$ie,UNo,JNo,Dj,YNo,KNo,ZNo,nv,Iie,eDo,oDo,jj,rDo,tDo,aDo,sv,Nie,nDo,sDo,qj,lDo,iDo,dDo,lv,Die,cDo,fDo,Gj,mDo,gDo,hDo,iv,jie,pDo,_Do,Oj,uDo,bDo,vDo,dv,qie,TDo,FDo,Xj,CDo,MDo,EDo,cv,yDo,Gie,wDo,ADo,Oie,LDo,BDo,Xie,xDo,kDo,_w,zke,Rd,fv,Vie,uw,RDo,zie,SDo,Wke,ir,bw,PDo,Sd,$Do,Wie,IDo,NDo,Qie,DDo,jDo,qDo,vw,GDo,Hie,ODo,XDo,VDo,rt,Tw,zDo,Uie,WDo,QDo,Pd,HDo,Jie,UDo,JDo,Yie,YDo,KDo,ZDo,Kie,ejo,ojo,Fw,rjo,Ue,Cw,tjo,Zie,ajo,njo,rn,sjo,ede,ljo,ijo,ode,djo,cjo,rde,fjo,mjo,gjo,tde,mv,ade,hjo,pjo,Vj,_jo,ujo,bjo,gv,vjo,nde,Tjo,Fjo,sde,Cjo,Mjo,lde,Ejo,yjo,Mw,Qke,$d,hv,ide,Ew,wjo,dde,Ajo,Hke,dr,yw,Ljo,Id,Bjo,cde,xjo,kjo,fde,Rjo,Sjo,Pjo,ww,$jo,mde,Ijo,Njo,Djo,tt,Aw,jjo,gde,qjo,Gjo,Nd,Ojo,hde,Xjo,Vjo,pde,zjo,Wjo,Qjo,_de,Hjo,Ujo,Lw,Jjo,Je,Bw,Yjo,ude,Kjo,Zjo,tn,eqo,bde,oqo,rqo,vde,tqo,aqo,Tde,nqo,sqo,lqo,ke,pv,Fde,iqo,dqo,zj,cqo,fqo,mqo,_v,Cde,gqo,hqo,Wj,pqo,_qo,uqo,uv,Mde,bqo,vqo,Qj,Tqo,Fqo,Cqo,bv,Ede,Mqo,Eqo,Hj,yqo,wqo,Aqo,vv,yde,Lqo,Bqo,Uj,xqo,kqo,Rqo,Tv,wde,Sqo,Pqo,Jj,$qo,Iqo,Nqo,Fv,Ade,Dqo,jqo,Yj,qqo,Gqo,Oqo,Cv,Lde,Xqo,Vqo,Kj,zqo,Wqo,Qqo,Mv,Hqo,Bde,Uqo,Jqo,xde,Yqo,Kqo,kde,Zqo,eGo,xw,Uke,Dd,Ev,Rde,kw,oGo,Sde,rGo,Jke,cr,Rw,tGo,jd,aGo,Pde,nGo,sGo,$de,lGo,iGo,dGo,Sw,cGo,Ide,fGo,mGo,gGo,at,Pw,hGo,Nde,pGo,_Go,qd,uGo,Dde,bGo,vGo,jde,TGo,FGo,CGo,qde,MGo,EGo,$w,yGo,Ye,Iw,wGo,Gde,AGo,LGo,an,BGo,Ode,xGo,kGo,Xde,RGo,SGo,Vde,PGo,$Go,IGo,nn,yv,zde,NGo,DGo,Zj,jGo,qGo,GGo,wv,Wde,OGo,XGo,eq,VGo,zGo,WGo,Av,Qde,QGo,HGo,oq,UGo,JGo,YGo,Lv,Hde,KGo,ZGo,rq,eOo,oOo,rOo,Bv,tOo,Ude,aOo,nOo,Jde,sOo,lOo,Yde,iOo,dOo,Nw,Yke,Gd,xv,Kde,Dw,cOo,Zde,fOo,Kke,fr,jw,mOo,Od,gOo,ece,hOo,pOo,oce,_Oo,uOo,bOo,qw,vOo,rce,TOo,FOo,COo,nt,Gw,MOo,tce,EOo,yOo,Xd,wOo,ace,AOo,LOo,nce,BOo,xOo,kOo,sce,ROo,SOo,Ow,POo,Ke,Xw,$Oo,lce,IOo,NOo,sn,DOo,ice,jOo,qOo,dce,GOo,OOo,cce,XOo,VOo,zOo,Re,kv,fce,WOo,QOo,tq,HOo,UOo,JOo,Rv,mce,YOo,KOo,aq,ZOo,eXo,oXo,Sv,gce,rXo,tXo,nq,aXo,nXo,sXo,Pv,hce,lXo,iXo,sq,dXo,cXo,fXo,$v,pce,mXo,gXo,lq,hXo,pXo,_Xo,Iv,_ce,uXo,bXo,iq,vXo,TXo,FXo,Nv,uce,CXo,MXo,dq,EXo,yXo,wXo,Dv,bce,AXo,LXo,cq,BXo,xXo,kXo,jv,RXo,vce,SXo,PXo,Tce,$Xo,IXo,Fce,NXo,DXo,Vw,Zke,Vd,qv,Cce,zw,jXo,Mce,qXo,eRe,mr,Ww,GXo,zd,OXo,Ece,XXo,VXo,yce,zXo,WXo,QXo,Qw,HXo,wce,UXo,JXo,YXo,st,Hw,KXo,Ace,ZXo,eVo,Wd,oVo,Lce,rVo,tVo,Bce,aVo,nVo,sVo,xce,lVo,iVo,Uw,dVo,Ze,Jw,cVo,kce,fVo,mVo,ln,gVo,Rce,hVo,pVo,Sce,_Vo,uVo,Pce,bVo,vVo,TVo,Yw,Gv,$ce,FVo,CVo,fq,MVo,EVo,yVo,Ov,Ice,wVo,AVo,mq,LVo,BVo,xVo,Xv,kVo,Nce,RVo,SVo,Dce,PVo,$Vo,jce,IVo,NVo,Kw,oRe,Qd,Vv,qce,Zw,DVo,Gce,jVo,rRe,gr,eA,qVo,Hd,GVo,Oce,OVo,XVo,Xce,VVo,zVo,WVo,oA,QVo,Vce,HVo,UVo,JVo,lt,rA,YVo,zce,KVo,ZVo,Ud,ezo,Wce,ozo,rzo,Qce,tzo,azo,nzo,Hce,szo,lzo,tA,izo,eo,aA,dzo,Uce,czo,fzo,dn,mzo,Jce,gzo,hzo,Yce,pzo,_zo,Kce,uzo,bzo,vzo,cn,zv,Zce,Tzo,Fzo,gq,Czo,Mzo,Ezo,Wv,efe,yzo,wzo,hq,Azo,Lzo,Bzo,Qv,ofe,xzo,kzo,pq,Rzo,Szo,Pzo,Hv,rfe,$zo,Izo,_q,Nzo,Dzo,jzo,Uv,qzo,tfe,Gzo,Ozo,afe,Xzo,Vzo,nfe,zzo,Wzo,nA,tRe,Jd,Jv,sfe,sA,Qzo,lfe,Hzo,aRe,hr,lA,Uzo,Yd,Jzo,ife,Yzo,Kzo,dfe,Zzo,eWo,oWo,iA,rWo,cfe,tWo,aWo,nWo,it,dA,sWo,ffe,lWo,iWo,Kd,dWo,mfe,cWo,fWo,gfe,mWo,gWo,hWo,hfe,pWo,_Wo,cA,uWo,oo,fA,bWo,pfe,vWo,TWo,fn,FWo,_fe,CWo,MWo,ufe,EWo,yWo,bfe,wWo,AWo,LWo,Zd,Yv,vfe,BWo,xWo,uq,kWo,RWo,SWo,Kv,Tfe,PWo,$Wo,bq,IWo,NWo,DWo,Zv,Ffe,jWo,qWo,vq,GWo,OWo,XWo,e6,VWo,Cfe,zWo,WWo,Mfe,QWo,HWo,Efe,UWo,JWo,mA,nRe,ec,o6,yfe,gA,YWo,wfe,KWo,sRe,pr,hA,ZWo,oc,eQo,Afe,oQo,rQo,Lfe,tQo,aQo,nQo,pA,sQo,Bfe,lQo,iQo,dQo,dt,_A,cQo,xfe,fQo,mQo,rc,gQo,kfe,hQo,pQo,Rfe,_Qo,uQo,bQo,Sfe,vQo,TQo,uA,FQo,ro,bA,CQo,Pfe,MQo,EQo,mn,yQo,$fe,wQo,AQo,Ife,LQo,BQo,Nfe,xQo,kQo,RQo,Dfe,r6,jfe,SQo,PQo,Tq,$Qo,IQo,NQo,t6,DQo,qfe,jQo,qQo,Gfe,GQo,OQo,Ofe,XQo,VQo,vA,lRe,tc,a6,Xfe,TA,zQo,Vfe,WQo,iRe,_r,FA,QQo,ac,HQo,zfe,UQo,JQo,Wfe,YQo,KQo,ZQo,CA,eHo,Qfe,oHo,rHo,tHo,ct,MA,aHo,Hfe,nHo,sHo,nc,lHo,Ufe,iHo,dHo,Jfe,cHo,fHo,mHo,Yfe,gHo,hHo,EA,pHo,to,yA,_Ho,Kfe,uHo,bHo,gn,vHo,Zfe,THo,FHo,eme,CHo,MHo,ome,EHo,yHo,wHo,rme,n6,tme,AHo,LHo,Fq,BHo,xHo,kHo,s6,RHo,ame,SHo,PHo,nme,$Ho,IHo,sme,NHo,DHo,wA,dRe,sc,l6,lme,AA,jHo,ime,qHo,cRe,ur,LA,GHo,lc,OHo,dme,XHo,VHo,cme,zHo,WHo,QHo,BA,HHo,fme,UHo,JHo,YHo,ft,xA,KHo,mme,ZHo,eUo,ic,oUo,gme,rUo,tUo,hme,aUo,nUo,sUo,pme,lUo,iUo,kA,dUo,ao,RA,cUo,_me,fUo,mUo,hn,gUo,ume,hUo,pUo,bme,_Uo,uUo,vme,bUo,vUo,TUo,SA,i6,Tme,FUo,CUo,Cq,MUo,EUo,yUo,d6,Fme,wUo,AUo,Mq,LUo,BUo,xUo,c6,kUo,Cme,RUo,SUo,Mme,PUo,$Uo,Eme,IUo,NUo,PA,fRe,dc,f6,yme,$A,DUo,wme,jUo,mRe,br,IA,qUo,cc,GUo,Ame,OUo,XUo,Lme,VUo,zUo,WUo,NA,QUo,Bme,HUo,UUo,JUo,mt,DA,YUo,xme,KUo,ZUo,fc,eJo,kme,oJo,rJo,Rme,tJo,aJo,nJo,Sme,sJo,lJo,jA,iJo,no,qA,dJo,Pme,cJo,fJo,pn,mJo,$me,gJo,hJo,Ime,pJo,_Jo,Nme,uJo,bJo,vJo,Dme,m6,jme,TJo,FJo,Eq,CJo,MJo,EJo,g6,yJo,qme,wJo,AJo,Gme,LJo,BJo,Ome,xJo,kJo,GA,gRe,mc,h6,Xme,OA,RJo,Vme,SJo,hRe,vr,XA,PJo,gc,$Jo,zme,IJo,NJo,Wme,DJo,jJo,qJo,VA,GJo,Qme,OJo,XJo,VJo,gt,zA,zJo,Hme,WJo,QJo,hc,HJo,Ume,UJo,JJo,Jme,YJo,KJo,ZJo,Yme,eYo,oYo,WA,rYo,ho,QA,tYo,Kme,aYo,nYo,_n,sYo,Zme,lYo,iYo,ege,dYo,cYo,oge,fYo,mYo,gYo,B,p6,rge,hYo,pYo,yq,_Yo,uYo,bYo,_6,tge,vYo,TYo,wq,FYo,CYo,MYo,u6,age,EYo,yYo,Aq,wYo,AYo,LYo,b6,nge,BYo,xYo,Lq,kYo,RYo,SYo,v6,sge,PYo,$Yo,Bq,IYo,NYo,DYo,T6,lge,jYo,qYo,xq,GYo,OYo,XYo,F6,ige,VYo,zYo,kq,WYo,QYo,HYo,C6,dge,UYo,JYo,Rq,YYo,KYo,ZYo,M6,cge,eKo,oKo,Sq,rKo,tKo,aKo,E6,fge,nKo,sKo,Pq,lKo,iKo,dKo,y6,mge,cKo,fKo,$q,mKo,gKo,hKo,w6,gge,pKo,_Ko,Iq,uKo,bKo,vKo,A6,hge,TKo,FKo,Nq,CKo,MKo,EKo,L6,pge,yKo,wKo,Dq,AKo,LKo,BKo,B6,_ge,xKo,kKo,jq,RKo,SKo,PKo,x6,uge,$Ko,IKo,qq,NKo,DKo,jKo,Gs,bge,qKo,GKo,Gq,OKo,XKo,Oq,VKo,zKo,WKo,k6,vge,QKo,HKo,Xq,UKo,JKo,YKo,R6,Tge,KKo,ZKo,Vq,eZo,oZo,rZo,S6,Fge,tZo,aZo,zq,nZo,sZo,lZo,P6,Cge,iZo,dZo,Wq,cZo,fZo,mZo,$6,Mge,gZo,hZo,Qq,pZo,_Zo,uZo,I6,Ege,bZo,vZo,Hq,TZo,FZo,CZo,N6,yge,MZo,EZo,Uq,yZo,wZo,AZo,D6,wge,LZo,BZo,Jq,xZo,kZo,RZo,j6,Age,SZo,PZo,Yq,$Zo,IZo,NZo,q6,Lge,DZo,jZo,Kq,qZo,GZo,OZo,G6,Bge,XZo,VZo,Zq,zZo,WZo,QZo,O6,xge,HZo,UZo,eG,JZo,YZo,KZo,X6,kge,ZZo,eer,oG,oer,rer,ter,V6,Rge,aer,ner,rG,ser,ler,ier,z6,Sge,der,cer,tG,fer,mer,ger,W6,Pge,her,per,aG,_er,uer,ber,Q6,$ge,ver,Ter,nG,Fer,Cer,Mer,H6,Ige,Eer,yer,sG,wer,Aer,Ler,U6,Nge,Ber,xer,lG,ker,Rer,Ser,J6,Dge,Per,$er,iG,Ier,Ner,Der,Y6,jge,jer,qer,dG,Ger,Oer,Xer,K6,qge,Ver,zer,cG,Wer,Qer,Her,Z6,Gge,Uer,Jer,fG,Yer,Ker,Zer,eT,Oge,eor,oor,mG,ror,tor,aor,oT,Xge,nor,sor,gG,lor,ior,dor,rT,Vge,cor,mor,hG,gor,hor,por,zge,_or,uor,HA,pRe,pc,tT,Wge,UA,bor,Qge,vor,_Re,Tr,JA,Tor,_c,For,Hge,Cor,Mor,Uge,Eor,yor,wor,YA,Aor,Jge,Lor,Bor,xor,ht,KA,kor,Yge,Ror,Sor,uc,Por,Kge,$or,Ior,Zge,Nor,Dor,jor,ehe,qor,Gor,ZA,Oor,po,e0,Xor,ohe,Vor,zor,un,Wor,rhe,Qor,Hor,the,Uor,Jor,ahe,Yor,Kor,Zor,H,aT,nhe,err,orr,pG,rrr,trr,arr,nT,she,nrr,srr,_G,lrr,irr,drr,sT,lhe,crr,frr,uG,mrr,grr,hrr,lT,ihe,prr,_rr,bG,urr,brr,vrr,iT,dhe,Trr,Frr,vG,Crr,Mrr,Err,dT,che,yrr,wrr,TG,Arr,Lrr,Brr,cT,fhe,xrr,krr,FG,Rrr,Srr,Prr,fT,mhe,$rr,Irr,CG,Nrr,Drr,jrr,mT,ghe,qrr,Grr,MG,Orr,Xrr,Vrr,gT,hhe,zrr,Wrr,EG,Qrr,Hrr,Urr,hT,phe,Jrr,Yrr,yG,Krr,Zrr,etr,pT,_he,otr,rtr,wG,ttr,atr,ntr,_T,uhe,str,ltr,AG,itr,dtr,ctr,uT,bhe,ftr,mtr,LG,gtr,htr,ptr,bT,vhe,_tr,utr,BG,btr,vtr,Ttr,vT,The,Ftr,Ctr,xG,Mtr,Etr,ytr,TT,Fhe,wtr,Atr,kG,Ltr,Btr,xtr,FT,Che,ktr,Rtr,RG,Str,Ptr,$tr,CT,Mhe,Itr,Ntr,SG,Dtr,jtr,qtr,MT,Ehe,Gtr,Otr,PG,Xtr,Vtr,ztr,ET,yhe,Wtr,Qtr,$G,Htr,Utr,Jtr,yT,whe,Ytr,Ktr,IG,Ztr,ear,oar,wT,Ahe,rar,tar,NG,aar,nar,sar,Lhe,lar,iar,o0,uRe,bc,AT,Bhe,r0,dar,xhe,car,bRe,Fr,t0,far,vc,mar,khe,gar,har,Rhe,par,_ar,uar,a0,bar,She,Tar,Far,Car,pt,n0,Mar,Phe,Ear,yar,Tc,war,$he,Aar,Lar,Ihe,Bar,xar,kar,Nhe,Rar,Sar,s0,Par,_o,l0,$ar,Dhe,Iar,Nar,bn,Dar,jhe,jar,qar,qhe,Gar,Oar,Ghe,Xar,Var,zar,ge,LT,Ohe,War,Qar,DG,Har,Uar,Jar,BT,Xhe,Yar,Kar,jG,Zar,enr,onr,xT,Vhe,rnr,tnr,qG,anr,nnr,snr,kT,zhe,lnr,inr,GG,dnr,cnr,fnr,RT,Whe,mnr,gnr,OG,hnr,pnr,_nr,ST,Qhe,unr,bnr,XG,vnr,Tnr,Fnr,PT,Hhe,Cnr,Mnr,VG,Enr,ynr,wnr,$T,Uhe,Anr,Lnr,zG,Bnr,xnr,knr,IT,Jhe,Rnr,Snr,WG,Pnr,$nr,Inr,NT,Yhe,Nnr,Dnr,QG,jnr,qnr,Gnr,DT,Khe,Onr,Xnr,HG,Vnr,znr,Wnr,Zhe,Qnr,Hnr,i0,vRe,Fc,jT,epe,d0,Unr,ope,Jnr,TRe,Cr,c0,Ynr,Cc,Knr,rpe,Znr,esr,tpe,osr,rsr,tsr,f0,asr,ape,nsr,ssr,lsr,_t,m0,isr,npe,dsr,csr,Mc,fsr,spe,msr,gsr,lpe,hsr,psr,_sr,ipe,usr,bsr,g0,vsr,uo,h0,Tsr,dpe,Fsr,Csr,vn,Msr,cpe,Esr,ysr,fpe,wsr,Asr,mpe,Lsr,Bsr,xsr,p0,qT,gpe,ksr,Rsr,UG,Ssr,Psr,$sr,GT,hpe,Isr,Nsr,JG,Dsr,jsr,qsr,ppe,Gsr,Osr,_0,FRe,Ec,OT,_pe,u0,Xsr,upe,Vsr,CRe,Mr,b0,zsr,yc,Wsr,bpe,Qsr,Hsr,vpe,Usr,Jsr,Ysr,v0,Ksr,Tpe,Zsr,elr,olr,ut,T0,rlr,Fpe,tlr,alr,wc,nlr,Cpe,slr,llr,Mpe,ilr,dlr,clr,Epe,flr,mlr,F0,glr,bo,C0,hlr,ype,plr,_lr,Tn,ulr,wpe,blr,vlr,Ape,Tlr,Flr,Lpe,Clr,Mlr,Elr,J,XT,Bpe,ylr,wlr,YG,Alr,Llr,Blr,VT,xpe,xlr,klr,KG,Rlr,Slr,Plr,zT,kpe,$lr,Ilr,ZG,Nlr,Dlr,jlr,WT,Rpe,qlr,Glr,eO,Olr,Xlr,Vlr,QT,Spe,zlr,Wlr,oO,Qlr,Hlr,Ulr,HT,Ppe,Jlr,Ylr,rO,Klr,Zlr,eir,UT,$pe,oir,rir,tO,tir,air,nir,JT,Ipe,sir,lir,aO,iir,dir,cir,YT,Npe,fir,mir,nO,gir,hir,pir,KT,Dpe,_ir,uir,sO,bir,vir,Tir,ZT,jpe,Fir,Cir,lO,Mir,Eir,yir,eF,qpe,wir,Air,iO,Lir,Bir,xir,oF,Gpe,kir,Rir,dO,Sir,Pir,$ir,rF,Ope,Iir,Nir,cO,Dir,jir,qir,tF,Xpe,Gir,Oir,fO,Xir,Vir,zir,aF,Vpe,Wir,Qir,mO,Hir,Uir,Jir,nF,zpe,Yir,Kir,gO,Zir,edr,odr,sF,Wpe,rdr,tdr,hO,adr,ndr,sdr,lF,Qpe,ldr,idr,pO,ddr,cdr,fdr,iF,Hpe,mdr,gdr,_O,hdr,pdr,_dr,Upe,udr,bdr,M0,MRe,Ac,dF,Jpe,E0,vdr,Ype,Tdr,ERe,Er,y0,Fdr,Lc,Cdr,Kpe,Mdr,Edr,Zpe,ydr,wdr,Adr,w0,Ldr,e_e,Bdr,xdr,kdr,bt,A0,Rdr,o_e,Sdr,Pdr,Bc,$dr,r_e,Idr,Ndr,t_e,Ddr,jdr,qdr,a_e,Gdr,Odr,L0,Xdr,vo,B0,Vdr,n_e,zdr,Wdr,Fn,Qdr,s_e,Hdr,Udr,l_e,Jdr,Ydr,i_e,Kdr,Zdr,ecr,_e,cF,d_e,ocr,rcr,uO,tcr,acr,ncr,fF,c_e,scr,lcr,bO,icr,dcr,ccr,mF,f_e,fcr,mcr,vO,gcr,hcr,pcr,gF,m_e,_cr,ucr,TO,bcr,vcr,Tcr,hF,g_e,Fcr,Ccr,FO,Mcr,Ecr,ycr,pF,h_e,wcr,Acr,CO,Lcr,Bcr,xcr,_F,p_e,kcr,Rcr,MO,Scr,Pcr,$cr,uF,__e,Icr,Ncr,EO,Dcr,jcr,qcr,bF,u_e,Gcr,Ocr,yO,Xcr,Vcr,zcr,vF,b_e,Wcr,Qcr,wO,Hcr,Ucr,Jcr,v_e,Ycr,Kcr,x0,yRe,xc,TF,T_e,k0,Zcr,F_e,efr,wRe,yr,R0,ofr,kc,rfr,C_e,tfr,afr,M_e,nfr,sfr,lfr,S0,ifr,E_e,dfr,cfr,ffr,vt,P0,mfr,y_e,gfr,hfr,Rc,pfr,w_e,_fr,ufr,A_e,bfr,vfr,Tfr,L_e,Ffr,Cfr,$0,Mfr,To,I0,Efr,B_e,yfr,wfr,Cn,Afr,x_e,Lfr,Bfr,k_e,xfr,kfr,R_e,Rfr,Sfr,Pfr,V,FF,S_e,$fr,Ifr,AO,Nfr,Dfr,jfr,CF,P_e,qfr,Gfr,LO,Ofr,Xfr,Vfr,MF,$_e,zfr,Wfr,BO,Qfr,Hfr,Ufr,EF,I_e,Jfr,Yfr,xO,Kfr,Zfr,emr,yF,N_e,omr,rmr,kO,tmr,amr,nmr,wF,D_e,smr,lmr,RO,imr,dmr,cmr,AF,j_e,fmr,mmr,SO,gmr,hmr,pmr,LF,q_e,_mr,umr,PO,bmr,vmr,Tmr,BF,G_e,Fmr,Cmr,$O,Mmr,Emr,ymr,xF,O_e,wmr,Amr,IO,Lmr,Bmr,xmr,kF,X_e,kmr,Rmr,NO,Smr,Pmr,$mr,RF,V_e,Imr,Nmr,DO,Dmr,jmr,qmr,SF,z_e,Gmr,Omr,jO,Xmr,Vmr,zmr,PF,W_e,Wmr,Qmr,qO,Hmr,Umr,Jmr,$F,Q_e,Ymr,Kmr,GO,Zmr,egr,ogr,IF,H_e,rgr,tgr,OO,agr,ngr,sgr,NF,U_e,lgr,igr,XO,dgr,cgr,fgr,DF,J_e,mgr,ggr,VO,hgr,pgr,_gr,jF,Y_e,ugr,bgr,zO,vgr,Tgr,Fgr,qF,K_e,Cgr,Mgr,WO,Egr,ygr,wgr,GF,Z_e,Agr,Lgr,QO,Bgr,xgr,kgr,OF,eue,Rgr,Sgr,HO,Pgr,$gr,Igr,XF,oue,Ngr,Dgr,UO,jgr,qgr,Ggr,VF,rue,Ogr,Xgr,JO,Vgr,zgr,Wgr,zF,tue,Qgr,Hgr,YO,Ugr,Jgr,Ygr,aue,Kgr,Zgr,N0,ARe,Sc,WF,nue,D0,ehr,sue,ohr,LRe,wr,j0,rhr,Pc,thr,lue,ahr,nhr,iue,shr,lhr,ihr,q0,dhr,due,chr,fhr,mhr,Tt,G0,ghr,cue,hhr,phr,$c,_hr,fue,uhr,bhr,mue,vhr,Thr,Fhr,gue,Chr,Mhr,O0,Ehr,Fo,X0,yhr,hue,whr,Ahr,Mn,Lhr,pue,Bhr,xhr,_ue,khr,Rhr,uue,Shr,Phr,$hr,ae,QF,bue,Ihr,Nhr,KO,Dhr,jhr,qhr,HF,vue,Ghr,Ohr,ZO,Xhr,Vhr,zhr,UF,Tue,Whr,Qhr,eX,Hhr,Uhr,Jhr,JF,Fue,Yhr,Khr,oX,Zhr,epr,opr,YF,Cue,rpr,tpr,rX,apr,npr,spr,KF,Mue,lpr,ipr,tX,dpr,cpr,fpr,ZF,Eue,mpr,gpr,aX,hpr,ppr,_pr,eC,yue,upr,bpr,nX,vpr,Tpr,Fpr,oC,wue,Cpr,Mpr,sX,Epr,ypr,wpr,rC,Aue,Apr,Lpr,lX,Bpr,xpr,kpr,tC,Lue,Rpr,Spr,iX,Ppr,$pr,Ipr,aC,Bue,Npr,Dpr,dX,jpr,qpr,Gpr,nC,xue,Opr,Xpr,cX,Vpr,zpr,Wpr,sC,kue,Qpr,Hpr,fX,Upr,Jpr,Ypr,lC,Rue,Kpr,Zpr,mX,e_r,o_r,r_r,iC,Sue,t_r,a_r,gX,n_r,s_r,l_r,dC,Pue,i_r,d_r,hX,c_r,f_r,m_r,$ue,g_r,h_r,V0,BRe,Ic,cC,Iue,z0,p_r,Nue,__r,xRe,Ar,W0,u_r,Nc,b_r,Due,v_r,T_r,jue,F_r,C_r,M_r,Q0,E_r,que,y_r,w_r,A_r,Ft,H0,L_r,Gue,B_r,x_r,Dc,k_r,Oue,R_r,S_r,Xue,P_r,$_r,I_r,Vue,N_r,D_r,U0,j_r,Co,J0,q_r,zue,G_r,O_r,En,X_r,Wue,V_r,z_r,Que,W_r,Q_r,Hue,H_r,U_r,J_r,Uue,fC,Jue,Y_r,K_r,pX,Z_r,eur,our,Yue,rur,tur,Y0,kRe,jc,mC,Kue,K0,aur,Zue,nur,RRe,Lr,Z0,sur,qc,lur,e5e,iur,dur,o5e,cur,fur,mur,eL,gur,r5e,hur,pur,_ur,Ct,oL,uur,t5e,bur,vur,Gc,Tur,a5e,Fur,Cur,n5e,Mur,Eur,yur,s5e,wur,Aur,rL,Lur,Mo,tL,Bur,l5e,xur,kur,yn,Rur,i5e,Sur,Pur,d5e,$ur,Iur,c5e,Nur,Dur,jur,Y,gC,f5e,qur,Gur,_X,Our,Xur,Vur,hC,m5e,zur,Wur,uX,Qur,Hur,Uur,pC,g5e,Jur,Yur,bX,Kur,Zur,e5r,_C,h5e,o5r,r5r,vX,t5r,a5r,n5r,uC,p5e,s5r,l5r,TX,i5r,d5r,c5r,bC,_5e,f5r,m5r,FX,g5r,h5r,p5r,vC,u5e,_5r,u5r,CX,b5r,v5r,T5r,TC,b5e,F5r,C5r,MX,M5r,E5r,y5r,FC,v5e,w5r,A5r,EX,L5r,B5r,x5r,CC,T5e,k5r,R5r,yX,S5r,P5r,$5r,MC,F5e,I5r,N5r,wX,D5r,j5r,q5r,EC,C5e,G5r,O5r,AX,X5r,V5r,z5r,yC,M5e,W5r,Q5r,LX,H5r,U5r,J5r,wC,E5e,Y5r,K5r,BX,Z5r,e2r,o2r,AC,y5e,r2r,t2r,xX,a2r,n2r,s2r,LC,w5e,l2r,i2r,kX,d2r,c2r,f2r,BC,A5e,m2r,g2r,RX,h2r,p2r,_2r,xC,L5e,u2r,b2r,SX,v2r,T2r,F2r,kC,B5e,C2r,M2r,PX,E2r,y2r,w2r,RC,x5e,A2r,L2r,$X,B2r,x2r,k2r,k5e,R2r,S2r,aL,SRe,Oc,SC,R5e,nL,P2r,S5e,$2r,PRe,Br,sL,I2r,Xc,N2r,P5e,D2r,j2r,$5e,q2r,G2r,O2r,lL,X2r,I5e,V2r,z2r,W2r,Mt,iL,Q2r,N5e,H2r,U2r,Vc,J2r,D5e,Y2r,K2r,j5e,Z2r,e1r,o1r,q5e,r1r,t1r,dL,a1r,Eo,cL,n1r,G5e,s1r,l1r,wn,i1r,O5e,d1r,c1r,X5e,f1r,m1r,V5e,g1r,h1r,p1r,Z,PC,z5e,_1r,u1r,IX,b1r,v1r,T1r,$C,W5e,F1r,C1r,NX,M1r,E1r,y1r,IC,Q5e,w1r,A1r,DX,L1r,B1r,x1r,NC,H5e,k1r,R1r,jX,S1r,P1r,$1r,DC,U5e,I1r,N1r,qX,D1r,j1r,q1r,jC,J5e,G1r,O1r,GX,X1r,V1r,z1r,qC,Y5e,W1r,Q1r,OX,H1r,U1r,J1r,GC,K5e,Y1r,K1r,XX,Z1r,ebr,obr,OC,Z5e,rbr,tbr,VX,abr,nbr,sbr,XC,e2e,lbr,ibr,zX,dbr,cbr,fbr,VC,o2e,mbr,gbr,WX,hbr,pbr,_br,zC,r2e,ubr,bbr,QX,vbr,Tbr,Fbr,WC,t2e,Cbr,Mbr,HX,Ebr,ybr,wbr,QC,a2e,Abr,Lbr,UX,Bbr,xbr,kbr,HC,n2e,Rbr,Sbr,JX,Pbr,$br,Ibr,UC,s2e,Nbr,Dbr,YX,jbr,qbr,Gbr,JC,l2e,Obr,Xbr,KX,Vbr,zbr,Wbr,YC,i2e,Qbr,Hbr,ZX,Ubr,Jbr,Ybr,KC,d2e,Kbr,Zbr,eV,evr,ovr,rvr,c2e,tvr,avr,fL,$Re,zc,ZC,f2e,mL,nvr,m2e,svr,IRe,xr,gL,lvr,Wc,ivr,g2e,dvr,cvr,h2e,fvr,mvr,gvr,hL,hvr,p2e,pvr,_vr,uvr,Et,pL,bvr,_2e,vvr,Tvr,Qc,Fvr,u2e,Cvr,Mvr,b2e,Evr,yvr,wvr,v2e,Avr,Lvr,_L,Bvr,yo,uL,xvr,T2e,kvr,Rvr,An,Svr,F2e,Pvr,$vr,C2e,Ivr,Nvr,M2e,Dvr,jvr,qvr,E2e,eM,y2e,Gvr,Ovr,oV,Xvr,Vvr,zvr,w2e,Wvr,Qvr,bL,NRe,Hc,oM,A2e,vL,Hvr,L2e,Uvr,DRe,kr,TL,Jvr,Uc,Yvr,B2e,Kvr,Zvr,x2e,e6r,o6r,r6r,FL,t6r,k2e,a6r,n6r,s6r,yt,CL,l6r,R2e,i6r,d6r,Jc,c6r,S2e,f6r,m6r,P2e,g6r,h6r,p6r,$2e,_6r,u6r,ML,b6r,wo,EL,v6r,I2e,T6r,F6r,Ln,C6r,N2e,M6r,E6r,D2e,y6r,w6r,j2e,A6r,L6r,B6r,q2e,rM,G2e,x6r,k6r,rV,R6r,S6r,P6r,O2e,$6r,I6r,yL,jRe,Yc,tM,X2e,wL,N6r,V2e,D6r,qRe,Rr,AL,j6r,Kc,q6r,z2e,G6r,O6r,W2e,X6r,V6r,z6r,LL,W6r,Q2e,Q6r,H6r,U6r,wt,BL,J6r,H2e,Y6r,K6r,Zc,Z6r,U2e,eTr,oTr,J2e,rTr,tTr,aTr,Y2e,nTr,sTr,xL,lTr,Ao,kL,iTr,K2e,dTr,cTr,Bn,fTr,Z2e,mTr,gTr,e1e,hTr,pTr,o1e,_Tr,uTr,bTr,z,aM,r1e,vTr,TTr,tV,FTr,CTr,MTr,nM,t1e,ETr,yTr,aV,wTr,ATr,LTr,sM,a1e,BTr,xTr,nV,kTr,RTr,STr,lM,n1e,PTr,$Tr,sV,ITr,NTr,DTr,iM,s1e,jTr,qTr,lV,GTr,OTr,XTr,dM,l1e,VTr,zTr,iV,WTr,QTr,HTr,cM,i1e,UTr,JTr,dV,YTr,KTr,ZTr,fM,d1e,eFr,oFr,cV,rFr,tFr,aFr,mM,c1e,nFr,sFr,fV,lFr,iFr,dFr,gM,f1e,cFr,fFr,mV,mFr,gFr,hFr,hM,m1e,pFr,_Fr,gV,uFr,bFr,vFr,pM,g1e,TFr,FFr,hV,CFr,MFr,EFr,_M,h1e,yFr,wFr,pV,AFr,LFr,BFr,uM,p1e,xFr,kFr,_V,RFr,SFr,PFr,bM,_1e,$Fr,IFr,uV,NFr,DFr,jFr,vM,u1e,qFr,GFr,bV,OFr,XFr,VFr,TM,b1e,zFr,WFr,vV,QFr,HFr,UFr,FM,v1e,JFr,YFr,TV,KFr,ZFr,eCr,CM,T1e,oCr,rCr,FV,tCr,aCr,nCr,MM,F1e,sCr,lCr,CV,iCr,dCr,cCr,EM,C1e,fCr,mCr,MV,gCr,hCr,pCr,yM,M1e,_Cr,uCr,EV,bCr,vCr,TCr,wM,E1e,FCr,CCr,yV,MCr,ECr,yCr,AM,y1e,wCr,ACr,wV,LCr,BCr,xCr,LM,w1e,kCr,RCr,AV,SCr,PCr,$Cr,A1e,ICr,NCr,RL,GRe,ef,BM,L1e,SL,DCr,B1e,jCr,ORe,Sr,PL,qCr,of,GCr,x1e,OCr,XCr,k1e,VCr,zCr,WCr,$L,QCr,R1e,HCr,UCr,JCr,At,IL,YCr,S1e,KCr,ZCr,rf,eMr,P1e,oMr,rMr,$1e,tMr,aMr,nMr,I1e,sMr,lMr,NL,iMr,Lo,DL,dMr,N1e,cMr,fMr,xn,mMr,D1e,gMr,hMr,j1e,pMr,_Mr,q1e,uMr,bMr,vMr,ca,xM,G1e,TMr,FMr,LV,CMr,MMr,EMr,kM,O1e,yMr,wMr,BV,AMr,LMr,BMr,RM,X1e,xMr,kMr,xV,RMr,SMr,PMr,SM,V1e,$Mr,IMr,kV,NMr,DMr,jMr,PM,z1e,qMr,GMr,RV,OMr,XMr,VMr,W1e,zMr,WMr,jL,XRe,tf,$M,Q1e,qL,QMr,H1e,HMr,VRe,Pr,GL,UMr,af,JMr,U1e,YMr,KMr,J1e,ZMr,e4r,o4r,OL,r4r,Y1e,t4r,a4r,n4r,Lt,XL,s4r,K1e,l4r,i4r,nf,d4r,Z1e,c4r,f4r,ebe,m4r,g4r,h4r,obe,p4r,_4r,VL,u4r,Bo,zL,b4r,rbe,v4r,T4r,kn,F4r,tbe,C4r,M4r,abe,E4r,y4r,nbe,w4r,A4r,L4r,ce,IM,sbe,B4r,x4r,SV,k4r,R4r,S4r,NM,lbe,P4r,$4r,PV,I4r,N4r,D4r,DM,ibe,j4r,q4r,$V,G4r,O4r,X4r,jM,dbe,V4r,z4r,IV,W4r,Q4r,H4r,qM,cbe,U4r,J4r,NV,Y4r,K4r,Z4r,GM,fbe,eEr,oEr,DV,rEr,tEr,aEr,OM,mbe,nEr,sEr,jV,lEr,iEr,dEr,XM,gbe,cEr,fEr,qV,mEr,gEr,hEr,VM,hbe,pEr,_Er,GV,uEr,bEr,vEr,zM,pbe,TEr,FEr,OV,CEr,MEr,EEr,WM,_be,yEr,wEr,XV,AEr,LEr,BEr,QM,ube,xEr,kEr,VV,REr,SEr,PEr,bbe,$Er,IEr,WL,zRe,sf,HM,vbe,QL,NEr,Tbe,DEr,WRe,$r,HL,jEr,lf,qEr,Fbe,GEr,OEr,Cbe,XEr,VEr,zEr,UL,WEr,Mbe,QEr,HEr,UEr,Bt,JL,JEr,Ebe,YEr,KEr,df,ZEr,ybe,e3r,o3r,wbe,r3r,t3r,a3r,Abe,n3r,s3r,YL,l3r,xo,KL,i3r,Lbe,d3r,c3r,Rn,f3r,Bbe,m3r,g3r,xbe,h3r,p3r,kbe,_3r,u3r,b3r,ue,UM,Rbe,v3r,T3r,zV,F3r,C3r,M3r,JM,Sbe,E3r,y3r,WV,w3r,A3r,L3r,YM,Pbe,B3r,x3r,QV,k3r,R3r,S3r,KM,$be,P3r,$3r,HV,I3r,N3r,D3r,ZM,Ibe,j3r,q3r,UV,G3r,O3r,X3r,e4,Nbe,V3r,z3r,JV,W3r,Q3r,H3r,o4,Dbe,U3r,J3r,YV,Y3r,K3r,Z3r,r4,jbe,eyr,oyr,KV,ryr,tyr,ayr,t4,qbe,nyr,syr,ZV,lyr,iyr,dyr,a4,Gbe,cyr,fyr,ez,myr,gyr,hyr,Obe,pyr,_yr,ZL,QRe,cf,n4,Xbe,e7,uyr,Vbe,byr,HRe,Ir,o7,vyr,ff,Tyr,zbe,Fyr,Cyr,Wbe,Myr,Eyr,yyr,r7,wyr,Qbe,Ayr,Lyr,Byr,xt,t7,xyr,Hbe,kyr,Ryr,mf,Syr,Ube,Pyr,$yr,Jbe,Iyr,Nyr,Dyr,Ybe,jyr,qyr,a7,Gyr,ko,n7,Oyr,Kbe,Xyr,Vyr,Sn,zyr,Zbe,Wyr,Qyr,eve,Hyr,Uyr,ove,Jyr,Yyr,Kyr,Me,s4,rve,Zyr,ewr,oz,owr,rwr,twr,l4,tve,awr,nwr,rz,swr,lwr,iwr,i4,ave,dwr,cwr,tz,fwr,mwr,gwr,d4,nve,hwr,pwr,az,_wr,uwr,bwr,c4,sve,vwr,Twr,nz,Fwr,Cwr,Mwr,f4,lve,Ewr,ywr,sz,wwr,Awr,Lwr,m4,ive,Bwr,xwr,lz,kwr,Rwr,Swr,g4,dve,Pwr,$wr,iz,Iwr,Nwr,Dwr,h4,cve,jwr,qwr,dz,Gwr,Owr,Xwr,fve,Vwr,zwr,s7,URe,gf,p4,mve,l7,Wwr,gve,Qwr,JRe,Nr,i7,Hwr,hf,Uwr,hve,Jwr,Ywr,pve,Kwr,Zwr,eAr,d7,oAr,_ve,rAr,tAr,aAr,kt,c7,nAr,uve,sAr,lAr,pf,iAr,bve,dAr,cAr,vve,fAr,mAr,gAr,Tve,hAr,pAr,f7,_Ar,Ro,m7,uAr,Fve,bAr,vAr,Pn,TAr,Cve,FAr,CAr,Mve,MAr,EAr,Eve,yAr,wAr,AAr,be,_4,yve,LAr,BAr,cz,xAr,kAr,RAr,u4,wve,SAr,PAr,fz,$Ar,IAr,NAr,b4,Ave,DAr,jAr,mz,qAr,GAr,OAr,v4,Lve,XAr,VAr,gz,zAr,WAr,QAr,T4,Bve,HAr,UAr,hz,JAr,YAr,KAr,F4,xve,ZAr,e0r,pz,o0r,r0r,t0r,C4,kve,a0r,n0r,_z,s0r,l0r,i0r,M4,Rve,d0r,c0r,uz,f0r,m0r,g0r,E4,Sve,h0r,p0r,bz,_0r,u0r,b0r,y4,Pve,v0r,T0r,vz,F0r,C0r,M0r,$ve,E0r,y0r,g7,YRe,_f,w4,Ive,h7,w0r,Nve,A0r,KRe,Dr,p7,L0r,uf,B0r,Dve,x0r,k0r,jve,R0r,S0r,P0r,_7,$0r,qve,I0r,N0r,D0r,Rt,u7,j0r,Gve,q0r,G0r,bf,O0r,Ove,X0r,V0r,Xve,z0r,W0r,Q0r,Vve,H0r,U0r,b7,J0r,So,v7,Y0r,zve,K0r,Z0r,$n,eLr,Wve,oLr,rLr,Qve,tLr,aLr,Hve,nLr,sLr,lLr,ve,A4,Uve,iLr,dLr,Tz,cLr,fLr,mLr,L4,Jve,gLr,hLr,Fz,pLr,_Lr,uLr,B4,Yve,bLr,vLr,Cz,TLr,FLr,CLr,x4,Kve,MLr,ELr,Mz,yLr,wLr,ALr,k4,Zve,LLr,BLr,Ez,xLr,kLr,RLr,R4,e6e,SLr,PLr,yz,$Lr,ILr,NLr,S4,o6e,DLr,jLr,wz,qLr,GLr,OLr,P4,r6e,XLr,VLr,Az,zLr,WLr,QLr,$4,t6e,HLr,ULr,Lz,JLr,YLr,KLr,I4,a6e,ZLr,e7r,Bz,o7r,r7r,t7r,n6e,a7r,n7r,T7,ZRe,vf,N4,s6e,F7,s7r,l6e,l7r,eSe,jr,C7,i7r,Tf,d7r,i6e,c7r,f7r,d6e,m7r,g7r,h7r,M7,p7r,c6e,_7r,u7r,b7r,St,E7,v7r,f6e,T7r,F7r,Ff,C7r,m6e,M7r,E7r,g6e,y7r,w7r,A7r,h6e,L7r,B7r,y7,x7r,Po,w7,k7r,p6e,R7r,S7r,In,P7r,_6e,$7r,I7r,u6e,N7r,D7r,b6e,j7r,q7r,G7r,Se,D4,v6e,O7r,X7r,xz,V7r,z7r,W7r,j4,T6e,Q7r,H7r,kz,U7r,J7r,Y7r,q4,F6e,K7r,Z7r,Rz,e8r,o8r,r8r,G4,C6e,t8r,a8r,Sz,n8r,s8r,l8r,O4,M6e,i8r,d8r,Pz,c8r,f8r,m8r,X4,E6e,g8r,h8r,$z,p8r,_8r,u8r,V4,y6e,b8r,v8r,Iz,T8r,F8r,C8r,z4,w6e,M8r,E8r,Nz,y8r,w8r,A8r,A6e,L8r,B8r,A7,oSe,Cf,W4,L6e,L7,x8r,B6e,k8r,rSe,qr,B7,R8r,Mf,S8r,x6e,P8r,$8r,k6e,I8r,N8r,D8r,x7,j8r,R6e,q8r,G8r,O8r,Pt,k7,X8r,S6e,V8r,z8r,Ef,W8r,P6e,Q8r,H8r,$6e,U8r,J8r,Y8r,I6e,K8r,Z8r,R7,e9r,$o,S7,o9r,N6e,r9r,t9r,Nn,a9r,D6e,n9r,s9r,j6e,l9r,i9r,q6e,d9r,c9r,f9r,Pe,Q4,G6e,m9r,g9r,Dz,h9r,p9r,_9r,H4,O6e,u9r,b9r,jz,v9r,T9r,F9r,U4,X6e,C9r,M9r,qz,E9r,y9r,w9r,J4,V6e,A9r,L9r,Gz,B9r,x9r,k9r,Y4,z6e,R9r,S9r,Oz,P9r,$9r,I9r,K4,W6e,N9r,D9r,Xz,j9r,q9r,G9r,Z4,Q6e,O9r,X9r,Vz,V9r,z9r,W9r,eE,H6e,Q9r,H9r,zz,U9r,J9r,Y9r,U6e,K9r,Z9r,P7,tSe,yf,oE,J6e,$7,eBr,Y6e,oBr,aSe,Gr,I7,rBr,wf,tBr,K6e,aBr,nBr,Z6e,sBr,lBr,iBr,N7,dBr,eTe,cBr,fBr,mBr,$t,D7,gBr,oTe,hBr,pBr,Af,_Br,rTe,uBr,bBr,tTe,vBr,TBr,FBr,aTe,CBr,MBr,j7,EBr,Io,q7,yBr,nTe,wBr,ABr,Dn,LBr,sTe,BBr,xBr,lTe,kBr,RBr,iTe,SBr,PBr,$Br,dTe,rE,cTe,IBr,NBr,Wz,DBr,jBr,qBr,fTe,GBr,OBr,G7,nSe,Lf,tE,mTe,O7,XBr,gTe,VBr,sSe,Or,X7,zBr,Bf,WBr,hTe,QBr,HBr,pTe,UBr,JBr,YBr,V7,KBr,_Te,ZBr,exr,oxr,It,z7,rxr,uTe,txr,axr,xf,nxr,bTe,sxr,lxr,vTe,ixr,dxr,cxr,TTe,fxr,mxr,W7,gxr,No,Q7,hxr,FTe,pxr,_xr,jn,uxr,CTe,bxr,vxr,MTe,Txr,Fxr,ETe,Cxr,Mxr,Exr,H7,aE,yTe,yxr,wxr,Qz,Axr,Lxr,Bxr,nE,wTe,xxr,kxr,Hz,Rxr,Sxr,Pxr,ATe,$xr,Ixr,U7,lSe,kf,sE,LTe,J7,Nxr,BTe,Dxr,iSe,Xr,Y7,jxr,Rf,qxr,xTe,Gxr,Oxr,kTe,Xxr,Vxr,zxr,K7,Wxr,RTe,Qxr,Hxr,Uxr,Nt,Z7,Jxr,STe,Yxr,Kxr,Sf,Zxr,PTe,ekr,okr,$Te,rkr,tkr,akr,ITe,nkr,skr,e8,lkr,Do,o8,ikr,NTe,dkr,ckr,qn,fkr,DTe,mkr,gkr,jTe,hkr,pkr,qTe,_kr,ukr,bkr,GTe,lE,OTe,vkr,Tkr,Uz,Fkr,Ckr,Mkr,XTe,Ekr,ykr,r8,dSe;return fe=new X({}),qa=new w({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),f3=new X({}),m3=new w({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Gf=new wkr({props:{warning:!0,$$slots:{default:[RMt]},$$scope:{ctx:$f}}}),g3=new X({}),h3=new M({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/configuration_auto.py#L538"}}),u3=new M({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/configuration_auto.py#L561",parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}]}}),b3=new w({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),v3=new M({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/configuration_auto.py#L683",parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}]}}),T3=new X({}),F3=new M({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/tokenization_auto.py#L351"}}),E3=new M({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/tokenization_auto.py#L365",parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_16255/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}]}}),y3=new w({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),w3=new M({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/tokenization_auto.py#L561",parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}]}}),A3=new X({}),L3=new M({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/feature_extraction_auto.py#L171"}}),k3=new M({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/feature_extraction_auto.py#L185",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_16255/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),xh=new wkr({props:{$$slots:{default:[SMt]},$$scope:{ctx:$f}}}),R3=new w({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),S3=new M({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/feature_extraction_auto.py#L312",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}]}}),P3=new X({}),$3=new M({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/processing_auto.py#L70"}}),D3=new M({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/processing_auto.py#L84",parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),Gh=new wkr({props:{$$slots:{default:[PMt]},$$scope:{ctx:$f}}}),j3=new w({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),q3=new M({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/processing_auto.py#L237",parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}]}}),G3=new X({}),O3=new M({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L705"}}),V3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),z3=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),W3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Q3=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),H3=new X({}),U3=new M({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L712"}}),Y3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),K3=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),Z3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ey=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),oy=new X({}),ry=new M({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L727"}}),ay=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),ny=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),sy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ly=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),iy=new X({}),dy=new M({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L734"}}),fy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code>(Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),my=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),gy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),hy=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),py=new X({}),_y=new M({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L741"}}),by=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}]}}),vy=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),Ty=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Fy=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Cy=new X({}),My=new M({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L750"}}),yy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),wy=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),Ay=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Ly=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),By=new X({}),xy=new M({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L784"}}),Ry=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),Sy=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),Py=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),$y=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Iy=new X({}),Ny=new M({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L791"}}),jy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}]}}),qy=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),Gy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Oy=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Xy=new X({}),Vy=new M({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L777"}}),Wy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),Qy=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),Hy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Uy=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Jy=new X({}),Yy=new M({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L759"}}),Zy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),ew=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),ow=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),rw=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),tw=new X({}),aw=new M({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L766"}}),sw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),lw=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),iw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),dw=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),cw=new X({}),fw=new M({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L800"}}),gw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),hw=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),pw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),_w=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),uw=new X({}),bw=new M({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L839"}}),Tw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),Fw=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),Cw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Mw=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Ew=new X({}),yw=new M({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L846"}}),Aw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),Lw=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),Bw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),xw=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),kw=new X({}),Rw=new M({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L869"}}),Pw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),$w=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),Iw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Nw=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Dw=new X({}),jw=new M({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L853"}}),Gw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),Ow=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),Xw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Vw=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),zw=new X({}),Ww=new M({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L860"}}),Hw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}]}}),Uw=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),Jw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Kw=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Zw=new X({}),eA=new M({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L878"}}),rA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),tA=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),aA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),nA=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),sA=new X({}),lA=new M({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L885"}}),dA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}]}}),cA=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),fA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),mA=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),gA=new X({}),hA=new M({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L832"}}),_A=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
</ul>`,name:"config"}]}}),uA=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),bA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),vA=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),TA=new X({}),FA=new M({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L807"}}),MA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}]}}),EA=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),yA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),wA=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),AA=new X({}),LA=new M({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L814"}}),xA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}]}}),kA=new w({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),RA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),PA=new w({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),$A=new X({}),IA=new M({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_auto.py#L823"}}),DA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}]}}),jA=new w({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),qA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),GA=new w({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),OA=new X({}),XA=new M({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L376"}}),zA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),WA=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),QA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),HA=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),UA=new X({}),JA=new M({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L383"}}),KA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),ZA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),e0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),o0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),r0=new X({}),t0=new M({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L398"}}),n0=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),s0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),l0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),i0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),d0=new X({}),c0=new M({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L405"}}),m0=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),g0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),h0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),_0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),u0=new X({}),b0=new M({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L419"}}),T0=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),F0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),C0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),M0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),E0=new X({}),y0=new M({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L426"}}),A0=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),L0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),B0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),x0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),k0=new X({}),R0=new M({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L435"}}),P0=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),$0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),I0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),N0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),D0=new X({}),j0=new M({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),G0=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),O0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),X0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),V0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),z0=new X({}),W0=new M({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),H0=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),U0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),J0=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Y0=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),K0=new X({}),Z0=new M({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),oL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),rL=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),tL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),aL=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),nL=new X({}),sL=new M({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),iL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),dL=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),cL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),fL=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),mL=new X({}),gL=new M({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L412"}}),pL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),_L=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),uL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),bL=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),vL=new X({}),TL=new M({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_tf_auto.py#L487"}}),CL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}]}}),ML=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),EL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),yL=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),wL=new X({}),AL=new M({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L237"}}),BL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),xL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),kL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),RL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),SL=new X({}),PL=new M({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L251"}}),IL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}]}}),NL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),DL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),jL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),qL=new X({}),GL=new M({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L244"}}),XL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),VL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),zL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),WL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),QL=new X({}),HL=new M({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L258"}}),JL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),YL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),KL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ZL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),e7=new X({}),o7=new M({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L265"}}),t7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),a7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),n7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),s7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),l7=new X({}),i7=new M({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),c7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),f7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),m7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),g7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),h7=new X({}),p7=new M({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),u7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),b7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),v7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),T7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),F7=new X({}),C7=new M({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L290"}}),E7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),y7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),w7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),A7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),L7=new X({}),B7=new M({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),k7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),R7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),S7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),P7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),$7=new X({}),I7=new M({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L306"}}),D7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}]}}),j7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),q7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),G7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),O7=new X({}),X7=new M({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),z7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),W7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),Q7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),U7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),J7=new X({}),Y7=new M({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),Z7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L389",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),e8=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),o8=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16255/src/transformers/models/auto/auto_factory.py#L417",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16255/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16255/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),r8=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){K=a("meta"),io=l(),de=a("h1"),Ee=a("a"),lo=a("span"),f(fe.$$.fragment),Ce=l(),Vo=a("span"),Ii=o("Auto Classes"),If=l(),fa=a("p"),Ni=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Di=a("code"),l3=o("from_pretrained()"),Nf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Be=l(),co=a("p"),ji=o("Instantiating one of "),Gn=a("a"),i3=o("AutoConfig"),On=o(", "),Xn=a("a"),d3=o("AutoModel"),qi=o(`, and
`),Vn=a("a"),c3=o("AutoTokenizer"),Gi=o(" will directly create a class of the relevant architecture. For instance"),Df=l(),f(qa.$$.fragment),fo=l(),pe=a("p"),e9=o("will create a model that is an instance of "),Oi=a("a"),o9=o("BertModel"),r9=o("."),zo=l(),Ga=a("p"),t9=o("There is one class of "),jf=a("code"),a9=o("AutoModel"),C$e=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ike=l(),Xi=a("h2"),qf=a("a"),OQ=a("span"),f(f3.$$.fragment),M$e=l(),XQ=a("span"),E$e=o("Extending the Auto Classes"),dke=l(),zn=a("p"),y$e=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),VQ=a("code"),w$e=o("NewModel"),A$e=o(", make sure you have a "),zQ=a("code"),L$e=o("NewModelConfig"),B$e=o(` then you can add those to the auto
classes like this:`),cke=l(),f(m3.$$.fragment),fke=l(),n9=a("p"),x$e=o("You will then be able to use the auto classes like you would usually do!"),mke=l(),f(Gf.$$.fragment),gke=l(),Vi=a("h2"),Of=a("a"),WQ=a("span"),f(g3.$$.fragment),k$e=l(),QQ=a("span"),R$e=o("AutoConfig"),hke=l(),Wo=a("div"),f(h3.$$.fragment),S$e=l(),p3=a("p"),P$e=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),s9=a("a"),$$e=o("from_pretrained()"),I$e=o(" class method."),N$e=l(),_3=a("p"),D$e=o("This class cannot be instantiated directly using "),HQ=a("code"),j$e=o("__init__()"),q$e=o(" (throws an error)."),G$e=l(),mo=a("div"),f(u3.$$.fragment),O$e=l(),UQ=a("p"),X$e=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),V$e=l(),zi=a("p"),z$e=o("The configuration class to instantiate is selected based on the "),JQ=a("code"),W$e=o("model_type"),Q$e=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),YQ=a("code"),H$e=o("pretrained_model_name_or_path"),U$e=o(":"),J$e=l(),v=a("ul"),Xf=a("li"),KQ=a("strong"),Y$e=o("albert"),K$e=o(" \u2014 "),l9=a("a"),Z$e=o("AlbertConfig"),eIe=o(" (ALBERT model)"),oIe=l(),Vf=a("li"),ZQ=a("strong"),rIe=o("bart"),tIe=o(" \u2014 "),i9=a("a"),aIe=o("BartConfig"),nIe=o(" (BART model)"),sIe=l(),zf=a("li"),eH=a("strong"),lIe=o("beit"),iIe=o(" \u2014 "),d9=a("a"),dIe=o("BeitConfig"),cIe=o(" (BEiT model)"),fIe=l(),Wf=a("li"),oH=a("strong"),mIe=o("bert"),gIe=o(" \u2014 "),c9=a("a"),hIe=o("BertConfig"),pIe=o(" (BERT model)"),_Ie=l(),Qf=a("li"),rH=a("strong"),uIe=o("bert-generation"),bIe=o(" \u2014 "),f9=a("a"),vIe=o("BertGenerationConfig"),TIe=o(" (Bert Generation model)"),FIe=l(),Hf=a("li"),tH=a("strong"),CIe=o("big_bird"),MIe=o(" \u2014 "),m9=a("a"),EIe=o("BigBirdConfig"),yIe=o(" (BigBird model)"),wIe=l(),Uf=a("li"),aH=a("strong"),AIe=o("bigbird_pegasus"),LIe=o(" \u2014 "),g9=a("a"),BIe=o("BigBirdPegasusConfig"),xIe=o(" (BigBirdPegasus model)"),kIe=l(),Jf=a("li"),nH=a("strong"),RIe=o("blenderbot"),SIe=o(" \u2014 "),h9=a("a"),PIe=o("BlenderbotConfig"),$Ie=o(" (Blenderbot model)"),IIe=l(),Yf=a("li"),sH=a("strong"),NIe=o("blenderbot-small"),DIe=o(" \u2014 "),p9=a("a"),jIe=o("BlenderbotSmallConfig"),qIe=o(" (BlenderbotSmall model)"),GIe=l(),Kf=a("li"),lH=a("strong"),OIe=o("camembert"),XIe=o(" \u2014 "),_9=a("a"),VIe=o("CamembertConfig"),zIe=o(" (CamemBERT model)"),WIe=l(),Zf=a("li"),iH=a("strong"),QIe=o("canine"),HIe=o(" \u2014 "),u9=a("a"),UIe=o("CanineConfig"),JIe=o(" (Canine model)"),YIe=l(),em=a("li"),dH=a("strong"),KIe=o("clip"),ZIe=o(" \u2014 "),b9=a("a"),eNe=o("CLIPConfig"),oNe=o(" (CLIP model)"),rNe=l(),om=a("li"),cH=a("strong"),tNe=o("convbert"),aNe=o(" \u2014 "),v9=a("a"),nNe=o("ConvBertConfig"),sNe=o(" (ConvBERT model)"),lNe=l(),rm=a("li"),fH=a("strong"),iNe=o("convnext"),dNe=o(" \u2014 "),T9=a("a"),cNe=o("ConvNextConfig"),fNe=o(" (ConvNext model)"),mNe=l(),tm=a("li"),mH=a("strong"),gNe=o("ctrl"),hNe=o(" \u2014 "),F9=a("a"),pNe=o("CTRLConfig"),_Ne=o(" (CTRL model)"),uNe=l(),am=a("li"),gH=a("strong"),bNe=o("data2vec-audio"),vNe=o(" \u2014 "),C9=a("a"),TNe=o("Data2VecAudioConfig"),FNe=o(" (Data2VecAudio model)"),CNe=l(),nm=a("li"),hH=a("strong"),MNe=o("data2vec-text"),ENe=o(" \u2014 "),M9=a("a"),yNe=o("Data2VecTextConfig"),wNe=o(" (Data2VecText model)"),ANe=l(),sm=a("li"),pH=a("strong"),LNe=o("deberta"),BNe=o(" \u2014 "),E9=a("a"),xNe=o("DebertaConfig"),kNe=o(" (DeBERTa model)"),RNe=l(),lm=a("li"),_H=a("strong"),SNe=o("deberta-v2"),PNe=o(" \u2014 "),y9=a("a"),$Ne=o("DebertaV2Config"),INe=o(" (DeBERTa-v2 model)"),NNe=l(),im=a("li"),uH=a("strong"),DNe=o("decision_transformer"),jNe=o(" \u2014 "),w9=a("a"),qNe=o("DecisionTransformerConfig"),GNe=o(" (Decision Transformer model)"),ONe=l(),dm=a("li"),bH=a("strong"),XNe=o("deit"),VNe=o(" \u2014 "),A9=a("a"),zNe=o("DeiTConfig"),WNe=o(" (DeiT model)"),QNe=l(),cm=a("li"),vH=a("strong"),HNe=o("detr"),UNe=o(" \u2014 "),L9=a("a"),JNe=o("DetrConfig"),YNe=o(" (DETR model)"),KNe=l(),fm=a("li"),TH=a("strong"),ZNe=o("distilbert"),eDe=o(" \u2014 "),B9=a("a"),oDe=o("DistilBertConfig"),rDe=o(" (DistilBERT model)"),tDe=l(),mm=a("li"),FH=a("strong"),aDe=o("dpr"),nDe=o(" \u2014 "),x9=a("a"),sDe=o("DPRConfig"),lDe=o(" (DPR model)"),iDe=l(),gm=a("li"),CH=a("strong"),dDe=o("electra"),cDe=o(" \u2014 "),k9=a("a"),fDe=o("ElectraConfig"),mDe=o(" (ELECTRA model)"),gDe=l(),hm=a("li"),MH=a("strong"),hDe=o("encoder-decoder"),pDe=o(" \u2014 "),R9=a("a"),_De=o("EncoderDecoderConfig"),uDe=o(" (Encoder decoder model)"),bDe=l(),pm=a("li"),EH=a("strong"),vDe=o("flaubert"),TDe=o(" \u2014 "),S9=a("a"),FDe=o("FlaubertConfig"),CDe=o(" (FlauBERT model)"),MDe=l(),_m=a("li"),yH=a("strong"),EDe=o("fnet"),yDe=o(" \u2014 "),P9=a("a"),wDe=o("FNetConfig"),ADe=o(" (FNet model)"),LDe=l(),um=a("li"),wH=a("strong"),BDe=o("fsmt"),xDe=o(" \u2014 "),$9=a("a"),kDe=o("FSMTConfig"),RDe=o(" (FairSeq Machine-Translation model)"),SDe=l(),bm=a("li"),AH=a("strong"),PDe=o("funnel"),$De=o(" \u2014 "),I9=a("a"),IDe=o("FunnelConfig"),NDe=o(" (Funnel Transformer model)"),DDe=l(),vm=a("li"),LH=a("strong"),jDe=o("glpn"),qDe=o(" \u2014 "),N9=a("a"),GDe=o("GLPNConfig"),ODe=o(" (GLPN model)"),XDe=l(),Tm=a("li"),BH=a("strong"),VDe=o("gpt2"),zDe=o(" \u2014 "),D9=a("a"),WDe=o("GPT2Config"),QDe=o(" (OpenAI GPT-2 model)"),HDe=l(),Fm=a("li"),xH=a("strong"),UDe=o("gpt_neo"),JDe=o(" \u2014 "),j9=a("a"),YDe=o("GPTNeoConfig"),KDe=o(" (GPT Neo model)"),ZDe=l(),Cm=a("li"),kH=a("strong"),eje=o("gptj"),oje=o(" \u2014 "),q9=a("a"),rje=o("GPTJConfig"),tje=o(" (GPT-J model)"),aje=l(),Mm=a("li"),RH=a("strong"),nje=o("hubert"),sje=o(" \u2014 "),G9=a("a"),lje=o("HubertConfig"),ije=o(" (Hubert model)"),dje=l(),Em=a("li"),SH=a("strong"),cje=o("ibert"),fje=o(" \u2014 "),O9=a("a"),mje=o("IBertConfig"),gje=o(" (I-BERT model)"),hje=l(),ym=a("li"),PH=a("strong"),pje=o("imagegpt"),_je=o(" \u2014 "),X9=a("a"),uje=o("ImageGPTConfig"),bje=o(" (ImageGPT model)"),vje=l(),wm=a("li"),$H=a("strong"),Tje=o("layoutlm"),Fje=o(" \u2014 "),V9=a("a"),Cje=o("LayoutLMConfig"),Mje=o(" (LayoutLM model)"),Eje=l(),Am=a("li"),IH=a("strong"),yje=o("layoutlmv2"),wje=o(" \u2014 "),z9=a("a"),Aje=o("LayoutLMv2Config"),Lje=o(" (LayoutLMv2 model)"),Bje=l(),Lm=a("li"),NH=a("strong"),xje=o("led"),kje=o(" \u2014 "),W9=a("a"),Rje=o("LEDConfig"),Sje=o(" (LED model)"),Pje=l(),Bm=a("li"),DH=a("strong"),$je=o("longformer"),Ije=o(" \u2014 "),Q9=a("a"),Nje=o("LongformerConfig"),Dje=o(" (Longformer model)"),jje=l(),xm=a("li"),jH=a("strong"),qje=o("luke"),Gje=o(" \u2014 "),H9=a("a"),Oje=o("LukeConfig"),Xje=o(" (LUKE model)"),Vje=l(),km=a("li"),qH=a("strong"),zje=o("lxmert"),Wje=o(" \u2014 "),U9=a("a"),Qje=o("LxmertConfig"),Hje=o(" (LXMERT model)"),Uje=l(),Rm=a("li"),GH=a("strong"),Jje=o("m2m_100"),Yje=o(" \u2014 "),J9=a("a"),Kje=o("M2M100Config"),Zje=o(" (M2M100 model)"),eqe=l(),Sm=a("li"),OH=a("strong"),oqe=o("marian"),rqe=o(" \u2014 "),Y9=a("a"),tqe=o("MarianConfig"),aqe=o(" (Marian model)"),nqe=l(),Pm=a("li"),XH=a("strong"),sqe=o("maskformer"),lqe=o(" \u2014 "),K9=a("a"),iqe=o("MaskFormerConfig"),dqe=o(" (MaskFormer model)"),cqe=l(),$m=a("li"),VH=a("strong"),fqe=o("mbart"),mqe=o(" \u2014 "),Z9=a("a"),gqe=o("MBartConfig"),hqe=o(" (mBART model)"),pqe=l(),Im=a("li"),zH=a("strong"),_qe=o("megatron-bert"),uqe=o(" \u2014 "),eB=a("a"),bqe=o("MegatronBertConfig"),vqe=o(" (MegatronBert model)"),Tqe=l(),Nm=a("li"),WH=a("strong"),Fqe=o("mobilebert"),Cqe=o(" \u2014 "),oB=a("a"),Mqe=o("MobileBertConfig"),Eqe=o(" (MobileBERT model)"),yqe=l(),Dm=a("li"),QH=a("strong"),wqe=o("mpnet"),Aqe=o(" \u2014 "),rB=a("a"),Lqe=o("MPNetConfig"),Bqe=o(" (MPNet model)"),xqe=l(),jm=a("li"),HH=a("strong"),kqe=o("mt5"),Rqe=o(" \u2014 "),tB=a("a"),Sqe=o("MT5Config"),Pqe=o(" (mT5 model)"),$qe=l(),qm=a("li"),UH=a("strong"),Iqe=o("nystromformer"),Nqe=o(" \u2014 "),aB=a("a"),Dqe=o("NystromformerConfig"),jqe=o(" (Nystromformer model)"),qqe=l(),Gm=a("li"),JH=a("strong"),Gqe=o("openai-gpt"),Oqe=o(" \u2014 "),nB=a("a"),Xqe=o("OpenAIGPTConfig"),Vqe=o(" (OpenAI GPT model)"),zqe=l(),Om=a("li"),YH=a("strong"),Wqe=o("pegasus"),Qqe=o(" \u2014 "),sB=a("a"),Hqe=o("PegasusConfig"),Uqe=o(" (Pegasus model)"),Jqe=l(),Xm=a("li"),KH=a("strong"),Yqe=o("perceiver"),Kqe=o(" \u2014 "),lB=a("a"),Zqe=o("PerceiverConfig"),eGe=o(" (Perceiver model)"),oGe=l(),Vm=a("li"),ZH=a("strong"),rGe=o("plbart"),tGe=o(" \u2014 "),iB=a("a"),aGe=o("PLBartConfig"),nGe=o(" (PLBart model)"),sGe=l(),zm=a("li"),eU=a("strong"),lGe=o("poolformer"),iGe=o(" \u2014 "),dB=a("a"),dGe=o("PoolFormerConfig"),cGe=o(" (PoolFormer model)"),fGe=l(),Wm=a("li"),oU=a("strong"),mGe=o("prophetnet"),gGe=o(" \u2014 "),cB=a("a"),hGe=o("ProphetNetConfig"),pGe=o(" (ProphetNet model)"),_Ge=l(),Qm=a("li"),rU=a("strong"),uGe=o("qdqbert"),bGe=o(" \u2014 "),fB=a("a"),vGe=o("QDQBertConfig"),TGe=o(" (QDQBert model)"),FGe=l(),Hm=a("li"),tU=a("strong"),CGe=o("rag"),MGe=o(" \u2014 "),mB=a("a"),EGe=o("RagConfig"),yGe=o(" (RAG model)"),wGe=l(),Um=a("li"),aU=a("strong"),AGe=o("realm"),LGe=o(" \u2014 "),gB=a("a"),BGe=o("RealmConfig"),xGe=o(" (Realm model)"),kGe=l(),Jm=a("li"),nU=a("strong"),RGe=o("reformer"),SGe=o(" \u2014 "),hB=a("a"),PGe=o("ReformerConfig"),$Ge=o(" (Reformer model)"),IGe=l(),Ym=a("li"),sU=a("strong"),NGe=o("rembert"),DGe=o(" \u2014 "),pB=a("a"),jGe=o("RemBertConfig"),qGe=o(" (RemBERT model)"),GGe=l(),Km=a("li"),lU=a("strong"),OGe=o("resnet"),XGe=o(" \u2014 "),_B=a("a"),VGe=o("ResNetConfig"),zGe=o(" (ResNet model)"),WGe=l(),Zm=a("li"),iU=a("strong"),QGe=o("retribert"),HGe=o(" \u2014 "),uB=a("a"),UGe=o("RetriBertConfig"),JGe=o(" (RetriBERT model)"),YGe=l(),eg=a("li"),dU=a("strong"),KGe=o("roberta"),ZGe=o(" \u2014 "),bB=a("a"),eOe=o("RobertaConfig"),oOe=o(" (RoBERTa model)"),rOe=l(),og=a("li"),cU=a("strong"),tOe=o("roformer"),aOe=o(" \u2014 "),vB=a("a"),nOe=o("RoFormerConfig"),sOe=o(" (RoFormer model)"),lOe=l(),rg=a("li"),fU=a("strong"),iOe=o("segformer"),dOe=o(" \u2014 "),TB=a("a"),cOe=o("SegformerConfig"),fOe=o(" (SegFormer model)"),mOe=l(),tg=a("li"),mU=a("strong"),gOe=o("sew"),hOe=o(" \u2014 "),FB=a("a"),pOe=o("SEWConfig"),_Oe=o(" (SEW model)"),uOe=l(),ag=a("li"),gU=a("strong"),bOe=o("sew-d"),vOe=o(" \u2014 "),CB=a("a"),TOe=o("SEWDConfig"),FOe=o(" (SEW-D model)"),COe=l(),ng=a("li"),hU=a("strong"),MOe=o("speech-encoder-decoder"),EOe=o(" \u2014 "),MB=a("a"),yOe=o("SpeechEncoderDecoderConfig"),wOe=o(" (Speech Encoder decoder model)"),AOe=l(),sg=a("li"),pU=a("strong"),LOe=o("speech_to_text"),BOe=o(" \u2014 "),EB=a("a"),xOe=o("Speech2TextConfig"),kOe=o(" (Speech2Text model)"),ROe=l(),lg=a("li"),_U=a("strong"),SOe=o("speech_to_text_2"),POe=o(" \u2014 "),yB=a("a"),$Oe=o("Speech2Text2Config"),IOe=o(" (Speech2Text2 model)"),NOe=l(),ig=a("li"),uU=a("strong"),DOe=o("splinter"),jOe=o(" \u2014 "),wB=a("a"),qOe=o("SplinterConfig"),GOe=o(" (Splinter model)"),OOe=l(),dg=a("li"),bU=a("strong"),XOe=o("squeezebert"),VOe=o(" \u2014 "),AB=a("a"),zOe=o("SqueezeBertConfig"),WOe=o(" (SqueezeBERT model)"),QOe=l(),cg=a("li"),vU=a("strong"),HOe=o("swin"),UOe=o(" \u2014 "),LB=a("a"),JOe=o("SwinConfig"),YOe=o(" (Swin model)"),KOe=l(),fg=a("li"),TU=a("strong"),ZOe=o("t5"),eXe=o(" \u2014 "),BB=a("a"),oXe=o("T5Config"),rXe=o(" (T5 model)"),tXe=l(),mg=a("li"),FU=a("strong"),aXe=o("tapas"),nXe=o(" \u2014 "),xB=a("a"),sXe=o("TapasConfig"),lXe=o(" (TAPAS model)"),iXe=l(),gg=a("li"),CU=a("strong"),dXe=o("transfo-xl"),cXe=o(" \u2014 "),kB=a("a"),fXe=o("TransfoXLConfig"),mXe=o(" (Transformer-XL model)"),gXe=l(),hg=a("li"),MU=a("strong"),hXe=o("trocr"),pXe=o(" \u2014 "),RB=a("a"),_Xe=o("TrOCRConfig"),uXe=o(" (TrOCR model)"),bXe=l(),pg=a("li"),EU=a("strong"),vXe=o("unispeech"),TXe=o(" \u2014 "),SB=a("a"),FXe=o("UniSpeechConfig"),CXe=o(" (UniSpeech model)"),MXe=l(),_g=a("li"),yU=a("strong"),EXe=o("unispeech-sat"),yXe=o(" \u2014 "),PB=a("a"),wXe=o("UniSpeechSatConfig"),AXe=o(" (UniSpeechSat model)"),LXe=l(),ug=a("li"),wU=a("strong"),BXe=o("van"),xXe=o(" \u2014 "),$B=a("a"),kXe=o("VanConfig"),RXe=o(" (VAN model)"),SXe=l(),bg=a("li"),AU=a("strong"),PXe=o("vilt"),$Xe=o(" \u2014 "),IB=a("a"),IXe=o("ViltConfig"),NXe=o(" (ViLT model)"),DXe=l(),vg=a("li"),LU=a("strong"),jXe=o("vision-encoder-decoder"),qXe=o(" \u2014 "),NB=a("a"),GXe=o("VisionEncoderDecoderConfig"),OXe=o(" (Vision Encoder decoder model)"),XXe=l(),Tg=a("li"),BU=a("strong"),VXe=o("vision-text-dual-encoder"),zXe=o(" \u2014 "),DB=a("a"),WXe=o("VisionTextDualEncoderConfig"),QXe=o(" (VisionTextDualEncoder model)"),HXe=l(),Fg=a("li"),xU=a("strong"),UXe=o("visual_bert"),JXe=o(" \u2014 "),jB=a("a"),YXe=o("VisualBertConfig"),KXe=o(" (VisualBert model)"),ZXe=l(),Cg=a("li"),kU=a("strong"),eVe=o("vit"),oVe=o(" \u2014 "),qB=a("a"),rVe=o("ViTConfig"),tVe=o(" (ViT model)"),aVe=l(),Mg=a("li"),RU=a("strong"),nVe=o("vit_mae"),sVe=o(" \u2014 "),GB=a("a"),lVe=o("ViTMAEConfig"),iVe=o(" (ViTMAE model)"),dVe=l(),Eg=a("li"),SU=a("strong"),cVe=o("wav2vec2"),fVe=o(" \u2014 "),OB=a("a"),mVe=o("Wav2Vec2Config"),gVe=o(" (Wav2Vec2 model)"),hVe=l(),yg=a("li"),PU=a("strong"),pVe=o("wavlm"),_Ve=o(" \u2014 "),XB=a("a"),uVe=o("WavLMConfig"),bVe=o(" (WavLM model)"),vVe=l(),wg=a("li"),$U=a("strong"),TVe=o("xglm"),FVe=o(" \u2014 "),VB=a("a"),CVe=o("XGLMConfig"),MVe=o(" (XGLM model)"),EVe=l(),Ag=a("li"),IU=a("strong"),yVe=o("xlm"),wVe=o(" \u2014 "),zB=a("a"),AVe=o("XLMConfig"),LVe=o(" (XLM model)"),BVe=l(),Lg=a("li"),NU=a("strong"),xVe=o("xlm-prophetnet"),kVe=o(" \u2014 "),WB=a("a"),RVe=o("XLMProphetNetConfig"),SVe=o(" (XLMProphetNet model)"),PVe=l(),Bg=a("li"),DU=a("strong"),$Ve=o("xlm-roberta"),IVe=o(" \u2014 "),QB=a("a"),NVe=o("XLMRobertaConfig"),DVe=o(" (XLM-RoBERTa model)"),jVe=l(),xg=a("li"),jU=a("strong"),qVe=o("xlm-roberta-xl"),GVe=o(" \u2014 "),HB=a("a"),OVe=o("XLMRobertaXLConfig"),XVe=o(" (XLM-RoBERTa-XL model)"),VVe=l(),kg=a("li"),qU=a("strong"),zVe=o("xlnet"),WVe=o(" \u2014 "),UB=a("a"),QVe=o("XLNetConfig"),HVe=o(" (XLNet model)"),UVe=l(),Rg=a("li"),GU=a("strong"),JVe=o("yoso"),YVe=o(" \u2014 "),JB=a("a"),KVe=o("YosoConfig"),ZVe=o(" (YOSO model)"),eze=l(),OU=a("p"),oze=o("Examples:"),rze=l(),f(b3.$$.fragment),tze=l(),Sg=a("div"),f(v3.$$.fragment),aze=l(),XU=a("p"),nze=o("Register a new configuration for this class."),pke=l(),Wi=a("h2"),Pg=a("a"),VU=a("span"),f(T3.$$.fragment),sze=l(),zU=a("span"),lze=o("AutoTokenizer"),_ke=l(),Qo=a("div"),f(F3.$$.fragment),ize=l(),C3=a("p"),dze=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),YB=a("a"),cze=o("AutoTokenizer.from_pretrained()"),fze=o(" class method."),mze=l(),M3=a("p"),gze=o("This class cannot be instantiated directly using "),WU=a("code"),hze=o("__init__()"),pze=o(" (throws an error)."),_ze=l(),go=a("div"),f(E3.$$.fragment),uze=l(),QU=a("p"),bze=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),vze=l(),Oa=a("p"),Tze=o("The tokenizer class to instantiate is selected based on the "),HU=a("code"),Fze=o("model_type"),Cze=o(` property of the config object (either
passed as an argument or loaded from `),UU=a("code"),Mze=o("pretrained_model_name_or_path"),Eze=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JU=a("code"),yze=o("pretrained_model_name_or_path"),wze=o(":"),Aze=l(),E=a("ul"),Wn=a("li"),YU=a("strong"),Lze=o("albert"),Bze=o(" \u2014 "),KB=a("a"),xze=o("AlbertTokenizer"),kze=o(" or "),ZB=a("a"),Rze=o("AlbertTokenizerFast"),Sze=o(" (ALBERT model)"),Pze=l(),Qn=a("li"),KU=a("strong"),$ze=o("bart"),Ize=o(" \u2014 "),ex=a("a"),Nze=o("BartTokenizer"),Dze=o(" or "),ox=a("a"),jze=o("BartTokenizerFast"),qze=o(" (BART model)"),Gze=l(),Hn=a("li"),ZU=a("strong"),Oze=o("barthez"),Xze=o(" \u2014 "),rx=a("a"),Vze=o("BarthezTokenizer"),zze=o(" or "),tx=a("a"),Wze=o("BarthezTokenizerFast"),Qze=o(" (BARThez model)"),Hze=l(),$g=a("li"),eJ=a("strong"),Uze=o("bartpho"),Jze=o(" \u2014 "),ax=a("a"),Yze=o("BartphoTokenizer"),Kze=o(" (BARTpho model)"),Zze=l(),Un=a("li"),oJ=a("strong"),eWe=o("bert"),oWe=o(" \u2014 "),nx=a("a"),rWe=o("BertTokenizer"),tWe=o(" or "),sx=a("a"),aWe=o("BertTokenizerFast"),nWe=o(" (BERT model)"),sWe=l(),Ig=a("li"),rJ=a("strong"),lWe=o("bert-generation"),iWe=o(" \u2014 "),lx=a("a"),dWe=o("BertGenerationTokenizer"),cWe=o(" (Bert Generation model)"),fWe=l(),Ng=a("li"),tJ=a("strong"),mWe=o("bert-japanese"),gWe=o(" \u2014 "),ix=a("a"),hWe=o("BertJapaneseTokenizer"),pWe=o(" (BertJapanese model)"),_We=l(),Dg=a("li"),aJ=a("strong"),uWe=o("bertweet"),bWe=o(" \u2014 "),dx=a("a"),vWe=o("BertweetTokenizer"),TWe=o(" (Bertweet model)"),FWe=l(),Jn=a("li"),nJ=a("strong"),CWe=o("big_bird"),MWe=o(" \u2014 "),cx=a("a"),EWe=o("BigBirdTokenizer"),yWe=o(" or "),fx=a("a"),wWe=o("BigBirdTokenizerFast"),AWe=o(" (BigBird model)"),LWe=l(),Yn=a("li"),sJ=a("strong"),BWe=o("bigbird_pegasus"),xWe=o(" \u2014 "),mx=a("a"),kWe=o("PegasusTokenizer"),RWe=o(" or "),gx=a("a"),SWe=o("PegasusTokenizerFast"),PWe=o(" (BigBirdPegasus model)"),$We=l(),Kn=a("li"),lJ=a("strong"),IWe=o("blenderbot"),NWe=o(" \u2014 "),hx=a("a"),DWe=o("BlenderbotTokenizer"),jWe=o(" or "),px=a("a"),qWe=o("BlenderbotTokenizerFast"),GWe=o(" (Blenderbot model)"),OWe=l(),jg=a("li"),iJ=a("strong"),XWe=o("blenderbot-small"),VWe=o(" \u2014 "),_x=a("a"),zWe=o("BlenderbotSmallTokenizer"),WWe=o(" (BlenderbotSmall model)"),QWe=l(),qg=a("li"),dJ=a("strong"),HWe=o("byt5"),UWe=o(" \u2014 "),ux=a("a"),JWe=o("ByT5Tokenizer"),YWe=o(" (ByT5 model)"),KWe=l(),Zn=a("li"),cJ=a("strong"),ZWe=o("camembert"),eQe=o(" \u2014 "),bx=a("a"),oQe=o("CamembertTokenizer"),rQe=o(" or "),vx=a("a"),tQe=o("CamembertTokenizerFast"),aQe=o(" (CamemBERT model)"),nQe=l(),Gg=a("li"),fJ=a("strong"),sQe=o("canine"),lQe=o(" \u2014 "),Tx=a("a"),iQe=o("CanineTokenizer"),dQe=o(" (Canine model)"),cQe=l(),es=a("li"),mJ=a("strong"),fQe=o("clip"),mQe=o(" \u2014 "),Fx=a("a"),gQe=o("CLIPTokenizer"),hQe=o(" or "),Cx=a("a"),pQe=o("CLIPTokenizerFast"),_Qe=o(" (CLIP model)"),uQe=l(),os=a("li"),gJ=a("strong"),bQe=o("convbert"),vQe=o(" \u2014 "),Mx=a("a"),TQe=o("ConvBertTokenizer"),FQe=o(" or "),Ex=a("a"),CQe=o("ConvBertTokenizerFast"),MQe=o(" (ConvBERT model)"),EQe=l(),rs=a("li"),hJ=a("strong"),yQe=o("cpm"),wQe=o(" \u2014 "),yx=a("a"),AQe=o("CpmTokenizer"),LQe=o(" or "),pJ=a("code"),BQe=o("CpmTokenizerFast"),xQe=o(" (CPM model)"),kQe=l(),Og=a("li"),_J=a("strong"),RQe=o("ctrl"),SQe=o(" \u2014 "),wx=a("a"),PQe=o("CTRLTokenizer"),$Qe=o(" (CTRL model)"),IQe=l(),ts=a("li"),uJ=a("strong"),NQe=o("deberta"),DQe=o(" \u2014 "),Ax=a("a"),jQe=o("DebertaTokenizer"),qQe=o(" or "),Lx=a("a"),GQe=o("DebertaTokenizerFast"),OQe=o(" (DeBERTa model)"),XQe=l(),Xg=a("li"),bJ=a("strong"),VQe=o("deberta-v2"),zQe=o(" \u2014 "),Bx=a("a"),WQe=o("DebertaV2Tokenizer"),QQe=o(" (DeBERTa-v2 model)"),HQe=l(),as=a("li"),vJ=a("strong"),UQe=o("distilbert"),JQe=o(" \u2014 "),xx=a("a"),YQe=o("DistilBertTokenizer"),KQe=o(" or "),kx=a("a"),ZQe=o("DistilBertTokenizerFast"),eHe=o(" (DistilBERT model)"),oHe=l(),ns=a("li"),TJ=a("strong"),rHe=o("dpr"),tHe=o(" \u2014 "),Rx=a("a"),aHe=o("DPRQuestionEncoderTokenizer"),nHe=o(" or "),Sx=a("a"),sHe=o("DPRQuestionEncoderTokenizerFast"),lHe=o(" (DPR model)"),iHe=l(),ss=a("li"),FJ=a("strong"),dHe=o("electra"),cHe=o(" \u2014 "),Px=a("a"),fHe=o("ElectraTokenizer"),mHe=o(" or "),$x=a("a"),gHe=o("ElectraTokenizerFast"),hHe=o(" (ELECTRA model)"),pHe=l(),Vg=a("li"),CJ=a("strong"),_He=o("flaubert"),uHe=o(" \u2014 "),Ix=a("a"),bHe=o("FlaubertTokenizer"),vHe=o(" (FlauBERT model)"),THe=l(),ls=a("li"),MJ=a("strong"),FHe=o("fnet"),CHe=o(" \u2014 "),Nx=a("a"),MHe=o("FNetTokenizer"),EHe=o(" or "),Dx=a("a"),yHe=o("FNetTokenizerFast"),wHe=o(" (FNet model)"),AHe=l(),zg=a("li"),EJ=a("strong"),LHe=o("fsmt"),BHe=o(" \u2014 "),jx=a("a"),xHe=o("FSMTTokenizer"),kHe=o(" (FairSeq Machine-Translation model)"),RHe=l(),is=a("li"),yJ=a("strong"),SHe=o("funnel"),PHe=o(" \u2014 "),qx=a("a"),$He=o("FunnelTokenizer"),IHe=o(" or "),Gx=a("a"),NHe=o("FunnelTokenizerFast"),DHe=o(" (Funnel Transformer model)"),jHe=l(),ds=a("li"),wJ=a("strong"),qHe=o("gpt2"),GHe=o(" \u2014 "),Ox=a("a"),OHe=o("GPT2Tokenizer"),XHe=o(" or "),Xx=a("a"),VHe=o("GPT2TokenizerFast"),zHe=o(" (OpenAI GPT-2 model)"),WHe=l(),cs=a("li"),AJ=a("strong"),QHe=o("gpt_neo"),HHe=o(" \u2014 "),Vx=a("a"),UHe=o("GPT2Tokenizer"),JHe=o(" or "),zx=a("a"),YHe=o("GPT2TokenizerFast"),KHe=o(" (GPT Neo model)"),ZHe=l(),fs=a("li"),LJ=a("strong"),eUe=o("herbert"),oUe=o(" \u2014 "),Wx=a("a"),rUe=o("HerbertTokenizer"),tUe=o(" or "),Qx=a("a"),aUe=o("HerbertTokenizerFast"),nUe=o(" (HerBERT model)"),sUe=l(),Wg=a("li"),BJ=a("strong"),lUe=o("hubert"),iUe=o(" \u2014 "),Hx=a("a"),dUe=o("Wav2Vec2CTCTokenizer"),cUe=o(" (Hubert model)"),fUe=l(),ms=a("li"),xJ=a("strong"),mUe=o("ibert"),gUe=o(" \u2014 "),Ux=a("a"),hUe=o("RobertaTokenizer"),pUe=o(" or "),Jx=a("a"),_Ue=o("RobertaTokenizerFast"),uUe=o(" (I-BERT model)"),bUe=l(),gs=a("li"),kJ=a("strong"),vUe=o("layoutlm"),TUe=o(" \u2014 "),Yx=a("a"),FUe=o("LayoutLMTokenizer"),CUe=o(" or "),Kx=a("a"),MUe=o("LayoutLMTokenizerFast"),EUe=o(" (LayoutLM model)"),yUe=l(),hs=a("li"),RJ=a("strong"),wUe=o("layoutlmv2"),AUe=o(" \u2014 "),Zx=a("a"),LUe=o("LayoutLMv2Tokenizer"),BUe=o(" or "),ek=a("a"),xUe=o("LayoutLMv2TokenizerFast"),kUe=o(" (LayoutLMv2 model)"),RUe=l(),ps=a("li"),SJ=a("strong"),SUe=o("layoutxlm"),PUe=o(" \u2014 "),ok=a("a"),$Ue=o("LayoutXLMTokenizer"),IUe=o(" or "),rk=a("a"),NUe=o("LayoutXLMTokenizerFast"),DUe=o(" (LayoutXLM model)"),jUe=l(),_s=a("li"),PJ=a("strong"),qUe=o("led"),GUe=o(" \u2014 "),tk=a("a"),OUe=o("LEDTokenizer"),XUe=o(" or "),ak=a("a"),VUe=o("LEDTokenizerFast"),zUe=o(" (LED model)"),WUe=l(),us=a("li"),$J=a("strong"),QUe=o("longformer"),HUe=o(" \u2014 "),nk=a("a"),UUe=o("LongformerTokenizer"),JUe=o(" or "),sk=a("a"),YUe=o("LongformerTokenizerFast"),KUe=o(" (Longformer model)"),ZUe=l(),Qg=a("li"),IJ=a("strong"),eJe=o("luke"),oJe=o(" \u2014 "),lk=a("a"),rJe=o("LukeTokenizer"),tJe=o(" (LUKE model)"),aJe=l(),bs=a("li"),NJ=a("strong"),nJe=o("lxmert"),sJe=o(" \u2014 "),ik=a("a"),lJe=o("LxmertTokenizer"),iJe=o(" or "),dk=a("a"),dJe=o("LxmertTokenizerFast"),cJe=o(" (LXMERT model)"),fJe=l(),Hg=a("li"),DJ=a("strong"),mJe=o("m2m_100"),gJe=o(" \u2014 "),ck=a("a"),hJe=o("M2M100Tokenizer"),pJe=o(" (M2M100 model)"),_Je=l(),Ug=a("li"),jJ=a("strong"),uJe=o("marian"),bJe=o(" \u2014 "),fk=a("a"),vJe=o("MarianTokenizer"),TJe=o(" (Marian model)"),FJe=l(),vs=a("li"),qJ=a("strong"),CJe=o("mbart"),MJe=o(" \u2014 "),mk=a("a"),EJe=o("MBartTokenizer"),yJe=o(" or "),gk=a("a"),wJe=o("MBartTokenizerFast"),AJe=o(" (mBART model)"),LJe=l(),Ts=a("li"),GJ=a("strong"),BJe=o("mbart50"),xJe=o(" \u2014 "),hk=a("a"),kJe=o("MBart50Tokenizer"),RJe=o(" or "),pk=a("a"),SJe=o("MBart50TokenizerFast"),PJe=o(" (mBART-50 model)"),$Je=l(),Jg=a("li"),OJ=a("strong"),IJe=o("mluke"),NJe=o(" \u2014 "),_k=a("a"),DJe=o("MLukeTokenizer"),jJe=o(" (mLUKE model)"),qJe=l(),Fs=a("li"),XJ=a("strong"),GJe=o("mobilebert"),OJe=o(" \u2014 "),uk=a("a"),XJe=o("MobileBertTokenizer"),VJe=o(" or "),bk=a("a"),zJe=o("MobileBertTokenizerFast"),WJe=o(" (MobileBERT model)"),QJe=l(),Cs=a("li"),VJ=a("strong"),HJe=o("mpnet"),UJe=o(" \u2014 "),vk=a("a"),JJe=o("MPNetTokenizer"),YJe=o(" or "),Tk=a("a"),KJe=o("MPNetTokenizerFast"),ZJe=o(" (MPNet model)"),eYe=l(),Ms=a("li"),zJ=a("strong"),oYe=o("mt5"),rYe=o(" \u2014 "),Fk=a("a"),tYe=o("MT5Tokenizer"),aYe=o(" or "),Ck=a("a"),nYe=o("MT5TokenizerFast"),sYe=o(" (mT5 model)"),lYe=l(),Es=a("li"),WJ=a("strong"),iYe=o("openai-gpt"),dYe=o(" \u2014 "),Mk=a("a"),cYe=o("OpenAIGPTTokenizer"),fYe=o(" or "),Ek=a("a"),mYe=o("OpenAIGPTTokenizerFast"),gYe=o(" (OpenAI GPT model)"),hYe=l(),ys=a("li"),QJ=a("strong"),pYe=o("pegasus"),_Ye=o(" \u2014 "),yk=a("a"),uYe=o("PegasusTokenizer"),bYe=o(" or "),wk=a("a"),vYe=o("PegasusTokenizerFast"),TYe=o(" (Pegasus model)"),FYe=l(),Yg=a("li"),HJ=a("strong"),CYe=o("perceiver"),MYe=o(" \u2014 "),Ak=a("a"),EYe=o("PerceiverTokenizer"),yYe=o(" (Perceiver model)"),wYe=l(),Kg=a("li"),UJ=a("strong"),AYe=o("phobert"),LYe=o(" \u2014 "),Lk=a("a"),BYe=o("PhobertTokenizer"),xYe=o(" (PhoBERT model)"),kYe=l(),Zg=a("li"),JJ=a("strong"),RYe=o("plbart"),SYe=o(" \u2014 "),Bk=a("a"),PYe=o("PLBartTokenizer"),$Ye=o(" (PLBart model)"),IYe=l(),eh=a("li"),YJ=a("strong"),NYe=o("prophetnet"),DYe=o(" \u2014 "),xk=a("a"),jYe=o("ProphetNetTokenizer"),qYe=o(" (ProphetNet model)"),GYe=l(),ws=a("li"),KJ=a("strong"),OYe=o("qdqbert"),XYe=o(" \u2014 "),kk=a("a"),VYe=o("BertTokenizer"),zYe=o(" or "),Rk=a("a"),WYe=o("BertTokenizerFast"),QYe=o(" (QDQBert model)"),HYe=l(),oh=a("li"),ZJ=a("strong"),UYe=o("rag"),JYe=o(" \u2014 "),Sk=a("a"),YYe=o("RagTokenizer"),KYe=o(" (RAG model)"),ZYe=l(),As=a("li"),eY=a("strong"),eKe=o("realm"),oKe=o(" \u2014 "),Pk=a("a"),rKe=o("RealmTokenizer"),tKe=o(" or "),$k=a("a"),aKe=o("RealmTokenizerFast"),nKe=o(" (Realm model)"),sKe=l(),Ls=a("li"),oY=a("strong"),lKe=o("reformer"),iKe=o(" \u2014 "),Ik=a("a"),dKe=o("ReformerTokenizer"),cKe=o(" or "),Nk=a("a"),fKe=o("ReformerTokenizerFast"),mKe=o(" (Reformer model)"),gKe=l(),Bs=a("li"),rY=a("strong"),hKe=o("rembert"),pKe=o(" \u2014 "),Dk=a("a"),_Ke=o("RemBertTokenizer"),uKe=o(" or "),jk=a("a"),bKe=o("RemBertTokenizerFast"),vKe=o(" (RemBERT model)"),TKe=l(),xs=a("li"),tY=a("strong"),FKe=o("retribert"),CKe=o(" \u2014 "),qk=a("a"),MKe=o("RetriBertTokenizer"),EKe=o(" or "),Gk=a("a"),yKe=o("RetriBertTokenizerFast"),wKe=o(" (RetriBERT model)"),AKe=l(),ks=a("li"),aY=a("strong"),LKe=o("roberta"),BKe=o(" \u2014 "),Ok=a("a"),xKe=o("RobertaTokenizer"),kKe=o(" or "),Xk=a("a"),RKe=o("RobertaTokenizerFast"),SKe=o(" (RoBERTa model)"),PKe=l(),Rs=a("li"),nY=a("strong"),$Ke=o("roformer"),IKe=o(" \u2014 "),Vk=a("a"),NKe=o("RoFormerTokenizer"),DKe=o(" or "),zk=a("a"),jKe=o("RoFormerTokenizerFast"),qKe=o(" (RoFormer model)"),GKe=l(),rh=a("li"),sY=a("strong"),OKe=o("speech_to_text"),XKe=o(" \u2014 "),Wk=a("a"),VKe=o("Speech2TextTokenizer"),zKe=o(" (Speech2Text model)"),WKe=l(),th=a("li"),lY=a("strong"),QKe=o("speech_to_text_2"),HKe=o(" \u2014 "),Qk=a("a"),UKe=o("Speech2Text2Tokenizer"),JKe=o(" (Speech2Text2 model)"),YKe=l(),Ss=a("li"),iY=a("strong"),KKe=o("splinter"),ZKe=o(" \u2014 "),Hk=a("a"),eZe=o("SplinterTokenizer"),oZe=o(" or "),Uk=a("a"),rZe=o("SplinterTokenizerFast"),tZe=o(" (Splinter model)"),aZe=l(),Ps=a("li"),dY=a("strong"),nZe=o("squeezebert"),sZe=o(" \u2014 "),Jk=a("a"),lZe=o("SqueezeBertTokenizer"),iZe=o(" or "),Yk=a("a"),dZe=o("SqueezeBertTokenizerFast"),cZe=o(" (SqueezeBERT model)"),fZe=l(),$s=a("li"),cY=a("strong"),mZe=o("t5"),gZe=o(" \u2014 "),Kk=a("a"),hZe=o("T5Tokenizer"),pZe=o(" or "),Zk=a("a"),_Ze=o("T5TokenizerFast"),uZe=o(" (T5 model)"),bZe=l(),ah=a("li"),fY=a("strong"),vZe=o("tapas"),TZe=o(" \u2014 "),eR=a("a"),FZe=o("TapasTokenizer"),CZe=o(" (TAPAS model)"),MZe=l(),nh=a("li"),mY=a("strong"),EZe=o("transfo-xl"),yZe=o(" \u2014 "),oR=a("a"),wZe=o("TransfoXLTokenizer"),AZe=o(" (Transformer-XL model)"),LZe=l(),sh=a("li"),gY=a("strong"),BZe=o("wav2vec2"),xZe=o(" \u2014 "),rR=a("a"),kZe=o("Wav2Vec2CTCTokenizer"),RZe=o(" (Wav2Vec2 model)"),SZe=l(),lh=a("li"),hY=a("strong"),PZe=o("wav2vec2_phoneme"),$Ze=o(" \u2014 "),tR=a("a"),IZe=o("Wav2Vec2PhonemeCTCTokenizer"),NZe=o(" (Wav2Vec2Phoneme model)"),DZe=l(),Is=a("li"),pY=a("strong"),jZe=o("xglm"),qZe=o(" \u2014 "),aR=a("a"),GZe=o("XGLMTokenizer"),OZe=o(" or "),nR=a("a"),XZe=o("XGLMTokenizerFast"),VZe=o(" (XGLM model)"),zZe=l(),ih=a("li"),_Y=a("strong"),WZe=o("xlm"),QZe=o(" \u2014 "),sR=a("a"),HZe=o("XLMTokenizer"),UZe=o(" (XLM model)"),JZe=l(),dh=a("li"),uY=a("strong"),YZe=o("xlm-prophetnet"),KZe=o(" \u2014 "),lR=a("a"),ZZe=o("XLMProphetNetTokenizer"),eeo=o(" (XLMProphetNet model)"),oeo=l(),Ns=a("li"),bY=a("strong"),reo=o("xlm-roberta"),teo=o(" \u2014 "),iR=a("a"),aeo=o("XLMRobertaTokenizer"),neo=o(" or "),dR=a("a"),seo=o("XLMRobertaTokenizerFast"),leo=o(" (XLM-RoBERTa model)"),ieo=l(),Ds=a("li"),vY=a("strong"),deo=o("xlnet"),ceo=o(" \u2014 "),cR=a("a"),feo=o("XLNetTokenizer"),meo=o(" or "),fR=a("a"),geo=o("XLNetTokenizerFast"),heo=o(" (XLNet model)"),peo=l(),TY=a("p"),_eo=o("Examples:"),ueo=l(),f(y3.$$.fragment),beo=l(),ch=a("div"),f(w3.$$.fragment),veo=l(),FY=a("p"),Teo=o("Register a new tokenizer in this mapping."),uke=l(),Qi=a("h2"),fh=a("a"),CY=a("span"),f(A3.$$.fragment),Feo=l(),MY=a("span"),Ceo=o("AutoFeatureExtractor"),bke=l(),Ho=a("div"),f(L3.$$.fragment),Meo=l(),B3=a("p"),Eeo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),mR=a("a"),yeo=o("AutoFeatureExtractor.from_pretrained()"),weo=o(" class method."),Aeo=l(),x3=a("p"),Leo=o("This class cannot be instantiated directly using "),EY=a("code"),Beo=o("__init__()"),xeo=o(" (throws an error)."),keo=l(),$e=a("div"),f(k3.$$.fragment),Reo=l(),yY=a("p"),Seo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Peo=l(),Xa=a("p"),$eo=o("The feature extractor class to instantiate is selected based on the "),wY=a("code"),Ieo=o("model_type"),Neo=o(` property of the config object
(either passed as an argument or loaded from `),AY=a("code"),Deo=o("pretrained_model_name_or_path"),jeo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),LY=a("code"),qeo=o("pretrained_model_name_or_path"),Geo=o(":"),Oeo=l(),re=a("ul"),mh=a("li"),BY=a("strong"),Xeo=o("beit"),Veo=o(" \u2014 "),gR=a("a"),zeo=o("BeitFeatureExtractor"),Weo=o(" (BEiT model)"),Qeo=l(),gh=a("li"),xY=a("strong"),Heo=o("clip"),Ueo=o(" \u2014 "),hR=a("a"),Jeo=o("CLIPFeatureExtractor"),Yeo=o(" (CLIP model)"),Keo=l(),hh=a("li"),kY=a("strong"),Zeo=o("convnext"),eoo=o(" \u2014 "),pR=a("a"),ooo=o("ConvNextFeatureExtractor"),roo=o(" (ConvNext model)"),too=l(),ph=a("li"),RY=a("strong"),aoo=o("deit"),noo=o(" \u2014 "),_R=a("a"),soo=o("DeiTFeatureExtractor"),loo=o(" (DeiT model)"),ioo=l(),_h=a("li"),SY=a("strong"),doo=o("detr"),coo=o(" \u2014 "),uR=a("a"),foo=o("DetrFeatureExtractor"),moo=o(" (DETR model)"),goo=l(),uh=a("li"),PY=a("strong"),hoo=o("hubert"),poo=o(" \u2014 "),bR=a("a"),_oo=o("Wav2Vec2FeatureExtractor"),uoo=o(" (Hubert model)"),boo=l(),bh=a("li"),$Y=a("strong"),voo=o("layoutlmv2"),Too=o(" \u2014 "),vR=a("a"),Foo=o("LayoutLMv2FeatureExtractor"),Coo=o(" (LayoutLMv2 model)"),Moo=l(),vh=a("li"),IY=a("strong"),Eoo=o("maskformer"),yoo=o(" \u2014 "),TR=a("a"),woo=o("MaskFormerFeatureExtractor"),Aoo=o(" (MaskFormer model)"),Loo=l(),Th=a("li"),NY=a("strong"),Boo=o("perceiver"),xoo=o(" \u2014 "),FR=a("a"),koo=o("PerceiverFeatureExtractor"),Roo=o(" (Perceiver model)"),Soo=l(),Fh=a("li"),DY=a("strong"),Poo=o("poolformer"),$oo=o(" \u2014 "),CR=a("a"),Ioo=o("PoolFormerFeatureExtractor"),Noo=o(" (PoolFormer model)"),Doo=l(),Ch=a("li"),jY=a("strong"),joo=o("resnet"),qoo=o(" \u2014 "),MR=a("a"),Goo=o("ConvNextFeatureExtractor"),Ooo=o(" (ResNet model)"),Xoo=l(),Mh=a("li"),qY=a("strong"),Voo=o("segformer"),zoo=o(" \u2014 "),ER=a("a"),Woo=o("SegformerFeatureExtractor"),Qoo=o(" (SegFormer model)"),Hoo=l(),Eh=a("li"),GY=a("strong"),Uoo=o("speech_to_text"),Joo=o(" \u2014 "),yR=a("a"),Yoo=o("Speech2TextFeatureExtractor"),Koo=o(" (Speech2Text model)"),Zoo=l(),yh=a("li"),OY=a("strong"),ero=o("swin"),oro=o(" \u2014 "),wR=a("a"),rro=o("ViTFeatureExtractor"),tro=o(" (Swin model)"),aro=l(),wh=a("li"),XY=a("strong"),nro=o("van"),sro=o(" \u2014 "),AR=a("a"),lro=o("ConvNextFeatureExtractor"),iro=o(" (VAN model)"),dro=l(),Ah=a("li"),VY=a("strong"),cro=o("vit"),fro=o(" \u2014 "),LR=a("a"),mro=o("ViTFeatureExtractor"),gro=o(" (ViT model)"),hro=l(),Lh=a("li"),zY=a("strong"),pro=o("vit_mae"),_ro=o(" \u2014 "),BR=a("a"),uro=o("ViTFeatureExtractor"),bro=o(" (ViTMAE model)"),vro=l(),Bh=a("li"),WY=a("strong"),Tro=o("wav2vec2"),Fro=o(" \u2014 "),xR=a("a"),Cro=o("Wav2Vec2FeatureExtractor"),Mro=o(" (Wav2Vec2 model)"),Ero=l(),f(xh.$$.fragment),yro=l(),QY=a("p"),wro=o("Examples:"),Aro=l(),f(R3.$$.fragment),Lro=l(),kh=a("div"),f(S3.$$.fragment),Bro=l(),HY=a("p"),xro=o("Register a new feature extractor for this class."),vke=l(),Hi=a("h2"),Rh=a("a"),UY=a("span"),f(P3.$$.fragment),kro=l(),JY=a("span"),Rro=o("AutoProcessor"),Tke=l(),Uo=a("div"),f($3.$$.fragment),Sro=l(),I3=a("p"),Pro=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),kR=a("a"),$ro=o("AutoProcessor.from_pretrained()"),Iro=o(" class method."),Nro=l(),N3=a("p"),Dro=o("This class cannot be instantiated directly using "),YY=a("code"),jro=o("__init__()"),qro=o(" (throws an error)."),Gro=l(),Ie=a("div"),f(D3.$$.fragment),Oro=l(),KY=a("p"),Xro=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Vro=l(),Ui=a("p"),zro=o("The processor class to instantiate is selected based on the "),ZY=a("code"),Wro=o("model_type"),Qro=o(` property of the config object (either
passed as an argument or loaded from `),eK=a("code"),Hro=o("pretrained_model_name_or_path"),Uro=o(" if possible):"),Jro=l(),xe=a("ul"),Sh=a("li"),oK=a("strong"),Yro=o("clip"),Kro=o(" \u2014 "),RR=a("a"),Zro=o("CLIPProcessor"),eto=o(" (CLIP model)"),oto=l(),Ph=a("li"),rK=a("strong"),rto=o("layoutlmv2"),tto=o(" \u2014 "),SR=a("a"),ato=o("LayoutLMv2Processor"),nto=o(" (LayoutLMv2 model)"),sto=l(),$h=a("li"),tK=a("strong"),lto=o("layoutxlm"),ito=o(" \u2014 "),PR=a("a"),dto=o("LayoutXLMProcessor"),cto=o(" (LayoutXLM model)"),fto=l(),Ih=a("li"),aK=a("strong"),mto=o("speech_to_text"),gto=o(" \u2014 "),$R=a("a"),hto=o("Speech2TextProcessor"),pto=o(" (Speech2Text model)"),_to=l(),Nh=a("li"),nK=a("strong"),uto=o("speech_to_text_2"),bto=o(" \u2014 "),IR=a("a"),vto=o("Speech2Text2Processor"),Tto=o(" (Speech2Text2 model)"),Fto=l(),Dh=a("li"),sK=a("strong"),Cto=o("trocr"),Mto=o(" \u2014 "),NR=a("a"),Eto=o("TrOCRProcessor"),yto=o(" (TrOCR model)"),wto=l(),jh=a("li"),lK=a("strong"),Ato=o("vision-text-dual-encoder"),Lto=o(" \u2014 "),DR=a("a"),Bto=o("VisionTextDualEncoderProcessor"),xto=o(" (VisionTextDualEncoder model)"),kto=l(),qh=a("li"),iK=a("strong"),Rto=o("wav2vec2"),Sto=o(" \u2014 "),jR=a("a"),Pto=o("Wav2Vec2Processor"),$to=o(" (Wav2Vec2 model)"),Ito=l(),f(Gh.$$.fragment),Nto=l(),dK=a("p"),Dto=o("Examples:"),jto=l(),f(j3.$$.fragment),qto=l(),Oh=a("div"),f(q3.$$.fragment),Gto=l(),cK=a("p"),Oto=o("Register a new processor for this class."),Fke=l(),Ji=a("h2"),Xh=a("a"),fK=a("span"),f(G3.$$.fragment),Xto=l(),mK=a("span"),Vto=o("AutoModel"),Cke=l(),Jo=a("div"),f(O3.$$.fragment),zto=l(),Yi=a("p"),Wto=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gK=a("code"),Qto=o("from_pretrained()"),Hto=o("class method or the "),hK=a("code"),Uto=o("from_config()"),Jto=o(`class
method.`),Yto=l(),X3=a("p"),Kto=o("This class cannot be instantiated directly using "),pK=a("code"),Zto=o("__init__()"),eao=o(" (throws an error)."),oao=l(),Vr=a("div"),f(V3.$$.fragment),rao=l(),_K=a("p"),tao=o("Instantiates one of the base model classes of the library from a configuration."),aao=l(),Ki=a("p"),nao=o(`Note:
Loading a model from its configuration file does `),uK=a("strong"),sao=o("not"),lao=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=a("code"),iao=o("from_pretrained()"),dao=o("to load the model weights."),cao=l(),vK=a("p"),fao=o("Examples:"),mao=l(),f(z3.$$.fragment),gao=l(),Ne=a("div"),f(W3.$$.fragment),hao=l(),TK=a("p"),pao=o("Instantiate one of the base model classes of the library from a pretrained model."),_ao=l(),Va=a("p"),uao=o("The model class to instantiate is selected based on the "),FK=a("code"),bao=o("model_type"),vao=o(` property of the config object (either
passed as an argument or loaded from `),CK=a("code"),Tao=o("pretrained_model_name_or_path"),Fao=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MK=a("code"),Cao=o("pretrained_model_name_or_path"),Mao=o(":"),Eao=l(),F=a("ul"),Vh=a("li"),EK=a("strong"),yao=o("albert"),wao=o(" \u2014 "),qR=a("a"),Aao=o("AlbertModel"),Lao=o(" (ALBERT model)"),Bao=l(),zh=a("li"),yK=a("strong"),xao=o("bart"),kao=o(" \u2014 "),GR=a("a"),Rao=o("BartModel"),Sao=o(" (BART model)"),Pao=l(),Wh=a("li"),wK=a("strong"),$ao=o("beit"),Iao=o(" \u2014 "),OR=a("a"),Nao=o("BeitModel"),Dao=o(" (BEiT model)"),jao=l(),Qh=a("li"),AK=a("strong"),qao=o("bert"),Gao=o(" \u2014 "),XR=a("a"),Oao=o("BertModel"),Xao=o(" (BERT model)"),Vao=l(),Hh=a("li"),LK=a("strong"),zao=o("bert-generation"),Wao=o(" \u2014 "),VR=a("a"),Qao=o("BertGenerationEncoder"),Hao=o(" (Bert Generation model)"),Uao=l(),Uh=a("li"),BK=a("strong"),Jao=o("big_bird"),Yao=o(" \u2014 "),zR=a("a"),Kao=o("BigBirdModel"),Zao=o(" (BigBird model)"),eno=l(),Jh=a("li"),xK=a("strong"),ono=o("bigbird_pegasus"),rno=o(" \u2014 "),WR=a("a"),tno=o("BigBirdPegasusModel"),ano=o(" (BigBirdPegasus model)"),nno=l(),Yh=a("li"),kK=a("strong"),sno=o("blenderbot"),lno=o(" \u2014 "),QR=a("a"),ino=o("BlenderbotModel"),dno=o(" (Blenderbot model)"),cno=l(),Kh=a("li"),RK=a("strong"),fno=o("blenderbot-small"),mno=o(" \u2014 "),HR=a("a"),gno=o("BlenderbotSmallModel"),hno=o(" (BlenderbotSmall model)"),pno=l(),Zh=a("li"),SK=a("strong"),_no=o("camembert"),uno=o(" \u2014 "),UR=a("a"),bno=o("CamembertModel"),vno=o(" (CamemBERT model)"),Tno=l(),ep=a("li"),PK=a("strong"),Fno=o("canine"),Cno=o(" \u2014 "),JR=a("a"),Mno=o("CanineModel"),Eno=o(" (Canine model)"),yno=l(),op=a("li"),$K=a("strong"),wno=o("clip"),Ano=o(" \u2014 "),YR=a("a"),Lno=o("CLIPModel"),Bno=o(" (CLIP model)"),xno=l(),rp=a("li"),IK=a("strong"),kno=o("convbert"),Rno=o(" \u2014 "),KR=a("a"),Sno=o("ConvBertModel"),Pno=o(" (ConvBERT model)"),$no=l(),tp=a("li"),NK=a("strong"),Ino=o("convnext"),Nno=o(" \u2014 "),ZR=a("a"),Dno=o("ConvNextModel"),jno=o(" (ConvNext model)"),qno=l(),ap=a("li"),DK=a("strong"),Gno=o("ctrl"),Ono=o(" \u2014 "),eS=a("a"),Xno=o("CTRLModel"),Vno=o(" (CTRL model)"),zno=l(),np=a("li"),jK=a("strong"),Wno=o("data2vec-audio"),Qno=o(" \u2014 "),oS=a("a"),Hno=o("Data2VecAudioModel"),Uno=o(" (Data2VecAudio model)"),Jno=l(),sp=a("li"),qK=a("strong"),Yno=o("data2vec-text"),Kno=o(" \u2014 "),rS=a("a"),Zno=o("Data2VecTextModel"),eso=o(" (Data2VecText model)"),oso=l(),lp=a("li"),GK=a("strong"),rso=o("deberta"),tso=o(" \u2014 "),tS=a("a"),aso=o("DebertaModel"),nso=o(" (DeBERTa model)"),sso=l(),ip=a("li"),OK=a("strong"),lso=o("deberta-v2"),iso=o(" \u2014 "),aS=a("a"),dso=o("DebertaV2Model"),cso=o(" (DeBERTa-v2 model)"),fso=l(),dp=a("li"),XK=a("strong"),mso=o("decision_transformer"),gso=o(" \u2014 "),nS=a("a"),hso=o("DecisionTransformerModel"),pso=o(" (Decision Transformer model)"),_so=l(),cp=a("li"),VK=a("strong"),uso=o("deit"),bso=o(" \u2014 "),sS=a("a"),vso=o("DeiTModel"),Tso=o(" (DeiT model)"),Fso=l(),fp=a("li"),zK=a("strong"),Cso=o("detr"),Mso=o(" \u2014 "),lS=a("a"),Eso=o("DetrModel"),yso=o(" (DETR model)"),wso=l(),mp=a("li"),WK=a("strong"),Aso=o("distilbert"),Lso=o(" \u2014 "),iS=a("a"),Bso=o("DistilBertModel"),xso=o(" (DistilBERT model)"),kso=l(),gp=a("li"),QK=a("strong"),Rso=o("dpr"),Sso=o(" \u2014 "),dS=a("a"),Pso=o("DPRQuestionEncoder"),$so=o(" (DPR model)"),Iso=l(),hp=a("li"),HK=a("strong"),Nso=o("electra"),Dso=o(" \u2014 "),cS=a("a"),jso=o("ElectraModel"),qso=o(" (ELECTRA model)"),Gso=l(),pp=a("li"),UK=a("strong"),Oso=o("flaubert"),Xso=o(" \u2014 "),fS=a("a"),Vso=o("FlaubertModel"),zso=o(" (FlauBERT model)"),Wso=l(),_p=a("li"),JK=a("strong"),Qso=o("fnet"),Hso=o(" \u2014 "),mS=a("a"),Uso=o("FNetModel"),Jso=o(" (FNet model)"),Yso=l(),up=a("li"),YK=a("strong"),Kso=o("fsmt"),Zso=o(" \u2014 "),gS=a("a"),elo=o("FSMTModel"),olo=o(" (FairSeq Machine-Translation model)"),rlo=l(),js=a("li"),KK=a("strong"),tlo=o("funnel"),alo=o(" \u2014 "),hS=a("a"),nlo=o("FunnelModel"),slo=o(" or "),pS=a("a"),llo=o("FunnelBaseModel"),ilo=o(" (Funnel Transformer model)"),dlo=l(),bp=a("li"),ZK=a("strong"),clo=o("glpn"),flo=o(" \u2014 "),_S=a("a"),mlo=o("GLPNModel"),glo=o(" (GLPN model)"),hlo=l(),vp=a("li"),eZ=a("strong"),plo=o("gpt2"),_lo=o(" \u2014 "),uS=a("a"),ulo=o("GPT2Model"),blo=o(" (OpenAI GPT-2 model)"),vlo=l(),Tp=a("li"),oZ=a("strong"),Tlo=o("gpt_neo"),Flo=o(" \u2014 "),bS=a("a"),Clo=o("GPTNeoModel"),Mlo=o(" (GPT Neo model)"),Elo=l(),Fp=a("li"),rZ=a("strong"),ylo=o("gptj"),wlo=o(" \u2014 "),vS=a("a"),Alo=o("GPTJModel"),Llo=o(" (GPT-J model)"),Blo=l(),Cp=a("li"),tZ=a("strong"),xlo=o("hubert"),klo=o(" \u2014 "),TS=a("a"),Rlo=o("HubertModel"),Slo=o(" (Hubert model)"),Plo=l(),Mp=a("li"),aZ=a("strong"),$lo=o("ibert"),Ilo=o(" \u2014 "),FS=a("a"),Nlo=o("IBertModel"),Dlo=o(" (I-BERT model)"),jlo=l(),Ep=a("li"),nZ=a("strong"),qlo=o("imagegpt"),Glo=o(" \u2014 "),CS=a("a"),Olo=o("ImageGPTModel"),Xlo=o(" (ImageGPT model)"),Vlo=l(),yp=a("li"),sZ=a("strong"),zlo=o("layoutlm"),Wlo=o(" \u2014 "),MS=a("a"),Qlo=o("LayoutLMModel"),Hlo=o(" (LayoutLM model)"),Ulo=l(),wp=a("li"),lZ=a("strong"),Jlo=o("layoutlmv2"),Ylo=o(" \u2014 "),ES=a("a"),Klo=o("LayoutLMv2Model"),Zlo=o(" (LayoutLMv2 model)"),eio=l(),Ap=a("li"),iZ=a("strong"),oio=o("led"),rio=o(" \u2014 "),yS=a("a"),tio=o("LEDModel"),aio=o(" (LED model)"),nio=l(),Lp=a("li"),dZ=a("strong"),sio=o("longformer"),lio=o(" \u2014 "),wS=a("a"),iio=o("LongformerModel"),dio=o(" (Longformer model)"),cio=l(),Bp=a("li"),cZ=a("strong"),fio=o("luke"),mio=o(" \u2014 "),AS=a("a"),gio=o("LukeModel"),hio=o(" (LUKE model)"),pio=l(),xp=a("li"),fZ=a("strong"),_io=o("lxmert"),uio=o(" \u2014 "),LS=a("a"),bio=o("LxmertModel"),vio=o(" (LXMERT model)"),Tio=l(),kp=a("li"),mZ=a("strong"),Fio=o("m2m_100"),Cio=o(" \u2014 "),BS=a("a"),Mio=o("M2M100Model"),Eio=o(" (M2M100 model)"),yio=l(),Rp=a("li"),gZ=a("strong"),wio=o("marian"),Aio=o(" \u2014 "),xS=a("a"),Lio=o("MarianModel"),Bio=o(" (Marian model)"),xio=l(),Sp=a("li"),hZ=a("strong"),kio=o("maskformer"),Rio=o(" \u2014 "),kS=a("a"),Sio=o("MaskFormerModel"),Pio=o(" (MaskFormer model)"),$io=l(),Pp=a("li"),pZ=a("strong"),Iio=o("mbart"),Nio=o(" \u2014 "),RS=a("a"),Dio=o("MBartModel"),jio=o(" (mBART model)"),qio=l(),$p=a("li"),_Z=a("strong"),Gio=o("megatron-bert"),Oio=o(" \u2014 "),SS=a("a"),Xio=o("MegatronBertModel"),Vio=o(" (MegatronBert model)"),zio=l(),Ip=a("li"),uZ=a("strong"),Wio=o("mobilebert"),Qio=o(" \u2014 "),PS=a("a"),Hio=o("MobileBertModel"),Uio=o(" (MobileBERT model)"),Jio=l(),Np=a("li"),bZ=a("strong"),Yio=o("mpnet"),Kio=o(" \u2014 "),$S=a("a"),Zio=o("MPNetModel"),edo=o(" (MPNet model)"),odo=l(),Dp=a("li"),vZ=a("strong"),rdo=o("mt5"),tdo=o(" \u2014 "),IS=a("a"),ado=o("MT5Model"),ndo=o(" (mT5 model)"),sdo=l(),jp=a("li"),TZ=a("strong"),ldo=o("nystromformer"),ido=o(" \u2014 "),NS=a("a"),ddo=o("NystromformerModel"),cdo=o(" (Nystromformer model)"),fdo=l(),qp=a("li"),FZ=a("strong"),mdo=o("openai-gpt"),gdo=o(" \u2014 "),DS=a("a"),hdo=o("OpenAIGPTModel"),pdo=o(" (OpenAI GPT model)"),_do=l(),Gp=a("li"),CZ=a("strong"),udo=o("pegasus"),bdo=o(" \u2014 "),jS=a("a"),vdo=o("PegasusModel"),Tdo=o(" (Pegasus model)"),Fdo=l(),Op=a("li"),MZ=a("strong"),Cdo=o("perceiver"),Mdo=o(" \u2014 "),qS=a("a"),Edo=o("PerceiverModel"),ydo=o(" (Perceiver model)"),wdo=l(),Xp=a("li"),EZ=a("strong"),Ado=o("plbart"),Ldo=o(" \u2014 "),GS=a("a"),Bdo=o("PLBartModel"),xdo=o(" (PLBart model)"),kdo=l(),Vp=a("li"),yZ=a("strong"),Rdo=o("poolformer"),Sdo=o(" \u2014 "),OS=a("a"),Pdo=o("PoolFormerModel"),$do=o(" (PoolFormer model)"),Ido=l(),zp=a("li"),wZ=a("strong"),Ndo=o("prophetnet"),Ddo=o(" \u2014 "),XS=a("a"),jdo=o("ProphetNetModel"),qdo=o(" (ProphetNet model)"),Gdo=l(),Wp=a("li"),AZ=a("strong"),Odo=o("qdqbert"),Xdo=o(" \u2014 "),VS=a("a"),Vdo=o("QDQBertModel"),zdo=o(" (QDQBert model)"),Wdo=l(),Qp=a("li"),LZ=a("strong"),Qdo=o("reformer"),Hdo=o(" \u2014 "),zS=a("a"),Udo=o("ReformerModel"),Jdo=o(" (Reformer model)"),Ydo=l(),Hp=a("li"),BZ=a("strong"),Kdo=o("rembert"),Zdo=o(" \u2014 "),WS=a("a"),eco=o("RemBertModel"),oco=o(" (RemBERT model)"),rco=l(),Up=a("li"),xZ=a("strong"),tco=o("resnet"),aco=o(" \u2014 "),QS=a("a"),nco=o("ResNetModel"),sco=o(" (ResNet model)"),lco=l(),Jp=a("li"),kZ=a("strong"),ico=o("retribert"),dco=o(" \u2014 "),HS=a("a"),cco=o("RetriBertModel"),fco=o(" (RetriBERT model)"),mco=l(),Yp=a("li"),RZ=a("strong"),gco=o("roberta"),hco=o(" \u2014 "),US=a("a"),pco=o("RobertaModel"),_co=o(" (RoBERTa model)"),uco=l(),Kp=a("li"),SZ=a("strong"),bco=o("roformer"),vco=o(" \u2014 "),JS=a("a"),Tco=o("RoFormerModel"),Fco=o(" (RoFormer model)"),Cco=l(),Zp=a("li"),PZ=a("strong"),Mco=o("segformer"),Eco=o(" \u2014 "),YS=a("a"),yco=o("SegformerModel"),wco=o(" (SegFormer model)"),Aco=l(),e_=a("li"),$Z=a("strong"),Lco=o("sew"),Bco=o(" \u2014 "),KS=a("a"),xco=o("SEWModel"),kco=o(" (SEW model)"),Rco=l(),o_=a("li"),IZ=a("strong"),Sco=o("sew-d"),Pco=o(" \u2014 "),ZS=a("a"),$co=o("SEWDModel"),Ico=o(" (SEW-D model)"),Nco=l(),r_=a("li"),NZ=a("strong"),Dco=o("speech_to_text"),jco=o(" \u2014 "),eP=a("a"),qco=o("Speech2TextModel"),Gco=o(" (Speech2Text model)"),Oco=l(),t_=a("li"),DZ=a("strong"),Xco=o("splinter"),Vco=o(" \u2014 "),oP=a("a"),zco=o("SplinterModel"),Wco=o(" (Splinter model)"),Qco=l(),a_=a("li"),jZ=a("strong"),Hco=o("squeezebert"),Uco=o(" \u2014 "),rP=a("a"),Jco=o("SqueezeBertModel"),Yco=o(" (SqueezeBERT model)"),Kco=l(),n_=a("li"),qZ=a("strong"),Zco=o("swin"),efo=o(" \u2014 "),tP=a("a"),ofo=o("SwinModel"),rfo=o(" (Swin model)"),tfo=l(),s_=a("li"),GZ=a("strong"),afo=o("t5"),nfo=o(" \u2014 "),aP=a("a"),sfo=o("T5Model"),lfo=o(" (T5 model)"),ifo=l(),l_=a("li"),OZ=a("strong"),dfo=o("tapas"),cfo=o(" \u2014 "),nP=a("a"),ffo=o("TapasModel"),mfo=o(" (TAPAS model)"),gfo=l(),i_=a("li"),XZ=a("strong"),hfo=o("transfo-xl"),pfo=o(" \u2014 "),sP=a("a"),_fo=o("TransfoXLModel"),ufo=o(" (Transformer-XL model)"),bfo=l(),d_=a("li"),VZ=a("strong"),vfo=o("unispeech"),Tfo=o(" \u2014 "),lP=a("a"),Ffo=o("UniSpeechModel"),Cfo=o(" (UniSpeech model)"),Mfo=l(),c_=a("li"),zZ=a("strong"),Efo=o("unispeech-sat"),yfo=o(" \u2014 "),iP=a("a"),wfo=o("UniSpeechSatModel"),Afo=o(" (UniSpeechSat model)"),Lfo=l(),f_=a("li"),WZ=a("strong"),Bfo=o("van"),xfo=o(" \u2014 "),dP=a("a"),kfo=o("VanModel"),Rfo=o(" (VAN model)"),Sfo=l(),m_=a("li"),QZ=a("strong"),Pfo=o("vilt"),$fo=o(" \u2014 "),cP=a("a"),Ifo=o("ViltModel"),Nfo=o(" (ViLT model)"),Dfo=l(),g_=a("li"),HZ=a("strong"),jfo=o("vision-text-dual-encoder"),qfo=o(" \u2014 "),fP=a("a"),Gfo=o("VisionTextDualEncoderModel"),Ofo=o(" (VisionTextDualEncoder model)"),Xfo=l(),h_=a("li"),UZ=a("strong"),Vfo=o("visual_bert"),zfo=o(" \u2014 "),mP=a("a"),Wfo=o("VisualBertModel"),Qfo=o(" (VisualBert model)"),Hfo=l(),p_=a("li"),JZ=a("strong"),Ufo=o("vit"),Jfo=o(" \u2014 "),gP=a("a"),Yfo=o("ViTModel"),Kfo=o(" (ViT model)"),Zfo=l(),__=a("li"),YZ=a("strong"),emo=o("vit_mae"),omo=o(" \u2014 "),hP=a("a"),rmo=o("ViTMAEModel"),tmo=o(" (ViTMAE model)"),amo=l(),u_=a("li"),KZ=a("strong"),nmo=o("wav2vec2"),smo=o(" \u2014 "),pP=a("a"),lmo=o("Wav2Vec2Model"),imo=o(" (Wav2Vec2 model)"),dmo=l(),b_=a("li"),ZZ=a("strong"),cmo=o("wavlm"),fmo=o(" \u2014 "),_P=a("a"),mmo=o("WavLMModel"),gmo=o(" (WavLM model)"),hmo=l(),v_=a("li"),eee=a("strong"),pmo=o("xglm"),_mo=o(" \u2014 "),uP=a("a"),umo=o("XGLMModel"),bmo=o(" (XGLM model)"),vmo=l(),T_=a("li"),oee=a("strong"),Tmo=o("xlm"),Fmo=o(" \u2014 "),bP=a("a"),Cmo=o("XLMModel"),Mmo=o(" (XLM model)"),Emo=l(),F_=a("li"),ree=a("strong"),ymo=o("xlm-prophetnet"),wmo=o(" \u2014 "),vP=a("a"),Amo=o("XLMProphetNetModel"),Lmo=o(" (XLMProphetNet model)"),Bmo=l(),C_=a("li"),tee=a("strong"),xmo=o("xlm-roberta"),kmo=o(" \u2014 "),TP=a("a"),Rmo=o("XLMRobertaModel"),Smo=o(" (XLM-RoBERTa model)"),Pmo=l(),M_=a("li"),aee=a("strong"),$mo=o("xlm-roberta-xl"),Imo=o(" \u2014 "),FP=a("a"),Nmo=o("XLMRobertaXLModel"),Dmo=o(" (XLM-RoBERTa-XL model)"),jmo=l(),E_=a("li"),nee=a("strong"),qmo=o("xlnet"),Gmo=o(" \u2014 "),CP=a("a"),Omo=o("XLNetModel"),Xmo=o(" (XLNet model)"),Vmo=l(),y_=a("li"),see=a("strong"),zmo=o("yoso"),Wmo=o(" \u2014 "),MP=a("a"),Qmo=o("YosoModel"),Hmo=o(" (YOSO model)"),Umo=l(),w_=a("p"),Jmo=o("The model is set in evaluation mode by default using "),lee=a("code"),Ymo=o("model.eval()"),Kmo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iee=a("code"),Zmo=o("model.train()"),ego=l(),dee=a("p"),ogo=o("Examples:"),rgo=l(),f(Q3.$$.fragment),Mke=l(),Zi=a("h2"),A_=a("a"),cee=a("span"),f(H3.$$.fragment),tgo=l(),fee=a("span"),ago=o("AutoModelForPreTraining"),Eke=l(),Yo=a("div"),f(U3.$$.fragment),ngo=l(),ed=a("p"),sgo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mee=a("code"),lgo=o("from_pretrained()"),igo=o("class method or the "),gee=a("code"),dgo=o("from_config()"),cgo=o(`class
method.`),fgo=l(),J3=a("p"),mgo=o("This class cannot be instantiated directly using "),hee=a("code"),ggo=o("__init__()"),hgo=o(" (throws an error)."),pgo=l(),zr=a("div"),f(Y3.$$.fragment),_go=l(),pee=a("p"),ugo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),bgo=l(),od=a("p"),vgo=o(`Note:
Loading a model from its configuration file does `),_ee=a("strong"),Tgo=o("not"),Fgo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=a("code"),Cgo=o("from_pretrained()"),Mgo=o("to load the model weights."),Ego=l(),bee=a("p"),ygo=o("Examples:"),wgo=l(),f(K3.$$.fragment),Ago=l(),De=a("div"),f(Z3.$$.fragment),Lgo=l(),vee=a("p"),Bgo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),xgo=l(),za=a("p"),kgo=o("The model class to instantiate is selected based on the "),Tee=a("code"),Rgo=o("model_type"),Sgo=o(` property of the config object (either
passed as an argument or loaded from `),Fee=a("code"),Pgo=o("pretrained_model_name_or_path"),$go=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cee=a("code"),Igo=o("pretrained_model_name_or_path"),Ngo=o(":"),Dgo=l(),k=a("ul"),L_=a("li"),Mee=a("strong"),jgo=o("albert"),qgo=o(" \u2014 "),EP=a("a"),Ggo=o("AlbertForPreTraining"),Ogo=o(" (ALBERT model)"),Xgo=l(),B_=a("li"),Eee=a("strong"),Vgo=o("bart"),zgo=o(" \u2014 "),yP=a("a"),Wgo=o("BartForConditionalGeneration"),Qgo=o(" (BART model)"),Hgo=l(),x_=a("li"),yee=a("strong"),Ugo=o("bert"),Jgo=o(" \u2014 "),wP=a("a"),Ygo=o("BertForPreTraining"),Kgo=o(" (BERT model)"),Zgo=l(),k_=a("li"),wee=a("strong"),eho=o("big_bird"),oho=o(" \u2014 "),AP=a("a"),rho=o("BigBirdForPreTraining"),tho=o(" (BigBird model)"),aho=l(),R_=a("li"),Aee=a("strong"),nho=o("camembert"),sho=o(" \u2014 "),LP=a("a"),lho=o("CamembertForMaskedLM"),iho=o(" (CamemBERT model)"),dho=l(),S_=a("li"),Lee=a("strong"),cho=o("ctrl"),fho=o(" \u2014 "),BP=a("a"),mho=o("CTRLLMHeadModel"),gho=o(" (CTRL model)"),hho=l(),P_=a("li"),Bee=a("strong"),pho=o("data2vec-text"),_ho=o(" \u2014 "),xP=a("a"),uho=o("Data2VecTextForMaskedLM"),bho=o(" (Data2VecText model)"),vho=l(),$_=a("li"),xee=a("strong"),Tho=o("deberta"),Fho=o(" \u2014 "),kP=a("a"),Cho=o("DebertaForMaskedLM"),Mho=o(" (DeBERTa model)"),Eho=l(),I_=a("li"),kee=a("strong"),yho=o("deberta-v2"),who=o(" \u2014 "),RP=a("a"),Aho=o("DebertaV2ForMaskedLM"),Lho=o(" (DeBERTa-v2 model)"),Bho=l(),N_=a("li"),Ree=a("strong"),xho=o("distilbert"),kho=o(" \u2014 "),SP=a("a"),Rho=o("DistilBertForMaskedLM"),Sho=o(" (DistilBERT model)"),Pho=l(),D_=a("li"),See=a("strong"),$ho=o("electra"),Iho=o(" \u2014 "),PP=a("a"),Nho=o("ElectraForPreTraining"),Dho=o(" (ELECTRA model)"),jho=l(),j_=a("li"),Pee=a("strong"),qho=o("flaubert"),Gho=o(" \u2014 "),$P=a("a"),Oho=o("FlaubertWithLMHeadModel"),Xho=o(" (FlauBERT model)"),Vho=l(),q_=a("li"),$ee=a("strong"),zho=o("fnet"),Who=o(" \u2014 "),IP=a("a"),Qho=o("FNetForPreTraining"),Hho=o(" (FNet model)"),Uho=l(),G_=a("li"),Iee=a("strong"),Jho=o("fsmt"),Yho=o(" \u2014 "),NP=a("a"),Kho=o("FSMTForConditionalGeneration"),Zho=o(" (FairSeq Machine-Translation model)"),epo=l(),O_=a("li"),Nee=a("strong"),opo=o("funnel"),rpo=o(" \u2014 "),DP=a("a"),tpo=o("FunnelForPreTraining"),apo=o(" (Funnel Transformer model)"),npo=l(),X_=a("li"),Dee=a("strong"),spo=o("gpt2"),lpo=o(" \u2014 "),jP=a("a"),ipo=o("GPT2LMHeadModel"),dpo=o(" (OpenAI GPT-2 model)"),cpo=l(),V_=a("li"),jee=a("strong"),fpo=o("ibert"),mpo=o(" \u2014 "),qP=a("a"),gpo=o("IBertForMaskedLM"),hpo=o(" (I-BERT model)"),ppo=l(),z_=a("li"),qee=a("strong"),_po=o("layoutlm"),upo=o(" \u2014 "),GP=a("a"),bpo=o("LayoutLMForMaskedLM"),vpo=o(" (LayoutLM model)"),Tpo=l(),W_=a("li"),Gee=a("strong"),Fpo=o("longformer"),Cpo=o(" \u2014 "),OP=a("a"),Mpo=o("LongformerForMaskedLM"),Epo=o(" (Longformer model)"),ypo=l(),Q_=a("li"),Oee=a("strong"),wpo=o("lxmert"),Apo=o(" \u2014 "),XP=a("a"),Lpo=o("LxmertForPreTraining"),Bpo=o(" (LXMERT model)"),xpo=l(),H_=a("li"),Xee=a("strong"),kpo=o("megatron-bert"),Rpo=o(" \u2014 "),VP=a("a"),Spo=o("MegatronBertForPreTraining"),Ppo=o(" (MegatronBert model)"),$po=l(),U_=a("li"),Vee=a("strong"),Ipo=o("mobilebert"),Npo=o(" \u2014 "),zP=a("a"),Dpo=o("MobileBertForPreTraining"),jpo=o(" (MobileBERT model)"),qpo=l(),J_=a("li"),zee=a("strong"),Gpo=o("mpnet"),Opo=o(" \u2014 "),WP=a("a"),Xpo=o("MPNetForMaskedLM"),Vpo=o(" (MPNet model)"),zpo=l(),Y_=a("li"),Wee=a("strong"),Wpo=o("openai-gpt"),Qpo=o(" \u2014 "),QP=a("a"),Hpo=o("OpenAIGPTLMHeadModel"),Upo=o(" (OpenAI GPT model)"),Jpo=l(),K_=a("li"),Qee=a("strong"),Ypo=o("retribert"),Kpo=o(" \u2014 "),HP=a("a"),Zpo=o("RetriBertModel"),e_o=o(" (RetriBERT model)"),o_o=l(),Z_=a("li"),Hee=a("strong"),r_o=o("roberta"),t_o=o(" \u2014 "),UP=a("a"),a_o=o("RobertaForMaskedLM"),n_o=o(" (RoBERTa model)"),s_o=l(),eu=a("li"),Uee=a("strong"),l_o=o("squeezebert"),i_o=o(" \u2014 "),JP=a("a"),d_o=o("SqueezeBertForMaskedLM"),c_o=o(" (SqueezeBERT model)"),f_o=l(),ou=a("li"),Jee=a("strong"),m_o=o("t5"),g_o=o(" \u2014 "),YP=a("a"),h_o=o("T5ForConditionalGeneration"),p_o=o(" (T5 model)"),__o=l(),ru=a("li"),Yee=a("strong"),u_o=o("tapas"),b_o=o(" \u2014 "),KP=a("a"),v_o=o("TapasForMaskedLM"),T_o=o(" (TAPAS model)"),F_o=l(),tu=a("li"),Kee=a("strong"),C_o=o("transfo-xl"),M_o=o(" \u2014 "),ZP=a("a"),E_o=o("TransfoXLLMHeadModel"),y_o=o(" (Transformer-XL model)"),w_o=l(),au=a("li"),Zee=a("strong"),A_o=o("unispeech"),L_o=o(" \u2014 "),e$=a("a"),B_o=o("UniSpeechForPreTraining"),x_o=o(" (UniSpeech model)"),k_o=l(),nu=a("li"),eoe=a("strong"),R_o=o("unispeech-sat"),S_o=o(" \u2014 "),o$=a("a"),P_o=o("UniSpeechSatForPreTraining"),$_o=o(" (UniSpeechSat model)"),I_o=l(),su=a("li"),ooe=a("strong"),N_o=o("visual_bert"),D_o=o(" \u2014 "),r$=a("a"),j_o=o("VisualBertForPreTraining"),q_o=o(" (VisualBert model)"),G_o=l(),lu=a("li"),roe=a("strong"),O_o=o("vit_mae"),X_o=o(" \u2014 "),t$=a("a"),V_o=o("ViTMAEForPreTraining"),z_o=o(" (ViTMAE model)"),W_o=l(),iu=a("li"),toe=a("strong"),Q_o=o("wav2vec2"),H_o=o(" \u2014 "),a$=a("a"),U_o=o("Wav2Vec2ForPreTraining"),J_o=o(" (Wav2Vec2 model)"),Y_o=l(),du=a("li"),aoe=a("strong"),K_o=o("xlm"),Z_o=o(" \u2014 "),n$=a("a"),euo=o("XLMWithLMHeadModel"),ouo=o(" (XLM model)"),ruo=l(),cu=a("li"),noe=a("strong"),tuo=o("xlm-roberta"),auo=o(" \u2014 "),s$=a("a"),nuo=o("XLMRobertaForMaskedLM"),suo=o(" (XLM-RoBERTa model)"),luo=l(),fu=a("li"),soe=a("strong"),iuo=o("xlm-roberta-xl"),duo=o(" \u2014 "),l$=a("a"),cuo=o("XLMRobertaXLForMaskedLM"),fuo=o(" (XLM-RoBERTa-XL model)"),muo=l(),mu=a("li"),loe=a("strong"),guo=o("xlnet"),huo=o(" \u2014 "),i$=a("a"),puo=o("XLNetLMHeadModel"),_uo=o(" (XLNet model)"),uuo=l(),gu=a("p"),buo=o("The model is set in evaluation mode by default using "),ioe=a("code"),vuo=o("model.eval()"),Tuo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),doe=a("code"),Fuo=o("model.train()"),Cuo=l(),coe=a("p"),Muo=o("Examples:"),Euo=l(),f(ey.$$.fragment),yke=l(),rd=a("h2"),hu=a("a"),foe=a("span"),f(oy.$$.fragment),yuo=l(),moe=a("span"),wuo=o("AutoModelForCausalLM"),wke=l(),Ko=a("div"),f(ry.$$.fragment),Auo=l(),td=a("p"),Luo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),goe=a("code"),Buo=o("from_pretrained()"),xuo=o("class method or the "),hoe=a("code"),kuo=o("from_config()"),Ruo=o(`class
method.`),Suo=l(),ty=a("p"),Puo=o("This class cannot be instantiated directly using "),poe=a("code"),$uo=o("__init__()"),Iuo=o(" (throws an error)."),Nuo=l(),Wr=a("div"),f(ay.$$.fragment),Duo=l(),_oe=a("p"),juo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),quo=l(),ad=a("p"),Guo=o(`Note:
Loading a model from its configuration file does `),uoe=a("strong"),Ouo=o("not"),Xuo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=a("code"),Vuo=o("from_pretrained()"),zuo=o("to load the model weights."),Wuo=l(),voe=a("p"),Quo=o("Examples:"),Huo=l(),f(ny.$$.fragment),Uuo=l(),je=a("div"),f(sy.$$.fragment),Juo=l(),Toe=a("p"),Yuo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Kuo=l(),Wa=a("p"),Zuo=o("The model class to instantiate is selected based on the "),Foe=a("code"),e5o=o("model_type"),o5o=o(` property of the config object (either
passed as an argument or loaded from `),Coe=a("code"),r5o=o("pretrained_model_name_or_path"),t5o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Moe=a("code"),a5o=o("pretrained_model_name_or_path"),n5o=o(":"),s5o=l(),$=a("ul"),pu=a("li"),Eoe=a("strong"),l5o=o("bart"),i5o=o(" \u2014 "),d$=a("a"),d5o=o("BartForCausalLM"),c5o=o(" (BART model)"),f5o=l(),_u=a("li"),yoe=a("strong"),m5o=o("bert"),g5o=o(" \u2014 "),c$=a("a"),h5o=o("BertLMHeadModel"),p5o=o(" (BERT model)"),_5o=l(),uu=a("li"),woe=a("strong"),u5o=o("bert-generation"),b5o=o(" \u2014 "),f$=a("a"),v5o=o("BertGenerationDecoder"),T5o=o(" (Bert Generation model)"),F5o=l(),bu=a("li"),Aoe=a("strong"),C5o=o("big_bird"),M5o=o(" \u2014 "),m$=a("a"),E5o=o("BigBirdForCausalLM"),y5o=o(" (BigBird model)"),w5o=l(),vu=a("li"),Loe=a("strong"),A5o=o("bigbird_pegasus"),L5o=o(" \u2014 "),g$=a("a"),B5o=o("BigBirdPegasusForCausalLM"),x5o=o(" (BigBirdPegasus model)"),k5o=l(),Tu=a("li"),Boe=a("strong"),R5o=o("blenderbot"),S5o=o(" \u2014 "),h$=a("a"),P5o=o("BlenderbotForCausalLM"),$5o=o(" (Blenderbot model)"),I5o=l(),Fu=a("li"),xoe=a("strong"),N5o=o("blenderbot-small"),D5o=o(" \u2014 "),p$=a("a"),j5o=o("BlenderbotSmallForCausalLM"),q5o=o(" (BlenderbotSmall model)"),G5o=l(),Cu=a("li"),koe=a("strong"),O5o=o("camembert"),X5o=o(" \u2014 "),_$=a("a"),V5o=o("CamembertForCausalLM"),z5o=o(" (CamemBERT model)"),W5o=l(),Mu=a("li"),Roe=a("strong"),Q5o=o("ctrl"),H5o=o(" \u2014 "),u$=a("a"),U5o=o("CTRLLMHeadModel"),J5o=o(" (CTRL model)"),Y5o=l(),Eu=a("li"),Soe=a("strong"),K5o=o("data2vec-text"),Z5o=o(" \u2014 "),b$=a("a"),e2o=o("Data2VecTextForCausalLM"),o2o=o(" (Data2VecText model)"),r2o=l(),yu=a("li"),Poe=a("strong"),t2o=o("electra"),a2o=o(" \u2014 "),v$=a("a"),n2o=o("ElectraForCausalLM"),s2o=o(" (ELECTRA model)"),l2o=l(),wu=a("li"),$oe=a("strong"),i2o=o("gpt2"),d2o=o(" \u2014 "),T$=a("a"),c2o=o("GPT2LMHeadModel"),f2o=o(" (OpenAI GPT-2 model)"),m2o=l(),Au=a("li"),Ioe=a("strong"),g2o=o("gpt_neo"),h2o=o(" \u2014 "),F$=a("a"),p2o=o("GPTNeoForCausalLM"),_2o=o(" (GPT Neo model)"),u2o=l(),Lu=a("li"),Noe=a("strong"),b2o=o("gptj"),v2o=o(" \u2014 "),C$=a("a"),T2o=o("GPTJForCausalLM"),F2o=o(" (GPT-J model)"),C2o=l(),Bu=a("li"),Doe=a("strong"),M2o=o("marian"),E2o=o(" \u2014 "),M$=a("a"),y2o=o("MarianForCausalLM"),w2o=o(" (Marian model)"),A2o=l(),xu=a("li"),joe=a("strong"),L2o=o("mbart"),B2o=o(" \u2014 "),E$=a("a"),x2o=o("MBartForCausalLM"),k2o=o(" (mBART model)"),R2o=l(),ku=a("li"),qoe=a("strong"),S2o=o("megatron-bert"),P2o=o(" \u2014 "),y$=a("a"),$2o=o("MegatronBertForCausalLM"),I2o=o(" (MegatronBert model)"),N2o=l(),Ru=a("li"),Goe=a("strong"),D2o=o("openai-gpt"),j2o=o(" \u2014 "),w$=a("a"),q2o=o("OpenAIGPTLMHeadModel"),G2o=o(" (OpenAI GPT model)"),O2o=l(),Su=a("li"),Ooe=a("strong"),X2o=o("pegasus"),V2o=o(" \u2014 "),A$=a("a"),z2o=o("PegasusForCausalLM"),W2o=o(" (Pegasus model)"),Q2o=l(),Pu=a("li"),Xoe=a("strong"),H2o=o("plbart"),U2o=o(" \u2014 "),L$=a("a"),J2o=o("PLBartForCausalLM"),Y2o=o(" (PLBart model)"),K2o=l(),$u=a("li"),Voe=a("strong"),Z2o=o("prophetnet"),e1o=o(" \u2014 "),B$=a("a"),o1o=o("ProphetNetForCausalLM"),r1o=o(" (ProphetNet model)"),t1o=l(),Iu=a("li"),zoe=a("strong"),a1o=o("qdqbert"),n1o=o(" \u2014 "),x$=a("a"),s1o=o("QDQBertLMHeadModel"),l1o=o(" (QDQBert model)"),i1o=l(),Nu=a("li"),Woe=a("strong"),d1o=o("reformer"),c1o=o(" \u2014 "),k$=a("a"),f1o=o("ReformerModelWithLMHead"),m1o=o(" (Reformer model)"),g1o=l(),Du=a("li"),Qoe=a("strong"),h1o=o("rembert"),p1o=o(" \u2014 "),R$=a("a"),_1o=o("RemBertForCausalLM"),u1o=o(" (RemBERT model)"),b1o=l(),ju=a("li"),Hoe=a("strong"),v1o=o("roberta"),T1o=o(" \u2014 "),S$=a("a"),F1o=o("RobertaForCausalLM"),C1o=o(" (RoBERTa model)"),M1o=l(),qu=a("li"),Uoe=a("strong"),E1o=o("roformer"),y1o=o(" \u2014 "),P$=a("a"),w1o=o("RoFormerForCausalLM"),A1o=o(" (RoFormer model)"),L1o=l(),Gu=a("li"),Joe=a("strong"),B1o=o("speech_to_text_2"),x1o=o(" \u2014 "),$$=a("a"),k1o=o("Speech2Text2ForCausalLM"),R1o=o(" (Speech2Text2 model)"),S1o=l(),Ou=a("li"),Yoe=a("strong"),P1o=o("transfo-xl"),$1o=o(" \u2014 "),I$=a("a"),I1o=o("TransfoXLLMHeadModel"),N1o=o(" (Transformer-XL model)"),D1o=l(),Xu=a("li"),Koe=a("strong"),j1o=o("trocr"),q1o=o(" \u2014 "),N$=a("a"),G1o=o("TrOCRForCausalLM"),O1o=o(" (TrOCR model)"),X1o=l(),Vu=a("li"),Zoe=a("strong"),V1o=o("xglm"),z1o=o(" \u2014 "),D$=a("a"),W1o=o("XGLMForCausalLM"),Q1o=o(" (XGLM model)"),H1o=l(),zu=a("li"),ere=a("strong"),U1o=o("xlm"),J1o=o(" \u2014 "),j$=a("a"),Y1o=o("XLMWithLMHeadModel"),K1o=o(" (XLM model)"),Z1o=l(),Wu=a("li"),ore=a("strong"),ebo=o("xlm-prophetnet"),obo=o(" \u2014 "),q$=a("a"),rbo=o("XLMProphetNetForCausalLM"),tbo=o(" (XLMProphetNet model)"),abo=l(),Qu=a("li"),rre=a("strong"),nbo=o("xlm-roberta"),sbo=o(" \u2014 "),G$=a("a"),lbo=o("XLMRobertaForCausalLM"),ibo=o(" (XLM-RoBERTa model)"),dbo=l(),Hu=a("li"),tre=a("strong"),cbo=o("xlm-roberta-xl"),fbo=o(" \u2014 "),O$=a("a"),mbo=o("XLMRobertaXLForCausalLM"),gbo=o(" (XLM-RoBERTa-XL model)"),hbo=l(),Uu=a("li"),are=a("strong"),pbo=o("xlnet"),_bo=o(" \u2014 "),X$=a("a"),ubo=o("XLNetLMHeadModel"),bbo=o(" (XLNet model)"),vbo=l(),Ju=a("p"),Tbo=o("The model is set in evaluation mode by default using "),nre=a("code"),Fbo=o("model.eval()"),Cbo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sre=a("code"),Mbo=o("model.train()"),Ebo=l(),lre=a("p"),ybo=o("Examples:"),wbo=l(),f(ly.$$.fragment),Ake=l(),nd=a("h2"),Yu=a("a"),ire=a("span"),f(iy.$$.fragment),Abo=l(),dre=a("span"),Lbo=o("AutoModelForMaskedLM"),Lke=l(),Zo=a("div"),f(dy.$$.fragment),Bbo=l(),sd=a("p"),xbo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cre=a("code"),kbo=o("from_pretrained()"),Rbo=o("class method or the "),fre=a("code"),Sbo=o("from_config()"),Pbo=o(`class
method.`),$bo=l(),cy=a("p"),Ibo=o("This class cannot be instantiated directly using "),mre=a("code"),Nbo=o("__init__()"),Dbo=o(" (throws an error)."),jbo=l(),Qr=a("div"),f(fy.$$.fragment),qbo=l(),gre=a("p"),Gbo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Obo=l(),ld=a("p"),Xbo=o(`Note:
Loading a model from its configuration file does `),hre=a("strong"),Vbo=o("not"),zbo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pre=a("code"),Wbo=o("from_pretrained()"),Qbo=o("to load the model weights."),Hbo=l(),_re=a("p"),Ubo=o("Examples:"),Jbo=l(),f(my.$$.fragment),Ybo=l(),qe=a("div"),f(gy.$$.fragment),Kbo=l(),ure=a("p"),Zbo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),evo=l(),Qa=a("p"),ovo=o("The model class to instantiate is selected based on the "),bre=a("code"),rvo=o("model_type"),tvo=o(` property of the config object (either
passed as an argument or loaded from `),vre=a("code"),avo=o("pretrained_model_name_or_path"),nvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tre=a("code"),svo=o("pretrained_model_name_or_path"),lvo=o(":"),ivo=l(),I=a("ul"),Ku=a("li"),Fre=a("strong"),dvo=o("albert"),cvo=o(" \u2014 "),V$=a("a"),fvo=o("AlbertForMaskedLM"),mvo=o(" (ALBERT model)"),gvo=l(),Zu=a("li"),Cre=a("strong"),hvo=o("bart"),pvo=o(" \u2014 "),z$=a("a"),_vo=o("BartForConditionalGeneration"),uvo=o(" (BART model)"),bvo=l(),e5=a("li"),Mre=a("strong"),vvo=o("bert"),Tvo=o(" \u2014 "),W$=a("a"),Fvo=o("BertForMaskedLM"),Cvo=o(" (BERT model)"),Mvo=l(),o5=a("li"),Ere=a("strong"),Evo=o("big_bird"),yvo=o(" \u2014 "),Q$=a("a"),wvo=o("BigBirdForMaskedLM"),Avo=o(" (BigBird model)"),Lvo=l(),r5=a("li"),yre=a("strong"),Bvo=o("camembert"),xvo=o(" \u2014 "),H$=a("a"),kvo=o("CamembertForMaskedLM"),Rvo=o(" (CamemBERT model)"),Svo=l(),t5=a("li"),wre=a("strong"),Pvo=o("convbert"),$vo=o(" \u2014 "),U$=a("a"),Ivo=o("ConvBertForMaskedLM"),Nvo=o(" (ConvBERT model)"),Dvo=l(),a5=a("li"),Are=a("strong"),jvo=o("data2vec-text"),qvo=o(" \u2014 "),J$=a("a"),Gvo=o("Data2VecTextForMaskedLM"),Ovo=o(" (Data2VecText model)"),Xvo=l(),n5=a("li"),Lre=a("strong"),Vvo=o("deberta"),zvo=o(" \u2014 "),Y$=a("a"),Wvo=o("DebertaForMaskedLM"),Qvo=o(" (DeBERTa model)"),Hvo=l(),s5=a("li"),Bre=a("strong"),Uvo=o("deberta-v2"),Jvo=o(" \u2014 "),K$=a("a"),Yvo=o("DebertaV2ForMaskedLM"),Kvo=o(" (DeBERTa-v2 model)"),Zvo=l(),l5=a("li"),xre=a("strong"),e6o=o("distilbert"),o6o=o(" \u2014 "),Z$=a("a"),r6o=o("DistilBertForMaskedLM"),t6o=o(" (DistilBERT model)"),a6o=l(),i5=a("li"),kre=a("strong"),n6o=o("electra"),s6o=o(" \u2014 "),eI=a("a"),l6o=o("ElectraForMaskedLM"),i6o=o(" (ELECTRA model)"),d6o=l(),d5=a("li"),Rre=a("strong"),c6o=o("flaubert"),f6o=o(" \u2014 "),oI=a("a"),m6o=o("FlaubertWithLMHeadModel"),g6o=o(" (FlauBERT model)"),h6o=l(),c5=a("li"),Sre=a("strong"),p6o=o("fnet"),_6o=o(" \u2014 "),rI=a("a"),u6o=o("FNetForMaskedLM"),b6o=o(" (FNet model)"),v6o=l(),f5=a("li"),Pre=a("strong"),T6o=o("funnel"),F6o=o(" \u2014 "),tI=a("a"),C6o=o("FunnelForMaskedLM"),M6o=o(" (Funnel Transformer model)"),E6o=l(),m5=a("li"),$re=a("strong"),y6o=o("ibert"),w6o=o(" \u2014 "),aI=a("a"),A6o=o("IBertForMaskedLM"),L6o=o(" (I-BERT model)"),B6o=l(),g5=a("li"),Ire=a("strong"),x6o=o("layoutlm"),k6o=o(" \u2014 "),nI=a("a"),R6o=o("LayoutLMForMaskedLM"),S6o=o(" (LayoutLM model)"),P6o=l(),h5=a("li"),Nre=a("strong"),$6o=o("longformer"),I6o=o(" \u2014 "),sI=a("a"),N6o=o("LongformerForMaskedLM"),D6o=o(" (Longformer model)"),j6o=l(),p5=a("li"),Dre=a("strong"),q6o=o("mbart"),G6o=o(" \u2014 "),lI=a("a"),O6o=o("MBartForConditionalGeneration"),X6o=o(" (mBART model)"),V6o=l(),_5=a("li"),jre=a("strong"),z6o=o("megatron-bert"),W6o=o(" \u2014 "),iI=a("a"),Q6o=o("MegatronBertForMaskedLM"),H6o=o(" (MegatronBert model)"),U6o=l(),u5=a("li"),qre=a("strong"),J6o=o("mobilebert"),Y6o=o(" \u2014 "),dI=a("a"),K6o=o("MobileBertForMaskedLM"),Z6o=o(" (MobileBERT model)"),eTo=l(),b5=a("li"),Gre=a("strong"),oTo=o("mpnet"),rTo=o(" \u2014 "),cI=a("a"),tTo=o("MPNetForMaskedLM"),aTo=o(" (MPNet model)"),nTo=l(),v5=a("li"),Ore=a("strong"),sTo=o("nystromformer"),lTo=o(" \u2014 "),fI=a("a"),iTo=o("NystromformerForMaskedLM"),dTo=o(" (Nystromformer model)"),cTo=l(),T5=a("li"),Xre=a("strong"),fTo=o("perceiver"),mTo=o(" \u2014 "),mI=a("a"),gTo=o("PerceiverForMaskedLM"),hTo=o(" (Perceiver model)"),pTo=l(),F5=a("li"),Vre=a("strong"),_To=o("qdqbert"),uTo=o(" \u2014 "),gI=a("a"),bTo=o("QDQBertForMaskedLM"),vTo=o(" (QDQBert model)"),TTo=l(),C5=a("li"),zre=a("strong"),FTo=o("reformer"),CTo=o(" \u2014 "),hI=a("a"),MTo=o("ReformerForMaskedLM"),ETo=o(" (Reformer model)"),yTo=l(),M5=a("li"),Wre=a("strong"),wTo=o("rembert"),ATo=o(" \u2014 "),pI=a("a"),LTo=o("RemBertForMaskedLM"),BTo=o(" (RemBERT model)"),xTo=l(),E5=a("li"),Qre=a("strong"),kTo=o("roberta"),RTo=o(" \u2014 "),_I=a("a"),STo=o("RobertaForMaskedLM"),PTo=o(" (RoBERTa model)"),$To=l(),y5=a("li"),Hre=a("strong"),ITo=o("roformer"),NTo=o(" \u2014 "),uI=a("a"),DTo=o("RoFormerForMaskedLM"),jTo=o(" (RoFormer model)"),qTo=l(),w5=a("li"),Ure=a("strong"),GTo=o("squeezebert"),OTo=o(" \u2014 "),bI=a("a"),XTo=o("SqueezeBertForMaskedLM"),VTo=o(" (SqueezeBERT model)"),zTo=l(),A5=a("li"),Jre=a("strong"),WTo=o("tapas"),QTo=o(" \u2014 "),vI=a("a"),HTo=o("TapasForMaskedLM"),UTo=o(" (TAPAS model)"),JTo=l(),L5=a("li"),Yre=a("strong"),YTo=o("wav2vec2"),KTo=o(" \u2014 "),Kre=a("code"),ZTo=o("Wav2Vec2ForMaskedLM"),eFo=o("(Wav2Vec2 model)"),oFo=l(),B5=a("li"),Zre=a("strong"),rFo=o("xlm"),tFo=o(" \u2014 "),TI=a("a"),aFo=o("XLMWithLMHeadModel"),nFo=o(" (XLM model)"),sFo=l(),x5=a("li"),ete=a("strong"),lFo=o("xlm-roberta"),iFo=o(" \u2014 "),FI=a("a"),dFo=o("XLMRobertaForMaskedLM"),cFo=o(" (XLM-RoBERTa model)"),fFo=l(),k5=a("li"),ote=a("strong"),mFo=o("xlm-roberta-xl"),gFo=o(" \u2014 "),CI=a("a"),hFo=o("XLMRobertaXLForMaskedLM"),pFo=o(" (XLM-RoBERTa-XL model)"),_Fo=l(),R5=a("li"),rte=a("strong"),uFo=o("yoso"),bFo=o(" \u2014 "),MI=a("a"),vFo=o("YosoForMaskedLM"),TFo=o(" (YOSO model)"),FFo=l(),S5=a("p"),CFo=o("The model is set in evaluation mode by default using "),tte=a("code"),MFo=o("model.eval()"),EFo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ate=a("code"),yFo=o("model.train()"),wFo=l(),nte=a("p"),AFo=o("Examples:"),LFo=l(),f(hy.$$.fragment),Bke=l(),id=a("h2"),P5=a("a"),ste=a("span"),f(py.$$.fragment),BFo=l(),lte=a("span"),xFo=o("AutoModelForSeq2SeqLM"),xke=l(),er=a("div"),f(_y.$$.fragment),kFo=l(),dd=a("p"),RFo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ite=a("code"),SFo=o("from_pretrained()"),PFo=o("class method or the "),dte=a("code"),$Fo=o("from_config()"),IFo=o(`class
method.`),NFo=l(),uy=a("p"),DFo=o("This class cannot be instantiated directly using "),cte=a("code"),jFo=o("__init__()"),qFo=o(" (throws an error)."),GFo=l(),Hr=a("div"),f(by.$$.fragment),OFo=l(),fte=a("p"),XFo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),VFo=l(),cd=a("p"),zFo=o(`Note:
Loading a model from its configuration file does `),mte=a("strong"),WFo=o("not"),QFo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gte=a("code"),HFo=o("from_pretrained()"),UFo=o("to load the model weights."),JFo=l(),hte=a("p"),YFo=o("Examples:"),KFo=l(),f(vy.$$.fragment),ZFo=l(),Ge=a("div"),f(Ty.$$.fragment),eCo=l(),pte=a("p"),oCo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),rCo=l(),Ha=a("p"),tCo=o("The model class to instantiate is selected based on the "),_te=a("code"),aCo=o("model_type"),nCo=o(` property of the config object (either
passed as an argument or loaded from `),ute=a("code"),sCo=o("pretrained_model_name_or_path"),lCo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bte=a("code"),iCo=o("pretrained_model_name_or_path"),dCo=o(":"),cCo=l(),se=a("ul"),$5=a("li"),vte=a("strong"),fCo=o("bart"),mCo=o(" \u2014 "),EI=a("a"),gCo=o("BartForConditionalGeneration"),hCo=o(" (BART model)"),pCo=l(),I5=a("li"),Tte=a("strong"),_Co=o("bigbird_pegasus"),uCo=o(" \u2014 "),yI=a("a"),bCo=o("BigBirdPegasusForConditionalGeneration"),vCo=o(" (BigBirdPegasus model)"),TCo=l(),N5=a("li"),Fte=a("strong"),FCo=o("blenderbot"),CCo=o(" \u2014 "),wI=a("a"),MCo=o("BlenderbotForConditionalGeneration"),ECo=o(" (Blenderbot model)"),yCo=l(),D5=a("li"),Cte=a("strong"),wCo=o("blenderbot-small"),ACo=o(" \u2014 "),AI=a("a"),LCo=o("BlenderbotSmallForConditionalGeneration"),BCo=o(" (BlenderbotSmall model)"),xCo=l(),j5=a("li"),Mte=a("strong"),kCo=o("encoder-decoder"),RCo=o(" \u2014 "),LI=a("a"),SCo=o("EncoderDecoderModel"),PCo=o(" (Encoder decoder model)"),$Co=l(),q5=a("li"),Ete=a("strong"),ICo=o("fsmt"),NCo=o(" \u2014 "),BI=a("a"),DCo=o("FSMTForConditionalGeneration"),jCo=o(" (FairSeq Machine-Translation model)"),qCo=l(),G5=a("li"),yte=a("strong"),GCo=o("led"),OCo=o(" \u2014 "),xI=a("a"),XCo=o("LEDForConditionalGeneration"),VCo=o(" (LED model)"),zCo=l(),O5=a("li"),wte=a("strong"),WCo=o("m2m_100"),QCo=o(" \u2014 "),kI=a("a"),HCo=o("M2M100ForConditionalGeneration"),UCo=o(" (M2M100 model)"),JCo=l(),X5=a("li"),Ate=a("strong"),YCo=o("marian"),KCo=o(" \u2014 "),RI=a("a"),ZCo=o("MarianMTModel"),eMo=o(" (Marian model)"),oMo=l(),V5=a("li"),Lte=a("strong"),rMo=o("mbart"),tMo=o(" \u2014 "),SI=a("a"),aMo=o("MBartForConditionalGeneration"),nMo=o(" (mBART model)"),sMo=l(),z5=a("li"),Bte=a("strong"),lMo=o("mt5"),iMo=o(" \u2014 "),PI=a("a"),dMo=o("MT5ForConditionalGeneration"),cMo=o(" (mT5 model)"),fMo=l(),W5=a("li"),xte=a("strong"),mMo=o("pegasus"),gMo=o(" \u2014 "),$I=a("a"),hMo=o("PegasusForConditionalGeneration"),pMo=o(" (Pegasus model)"),_Mo=l(),Q5=a("li"),kte=a("strong"),uMo=o("plbart"),bMo=o(" \u2014 "),II=a("a"),vMo=o("PLBartForConditionalGeneration"),TMo=o(" (PLBart model)"),FMo=l(),H5=a("li"),Rte=a("strong"),CMo=o("prophetnet"),MMo=o(" \u2014 "),NI=a("a"),EMo=o("ProphetNetForConditionalGeneration"),yMo=o(" (ProphetNet model)"),wMo=l(),U5=a("li"),Ste=a("strong"),AMo=o("t5"),LMo=o(" \u2014 "),DI=a("a"),BMo=o("T5ForConditionalGeneration"),xMo=o(" (T5 model)"),kMo=l(),J5=a("li"),Pte=a("strong"),RMo=o("xlm-prophetnet"),SMo=o(" \u2014 "),jI=a("a"),PMo=o("XLMProphetNetForConditionalGeneration"),$Mo=o(" (XLMProphetNet model)"),IMo=l(),Y5=a("p"),NMo=o("The model is set in evaluation mode by default using "),$te=a("code"),DMo=o("model.eval()"),jMo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ite=a("code"),qMo=o("model.train()"),GMo=l(),Nte=a("p"),OMo=o("Examples:"),XMo=l(),f(Fy.$$.fragment),kke=l(),fd=a("h2"),K5=a("a"),Dte=a("span"),f(Cy.$$.fragment),VMo=l(),jte=a("span"),zMo=o("AutoModelForSequenceClassification"),Rke=l(),or=a("div"),f(My.$$.fragment),WMo=l(),md=a("p"),QMo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qte=a("code"),HMo=o("from_pretrained()"),UMo=o("class method or the "),Gte=a("code"),JMo=o("from_config()"),YMo=o(`class
method.`),KMo=l(),Ey=a("p"),ZMo=o("This class cannot be instantiated directly using "),Ote=a("code"),e4o=o("__init__()"),o4o=o(" (throws an error)."),r4o=l(),Ur=a("div"),f(yy.$$.fragment),t4o=l(),Xte=a("p"),a4o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),n4o=l(),gd=a("p"),s4o=o(`Note:
Loading a model from its configuration file does `),Vte=a("strong"),l4o=o("not"),i4o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=a("code"),d4o=o("from_pretrained()"),c4o=o("to load the model weights."),f4o=l(),Wte=a("p"),m4o=o("Examples:"),g4o=l(),f(wy.$$.fragment),h4o=l(),Oe=a("div"),f(Ay.$$.fragment),p4o=l(),Qte=a("p"),_4o=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),u4o=l(),Ua=a("p"),b4o=o("The model class to instantiate is selected based on the "),Hte=a("code"),v4o=o("model_type"),T4o=o(` property of the config object (either
passed as an argument or loaded from `),Ute=a("code"),F4o=o("pretrained_model_name_or_path"),C4o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jte=a("code"),M4o=o("pretrained_model_name_or_path"),E4o=o(":"),y4o=l(),A=a("ul"),Z5=a("li"),Yte=a("strong"),w4o=o("albert"),A4o=o(" \u2014 "),qI=a("a"),L4o=o("AlbertForSequenceClassification"),B4o=o(" (ALBERT model)"),x4o=l(),e2=a("li"),Kte=a("strong"),k4o=o("bart"),R4o=o(" \u2014 "),GI=a("a"),S4o=o("BartForSequenceClassification"),P4o=o(" (BART model)"),$4o=l(),o2=a("li"),Zte=a("strong"),I4o=o("bert"),N4o=o(" \u2014 "),OI=a("a"),D4o=o("BertForSequenceClassification"),j4o=o(" (BERT model)"),q4o=l(),r2=a("li"),eae=a("strong"),G4o=o("big_bird"),O4o=o(" \u2014 "),XI=a("a"),X4o=o("BigBirdForSequenceClassification"),V4o=o(" (BigBird model)"),z4o=l(),t2=a("li"),oae=a("strong"),W4o=o("bigbird_pegasus"),Q4o=o(" \u2014 "),VI=a("a"),H4o=o("BigBirdPegasusForSequenceClassification"),U4o=o(" (BigBirdPegasus model)"),J4o=l(),a2=a("li"),rae=a("strong"),Y4o=o("camembert"),K4o=o(" \u2014 "),zI=a("a"),Z4o=o("CamembertForSequenceClassification"),eEo=o(" (CamemBERT model)"),oEo=l(),n2=a("li"),tae=a("strong"),rEo=o("canine"),tEo=o(" \u2014 "),WI=a("a"),aEo=o("CanineForSequenceClassification"),nEo=o(" (Canine model)"),sEo=l(),s2=a("li"),aae=a("strong"),lEo=o("convbert"),iEo=o(" \u2014 "),QI=a("a"),dEo=o("ConvBertForSequenceClassification"),cEo=o(" (ConvBERT model)"),fEo=l(),l2=a("li"),nae=a("strong"),mEo=o("ctrl"),gEo=o(" \u2014 "),HI=a("a"),hEo=o("CTRLForSequenceClassification"),pEo=o(" (CTRL model)"),_Eo=l(),i2=a("li"),sae=a("strong"),uEo=o("data2vec-text"),bEo=o(" \u2014 "),UI=a("a"),vEo=o("Data2VecTextForSequenceClassification"),TEo=o(" (Data2VecText model)"),FEo=l(),d2=a("li"),lae=a("strong"),CEo=o("deberta"),MEo=o(" \u2014 "),JI=a("a"),EEo=o("DebertaForSequenceClassification"),yEo=o(" (DeBERTa model)"),wEo=l(),c2=a("li"),iae=a("strong"),AEo=o("deberta-v2"),LEo=o(" \u2014 "),YI=a("a"),BEo=o("DebertaV2ForSequenceClassification"),xEo=o(" (DeBERTa-v2 model)"),kEo=l(),f2=a("li"),dae=a("strong"),REo=o("distilbert"),SEo=o(" \u2014 "),KI=a("a"),PEo=o("DistilBertForSequenceClassification"),$Eo=o(" (DistilBERT model)"),IEo=l(),m2=a("li"),cae=a("strong"),NEo=o("electra"),DEo=o(" \u2014 "),ZI=a("a"),jEo=o("ElectraForSequenceClassification"),qEo=o(" (ELECTRA model)"),GEo=l(),g2=a("li"),fae=a("strong"),OEo=o("flaubert"),XEo=o(" \u2014 "),eN=a("a"),VEo=o("FlaubertForSequenceClassification"),zEo=o(" (FlauBERT model)"),WEo=l(),h2=a("li"),mae=a("strong"),QEo=o("fnet"),HEo=o(" \u2014 "),oN=a("a"),UEo=o("FNetForSequenceClassification"),JEo=o(" (FNet model)"),YEo=l(),p2=a("li"),gae=a("strong"),KEo=o("funnel"),ZEo=o(" \u2014 "),rN=a("a"),e3o=o("FunnelForSequenceClassification"),o3o=o(" (Funnel Transformer model)"),r3o=l(),_2=a("li"),hae=a("strong"),t3o=o("gpt2"),a3o=o(" \u2014 "),tN=a("a"),n3o=o("GPT2ForSequenceClassification"),s3o=o(" (OpenAI GPT-2 model)"),l3o=l(),u2=a("li"),pae=a("strong"),i3o=o("gpt_neo"),d3o=o(" \u2014 "),aN=a("a"),c3o=o("GPTNeoForSequenceClassification"),f3o=o(" (GPT Neo model)"),m3o=l(),b2=a("li"),_ae=a("strong"),g3o=o("gptj"),h3o=o(" \u2014 "),nN=a("a"),p3o=o("GPTJForSequenceClassification"),_3o=o(" (GPT-J model)"),u3o=l(),v2=a("li"),uae=a("strong"),b3o=o("ibert"),v3o=o(" \u2014 "),sN=a("a"),T3o=o("IBertForSequenceClassification"),F3o=o(" (I-BERT model)"),C3o=l(),T2=a("li"),bae=a("strong"),M3o=o("layoutlm"),E3o=o(" \u2014 "),lN=a("a"),y3o=o("LayoutLMForSequenceClassification"),w3o=o(" (LayoutLM model)"),A3o=l(),F2=a("li"),vae=a("strong"),L3o=o("layoutlmv2"),B3o=o(" \u2014 "),iN=a("a"),x3o=o("LayoutLMv2ForSequenceClassification"),k3o=o(" (LayoutLMv2 model)"),R3o=l(),C2=a("li"),Tae=a("strong"),S3o=o("led"),P3o=o(" \u2014 "),dN=a("a"),$3o=o("LEDForSequenceClassification"),I3o=o(" (LED model)"),N3o=l(),M2=a("li"),Fae=a("strong"),D3o=o("longformer"),j3o=o(" \u2014 "),cN=a("a"),q3o=o("LongformerForSequenceClassification"),G3o=o(" (Longformer model)"),O3o=l(),E2=a("li"),Cae=a("strong"),X3o=o("mbart"),V3o=o(" \u2014 "),fN=a("a"),z3o=o("MBartForSequenceClassification"),W3o=o(" (mBART model)"),Q3o=l(),y2=a("li"),Mae=a("strong"),H3o=o("megatron-bert"),U3o=o(" \u2014 "),mN=a("a"),J3o=o("MegatronBertForSequenceClassification"),Y3o=o(" (MegatronBert model)"),K3o=l(),w2=a("li"),Eae=a("strong"),Z3o=o("mobilebert"),eyo=o(" \u2014 "),gN=a("a"),oyo=o("MobileBertForSequenceClassification"),ryo=o(" (MobileBERT model)"),tyo=l(),A2=a("li"),yae=a("strong"),ayo=o("mpnet"),nyo=o(" \u2014 "),hN=a("a"),syo=o("MPNetForSequenceClassification"),lyo=o(" (MPNet model)"),iyo=l(),L2=a("li"),wae=a("strong"),dyo=o("nystromformer"),cyo=o(" \u2014 "),pN=a("a"),fyo=o("NystromformerForSequenceClassification"),myo=o(" (Nystromformer model)"),gyo=l(),B2=a("li"),Aae=a("strong"),hyo=o("openai-gpt"),pyo=o(" \u2014 "),_N=a("a"),_yo=o("OpenAIGPTForSequenceClassification"),uyo=o(" (OpenAI GPT model)"),byo=l(),x2=a("li"),Lae=a("strong"),vyo=o("perceiver"),Tyo=o(" \u2014 "),uN=a("a"),Fyo=o("PerceiverForSequenceClassification"),Cyo=o(" (Perceiver model)"),Myo=l(),k2=a("li"),Bae=a("strong"),Eyo=o("plbart"),yyo=o(" \u2014 "),bN=a("a"),wyo=o("PLBartForSequenceClassification"),Ayo=o(" (PLBart model)"),Lyo=l(),R2=a("li"),xae=a("strong"),Byo=o("qdqbert"),xyo=o(" \u2014 "),vN=a("a"),kyo=o("QDQBertForSequenceClassification"),Ryo=o(" (QDQBert model)"),Syo=l(),S2=a("li"),kae=a("strong"),Pyo=o("reformer"),$yo=o(" \u2014 "),TN=a("a"),Iyo=o("ReformerForSequenceClassification"),Nyo=o(" (Reformer model)"),Dyo=l(),P2=a("li"),Rae=a("strong"),jyo=o("rembert"),qyo=o(" \u2014 "),FN=a("a"),Gyo=o("RemBertForSequenceClassification"),Oyo=o(" (RemBERT model)"),Xyo=l(),$2=a("li"),Sae=a("strong"),Vyo=o("roberta"),zyo=o(" \u2014 "),CN=a("a"),Wyo=o("RobertaForSequenceClassification"),Qyo=o(" (RoBERTa model)"),Hyo=l(),I2=a("li"),Pae=a("strong"),Uyo=o("roformer"),Jyo=o(" \u2014 "),MN=a("a"),Yyo=o("RoFormerForSequenceClassification"),Kyo=o(" (RoFormer model)"),Zyo=l(),N2=a("li"),$ae=a("strong"),ewo=o("squeezebert"),owo=o(" \u2014 "),EN=a("a"),rwo=o("SqueezeBertForSequenceClassification"),two=o(" (SqueezeBERT model)"),awo=l(),D2=a("li"),Iae=a("strong"),nwo=o("tapas"),swo=o(" \u2014 "),yN=a("a"),lwo=o("TapasForSequenceClassification"),iwo=o(" (TAPAS model)"),dwo=l(),j2=a("li"),Nae=a("strong"),cwo=o("transfo-xl"),fwo=o(" \u2014 "),wN=a("a"),mwo=o("TransfoXLForSequenceClassification"),gwo=o(" (Transformer-XL model)"),hwo=l(),q2=a("li"),Dae=a("strong"),pwo=o("xlm"),_wo=o(" \u2014 "),AN=a("a"),uwo=o("XLMForSequenceClassification"),bwo=o(" (XLM model)"),vwo=l(),G2=a("li"),jae=a("strong"),Two=o("xlm-roberta"),Fwo=o(" \u2014 "),LN=a("a"),Cwo=o("XLMRobertaForSequenceClassification"),Mwo=o(" (XLM-RoBERTa model)"),Ewo=l(),O2=a("li"),qae=a("strong"),ywo=o("xlm-roberta-xl"),wwo=o(" \u2014 "),BN=a("a"),Awo=o("XLMRobertaXLForSequenceClassification"),Lwo=o(" (XLM-RoBERTa-XL model)"),Bwo=l(),X2=a("li"),Gae=a("strong"),xwo=o("xlnet"),kwo=o(" \u2014 "),xN=a("a"),Rwo=o("XLNetForSequenceClassification"),Swo=o(" (XLNet model)"),Pwo=l(),V2=a("li"),Oae=a("strong"),$wo=o("yoso"),Iwo=o(" \u2014 "),kN=a("a"),Nwo=o("YosoForSequenceClassification"),Dwo=o(" (YOSO model)"),jwo=l(),z2=a("p"),qwo=o("The model is set in evaluation mode by default using "),Xae=a("code"),Gwo=o("model.eval()"),Owo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vae=a("code"),Xwo=o("model.train()"),Vwo=l(),zae=a("p"),zwo=o("Examples:"),Wwo=l(),f(Ly.$$.fragment),Ske=l(),hd=a("h2"),W2=a("a"),Wae=a("span"),f(By.$$.fragment),Qwo=l(),Qae=a("span"),Hwo=o("AutoModelForMultipleChoice"),Pke=l(),rr=a("div"),f(xy.$$.fragment),Uwo=l(),pd=a("p"),Jwo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hae=a("code"),Ywo=o("from_pretrained()"),Kwo=o("class method or the "),Uae=a("code"),Zwo=o("from_config()"),eAo=o(`class
method.`),oAo=l(),ky=a("p"),rAo=o("This class cannot be instantiated directly using "),Jae=a("code"),tAo=o("__init__()"),aAo=o(" (throws an error)."),nAo=l(),Jr=a("div"),f(Ry.$$.fragment),sAo=l(),Yae=a("p"),lAo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),iAo=l(),_d=a("p"),dAo=o(`Note:
Loading a model from its configuration file does `),Kae=a("strong"),cAo=o("not"),fAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=a("code"),mAo=o("from_pretrained()"),gAo=o("to load the model weights."),hAo=l(),ene=a("p"),pAo=o("Examples:"),_Ao=l(),f(Sy.$$.fragment),uAo=l(),Xe=a("div"),f(Py.$$.fragment),bAo=l(),one=a("p"),vAo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),TAo=l(),Ja=a("p"),FAo=o("The model class to instantiate is selected based on the "),rne=a("code"),CAo=o("model_type"),MAo=o(` property of the config object (either
passed as an argument or loaded from `),tne=a("code"),EAo=o("pretrained_model_name_or_path"),yAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ane=a("code"),wAo=o("pretrained_model_name_or_path"),AAo=o(":"),LAo=l(),G=a("ul"),Q2=a("li"),nne=a("strong"),BAo=o("albert"),xAo=o(" \u2014 "),RN=a("a"),kAo=o("AlbertForMultipleChoice"),RAo=o(" (ALBERT model)"),SAo=l(),H2=a("li"),sne=a("strong"),PAo=o("bert"),$Ao=o(" \u2014 "),SN=a("a"),IAo=o("BertForMultipleChoice"),NAo=o(" (BERT model)"),DAo=l(),U2=a("li"),lne=a("strong"),jAo=o("big_bird"),qAo=o(" \u2014 "),PN=a("a"),GAo=o("BigBirdForMultipleChoice"),OAo=o(" (BigBird model)"),XAo=l(),J2=a("li"),ine=a("strong"),VAo=o("camembert"),zAo=o(" \u2014 "),$N=a("a"),WAo=o("CamembertForMultipleChoice"),QAo=o(" (CamemBERT model)"),HAo=l(),Y2=a("li"),dne=a("strong"),UAo=o("canine"),JAo=o(" \u2014 "),IN=a("a"),YAo=o("CanineForMultipleChoice"),KAo=o(" (Canine model)"),ZAo=l(),K2=a("li"),cne=a("strong"),e0o=o("convbert"),o0o=o(" \u2014 "),NN=a("a"),r0o=o("ConvBertForMultipleChoice"),t0o=o(" (ConvBERT model)"),a0o=l(),Z2=a("li"),fne=a("strong"),n0o=o("data2vec-text"),s0o=o(" \u2014 "),DN=a("a"),l0o=o("Data2VecTextForMultipleChoice"),i0o=o(" (Data2VecText model)"),d0o=l(),e1=a("li"),mne=a("strong"),c0o=o("distilbert"),f0o=o(" \u2014 "),jN=a("a"),m0o=o("DistilBertForMultipleChoice"),g0o=o(" (DistilBERT model)"),h0o=l(),o1=a("li"),gne=a("strong"),p0o=o("electra"),_0o=o(" \u2014 "),qN=a("a"),u0o=o("ElectraForMultipleChoice"),b0o=o(" (ELECTRA model)"),v0o=l(),r1=a("li"),hne=a("strong"),T0o=o("flaubert"),F0o=o(" \u2014 "),GN=a("a"),C0o=o("FlaubertForMultipleChoice"),M0o=o(" (FlauBERT model)"),E0o=l(),t1=a("li"),pne=a("strong"),y0o=o("fnet"),w0o=o(" \u2014 "),ON=a("a"),A0o=o("FNetForMultipleChoice"),L0o=o(" (FNet model)"),B0o=l(),a1=a("li"),_ne=a("strong"),x0o=o("funnel"),k0o=o(" \u2014 "),XN=a("a"),R0o=o("FunnelForMultipleChoice"),S0o=o(" (Funnel Transformer model)"),P0o=l(),n1=a("li"),une=a("strong"),$0o=o("ibert"),I0o=o(" \u2014 "),VN=a("a"),N0o=o("IBertForMultipleChoice"),D0o=o(" (I-BERT model)"),j0o=l(),s1=a("li"),bne=a("strong"),q0o=o("longformer"),G0o=o(" \u2014 "),zN=a("a"),O0o=o("LongformerForMultipleChoice"),X0o=o(" (Longformer model)"),V0o=l(),l1=a("li"),vne=a("strong"),z0o=o("megatron-bert"),W0o=o(" \u2014 "),WN=a("a"),Q0o=o("MegatronBertForMultipleChoice"),H0o=o(" (MegatronBert model)"),U0o=l(),i1=a("li"),Tne=a("strong"),J0o=o("mobilebert"),Y0o=o(" \u2014 "),QN=a("a"),K0o=o("MobileBertForMultipleChoice"),Z0o=o(" (MobileBERT model)"),eLo=l(),d1=a("li"),Fne=a("strong"),oLo=o("mpnet"),rLo=o(" \u2014 "),HN=a("a"),tLo=o("MPNetForMultipleChoice"),aLo=o(" (MPNet model)"),nLo=l(),c1=a("li"),Cne=a("strong"),sLo=o("nystromformer"),lLo=o(" \u2014 "),UN=a("a"),iLo=o("NystromformerForMultipleChoice"),dLo=o(" (Nystromformer model)"),cLo=l(),f1=a("li"),Mne=a("strong"),fLo=o("qdqbert"),mLo=o(" \u2014 "),JN=a("a"),gLo=o("QDQBertForMultipleChoice"),hLo=o(" (QDQBert model)"),pLo=l(),m1=a("li"),Ene=a("strong"),_Lo=o("rembert"),uLo=o(" \u2014 "),YN=a("a"),bLo=o("RemBertForMultipleChoice"),vLo=o(" (RemBERT model)"),TLo=l(),g1=a("li"),yne=a("strong"),FLo=o("roberta"),CLo=o(" \u2014 "),KN=a("a"),MLo=o("RobertaForMultipleChoice"),ELo=o(" (RoBERTa model)"),yLo=l(),h1=a("li"),wne=a("strong"),wLo=o("roformer"),ALo=o(" \u2014 "),ZN=a("a"),LLo=o("RoFormerForMultipleChoice"),BLo=o(" (RoFormer model)"),xLo=l(),p1=a("li"),Ane=a("strong"),kLo=o("squeezebert"),RLo=o(" \u2014 "),eD=a("a"),SLo=o("SqueezeBertForMultipleChoice"),PLo=o(" (SqueezeBERT model)"),$Lo=l(),_1=a("li"),Lne=a("strong"),ILo=o("xlm"),NLo=o(" \u2014 "),oD=a("a"),DLo=o("XLMForMultipleChoice"),jLo=o(" (XLM model)"),qLo=l(),u1=a("li"),Bne=a("strong"),GLo=o("xlm-roberta"),OLo=o(" \u2014 "),rD=a("a"),XLo=o("XLMRobertaForMultipleChoice"),VLo=o(" (XLM-RoBERTa model)"),zLo=l(),b1=a("li"),xne=a("strong"),WLo=o("xlm-roberta-xl"),QLo=o(" \u2014 "),tD=a("a"),HLo=o("XLMRobertaXLForMultipleChoice"),ULo=o(" (XLM-RoBERTa-XL model)"),JLo=l(),v1=a("li"),kne=a("strong"),YLo=o("xlnet"),KLo=o(" \u2014 "),aD=a("a"),ZLo=o("XLNetForMultipleChoice"),e7o=o(" (XLNet model)"),o7o=l(),T1=a("li"),Rne=a("strong"),r7o=o("yoso"),t7o=o(" \u2014 "),nD=a("a"),a7o=o("YosoForMultipleChoice"),n7o=o(" (YOSO model)"),s7o=l(),F1=a("p"),l7o=o("The model is set in evaluation mode by default using "),Sne=a("code"),i7o=o("model.eval()"),d7o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pne=a("code"),c7o=o("model.train()"),f7o=l(),$ne=a("p"),m7o=o("Examples:"),g7o=l(),f($y.$$.fragment),$ke=l(),ud=a("h2"),C1=a("a"),Ine=a("span"),f(Iy.$$.fragment),h7o=l(),Nne=a("span"),p7o=o("AutoModelForNextSentencePrediction"),Ike=l(),tr=a("div"),f(Ny.$$.fragment),_7o=l(),bd=a("p"),u7o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Dne=a("code"),b7o=o("from_pretrained()"),v7o=o("class method or the "),jne=a("code"),T7o=o("from_config()"),F7o=o(`class
method.`),C7o=l(),Dy=a("p"),M7o=o("This class cannot be instantiated directly using "),qne=a("code"),E7o=o("__init__()"),y7o=o(" (throws an error)."),w7o=l(),Yr=a("div"),f(jy.$$.fragment),A7o=l(),Gne=a("p"),L7o=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),B7o=l(),vd=a("p"),x7o=o(`Note:
Loading a model from its configuration file does `),One=a("strong"),k7o=o("not"),R7o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xne=a("code"),S7o=o("from_pretrained()"),P7o=o("to load the model weights."),$7o=l(),Vne=a("p"),I7o=o("Examples:"),N7o=l(),f(qy.$$.fragment),D7o=l(),Ve=a("div"),f(Gy.$$.fragment),j7o=l(),zne=a("p"),q7o=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),G7o=l(),Ya=a("p"),O7o=o("The model class to instantiate is selected based on the "),Wne=a("code"),X7o=o("model_type"),V7o=o(` property of the config object (either
passed as an argument or loaded from `),Qne=a("code"),z7o=o("pretrained_model_name_or_path"),W7o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hne=a("code"),Q7o=o("pretrained_model_name_or_path"),H7o=o(":"),U7o=l(),da=a("ul"),M1=a("li"),Une=a("strong"),J7o=o("bert"),Y7o=o(" \u2014 "),sD=a("a"),K7o=o("BertForNextSentencePrediction"),Z7o=o(" (BERT model)"),e8o=l(),E1=a("li"),Jne=a("strong"),o8o=o("fnet"),r8o=o(" \u2014 "),lD=a("a"),t8o=o("FNetForNextSentencePrediction"),a8o=o(" (FNet model)"),n8o=l(),y1=a("li"),Yne=a("strong"),s8o=o("megatron-bert"),l8o=o(" \u2014 "),iD=a("a"),i8o=o("MegatronBertForNextSentencePrediction"),d8o=o(" (MegatronBert model)"),c8o=l(),w1=a("li"),Kne=a("strong"),f8o=o("mobilebert"),m8o=o(" \u2014 "),dD=a("a"),g8o=o("MobileBertForNextSentencePrediction"),h8o=o(" (MobileBERT model)"),p8o=l(),A1=a("li"),Zne=a("strong"),_8o=o("qdqbert"),u8o=o(" \u2014 "),cD=a("a"),b8o=o("QDQBertForNextSentencePrediction"),v8o=o(" (QDQBert model)"),T8o=l(),L1=a("p"),F8o=o("The model is set in evaluation mode by default using "),ese=a("code"),C8o=o("model.eval()"),M8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ose=a("code"),E8o=o("model.train()"),y8o=l(),rse=a("p"),w8o=o("Examples:"),A8o=l(),f(Oy.$$.fragment),Nke=l(),Td=a("h2"),B1=a("a"),tse=a("span"),f(Xy.$$.fragment),L8o=l(),ase=a("span"),B8o=o("AutoModelForTokenClassification"),Dke=l(),ar=a("div"),f(Vy.$$.fragment),x8o=l(),Fd=a("p"),k8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),nse=a("code"),R8o=o("from_pretrained()"),S8o=o("class method or the "),sse=a("code"),P8o=o("from_config()"),$8o=o(`class
method.`),I8o=l(),zy=a("p"),N8o=o("This class cannot be instantiated directly using "),lse=a("code"),D8o=o("__init__()"),j8o=o(" (throws an error)."),q8o=l(),Kr=a("div"),f(Wy.$$.fragment),G8o=l(),ise=a("p"),O8o=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),X8o=l(),Cd=a("p"),V8o=o(`Note:
Loading a model from its configuration file does `),dse=a("strong"),z8o=o("not"),W8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cse=a("code"),Q8o=o("from_pretrained()"),H8o=o("to load the model weights."),U8o=l(),fse=a("p"),J8o=o("Examples:"),Y8o=l(),f(Qy.$$.fragment),K8o=l(),ze=a("div"),f(Hy.$$.fragment),Z8o=l(),mse=a("p"),e9o=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),o9o=l(),Ka=a("p"),r9o=o("The model class to instantiate is selected based on the "),gse=a("code"),t9o=o("model_type"),a9o=o(` property of the config object (either
passed as an argument or loaded from `),hse=a("code"),n9o=o("pretrained_model_name_or_path"),s9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pse=a("code"),l9o=o("pretrained_model_name_or_path"),i9o=o(":"),d9o=l(),j=a("ul"),x1=a("li"),_se=a("strong"),c9o=o("albert"),f9o=o(" \u2014 "),fD=a("a"),m9o=o("AlbertForTokenClassification"),g9o=o(" (ALBERT model)"),h9o=l(),k1=a("li"),use=a("strong"),p9o=o("bert"),_9o=o(" \u2014 "),mD=a("a"),u9o=o("BertForTokenClassification"),b9o=o(" (BERT model)"),v9o=l(),R1=a("li"),bse=a("strong"),T9o=o("big_bird"),F9o=o(" \u2014 "),gD=a("a"),C9o=o("BigBirdForTokenClassification"),M9o=o(" (BigBird model)"),E9o=l(),S1=a("li"),vse=a("strong"),y9o=o("camembert"),w9o=o(" \u2014 "),hD=a("a"),A9o=o("CamembertForTokenClassification"),L9o=o(" (CamemBERT model)"),B9o=l(),P1=a("li"),Tse=a("strong"),x9o=o("canine"),k9o=o(" \u2014 "),pD=a("a"),R9o=o("CanineForTokenClassification"),S9o=o(" (Canine model)"),P9o=l(),$1=a("li"),Fse=a("strong"),$9o=o("convbert"),I9o=o(" \u2014 "),_D=a("a"),N9o=o("ConvBertForTokenClassification"),D9o=o(" (ConvBERT model)"),j9o=l(),I1=a("li"),Cse=a("strong"),q9o=o("data2vec-text"),G9o=o(" \u2014 "),uD=a("a"),O9o=o("Data2VecTextForTokenClassification"),X9o=o(" (Data2VecText model)"),V9o=l(),N1=a("li"),Mse=a("strong"),z9o=o("deberta"),W9o=o(" \u2014 "),bD=a("a"),Q9o=o("DebertaForTokenClassification"),H9o=o(" (DeBERTa model)"),U9o=l(),D1=a("li"),Ese=a("strong"),J9o=o("deberta-v2"),Y9o=o(" \u2014 "),vD=a("a"),K9o=o("DebertaV2ForTokenClassification"),Z9o=o(" (DeBERTa-v2 model)"),eBo=l(),j1=a("li"),yse=a("strong"),oBo=o("distilbert"),rBo=o(" \u2014 "),TD=a("a"),tBo=o("DistilBertForTokenClassification"),aBo=o(" (DistilBERT model)"),nBo=l(),q1=a("li"),wse=a("strong"),sBo=o("electra"),lBo=o(" \u2014 "),FD=a("a"),iBo=o("ElectraForTokenClassification"),dBo=o(" (ELECTRA model)"),cBo=l(),G1=a("li"),Ase=a("strong"),fBo=o("flaubert"),mBo=o(" \u2014 "),CD=a("a"),gBo=o("FlaubertForTokenClassification"),hBo=o(" (FlauBERT model)"),pBo=l(),O1=a("li"),Lse=a("strong"),_Bo=o("fnet"),uBo=o(" \u2014 "),MD=a("a"),bBo=o("FNetForTokenClassification"),vBo=o(" (FNet model)"),TBo=l(),X1=a("li"),Bse=a("strong"),FBo=o("funnel"),CBo=o(" \u2014 "),ED=a("a"),MBo=o("FunnelForTokenClassification"),EBo=o(" (Funnel Transformer model)"),yBo=l(),V1=a("li"),xse=a("strong"),wBo=o("gpt2"),ABo=o(" \u2014 "),yD=a("a"),LBo=o("GPT2ForTokenClassification"),BBo=o(" (OpenAI GPT-2 model)"),xBo=l(),z1=a("li"),kse=a("strong"),kBo=o("ibert"),RBo=o(" \u2014 "),wD=a("a"),SBo=o("IBertForTokenClassification"),PBo=o(" (I-BERT model)"),$Bo=l(),W1=a("li"),Rse=a("strong"),IBo=o("layoutlm"),NBo=o(" \u2014 "),AD=a("a"),DBo=o("LayoutLMForTokenClassification"),jBo=o(" (LayoutLM model)"),qBo=l(),Q1=a("li"),Sse=a("strong"),GBo=o("layoutlmv2"),OBo=o(" \u2014 "),LD=a("a"),XBo=o("LayoutLMv2ForTokenClassification"),VBo=o(" (LayoutLMv2 model)"),zBo=l(),H1=a("li"),Pse=a("strong"),WBo=o("longformer"),QBo=o(" \u2014 "),BD=a("a"),HBo=o("LongformerForTokenClassification"),UBo=o(" (Longformer model)"),JBo=l(),U1=a("li"),$se=a("strong"),YBo=o("megatron-bert"),KBo=o(" \u2014 "),xD=a("a"),ZBo=o("MegatronBertForTokenClassification"),exo=o(" (MegatronBert model)"),oxo=l(),J1=a("li"),Ise=a("strong"),rxo=o("mobilebert"),txo=o(" \u2014 "),kD=a("a"),axo=o("MobileBertForTokenClassification"),nxo=o(" (MobileBERT model)"),sxo=l(),Y1=a("li"),Nse=a("strong"),lxo=o("mpnet"),ixo=o(" \u2014 "),RD=a("a"),dxo=o("MPNetForTokenClassification"),cxo=o(" (MPNet model)"),fxo=l(),K1=a("li"),Dse=a("strong"),mxo=o("nystromformer"),gxo=o(" \u2014 "),SD=a("a"),hxo=o("NystromformerForTokenClassification"),pxo=o(" (Nystromformer model)"),_xo=l(),Z1=a("li"),jse=a("strong"),uxo=o("qdqbert"),bxo=o(" \u2014 "),PD=a("a"),vxo=o("QDQBertForTokenClassification"),Txo=o(" (QDQBert model)"),Fxo=l(),eb=a("li"),qse=a("strong"),Cxo=o("rembert"),Mxo=o(" \u2014 "),$D=a("a"),Exo=o("RemBertForTokenClassification"),yxo=o(" (RemBERT model)"),wxo=l(),ob=a("li"),Gse=a("strong"),Axo=o("roberta"),Lxo=o(" \u2014 "),ID=a("a"),Bxo=o("RobertaForTokenClassification"),xxo=o(" (RoBERTa model)"),kxo=l(),rb=a("li"),Ose=a("strong"),Rxo=o("roformer"),Sxo=o(" \u2014 "),ND=a("a"),Pxo=o("RoFormerForTokenClassification"),$xo=o(" (RoFormer model)"),Ixo=l(),tb=a("li"),Xse=a("strong"),Nxo=o("squeezebert"),Dxo=o(" \u2014 "),DD=a("a"),jxo=o("SqueezeBertForTokenClassification"),qxo=o(" (SqueezeBERT model)"),Gxo=l(),ab=a("li"),Vse=a("strong"),Oxo=o("xlm"),Xxo=o(" \u2014 "),jD=a("a"),Vxo=o("XLMForTokenClassification"),zxo=o(" (XLM model)"),Wxo=l(),nb=a("li"),zse=a("strong"),Qxo=o("xlm-roberta"),Hxo=o(" \u2014 "),qD=a("a"),Uxo=o("XLMRobertaForTokenClassification"),Jxo=o(" (XLM-RoBERTa model)"),Yxo=l(),sb=a("li"),Wse=a("strong"),Kxo=o("xlm-roberta-xl"),Zxo=o(" \u2014 "),GD=a("a"),eko=o("XLMRobertaXLForTokenClassification"),oko=o(" (XLM-RoBERTa-XL model)"),rko=l(),lb=a("li"),Qse=a("strong"),tko=o("xlnet"),ako=o(" \u2014 "),OD=a("a"),nko=o("XLNetForTokenClassification"),sko=o(" (XLNet model)"),lko=l(),ib=a("li"),Hse=a("strong"),iko=o("yoso"),dko=o(" \u2014 "),XD=a("a"),cko=o("YosoForTokenClassification"),fko=o(" (YOSO model)"),mko=l(),db=a("p"),gko=o("The model is set in evaluation mode by default using "),Use=a("code"),hko=o("model.eval()"),pko=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jse=a("code"),_ko=o("model.train()"),uko=l(),Yse=a("p"),bko=o("Examples:"),vko=l(),f(Uy.$$.fragment),jke=l(),Md=a("h2"),cb=a("a"),Kse=a("span"),f(Jy.$$.fragment),Tko=l(),Zse=a("span"),Fko=o("AutoModelForQuestionAnswering"),qke=l(),nr=a("div"),f(Yy.$$.fragment),Cko=l(),Ed=a("p"),Mko=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ele=a("code"),Eko=o("from_pretrained()"),yko=o("class method or the "),ole=a("code"),wko=o("from_config()"),Ako=o(`class
method.`),Lko=l(),Ky=a("p"),Bko=o("This class cannot be instantiated directly using "),rle=a("code"),xko=o("__init__()"),kko=o(" (throws an error)."),Rko=l(),Zr=a("div"),f(Zy.$$.fragment),Sko=l(),tle=a("p"),Pko=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),$ko=l(),yd=a("p"),Iko=o(`Note:
Loading a model from its configuration file does `),ale=a("strong"),Nko=o("not"),Dko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nle=a("code"),jko=o("from_pretrained()"),qko=o("to load the model weights."),Gko=l(),sle=a("p"),Oko=o("Examples:"),Xko=l(),f(ew.$$.fragment),Vko=l(),We=a("div"),f(ow.$$.fragment),zko=l(),lle=a("p"),Wko=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Qko=l(),Za=a("p"),Hko=o("The model class to instantiate is selected based on the "),ile=a("code"),Uko=o("model_type"),Jko=o(` property of the config object (either
passed as an argument or loaded from `),dle=a("code"),Yko=o("pretrained_model_name_or_path"),Kko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cle=a("code"),Zko=o("pretrained_model_name_or_path"),eRo=o(":"),oRo=l(),R=a("ul"),fb=a("li"),fle=a("strong"),rRo=o("albert"),tRo=o(" \u2014 "),VD=a("a"),aRo=o("AlbertForQuestionAnswering"),nRo=o(" (ALBERT model)"),sRo=l(),mb=a("li"),mle=a("strong"),lRo=o("bart"),iRo=o(" \u2014 "),zD=a("a"),dRo=o("BartForQuestionAnswering"),cRo=o(" (BART model)"),fRo=l(),gb=a("li"),gle=a("strong"),mRo=o("bert"),gRo=o(" \u2014 "),WD=a("a"),hRo=o("BertForQuestionAnswering"),pRo=o(" (BERT model)"),_Ro=l(),hb=a("li"),hle=a("strong"),uRo=o("big_bird"),bRo=o(" \u2014 "),QD=a("a"),vRo=o("BigBirdForQuestionAnswering"),TRo=o(" (BigBird model)"),FRo=l(),pb=a("li"),ple=a("strong"),CRo=o("bigbird_pegasus"),MRo=o(" \u2014 "),HD=a("a"),ERo=o("BigBirdPegasusForQuestionAnswering"),yRo=o(" (BigBirdPegasus model)"),wRo=l(),_b=a("li"),_le=a("strong"),ARo=o("camembert"),LRo=o(" \u2014 "),UD=a("a"),BRo=o("CamembertForQuestionAnswering"),xRo=o(" (CamemBERT model)"),kRo=l(),ub=a("li"),ule=a("strong"),RRo=o("canine"),SRo=o(" \u2014 "),JD=a("a"),PRo=o("CanineForQuestionAnswering"),$Ro=o(" (Canine model)"),IRo=l(),bb=a("li"),ble=a("strong"),NRo=o("convbert"),DRo=o(" \u2014 "),YD=a("a"),jRo=o("ConvBertForQuestionAnswering"),qRo=o(" (ConvBERT model)"),GRo=l(),vb=a("li"),vle=a("strong"),ORo=o("data2vec-text"),XRo=o(" \u2014 "),KD=a("a"),VRo=o("Data2VecTextForQuestionAnswering"),zRo=o(" (Data2VecText model)"),WRo=l(),Tb=a("li"),Tle=a("strong"),QRo=o("deberta"),HRo=o(" \u2014 "),ZD=a("a"),URo=o("DebertaForQuestionAnswering"),JRo=o(" (DeBERTa model)"),YRo=l(),Fb=a("li"),Fle=a("strong"),KRo=o("deberta-v2"),ZRo=o(" \u2014 "),ej=a("a"),eSo=o("DebertaV2ForQuestionAnswering"),oSo=o(" (DeBERTa-v2 model)"),rSo=l(),Cb=a("li"),Cle=a("strong"),tSo=o("distilbert"),aSo=o(" \u2014 "),oj=a("a"),nSo=o("DistilBertForQuestionAnswering"),sSo=o(" (DistilBERT model)"),lSo=l(),Mb=a("li"),Mle=a("strong"),iSo=o("electra"),dSo=o(" \u2014 "),rj=a("a"),cSo=o("ElectraForQuestionAnswering"),fSo=o(" (ELECTRA model)"),mSo=l(),Eb=a("li"),Ele=a("strong"),gSo=o("flaubert"),hSo=o(" \u2014 "),tj=a("a"),pSo=o("FlaubertForQuestionAnsweringSimple"),_So=o(" (FlauBERT model)"),uSo=l(),yb=a("li"),yle=a("strong"),bSo=o("fnet"),vSo=o(" \u2014 "),aj=a("a"),TSo=o("FNetForQuestionAnswering"),FSo=o(" (FNet model)"),CSo=l(),wb=a("li"),wle=a("strong"),MSo=o("funnel"),ESo=o(" \u2014 "),nj=a("a"),ySo=o("FunnelForQuestionAnswering"),wSo=o(" (Funnel Transformer model)"),ASo=l(),Ab=a("li"),Ale=a("strong"),LSo=o("gptj"),BSo=o(" \u2014 "),sj=a("a"),xSo=o("GPTJForQuestionAnswering"),kSo=o(" (GPT-J model)"),RSo=l(),Lb=a("li"),Lle=a("strong"),SSo=o("ibert"),PSo=o(" \u2014 "),lj=a("a"),$So=o("IBertForQuestionAnswering"),ISo=o(" (I-BERT model)"),NSo=l(),Bb=a("li"),Ble=a("strong"),DSo=o("layoutlmv2"),jSo=o(" \u2014 "),ij=a("a"),qSo=o("LayoutLMv2ForQuestionAnswering"),GSo=o(" (LayoutLMv2 model)"),OSo=l(),xb=a("li"),xle=a("strong"),XSo=o("led"),VSo=o(" \u2014 "),dj=a("a"),zSo=o("LEDForQuestionAnswering"),WSo=o(" (LED model)"),QSo=l(),kb=a("li"),kle=a("strong"),HSo=o("longformer"),USo=o(" \u2014 "),cj=a("a"),JSo=o("LongformerForQuestionAnswering"),YSo=o(" (Longformer model)"),KSo=l(),Rb=a("li"),Rle=a("strong"),ZSo=o("lxmert"),ePo=o(" \u2014 "),fj=a("a"),oPo=o("LxmertForQuestionAnswering"),rPo=o(" (LXMERT model)"),tPo=l(),Sb=a("li"),Sle=a("strong"),aPo=o("mbart"),nPo=o(" \u2014 "),mj=a("a"),sPo=o("MBartForQuestionAnswering"),lPo=o(" (mBART model)"),iPo=l(),Pb=a("li"),Ple=a("strong"),dPo=o("megatron-bert"),cPo=o(" \u2014 "),gj=a("a"),fPo=o("MegatronBertForQuestionAnswering"),mPo=o(" (MegatronBert model)"),gPo=l(),$b=a("li"),$le=a("strong"),hPo=o("mobilebert"),pPo=o(" \u2014 "),hj=a("a"),_Po=o("MobileBertForQuestionAnswering"),uPo=o(" (MobileBERT model)"),bPo=l(),Ib=a("li"),Ile=a("strong"),vPo=o("mpnet"),TPo=o(" \u2014 "),pj=a("a"),FPo=o("MPNetForQuestionAnswering"),CPo=o(" (MPNet model)"),MPo=l(),Nb=a("li"),Nle=a("strong"),EPo=o("nystromformer"),yPo=o(" \u2014 "),_j=a("a"),wPo=o("NystromformerForQuestionAnswering"),APo=o(" (Nystromformer model)"),LPo=l(),Db=a("li"),Dle=a("strong"),BPo=o("qdqbert"),xPo=o(" \u2014 "),uj=a("a"),kPo=o("QDQBertForQuestionAnswering"),RPo=o(" (QDQBert model)"),SPo=l(),jb=a("li"),jle=a("strong"),PPo=o("reformer"),$Po=o(" \u2014 "),bj=a("a"),IPo=o("ReformerForQuestionAnswering"),NPo=o(" (Reformer model)"),DPo=l(),qb=a("li"),qle=a("strong"),jPo=o("rembert"),qPo=o(" \u2014 "),vj=a("a"),GPo=o("RemBertForQuestionAnswering"),OPo=o(" (RemBERT model)"),XPo=l(),Gb=a("li"),Gle=a("strong"),VPo=o("roberta"),zPo=o(" \u2014 "),Tj=a("a"),WPo=o("RobertaForQuestionAnswering"),QPo=o(" (RoBERTa model)"),HPo=l(),Ob=a("li"),Ole=a("strong"),UPo=o("roformer"),JPo=o(" \u2014 "),Fj=a("a"),YPo=o("RoFormerForQuestionAnswering"),KPo=o(" (RoFormer model)"),ZPo=l(),Xb=a("li"),Xle=a("strong"),e$o=o("splinter"),o$o=o(" \u2014 "),Cj=a("a"),r$o=o("SplinterForQuestionAnswering"),t$o=o(" (Splinter model)"),a$o=l(),Vb=a("li"),Vle=a("strong"),n$o=o("squeezebert"),s$o=o(" \u2014 "),Mj=a("a"),l$o=o("SqueezeBertForQuestionAnswering"),i$o=o(" (SqueezeBERT model)"),d$o=l(),zb=a("li"),zle=a("strong"),c$o=o("xlm"),f$o=o(" \u2014 "),Ej=a("a"),m$o=o("XLMForQuestionAnsweringSimple"),g$o=o(" (XLM model)"),h$o=l(),Wb=a("li"),Wle=a("strong"),p$o=o("xlm-roberta"),_$o=o(" \u2014 "),yj=a("a"),u$o=o("XLMRobertaForQuestionAnswering"),b$o=o(" (XLM-RoBERTa model)"),v$o=l(),Qb=a("li"),Qle=a("strong"),T$o=o("xlm-roberta-xl"),F$o=o(" \u2014 "),wj=a("a"),C$o=o("XLMRobertaXLForQuestionAnswering"),M$o=o(" (XLM-RoBERTa-XL model)"),E$o=l(),Hb=a("li"),Hle=a("strong"),y$o=o("xlnet"),w$o=o(" \u2014 "),Aj=a("a"),A$o=o("XLNetForQuestionAnsweringSimple"),L$o=o(" (XLNet model)"),B$o=l(),Ub=a("li"),Ule=a("strong"),x$o=o("yoso"),k$o=o(" \u2014 "),Lj=a("a"),R$o=o("YosoForQuestionAnswering"),S$o=o(" (YOSO model)"),P$o=l(),Jb=a("p"),$$o=o("The model is set in evaluation mode by default using "),Jle=a("code"),I$o=o("model.eval()"),N$o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yle=a("code"),D$o=o("model.train()"),j$o=l(),Kle=a("p"),q$o=o("Examples:"),G$o=l(),f(rw.$$.fragment),Gke=l(),wd=a("h2"),Yb=a("a"),Zle=a("span"),f(tw.$$.fragment),O$o=l(),eie=a("span"),X$o=o("AutoModelForTableQuestionAnswering"),Oke=l(),sr=a("div"),f(aw.$$.fragment),V$o=l(),Ad=a("p"),z$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),oie=a("code"),W$o=o("from_pretrained()"),Q$o=o("class method or the "),rie=a("code"),H$o=o("from_config()"),U$o=o(`class
method.`),J$o=l(),nw=a("p"),Y$o=o("This class cannot be instantiated directly using "),tie=a("code"),K$o=o("__init__()"),Z$o=o(" (throws an error)."),eIo=l(),et=a("div"),f(sw.$$.fragment),oIo=l(),aie=a("p"),rIo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),tIo=l(),Ld=a("p"),aIo=o(`Note:
Loading a model from its configuration file does `),nie=a("strong"),nIo=o("not"),sIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=a("code"),lIo=o("from_pretrained()"),iIo=o("to load the model weights."),dIo=l(),lie=a("p"),cIo=o("Examples:"),fIo=l(),f(lw.$$.fragment),mIo=l(),Qe=a("div"),f(iw.$$.fragment),gIo=l(),iie=a("p"),hIo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),pIo=l(),en=a("p"),_Io=o("The model class to instantiate is selected based on the "),die=a("code"),uIo=o("model_type"),bIo=o(` property of the config object (either
passed as an argument or loaded from `),cie=a("code"),vIo=o("pretrained_model_name_or_path"),TIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fie=a("code"),FIo=o("pretrained_model_name_or_path"),CIo=o(":"),MIo=l(),mie=a("ul"),Kb=a("li"),gie=a("strong"),EIo=o("tapas"),yIo=o(" \u2014 "),Bj=a("a"),wIo=o("TapasForQuestionAnswering"),AIo=o(" (TAPAS model)"),LIo=l(),Zb=a("p"),BIo=o("The model is set in evaluation mode by default using "),hie=a("code"),xIo=o("model.eval()"),kIo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pie=a("code"),RIo=o("model.train()"),SIo=l(),_ie=a("p"),PIo=o("Examples:"),$Io=l(),f(dw.$$.fragment),Xke=l(),Bd=a("h2"),ev=a("a"),uie=a("span"),f(cw.$$.fragment),IIo=l(),bie=a("span"),NIo=o("AutoModelForImageClassification"),Vke=l(),lr=a("div"),f(fw.$$.fragment),DIo=l(),xd=a("p"),jIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),vie=a("code"),qIo=o("from_pretrained()"),GIo=o("class method or the "),Tie=a("code"),OIo=o("from_config()"),XIo=o(`class
method.`),VIo=l(),mw=a("p"),zIo=o("This class cannot be instantiated directly using "),Fie=a("code"),WIo=o("__init__()"),QIo=o(" (throws an error)."),HIo=l(),ot=a("div"),f(gw.$$.fragment),UIo=l(),Cie=a("p"),JIo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),YIo=l(),kd=a("p"),KIo=o(`Note:
Loading a model from its configuration file does `),Mie=a("strong"),ZIo=o("not"),eNo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eie=a("code"),oNo=o("from_pretrained()"),rNo=o("to load the model weights."),tNo=l(),yie=a("p"),aNo=o("Examples:"),nNo=l(),f(hw.$$.fragment),sNo=l(),He=a("div"),f(pw.$$.fragment),lNo=l(),wie=a("p"),iNo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dNo=l(),on=a("p"),cNo=o("The model class to instantiate is selected based on the "),Aie=a("code"),fNo=o("model_type"),mNo=o(` property of the config object (either
passed as an argument or loaded from `),Lie=a("code"),gNo=o("pretrained_model_name_or_path"),hNo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bie=a("code"),pNo=o("pretrained_model_name_or_path"),_No=o(":"),uNo=l(),me=a("ul"),ov=a("li"),xie=a("strong"),bNo=o("beit"),vNo=o(" \u2014 "),xj=a("a"),TNo=o("BeitForImageClassification"),FNo=o(" (BEiT model)"),CNo=l(),rv=a("li"),kie=a("strong"),MNo=o("convnext"),ENo=o(" \u2014 "),kj=a("a"),yNo=o("ConvNextForImageClassification"),wNo=o(" (ConvNext model)"),ANo=l(),qs=a("li"),Rie=a("strong"),LNo=o("deit"),BNo=o(" \u2014 "),Rj=a("a"),xNo=o("DeiTForImageClassification"),kNo=o(" or "),Sj=a("a"),RNo=o("DeiTForImageClassificationWithTeacher"),SNo=o(" (DeiT model)"),PNo=l(),tv=a("li"),Sie=a("strong"),$No=o("imagegpt"),INo=o(" \u2014 "),Pj=a("a"),NNo=o("ImageGPTForImageClassification"),DNo=o(" (ImageGPT model)"),jNo=l(),ma=a("li"),Pie=a("strong"),qNo=o("perceiver"),GNo=o(" \u2014 "),$j=a("a"),ONo=o("PerceiverForImageClassificationLearned"),XNo=o(" or "),Ij=a("a"),VNo=o("PerceiverForImageClassificationFourier"),zNo=o(" or "),Nj=a("a"),WNo=o("PerceiverForImageClassificationConvProcessing"),QNo=o(" (Perceiver model)"),HNo=l(),av=a("li"),$ie=a("strong"),UNo=o("poolformer"),JNo=o(" \u2014 "),Dj=a("a"),YNo=o("PoolFormerForImageClassification"),KNo=o(" (PoolFormer model)"),ZNo=l(),nv=a("li"),Iie=a("strong"),eDo=o("resnet"),oDo=o(" \u2014 "),jj=a("a"),rDo=o("ResNetForImageClassification"),tDo=o(" (ResNet model)"),aDo=l(),sv=a("li"),Nie=a("strong"),nDo=o("segformer"),sDo=o(" \u2014 "),qj=a("a"),lDo=o("SegformerForImageClassification"),iDo=o(" (SegFormer model)"),dDo=l(),lv=a("li"),Die=a("strong"),cDo=o("swin"),fDo=o(" \u2014 "),Gj=a("a"),mDo=o("SwinForImageClassification"),gDo=o(" (Swin model)"),hDo=l(),iv=a("li"),jie=a("strong"),pDo=o("van"),_Do=o(" \u2014 "),Oj=a("a"),uDo=o("VanForImageClassification"),bDo=o(" (VAN model)"),vDo=l(),dv=a("li"),qie=a("strong"),TDo=o("vit"),FDo=o(" \u2014 "),Xj=a("a"),CDo=o("ViTForImageClassification"),MDo=o(" (ViT model)"),EDo=l(),cv=a("p"),yDo=o("The model is set in evaluation mode by default using "),Gie=a("code"),wDo=o("model.eval()"),ADo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oie=a("code"),LDo=o("model.train()"),BDo=l(),Xie=a("p"),xDo=o("Examples:"),kDo=l(),f(_w.$$.fragment),zke=l(),Rd=a("h2"),fv=a("a"),Vie=a("span"),f(uw.$$.fragment),RDo=l(),zie=a("span"),SDo=o("AutoModelForVision2Seq"),Wke=l(),ir=a("div"),f(bw.$$.fragment),PDo=l(),Sd=a("p"),$Do=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wie=a("code"),IDo=o("from_pretrained()"),NDo=o("class method or the "),Qie=a("code"),DDo=o("from_config()"),jDo=o(`class
method.`),qDo=l(),vw=a("p"),GDo=o("This class cannot be instantiated directly using "),Hie=a("code"),ODo=o("__init__()"),XDo=o(" (throws an error)."),VDo=l(),rt=a("div"),f(Tw.$$.fragment),zDo=l(),Uie=a("p"),WDo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),QDo=l(),Pd=a("p"),HDo=o(`Note:
Loading a model from its configuration file does `),Jie=a("strong"),UDo=o("not"),JDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yie=a("code"),YDo=o("from_pretrained()"),KDo=o("to load the model weights."),ZDo=l(),Kie=a("p"),ejo=o("Examples:"),ojo=l(),f(Fw.$$.fragment),rjo=l(),Ue=a("div"),f(Cw.$$.fragment),tjo=l(),Zie=a("p"),ajo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),njo=l(),rn=a("p"),sjo=o("The model class to instantiate is selected based on the "),ede=a("code"),ljo=o("model_type"),ijo=o(` property of the config object (either
passed as an argument or loaded from `),ode=a("code"),djo=o("pretrained_model_name_or_path"),cjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rde=a("code"),fjo=o("pretrained_model_name_or_path"),mjo=o(":"),gjo=l(),tde=a("ul"),mv=a("li"),ade=a("strong"),hjo=o("vision-encoder-decoder"),pjo=o(" \u2014 "),Vj=a("a"),_jo=o("VisionEncoderDecoderModel"),ujo=o(" (Vision Encoder decoder model)"),bjo=l(),gv=a("p"),vjo=o("The model is set in evaluation mode by default using "),nde=a("code"),Tjo=o("model.eval()"),Fjo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sde=a("code"),Cjo=o("model.train()"),Mjo=l(),lde=a("p"),Ejo=o("Examples:"),yjo=l(),f(Mw.$$.fragment),Qke=l(),$d=a("h2"),hv=a("a"),ide=a("span"),f(Ew.$$.fragment),wjo=l(),dde=a("span"),Ajo=o("AutoModelForAudioClassification"),Hke=l(),dr=a("div"),f(yw.$$.fragment),Ljo=l(),Id=a("p"),Bjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),cde=a("code"),xjo=o("from_pretrained()"),kjo=o("class method or the "),fde=a("code"),Rjo=o("from_config()"),Sjo=o(`class
method.`),Pjo=l(),ww=a("p"),$jo=o("This class cannot be instantiated directly using "),mde=a("code"),Ijo=o("__init__()"),Njo=o(" (throws an error)."),Djo=l(),tt=a("div"),f(Aw.$$.fragment),jjo=l(),gde=a("p"),qjo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Gjo=l(),Nd=a("p"),Ojo=o(`Note:
Loading a model from its configuration file does `),hde=a("strong"),Xjo=o("not"),Vjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pde=a("code"),zjo=o("from_pretrained()"),Wjo=o("to load the model weights."),Qjo=l(),_de=a("p"),Hjo=o("Examples:"),Ujo=l(),f(Lw.$$.fragment),Jjo=l(),Je=a("div"),f(Bw.$$.fragment),Yjo=l(),ude=a("p"),Kjo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Zjo=l(),tn=a("p"),eqo=o("The model class to instantiate is selected based on the "),bde=a("code"),oqo=o("model_type"),rqo=o(` property of the config object (either
passed as an argument or loaded from `),vde=a("code"),tqo=o("pretrained_model_name_or_path"),aqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tde=a("code"),nqo=o("pretrained_model_name_or_path"),sqo=o(":"),lqo=l(),ke=a("ul"),pv=a("li"),Fde=a("strong"),iqo=o("data2vec-audio"),dqo=o(" \u2014 "),zj=a("a"),cqo=o("Data2VecAudioForSequenceClassification"),fqo=o(" (Data2VecAudio model)"),mqo=l(),_v=a("li"),Cde=a("strong"),gqo=o("hubert"),hqo=o(" \u2014 "),Wj=a("a"),pqo=o("HubertForSequenceClassification"),_qo=o(" (Hubert model)"),uqo=l(),uv=a("li"),Mde=a("strong"),bqo=o("sew"),vqo=o(" \u2014 "),Qj=a("a"),Tqo=o("SEWForSequenceClassification"),Fqo=o(" (SEW model)"),Cqo=l(),bv=a("li"),Ede=a("strong"),Mqo=o("sew-d"),Eqo=o(" \u2014 "),Hj=a("a"),yqo=o("SEWDForSequenceClassification"),wqo=o(" (SEW-D model)"),Aqo=l(),vv=a("li"),yde=a("strong"),Lqo=o("unispeech"),Bqo=o(" \u2014 "),Uj=a("a"),xqo=o("UniSpeechForSequenceClassification"),kqo=o(" (UniSpeech model)"),Rqo=l(),Tv=a("li"),wde=a("strong"),Sqo=o("unispeech-sat"),Pqo=o(" \u2014 "),Jj=a("a"),$qo=o("UniSpeechSatForSequenceClassification"),Iqo=o(" (UniSpeechSat model)"),Nqo=l(),Fv=a("li"),Ade=a("strong"),Dqo=o("wav2vec2"),jqo=o(" \u2014 "),Yj=a("a"),qqo=o("Wav2Vec2ForSequenceClassification"),Gqo=o(" (Wav2Vec2 model)"),Oqo=l(),Cv=a("li"),Lde=a("strong"),Xqo=o("wavlm"),Vqo=o(" \u2014 "),Kj=a("a"),zqo=o("WavLMForSequenceClassification"),Wqo=o(" (WavLM model)"),Qqo=l(),Mv=a("p"),Hqo=o("The model is set in evaluation mode by default using "),Bde=a("code"),Uqo=o("model.eval()"),Jqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xde=a("code"),Yqo=o("model.train()"),Kqo=l(),kde=a("p"),Zqo=o("Examples:"),eGo=l(),f(xw.$$.fragment),Uke=l(),Dd=a("h2"),Ev=a("a"),Rde=a("span"),f(kw.$$.fragment),oGo=l(),Sde=a("span"),rGo=o("AutoModelForAudioFrameClassification"),Jke=l(),cr=a("div"),f(Rw.$$.fragment),tGo=l(),jd=a("p"),aGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Pde=a("code"),nGo=o("from_pretrained()"),sGo=o("class method or the "),$de=a("code"),lGo=o("from_config()"),iGo=o(`class
method.`),dGo=l(),Sw=a("p"),cGo=o("This class cannot be instantiated directly using "),Ide=a("code"),fGo=o("__init__()"),mGo=o(" (throws an error)."),gGo=l(),at=a("div"),f(Pw.$$.fragment),hGo=l(),Nde=a("p"),pGo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),_Go=l(),qd=a("p"),uGo=o(`Note:
Loading a model from its configuration file does `),Dde=a("strong"),bGo=o("not"),vGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jde=a("code"),TGo=o("from_pretrained()"),FGo=o("to load the model weights."),CGo=l(),qde=a("p"),MGo=o("Examples:"),EGo=l(),f($w.$$.fragment),yGo=l(),Ye=a("div"),f(Iw.$$.fragment),wGo=l(),Gde=a("p"),AGo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),LGo=l(),an=a("p"),BGo=o("The model class to instantiate is selected based on the "),Ode=a("code"),xGo=o("model_type"),kGo=o(` property of the config object (either
passed as an argument or loaded from `),Xde=a("code"),RGo=o("pretrained_model_name_or_path"),SGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vde=a("code"),PGo=o("pretrained_model_name_or_path"),$Go=o(":"),IGo=l(),nn=a("ul"),yv=a("li"),zde=a("strong"),NGo=o("data2vec-audio"),DGo=o(" \u2014 "),Zj=a("a"),jGo=o("Data2VecAudioForAudioFrameClassification"),qGo=o(" (Data2VecAudio model)"),GGo=l(),wv=a("li"),Wde=a("strong"),OGo=o("unispeech-sat"),XGo=o(" \u2014 "),eq=a("a"),VGo=o("UniSpeechSatForAudioFrameClassification"),zGo=o(" (UniSpeechSat model)"),WGo=l(),Av=a("li"),Qde=a("strong"),QGo=o("wav2vec2"),HGo=o(" \u2014 "),oq=a("a"),UGo=o("Wav2Vec2ForAudioFrameClassification"),JGo=o(" (Wav2Vec2 model)"),YGo=l(),Lv=a("li"),Hde=a("strong"),KGo=o("wavlm"),ZGo=o(" \u2014 "),rq=a("a"),eOo=o("WavLMForAudioFrameClassification"),oOo=o(" (WavLM model)"),rOo=l(),Bv=a("p"),tOo=o("The model is set in evaluation mode by default using "),Ude=a("code"),aOo=o("model.eval()"),nOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jde=a("code"),sOo=o("model.train()"),lOo=l(),Yde=a("p"),iOo=o("Examples:"),dOo=l(),f(Nw.$$.fragment),Yke=l(),Gd=a("h2"),xv=a("a"),Kde=a("span"),f(Dw.$$.fragment),cOo=l(),Zde=a("span"),fOo=o("AutoModelForCTC"),Kke=l(),fr=a("div"),f(jw.$$.fragment),mOo=l(),Od=a("p"),gOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),ece=a("code"),hOo=o("from_pretrained()"),pOo=o("class method or the "),oce=a("code"),_Oo=o("from_config()"),uOo=o(`class
method.`),bOo=l(),qw=a("p"),vOo=o("This class cannot be instantiated directly using "),rce=a("code"),TOo=o("__init__()"),FOo=o(" (throws an error)."),COo=l(),nt=a("div"),f(Gw.$$.fragment),MOo=l(),tce=a("p"),EOo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),yOo=l(),Xd=a("p"),wOo=o(`Note:
Loading a model from its configuration file does `),ace=a("strong"),AOo=o("not"),LOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nce=a("code"),BOo=o("from_pretrained()"),xOo=o("to load the model weights."),kOo=l(),sce=a("p"),ROo=o("Examples:"),SOo=l(),f(Ow.$$.fragment),POo=l(),Ke=a("div"),f(Xw.$$.fragment),$Oo=l(),lce=a("p"),IOo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),NOo=l(),sn=a("p"),DOo=o("The model class to instantiate is selected based on the "),ice=a("code"),jOo=o("model_type"),qOo=o(` property of the config object (either
passed as an argument or loaded from `),dce=a("code"),GOo=o("pretrained_model_name_or_path"),OOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cce=a("code"),XOo=o("pretrained_model_name_or_path"),VOo=o(":"),zOo=l(),Re=a("ul"),kv=a("li"),fce=a("strong"),WOo=o("data2vec-audio"),QOo=o(" \u2014 "),tq=a("a"),HOo=o("Data2VecAudioForCTC"),UOo=o(" (Data2VecAudio model)"),JOo=l(),Rv=a("li"),mce=a("strong"),YOo=o("hubert"),KOo=o(" \u2014 "),aq=a("a"),ZOo=o("HubertForCTC"),eXo=o(" (Hubert model)"),oXo=l(),Sv=a("li"),gce=a("strong"),rXo=o("sew"),tXo=o(" \u2014 "),nq=a("a"),aXo=o("SEWForCTC"),nXo=o(" (SEW model)"),sXo=l(),Pv=a("li"),hce=a("strong"),lXo=o("sew-d"),iXo=o(" \u2014 "),sq=a("a"),dXo=o("SEWDForCTC"),cXo=o(" (SEW-D model)"),fXo=l(),$v=a("li"),pce=a("strong"),mXo=o("unispeech"),gXo=o(" \u2014 "),lq=a("a"),hXo=o("UniSpeechForCTC"),pXo=o(" (UniSpeech model)"),_Xo=l(),Iv=a("li"),_ce=a("strong"),uXo=o("unispeech-sat"),bXo=o(" \u2014 "),iq=a("a"),vXo=o("UniSpeechSatForCTC"),TXo=o(" (UniSpeechSat model)"),FXo=l(),Nv=a("li"),uce=a("strong"),CXo=o("wav2vec2"),MXo=o(" \u2014 "),dq=a("a"),EXo=o("Wav2Vec2ForCTC"),yXo=o(" (Wav2Vec2 model)"),wXo=l(),Dv=a("li"),bce=a("strong"),AXo=o("wavlm"),LXo=o(" \u2014 "),cq=a("a"),BXo=o("WavLMForCTC"),xXo=o(" (WavLM model)"),kXo=l(),jv=a("p"),RXo=o("The model is set in evaluation mode by default using "),vce=a("code"),SXo=o("model.eval()"),PXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tce=a("code"),$Xo=o("model.train()"),IXo=l(),Fce=a("p"),NXo=o("Examples:"),DXo=l(),f(Vw.$$.fragment),Zke=l(),Vd=a("h2"),qv=a("a"),Cce=a("span"),f(zw.$$.fragment),jXo=l(),Mce=a("span"),qXo=o("AutoModelForSpeechSeq2Seq"),eRe=l(),mr=a("div"),f(Ww.$$.fragment),GXo=l(),zd=a("p"),OXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Ece=a("code"),XXo=o("from_pretrained()"),VXo=o("class method or the "),yce=a("code"),zXo=o("from_config()"),WXo=o(`class
method.`),QXo=l(),Qw=a("p"),HXo=o("This class cannot be instantiated directly using "),wce=a("code"),UXo=o("__init__()"),JXo=o(" (throws an error)."),YXo=l(),st=a("div"),f(Hw.$$.fragment),KXo=l(),Ace=a("p"),ZXo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),eVo=l(),Wd=a("p"),oVo=o(`Note:
Loading a model from its configuration file does `),Lce=a("strong"),rVo=o("not"),tVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bce=a("code"),aVo=o("from_pretrained()"),nVo=o("to load the model weights."),sVo=l(),xce=a("p"),lVo=o("Examples:"),iVo=l(),f(Uw.$$.fragment),dVo=l(),Ze=a("div"),f(Jw.$$.fragment),cVo=l(),kce=a("p"),fVo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),mVo=l(),ln=a("p"),gVo=o("The model class to instantiate is selected based on the "),Rce=a("code"),hVo=o("model_type"),pVo=o(` property of the config object (either
passed as an argument or loaded from `),Sce=a("code"),_Vo=o("pretrained_model_name_or_path"),uVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pce=a("code"),bVo=o("pretrained_model_name_or_path"),vVo=o(":"),TVo=l(),Yw=a("ul"),Gv=a("li"),$ce=a("strong"),FVo=o("speech-encoder-decoder"),CVo=o(" \u2014 "),fq=a("a"),MVo=o("SpeechEncoderDecoderModel"),EVo=o(" (Speech Encoder decoder model)"),yVo=l(),Ov=a("li"),Ice=a("strong"),wVo=o("speech_to_text"),AVo=o(" \u2014 "),mq=a("a"),LVo=o("Speech2TextForConditionalGeneration"),BVo=o(" (Speech2Text model)"),xVo=l(),Xv=a("p"),kVo=o("The model is set in evaluation mode by default using "),Nce=a("code"),RVo=o("model.eval()"),SVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dce=a("code"),PVo=o("model.train()"),$Vo=l(),jce=a("p"),IVo=o("Examples:"),NVo=l(),f(Kw.$$.fragment),oRe=l(),Qd=a("h2"),Vv=a("a"),qce=a("span"),f(Zw.$$.fragment),DVo=l(),Gce=a("span"),jVo=o("AutoModelForAudioXVector"),rRe=l(),gr=a("div"),f(eA.$$.fragment),qVo=l(),Hd=a("p"),GVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Oce=a("code"),OVo=o("from_pretrained()"),XVo=o("class method or the "),Xce=a("code"),VVo=o("from_config()"),zVo=o(`class
method.`),WVo=l(),oA=a("p"),QVo=o("This class cannot be instantiated directly using "),Vce=a("code"),HVo=o("__init__()"),UVo=o(" (throws an error)."),JVo=l(),lt=a("div"),f(rA.$$.fragment),YVo=l(),zce=a("p"),KVo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),ZVo=l(),Ud=a("p"),ezo=o(`Note:
Loading a model from its configuration file does `),Wce=a("strong"),ozo=o("not"),rzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qce=a("code"),tzo=o("from_pretrained()"),azo=o("to load the model weights."),nzo=l(),Hce=a("p"),szo=o("Examples:"),lzo=l(),f(tA.$$.fragment),izo=l(),eo=a("div"),f(aA.$$.fragment),dzo=l(),Uce=a("p"),czo=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),fzo=l(),dn=a("p"),mzo=o("The model class to instantiate is selected based on the "),Jce=a("code"),gzo=o("model_type"),hzo=o(` property of the config object (either
passed as an argument or loaded from `),Yce=a("code"),pzo=o("pretrained_model_name_or_path"),_zo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kce=a("code"),uzo=o("pretrained_model_name_or_path"),bzo=o(":"),vzo=l(),cn=a("ul"),zv=a("li"),Zce=a("strong"),Tzo=o("data2vec-audio"),Fzo=o(" \u2014 "),gq=a("a"),Czo=o("Data2VecAudioForXVector"),Mzo=o(" (Data2VecAudio model)"),Ezo=l(),Wv=a("li"),efe=a("strong"),yzo=o("unispeech-sat"),wzo=o(" \u2014 "),hq=a("a"),Azo=o("UniSpeechSatForXVector"),Lzo=o(" (UniSpeechSat model)"),Bzo=l(),Qv=a("li"),ofe=a("strong"),xzo=o("wav2vec2"),kzo=o(" \u2014 "),pq=a("a"),Rzo=o("Wav2Vec2ForXVector"),Szo=o(" (Wav2Vec2 model)"),Pzo=l(),Hv=a("li"),rfe=a("strong"),$zo=o("wavlm"),Izo=o(" \u2014 "),_q=a("a"),Nzo=o("WavLMForXVector"),Dzo=o(" (WavLM model)"),jzo=l(),Uv=a("p"),qzo=o("The model is set in evaluation mode by default using "),tfe=a("code"),Gzo=o("model.eval()"),Ozo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),afe=a("code"),Xzo=o("model.train()"),Vzo=l(),nfe=a("p"),zzo=o("Examples:"),Wzo=l(),f(nA.$$.fragment),tRe=l(),Jd=a("h2"),Jv=a("a"),sfe=a("span"),f(sA.$$.fragment),Qzo=l(),lfe=a("span"),Hzo=o("AutoModelForMaskedImageModeling"),aRe=l(),hr=a("div"),f(lA.$$.fragment),Uzo=l(),Yd=a("p"),Jzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),ife=a("code"),Yzo=o("from_pretrained()"),Kzo=o("class method or the "),dfe=a("code"),Zzo=o("from_config()"),eWo=o(`class
method.`),oWo=l(),iA=a("p"),rWo=o("This class cannot be instantiated directly using "),cfe=a("code"),tWo=o("__init__()"),aWo=o(" (throws an error)."),nWo=l(),it=a("div"),f(dA.$$.fragment),sWo=l(),ffe=a("p"),lWo=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),iWo=l(),Kd=a("p"),dWo=o(`Note:
Loading a model from its configuration file does `),mfe=a("strong"),cWo=o("not"),fWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gfe=a("code"),mWo=o("from_pretrained()"),gWo=o("to load the model weights."),hWo=l(),hfe=a("p"),pWo=o("Examples:"),_Wo=l(),f(cA.$$.fragment),uWo=l(),oo=a("div"),f(fA.$$.fragment),bWo=l(),pfe=a("p"),vWo=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),TWo=l(),fn=a("p"),FWo=o("The model class to instantiate is selected based on the "),_fe=a("code"),CWo=o("model_type"),MWo=o(` property of the config object (either
passed as an argument or loaded from `),ufe=a("code"),EWo=o("pretrained_model_name_or_path"),yWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bfe=a("code"),wWo=o("pretrained_model_name_or_path"),AWo=o(":"),LWo=l(),Zd=a("ul"),Yv=a("li"),vfe=a("strong"),BWo=o("deit"),xWo=o(" \u2014 "),uq=a("a"),kWo=o("DeiTForMaskedImageModeling"),RWo=o(" (DeiT model)"),SWo=l(),Kv=a("li"),Tfe=a("strong"),PWo=o("swin"),$Wo=o(" \u2014 "),bq=a("a"),IWo=o("SwinForMaskedImageModeling"),NWo=o(" (Swin model)"),DWo=l(),Zv=a("li"),Ffe=a("strong"),jWo=o("vit"),qWo=o(" \u2014 "),vq=a("a"),GWo=o("ViTForMaskedImageModeling"),OWo=o(" (ViT model)"),XWo=l(),e6=a("p"),VWo=o("The model is set in evaluation mode by default using "),Cfe=a("code"),zWo=o("model.eval()"),WWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mfe=a("code"),QWo=o("model.train()"),HWo=l(),Efe=a("p"),UWo=o("Examples:"),JWo=l(),f(mA.$$.fragment),nRe=l(),ec=a("h2"),o6=a("a"),yfe=a("span"),f(gA.$$.fragment),YWo=l(),wfe=a("span"),KWo=o("AutoModelForObjectDetection"),sRe=l(),pr=a("div"),f(hA.$$.fragment),ZWo=l(),oc=a("p"),eQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Afe=a("code"),oQo=o("from_pretrained()"),rQo=o("class method or the "),Lfe=a("code"),tQo=o("from_config()"),aQo=o(`class
method.`),nQo=l(),pA=a("p"),sQo=o("This class cannot be instantiated directly using "),Bfe=a("code"),lQo=o("__init__()"),iQo=o(" (throws an error)."),dQo=l(),dt=a("div"),f(_A.$$.fragment),cQo=l(),xfe=a("p"),fQo=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),mQo=l(),rc=a("p"),gQo=o(`Note:
Loading a model from its configuration file does `),kfe=a("strong"),hQo=o("not"),pQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rfe=a("code"),_Qo=o("from_pretrained()"),uQo=o("to load the model weights."),bQo=l(),Sfe=a("p"),vQo=o("Examples:"),TQo=l(),f(uA.$$.fragment),FQo=l(),ro=a("div"),f(bA.$$.fragment),CQo=l(),Pfe=a("p"),MQo=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),EQo=l(),mn=a("p"),yQo=o("The model class to instantiate is selected based on the "),$fe=a("code"),wQo=o("model_type"),AQo=o(` property of the config object (either
passed as an argument or loaded from `),Ife=a("code"),LQo=o("pretrained_model_name_or_path"),BQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nfe=a("code"),xQo=o("pretrained_model_name_or_path"),kQo=o(":"),RQo=l(),Dfe=a("ul"),r6=a("li"),jfe=a("strong"),SQo=o("detr"),PQo=o(" \u2014 "),Tq=a("a"),$Qo=o("DetrForObjectDetection"),IQo=o(" (DETR model)"),NQo=l(),t6=a("p"),DQo=o("The model is set in evaluation mode by default using "),qfe=a("code"),jQo=o("model.eval()"),qQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gfe=a("code"),GQo=o("model.train()"),OQo=l(),Ofe=a("p"),XQo=o("Examples:"),VQo=l(),f(vA.$$.fragment),lRe=l(),tc=a("h2"),a6=a("a"),Xfe=a("span"),f(TA.$$.fragment),zQo=l(),Vfe=a("span"),WQo=o("AutoModelForImageSegmentation"),iRe=l(),_r=a("div"),f(FA.$$.fragment),QQo=l(),ac=a("p"),HQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),zfe=a("code"),UQo=o("from_pretrained()"),JQo=o("class method or the "),Wfe=a("code"),YQo=o("from_config()"),KQo=o(`class
method.`),ZQo=l(),CA=a("p"),eHo=o("This class cannot be instantiated directly using "),Qfe=a("code"),oHo=o("__init__()"),rHo=o(" (throws an error)."),tHo=l(),ct=a("div"),f(MA.$$.fragment),aHo=l(),Hfe=a("p"),nHo=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),sHo=l(),nc=a("p"),lHo=o(`Note:
Loading a model from its configuration file does `),Ufe=a("strong"),iHo=o("not"),dHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jfe=a("code"),cHo=o("from_pretrained()"),fHo=o("to load the model weights."),mHo=l(),Yfe=a("p"),gHo=o("Examples:"),hHo=l(),f(EA.$$.fragment),pHo=l(),to=a("div"),f(yA.$$.fragment),_Ho=l(),Kfe=a("p"),uHo=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),bHo=l(),gn=a("p"),vHo=o("The model class to instantiate is selected based on the "),Zfe=a("code"),THo=o("model_type"),FHo=o(` property of the config object (either
passed as an argument or loaded from `),eme=a("code"),CHo=o("pretrained_model_name_or_path"),MHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ome=a("code"),EHo=o("pretrained_model_name_or_path"),yHo=o(":"),wHo=l(),rme=a("ul"),n6=a("li"),tme=a("strong"),AHo=o("detr"),LHo=o(" \u2014 "),Fq=a("a"),BHo=o("DetrForSegmentation"),xHo=o(" (DETR model)"),kHo=l(),s6=a("p"),RHo=o("The model is set in evaluation mode by default using "),ame=a("code"),SHo=o("model.eval()"),PHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nme=a("code"),$Ho=o("model.train()"),IHo=l(),sme=a("p"),NHo=o("Examples:"),DHo=l(),f(wA.$$.fragment),dRe=l(),sc=a("h2"),l6=a("a"),lme=a("span"),f(AA.$$.fragment),jHo=l(),ime=a("span"),qHo=o("AutoModelForSemanticSegmentation"),cRe=l(),ur=a("div"),f(LA.$$.fragment),GHo=l(),lc=a("p"),OHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),dme=a("code"),XHo=o("from_pretrained()"),VHo=o("class method or the "),cme=a("code"),zHo=o("from_config()"),WHo=o(`class
method.`),QHo=l(),BA=a("p"),HHo=o("This class cannot be instantiated directly using "),fme=a("code"),UHo=o("__init__()"),JHo=o(" (throws an error)."),YHo=l(),ft=a("div"),f(xA.$$.fragment),KHo=l(),mme=a("p"),ZHo=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),eUo=l(),ic=a("p"),oUo=o(`Note:
Loading a model from its configuration file does `),gme=a("strong"),rUo=o("not"),tUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hme=a("code"),aUo=o("from_pretrained()"),nUo=o("to load the model weights."),sUo=l(),pme=a("p"),lUo=o("Examples:"),iUo=l(),f(kA.$$.fragment),dUo=l(),ao=a("div"),f(RA.$$.fragment),cUo=l(),_me=a("p"),fUo=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),mUo=l(),hn=a("p"),gUo=o("The model class to instantiate is selected based on the "),ume=a("code"),hUo=o("model_type"),pUo=o(` property of the config object (either
passed as an argument or loaded from `),bme=a("code"),_Uo=o("pretrained_model_name_or_path"),uUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vme=a("code"),bUo=o("pretrained_model_name_or_path"),vUo=o(":"),TUo=l(),SA=a("ul"),i6=a("li"),Tme=a("strong"),FUo=o("beit"),CUo=o(" \u2014 "),Cq=a("a"),MUo=o("BeitForSemanticSegmentation"),EUo=o(" (BEiT model)"),yUo=l(),d6=a("li"),Fme=a("strong"),wUo=o("segformer"),AUo=o(" \u2014 "),Mq=a("a"),LUo=o("SegformerForSemanticSegmentation"),BUo=o(" (SegFormer model)"),xUo=l(),c6=a("p"),kUo=o("The model is set in evaluation mode by default using "),Cme=a("code"),RUo=o("model.eval()"),SUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mme=a("code"),PUo=o("model.train()"),$Uo=l(),Eme=a("p"),IUo=o("Examples:"),NUo=l(),f(PA.$$.fragment),fRe=l(),dc=a("h2"),f6=a("a"),yme=a("span"),f($A.$$.fragment),DUo=l(),wme=a("span"),jUo=o("AutoModelForInstanceSegmentation"),mRe=l(),br=a("div"),f(IA.$$.fragment),qUo=l(),cc=a("p"),GUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Ame=a("code"),OUo=o("from_pretrained()"),XUo=o("class method or the "),Lme=a("code"),VUo=o("from_config()"),zUo=o(`class
method.`),WUo=l(),NA=a("p"),QUo=o("This class cannot be instantiated directly using "),Bme=a("code"),HUo=o("__init__()"),UUo=o(" (throws an error)."),JUo=l(),mt=a("div"),f(DA.$$.fragment),YUo=l(),xme=a("p"),KUo=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),ZUo=l(),fc=a("p"),eJo=o(`Note:
Loading a model from its configuration file does `),kme=a("strong"),oJo=o("not"),rJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rme=a("code"),tJo=o("from_pretrained()"),aJo=o("to load the model weights."),nJo=l(),Sme=a("p"),sJo=o("Examples:"),lJo=l(),f(jA.$$.fragment),iJo=l(),no=a("div"),f(qA.$$.fragment),dJo=l(),Pme=a("p"),cJo=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),fJo=l(),pn=a("p"),mJo=o("The model class to instantiate is selected based on the "),$me=a("code"),gJo=o("model_type"),hJo=o(` property of the config object (either
passed as an argument or loaded from `),Ime=a("code"),pJo=o("pretrained_model_name_or_path"),_Jo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nme=a("code"),uJo=o("pretrained_model_name_or_path"),bJo=o(":"),vJo=l(),Dme=a("ul"),m6=a("li"),jme=a("strong"),TJo=o("maskformer"),FJo=o(" \u2014 "),Eq=a("a"),CJo=o("MaskFormerForInstanceSegmentation"),MJo=o(" (MaskFormer model)"),EJo=l(),g6=a("p"),yJo=o("The model is set in evaluation mode by default using "),qme=a("code"),wJo=o("model.eval()"),AJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gme=a("code"),LJo=o("model.train()"),BJo=l(),Ome=a("p"),xJo=o("Examples:"),kJo=l(),f(GA.$$.fragment),gRe=l(),mc=a("h2"),h6=a("a"),Xme=a("span"),f(OA.$$.fragment),RJo=l(),Vme=a("span"),SJo=o("TFAutoModel"),hRe=l(),vr=a("div"),f(XA.$$.fragment),PJo=l(),gc=a("p"),$Jo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),zme=a("code"),IJo=o("from_pretrained()"),NJo=o("class method or the "),Wme=a("code"),DJo=o("from_config()"),jJo=o(`class
method.`),qJo=l(),VA=a("p"),GJo=o("This class cannot be instantiated directly using "),Qme=a("code"),OJo=o("__init__()"),XJo=o(" (throws an error)."),VJo=l(),gt=a("div"),f(zA.$$.fragment),zJo=l(),Hme=a("p"),WJo=o("Instantiates one of the base model classes of the library from a configuration."),QJo=l(),hc=a("p"),HJo=o(`Note:
Loading a model from its configuration file does `),Ume=a("strong"),UJo=o("not"),JJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jme=a("code"),YJo=o("from_pretrained()"),KJo=o("to load the model weights."),ZJo=l(),Yme=a("p"),eYo=o("Examples:"),oYo=l(),f(WA.$$.fragment),rYo=l(),ho=a("div"),f(QA.$$.fragment),tYo=l(),Kme=a("p"),aYo=o("Instantiate one of the base model classes of the library from a pretrained model."),nYo=l(),_n=a("p"),sYo=o("The model class to instantiate is selected based on the "),Zme=a("code"),lYo=o("model_type"),iYo=o(` property of the config object (either
passed as an argument or loaded from `),ege=a("code"),dYo=o("pretrained_model_name_or_path"),cYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oge=a("code"),fYo=o("pretrained_model_name_or_path"),mYo=o(":"),gYo=l(),B=a("ul"),p6=a("li"),rge=a("strong"),hYo=o("albert"),pYo=o(" \u2014 "),yq=a("a"),_Yo=o("TFAlbertModel"),uYo=o(" (ALBERT model)"),bYo=l(),_6=a("li"),tge=a("strong"),vYo=o("bart"),TYo=o(" \u2014 "),wq=a("a"),FYo=o("TFBartModel"),CYo=o(" (BART model)"),MYo=l(),u6=a("li"),age=a("strong"),EYo=o("bert"),yYo=o(" \u2014 "),Aq=a("a"),wYo=o("TFBertModel"),AYo=o(" (BERT model)"),LYo=l(),b6=a("li"),nge=a("strong"),BYo=o("blenderbot"),xYo=o(" \u2014 "),Lq=a("a"),kYo=o("TFBlenderbotModel"),RYo=o(" (Blenderbot model)"),SYo=l(),v6=a("li"),sge=a("strong"),PYo=o("blenderbot-small"),$Yo=o(" \u2014 "),Bq=a("a"),IYo=o("TFBlenderbotSmallModel"),NYo=o(" (BlenderbotSmall model)"),DYo=l(),T6=a("li"),lge=a("strong"),jYo=o("camembert"),qYo=o(" \u2014 "),xq=a("a"),GYo=o("TFCamembertModel"),OYo=o(" (CamemBERT model)"),XYo=l(),F6=a("li"),ige=a("strong"),VYo=o("clip"),zYo=o(" \u2014 "),kq=a("a"),WYo=o("TFCLIPModel"),QYo=o(" (CLIP model)"),HYo=l(),C6=a("li"),dge=a("strong"),UYo=o("convbert"),JYo=o(" \u2014 "),Rq=a("a"),YYo=o("TFConvBertModel"),KYo=o(" (ConvBERT model)"),ZYo=l(),M6=a("li"),cge=a("strong"),eKo=o("convnext"),oKo=o(" \u2014 "),Sq=a("a"),rKo=o("TFConvNextModel"),tKo=o(" (ConvNext model)"),aKo=l(),E6=a("li"),fge=a("strong"),nKo=o("ctrl"),sKo=o(" \u2014 "),Pq=a("a"),lKo=o("TFCTRLModel"),iKo=o(" (CTRL model)"),dKo=l(),y6=a("li"),mge=a("strong"),cKo=o("deberta"),fKo=o(" \u2014 "),$q=a("a"),mKo=o("TFDebertaModel"),gKo=o(" (DeBERTa model)"),hKo=l(),w6=a("li"),gge=a("strong"),pKo=o("deberta-v2"),_Ko=o(" \u2014 "),Iq=a("a"),uKo=o("TFDebertaV2Model"),bKo=o(" (DeBERTa-v2 model)"),vKo=l(),A6=a("li"),hge=a("strong"),TKo=o("distilbert"),FKo=o(" \u2014 "),Nq=a("a"),CKo=o("TFDistilBertModel"),MKo=o(" (DistilBERT model)"),EKo=l(),L6=a("li"),pge=a("strong"),yKo=o("dpr"),wKo=o(" \u2014 "),Dq=a("a"),AKo=o("TFDPRQuestionEncoder"),LKo=o(" (DPR model)"),BKo=l(),B6=a("li"),_ge=a("strong"),xKo=o("electra"),kKo=o(" \u2014 "),jq=a("a"),RKo=o("TFElectraModel"),SKo=o(" (ELECTRA model)"),PKo=l(),x6=a("li"),uge=a("strong"),$Ko=o("flaubert"),IKo=o(" \u2014 "),qq=a("a"),NKo=o("TFFlaubertModel"),DKo=o(" (FlauBERT model)"),jKo=l(),Gs=a("li"),bge=a("strong"),qKo=o("funnel"),GKo=o(" \u2014 "),Gq=a("a"),OKo=o("TFFunnelModel"),XKo=o(" or "),Oq=a("a"),VKo=o("TFFunnelBaseModel"),zKo=o(" (Funnel Transformer model)"),WKo=l(),k6=a("li"),vge=a("strong"),QKo=o("gpt2"),HKo=o(" \u2014 "),Xq=a("a"),UKo=o("TFGPT2Model"),JKo=o(" (OpenAI GPT-2 model)"),YKo=l(),R6=a("li"),Tge=a("strong"),KKo=o("hubert"),ZKo=o(" \u2014 "),Vq=a("a"),eZo=o("TFHubertModel"),oZo=o(" (Hubert model)"),rZo=l(),S6=a("li"),Fge=a("strong"),tZo=o("layoutlm"),aZo=o(" \u2014 "),zq=a("a"),nZo=o("TFLayoutLMModel"),sZo=o(" (LayoutLM model)"),lZo=l(),P6=a("li"),Cge=a("strong"),iZo=o("led"),dZo=o(" \u2014 "),Wq=a("a"),cZo=o("TFLEDModel"),fZo=o(" (LED model)"),mZo=l(),$6=a("li"),Mge=a("strong"),gZo=o("longformer"),hZo=o(" \u2014 "),Qq=a("a"),pZo=o("TFLongformerModel"),_Zo=o(" (Longformer model)"),uZo=l(),I6=a("li"),Ege=a("strong"),bZo=o("lxmert"),vZo=o(" \u2014 "),Hq=a("a"),TZo=o("TFLxmertModel"),FZo=o(" (LXMERT model)"),CZo=l(),N6=a("li"),yge=a("strong"),MZo=o("marian"),EZo=o(" \u2014 "),Uq=a("a"),yZo=o("TFMarianModel"),wZo=o(" (Marian model)"),AZo=l(),D6=a("li"),wge=a("strong"),LZo=o("mbart"),BZo=o(" \u2014 "),Jq=a("a"),xZo=o("TFMBartModel"),kZo=o(" (mBART model)"),RZo=l(),j6=a("li"),Age=a("strong"),SZo=o("mobilebert"),PZo=o(" \u2014 "),Yq=a("a"),$Zo=o("TFMobileBertModel"),IZo=o(" (MobileBERT model)"),NZo=l(),q6=a("li"),Lge=a("strong"),DZo=o("mpnet"),jZo=o(" \u2014 "),Kq=a("a"),qZo=o("TFMPNetModel"),GZo=o(" (MPNet model)"),OZo=l(),G6=a("li"),Bge=a("strong"),XZo=o("mt5"),VZo=o(" \u2014 "),Zq=a("a"),zZo=o("TFMT5Model"),WZo=o(" (mT5 model)"),QZo=l(),O6=a("li"),xge=a("strong"),HZo=o("openai-gpt"),UZo=o(" \u2014 "),eG=a("a"),JZo=o("TFOpenAIGPTModel"),YZo=o(" (OpenAI GPT model)"),KZo=l(),X6=a("li"),kge=a("strong"),ZZo=o("pegasus"),eer=o(" \u2014 "),oG=a("a"),oer=o("TFPegasusModel"),rer=o(" (Pegasus model)"),ter=l(),V6=a("li"),Rge=a("strong"),aer=o("rembert"),ner=o(" \u2014 "),rG=a("a"),ser=o("TFRemBertModel"),ler=o(" (RemBERT model)"),ier=l(),z6=a("li"),Sge=a("strong"),der=o("roberta"),cer=o(" \u2014 "),tG=a("a"),fer=o("TFRobertaModel"),mer=o(" (RoBERTa model)"),ger=l(),W6=a("li"),Pge=a("strong"),her=o("roformer"),per=o(" \u2014 "),aG=a("a"),_er=o("TFRoFormerModel"),uer=o(" (RoFormer model)"),ber=l(),Q6=a("li"),$ge=a("strong"),ver=o("speech_to_text"),Ter=o(" \u2014 "),nG=a("a"),Fer=o("TFSpeech2TextModel"),Cer=o(" (Speech2Text model)"),Mer=l(),H6=a("li"),Ige=a("strong"),Eer=o("t5"),yer=o(" \u2014 "),sG=a("a"),wer=o("TFT5Model"),Aer=o(" (T5 model)"),Ler=l(),U6=a("li"),Nge=a("strong"),Ber=o("tapas"),xer=o(" \u2014 "),lG=a("a"),ker=o("TFTapasModel"),Rer=o(" (TAPAS model)"),Ser=l(),J6=a("li"),Dge=a("strong"),Per=o("transfo-xl"),$er=o(" \u2014 "),iG=a("a"),Ier=o("TFTransfoXLModel"),Ner=o(" (Transformer-XL model)"),Der=l(),Y6=a("li"),jge=a("strong"),jer=o("vit"),qer=o(" \u2014 "),dG=a("a"),Ger=o("TFViTModel"),Oer=o(" (ViT model)"),Xer=l(),K6=a("li"),qge=a("strong"),Ver=o("vit_mae"),zer=o(" \u2014 "),cG=a("a"),Wer=o("TFViTMAEModel"),Qer=o(" (ViTMAE model)"),Her=l(),Z6=a("li"),Gge=a("strong"),Uer=o("wav2vec2"),Jer=o(" \u2014 "),fG=a("a"),Yer=o("TFWav2Vec2Model"),Ker=o(" (Wav2Vec2 model)"),Zer=l(),eT=a("li"),Oge=a("strong"),eor=o("xlm"),oor=o(" \u2014 "),mG=a("a"),ror=o("TFXLMModel"),tor=o(" (XLM model)"),aor=l(),oT=a("li"),Xge=a("strong"),nor=o("xlm-roberta"),sor=o(" \u2014 "),gG=a("a"),lor=o("TFXLMRobertaModel"),ior=o(" (XLM-RoBERTa model)"),dor=l(),rT=a("li"),Vge=a("strong"),cor=o("xlnet"),mor=o(" \u2014 "),hG=a("a"),gor=o("TFXLNetModel"),hor=o(" (XLNet model)"),por=l(),zge=a("p"),_or=o("Examples:"),uor=l(),f(HA.$$.fragment),pRe=l(),pc=a("h2"),tT=a("a"),Wge=a("span"),f(UA.$$.fragment),bor=l(),Qge=a("span"),vor=o("TFAutoModelForPreTraining"),_Re=l(),Tr=a("div"),f(JA.$$.fragment),Tor=l(),_c=a("p"),For=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Hge=a("code"),Cor=o("from_pretrained()"),Mor=o("class method or the "),Uge=a("code"),Eor=o("from_config()"),yor=o(`class
method.`),wor=l(),YA=a("p"),Aor=o("This class cannot be instantiated directly using "),Jge=a("code"),Lor=o("__init__()"),Bor=o(" (throws an error)."),xor=l(),ht=a("div"),f(KA.$$.fragment),kor=l(),Yge=a("p"),Ror=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Sor=l(),uc=a("p"),Por=o(`Note:
Loading a model from its configuration file does `),Kge=a("strong"),$or=o("not"),Ior=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zge=a("code"),Nor=o("from_pretrained()"),Dor=o("to load the model weights."),jor=l(),ehe=a("p"),qor=o("Examples:"),Gor=l(),f(ZA.$$.fragment),Oor=l(),po=a("div"),f(e0.$$.fragment),Xor=l(),ohe=a("p"),Vor=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),zor=l(),un=a("p"),Wor=o("The model class to instantiate is selected based on the "),rhe=a("code"),Qor=o("model_type"),Hor=o(` property of the config object (either
passed as an argument or loaded from `),the=a("code"),Uor=o("pretrained_model_name_or_path"),Jor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ahe=a("code"),Yor=o("pretrained_model_name_or_path"),Kor=o(":"),Zor=l(),H=a("ul"),aT=a("li"),nhe=a("strong"),err=o("albert"),orr=o(" \u2014 "),pG=a("a"),rrr=o("TFAlbertForPreTraining"),trr=o(" (ALBERT model)"),arr=l(),nT=a("li"),she=a("strong"),nrr=o("bart"),srr=o(" \u2014 "),_G=a("a"),lrr=o("TFBartForConditionalGeneration"),irr=o(" (BART model)"),drr=l(),sT=a("li"),lhe=a("strong"),crr=o("bert"),frr=o(" \u2014 "),uG=a("a"),mrr=o("TFBertForPreTraining"),grr=o(" (BERT model)"),hrr=l(),lT=a("li"),ihe=a("strong"),prr=o("camembert"),_rr=o(" \u2014 "),bG=a("a"),urr=o("TFCamembertForMaskedLM"),brr=o(" (CamemBERT model)"),vrr=l(),iT=a("li"),dhe=a("strong"),Trr=o("ctrl"),Frr=o(" \u2014 "),vG=a("a"),Crr=o("TFCTRLLMHeadModel"),Mrr=o(" (CTRL model)"),Err=l(),dT=a("li"),che=a("strong"),yrr=o("distilbert"),wrr=o(" \u2014 "),TG=a("a"),Arr=o("TFDistilBertForMaskedLM"),Lrr=o(" (DistilBERT model)"),Brr=l(),cT=a("li"),fhe=a("strong"),xrr=o("electra"),krr=o(" \u2014 "),FG=a("a"),Rrr=o("TFElectraForPreTraining"),Srr=o(" (ELECTRA model)"),Prr=l(),fT=a("li"),mhe=a("strong"),$rr=o("flaubert"),Irr=o(" \u2014 "),CG=a("a"),Nrr=o("TFFlaubertWithLMHeadModel"),Drr=o(" (FlauBERT model)"),jrr=l(),mT=a("li"),ghe=a("strong"),qrr=o("funnel"),Grr=o(" \u2014 "),MG=a("a"),Orr=o("TFFunnelForPreTraining"),Xrr=o(" (Funnel Transformer model)"),Vrr=l(),gT=a("li"),hhe=a("strong"),zrr=o("gpt2"),Wrr=o(" \u2014 "),EG=a("a"),Qrr=o("TFGPT2LMHeadModel"),Hrr=o(" (OpenAI GPT-2 model)"),Urr=l(),hT=a("li"),phe=a("strong"),Jrr=o("layoutlm"),Yrr=o(" \u2014 "),yG=a("a"),Krr=o("TFLayoutLMForMaskedLM"),Zrr=o(" (LayoutLM model)"),etr=l(),pT=a("li"),_he=a("strong"),otr=o("lxmert"),rtr=o(" \u2014 "),wG=a("a"),ttr=o("TFLxmertForPreTraining"),atr=o(" (LXMERT model)"),ntr=l(),_T=a("li"),uhe=a("strong"),str=o("mobilebert"),ltr=o(" \u2014 "),AG=a("a"),itr=o("TFMobileBertForPreTraining"),dtr=o(" (MobileBERT model)"),ctr=l(),uT=a("li"),bhe=a("strong"),ftr=o("mpnet"),mtr=o(" \u2014 "),LG=a("a"),gtr=o("TFMPNetForMaskedLM"),htr=o(" (MPNet model)"),ptr=l(),bT=a("li"),vhe=a("strong"),_tr=o("openai-gpt"),utr=o(" \u2014 "),BG=a("a"),btr=o("TFOpenAIGPTLMHeadModel"),vtr=o(" (OpenAI GPT model)"),Ttr=l(),vT=a("li"),The=a("strong"),Ftr=o("roberta"),Ctr=o(" \u2014 "),xG=a("a"),Mtr=o("TFRobertaForMaskedLM"),Etr=o(" (RoBERTa model)"),ytr=l(),TT=a("li"),Fhe=a("strong"),wtr=o("t5"),Atr=o(" \u2014 "),kG=a("a"),Ltr=o("TFT5ForConditionalGeneration"),Btr=o(" (T5 model)"),xtr=l(),FT=a("li"),Che=a("strong"),ktr=o("tapas"),Rtr=o(" \u2014 "),RG=a("a"),Str=o("TFTapasForMaskedLM"),Ptr=o(" (TAPAS model)"),$tr=l(),CT=a("li"),Mhe=a("strong"),Itr=o("transfo-xl"),Ntr=o(" \u2014 "),SG=a("a"),Dtr=o("TFTransfoXLLMHeadModel"),jtr=o(" (Transformer-XL model)"),qtr=l(),MT=a("li"),Ehe=a("strong"),Gtr=o("vit_mae"),Otr=o(" \u2014 "),PG=a("a"),Xtr=o("TFViTMAEForPreTraining"),Vtr=o(" (ViTMAE model)"),ztr=l(),ET=a("li"),yhe=a("strong"),Wtr=o("xlm"),Qtr=o(" \u2014 "),$G=a("a"),Htr=o("TFXLMWithLMHeadModel"),Utr=o(" (XLM model)"),Jtr=l(),yT=a("li"),whe=a("strong"),Ytr=o("xlm-roberta"),Ktr=o(" \u2014 "),IG=a("a"),Ztr=o("TFXLMRobertaForMaskedLM"),ear=o(" (XLM-RoBERTa model)"),oar=l(),wT=a("li"),Ahe=a("strong"),rar=o("xlnet"),tar=o(" \u2014 "),NG=a("a"),aar=o("TFXLNetLMHeadModel"),nar=o(" (XLNet model)"),sar=l(),Lhe=a("p"),lar=o("Examples:"),iar=l(),f(o0.$$.fragment),uRe=l(),bc=a("h2"),AT=a("a"),Bhe=a("span"),f(r0.$$.fragment),dar=l(),xhe=a("span"),car=o("TFAutoModelForCausalLM"),bRe=l(),Fr=a("div"),f(t0.$$.fragment),far=l(),vc=a("p"),mar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),khe=a("code"),gar=o("from_pretrained()"),har=o("class method or the "),Rhe=a("code"),par=o("from_config()"),_ar=o(`class
method.`),uar=l(),a0=a("p"),bar=o("This class cannot be instantiated directly using "),She=a("code"),Tar=o("__init__()"),Far=o(" (throws an error)."),Car=l(),pt=a("div"),f(n0.$$.fragment),Mar=l(),Phe=a("p"),Ear=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yar=l(),Tc=a("p"),war=o(`Note:
Loading a model from its configuration file does `),$he=a("strong"),Aar=o("not"),Lar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ihe=a("code"),Bar=o("from_pretrained()"),xar=o("to load the model weights."),kar=l(),Nhe=a("p"),Rar=o("Examples:"),Sar=l(),f(s0.$$.fragment),Par=l(),_o=a("div"),f(l0.$$.fragment),$ar=l(),Dhe=a("p"),Iar=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Nar=l(),bn=a("p"),Dar=o("The model class to instantiate is selected based on the "),jhe=a("code"),jar=o("model_type"),qar=o(` property of the config object (either
passed as an argument or loaded from `),qhe=a("code"),Gar=o("pretrained_model_name_or_path"),Oar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ghe=a("code"),Xar=o("pretrained_model_name_or_path"),Var=o(":"),zar=l(),ge=a("ul"),LT=a("li"),Ohe=a("strong"),War=o("bert"),Qar=o(" \u2014 "),DG=a("a"),Har=o("TFBertLMHeadModel"),Uar=o(" (BERT model)"),Jar=l(),BT=a("li"),Xhe=a("strong"),Yar=o("camembert"),Kar=o(" \u2014 "),jG=a("a"),Zar=o("TFCamembertForCausalLM"),enr=o(" (CamemBERT model)"),onr=l(),xT=a("li"),Vhe=a("strong"),rnr=o("ctrl"),tnr=o(" \u2014 "),qG=a("a"),anr=o("TFCTRLLMHeadModel"),nnr=o(" (CTRL model)"),snr=l(),kT=a("li"),zhe=a("strong"),lnr=o("gpt2"),inr=o(" \u2014 "),GG=a("a"),dnr=o("TFGPT2LMHeadModel"),cnr=o(" (OpenAI GPT-2 model)"),fnr=l(),RT=a("li"),Whe=a("strong"),mnr=o("openai-gpt"),gnr=o(" \u2014 "),OG=a("a"),hnr=o("TFOpenAIGPTLMHeadModel"),pnr=o(" (OpenAI GPT model)"),_nr=l(),ST=a("li"),Qhe=a("strong"),unr=o("rembert"),bnr=o(" \u2014 "),XG=a("a"),vnr=o("TFRemBertForCausalLM"),Tnr=o(" (RemBERT model)"),Fnr=l(),PT=a("li"),Hhe=a("strong"),Cnr=o("roberta"),Mnr=o(" \u2014 "),VG=a("a"),Enr=o("TFRobertaForCausalLM"),ynr=o(" (RoBERTa model)"),wnr=l(),$T=a("li"),Uhe=a("strong"),Anr=o("roformer"),Lnr=o(" \u2014 "),zG=a("a"),Bnr=o("TFRoFormerForCausalLM"),xnr=o(" (RoFormer model)"),knr=l(),IT=a("li"),Jhe=a("strong"),Rnr=o("transfo-xl"),Snr=o(" \u2014 "),WG=a("a"),Pnr=o("TFTransfoXLLMHeadModel"),$nr=o(" (Transformer-XL model)"),Inr=l(),NT=a("li"),Yhe=a("strong"),Nnr=o("xlm"),Dnr=o(" \u2014 "),QG=a("a"),jnr=o("TFXLMWithLMHeadModel"),qnr=o(" (XLM model)"),Gnr=l(),DT=a("li"),Khe=a("strong"),Onr=o("xlnet"),Xnr=o(" \u2014 "),HG=a("a"),Vnr=o("TFXLNetLMHeadModel"),znr=o(" (XLNet model)"),Wnr=l(),Zhe=a("p"),Qnr=o("Examples:"),Hnr=l(),f(i0.$$.fragment),vRe=l(),Fc=a("h2"),jT=a("a"),epe=a("span"),f(d0.$$.fragment),Unr=l(),ope=a("span"),Jnr=o("TFAutoModelForImageClassification"),TRe=l(),Cr=a("div"),f(c0.$$.fragment),Ynr=l(),Cc=a("p"),Knr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rpe=a("code"),Znr=o("from_pretrained()"),esr=o("class method or the "),tpe=a("code"),osr=o("from_config()"),rsr=o(`class
method.`),tsr=l(),f0=a("p"),asr=o("This class cannot be instantiated directly using "),ape=a("code"),nsr=o("__init__()"),ssr=o(" (throws an error)."),lsr=l(),_t=a("div"),f(m0.$$.fragment),isr=l(),npe=a("p"),dsr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),csr=l(),Mc=a("p"),fsr=o(`Note:
Loading a model from its configuration file does `),spe=a("strong"),msr=o("not"),gsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lpe=a("code"),hsr=o("from_pretrained()"),psr=o("to load the model weights."),_sr=l(),ipe=a("p"),usr=o("Examples:"),bsr=l(),f(g0.$$.fragment),vsr=l(),uo=a("div"),f(h0.$$.fragment),Tsr=l(),dpe=a("p"),Fsr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Csr=l(),vn=a("p"),Msr=o("The model class to instantiate is selected based on the "),cpe=a("code"),Esr=o("model_type"),ysr=o(` property of the config object (either
passed as an argument or loaded from `),fpe=a("code"),wsr=o("pretrained_model_name_or_path"),Asr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mpe=a("code"),Lsr=o("pretrained_model_name_or_path"),Bsr=o(":"),xsr=l(),p0=a("ul"),qT=a("li"),gpe=a("strong"),ksr=o("convnext"),Rsr=o(" \u2014 "),UG=a("a"),Ssr=o("TFConvNextForImageClassification"),Psr=o(" (ConvNext model)"),$sr=l(),GT=a("li"),hpe=a("strong"),Isr=o("vit"),Nsr=o(" \u2014 "),JG=a("a"),Dsr=o("TFViTForImageClassification"),jsr=o(" (ViT model)"),qsr=l(),ppe=a("p"),Gsr=o("Examples:"),Osr=l(),f(_0.$$.fragment),FRe=l(),Ec=a("h2"),OT=a("a"),_pe=a("span"),f(u0.$$.fragment),Xsr=l(),upe=a("span"),Vsr=o("TFAutoModelForMaskedLM"),CRe=l(),Mr=a("div"),f(b0.$$.fragment),zsr=l(),yc=a("p"),Wsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),bpe=a("code"),Qsr=o("from_pretrained()"),Hsr=o("class method or the "),vpe=a("code"),Usr=o("from_config()"),Jsr=o(`class
method.`),Ysr=l(),v0=a("p"),Ksr=o("This class cannot be instantiated directly using "),Tpe=a("code"),Zsr=o("__init__()"),elr=o(" (throws an error)."),olr=l(),ut=a("div"),f(T0.$$.fragment),rlr=l(),Fpe=a("p"),tlr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),alr=l(),wc=a("p"),nlr=o(`Note:
Loading a model from its configuration file does `),Cpe=a("strong"),slr=o("not"),llr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mpe=a("code"),ilr=o("from_pretrained()"),dlr=o("to load the model weights."),clr=l(),Epe=a("p"),flr=o("Examples:"),mlr=l(),f(F0.$$.fragment),glr=l(),bo=a("div"),f(C0.$$.fragment),hlr=l(),ype=a("p"),plr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_lr=l(),Tn=a("p"),ulr=o("The model class to instantiate is selected based on the "),wpe=a("code"),blr=o("model_type"),vlr=o(` property of the config object (either
passed as an argument or loaded from `),Ape=a("code"),Tlr=o("pretrained_model_name_or_path"),Flr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lpe=a("code"),Clr=o("pretrained_model_name_or_path"),Mlr=o(":"),Elr=l(),J=a("ul"),XT=a("li"),Bpe=a("strong"),ylr=o("albert"),wlr=o(" \u2014 "),YG=a("a"),Alr=o("TFAlbertForMaskedLM"),Llr=o(" (ALBERT model)"),Blr=l(),VT=a("li"),xpe=a("strong"),xlr=o("bert"),klr=o(" \u2014 "),KG=a("a"),Rlr=o("TFBertForMaskedLM"),Slr=o(" (BERT model)"),Plr=l(),zT=a("li"),kpe=a("strong"),$lr=o("camembert"),Ilr=o(" \u2014 "),ZG=a("a"),Nlr=o("TFCamembertForMaskedLM"),Dlr=o(" (CamemBERT model)"),jlr=l(),WT=a("li"),Rpe=a("strong"),qlr=o("convbert"),Glr=o(" \u2014 "),eO=a("a"),Olr=o("TFConvBertForMaskedLM"),Xlr=o(" (ConvBERT model)"),Vlr=l(),QT=a("li"),Spe=a("strong"),zlr=o("deberta"),Wlr=o(" \u2014 "),oO=a("a"),Qlr=o("TFDebertaForMaskedLM"),Hlr=o(" (DeBERTa model)"),Ulr=l(),HT=a("li"),Ppe=a("strong"),Jlr=o("deberta-v2"),Ylr=o(" \u2014 "),rO=a("a"),Klr=o("TFDebertaV2ForMaskedLM"),Zlr=o(" (DeBERTa-v2 model)"),eir=l(),UT=a("li"),$pe=a("strong"),oir=o("distilbert"),rir=o(" \u2014 "),tO=a("a"),tir=o("TFDistilBertForMaskedLM"),air=o(" (DistilBERT model)"),nir=l(),JT=a("li"),Ipe=a("strong"),sir=o("electra"),lir=o(" \u2014 "),aO=a("a"),iir=o("TFElectraForMaskedLM"),dir=o(" (ELECTRA model)"),cir=l(),YT=a("li"),Npe=a("strong"),fir=o("flaubert"),mir=o(" \u2014 "),nO=a("a"),gir=o("TFFlaubertWithLMHeadModel"),hir=o(" (FlauBERT model)"),pir=l(),KT=a("li"),Dpe=a("strong"),_ir=o("funnel"),uir=o(" \u2014 "),sO=a("a"),bir=o("TFFunnelForMaskedLM"),vir=o(" (Funnel Transformer model)"),Tir=l(),ZT=a("li"),jpe=a("strong"),Fir=o("layoutlm"),Cir=o(" \u2014 "),lO=a("a"),Mir=o("TFLayoutLMForMaskedLM"),Eir=o(" (LayoutLM model)"),yir=l(),eF=a("li"),qpe=a("strong"),wir=o("longformer"),Air=o(" \u2014 "),iO=a("a"),Lir=o("TFLongformerForMaskedLM"),Bir=o(" (Longformer model)"),xir=l(),oF=a("li"),Gpe=a("strong"),kir=o("mobilebert"),Rir=o(" \u2014 "),dO=a("a"),Sir=o("TFMobileBertForMaskedLM"),Pir=o(" (MobileBERT model)"),$ir=l(),rF=a("li"),Ope=a("strong"),Iir=o("mpnet"),Nir=o(" \u2014 "),cO=a("a"),Dir=o("TFMPNetForMaskedLM"),jir=o(" (MPNet model)"),qir=l(),tF=a("li"),Xpe=a("strong"),Gir=o("rembert"),Oir=o(" \u2014 "),fO=a("a"),Xir=o("TFRemBertForMaskedLM"),Vir=o(" (RemBERT model)"),zir=l(),aF=a("li"),Vpe=a("strong"),Wir=o("roberta"),Qir=o(" \u2014 "),mO=a("a"),Hir=o("TFRobertaForMaskedLM"),Uir=o(" (RoBERTa model)"),Jir=l(),nF=a("li"),zpe=a("strong"),Yir=o("roformer"),Kir=o(" \u2014 "),gO=a("a"),Zir=o("TFRoFormerForMaskedLM"),edr=o(" (RoFormer model)"),odr=l(),sF=a("li"),Wpe=a("strong"),rdr=o("tapas"),tdr=o(" \u2014 "),hO=a("a"),adr=o("TFTapasForMaskedLM"),ndr=o(" (TAPAS model)"),sdr=l(),lF=a("li"),Qpe=a("strong"),ldr=o("xlm"),idr=o(" \u2014 "),pO=a("a"),ddr=o("TFXLMWithLMHeadModel"),cdr=o(" (XLM model)"),fdr=l(),iF=a("li"),Hpe=a("strong"),mdr=o("xlm-roberta"),gdr=o(" \u2014 "),_O=a("a"),hdr=o("TFXLMRobertaForMaskedLM"),pdr=o(" (XLM-RoBERTa model)"),_dr=l(),Upe=a("p"),udr=o("Examples:"),bdr=l(),f(M0.$$.fragment),MRe=l(),Ac=a("h2"),dF=a("a"),Jpe=a("span"),f(E0.$$.fragment),vdr=l(),Ype=a("span"),Tdr=o("TFAutoModelForSeq2SeqLM"),ERe=l(),Er=a("div"),f(y0.$$.fragment),Fdr=l(),Lc=a("p"),Cdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Kpe=a("code"),Mdr=o("from_pretrained()"),Edr=o("class method or the "),Zpe=a("code"),ydr=o("from_config()"),wdr=o(`class
method.`),Adr=l(),w0=a("p"),Ldr=o("This class cannot be instantiated directly using "),e_e=a("code"),Bdr=o("__init__()"),xdr=o(" (throws an error)."),kdr=l(),bt=a("div"),f(A0.$$.fragment),Rdr=l(),o_e=a("p"),Sdr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Pdr=l(),Bc=a("p"),$dr=o(`Note:
Loading a model from its configuration file does `),r_e=a("strong"),Idr=o("not"),Ndr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),t_e=a("code"),Ddr=o("from_pretrained()"),jdr=o("to load the model weights."),qdr=l(),a_e=a("p"),Gdr=o("Examples:"),Odr=l(),f(L0.$$.fragment),Xdr=l(),vo=a("div"),f(B0.$$.fragment),Vdr=l(),n_e=a("p"),zdr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Wdr=l(),Fn=a("p"),Qdr=o("The model class to instantiate is selected based on the "),s_e=a("code"),Hdr=o("model_type"),Udr=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),Jdr=o("pretrained_model_name_or_path"),Ydr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),Kdr=o("pretrained_model_name_or_path"),Zdr=o(":"),ecr=l(),_e=a("ul"),cF=a("li"),d_e=a("strong"),ocr=o("bart"),rcr=o(" \u2014 "),uO=a("a"),tcr=o("TFBartForConditionalGeneration"),acr=o(" (BART model)"),ncr=l(),fF=a("li"),c_e=a("strong"),scr=o("blenderbot"),lcr=o(" \u2014 "),bO=a("a"),icr=o("TFBlenderbotForConditionalGeneration"),dcr=o(" (Blenderbot model)"),ccr=l(),mF=a("li"),f_e=a("strong"),fcr=o("blenderbot-small"),mcr=o(" \u2014 "),vO=a("a"),gcr=o("TFBlenderbotSmallForConditionalGeneration"),hcr=o(" (BlenderbotSmall model)"),pcr=l(),gF=a("li"),m_e=a("strong"),_cr=o("encoder-decoder"),ucr=o(" \u2014 "),TO=a("a"),bcr=o("TFEncoderDecoderModel"),vcr=o(" (Encoder decoder model)"),Tcr=l(),hF=a("li"),g_e=a("strong"),Fcr=o("led"),Ccr=o(" \u2014 "),FO=a("a"),Mcr=o("TFLEDForConditionalGeneration"),Ecr=o(" (LED model)"),ycr=l(),pF=a("li"),h_e=a("strong"),wcr=o("marian"),Acr=o(" \u2014 "),CO=a("a"),Lcr=o("TFMarianMTModel"),Bcr=o(" (Marian model)"),xcr=l(),_F=a("li"),p_e=a("strong"),kcr=o("mbart"),Rcr=o(" \u2014 "),MO=a("a"),Scr=o("TFMBartForConditionalGeneration"),Pcr=o(" (mBART model)"),$cr=l(),uF=a("li"),__e=a("strong"),Icr=o("mt5"),Ncr=o(" \u2014 "),EO=a("a"),Dcr=o("TFMT5ForConditionalGeneration"),jcr=o(" (mT5 model)"),qcr=l(),bF=a("li"),u_e=a("strong"),Gcr=o("pegasus"),Ocr=o(" \u2014 "),yO=a("a"),Xcr=o("TFPegasusForConditionalGeneration"),Vcr=o(" (Pegasus model)"),zcr=l(),vF=a("li"),b_e=a("strong"),Wcr=o("t5"),Qcr=o(" \u2014 "),wO=a("a"),Hcr=o("TFT5ForConditionalGeneration"),Ucr=o(" (T5 model)"),Jcr=l(),v_e=a("p"),Ycr=o("Examples:"),Kcr=l(),f(x0.$$.fragment),yRe=l(),xc=a("h2"),TF=a("a"),T_e=a("span"),f(k0.$$.fragment),Zcr=l(),F_e=a("span"),efr=o("TFAutoModelForSequenceClassification"),wRe=l(),yr=a("div"),f(R0.$$.fragment),ofr=l(),kc=a("p"),rfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),C_e=a("code"),tfr=o("from_pretrained()"),afr=o("class method or the "),M_e=a("code"),nfr=o("from_config()"),sfr=o(`class
method.`),lfr=l(),S0=a("p"),ifr=o("This class cannot be instantiated directly using "),E_e=a("code"),dfr=o("__init__()"),cfr=o(" (throws an error)."),ffr=l(),vt=a("div"),f(P0.$$.fragment),mfr=l(),y_e=a("p"),gfr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hfr=l(),Rc=a("p"),pfr=o(`Note:
Loading a model from its configuration file does `),w_e=a("strong"),_fr=o("not"),ufr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),A_e=a("code"),bfr=o("from_pretrained()"),vfr=o("to load the model weights."),Tfr=l(),L_e=a("p"),Ffr=o("Examples:"),Cfr=l(),f($0.$$.fragment),Mfr=l(),To=a("div"),f(I0.$$.fragment),Efr=l(),B_e=a("p"),yfr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),wfr=l(),Cn=a("p"),Afr=o("The model class to instantiate is selected based on the "),x_e=a("code"),Lfr=o("model_type"),Bfr=o(` property of the config object (either
passed as an argument or loaded from `),k_e=a("code"),xfr=o("pretrained_model_name_or_path"),kfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R_e=a("code"),Rfr=o("pretrained_model_name_or_path"),Sfr=o(":"),Pfr=l(),V=a("ul"),FF=a("li"),S_e=a("strong"),$fr=o("albert"),Ifr=o(" \u2014 "),AO=a("a"),Nfr=o("TFAlbertForSequenceClassification"),Dfr=o(" (ALBERT model)"),jfr=l(),CF=a("li"),P_e=a("strong"),qfr=o("bert"),Gfr=o(" \u2014 "),LO=a("a"),Ofr=o("TFBertForSequenceClassification"),Xfr=o(" (BERT model)"),Vfr=l(),MF=a("li"),$_e=a("strong"),zfr=o("camembert"),Wfr=o(" \u2014 "),BO=a("a"),Qfr=o("TFCamembertForSequenceClassification"),Hfr=o(" (CamemBERT model)"),Ufr=l(),EF=a("li"),I_e=a("strong"),Jfr=o("convbert"),Yfr=o(" \u2014 "),xO=a("a"),Kfr=o("TFConvBertForSequenceClassification"),Zfr=o(" (ConvBERT model)"),emr=l(),yF=a("li"),N_e=a("strong"),omr=o("ctrl"),rmr=o(" \u2014 "),kO=a("a"),tmr=o("TFCTRLForSequenceClassification"),amr=o(" (CTRL model)"),nmr=l(),wF=a("li"),D_e=a("strong"),smr=o("deberta"),lmr=o(" \u2014 "),RO=a("a"),imr=o("TFDebertaForSequenceClassification"),dmr=o(" (DeBERTa model)"),cmr=l(),AF=a("li"),j_e=a("strong"),fmr=o("deberta-v2"),mmr=o(" \u2014 "),SO=a("a"),gmr=o("TFDebertaV2ForSequenceClassification"),hmr=o(" (DeBERTa-v2 model)"),pmr=l(),LF=a("li"),q_e=a("strong"),_mr=o("distilbert"),umr=o(" \u2014 "),PO=a("a"),bmr=o("TFDistilBertForSequenceClassification"),vmr=o(" (DistilBERT model)"),Tmr=l(),BF=a("li"),G_e=a("strong"),Fmr=o("electra"),Cmr=o(" \u2014 "),$O=a("a"),Mmr=o("TFElectraForSequenceClassification"),Emr=o(" (ELECTRA model)"),ymr=l(),xF=a("li"),O_e=a("strong"),wmr=o("flaubert"),Amr=o(" \u2014 "),IO=a("a"),Lmr=o("TFFlaubertForSequenceClassification"),Bmr=o(" (FlauBERT model)"),xmr=l(),kF=a("li"),X_e=a("strong"),kmr=o("funnel"),Rmr=o(" \u2014 "),NO=a("a"),Smr=o("TFFunnelForSequenceClassification"),Pmr=o(" (Funnel Transformer model)"),$mr=l(),RF=a("li"),V_e=a("strong"),Imr=o("gpt2"),Nmr=o(" \u2014 "),DO=a("a"),Dmr=o("TFGPT2ForSequenceClassification"),jmr=o(" (OpenAI GPT-2 model)"),qmr=l(),SF=a("li"),z_e=a("strong"),Gmr=o("layoutlm"),Omr=o(" \u2014 "),jO=a("a"),Xmr=o("TFLayoutLMForSequenceClassification"),Vmr=o(" (LayoutLM model)"),zmr=l(),PF=a("li"),W_e=a("strong"),Wmr=o("longformer"),Qmr=o(" \u2014 "),qO=a("a"),Hmr=o("TFLongformerForSequenceClassification"),Umr=o(" (Longformer model)"),Jmr=l(),$F=a("li"),Q_e=a("strong"),Ymr=o("mobilebert"),Kmr=o(" \u2014 "),GO=a("a"),Zmr=o("TFMobileBertForSequenceClassification"),egr=o(" (MobileBERT model)"),ogr=l(),IF=a("li"),H_e=a("strong"),rgr=o("mpnet"),tgr=o(" \u2014 "),OO=a("a"),agr=o("TFMPNetForSequenceClassification"),ngr=o(" (MPNet model)"),sgr=l(),NF=a("li"),U_e=a("strong"),lgr=o("openai-gpt"),igr=o(" \u2014 "),XO=a("a"),dgr=o("TFOpenAIGPTForSequenceClassification"),cgr=o(" (OpenAI GPT model)"),fgr=l(),DF=a("li"),J_e=a("strong"),mgr=o("rembert"),ggr=o(" \u2014 "),VO=a("a"),hgr=o("TFRemBertForSequenceClassification"),pgr=o(" (RemBERT model)"),_gr=l(),jF=a("li"),Y_e=a("strong"),ugr=o("roberta"),bgr=o(" \u2014 "),zO=a("a"),vgr=o("TFRobertaForSequenceClassification"),Tgr=o(" (RoBERTa model)"),Fgr=l(),qF=a("li"),K_e=a("strong"),Cgr=o("roformer"),Mgr=o(" \u2014 "),WO=a("a"),Egr=o("TFRoFormerForSequenceClassification"),ygr=o(" (RoFormer model)"),wgr=l(),GF=a("li"),Z_e=a("strong"),Agr=o("tapas"),Lgr=o(" \u2014 "),QO=a("a"),Bgr=o("TFTapasForSequenceClassification"),xgr=o(" (TAPAS model)"),kgr=l(),OF=a("li"),eue=a("strong"),Rgr=o("transfo-xl"),Sgr=o(" \u2014 "),HO=a("a"),Pgr=o("TFTransfoXLForSequenceClassification"),$gr=o(" (Transformer-XL model)"),Igr=l(),XF=a("li"),oue=a("strong"),Ngr=o("xlm"),Dgr=o(" \u2014 "),UO=a("a"),jgr=o("TFXLMForSequenceClassification"),qgr=o(" (XLM model)"),Ggr=l(),VF=a("li"),rue=a("strong"),Ogr=o("xlm-roberta"),Xgr=o(" \u2014 "),JO=a("a"),Vgr=o("TFXLMRobertaForSequenceClassification"),zgr=o(" (XLM-RoBERTa model)"),Wgr=l(),zF=a("li"),tue=a("strong"),Qgr=o("xlnet"),Hgr=o(" \u2014 "),YO=a("a"),Ugr=o("TFXLNetForSequenceClassification"),Jgr=o(" (XLNet model)"),Ygr=l(),aue=a("p"),Kgr=o("Examples:"),Zgr=l(),f(N0.$$.fragment),ARe=l(),Sc=a("h2"),WF=a("a"),nue=a("span"),f(D0.$$.fragment),ehr=l(),sue=a("span"),ohr=o("TFAutoModelForMultipleChoice"),LRe=l(),wr=a("div"),f(j0.$$.fragment),rhr=l(),Pc=a("p"),thr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lue=a("code"),ahr=o("from_pretrained()"),nhr=o("class method or the "),iue=a("code"),shr=o("from_config()"),lhr=o(`class
method.`),ihr=l(),q0=a("p"),dhr=o("This class cannot be instantiated directly using "),due=a("code"),chr=o("__init__()"),fhr=o(" (throws an error)."),mhr=l(),Tt=a("div"),f(G0.$$.fragment),ghr=l(),cue=a("p"),hhr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),phr=l(),$c=a("p"),_hr=o(`Note:
Loading a model from its configuration file does `),fue=a("strong"),uhr=o("not"),bhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mue=a("code"),vhr=o("from_pretrained()"),Thr=o("to load the model weights."),Fhr=l(),gue=a("p"),Chr=o("Examples:"),Mhr=l(),f(O0.$$.fragment),Ehr=l(),Fo=a("div"),f(X0.$$.fragment),yhr=l(),hue=a("p"),whr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Ahr=l(),Mn=a("p"),Lhr=o("The model class to instantiate is selected based on the "),pue=a("code"),Bhr=o("model_type"),xhr=o(` property of the config object (either
passed as an argument or loaded from `),_ue=a("code"),khr=o("pretrained_model_name_or_path"),Rhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uue=a("code"),Shr=o("pretrained_model_name_or_path"),Phr=o(":"),$hr=l(),ae=a("ul"),QF=a("li"),bue=a("strong"),Ihr=o("albert"),Nhr=o(" \u2014 "),KO=a("a"),Dhr=o("TFAlbertForMultipleChoice"),jhr=o(" (ALBERT model)"),qhr=l(),HF=a("li"),vue=a("strong"),Ghr=o("bert"),Ohr=o(" \u2014 "),ZO=a("a"),Xhr=o("TFBertForMultipleChoice"),Vhr=o(" (BERT model)"),zhr=l(),UF=a("li"),Tue=a("strong"),Whr=o("camembert"),Qhr=o(" \u2014 "),eX=a("a"),Hhr=o("TFCamembertForMultipleChoice"),Uhr=o(" (CamemBERT model)"),Jhr=l(),JF=a("li"),Fue=a("strong"),Yhr=o("convbert"),Khr=o(" \u2014 "),oX=a("a"),Zhr=o("TFConvBertForMultipleChoice"),epr=o(" (ConvBERT model)"),opr=l(),YF=a("li"),Cue=a("strong"),rpr=o("distilbert"),tpr=o(" \u2014 "),rX=a("a"),apr=o("TFDistilBertForMultipleChoice"),npr=o(" (DistilBERT model)"),spr=l(),KF=a("li"),Mue=a("strong"),lpr=o("electra"),ipr=o(" \u2014 "),tX=a("a"),dpr=o("TFElectraForMultipleChoice"),cpr=o(" (ELECTRA model)"),fpr=l(),ZF=a("li"),Eue=a("strong"),mpr=o("flaubert"),gpr=o(" \u2014 "),aX=a("a"),hpr=o("TFFlaubertForMultipleChoice"),ppr=o(" (FlauBERT model)"),_pr=l(),eC=a("li"),yue=a("strong"),upr=o("funnel"),bpr=o(" \u2014 "),nX=a("a"),vpr=o("TFFunnelForMultipleChoice"),Tpr=o(" (Funnel Transformer model)"),Fpr=l(),oC=a("li"),wue=a("strong"),Cpr=o("longformer"),Mpr=o(" \u2014 "),sX=a("a"),Epr=o("TFLongformerForMultipleChoice"),ypr=o(" (Longformer model)"),wpr=l(),rC=a("li"),Aue=a("strong"),Apr=o("mobilebert"),Lpr=o(" \u2014 "),lX=a("a"),Bpr=o("TFMobileBertForMultipleChoice"),xpr=o(" (MobileBERT model)"),kpr=l(),tC=a("li"),Lue=a("strong"),Rpr=o("mpnet"),Spr=o(" \u2014 "),iX=a("a"),Ppr=o("TFMPNetForMultipleChoice"),$pr=o(" (MPNet model)"),Ipr=l(),aC=a("li"),Bue=a("strong"),Npr=o("rembert"),Dpr=o(" \u2014 "),dX=a("a"),jpr=o("TFRemBertForMultipleChoice"),qpr=o(" (RemBERT model)"),Gpr=l(),nC=a("li"),xue=a("strong"),Opr=o("roberta"),Xpr=o(" \u2014 "),cX=a("a"),Vpr=o("TFRobertaForMultipleChoice"),zpr=o(" (RoBERTa model)"),Wpr=l(),sC=a("li"),kue=a("strong"),Qpr=o("roformer"),Hpr=o(" \u2014 "),fX=a("a"),Upr=o("TFRoFormerForMultipleChoice"),Jpr=o(" (RoFormer model)"),Ypr=l(),lC=a("li"),Rue=a("strong"),Kpr=o("xlm"),Zpr=o(" \u2014 "),mX=a("a"),e_r=o("TFXLMForMultipleChoice"),o_r=o(" (XLM model)"),r_r=l(),iC=a("li"),Sue=a("strong"),t_r=o("xlm-roberta"),a_r=o(" \u2014 "),gX=a("a"),n_r=o("TFXLMRobertaForMultipleChoice"),s_r=o(" (XLM-RoBERTa model)"),l_r=l(),dC=a("li"),Pue=a("strong"),i_r=o("xlnet"),d_r=o(" \u2014 "),hX=a("a"),c_r=o("TFXLNetForMultipleChoice"),f_r=o(" (XLNet model)"),m_r=l(),$ue=a("p"),g_r=o("Examples:"),h_r=l(),f(V0.$$.fragment),BRe=l(),Ic=a("h2"),cC=a("a"),Iue=a("span"),f(z0.$$.fragment),p_r=l(),Nue=a("span"),__r=o("TFAutoModelForTableQuestionAnswering"),xRe=l(),Ar=a("div"),f(W0.$$.fragment),u_r=l(),Nc=a("p"),b_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Due=a("code"),v_r=o("from_pretrained()"),T_r=o("class method or the "),jue=a("code"),F_r=o("from_config()"),C_r=o(`class
method.`),M_r=l(),Q0=a("p"),E_r=o("This class cannot be instantiated directly using "),que=a("code"),y_r=o("__init__()"),w_r=o(" (throws an error)."),A_r=l(),Ft=a("div"),f(H0.$$.fragment),L_r=l(),Gue=a("p"),B_r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),x_r=l(),Dc=a("p"),k_r=o(`Note:
Loading a model from its configuration file does `),Oue=a("strong"),R_r=o("not"),S_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xue=a("code"),P_r=o("from_pretrained()"),$_r=o("to load the model weights."),I_r=l(),Vue=a("p"),N_r=o("Examples:"),D_r=l(),f(U0.$$.fragment),j_r=l(),Co=a("div"),f(J0.$$.fragment),q_r=l(),zue=a("p"),G_r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),O_r=l(),En=a("p"),X_r=o("The model class to instantiate is selected based on the "),Wue=a("code"),V_r=o("model_type"),z_r=o(` property of the config object (either
passed as an argument or loaded from `),Que=a("code"),W_r=o("pretrained_model_name_or_path"),Q_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hue=a("code"),H_r=o("pretrained_model_name_or_path"),U_r=o(":"),J_r=l(),Uue=a("ul"),fC=a("li"),Jue=a("strong"),Y_r=o("tapas"),K_r=o(" \u2014 "),pX=a("a"),Z_r=o("TFTapasForQuestionAnswering"),eur=o(" (TAPAS model)"),our=l(),Yue=a("p"),rur=o("Examples:"),tur=l(),f(Y0.$$.fragment),kRe=l(),jc=a("h2"),mC=a("a"),Kue=a("span"),f(K0.$$.fragment),aur=l(),Zue=a("span"),nur=o("TFAutoModelForTokenClassification"),RRe=l(),Lr=a("div"),f(Z0.$$.fragment),sur=l(),qc=a("p"),lur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),e5e=a("code"),iur=o("from_pretrained()"),dur=o("class method or the "),o5e=a("code"),cur=o("from_config()"),fur=o(`class
method.`),mur=l(),eL=a("p"),gur=o("This class cannot be instantiated directly using "),r5e=a("code"),hur=o("__init__()"),pur=o(" (throws an error)."),_ur=l(),Ct=a("div"),f(oL.$$.fragment),uur=l(),t5e=a("p"),bur=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),vur=l(),Gc=a("p"),Tur=o(`Note:
Loading a model from its configuration file does `),a5e=a("strong"),Fur=o("not"),Cur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),n5e=a("code"),Mur=o("from_pretrained()"),Eur=o("to load the model weights."),yur=l(),s5e=a("p"),wur=o("Examples:"),Aur=l(),f(rL.$$.fragment),Lur=l(),Mo=a("div"),f(tL.$$.fragment),Bur=l(),l5e=a("p"),xur=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),kur=l(),yn=a("p"),Rur=o("The model class to instantiate is selected based on the "),i5e=a("code"),Sur=o("model_type"),Pur=o(` property of the config object (either
passed as an argument or loaded from `),d5e=a("code"),$ur=o("pretrained_model_name_or_path"),Iur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c5e=a("code"),Nur=o("pretrained_model_name_or_path"),Dur=o(":"),jur=l(),Y=a("ul"),gC=a("li"),f5e=a("strong"),qur=o("albert"),Gur=o(" \u2014 "),_X=a("a"),Our=o("TFAlbertForTokenClassification"),Xur=o(" (ALBERT model)"),Vur=l(),hC=a("li"),m5e=a("strong"),zur=o("bert"),Wur=o(" \u2014 "),uX=a("a"),Qur=o("TFBertForTokenClassification"),Hur=o(" (BERT model)"),Uur=l(),pC=a("li"),g5e=a("strong"),Jur=o("camembert"),Yur=o(" \u2014 "),bX=a("a"),Kur=o("TFCamembertForTokenClassification"),Zur=o(" (CamemBERT model)"),e5r=l(),_C=a("li"),h5e=a("strong"),o5r=o("convbert"),r5r=o(" \u2014 "),vX=a("a"),t5r=o("TFConvBertForTokenClassification"),a5r=o(" (ConvBERT model)"),n5r=l(),uC=a("li"),p5e=a("strong"),s5r=o("deberta"),l5r=o(" \u2014 "),TX=a("a"),i5r=o("TFDebertaForTokenClassification"),d5r=o(" (DeBERTa model)"),c5r=l(),bC=a("li"),_5e=a("strong"),f5r=o("deberta-v2"),m5r=o(" \u2014 "),FX=a("a"),g5r=o("TFDebertaV2ForTokenClassification"),h5r=o(" (DeBERTa-v2 model)"),p5r=l(),vC=a("li"),u5e=a("strong"),_5r=o("distilbert"),u5r=o(" \u2014 "),CX=a("a"),b5r=o("TFDistilBertForTokenClassification"),v5r=o(" (DistilBERT model)"),T5r=l(),TC=a("li"),b5e=a("strong"),F5r=o("electra"),C5r=o(" \u2014 "),MX=a("a"),M5r=o("TFElectraForTokenClassification"),E5r=o(" (ELECTRA model)"),y5r=l(),FC=a("li"),v5e=a("strong"),w5r=o("flaubert"),A5r=o(" \u2014 "),EX=a("a"),L5r=o("TFFlaubertForTokenClassification"),B5r=o(" (FlauBERT model)"),x5r=l(),CC=a("li"),T5e=a("strong"),k5r=o("funnel"),R5r=o(" \u2014 "),yX=a("a"),S5r=o("TFFunnelForTokenClassification"),P5r=o(" (Funnel Transformer model)"),$5r=l(),MC=a("li"),F5e=a("strong"),I5r=o("layoutlm"),N5r=o(" \u2014 "),wX=a("a"),D5r=o("TFLayoutLMForTokenClassification"),j5r=o(" (LayoutLM model)"),q5r=l(),EC=a("li"),C5e=a("strong"),G5r=o("longformer"),O5r=o(" \u2014 "),AX=a("a"),X5r=o("TFLongformerForTokenClassification"),V5r=o(" (Longformer model)"),z5r=l(),yC=a("li"),M5e=a("strong"),W5r=o("mobilebert"),Q5r=o(" \u2014 "),LX=a("a"),H5r=o("TFMobileBertForTokenClassification"),U5r=o(" (MobileBERT model)"),J5r=l(),wC=a("li"),E5e=a("strong"),Y5r=o("mpnet"),K5r=o(" \u2014 "),BX=a("a"),Z5r=o("TFMPNetForTokenClassification"),e2r=o(" (MPNet model)"),o2r=l(),AC=a("li"),y5e=a("strong"),r2r=o("rembert"),t2r=o(" \u2014 "),xX=a("a"),a2r=o("TFRemBertForTokenClassification"),n2r=o(" (RemBERT model)"),s2r=l(),LC=a("li"),w5e=a("strong"),l2r=o("roberta"),i2r=o(" \u2014 "),kX=a("a"),d2r=o("TFRobertaForTokenClassification"),c2r=o(" (RoBERTa model)"),f2r=l(),BC=a("li"),A5e=a("strong"),m2r=o("roformer"),g2r=o(" \u2014 "),RX=a("a"),h2r=o("TFRoFormerForTokenClassification"),p2r=o(" (RoFormer model)"),_2r=l(),xC=a("li"),L5e=a("strong"),u2r=o("xlm"),b2r=o(" \u2014 "),SX=a("a"),v2r=o("TFXLMForTokenClassification"),T2r=o(" (XLM model)"),F2r=l(),kC=a("li"),B5e=a("strong"),C2r=o("xlm-roberta"),M2r=o(" \u2014 "),PX=a("a"),E2r=o("TFXLMRobertaForTokenClassification"),y2r=o(" (XLM-RoBERTa model)"),w2r=l(),RC=a("li"),x5e=a("strong"),A2r=o("xlnet"),L2r=o(" \u2014 "),$X=a("a"),B2r=o("TFXLNetForTokenClassification"),x2r=o(" (XLNet model)"),k2r=l(),k5e=a("p"),R2r=o("Examples:"),S2r=l(),f(aL.$$.fragment),SRe=l(),Oc=a("h2"),SC=a("a"),R5e=a("span"),f(nL.$$.fragment),P2r=l(),S5e=a("span"),$2r=o("TFAutoModelForQuestionAnswering"),PRe=l(),Br=a("div"),f(sL.$$.fragment),I2r=l(),Xc=a("p"),N2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),P5e=a("code"),D2r=o("from_pretrained()"),j2r=o("class method or the "),$5e=a("code"),q2r=o("from_config()"),G2r=o(`class
method.`),O2r=l(),lL=a("p"),X2r=o("This class cannot be instantiated directly using "),I5e=a("code"),V2r=o("__init__()"),z2r=o(" (throws an error)."),W2r=l(),Mt=a("div"),f(iL.$$.fragment),Q2r=l(),N5e=a("p"),H2r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),U2r=l(),Vc=a("p"),J2r=o(`Note:
Loading a model from its configuration file does `),D5e=a("strong"),Y2r=o("not"),K2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),j5e=a("code"),Z2r=o("from_pretrained()"),e1r=o("to load the model weights."),o1r=l(),q5e=a("p"),r1r=o("Examples:"),t1r=l(),f(dL.$$.fragment),a1r=l(),Eo=a("div"),f(cL.$$.fragment),n1r=l(),G5e=a("p"),s1r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),l1r=l(),wn=a("p"),i1r=o("The model class to instantiate is selected based on the "),O5e=a("code"),d1r=o("model_type"),c1r=o(` property of the config object (either
passed as an argument or loaded from `),X5e=a("code"),f1r=o("pretrained_model_name_or_path"),m1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=a("code"),g1r=o("pretrained_model_name_or_path"),h1r=o(":"),p1r=l(),Z=a("ul"),PC=a("li"),z5e=a("strong"),_1r=o("albert"),u1r=o(" \u2014 "),IX=a("a"),b1r=o("TFAlbertForQuestionAnswering"),v1r=o(" (ALBERT model)"),T1r=l(),$C=a("li"),W5e=a("strong"),F1r=o("bert"),C1r=o(" \u2014 "),NX=a("a"),M1r=o("TFBertForQuestionAnswering"),E1r=o(" (BERT model)"),y1r=l(),IC=a("li"),Q5e=a("strong"),w1r=o("camembert"),A1r=o(" \u2014 "),DX=a("a"),L1r=o("TFCamembertForQuestionAnswering"),B1r=o(" (CamemBERT model)"),x1r=l(),NC=a("li"),H5e=a("strong"),k1r=o("convbert"),R1r=o(" \u2014 "),jX=a("a"),S1r=o("TFConvBertForQuestionAnswering"),P1r=o(" (ConvBERT model)"),$1r=l(),DC=a("li"),U5e=a("strong"),I1r=o("deberta"),N1r=o(" \u2014 "),qX=a("a"),D1r=o("TFDebertaForQuestionAnswering"),j1r=o(" (DeBERTa model)"),q1r=l(),jC=a("li"),J5e=a("strong"),G1r=o("deberta-v2"),O1r=o(" \u2014 "),GX=a("a"),X1r=o("TFDebertaV2ForQuestionAnswering"),V1r=o(" (DeBERTa-v2 model)"),z1r=l(),qC=a("li"),Y5e=a("strong"),W1r=o("distilbert"),Q1r=o(" \u2014 "),OX=a("a"),H1r=o("TFDistilBertForQuestionAnswering"),U1r=o(" (DistilBERT model)"),J1r=l(),GC=a("li"),K5e=a("strong"),Y1r=o("electra"),K1r=o(" \u2014 "),XX=a("a"),Z1r=o("TFElectraForQuestionAnswering"),ebr=o(" (ELECTRA model)"),obr=l(),OC=a("li"),Z5e=a("strong"),rbr=o("flaubert"),tbr=o(" \u2014 "),VX=a("a"),abr=o("TFFlaubertForQuestionAnsweringSimple"),nbr=o(" (FlauBERT model)"),sbr=l(),XC=a("li"),e2e=a("strong"),lbr=o("funnel"),ibr=o(" \u2014 "),zX=a("a"),dbr=o("TFFunnelForQuestionAnswering"),cbr=o(" (Funnel Transformer model)"),fbr=l(),VC=a("li"),o2e=a("strong"),mbr=o("longformer"),gbr=o(" \u2014 "),WX=a("a"),hbr=o("TFLongformerForQuestionAnswering"),pbr=o(" (Longformer model)"),_br=l(),zC=a("li"),r2e=a("strong"),ubr=o("mobilebert"),bbr=o(" \u2014 "),QX=a("a"),vbr=o("TFMobileBertForQuestionAnswering"),Tbr=o(" (MobileBERT model)"),Fbr=l(),WC=a("li"),t2e=a("strong"),Cbr=o("mpnet"),Mbr=o(" \u2014 "),HX=a("a"),Ebr=o("TFMPNetForQuestionAnswering"),ybr=o(" (MPNet model)"),wbr=l(),QC=a("li"),a2e=a("strong"),Abr=o("rembert"),Lbr=o(" \u2014 "),UX=a("a"),Bbr=o("TFRemBertForQuestionAnswering"),xbr=o(" (RemBERT model)"),kbr=l(),HC=a("li"),n2e=a("strong"),Rbr=o("roberta"),Sbr=o(" \u2014 "),JX=a("a"),Pbr=o("TFRobertaForQuestionAnswering"),$br=o(" (RoBERTa model)"),Ibr=l(),UC=a("li"),s2e=a("strong"),Nbr=o("roformer"),Dbr=o(" \u2014 "),YX=a("a"),jbr=o("TFRoFormerForQuestionAnswering"),qbr=o(" (RoFormer model)"),Gbr=l(),JC=a("li"),l2e=a("strong"),Obr=o("xlm"),Xbr=o(" \u2014 "),KX=a("a"),Vbr=o("TFXLMForQuestionAnsweringSimple"),zbr=o(" (XLM model)"),Wbr=l(),YC=a("li"),i2e=a("strong"),Qbr=o("xlm-roberta"),Hbr=o(" \u2014 "),ZX=a("a"),Ubr=o("TFXLMRobertaForQuestionAnswering"),Jbr=o(" (XLM-RoBERTa model)"),Ybr=l(),KC=a("li"),d2e=a("strong"),Kbr=o("xlnet"),Zbr=o(" \u2014 "),eV=a("a"),evr=o("TFXLNetForQuestionAnsweringSimple"),ovr=o(" (XLNet model)"),rvr=l(),c2e=a("p"),tvr=o("Examples:"),avr=l(),f(fL.$$.fragment),$Re=l(),zc=a("h2"),ZC=a("a"),f2e=a("span"),f(mL.$$.fragment),nvr=l(),m2e=a("span"),svr=o("TFAutoModelForVision2Seq"),IRe=l(),xr=a("div"),f(gL.$$.fragment),lvr=l(),Wc=a("p"),ivr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),g2e=a("code"),dvr=o("from_pretrained()"),cvr=o("class method or the "),h2e=a("code"),fvr=o("from_config()"),mvr=o(`class
method.`),gvr=l(),hL=a("p"),hvr=o("This class cannot be instantiated directly using "),p2e=a("code"),pvr=o("__init__()"),_vr=o(" (throws an error)."),uvr=l(),Et=a("div"),f(pL.$$.fragment),bvr=l(),_2e=a("p"),vvr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Tvr=l(),Qc=a("p"),Fvr=o(`Note:
Loading a model from its configuration file does `),u2e=a("strong"),Cvr=o("not"),Mvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),b2e=a("code"),Evr=o("from_pretrained()"),yvr=o("to load the model weights."),wvr=l(),v2e=a("p"),Avr=o("Examples:"),Lvr=l(),f(_L.$$.fragment),Bvr=l(),yo=a("div"),f(uL.$$.fragment),xvr=l(),T2e=a("p"),kvr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Rvr=l(),An=a("p"),Svr=o("The model class to instantiate is selected based on the "),F2e=a("code"),Pvr=o("model_type"),$vr=o(` property of the config object (either
passed as an argument or loaded from `),C2e=a("code"),Ivr=o("pretrained_model_name_or_path"),Nvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M2e=a("code"),Dvr=o("pretrained_model_name_or_path"),jvr=o(":"),qvr=l(),E2e=a("ul"),eM=a("li"),y2e=a("strong"),Gvr=o("vision-encoder-decoder"),Ovr=o(" \u2014 "),oV=a("a"),Xvr=o("TFVisionEncoderDecoderModel"),Vvr=o(" (Vision Encoder decoder model)"),zvr=l(),w2e=a("p"),Wvr=o("Examples:"),Qvr=l(),f(bL.$$.fragment),NRe=l(),Hc=a("h2"),oM=a("a"),A2e=a("span"),f(vL.$$.fragment),Hvr=l(),L2e=a("span"),Uvr=o("TFAutoModelForSpeechSeq2Seq"),DRe=l(),kr=a("div"),f(TL.$$.fragment),Jvr=l(),Uc=a("p"),Yvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),B2e=a("code"),Kvr=o("from_pretrained()"),Zvr=o("class method or the "),x2e=a("code"),e6r=o("from_config()"),o6r=o(`class
method.`),r6r=l(),FL=a("p"),t6r=o("This class cannot be instantiated directly using "),k2e=a("code"),a6r=o("__init__()"),n6r=o(" (throws an error)."),s6r=l(),yt=a("div"),f(CL.$$.fragment),l6r=l(),R2e=a("p"),i6r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),d6r=l(),Jc=a("p"),c6r=o(`Note:
Loading a model from its configuration file does `),S2e=a("strong"),f6r=o("not"),m6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),P2e=a("code"),g6r=o("from_pretrained()"),h6r=o("to load the model weights."),p6r=l(),$2e=a("p"),_6r=o("Examples:"),u6r=l(),f(ML.$$.fragment),b6r=l(),wo=a("div"),f(EL.$$.fragment),v6r=l(),I2e=a("p"),T6r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),F6r=l(),Ln=a("p"),C6r=o("The model class to instantiate is selected based on the "),N2e=a("code"),M6r=o("model_type"),E6r=o(` property of the config object (either
passed as an argument or loaded from `),D2e=a("code"),y6r=o("pretrained_model_name_or_path"),w6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j2e=a("code"),A6r=o("pretrained_model_name_or_path"),L6r=o(":"),B6r=l(),q2e=a("ul"),rM=a("li"),G2e=a("strong"),x6r=o("speech_to_text"),k6r=o(" \u2014 "),rV=a("a"),R6r=o("TFSpeech2TextForConditionalGeneration"),S6r=o(" (Speech2Text model)"),P6r=l(),O2e=a("p"),$6r=o("Examples:"),I6r=l(),f(yL.$$.fragment),jRe=l(),Yc=a("h2"),tM=a("a"),X2e=a("span"),f(wL.$$.fragment),N6r=l(),V2e=a("span"),D6r=o("FlaxAutoModel"),qRe=l(),Rr=a("div"),f(AL.$$.fragment),j6r=l(),Kc=a("p"),q6r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),z2e=a("code"),G6r=o("from_pretrained()"),O6r=o("class method or the "),W2e=a("code"),X6r=o("from_config()"),V6r=o(`class
method.`),z6r=l(),LL=a("p"),W6r=o("This class cannot be instantiated directly using "),Q2e=a("code"),Q6r=o("__init__()"),H6r=o(" (throws an error)."),U6r=l(),wt=a("div"),f(BL.$$.fragment),J6r=l(),H2e=a("p"),Y6r=o("Instantiates one of the base model classes of the library from a configuration."),K6r=l(),Zc=a("p"),Z6r=o(`Note:
Loading a model from its configuration file does `),U2e=a("strong"),eTr=o("not"),oTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),J2e=a("code"),rTr=o("from_pretrained()"),tTr=o("to load the model weights."),aTr=l(),Y2e=a("p"),nTr=o("Examples:"),sTr=l(),f(xL.$$.fragment),lTr=l(),Ao=a("div"),f(kL.$$.fragment),iTr=l(),K2e=a("p"),dTr=o("Instantiate one of the base model classes of the library from a pretrained model."),cTr=l(),Bn=a("p"),fTr=o("The model class to instantiate is selected based on the "),Z2e=a("code"),mTr=o("model_type"),gTr=o(` property of the config object (either
passed as an argument or loaded from `),e1e=a("code"),hTr=o("pretrained_model_name_or_path"),pTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=a("code"),_Tr=o("pretrained_model_name_or_path"),uTr=o(":"),bTr=l(),z=a("ul"),aM=a("li"),r1e=a("strong"),vTr=o("albert"),TTr=o(" \u2014 "),tV=a("a"),FTr=o("FlaxAlbertModel"),CTr=o(" (ALBERT model)"),MTr=l(),nM=a("li"),t1e=a("strong"),ETr=o("bart"),yTr=o(" \u2014 "),aV=a("a"),wTr=o("FlaxBartModel"),ATr=o(" (BART model)"),LTr=l(),sM=a("li"),a1e=a("strong"),BTr=o("beit"),xTr=o(" \u2014 "),nV=a("a"),kTr=o("FlaxBeitModel"),RTr=o(" (BEiT model)"),STr=l(),lM=a("li"),n1e=a("strong"),PTr=o("bert"),$Tr=o(" \u2014 "),sV=a("a"),ITr=o("FlaxBertModel"),NTr=o(" (BERT model)"),DTr=l(),iM=a("li"),s1e=a("strong"),jTr=o("big_bird"),qTr=o(" \u2014 "),lV=a("a"),GTr=o("FlaxBigBirdModel"),OTr=o(" (BigBird model)"),XTr=l(),dM=a("li"),l1e=a("strong"),VTr=o("blenderbot"),zTr=o(" \u2014 "),iV=a("a"),WTr=o("FlaxBlenderbotModel"),QTr=o(" (Blenderbot model)"),HTr=l(),cM=a("li"),i1e=a("strong"),UTr=o("blenderbot-small"),JTr=o(" \u2014 "),dV=a("a"),YTr=o("FlaxBlenderbotSmallModel"),KTr=o(" (BlenderbotSmall model)"),ZTr=l(),fM=a("li"),d1e=a("strong"),eFr=o("clip"),oFr=o(" \u2014 "),cV=a("a"),rFr=o("FlaxCLIPModel"),tFr=o(" (CLIP model)"),aFr=l(),mM=a("li"),c1e=a("strong"),nFr=o("distilbert"),sFr=o(" \u2014 "),fV=a("a"),lFr=o("FlaxDistilBertModel"),iFr=o(" (DistilBERT model)"),dFr=l(),gM=a("li"),f1e=a("strong"),cFr=o("electra"),fFr=o(" \u2014 "),mV=a("a"),mFr=o("FlaxElectraModel"),gFr=o(" (ELECTRA model)"),hFr=l(),hM=a("li"),m1e=a("strong"),pFr=o("gpt2"),_Fr=o(" \u2014 "),gV=a("a"),uFr=o("FlaxGPT2Model"),bFr=o(" (OpenAI GPT-2 model)"),vFr=l(),pM=a("li"),g1e=a("strong"),TFr=o("gpt_neo"),FFr=o(" \u2014 "),hV=a("a"),CFr=o("FlaxGPTNeoModel"),MFr=o(" (GPT Neo model)"),EFr=l(),_M=a("li"),h1e=a("strong"),yFr=o("gptj"),wFr=o(" \u2014 "),pV=a("a"),AFr=o("FlaxGPTJModel"),LFr=o(" (GPT-J model)"),BFr=l(),uM=a("li"),p1e=a("strong"),xFr=o("marian"),kFr=o(" \u2014 "),_V=a("a"),RFr=o("FlaxMarianModel"),SFr=o(" (Marian model)"),PFr=l(),bM=a("li"),_1e=a("strong"),$Fr=o("mbart"),IFr=o(" \u2014 "),uV=a("a"),NFr=o("FlaxMBartModel"),DFr=o(" (mBART model)"),jFr=l(),vM=a("li"),u1e=a("strong"),qFr=o("mt5"),GFr=o(" \u2014 "),bV=a("a"),OFr=o("FlaxMT5Model"),XFr=o(" (mT5 model)"),VFr=l(),TM=a("li"),b1e=a("strong"),zFr=o("pegasus"),WFr=o(" \u2014 "),vV=a("a"),QFr=o("FlaxPegasusModel"),HFr=o(" (Pegasus model)"),UFr=l(),FM=a("li"),v1e=a("strong"),JFr=o("roberta"),YFr=o(" \u2014 "),TV=a("a"),KFr=o("FlaxRobertaModel"),ZFr=o(" (RoBERTa model)"),eCr=l(),CM=a("li"),T1e=a("strong"),oCr=o("roformer"),rCr=o(" \u2014 "),FV=a("a"),tCr=o("FlaxRoFormerModel"),aCr=o(" (RoFormer model)"),nCr=l(),MM=a("li"),F1e=a("strong"),sCr=o("t5"),lCr=o(" \u2014 "),CV=a("a"),iCr=o("FlaxT5Model"),dCr=o(" (T5 model)"),cCr=l(),EM=a("li"),C1e=a("strong"),fCr=o("vision-text-dual-encoder"),mCr=o(" \u2014 "),MV=a("a"),gCr=o("FlaxVisionTextDualEncoderModel"),hCr=o(" (VisionTextDualEncoder model)"),pCr=l(),yM=a("li"),M1e=a("strong"),_Cr=o("vit"),uCr=o(" \u2014 "),EV=a("a"),bCr=o("FlaxViTModel"),vCr=o(" (ViT model)"),TCr=l(),wM=a("li"),E1e=a("strong"),FCr=o("wav2vec2"),CCr=o(" \u2014 "),yV=a("a"),MCr=o("FlaxWav2Vec2Model"),ECr=o(" (Wav2Vec2 model)"),yCr=l(),AM=a("li"),y1e=a("strong"),wCr=o("xglm"),ACr=o(" \u2014 "),wV=a("a"),LCr=o("FlaxXGLMModel"),BCr=o(" (XGLM model)"),xCr=l(),LM=a("li"),w1e=a("strong"),kCr=o("xlm-roberta"),RCr=o(" \u2014 "),AV=a("a"),SCr=o("FlaxXLMRobertaModel"),PCr=o(" (XLM-RoBERTa model)"),$Cr=l(),A1e=a("p"),ICr=o("Examples:"),NCr=l(),f(RL.$$.fragment),GRe=l(),ef=a("h2"),BM=a("a"),L1e=a("span"),f(SL.$$.fragment),DCr=l(),B1e=a("span"),jCr=o("FlaxAutoModelForCausalLM"),ORe=l(),Sr=a("div"),f(PL.$$.fragment),qCr=l(),of=a("p"),GCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),x1e=a("code"),OCr=o("from_pretrained()"),XCr=o("class method or the "),k1e=a("code"),VCr=o("from_config()"),zCr=o(`class
method.`),WCr=l(),$L=a("p"),QCr=o("This class cannot be instantiated directly using "),R1e=a("code"),HCr=o("__init__()"),UCr=o(" (throws an error)."),JCr=l(),At=a("div"),f(IL.$$.fragment),YCr=l(),S1e=a("p"),KCr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ZCr=l(),rf=a("p"),eMr=o(`Note:
Loading a model from its configuration file does `),P1e=a("strong"),oMr=o("not"),rMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$1e=a("code"),tMr=o("from_pretrained()"),aMr=o("to load the model weights."),nMr=l(),I1e=a("p"),sMr=o("Examples:"),lMr=l(),f(NL.$$.fragment),iMr=l(),Lo=a("div"),f(DL.$$.fragment),dMr=l(),N1e=a("p"),cMr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),fMr=l(),xn=a("p"),mMr=o("The model class to instantiate is selected based on the "),D1e=a("code"),gMr=o("model_type"),hMr=o(` property of the config object (either
passed as an argument or loaded from `),j1e=a("code"),pMr=o("pretrained_model_name_or_path"),_Mr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q1e=a("code"),uMr=o("pretrained_model_name_or_path"),bMr=o(":"),vMr=l(),ca=a("ul"),xM=a("li"),G1e=a("strong"),TMr=o("bart"),FMr=o(" \u2014 "),LV=a("a"),CMr=o("FlaxBartForCausalLM"),MMr=o(" (BART model)"),EMr=l(),kM=a("li"),O1e=a("strong"),yMr=o("gpt2"),wMr=o(" \u2014 "),BV=a("a"),AMr=o("FlaxGPT2LMHeadModel"),LMr=o(" (OpenAI GPT-2 model)"),BMr=l(),RM=a("li"),X1e=a("strong"),xMr=o("gpt_neo"),kMr=o(" \u2014 "),xV=a("a"),RMr=o("FlaxGPTNeoForCausalLM"),SMr=o(" (GPT Neo model)"),PMr=l(),SM=a("li"),V1e=a("strong"),$Mr=o("gptj"),IMr=o(" \u2014 "),kV=a("a"),NMr=o("FlaxGPTJForCausalLM"),DMr=o(" (GPT-J model)"),jMr=l(),PM=a("li"),z1e=a("strong"),qMr=o("xglm"),GMr=o(" \u2014 "),RV=a("a"),OMr=o("FlaxXGLMForCausalLM"),XMr=o(" (XGLM model)"),VMr=l(),W1e=a("p"),zMr=o("Examples:"),WMr=l(),f(jL.$$.fragment),XRe=l(),tf=a("h2"),$M=a("a"),Q1e=a("span"),f(qL.$$.fragment),QMr=l(),H1e=a("span"),HMr=o("FlaxAutoModelForPreTraining"),VRe=l(),Pr=a("div"),f(GL.$$.fragment),UMr=l(),af=a("p"),JMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),U1e=a("code"),YMr=o("from_pretrained()"),KMr=o("class method or the "),J1e=a("code"),ZMr=o("from_config()"),e4r=o(`class
method.`),o4r=l(),OL=a("p"),r4r=o("This class cannot be instantiated directly using "),Y1e=a("code"),t4r=o("__init__()"),a4r=o(" (throws an error)."),n4r=l(),Lt=a("div"),f(XL.$$.fragment),s4r=l(),K1e=a("p"),l4r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),i4r=l(),nf=a("p"),d4r=o(`Note:
Loading a model from its configuration file does `),Z1e=a("strong"),c4r=o("not"),f4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ebe=a("code"),m4r=o("from_pretrained()"),g4r=o("to load the model weights."),h4r=l(),obe=a("p"),p4r=o("Examples:"),_4r=l(),f(VL.$$.fragment),u4r=l(),Bo=a("div"),f(zL.$$.fragment),b4r=l(),rbe=a("p"),v4r=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),T4r=l(),kn=a("p"),F4r=o("The model class to instantiate is selected based on the "),tbe=a("code"),C4r=o("model_type"),M4r=o(` property of the config object (either
passed as an argument or loaded from `),abe=a("code"),E4r=o("pretrained_model_name_or_path"),y4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=a("code"),w4r=o("pretrained_model_name_or_path"),A4r=o(":"),L4r=l(),ce=a("ul"),IM=a("li"),sbe=a("strong"),B4r=o("albert"),x4r=o(" \u2014 "),SV=a("a"),k4r=o("FlaxAlbertForPreTraining"),R4r=o(" (ALBERT model)"),S4r=l(),NM=a("li"),lbe=a("strong"),P4r=o("bart"),$4r=o(" \u2014 "),PV=a("a"),I4r=o("FlaxBartForConditionalGeneration"),N4r=o(" (BART model)"),D4r=l(),DM=a("li"),ibe=a("strong"),j4r=o("bert"),q4r=o(" \u2014 "),$V=a("a"),G4r=o("FlaxBertForPreTraining"),O4r=o(" (BERT model)"),X4r=l(),jM=a("li"),dbe=a("strong"),V4r=o("big_bird"),z4r=o(" \u2014 "),IV=a("a"),W4r=o("FlaxBigBirdForPreTraining"),Q4r=o(" (BigBird model)"),H4r=l(),qM=a("li"),cbe=a("strong"),U4r=o("electra"),J4r=o(" \u2014 "),NV=a("a"),Y4r=o("FlaxElectraForPreTraining"),K4r=o(" (ELECTRA model)"),Z4r=l(),GM=a("li"),fbe=a("strong"),eEr=o("mbart"),oEr=o(" \u2014 "),DV=a("a"),rEr=o("FlaxMBartForConditionalGeneration"),tEr=o(" (mBART model)"),aEr=l(),OM=a("li"),mbe=a("strong"),nEr=o("mt5"),sEr=o(" \u2014 "),jV=a("a"),lEr=o("FlaxMT5ForConditionalGeneration"),iEr=o(" (mT5 model)"),dEr=l(),XM=a("li"),gbe=a("strong"),cEr=o("roberta"),fEr=o(" \u2014 "),qV=a("a"),mEr=o("FlaxRobertaForMaskedLM"),gEr=o(" (RoBERTa model)"),hEr=l(),VM=a("li"),hbe=a("strong"),pEr=o("roformer"),_Er=o(" \u2014 "),GV=a("a"),uEr=o("FlaxRoFormerForMaskedLM"),bEr=o(" (RoFormer model)"),vEr=l(),zM=a("li"),pbe=a("strong"),TEr=o("t5"),FEr=o(" \u2014 "),OV=a("a"),CEr=o("FlaxT5ForConditionalGeneration"),MEr=o(" (T5 model)"),EEr=l(),WM=a("li"),_be=a("strong"),yEr=o("wav2vec2"),wEr=o(" \u2014 "),XV=a("a"),AEr=o("FlaxWav2Vec2ForPreTraining"),LEr=o(" (Wav2Vec2 model)"),BEr=l(),QM=a("li"),ube=a("strong"),xEr=o("xlm-roberta"),kEr=o(" \u2014 "),VV=a("a"),REr=o("FlaxXLMRobertaForMaskedLM"),SEr=o(" (XLM-RoBERTa model)"),PEr=l(),bbe=a("p"),$Er=o("Examples:"),IEr=l(),f(WL.$$.fragment),zRe=l(),sf=a("h2"),HM=a("a"),vbe=a("span"),f(QL.$$.fragment),NEr=l(),Tbe=a("span"),DEr=o("FlaxAutoModelForMaskedLM"),WRe=l(),$r=a("div"),f(HL.$$.fragment),jEr=l(),lf=a("p"),qEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fbe=a("code"),GEr=o("from_pretrained()"),OEr=o("class method or the "),Cbe=a("code"),XEr=o("from_config()"),VEr=o(`class
method.`),zEr=l(),UL=a("p"),WEr=o("This class cannot be instantiated directly using "),Mbe=a("code"),QEr=o("__init__()"),HEr=o(" (throws an error)."),UEr=l(),Bt=a("div"),f(JL.$$.fragment),JEr=l(),Ebe=a("p"),YEr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),KEr=l(),df=a("p"),ZEr=o(`Note:
Loading a model from its configuration file does `),ybe=a("strong"),e3r=o("not"),o3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wbe=a("code"),r3r=o("from_pretrained()"),t3r=o("to load the model weights."),a3r=l(),Abe=a("p"),n3r=o("Examples:"),s3r=l(),f(YL.$$.fragment),l3r=l(),xo=a("div"),f(KL.$$.fragment),i3r=l(),Lbe=a("p"),d3r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),c3r=l(),Rn=a("p"),f3r=o("The model class to instantiate is selected based on the "),Bbe=a("code"),m3r=o("model_type"),g3r=o(` property of the config object (either
passed as an argument or loaded from `),xbe=a("code"),h3r=o("pretrained_model_name_or_path"),p3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kbe=a("code"),_3r=o("pretrained_model_name_or_path"),u3r=o(":"),b3r=l(),ue=a("ul"),UM=a("li"),Rbe=a("strong"),v3r=o("albert"),T3r=o(" \u2014 "),zV=a("a"),F3r=o("FlaxAlbertForMaskedLM"),C3r=o(" (ALBERT model)"),M3r=l(),JM=a("li"),Sbe=a("strong"),E3r=o("bart"),y3r=o(" \u2014 "),WV=a("a"),w3r=o("FlaxBartForConditionalGeneration"),A3r=o(" (BART model)"),L3r=l(),YM=a("li"),Pbe=a("strong"),B3r=o("bert"),x3r=o(" \u2014 "),QV=a("a"),k3r=o("FlaxBertForMaskedLM"),R3r=o(" (BERT model)"),S3r=l(),KM=a("li"),$be=a("strong"),P3r=o("big_bird"),$3r=o(" \u2014 "),HV=a("a"),I3r=o("FlaxBigBirdForMaskedLM"),N3r=o(" (BigBird model)"),D3r=l(),ZM=a("li"),Ibe=a("strong"),j3r=o("distilbert"),q3r=o(" \u2014 "),UV=a("a"),G3r=o("FlaxDistilBertForMaskedLM"),O3r=o(" (DistilBERT model)"),X3r=l(),e4=a("li"),Nbe=a("strong"),V3r=o("electra"),z3r=o(" \u2014 "),JV=a("a"),W3r=o("FlaxElectraForMaskedLM"),Q3r=o(" (ELECTRA model)"),H3r=l(),o4=a("li"),Dbe=a("strong"),U3r=o("mbart"),J3r=o(" \u2014 "),YV=a("a"),Y3r=o("FlaxMBartForConditionalGeneration"),K3r=o(" (mBART model)"),Z3r=l(),r4=a("li"),jbe=a("strong"),eyr=o("roberta"),oyr=o(" \u2014 "),KV=a("a"),ryr=o("FlaxRobertaForMaskedLM"),tyr=o(" (RoBERTa model)"),ayr=l(),t4=a("li"),qbe=a("strong"),nyr=o("roformer"),syr=o(" \u2014 "),ZV=a("a"),lyr=o("FlaxRoFormerForMaskedLM"),iyr=o(" (RoFormer model)"),dyr=l(),a4=a("li"),Gbe=a("strong"),cyr=o("xlm-roberta"),fyr=o(" \u2014 "),ez=a("a"),myr=o("FlaxXLMRobertaForMaskedLM"),gyr=o(" (XLM-RoBERTa model)"),hyr=l(),Obe=a("p"),pyr=o("Examples:"),_yr=l(),f(ZL.$$.fragment),QRe=l(),cf=a("h2"),n4=a("a"),Xbe=a("span"),f(e7.$$.fragment),uyr=l(),Vbe=a("span"),byr=o("FlaxAutoModelForSeq2SeqLM"),HRe=l(),Ir=a("div"),f(o7.$$.fragment),vyr=l(),ff=a("p"),Tyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zbe=a("code"),Fyr=o("from_pretrained()"),Cyr=o("class method or the "),Wbe=a("code"),Myr=o("from_config()"),Eyr=o(`class
method.`),yyr=l(),r7=a("p"),wyr=o("This class cannot be instantiated directly using "),Qbe=a("code"),Ayr=o("__init__()"),Lyr=o(" (throws an error)."),Byr=l(),xt=a("div"),f(t7.$$.fragment),xyr=l(),Hbe=a("p"),kyr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Ryr=l(),mf=a("p"),Syr=o(`Note:
Loading a model from its configuration file does `),Ube=a("strong"),Pyr=o("not"),$yr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jbe=a("code"),Iyr=o("from_pretrained()"),Nyr=o("to load the model weights."),Dyr=l(),Ybe=a("p"),jyr=o("Examples:"),qyr=l(),f(a7.$$.fragment),Gyr=l(),ko=a("div"),f(n7.$$.fragment),Oyr=l(),Kbe=a("p"),Xyr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Vyr=l(),Sn=a("p"),zyr=o("The model class to instantiate is selected based on the "),Zbe=a("code"),Wyr=o("model_type"),Qyr=o(` property of the config object (either
passed as an argument or loaded from `),eve=a("code"),Hyr=o("pretrained_model_name_or_path"),Uyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ove=a("code"),Jyr=o("pretrained_model_name_or_path"),Yyr=o(":"),Kyr=l(),Me=a("ul"),s4=a("li"),rve=a("strong"),Zyr=o("bart"),ewr=o(" \u2014 "),oz=a("a"),owr=o("FlaxBartForConditionalGeneration"),rwr=o(" (BART model)"),twr=l(),l4=a("li"),tve=a("strong"),awr=o("blenderbot"),nwr=o(" \u2014 "),rz=a("a"),swr=o("FlaxBlenderbotForConditionalGeneration"),lwr=o(" (Blenderbot model)"),iwr=l(),i4=a("li"),ave=a("strong"),dwr=o("blenderbot-small"),cwr=o(" \u2014 "),tz=a("a"),fwr=o("FlaxBlenderbotSmallForConditionalGeneration"),mwr=o(" (BlenderbotSmall model)"),gwr=l(),d4=a("li"),nve=a("strong"),hwr=o("encoder-decoder"),pwr=o(" \u2014 "),az=a("a"),_wr=o("FlaxEncoderDecoderModel"),uwr=o(" (Encoder decoder model)"),bwr=l(),c4=a("li"),sve=a("strong"),vwr=o("marian"),Twr=o(" \u2014 "),nz=a("a"),Fwr=o("FlaxMarianMTModel"),Cwr=o(" (Marian model)"),Mwr=l(),f4=a("li"),lve=a("strong"),Ewr=o("mbart"),ywr=o(" \u2014 "),sz=a("a"),wwr=o("FlaxMBartForConditionalGeneration"),Awr=o(" (mBART model)"),Lwr=l(),m4=a("li"),ive=a("strong"),Bwr=o("mt5"),xwr=o(" \u2014 "),lz=a("a"),kwr=o("FlaxMT5ForConditionalGeneration"),Rwr=o(" (mT5 model)"),Swr=l(),g4=a("li"),dve=a("strong"),Pwr=o("pegasus"),$wr=o(" \u2014 "),iz=a("a"),Iwr=o("FlaxPegasusForConditionalGeneration"),Nwr=o(" (Pegasus model)"),Dwr=l(),h4=a("li"),cve=a("strong"),jwr=o("t5"),qwr=o(" \u2014 "),dz=a("a"),Gwr=o("FlaxT5ForConditionalGeneration"),Owr=o(" (T5 model)"),Xwr=l(),fve=a("p"),Vwr=o("Examples:"),zwr=l(),f(s7.$$.fragment),URe=l(),gf=a("h2"),p4=a("a"),mve=a("span"),f(l7.$$.fragment),Wwr=l(),gve=a("span"),Qwr=o("FlaxAutoModelForSequenceClassification"),JRe=l(),Nr=a("div"),f(i7.$$.fragment),Hwr=l(),hf=a("p"),Uwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hve=a("code"),Jwr=o("from_pretrained()"),Ywr=o("class method or the "),pve=a("code"),Kwr=o("from_config()"),Zwr=o(`class
method.`),eAr=l(),d7=a("p"),oAr=o("This class cannot be instantiated directly using "),_ve=a("code"),rAr=o("__init__()"),tAr=o(" (throws an error)."),aAr=l(),kt=a("div"),f(c7.$$.fragment),nAr=l(),uve=a("p"),sAr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lAr=l(),pf=a("p"),iAr=o(`Note:
Loading a model from its configuration file does `),bve=a("strong"),dAr=o("not"),cAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vve=a("code"),fAr=o("from_pretrained()"),mAr=o("to load the model weights."),gAr=l(),Tve=a("p"),hAr=o("Examples:"),pAr=l(),f(f7.$$.fragment),_Ar=l(),Ro=a("div"),f(m7.$$.fragment),uAr=l(),Fve=a("p"),bAr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),vAr=l(),Pn=a("p"),TAr=o("The model class to instantiate is selected based on the "),Cve=a("code"),FAr=o("model_type"),CAr=o(` property of the config object (either
passed as an argument or loaded from `),Mve=a("code"),MAr=o("pretrained_model_name_or_path"),EAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Eve=a("code"),yAr=o("pretrained_model_name_or_path"),wAr=o(":"),AAr=l(),be=a("ul"),_4=a("li"),yve=a("strong"),LAr=o("albert"),BAr=o(" \u2014 "),cz=a("a"),xAr=o("FlaxAlbertForSequenceClassification"),kAr=o(" (ALBERT model)"),RAr=l(),u4=a("li"),wve=a("strong"),SAr=o("bart"),PAr=o(" \u2014 "),fz=a("a"),$Ar=o("FlaxBartForSequenceClassification"),IAr=o(" (BART model)"),NAr=l(),b4=a("li"),Ave=a("strong"),DAr=o("bert"),jAr=o(" \u2014 "),mz=a("a"),qAr=o("FlaxBertForSequenceClassification"),GAr=o(" (BERT model)"),OAr=l(),v4=a("li"),Lve=a("strong"),XAr=o("big_bird"),VAr=o(" \u2014 "),gz=a("a"),zAr=o("FlaxBigBirdForSequenceClassification"),WAr=o(" (BigBird model)"),QAr=l(),T4=a("li"),Bve=a("strong"),HAr=o("distilbert"),UAr=o(" \u2014 "),hz=a("a"),JAr=o("FlaxDistilBertForSequenceClassification"),YAr=o(" (DistilBERT model)"),KAr=l(),F4=a("li"),xve=a("strong"),ZAr=o("electra"),e0r=o(" \u2014 "),pz=a("a"),o0r=o("FlaxElectraForSequenceClassification"),r0r=o(" (ELECTRA model)"),t0r=l(),C4=a("li"),kve=a("strong"),a0r=o("mbart"),n0r=o(" \u2014 "),_z=a("a"),s0r=o("FlaxMBartForSequenceClassification"),l0r=o(" (mBART model)"),i0r=l(),M4=a("li"),Rve=a("strong"),d0r=o("roberta"),c0r=o(" \u2014 "),uz=a("a"),f0r=o("FlaxRobertaForSequenceClassification"),m0r=o(" (RoBERTa model)"),g0r=l(),E4=a("li"),Sve=a("strong"),h0r=o("roformer"),p0r=o(" \u2014 "),bz=a("a"),_0r=o("FlaxRoFormerForSequenceClassification"),u0r=o(" (RoFormer model)"),b0r=l(),y4=a("li"),Pve=a("strong"),v0r=o("xlm-roberta"),T0r=o(" \u2014 "),vz=a("a"),F0r=o("FlaxXLMRobertaForSequenceClassification"),C0r=o(" (XLM-RoBERTa model)"),M0r=l(),$ve=a("p"),E0r=o("Examples:"),y0r=l(),f(g7.$$.fragment),YRe=l(),_f=a("h2"),w4=a("a"),Ive=a("span"),f(h7.$$.fragment),w0r=l(),Nve=a("span"),A0r=o("FlaxAutoModelForQuestionAnswering"),KRe=l(),Dr=a("div"),f(p7.$$.fragment),L0r=l(),uf=a("p"),B0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dve=a("code"),x0r=o("from_pretrained()"),k0r=o("class method or the "),jve=a("code"),R0r=o("from_config()"),S0r=o(`class
method.`),P0r=l(),_7=a("p"),$0r=o("This class cannot be instantiated directly using "),qve=a("code"),I0r=o("__init__()"),N0r=o(" (throws an error)."),D0r=l(),Rt=a("div"),f(u7.$$.fragment),j0r=l(),Gve=a("p"),q0r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),G0r=l(),bf=a("p"),O0r=o(`Note:
Loading a model from its configuration file does `),Ove=a("strong"),X0r=o("not"),V0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xve=a("code"),z0r=o("from_pretrained()"),W0r=o("to load the model weights."),Q0r=l(),Vve=a("p"),H0r=o("Examples:"),U0r=l(),f(b7.$$.fragment),J0r=l(),So=a("div"),f(v7.$$.fragment),Y0r=l(),zve=a("p"),K0r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Z0r=l(),$n=a("p"),eLr=o("The model class to instantiate is selected based on the "),Wve=a("code"),oLr=o("model_type"),rLr=o(` property of the config object (either
passed as an argument or loaded from `),Qve=a("code"),tLr=o("pretrained_model_name_or_path"),aLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hve=a("code"),nLr=o("pretrained_model_name_or_path"),sLr=o(":"),lLr=l(),ve=a("ul"),A4=a("li"),Uve=a("strong"),iLr=o("albert"),dLr=o(" \u2014 "),Tz=a("a"),cLr=o("FlaxAlbertForQuestionAnswering"),fLr=o(" (ALBERT model)"),mLr=l(),L4=a("li"),Jve=a("strong"),gLr=o("bart"),hLr=o(" \u2014 "),Fz=a("a"),pLr=o("FlaxBartForQuestionAnswering"),_Lr=o(" (BART model)"),uLr=l(),B4=a("li"),Yve=a("strong"),bLr=o("bert"),vLr=o(" \u2014 "),Cz=a("a"),TLr=o("FlaxBertForQuestionAnswering"),FLr=o(" (BERT model)"),CLr=l(),x4=a("li"),Kve=a("strong"),MLr=o("big_bird"),ELr=o(" \u2014 "),Mz=a("a"),yLr=o("FlaxBigBirdForQuestionAnswering"),wLr=o(" (BigBird model)"),ALr=l(),k4=a("li"),Zve=a("strong"),LLr=o("distilbert"),BLr=o(" \u2014 "),Ez=a("a"),xLr=o("FlaxDistilBertForQuestionAnswering"),kLr=o(" (DistilBERT model)"),RLr=l(),R4=a("li"),e6e=a("strong"),SLr=o("electra"),PLr=o(" \u2014 "),yz=a("a"),$Lr=o("FlaxElectraForQuestionAnswering"),ILr=o(" (ELECTRA model)"),NLr=l(),S4=a("li"),o6e=a("strong"),DLr=o("mbart"),jLr=o(" \u2014 "),wz=a("a"),qLr=o("FlaxMBartForQuestionAnswering"),GLr=o(" (mBART model)"),OLr=l(),P4=a("li"),r6e=a("strong"),XLr=o("roberta"),VLr=o(" \u2014 "),Az=a("a"),zLr=o("FlaxRobertaForQuestionAnswering"),WLr=o(" (RoBERTa model)"),QLr=l(),$4=a("li"),t6e=a("strong"),HLr=o("roformer"),ULr=o(" \u2014 "),Lz=a("a"),JLr=o("FlaxRoFormerForQuestionAnswering"),YLr=o(" (RoFormer model)"),KLr=l(),I4=a("li"),a6e=a("strong"),ZLr=o("xlm-roberta"),e7r=o(" \u2014 "),Bz=a("a"),o7r=o("FlaxXLMRobertaForQuestionAnswering"),r7r=o(" (XLM-RoBERTa model)"),t7r=l(),n6e=a("p"),a7r=o("Examples:"),n7r=l(),f(T7.$$.fragment),ZRe=l(),vf=a("h2"),N4=a("a"),s6e=a("span"),f(F7.$$.fragment),s7r=l(),l6e=a("span"),l7r=o("FlaxAutoModelForTokenClassification"),eSe=l(),jr=a("div"),f(C7.$$.fragment),i7r=l(),Tf=a("p"),d7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),i6e=a("code"),c7r=o("from_pretrained()"),f7r=o("class method or the "),d6e=a("code"),m7r=o("from_config()"),g7r=o(`class
method.`),h7r=l(),M7=a("p"),p7r=o("This class cannot be instantiated directly using "),c6e=a("code"),_7r=o("__init__()"),u7r=o(" (throws an error)."),b7r=l(),St=a("div"),f(E7.$$.fragment),v7r=l(),f6e=a("p"),T7r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),F7r=l(),Ff=a("p"),C7r=o(`Note:
Loading a model from its configuration file does `),m6e=a("strong"),M7r=o("not"),E7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),g6e=a("code"),y7r=o("from_pretrained()"),w7r=o("to load the model weights."),A7r=l(),h6e=a("p"),L7r=o("Examples:"),B7r=l(),f(y7.$$.fragment),x7r=l(),Po=a("div"),f(w7.$$.fragment),k7r=l(),p6e=a("p"),R7r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),S7r=l(),In=a("p"),P7r=o("The model class to instantiate is selected based on the "),_6e=a("code"),$7r=o("model_type"),I7r=o(` property of the config object (either
passed as an argument or loaded from `),u6e=a("code"),N7r=o("pretrained_model_name_or_path"),D7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b6e=a("code"),j7r=o("pretrained_model_name_or_path"),q7r=o(":"),G7r=l(),Se=a("ul"),D4=a("li"),v6e=a("strong"),O7r=o("albert"),X7r=o(" \u2014 "),xz=a("a"),V7r=o("FlaxAlbertForTokenClassification"),z7r=o(" (ALBERT model)"),W7r=l(),j4=a("li"),T6e=a("strong"),Q7r=o("bert"),H7r=o(" \u2014 "),kz=a("a"),U7r=o("FlaxBertForTokenClassification"),J7r=o(" (BERT model)"),Y7r=l(),q4=a("li"),F6e=a("strong"),K7r=o("big_bird"),Z7r=o(" \u2014 "),Rz=a("a"),e8r=o("FlaxBigBirdForTokenClassification"),o8r=o(" (BigBird model)"),r8r=l(),G4=a("li"),C6e=a("strong"),t8r=o("distilbert"),a8r=o(" \u2014 "),Sz=a("a"),n8r=o("FlaxDistilBertForTokenClassification"),s8r=o(" (DistilBERT model)"),l8r=l(),O4=a("li"),M6e=a("strong"),i8r=o("electra"),d8r=o(" \u2014 "),Pz=a("a"),c8r=o("FlaxElectraForTokenClassification"),f8r=o(" (ELECTRA model)"),m8r=l(),X4=a("li"),E6e=a("strong"),g8r=o("roberta"),h8r=o(" \u2014 "),$z=a("a"),p8r=o("FlaxRobertaForTokenClassification"),_8r=o(" (RoBERTa model)"),u8r=l(),V4=a("li"),y6e=a("strong"),b8r=o("roformer"),v8r=o(" \u2014 "),Iz=a("a"),T8r=o("FlaxRoFormerForTokenClassification"),F8r=o(" (RoFormer model)"),C8r=l(),z4=a("li"),w6e=a("strong"),M8r=o("xlm-roberta"),E8r=o(" \u2014 "),Nz=a("a"),y8r=o("FlaxXLMRobertaForTokenClassification"),w8r=o(" (XLM-RoBERTa model)"),A8r=l(),A6e=a("p"),L8r=o("Examples:"),B8r=l(),f(A7.$$.fragment),oSe=l(),Cf=a("h2"),W4=a("a"),L6e=a("span"),f(L7.$$.fragment),x8r=l(),B6e=a("span"),k8r=o("FlaxAutoModelForMultipleChoice"),rSe=l(),qr=a("div"),f(B7.$$.fragment),R8r=l(),Mf=a("p"),S8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),x6e=a("code"),P8r=o("from_pretrained()"),$8r=o("class method or the "),k6e=a("code"),I8r=o("from_config()"),N8r=o(`class
method.`),D8r=l(),x7=a("p"),j8r=o("This class cannot be instantiated directly using "),R6e=a("code"),q8r=o("__init__()"),G8r=o(" (throws an error)."),O8r=l(),Pt=a("div"),f(k7.$$.fragment),X8r=l(),S6e=a("p"),V8r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),z8r=l(),Ef=a("p"),W8r=o(`Note:
Loading a model from its configuration file does `),P6e=a("strong"),Q8r=o("not"),H8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$6e=a("code"),U8r=o("from_pretrained()"),J8r=o("to load the model weights."),Y8r=l(),I6e=a("p"),K8r=o("Examples:"),Z8r=l(),f(R7.$$.fragment),e9r=l(),$o=a("div"),f(S7.$$.fragment),o9r=l(),N6e=a("p"),r9r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),t9r=l(),Nn=a("p"),a9r=o("The model class to instantiate is selected based on the "),D6e=a("code"),n9r=o("model_type"),s9r=o(` property of the config object (either
passed as an argument or loaded from `),j6e=a("code"),l9r=o("pretrained_model_name_or_path"),i9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q6e=a("code"),d9r=o("pretrained_model_name_or_path"),c9r=o(":"),f9r=l(),Pe=a("ul"),Q4=a("li"),G6e=a("strong"),m9r=o("albert"),g9r=o(" \u2014 "),Dz=a("a"),h9r=o("FlaxAlbertForMultipleChoice"),p9r=o(" (ALBERT model)"),_9r=l(),H4=a("li"),O6e=a("strong"),u9r=o("bert"),b9r=o(" \u2014 "),jz=a("a"),v9r=o("FlaxBertForMultipleChoice"),T9r=o(" (BERT model)"),F9r=l(),U4=a("li"),X6e=a("strong"),C9r=o("big_bird"),M9r=o(" \u2014 "),qz=a("a"),E9r=o("FlaxBigBirdForMultipleChoice"),y9r=o(" (BigBird model)"),w9r=l(),J4=a("li"),V6e=a("strong"),A9r=o("distilbert"),L9r=o(" \u2014 "),Gz=a("a"),B9r=o("FlaxDistilBertForMultipleChoice"),x9r=o(" (DistilBERT model)"),k9r=l(),Y4=a("li"),z6e=a("strong"),R9r=o("electra"),S9r=o(" \u2014 "),Oz=a("a"),P9r=o("FlaxElectraForMultipleChoice"),$9r=o(" (ELECTRA model)"),I9r=l(),K4=a("li"),W6e=a("strong"),N9r=o("roberta"),D9r=o(" \u2014 "),Xz=a("a"),j9r=o("FlaxRobertaForMultipleChoice"),q9r=o(" (RoBERTa model)"),G9r=l(),Z4=a("li"),Q6e=a("strong"),O9r=o("roformer"),X9r=o(" \u2014 "),Vz=a("a"),V9r=o("FlaxRoFormerForMultipleChoice"),z9r=o(" (RoFormer model)"),W9r=l(),eE=a("li"),H6e=a("strong"),Q9r=o("xlm-roberta"),H9r=o(" \u2014 "),zz=a("a"),U9r=o("FlaxXLMRobertaForMultipleChoice"),J9r=o(" (XLM-RoBERTa model)"),Y9r=l(),U6e=a("p"),K9r=o("Examples:"),Z9r=l(),f(P7.$$.fragment),tSe=l(),yf=a("h2"),oE=a("a"),J6e=a("span"),f($7.$$.fragment),eBr=l(),Y6e=a("span"),oBr=o("FlaxAutoModelForNextSentencePrediction"),aSe=l(),Gr=a("div"),f(I7.$$.fragment),rBr=l(),wf=a("p"),tBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),K6e=a("code"),aBr=o("from_pretrained()"),nBr=o("class method or the "),Z6e=a("code"),sBr=o("from_config()"),lBr=o(`class
method.`),iBr=l(),N7=a("p"),dBr=o("This class cannot be instantiated directly using "),eTe=a("code"),cBr=o("__init__()"),fBr=o(" (throws an error)."),mBr=l(),$t=a("div"),f(D7.$$.fragment),gBr=l(),oTe=a("p"),hBr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),pBr=l(),Af=a("p"),_Br=o(`Note:
Loading a model from its configuration file does `),rTe=a("strong"),uBr=o("not"),bBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tTe=a("code"),vBr=o("from_pretrained()"),TBr=o("to load the model weights."),FBr=l(),aTe=a("p"),CBr=o("Examples:"),MBr=l(),f(j7.$$.fragment),EBr=l(),Io=a("div"),f(q7.$$.fragment),yBr=l(),nTe=a("p"),wBr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),ABr=l(),Dn=a("p"),LBr=o("The model class to instantiate is selected based on the "),sTe=a("code"),BBr=o("model_type"),xBr=o(` property of the config object (either
passed as an argument or loaded from `),lTe=a("code"),kBr=o("pretrained_model_name_or_path"),RBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=a("code"),SBr=o("pretrained_model_name_or_path"),PBr=o(":"),$Br=l(),dTe=a("ul"),rE=a("li"),cTe=a("strong"),IBr=o("bert"),NBr=o(" \u2014 "),Wz=a("a"),DBr=o("FlaxBertForNextSentencePrediction"),jBr=o(" (BERT model)"),qBr=l(),fTe=a("p"),GBr=o("Examples:"),OBr=l(),f(G7.$$.fragment),nSe=l(),Lf=a("h2"),tE=a("a"),mTe=a("span"),f(O7.$$.fragment),XBr=l(),gTe=a("span"),VBr=o("FlaxAutoModelForImageClassification"),sSe=l(),Or=a("div"),f(X7.$$.fragment),zBr=l(),Bf=a("p"),WBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hTe=a("code"),QBr=o("from_pretrained()"),HBr=o("class method or the "),pTe=a("code"),UBr=o("from_config()"),JBr=o(`class
method.`),YBr=l(),V7=a("p"),KBr=o("This class cannot be instantiated directly using "),_Te=a("code"),ZBr=o("__init__()"),exr=o(" (throws an error)."),oxr=l(),It=a("div"),f(z7.$$.fragment),rxr=l(),uTe=a("p"),txr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),axr=l(),xf=a("p"),nxr=o(`Note:
Loading a model from its configuration file does `),bTe=a("strong"),sxr=o("not"),lxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vTe=a("code"),ixr=o("from_pretrained()"),dxr=o("to load the model weights."),cxr=l(),TTe=a("p"),fxr=o("Examples:"),mxr=l(),f(W7.$$.fragment),gxr=l(),No=a("div"),f(Q7.$$.fragment),hxr=l(),FTe=a("p"),pxr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_xr=l(),jn=a("p"),uxr=o("The model class to instantiate is selected based on the "),CTe=a("code"),bxr=o("model_type"),vxr=o(` property of the config object (either
passed as an argument or loaded from `),MTe=a("code"),Txr=o("pretrained_model_name_or_path"),Fxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ETe=a("code"),Cxr=o("pretrained_model_name_or_path"),Mxr=o(":"),Exr=l(),H7=a("ul"),aE=a("li"),yTe=a("strong"),yxr=o("beit"),wxr=o(" \u2014 "),Qz=a("a"),Axr=o("FlaxBeitForImageClassification"),Lxr=o(" (BEiT model)"),Bxr=l(),nE=a("li"),wTe=a("strong"),xxr=o("vit"),kxr=o(" \u2014 "),Hz=a("a"),Rxr=o("FlaxViTForImageClassification"),Sxr=o(" (ViT model)"),Pxr=l(),ATe=a("p"),$xr=o("Examples:"),Ixr=l(),f(U7.$$.fragment),lSe=l(),kf=a("h2"),sE=a("a"),LTe=a("span"),f(J7.$$.fragment),Nxr=l(),BTe=a("span"),Dxr=o("FlaxAutoModelForVision2Seq"),iSe=l(),Xr=a("div"),f(Y7.$$.fragment),jxr=l(),Rf=a("p"),qxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xTe=a("code"),Gxr=o("from_pretrained()"),Oxr=o("class method or the "),kTe=a("code"),Xxr=o("from_config()"),Vxr=o(`class
method.`),zxr=l(),K7=a("p"),Wxr=o("This class cannot be instantiated directly using "),RTe=a("code"),Qxr=o("__init__()"),Hxr=o(" (throws an error)."),Uxr=l(),Nt=a("div"),f(Z7.$$.fragment),Jxr=l(),STe=a("p"),Yxr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Kxr=l(),Sf=a("p"),Zxr=o(`Note:
Loading a model from its configuration file does `),PTe=a("strong"),ekr=o("not"),okr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$Te=a("code"),rkr=o("from_pretrained()"),tkr=o("to load the model weights."),akr=l(),ITe=a("p"),nkr=o("Examples:"),skr=l(),f(e8.$$.fragment),lkr=l(),Do=a("div"),f(o8.$$.fragment),ikr=l(),NTe=a("p"),dkr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ckr=l(),qn=a("p"),fkr=o("The model class to instantiate is selected based on the "),DTe=a("code"),mkr=o("model_type"),gkr=o(` property of the config object (either
passed as an argument or loaded from `),jTe=a("code"),hkr=o("pretrained_model_name_or_path"),pkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qTe=a("code"),_kr=o("pretrained_model_name_or_path"),ukr=o(":"),bkr=l(),GTe=a("ul"),lE=a("li"),OTe=a("strong"),vkr=o("vision-encoder-decoder"),Tkr=o(" \u2014 "),Uz=a("a"),Fkr=o("FlaxVisionEncoderDecoderModel"),Ckr=o(" (Vision Encoder decoder model)"),Mkr=l(),XTe=a("p"),Ekr=o("Examples:"),ykr=l(),f(r8.$$.fragment),this.h()},l(c){const u=xMt('[data-svelte="svelte-1phssyn"]',document.head);K=n(u,"META",{name:!0,content:!0}),u.forEach(t),io=i(c),de=n(c,"H1",{class:!0});var t8=s(de);Ee=n(t8,"A",{id:!0,class:!0,href:!0});var VTe=s(Ee);lo=n(VTe,"SPAN",{});var zTe=s(lo);m(fe.$$.fragment,zTe),zTe.forEach(t),VTe.forEach(t),Ce=i(t8),Vo=n(t8,"SPAN",{});var Akr=s(Vo);Ii=r(Akr,"Auto Classes"),Akr.forEach(t),t8.forEach(t),If=i(c),fa=n(c,"P",{});var cSe=s(fa);Ni=r(cSe,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Di=n(cSe,"CODE",{});var Lkr=s(Di);l3=r(Lkr,"from_pretrained()"),Lkr.forEach(t),Nf=r(cSe,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),cSe.forEach(t),Be=i(c),co=n(c,"P",{});var iE=s(co);ji=r(iE,"Instantiating one of "),Gn=n(iE,"A",{href:!0});var Bkr=s(Gn);i3=r(Bkr,"AutoConfig"),Bkr.forEach(t),On=r(iE,", "),Xn=n(iE,"A",{href:!0});var xkr=s(Xn);d3=r(xkr,"AutoModel"),xkr.forEach(t),qi=r(iE,`, and
`),Vn=n(iE,"A",{href:!0});var kkr=s(Vn);c3=r(kkr,"AutoTokenizer"),kkr.forEach(t),Gi=r(iE," will directly create a class of the relevant architecture. For instance"),iE.forEach(t),Df=i(c),m(qa.$$.fragment,c),fo=i(c),pe=n(c,"P",{});var fSe=s(pe);e9=r(fSe,"will create a model that is an instance of "),Oi=n(fSe,"A",{href:!0});var Rkr=s(Oi);o9=r(Rkr,"BertModel"),Rkr.forEach(t),r9=r(fSe,"."),fSe.forEach(t),zo=i(c),Ga=n(c,"P",{});var mSe=s(Ga);t9=r(mSe,"There is one class of "),jf=n(mSe,"CODE",{});var Skr=s(jf);a9=r(Skr,"AutoModel"),Skr.forEach(t),C$e=r(mSe," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),mSe.forEach(t),ike=i(c),Xi=n(c,"H2",{class:!0});var gSe=s(Xi);qf=n(gSe,"A",{id:!0,class:!0,href:!0});var Pkr=s(qf);OQ=n(Pkr,"SPAN",{});var $kr=s(OQ);m(f3.$$.fragment,$kr),$kr.forEach(t),Pkr.forEach(t),M$e=i(gSe),XQ=n(gSe,"SPAN",{});var Ikr=s(XQ);E$e=r(Ikr,"Extending the Auto Classes"),Ikr.forEach(t),gSe.forEach(t),dke=i(c),zn=n(c,"P",{});var Jz=s(zn);y$e=r(Jz,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),VQ=n(Jz,"CODE",{});var Nkr=s(VQ);w$e=r(Nkr,"NewModel"),Nkr.forEach(t),A$e=r(Jz,", make sure you have a "),zQ=n(Jz,"CODE",{});var Dkr=s(zQ);L$e=r(Dkr,"NewModelConfig"),Dkr.forEach(t),B$e=r(Jz,` then you can add those to the auto
classes like this:`),Jz.forEach(t),cke=i(c),m(m3.$$.fragment,c),fke=i(c),n9=n(c,"P",{});var jkr=s(n9);x$e=r(jkr,"You will then be able to use the auto classes like you would usually do!"),jkr.forEach(t),mke=i(c),m(Gf.$$.fragment,c),gke=i(c),Vi=n(c,"H2",{class:!0});var hSe=s(Vi);Of=n(hSe,"A",{id:!0,class:!0,href:!0});var qkr=s(Of);WQ=n(qkr,"SPAN",{});var Gkr=s(WQ);m(g3.$$.fragment,Gkr),Gkr.forEach(t),qkr.forEach(t),k$e=i(hSe),QQ=n(hSe,"SPAN",{});var Okr=s(QQ);R$e=r(Okr,"AutoConfig"),Okr.forEach(t),hSe.forEach(t),hke=i(c),Wo=n(c,"DIV",{class:!0});var Os=s(Wo);m(h3.$$.fragment,Os),S$e=i(Os),p3=n(Os,"P",{});var pSe=s(p3);P$e=r(pSe,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),s9=n(pSe,"A",{href:!0});var Xkr=s(s9);$$e=r(Xkr,"from_pretrained()"),Xkr.forEach(t),I$e=r(pSe," class method."),pSe.forEach(t),N$e=i(Os),_3=n(Os,"P",{});var _Se=s(_3);D$e=r(_Se,"This class cannot be instantiated directly using "),HQ=n(_Se,"CODE",{});var Vkr=s(HQ);j$e=r(Vkr,"__init__()"),Vkr.forEach(t),q$e=r(_Se," (throws an error)."),_Se.forEach(t),G$e=i(Os),mo=n(Os,"DIV",{class:!0});var ga=s(mo);m(u3.$$.fragment,ga),O$e=i(ga),UQ=n(ga,"P",{});var zkr=s(UQ);X$e=r(zkr,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),zkr.forEach(t),V$e=i(ga),zi=n(ga,"P",{});var Yz=s(zi);z$e=r(Yz,"The configuration class to instantiate is selected based on the "),JQ=n(Yz,"CODE",{});var Wkr=s(JQ);W$e=r(Wkr,"model_type"),Wkr.forEach(t),Q$e=r(Yz,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),YQ=n(Yz,"CODE",{});var Qkr=s(YQ);H$e=r(Qkr,"pretrained_model_name_or_path"),Qkr.forEach(t),U$e=r(Yz,":"),Yz.forEach(t),J$e=i(ga),v=n(ga,"UL",{});var T=s(v);Xf=n(T,"LI",{});var WTe=s(Xf);KQ=n(WTe,"STRONG",{});var Hkr=s(KQ);Y$e=r(Hkr,"albert"),Hkr.forEach(t),K$e=r(WTe," \u2014 "),l9=n(WTe,"A",{href:!0});var Ukr=s(l9);Z$e=r(Ukr,"AlbertConfig"),Ukr.forEach(t),eIe=r(WTe," (ALBERT model)"),WTe.forEach(t),oIe=i(T),Vf=n(T,"LI",{});var QTe=s(Vf);ZQ=n(QTe,"STRONG",{});var Jkr=s(ZQ);rIe=r(Jkr,"bart"),Jkr.forEach(t),tIe=r(QTe," \u2014 "),i9=n(QTe,"A",{href:!0});var Ykr=s(i9);aIe=r(Ykr,"BartConfig"),Ykr.forEach(t),nIe=r(QTe," (BART model)"),QTe.forEach(t),sIe=i(T),zf=n(T,"LI",{});var HTe=s(zf);eH=n(HTe,"STRONG",{});var Kkr=s(eH);lIe=r(Kkr,"beit"),Kkr.forEach(t),iIe=r(HTe," \u2014 "),d9=n(HTe,"A",{href:!0});var Zkr=s(d9);dIe=r(Zkr,"BeitConfig"),Zkr.forEach(t),cIe=r(HTe," (BEiT model)"),HTe.forEach(t),fIe=i(T),Wf=n(T,"LI",{});var UTe=s(Wf);oH=n(UTe,"STRONG",{});var eRr=s(oH);mIe=r(eRr,"bert"),eRr.forEach(t),gIe=r(UTe," \u2014 "),c9=n(UTe,"A",{href:!0});var oRr=s(c9);hIe=r(oRr,"BertConfig"),oRr.forEach(t),pIe=r(UTe," (BERT model)"),UTe.forEach(t),_Ie=i(T),Qf=n(T,"LI",{});var JTe=s(Qf);rH=n(JTe,"STRONG",{});var rRr=s(rH);uIe=r(rRr,"bert-generation"),rRr.forEach(t),bIe=r(JTe," \u2014 "),f9=n(JTe,"A",{href:!0});var tRr=s(f9);vIe=r(tRr,"BertGenerationConfig"),tRr.forEach(t),TIe=r(JTe," (Bert Generation model)"),JTe.forEach(t),FIe=i(T),Hf=n(T,"LI",{});var YTe=s(Hf);tH=n(YTe,"STRONG",{});var aRr=s(tH);CIe=r(aRr,"big_bird"),aRr.forEach(t),MIe=r(YTe," \u2014 "),m9=n(YTe,"A",{href:!0});var nRr=s(m9);EIe=r(nRr,"BigBirdConfig"),nRr.forEach(t),yIe=r(YTe," (BigBird model)"),YTe.forEach(t),wIe=i(T),Uf=n(T,"LI",{});var KTe=s(Uf);aH=n(KTe,"STRONG",{});var sRr=s(aH);AIe=r(sRr,"bigbird_pegasus"),sRr.forEach(t),LIe=r(KTe," \u2014 "),g9=n(KTe,"A",{href:!0});var lRr=s(g9);BIe=r(lRr,"BigBirdPegasusConfig"),lRr.forEach(t),xIe=r(KTe," (BigBirdPegasus model)"),KTe.forEach(t),kIe=i(T),Jf=n(T,"LI",{});var ZTe=s(Jf);nH=n(ZTe,"STRONG",{});var iRr=s(nH);RIe=r(iRr,"blenderbot"),iRr.forEach(t),SIe=r(ZTe," \u2014 "),h9=n(ZTe,"A",{href:!0});var dRr=s(h9);PIe=r(dRr,"BlenderbotConfig"),dRr.forEach(t),$Ie=r(ZTe," (Blenderbot model)"),ZTe.forEach(t),IIe=i(T),Yf=n(T,"LI",{});var eFe=s(Yf);sH=n(eFe,"STRONG",{});var cRr=s(sH);NIe=r(cRr,"blenderbot-small"),cRr.forEach(t),DIe=r(eFe," \u2014 "),p9=n(eFe,"A",{href:!0});var fRr=s(p9);jIe=r(fRr,"BlenderbotSmallConfig"),fRr.forEach(t),qIe=r(eFe," (BlenderbotSmall model)"),eFe.forEach(t),GIe=i(T),Kf=n(T,"LI",{});var oFe=s(Kf);lH=n(oFe,"STRONG",{});var mRr=s(lH);OIe=r(mRr,"camembert"),mRr.forEach(t),XIe=r(oFe," \u2014 "),_9=n(oFe,"A",{href:!0});var gRr=s(_9);VIe=r(gRr,"CamembertConfig"),gRr.forEach(t),zIe=r(oFe," (CamemBERT model)"),oFe.forEach(t),WIe=i(T),Zf=n(T,"LI",{});var rFe=s(Zf);iH=n(rFe,"STRONG",{});var hRr=s(iH);QIe=r(hRr,"canine"),hRr.forEach(t),HIe=r(rFe," \u2014 "),u9=n(rFe,"A",{href:!0});var pRr=s(u9);UIe=r(pRr,"CanineConfig"),pRr.forEach(t),JIe=r(rFe," (Canine model)"),rFe.forEach(t),YIe=i(T),em=n(T,"LI",{});var tFe=s(em);dH=n(tFe,"STRONG",{});var _Rr=s(dH);KIe=r(_Rr,"clip"),_Rr.forEach(t),ZIe=r(tFe," \u2014 "),b9=n(tFe,"A",{href:!0});var uRr=s(b9);eNe=r(uRr,"CLIPConfig"),uRr.forEach(t),oNe=r(tFe," (CLIP model)"),tFe.forEach(t),rNe=i(T),om=n(T,"LI",{});var aFe=s(om);cH=n(aFe,"STRONG",{});var bRr=s(cH);tNe=r(bRr,"convbert"),bRr.forEach(t),aNe=r(aFe," \u2014 "),v9=n(aFe,"A",{href:!0});var vRr=s(v9);nNe=r(vRr,"ConvBertConfig"),vRr.forEach(t),sNe=r(aFe," (ConvBERT model)"),aFe.forEach(t),lNe=i(T),rm=n(T,"LI",{});var nFe=s(rm);fH=n(nFe,"STRONG",{});var TRr=s(fH);iNe=r(TRr,"convnext"),TRr.forEach(t),dNe=r(nFe," \u2014 "),T9=n(nFe,"A",{href:!0});var FRr=s(T9);cNe=r(FRr,"ConvNextConfig"),FRr.forEach(t),fNe=r(nFe," (ConvNext model)"),nFe.forEach(t),mNe=i(T),tm=n(T,"LI",{});var sFe=s(tm);mH=n(sFe,"STRONG",{});var CRr=s(mH);gNe=r(CRr,"ctrl"),CRr.forEach(t),hNe=r(sFe," \u2014 "),F9=n(sFe,"A",{href:!0});var MRr=s(F9);pNe=r(MRr,"CTRLConfig"),MRr.forEach(t),_Ne=r(sFe," (CTRL model)"),sFe.forEach(t),uNe=i(T),am=n(T,"LI",{});var lFe=s(am);gH=n(lFe,"STRONG",{});var ERr=s(gH);bNe=r(ERr,"data2vec-audio"),ERr.forEach(t),vNe=r(lFe," \u2014 "),C9=n(lFe,"A",{href:!0});var yRr=s(C9);TNe=r(yRr,"Data2VecAudioConfig"),yRr.forEach(t),FNe=r(lFe," (Data2VecAudio model)"),lFe.forEach(t),CNe=i(T),nm=n(T,"LI",{});var iFe=s(nm);hH=n(iFe,"STRONG",{});var wRr=s(hH);MNe=r(wRr,"data2vec-text"),wRr.forEach(t),ENe=r(iFe," \u2014 "),M9=n(iFe,"A",{href:!0});var ARr=s(M9);yNe=r(ARr,"Data2VecTextConfig"),ARr.forEach(t),wNe=r(iFe," (Data2VecText model)"),iFe.forEach(t),ANe=i(T),sm=n(T,"LI",{});var dFe=s(sm);pH=n(dFe,"STRONG",{});var LRr=s(pH);LNe=r(LRr,"deberta"),LRr.forEach(t),BNe=r(dFe," \u2014 "),E9=n(dFe,"A",{href:!0});var BRr=s(E9);xNe=r(BRr,"DebertaConfig"),BRr.forEach(t),kNe=r(dFe," (DeBERTa model)"),dFe.forEach(t),RNe=i(T),lm=n(T,"LI",{});var cFe=s(lm);_H=n(cFe,"STRONG",{});var xRr=s(_H);SNe=r(xRr,"deberta-v2"),xRr.forEach(t),PNe=r(cFe," \u2014 "),y9=n(cFe,"A",{href:!0});var kRr=s(y9);$Ne=r(kRr,"DebertaV2Config"),kRr.forEach(t),INe=r(cFe," (DeBERTa-v2 model)"),cFe.forEach(t),NNe=i(T),im=n(T,"LI",{});var fFe=s(im);uH=n(fFe,"STRONG",{});var RRr=s(uH);DNe=r(RRr,"decision_transformer"),RRr.forEach(t),jNe=r(fFe," \u2014 "),w9=n(fFe,"A",{href:!0});var SRr=s(w9);qNe=r(SRr,"DecisionTransformerConfig"),SRr.forEach(t),GNe=r(fFe," (Decision Transformer model)"),fFe.forEach(t),ONe=i(T),dm=n(T,"LI",{});var mFe=s(dm);bH=n(mFe,"STRONG",{});var PRr=s(bH);XNe=r(PRr,"deit"),PRr.forEach(t),VNe=r(mFe," \u2014 "),A9=n(mFe,"A",{href:!0});var $Rr=s(A9);zNe=r($Rr,"DeiTConfig"),$Rr.forEach(t),WNe=r(mFe," (DeiT model)"),mFe.forEach(t),QNe=i(T),cm=n(T,"LI",{});var gFe=s(cm);vH=n(gFe,"STRONG",{});var IRr=s(vH);HNe=r(IRr,"detr"),IRr.forEach(t),UNe=r(gFe," \u2014 "),L9=n(gFe,"A",{href:!0});var NRr=s(L9);JNe=r(NRr,"DetrConfig"),NRr.forEach(t),YNe=r(gFe," (DETR model)"),gFe.forEach(t),KNe=i(T),fm=n(T,"LI",{});var hFe=s(fm);TH=n(hFe,"STRONG",{});var DRr=s(TH);ZNe=r(DRr,"distilbert"),DRr.forEach(t),eDe=r(hFe," \u2014 "),B9=n(hFe,"A",{href:!0});var jRr=s(B9);oDe=r(jRr,"DistilBertConfig"),jRr.forEach(t),rDe=r(hFe," (DistilBERT model)"),hFe.forEach(t),tDe=i(T),mm=n(T,"LI",{});var pFe=s(mm);FH=n(pFe,"STRONG",{});var qRr=s(FH);aDe=r(qRr,"dpr"),qRr.forEach(t),nDe=r(pFe," \u2014 "),x9=n(pFe,"A",{href:!0});var GRr=s(x9);sDe=r(GRr,"DPRConfig"),GRr.forEach(t),lDe=r(pFe," (DPR model)"),pFe.forEach(t),iDe=i(T),gm=n(T,"LI",{});var _Fe=s(gm);CH=n(_Fe,"STRONG",{});var ORr=s(CH);dDe=r(ORr,"electra"),ORr.forEach(t),cDe=r(_Fe," \u2014 "),k9=n(_Fe,"A",{href:!0});var XRr=s(k9);fDe=r(XRr,"ElectraConfig"),XRr.forEach(t),mDe=r(_Fe," (ELECTRA model)"),_Fe.forEach(t),gDe=i(T),hm=n(T,"LI",{});var uFe=s(hm);MH=n(uFe,"STRONG",{});var VRr=s(MH);hDe=r(VRr,"encoder-decoder"),VRr.forEach(t),pDe=r(uFe," \u2014 "),R9=n(uFe,"A",{href:!0});var zRr=s(R9);_De=r(zRr,"EncoderDecoderConfig"),zRr.forEach(t),uDe=r(uFe," (Encoder decoder model)"),uFe.forEach(t),bDe=i(T),pm=n(T,"LI",{});var bFe=s(pm);EH=n(bFe,"STRONG",{});var WRr=s(EH);vDe=r(WRr,"flaubert"),WRr.forEach(t),TDe=r(bFe," \u2014 "),S9=n(bFe,"A",{href:!0});var QRr=s(S9);FDe=r(QRr,"FlaubertConfig"),QRr.forEach(t),CDe=r(bFe," (FlauBERT model)"),bFe.forEach(t),MDe=i(T),_m=n(T,"LI",{});var vFe=s(_m);yH=n(vFe,"STRONG",{});var HRr=s(yH);EDe=r(HRr,"fnet"),HRr.forEach(t),yDe=r(vFe," \u2014 "),P9=n(vFe,"A",{href:!0});var URr=s(P9);wDe=r(URr,"FNetConfig"),URr.forEach(t),ADe=r(vFe," (FNet model)"),vFe.forEach(t),LDe=i(T),um=n(T,"LI",{});var TFe=s(um);wH=n(TFe,"STRONG",{});var JRr=s(wH);BDe=r(JRr,"fsmt"),JRr.forEach(t),xDe=r(TFe," \u2014 "),$9=n(TFe,"A",{href:!0});var YRr=s($9);kDe=r(YRr,"FSMTConfig"),YRr.forEach(t),RDe=r(TFe," (FairSeq Machine-Translation model)"),TFe.forEach(t),SDe=i(T),bm=n(T,"LI",{});var FFe=s(bm);AH=n(FFe,"STRONG",{});var KRr=s(AH);PDe=r(KRr,"funnel"),KRr.forEach(t),$De=r(FFe," \u2014 "),I9=n(FFe,"A",{href:!0});var ZRr=s(I9);IDe=r(ZRr,"FunnelConfig"),ZRr.forEach(t),NDe=r(FFe," (Funnel Transformer model)"),FFe.forEach(t),DDe=i(T),vm=n(T,"LI",{});var CFe=s(vm);LH=n(CFe,"STRONG",{});var eSr=s(LH);jDe=r(eSr,"glpn"),eSr.forEach(t),qDe=r(CFe," \u2014 "),N9=n(CFe,"A",{href:!0});var oSr=s(N9);GDe=r(oSr,"GLPNConfig"),oSr.forEach(t),ODe=r(CFe," (GLPN model)"),CFe.forEach(t),XDe=i(T),Tm=n(T,"LI",{});var MFe=s(Tm);BH=n(MFe,"STRONG",{});var rSr=s(BH);VDe=r(rSr,"gpt2"),rSr.forEach(t),zDe=r(MFe," \u2014 "),D9=n(MFe,"A",{href:!0});var tSr=s(D9);WDe=r(tSr,"GPT2Config"),tSr.forEach(t),QDe=r(MFe," (OpenAI GPT-2 model)"),MFe.forEach(t),HDe=i(T),Fm=n(T,"LI",{});var EFe=s(Fm);xH=n(EFe,"STRONG",{});var aSr=s(xH);UDe=r(aSr,"gpt_neo"),aSr.forEach(t),JDe=r(EFe," \u2014 "),j9=n(EFe,"A",{href:!0});var nSr=s(j9);YDe=r(nSr,"GPTNeoConfig"),nSr.forEach(t),KDe=r(EFe," (GPT Neo model)"),EFe.forEach(t),ZDe=i(T),Cm=n(T,"LI",{});var yFe=s(Cm);kH=n(yFe,"STRONG",{});var sSr=s(kH);eje=r(sSr,"gptj"),sSr.forEach(t),oje=r(yFe," \u2014 "),q9=n(yFe,"A",{href:!0});var lSr=s(q9);rje=r(lSr,"GPTJConfig"),lSr.forEach(t),tje=r(yFe," (GPT-J model)"),yFe.forEach(t),aje=i(T),Mm=n(T,"LI",{});var wFe=s(Mm);RH=n(wFe,"STRONG",{});var iSr=s(RH);nje=r(iSr,"hubert"),iSr.forEach(t),sje=r(wFe," \u2014 "),G9=n(wFe,"A",{href:!0});var dSr=s(G9);lje=r(dSr,"HubertConfig"),dSr.forEach(t),ije=r(wFe," (Hubert model)"),wFe.forEach(t),dje=i(T),Em=n(T,"LI",{});var AFe=s(Em);SH=n(AFe,"STRONG",{});var cSr=s(SH);cje=r(cSr,"ibert"),cSr.forEach(t),fje=r(AFe," \u2014 "),O9=n(AFe,"A",{href:!0});var fSr=s(O9);mje=r(fSr,"IBertConfig"),fSr.forEach(t),gje=r(AFe," (I-BERT model)"),AFe.forEach(t),hje=i(T),ym=n(T,"LI",{});var LFe=s(ym);PH=n(LFe,"STRONG",{});var mSr=s(PH);pje=r(mSr,"imagegpt"),mSr.forEach(t),_je=r(LFe," \u2014 "),X9=n(LFe,"A",{href:!0});var gSr=s(X9);uje=r(gSr,"ImageGPTConfig"),gSr.forEach(t),bje=r(LFe," (ImageGPT model)"),LFe.forEach(t),vje=i(T),wm=n(T,"LI",{});var BFe=s(wm);$H=n(BFe,"STRONG",{});var hSr=s($H);Tje=r(hSr,"layoutlm"),hSr.forEach(t),Fje=r(BFe," \u2014 "),V9=n(BFe,"A",{href:!0});var pSr=s(V9);Cje=r(pSr,"LayoutLMConfig"),pSr.forEach(t),Mje=r(BFe," (LayoutLM model)"),BFe.forEach(t),Eje=i(T),Am=n(T,"LI",{});var xFe=s(Am);IH=n(xFe,"STRONG",{});var _Sr=s(IH);yje=r(_Sr,"layoutlmv2"),_Sr.forEach(t),wje=r(xFe," \u2014 "),z9=n(xFe,"A",{href:!0});var uSr=s(z9);Aje=r(uSr,"LayoutLMv2Config"),uSr.forEach(t),Lje=r(xFe," (LayoutLMv2 model)"),xFe.forEach(t),Bje=i(T),Lm=n(T,"LI",{});var kFe=s(Lm);NH=n(kFe,"STRONG",{});var bSr=s(NH);xje=r(bSr,"led"),bSr.forEach(t),kje=r(kFe," \u2014 "),W9=n(kFe,"A",{href:!0});var vSr=s(W9);Rje=r(vSr,"LEDConfig"),vSr.forEach(t),Sje=r(kFe," (LED model)"),kFe.forEach(t),Pje=i(T),Bm=n(T,"LI",{});var RFe=s(Bm);DH=n(RFe,"STRONG",{});var TSr=s(DH);$je=r(TSr,"longformer"),TSr.forEach(t),Ije=r(RFe," \u2014 "),Q9=n(RFe,"A",{href:!0});var FSr=s(Q9);Nje=r(FSr,"LongformerConfig"),FSr.forEach(t),Dje=r(RFe," (Longformer model)"),RFe.forEach(t),jje=i(T),xm=n(T,"LI",{});var SFe=s(xm);jH=n(SFe,"STRONG",{});var CSr=s(jH);qje=r(CSr,"luke"),CSr.forEach(t),Gje=r(SFe," \u2014 "),H9=n(SFe,"A",{href:!0});var MSr=s(H9);Oje=r(MSr,"LukeConfig"),MSr.forEach(t),Xje=r(SFe," (LUKE model)"),SFe.forEach(t),Vje=i(T),km=n(T,"LI",{});var PFe=s(km);qH=n(PFe,"STRONG",{});var ESr=s(qH);zje=r(ESr,"lxmert"),ESr.forEach(t),Wje=r(PFe," \u2014 "),U9=n(PFe,"A",{href:!0});var ySr=s(U9);Qje=r(ySr,"LxmertConfig"),ySr.forEach(t),Hje=r(PFe," (LXMERT model)"),PFe.forEach(t),Uje=i(T),Rm=n(T,"LI",{});var $Fe=s(Rm);GH=n($Fe,"STRONG",{});var wSr=s(GH);Jje=r(wSr,"m2m_100"),wSr.forEach(t),Yje=r($Fe," \u2014 "),J9=n($Fe,"A",{href:!0});var ASr=s(J9);Kje=r(ASr,"M2M100Config"),ASr.forEach(t),Zje=r($Fe," (M2M100 model)"),$Fe.forEach(t),eqe=i(T),Sm=n(T,"LI",{});var IFe=s(Sm);OH=n(IFe,"STRONG",{});var LSr=s(OH);oqe=r(LSr,"marian"),LSr.forEach(t),rqe=r(IFe," \u2014 "),Y9=n(IFe,"A",{href:!0});var BSr=s(Y9);tqe=r(BSr,"MarianConfig"),BSr.forEach(t),aqe=r(IFe," (Marian model)"),IFe.forEach(t),nqe=i(T),Pm=n(T,"LI",{});var NFe=s(Pm);XH=n(NFe,"STRONG",{});var xSr=s(XH);sqe=r(xSr,"maskformer"),xSr.forEach(t),lqe=r(NFe," \u2014 "),K9=n(NFe,"A",{href:!0});var kSr=s(K9);iqe=r(kSr,"MaskFormerConfig"),kSr.forEach(t),dqe=r(NFe," (MaskFormer model)"),NFe.forEach(t),cqe=i(T),$m=n(T,"LI",{});var DFe=s($m);VH=n(DFe,"STRONG",{});var RSr=s(VH);fqe=r(RSr,"mbart"),RSr.forEach(t),mqe=r(DFe," \u2014 "),Z9=n(DFe,"A",{href:!0});var SSr=s(Z9);gqe=r(SSr,"MBartConfig"),SSr.forEach(t),hqe=r(DFe," (mBART model)"),DFe.forEach(t),pqe=i(T),Im=n(T,"LI",{});var jFe=s(Im);zH=n(jFe,"STRONG",{});var PSr=s(zH);_qe=r(PSr,"megatron-bert"),PSr.forEach(t),uqe=r(jFe," \u2014 "),eB=n(jFe,"A",{href:!0});var $Sr=s(eB);bqe=r($Sr,"MegatronBertConfig"),$Sr.forEach(t),vqe=r(jFe," (MegatronBert model)"),jFe.forEach(t),Tqe=i(T),Nm=n(T,"LI",{});var qFe=s(Nm);WH=n(qFe,"STRONG",{});var ISr=s(WH);Fqe=r(ISr,"mobilebert"),ISr.forEach(t),Cqe=r(qFe," \u2014 "),oB=n(qFe,"A",{href:!0});var NSr=s(oB);Mqe=r(NSr,"MobileBertConfig"),NSr.forEach(t),Eqe=r(qFe," (MobileBERT model)"),qFe.forEach(t),yqe=i(T),Dm=n(T,"LI",{});var GFe=s(Dm);QH=n(GFe,"STRONG",{});var DSr=s(QH);wqe=r(DSr,"mpnet"),DSr.forEach(t),Aqe=r(GFe," \u2014 "),rB=n(GFe,"A",{href:!0});var jSr=s(rB);Lqe=r(jSr,"MPNetConfig"),jSr.forEach(t),Bqe=r(GFe," (MPNet model)"),GFe.forEach(t),xqe=i(T),jm=n(T,"LI",{});var OFe=s(jm);HH=n(OFe,"STRONG",{});var qSr=s(HH);kqe=r(qSr,"mt5"),qSr.forEach(t),Rqe=r(OFe," \u2014 "),tB=n(OFe,"A",{href:!0});var GSr=s(tB);Sqe=r(GSr,"MT5Config"),GSr.forEach(t),Pqe=r(OFe," (mT5 model)"),OFe.forEach(t),$qe=i(T),qm=n(T,"LI",{});var XFe=s(qm);UH=n(XFe,"STRONG",{});var OSr=s(UH);Iqe=r(OSr,"nystromformer"),OSr.forEach(t),Nqe=r(XFe," \u2014 "),aB=n(XFe,"A",{href:!0});var XSr=s(aB);Dqe=r(XSr,"NystromformerConfig"),XSr.forEach(t),jqe=r(XFe," (Nystromformer model)"),XFe.forEach(t),qqe=i(T),Gm=n(T,"LI",{});var VFe=s(Gm);JH=n(VFe,"STRONG",{});var VSr=s(JH);Gqe=r(VSr,"openai-gpt"),VSr.forEach(t),Oqe=r(VFe," \u2014 "),nB=n(VFe,"A",{href:!0});var zSr=s(nB);Xqe=r(zSr,"OpenAIGPTConfig"),zSr.forEach(t),Vqe=r(VFe," (OpenAI GPT model)"),VFe.forEach(t),zqe=i(T),Om=n(T,"LI",{});var zFe=s(Om);YH=n(zFe,"STRONG",{});var WSr=s(YH);Wqe=r(WSr,"pegasus"),WSr.forEach(t),Qqe=r(zFe," \u2014 "),sB=n(zFe,"A",{href:!0});var QSr=s(sB);Hqe=r(QSr,"PegasusConfig"),QSr.forEach(t),Uqe=r(zFe," (Pegasus model)"),zFe.forEach(t),Jqe=i(T),Xm=n(T,"LI",{});var WFe=s(Xm);KH=n(WFe,"STRONG",{});var HSr=s(KH);Yqe=r(HSr,"perceiver"),HSr.forEach(t),Kqe=r(WFe," \u2014 "),lB=n(WFe,"A",{href:!0});var USr=s(lB);Zqe=r(USr,"PerceiverConfig"),USr.forEach(t),eGe=r(WFe," (Perceiver model)"),WFe.forEach(t),oGe=i(T),Vm=n(T,"LI",{});var QFe=s(Vm);ZH=n(QFe,"STRONG",{});var JSr=s(ZH);rGe=r(JSr,"plbart"),JSr.forEach(t),tGe=r(QFe," \u2014 "),iB=n(QFe,"A",{href:!0});var YSr=s(iB);aGe=r(YSr,"PLBartConfig"),YSr.forEach(t),nGe=r(QFe," (PLBart model)"),QFe.forEach(t),sGe=i(T),zm=n(T,"LI",{});var HFe=s(zm);eU=n(HFe,"STRONG",{});var KSr=s(eU);lGe=r(KSr,"poolformer"),KSr.forEach(t),iGe=r(HFe," \u2014 "),dB=n(HFe,"A",{href:!0});var ZSr=s(dB);dGe=r(ZSr,"PoolFormerConfig"),ZSr.forEach(t),cGe=r(HFe," (PoolFormer model)"),HFe.forEach(t),fGe=i(T),Wm=n(T,"LI",{});var UFe=s(Wm);oU=n(UFe,"STRONG",{});var ePr=s(oU);mGe=r(ePr,"prophetnet"),ePr.forEach(t),gGe=r(UFe," \u2014 "),cB=n(UFe,"A",{href:!0});var oPr=s(cB);hGe=r(oPr,"ProphetNetConfig"),oPr.forEach(t),pGe=r(UFe," (ProphetNet model)"),UFe.forEach(t),_Ge=i(T),Qm=n(T,"LI",{});var JFe=s(Qm);rU=n(JFe,"STRONG",{});var rPr=s(rU);uGe=r(rPr,"qdqbert"),rPr.forEach(t),bGe=r(JFe," \u2014 "),fB=n(JFe,"A",{href:!0});var tPr=s(fB);vGe=r(tPr,"QDQBertConfig"),tPr.forEach(t),TGe=r(JFe," (QDQBert model)"),JFe.forEach(t),FGe=i(T),Hm=n(T,"LI",{});var YFe=s(Hm);tU=n(YFe,"STRONG",{});var aPr=s(tU);CGe=r(aPr,"rag"),aPr.forEach(t),MGe=r(YFe," \u2014 "),mB=n(YFe,"A",{href:!0});var nPr=s(mB);EGe=r(nPr,"RagConfig"),nPr.forEach(t),yGe=r(YFe," (RAG model)"),YFe.forEach(t),wGe=i(T),Um=n(T,"LI",{});var KFe=s(Um);aU=n(KFe,"STRONG",{});var sPr=s(aU);AGe=r(sPr,"realm"),sPr.forEach(t),LGe=r(KFe," \u2014 "),gB=n(KFe,"A",{href:!0});var lPr=s(gB);BGe=r(lPr,"RealmConfig"),lPr.forEach(t),xGe=r(KFe," (Realm model)"),KFe.forEach(t),kGe=i(T),Jm=n(T,"LI",{});var ZFe=s(Jm);nU=n(ZFe,"STRONG",{});var iPr=s(nU);RGe=r(iPr,"reformer"),iPr.forEach(t),SGe=r(ZFe," \u2014 "),hB=n(ZFe,"A",{href:!0});var dPr=s(hB);PGe=r(dPr,"ReformerConfig"),dPr.forEach(t),$Ge=r(ZFe," (Reformer model)"),ZFe.forEach(t),IGe=i(T),Ym=n(T,"LI",{});var eCe=s(Ym);sU=n(eCe,"STRONG",{});var cPr=s(sU);NGe=r(cPr,"rembert"),cPr.forEach(t),DGe=r(eCe," \u2014 "),pB=n(eCe,"A",{href:!0});var fPr=s(pB);jGe=r(fPr,"RemBertConfig"),fPr.forEach(t),qGe=r(eCe," (RemBERT model)"),eCe.forEach(t),GGe=i(T),Km=n(T,"LI",{});var oCe=s(Km);lU=n(oCe,"STRONG",{});var mPr=s(lU);OGe=r(mPr,"resnet"),mPr.forEach(t),XGe=r(oCe," \u2014 "),_B=n(oCe,"A",{href:!0});var gPr=s(_B);VGe=r(gPr,"ResNetConfig"),gPr.forEach(t),zGe=r(oCe," (ResNet model)"),oCe.forEach(t),WGe=i(T),Zm=n(T,"LI",{});var rCe=s(Zm);iU=n(rCe,"STRONG",{});var hPr=s(iU);QGe=r(hPr,"retribert"),hPr.forEach(t),HGe=r(rCe," \u2014 "),uB=n(rCe,"A",{href:!0});var pPr=s(uB);UGe=r(pPr,"RetriBertConfig"),pPr.forEach(t),JGe=r(rCe," (RetriBERT model)"),rCe.forEach(t),YGe=i(T),eg=n(T,"LI",{});var tCe=s(eg);dU=n(tCe,"STRONG",{});var _Pr=s(dU);KGe=r(_Pr,"roberta"),_Pr.forEach(t),ZGe=r(tCe," \u2014 "),bB=n(tCe,"A",{href:!0});var uPr=s(bB);eOe=r(uPr,"RobertaConfig"),uPr.forEach(t),oOe=r(tCe," (RoBERTa model)"),tCe.forEach(t),rOe=i(T),og=n(T,"LI",{});var aCe=s(og);cU=n(aCe,"STRONG",{});var bPr=s(cU);tOe=r(bPr,"roformer"),bPr.forEach(t),aOe=r(aCe," \u2014 "),vB=n(aCe,"A",{href:!0});var vPr=s(vB);nOe=r(vPr,"RoFormerConfig"),vPr.forEach(t),sOe=r(aCe," (RoFormer model)"),aCe.forEach(t),lOe=i(T),rg=n(T,"LI",{});var nCe=s(rg);fU=n(nCe,"STRONG",{});var TPr=s(fU);iOe=r(TPr,"segformer"),TPr.forEach(t),dOe=r(nCe," \u2014 "),TB=n(nCe,"A",{href:!0});var FPr=s(TB);cOe=r(FPr,"SegformerConfig"),FPr.forEach(t),fOe=r(nCe," (SegFormer model)"),nCe.forEach(t),mOe=i(T),tg=n(T,"LI",{});var sCe=s(tg);mU=n(sCe,"STRONG",{});var CPr=s(mU);gOe=r(CPr,"sew"),CPr.forEach(t),hOe=r(sCe," \u2014 "),FB=n(sCe,"A",{href:!0});var MPr=s(FB);pOe=r(MPr,"SEWConfig"),MPr.forEach(t),_Oe=r(sCe," (SEW model)"),sCe.forEach(t),uOe=i(T),ag=n(T,"LI",{});var lCe=s(ag);gU=n(lCe,"STRONG",{});var EPr=s(gU);bOe=r(EPr,"sew-d"),EPr.forEach(t),vOe=r(lCe," \u2014 "),CB=n(lCe,"A",{href:!0});var yPr=s(CB);TOe=r(yPr,"SEWDConfig"),yPr.forEach(t),FOe=r(lCe," (SEW-D model)"),lCe.forEach(t),COe=i(T),ng=n(T,"LI",{});var iCe=s(ng);hU=n(iCe,"STRONG",{});var wPr=s(hU);MOe=r(wPr,"speech-encoder-decoder"),wPr.forEach(t),EOe=r(iCe," \u2014 "),MB=n(iCe,"A",{href:!0});var APr=s(MB);yOe=r(APr,"SpeechEncoderDecoderConfig"),APr.forEach(t),wOe=r(iCe," (Speech Encoder decoder model)"),iCe.forEach(t),AOe=i(T),sg=n(T,"LI",{});var dCe=s(sg);pU=n(dCe,"STRONG",{});var LPr=s(pU);LOe=r(LPr,"speech_to_text"),LPr.forEach(t),BOe=r(dCe," \u2014 "),EB=n(dCe,"A",{href:!0});var BPr=s(EB);xOe=r(BPr,"Speech2TextConfig"),BPr.forEach(t),kOe=r(dCe," (Speech2Text model)"),dCe.forEach(t),ROe=i(T),lg=n(T,"LI",{});var cCe=s(lg);_U=n(cCe,"STRONG",{});var xPr=s(_U);SOe=r(xPr,"speech_to_text_2"),xPr.forEach(t),POe=r(cCe," \u2014 "),yB=n(cCe,"A",{href:!0});var kPr=s(yB);$Oe=r(kPr,"Speech2Text2Config"),kPr.forEach(t),IOe=r(cCe," (Speech2Text2 model)"),cCe.forEach(t),NOe=i(T),ig=n(T,"LI",{});var fCe=s(ig);uU=n(fCe,"STRONG",{});var RPr=s(uU);DOe=r(RPr,"splinter"),RPr.forEach(t),jOe=r(fCe," \u2014 "),wB=n(fCe,"A",{href:!0});var SPr=s(wB);qOe=r(SPr,"SplinterConfig"),SPr.forEach(t),GOe=r(fCe," (Splinter model)"),fCe.forEach(t),OOe=i(T),dg=n(T,"LI",{});var mCe=s(dg);bU=n(mCe,"STRONG",{});var PPr=s(bU);XOe=r(PPr,"squeezebert"),PPr.forEach(t),VOe=r(mCe," \u2014 "),AB=n(mCe,"A",{href:!0});var $Pr=s(AB);zOe=r($Pr,"SqueezeBertConfig"),$Pr.forEach(t),WOe=r(mCe," (SqueezeBERT model)"),mCe.forEach(t),QOe=i(T),cg=n(T,"LI",{});var gCe=s(cg);vU=n(gCe,"STRONG",{});var IPr=s(vU);HOe=r(IPr,"swin"),IPr.forEach(t),UOe=r(gCe," \u2014 "),LB=n(gCe,"A",{href:!0});var NPr=s(LB);JOe=r(NPr,"SwinConfig"),NPr.forEach(t),YOe=r(gCe," (Swin model)"),gCe.forEach(t),KOe=i(T),fg=n(T,"LI",{});var hCe=s(fg);TU=n(hCe,"STRONG",{});var DPr=s(TU);ZOe=r(DPr,"t5"),DPr.forEach(t),eXe=r(hCe," \u2014 "),BB=n(hCe,"A",{href:!0});var jPr=s(BB);oXe=r(jPr,"T5Config"),jPr.forEach(t),rXe=r(hCe," (T5 model)"),hCe.forEach(t),tXe=i(T),mg=n(T,"LI",{});var pCe=s(mg);FU=n(pCe,"STRONG",{});var qPr=s(FU);aXe=r(qPr,"tapas"),qPr.forEach(t),nXe=r(pCe," \u2014 "),xB=n(pCe,"A",{href:!0});var GPr=s(xB);sXe=r(GPr,"TapasConfig"),GPr.forEach(t),lXe=r(pCe," (TAPAS model)"),pCe.forEach(t),iXe=i(T),gg=n(T,"LI",{});var _Ce=s(gg);CU=n(_Ce,"STRONG",{});var OPr=s(CU);dXe=r(OPr,"transfo-xl"),OPr.forEach(t),cXe=r(_Ce," \u2014 "),kB=n(_Ce,"A",{href:!0});var XPr=s(kB);fXe=r(XPr,"TransfoXLConfig"),XPr.forEach(t),mXe=r(_Ce," (Transformer-XL model)"),_Ce.forEach(t),gXe=i(T),hg=n(T,"LI",{});var uCe=s(hg);MU=n(uCe,"STRONG",{});var VPr=s(MU);hXe=r(VPr,"trocr"),VPr.forEach(t),pXe=r(uCe," \u2014 "),RB=n(uCe,"A",{href:!0});var zPr=s(RB);_Xe=r(zPr,"TrOCRConfig"),zPr.forEach(t),uXe=r(uCe," (TrOCR model)"),uCe.forEach(t),bXe=i(T),pg=n(T,"LI",{});var bCe=s(pg);EU=n(bCe,"STRONG",{});var WPr=s(EU);vXe=r(WPr,"unispeech"),WPr.forEach(t),TXe=r(bCe," \u2014 "),SB=n(bCe,"A",{href:!0});var QPr=s(SB);FXe=r(QPr,"UniSpeechConfig"),QPr.forEach(t),CXe=r(bCe," (UniSpeech model)"),bCe.forEach(t),MXe=i(T),_g=n(T,"LI",{});var vCe=s(_g);yU=n(vCe,"STRONG",{});var HPr=s(yU);EXe=r(HPr,"unispeech-sat"),HPr.forEach(t),yXe=r(vCe," \u2014 "),PB=n(vCe,"A",{href:!0});var UPr=s(PB);wXe=r(UPr,"UniSpeechSatConfig"),UPr.forEach(t),AXe=r(vCe," (UniSpeechSat model)"),vCe.forEach(t),LXe=i(T),ug=n(T,"LI",{});var TCe=s(ug);wU=n(TCe,"STRONG",{});var JPr=s(wU);BXe=r(JPr,"van"),JPr.forEach(t),xXe=r(TCe," \u2014 "),$B=n(TCe,"A",{href:!0});var YPr=s($B);kXe=r(YPr,"VanConfig"),YPr.forEach(t),RXe=r(TCe," (VAN model)"),TCe.forEach(t),SXe=i(T),bg=n(T,"LI",{});var FCe=s(bg);AU=n(FCe,"STRONG",{});var KPr=s(AU);PXe=r(KPr,"vilt"),KPr.forEach(t),$Xe=r(FCe," \u2014 "),IB=n(FCe,"A",{href:!0});var ZPr=s(IB);IXe=r(ZPr,"ViltConfig"),ZPr.forEach(t),NXe=r(FCe," (ViLT model)"),FCe.forEach(t),DXe=i(T),vg=n(T,"LI",{});var CCe=s(vg);LU=n(CCe,"STRONG",{});var e$r=s(LU);jXe=r(e$r,"vision-encoder-decoder"),e$r.forEach(t),qXe=r(CCe," \u2014 "),NB=n(CCe,"A",{href:!0});var o$r=s(NB);GXe=r(o$r,"VisionEncoderDecoderConfig"),o$r.forEach(t),OXe=r(CCe," (Vision Encoder decoder model)"),CCe.forEach(t),XXe=i(T),Tg=n(T,"LI",{});var MCe=s(Tg);BU=n(MCe,"STRONG",{});var r$r=s(BU);VXe=r(r$r,"vision-text-dual-encoder"),r$r.forEach(t),zXe=r(MCe," \u2014 "),DB=n(MCe,"A",{href:!0});var t$r=s(DB);WXe=r(t$r,"VisionTextDualEncoderConfig"),t$r.forEach(t),QXe=r(MCe," (VisionTextDualEncoder model)"),MCe.forEach(t),HXe=i(T),Fg=n(T,"LI",{});var ECe=s(Fg);xU=n(ECe,"STRONG",{});var a$r=s(xU);UXe=r(a$r,"visual_bert"),a$r.forEach(t),JXe=r(ECe," \u2014 "),jB=n(ECe,"A",{href:!0});var n$r=s(jB);YXe=r(n$r,"VisualBertConfig"),n$r.forEach(t),KXe=r(ECe," (VisualBert model)"),ECe.forEach(t),ZXe=i(T),Cg=n(T,"LI",{});var yCe=s(Cg);kU=n(yCe,"STRONG",{});var s$r=s(kU);eVe=r(s$r,"vit"),s$r.forEach(t),oVe=r(yCe," \u2014 "),qB=n(yCe,"A",{href:!0});var l$r=s(qB);rVe=r(l$r,"ViTConfig"),l$r.forEach(t),tVe=r(yCe," (ViT model)"),yCe.forEach(t),aVe=i(T),Mg=n(T,"LI",{});var wCe=s(Mg);RU=n(wCe,"STRONG",{});var i$r=s(RU);nVe=r(i$r,"vit_mae"),i$r.forEach(t),sVe=r(wCe," \u2014 "),GB=n(wCe,"A",{href:!0});var d$r=s(GB);lVe=r(d$r,"ViTMAEConfig"),d$r.forEach(t),iVe=r(wCe," (ViTMAE model)"),wCe.forEach(t),dVe=i(T),Eg=n(T,"LI",{});var ACe=s(Eg);SU=n(ACe,"STRONG",{});var c$r=s(SU);cVe=r(c$r,"wav2vec2"),c$r.forEach(t),fVe=r(ACe," \u2014 "),OB=n(ACe,"A",{href:!0});var f$r=s(OB);mVe=r(f$r,"Wav2Vec2Config"),f$r.forEach(t),gVe=r(ACe," (Wav2Vec2 model)"),ACe.forEach(t),hVe=i(T),yg=n(T,"LI",{});var LCe=s(yg);PU=n(LCe,"STRONG",{});var m$r=s(PU);pVe=r(m$r,"wavlm"),m$r.forEach(t),_Ve=r(LCe," \u2014 "),XB=n(LCe,"A",{href:!0});var g$r=s(XB);uVe=r(g$r,"WavLMConfig"),g$r.forEach(t),bVe=r(LCe," (WavLM model)"),LCe.forEach(t),vVe=i(T),wg=n(T,"LI",{});var BCe=s(wg);$U=n(BCe,"STRONG",{});var h$r=s($U);TVe=r(h$r,"xglm"),h$r.forEach(t),FVe=r(BCe," \u2014 "),VB=n(BCe,"A",{href:!0});var p$r=s(VB);CVe=r(p$r,"XGLMConfig"),p$r.forEach(t),MVe=r(BCe," (XGLM model)"),BCe.forEach(t),EVe=i(T),Ag=n(T,"LI",{});var xCe=s(Ag);IU=n(xCe,"STRONG",{});var _$r=s(IU);yVe=r(_$r,"xlm"),_$r.forEach(t),wVe=r(xCe," \u2014 "),zB=n(xCe,"A",{href:!0});var u$r=s(zB);AVe=r(u$r,"XLMConfig"),u$r.forEach(t),LVe=r(xCe," (XLM model)"),xCe.forEach(t),BVe=i(T),Lg=n(T,"LI",{});var kCe=s(Lg);NU=n(kCe,"STRONG",{});var b$r=s(NU);xVe=r(b$r,"xlm-prophetnet"),b$r.forEach(t),kVe=r(kCe," \u2014 "),WB=n(kCe,"A",{href:!0});var v$r=s(WB);RVe=r(v$r,"XLMProphetNetConfig"),v$r.forEach(t),SVe=r(kCe," (XLMProphetNet model)"),kCe.forEach(t),PVe=i(T),Bg=n(T,"LI",{});var RCe=s(Bg);DU=n(RCe,"STRONG",{});var T$r=s(DU);$Ve=r(T$r,"xlm-roberta"),T$r.forEach(t),IVe=r(RCe," \u2014 "),QB=n(RCe,"A",{href:!0});var F$r=s(QB);NVe=r(F$r,"XLMRobertaConfig"),F$r.forEach(t),DVe=r(RCe," (XLM-RoBERTa model)"),RCe.forEach(t),jVe=i(T),xg=n(T,"LI",{});var SCe=s(xg);jU=n(SCe,"STRONG",{});var C$r=s(jU);qVe=r(C$r,"xlm-roberta-xl"),C$r.forEach(t),GVe=r(SCe," \u2014 "),HB=n(SCe,"A",{href:!0});var M$r=s(HB);OVe=r(M$r,"XLMRobertaXLConfig"),M$r.forEach(t),XVe=r(SCe," (XLM-RoBERTa-XL model)"),SCe.forEach(t),VVe=i(T),kg=n(T,"LI",{});var PCe=s(kg);qU=n(PCe,"STRONG",{});var E$r=s(qU);zVe=r(E$r,"xlnet"),E$r.forEach(t),WVe=r(PCe," \u2014 "),UB=n(PCe,"A",{href:!0});var y$r=s(UB);QVe=r(y$r,"XLNetConfig"),y$r.forEach(t),HVe=r(PCe," (XLNet model)"),PCe.forEach(t),UVe=i(T),Rg=n(T,"LI",{});var $Ce=s(Rg);GU=n($Ce,"STRONG",{});var w$r=s(GU);JVe=r(w$r,"yoso"),w$r.forEach(t),YVe=r($Ce," \u2014 "),JB=n($Ce,"A",{href:!0});var A$r=s(JB);KVe=r(A$r,"YosoConfig"),A$r.forEach(t),ZVe=r($Ce," (YOSO model)"),$Ce.forEach(t),T.forEach(t),eze=i(ga),OU=n(ga,"P",{});var L$r=s(OU);oze=r(L$r,"Examples:"),L$r.forEach(t),rze=i(ga),m(b3.$$.fragment,ga),ga.forEach(t),tze=i(Os),Sg=n(Os,"DIV",{class:!0});var uSe=s(Sg);m(v3.$$.fragment,uSe),aze=i(uSe),XU=n(uSe,"P",{});var B$r=s(XU);nze=r(B$r,"Register a new configuration for this class."),B$r.forEach(t),uSe.forEach(t),Os.forEach(t),pke=i(c),Wi=n(c,"H2",{class:!0});var bSe=s(Wi);Pg=n(bSe,"A",{id:!0,class:!0,href:!0});var x$r=s(Pg);VU=n(x$r,"SPAN",{});var k$r=s(VU);m(T3.$$.fragment,k$r),k$r.forEach(t),x$r.forEach(t),sze=i(bSe),zU=n(bSe,"SPAN",{});var R$r=s(zU);lze=r(R$r,"AutoTokenizer"),R$r.forEach(t),bSe.forEach(t),_ke=i(c),Qo=n(c,"DIV",{class:!0});var Xs=s(Qo);m(F3.$$.fragment,Xs),ize=i(Xs),C3=n(Xs,"P",{});var vSe=s(C3);dze=r(vSe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),YB=n(vSe,"A",{href:!0});var S$r=s(YB);cze=r(S$r,"AutoTokenizer.from_pretrained()"),S$r.forEach(t),fze=r(vSe," class method."),vSe.forEach(t),mze=i(Xs),M3=n(Xs,"P",{});var TSe=s(M3);gze=r(TSe,"This class cannot be instantiated directly using "),WU=n(TSe,"CODE",{});var P$r=s(WU);hze=r(P$r,"__init__()"),P$r.forEach(t),pze=r(TSe," (throws an error)."),TSe.forEach(t),_ze=i(Xs),go=n(Xs,"DIV",{class:!0});var ha=s(go);m(E3.$$.fragment,ha),uze=i(ha),QU=n(ha,"P",{});var $$r=s(QU);bze=r($$r,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),$$r.forEach(t),vze=i(ha),Oa=n(ha,"P",{});var dE=s(Oa);Tze=r(dE,"The tokenizer class to instantiate is selected based on the "),HU=n(dE,"CODE",{});var I$r=s(HU);Fze=r(I$r,"model_type"),I$r.forEach(t),Cze=r(dE,` property of the config object (either
passed as an argument or loaded from `),UU=n(dE,"CODE",{});var N$r=s(UU);Mze=r(N$r,"pretrained_model_name_or_path"),N$r.forEach(t),Eze=r(dE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JU=n(dE,"CODE",{});var D$r=s(JU);yze=r(D$r,"pretrained_model_name_or_path"),D$r.forEach(t),wze=r(dE,":"),dE.forEach(t),Aze=i(ha),E=n(ha,"UL",{});var y=s(E);Wn=n(y,"LI",{});var a8=s(Wn);YU=n(a8,"STRONG",{});var j$r=s(YU);Lze=r(j$r,"albert"),j$r.forEach(t),Bze=r(a8," \u2014 "),KB=n(a8,"A",{href:!0});var q$r=s(KB);xze=r(q$r,"AlbertTokenizer"),q$r.forEach(t),kze=r(a8," or "),ZB=n(a8,"A",{href:!0});var G$r=s(ZB);Rze=r(G$r,"AlbertTokenizerFast"),G$r.forEach(t),Sze=r(a8," (ALBERT model)"),a8.forEach(t),Pze=i(y),Qn=n(y,"LI",{});var n8=s(Qn);KU=n(n8,"STRONG",{});var O$r=s(KU);$ze=r(O$r,"bart"),O$r.forEach(t),Ize=r(n8," \u2014 "),ex=n(n8,"A",{href:!0});var X$r=s(ex);Nze=r(X$r,"BartTokenizer"),X$r.forEach(t),Dze=r(n8," or "),ox=n(n8,"A",{href:!0});var V$r=s(ox);jze=r(V$r,"BartTokenizerFast"),V$r.forEach(t),qze=r(n8," (BART model)"),n8.forEach(t),Gze=i(y),Hn=n(y,"LI",{});var s8=s(Hn);ZU=n(s8,"STRONG",{});var z$r=s(ZU);Oze=r(z$r,"barthez"),z$r.forEach(t),Xze=r(s8," \u2014 "),rx=n(s8,"A",{href:!0});var W$r=s(rx);Vze=r(W$r,"BarthezTokenizer"),W$r.forEach(t),zze=r(s8," or "),tx=n(s8,"A",{href:!0});var Q$r=s(tx);Wze=r(Q$r,"BarthezTokenizerFast"),Q$r.forEach(t),Qze=r(s8," (BARThez model)"),s8.forEach(t),Hze=i(y),$g=n(y,"LI",{});var ICe=s($g);eJ=n(ICe,"STRONG",{});var H$r=s(eJ);Uze=r(H$r,"bartpho"),H$r.forEach(t),Jze=r(ICe," \u2014 "),ax=n(ICe,"A",{href:!0});var U$r=s(ax);Yze=r(U$r,"BartphoTokenizer"),U$r.forEach(t),Kze=r(ICe," (BARTpho model)"),ICe.forEach(t),Zze=i(y),Un=n(y,"LI",{});var l8=s(Un);oJ=n(l8,"STRONG",{});var J$r=s(oJ);eWe=r(J$r,"bert"),J$r.forEach(t),oWe=r(l8," \u2014 "),nx=n(l8,"A",{href:!0});var Y$r=s(nx);rWe=r(Y$r,"BertTokenizer"),Y$r.forEach(t),tWe=r(l8," or "),sx=n(l8,"A",{href:!0});var K$r=s(sx);aWe=r(K$r,"BertTokenizerFast"),K$r.forEach(t),nWe=r(l8," (BERT model)"),l8.forEach(t),sWe=i(y),Ig=n(y,"LI",{});var NCe=s(Ig);rJ=n(NCe,"STRONG",{});var Z$r=s(rJ);lWe=r(Z$r,"bert-generation"),Z$r.forEach(t),iWe=r(NCe," \u2014 "),lx=n(NCe,"A",{href:!0});var eIr=s(lx);dWe=r(eIr,"BertGenerationTokenizer"),eIr.forEach(t),cWe=r(NCe," (Bert Generation model)"),NCe.forEach(t),fWe=i(y),Ng=n(y,"LI",{});var DCe=s(Ng);tJ=n(DCe,"STRONG",{});var oIr=s(tJ);mWe=r(oIr,"bert-japanese"),oIr.forEach(t),gWe=r(DCe," \u2014 "),ix=n(DCe,"A",{href:!0});var rIr=s(ix);hWe=r(rIr,"BertJapaneseTokenizer"),rIr.forEach(t),pWe=r(DCe," (BertJapanese model)"),DCe.forEach(t),_We=i(y),Dg=n(y,"LI",{});var jCe=s(Dg);aJ=n(jCe,"STRONG",{});var tIr=s(aJ);uWe=r(tIr,"bertweet"),tIr.forEach(t),bWe=r(jCe," \u2014 "),dx=n(jCe,"A",{href:!0});var aIr=s(dx);vWe=r(aIr,"BertweetTokenizer"),aIr.forEach(t),TWe=r(jCe," (Bertweet model)"),jCe.forEach(t),FWe=i(y),Jn=n(y,"LI",{});var i8=s(Jn);nJ=n(i8,"STRONG",{});var nIr=s(nJ);CWe=r(nIr,"big_bird"),nIr.forEach(t),MWe=r(i8," \u2014 "),cx=n(i8,"A",{href:!0});var sIr=s(cx);EWe=r(sIr,"BigBirdTokenizer"),sIr.forEach(t),yWe=r(i8," or "),fx=n(i8,"A",{href:!0});var lIr=s(fx);wWe=r(lIr,"BigBirdTokenizerFast"),lIr.forEach(t),AWe=r(i8," (BigBird model)"),i8.forEach(t),LWe=i(y),Yn=n(y,"LI",{});var d8=s(Yn);sJ=n(d8,"STRONG",{});var iIr=s(sJ);BWe=r(iIr,"bigbird_pegasus"),iIr.forEach(t),xWe=r(d8," \u2014 "),mx=n(d8,"A",{href:!0});var dIr=s(mx);kWe=r(dIr,"PegasusTokenizer"),dIr.forEach(t),RWe=r(d8," or "),gx=n(d8,"A",{href:!0});var cIr=s(gx);SWe=r(cIr,"PegasusTokenizerFast"),cIr.forEach(t),PWe=r(d8," (BigBirdPegasus model)"),d8.forEach(t),$We=i(y),Kn=n(y,"LI",{});var c8=s(Kn);lJ=n(c8,"STRONG",{});var fIr=s(lJ);IWe=r(fIr,"blenderbot"),fIr.forEach(t),NWe=r(c8," \u2014 "),hx=n(c8,"A",{href:!0});var mIr=s(hx);DWe=r(mIr,"BlenderbotTokenizer"),mIr.forEach(t),jWe=r(c8," or "),px=n(c8,"A",{href:!0});var gIr=s(px);qWe=r(gIr,"BlenderbotTokenizerFast"),gIr.forEach(t),GWe=r(c8," (Blenderbot model)"),c8.forEach(t),OWe=i(y),jg=n(y,"LI",{});var qCe=s(jg);iJ=n(qCe,"STRONG",{});var hIr=s(iJ);XWe=r(hIr,"blenderbot-small"),hIr.forEach(t),VWe=r(qCe," \u2014 "),_x=n(qCe,"A",{href:!0});var pIr=s(_x);zWe=r(pIr,"BlenderbotSmallTokenizer"),pIr.forEach(t),WWe=r(qCe," (BlenderbotSmall model)"),qCe.forEach(t),QWe=i(y),qg=n(y,"LI",{});var GCe=s(qg);dJ=n(GCe,"STRONG",{});var _Ir=s(dJ);HWe=r(_Ir,"byt5"),_Ir.forEach(t),UWe=r(GCe," \u2014 "),ux=n(GCe,"A",{href:!0});var uIr=s(ux);JWe=r(uIr,"ByT5Tokenizer"),uIr.forEach(t),YWe=r(GCe," (ByT5 model)"),GCe.forEach(t),KWe=i(y),Zn=n(y,"LI",{});var f8=s(Zn);cJ=n(f8,"STRONG",{});var bIr=s(cJ);ZWe=r(bIr,"camembert"),bIr.forEach(t),eQe=r(f8," \u2014 "),bx=n(f8,"A",{href:!0});var vIr=s(bx);oQe=r(vIr,"CamembertTokenizer"),vIr.forEach(t),rQe=r(f8," or "),vx=n(f8,"A",{href:!0});var TIr=s(vx);tQe=r(TIr,"CamembertTokenizerFast"),TIr.forEach(t),aQe=r(f8," (CamemBERT model)"),f8.forEach(t),nQe=i(y),Gg=n(y,"LI",{});var OCe=s(Gg);fJ=n(OCe,"STRONG",{});var FIr=s(fJ);sQe=r(FIr,"canine"),FIr.forEach(t),lQe=r(OCe," \u2014 "),Tx=n(OCe,"A",{href:!0});var CIr=s(Tx);iQe=r(CIr,"CanineTokenizer"),CIr.forEach(t),dQe=r(OCe," (Canine model)"),OCe.forEach(t),cQe=i(y),es=n(y,"LI",{});var m8=s(es);mJ=n(m8,"STRONG",{});var MIr=s(mJ);fQe=r(MIr,"clip"),MIr.forEach(t),mQe=r(m8," \u2014 "),Fx=n(m8,"A",{href:!0});var EIr=s(Fx);gQe=r(EIr,"CLIPTokenizer"),EIr.forEach(t),hQe=r(m8," or "),Cx=n(m8,"A",{href:!0});var yIr=s(Cx);pQe=r(yIr,"CLIPTokenizerFast"),yIr.forEach(t),_Qe=r(m8," (CLIP model)"),m8.forEach(t),uQe=i(y),os=n(y,"LI",{});var g8=s(os);gJ=n(g8,"STRONG",{});var wIr=s(gJ);bQe=r(wIr,"convbert"),wIr.forEach(t),vQe=r(g8," \u2014 "),Mx=n(g8,"A",{href:!0});var AIr=s(Mx);TQe=r(AIr,"ConvBertTokenizer"),AIr.forEach(t),FQe=r(g8," or "),Ex=n(g8,"A",{href:!0});var LIr=s(Ex);CQe=r(LIr,"ConvBertTokenizerFast"),LIr.forEach(t),MQe=r(g8," (ConvBERT model)"),g8.forEach(t),EQe=i(y),rs=n(y,"LI",{});var h8=s(rs);hJ=n(h8,"STRONG",{});var BIr=s(hJ);yQe=r(BIr,"cpm"),BIr.forEach(t),wQe=r(h8," \u2014 "),yx=n(h8,"A",{href:!0});var xIr=s(yx);AQe=r(xIr,"CpmTokenizer"),xIr.forEach(t),LQe=r(h8," or "),pJ=n(h8,"CODE",{});var kIr=s(pJ);BQe=r(kIr,"CpmTokenizerFast"),kIr.forEach(t),xQe=r(h8," (CPM model)"),h8.forEach(t),kQe=i(y),Og=n(y,"LI",{});var XCe=s(Og);_J=n(XCe,"STRONG",{});var RIr=s(_J);RQe=r(RIr,"ctrl"),RIr.forEach(t),SQe=r(XCe," \u2014 "),wx=n(XCe,"A",{href:!0});var SIr=s(wx);PQe=r(SIr,"CTRLTokenizer"),SIr.forEach(t),$Qe=r(XCe," (CTRL model)"),XCe.forEach(t),IQe=i(y),ts=n(y,"LI",{});var p8=s(ts);uJ=n(p8,"STRONG",{});var PIr=s(uJ);NQe=r(PIr,"deberta"),PIr.forEach(t),DQe=r(p8," \u2014 "),Ax=n(p8,"A",{href:!0});var $Ir=s(Ax);jQe=r($Ir,"DebertaTokenizer"),$Ir.forEach(t),qQe=r(p8," or "),Lx=n(p8,"A",{href:!0});var IIr=s(Lx);GQe=r(IIr,"DebertaTokenizerFast"),IIr.forEach(t),OQe=r(p8," (DeBERTa model)"),p8.forEach(t),XQe=i(y),Xg=n(y,"LI",{});var VCe=s(Xg);bJ=n(VCe,"STRONG",{});var NIr=s(bJ);VQe=r(NIr,"deberta-v2"),NIr.forEach(t),zQe=r(VCe," \u2014 "),Bx=n(VCe,"A",{href:!0});var DIr=s(Bx);WQe=r(DIr,"DebertaV2Tokenizer"),DIr.forEach(t),QQe=r(VCe," (DeBERTa-v2 model)"),VCe.forEach(t),HQe=i(y),as=n(y,"LI",{});var _8=s(as);vJ=n(_8,"STRONG",{});var jIr=s(vJ);UQe=r(jIr,"distilbert"),jIr.forEach(t),JQe=r(_8," \u2014 "),xx=n(_8,"A",{href:!0});var qIr=s(xx);YQe=r(qIr,"DistilBertTokenizer"),qIr.forEach(t),KQe=r(_8," or "),kx=n(_8,"A",{href:!0});var GIr=s(kx);ZQe=r(GIr,"DistilBertTokenizerFast"),GIr.forEach(t),eHe=r(_8," (DistilBERT model)"),_8.forEach(t),oHe=i(y),ns=n(y,"LI",{});var u8=s(ns);TJ=n(u8,"STRONG",{});var OIr=s(TJ);rHe=r(OIr,"dpr"),OIr.forEach(t),tHe=r(u8," \u2014 "),Rx=n(u8,"A",{href:!0});var XIr=s(Rx);aHe=r(XIr,"DPRQuestionEncoderTokenizer"),XIr.forEach(t),nHe=r(u8," or "),Sx=n(u8,"A",{href:!0});var VIr=s(Sx);sHe=r(VIr,"DPRQuestionEncoderTokenizerFast"),VIr.forEach(t),lHe=r(u8," (DPR model)"),u8.forEach(t),iHe=i(y),ss=n(y,"LI",{});var b8=s(ss);FJ=n(b8,"STRONG",{});var zIr=s(FJ);dHe=r(zIr,"electra"),zIr.forEach(t),cHe=r(b8," \u2014 "),Px=n(b8,"A",{href:!0});var WIr=s(Px);fHe=r(WIr,"ElectraTokenizer"),WIr.forEach(t),mHe=r(b8," or "),$x=n(b8,"A",{href:!0});var QIr=s($x);gHe=r(QIr,"ElectraTokenizerFast"),QIr.forEach(t),hHe=r(b8," (ELECTRA model)"),b8.forEach(t),pHe=i(y),Vg=n(y,"LI",{});var zCe=s(Vg);CJ=n(zCe,"STRONG",{});var HIr=s(CJ);_He=r(HIr,"flaubert"),HIr.forEach(t),uHe=r(zCe," \u2014 "),Ix=n(zCe,"A",{href:!0});var UIr=s(Ix);bHe=r(UIr,"FlaubertTokenizer"),UIr.forEach(t),vHe=r(zCe," (FlauBERT model)"),zCe.forEach(t),THe=i(y),ls=n(y,"LI",{});var v8=s(ls);MJ=n(v8,"STRONG",{});var JIr=s(MJ);FHe=r(JIr,"fnet"),JIr.forEach(t),CHe=r(v8," \u2014 "),Nx=n(v8,"A",{href:!0});var YIr=s(Nx);MHe=r(YIr,"FNetTokenizer"),YIr.forEach(t),EHe=r(v8," or "),Dx=n(v8,"A",{href:!0});var KIr=s(Dx);yHe=r(KIr,"FNetTokenizerFast"),KIr.forEach(t),wHe=r(v8," (FNet model)"),v8.forEach(t),AHe=i(y),zg=n(y,"LI",{});var WCe=s(zg);EJ=n(WCe,"STRONG",{});var ZIr=s(EJ);LHe=r(ZIr,"fsmt"),ZIr.forEach(t),BHe=r(WCe," \u2014 "),jx=n(WCe,"A",{href:!0});var eNr=s(jx);xHe=r(eNr,"FSMTTokenizer"),eNr.forEach(t),kHe=r(WCe," (FairSeq Machine-Translation model)"),WCe.forEach(t),RHe=i(y),is=n(y,"LI",{});var T8=s(is);yJ=n(T8,"STRONG",{});var oNr=s(yJ);SHe=r(oNr,"funnel"),oNr.forEach(t),PHe=r(T8," \u2014 "),qx=n(T8,"A",{href:!0});var rNr=s(qx);$He=r(rNr,"FunnelTokenizer"),rNr.forEach(t),IHe=r(T8," or "),Gx=n(T8,"A",{href:!0});var tNr=s(Gx);NHe=r(tNr,"FunnelTokenizerFast"),tNr.forEach(t),DHe=r(T8," (Funnel Transformer model)"),T8.forEach(t),jHe=i(y),ds=n(y,"LI",{});var F8=s(ds);wJ=n(F8,"STRONG",{});var aNr=s(wJ);qHe=r(aNr,"gpt2"),aNr.forEach(t),GHe=r(F8," \u2014 "),Ox=n(F8,"A",{href:!0});var nNr=s(Ox);OHe=r(nNr,"GPT2Tokenizer"),nNr.forEach(t),XHe=r(F8," or "),Xx=n(F8,"A",{href:!0});var sNr=s(Xx);VHe=r(sNr,"GPT2TokenizerFast"),sNr.forEach(t),zHe=r(F8," (OpenAI GPT-2 model)"),F8.forEach(t),WHe=i(y),cs=n(y,"LI",{});var C8=s(cs);AJ=n(C8,"STRONG",{});var lNr=s(AJ);QHe=r(lNr,"gpt_neo"),lNr.forEach(t),HHe=r(C8," \u2014 "),Vx=n(C8,"A",{href:!0});var iNr=s(Vx);UHe=r(iNr,"GPT2Tokenizer"),iNr.forEach(t),JHe=r(C8," or "),zx=n(C8,"A",{href:!0});var dNr=s(zx);YHe=r(dNr,"GPT2TokenizerFast"),dNr.forEach(t),KHe=r(C8," (GPT Neo model)"),C8.forEach(t),ZHe=i(y),fs=n(y,"LI",{});var M8=s(fs);LJ=n(M8,"STRONG",{});var cNr=s(LJ);eUe=r(cNr,"herbert"),cNr.forEach(t),oUe=r(M8," \u2014 "),Wx=n(M8,"A",{href:!0});var fNr=s(Wx);rUe=r(fNr,"HerbertTokenizer"),fNr.forEach(t),tUe=r(M8," or "),Qx=n(M8,"A",{href:!0});var mNr=s(Qx);aUe=r(mNr,"HerbertTokenizerFast"),mNr.forEach(t),nUe=r(M8," (HerBERT model)"),M8.forEach(t),sUe=i(y),Wg=n(y,"LI",{});var QCe=s(Wg);BJ=n(QCe,"STRONG",{});var gNr=s(BJ);lUe=r(gNr,"hubert"),gNr.forEach(t),iUe=r(QCe," \u2014 "),Hx=n(QCe,"A",{href:!0});var hNr=s(Hx);dUe=r(hNr,"Wav2Vec2CTCTokenizer"),hNr.forEach(t),cUe=r(QCe," (Hubert model)"),QCe.forEach(t),fUe=i(y),ms=n(y,"LI",{});var E8=s(ms);xJ=n(E8,"STRONG",{});var pNr=s(xJ);mUe=r(pNr,"ibert"),pNr.forEach(t),gUe=r(E8," \u2014 "),Ux=n(E8,"A",{href:!0});var _Nr=s(Ux);hUe=r(_Nr,"RobertaTokenizer"),_Nr.forEach(t),pUe=r(E8," or "),Jx=n(E8,"A",{href:!0});var uNr=s(Jx);_Ue=r(uNr,"RobertaTokenizerFast"),uNr.forEach(t),uUe=r(E8," (I-BERT model)"),E8.forEach(t),bUe=i(y),gs=n(y,"LI",{});var y8=s(gs);kJ=n(y8,"STRONG",{});var bNr=s(kJ);vUe=r(bNr,"layoutlm"),bNr.forEach(t),TUe=r(y8," \u2014 "),Yx=n(y8,"A",{href:!0});var vNr=s(Yx);FUe=r(vNr,"LayoutLMTokenizer"),vNr.forEach(t),CUe=r(y8," or "),Kx=n(y8,"A",{href:!0});var TNr=s(Kx);MUe=r(TNr,"LayoutLMTokenizerFast"),TNr.forEach(t),EUe=r(y8," (LayoutLM model)"),y8.forEach(t),yUe=i(y),hs=n(y,"LI",{});var w8=s(hs);RJ=n(w8,"STRONG",{});var FNr=s(RJ);wUe=r(FNr,"layoutlmv2"),FNr.forEach(t),AUe=r(w8," \u2014 "),Zx=n(w8,"A",{href:!0});var CNr=s(Zx);LUe=r(CNr,"LayoutLMv2Tokenizer"),CNr.forEach(t),BUe=r(w8," or "),ek=n(w8,"A",{href:!0});var MNr=s(ek);xUe=r(MNr,"LayoutLMv2TokenizerFast"),MNr.forEach(t),kUe=r(w8," (LayoutLMv2 model)"),w8.forEach(t),RUe=i(y),ps=n(y,"LI",{});var A8=s(ps);SJ=n(A8,"STRONG",{});var ENr=s(SJ);SUe=r(ENr,"layoutxlm"),ENr.forEach(t),PUe=r(A8," \u2014 "),ok=n(A8,"A",{href:!0});var yNr=s(ok);$Ue=r(yNr,"LayoutXLMTokenizer"),yNr.forEach(t),IUe=r(A8," or "),rk=n(A8,"A",{href:!0});var wNr=s(rk);NUe=r(wNr,"LayoutXLMTokenizerFast"),wNr.forEach(t),DUe=r(A8," (LayoutXLM model)"),A8.forEach(t),jUe=i(y),_s=n(y,"LI",{});var L8=s(_s);PJ=n(L8,"STRONG",{});var ANr=s(PJ);qUe=r(ANr,"led"),ANr.forEach(t),GUe=r(L8," \u2014 "),tk=n(L8,"A",{href:!0});var LNr=s(tk);OUe=r(LNr,"LEDTokenizer"),LNr.forEach(t),XUe=r(L8," or "),ak=n(L8,"A",{href:!0});var BNr=s(ak);VUe=r(BNr,"LEDTokenizerFast"),BNr.forEach(t),zUe=r(L8," (LED model)"),L8.forEach(t),WUe=i(y),us=n(y,"LI",{});var B8=s(us);$J=n(B8,"STRONG",{});var xNr=s($J);QUe=r(xNr,"longformer"),xNr.forEach(t),HUe=r(B8," \u2014 "),nk=n(B8,"A",{href:!0});var kNr=s(nk);UUe=r(kNr,"LongformerTokenizer"),kNr.forEach(t),JUe=r(B8," or "),sk=n(B8,"A",{href:!0});var RNr=s(sk);YUe=r(RNr,"LongformerTokenizerFast"),RNr.forEach(t),KUe=r(B8," (Longformer model)"),B8.forEach(t),ZUe=i(y),Qg=n(y,"LI",{});var HCe=s(Qg);IJ=n(HCe,"STRONG",{});var SNr=s(IJ);eJe=r(SNr,"luke"),SNr.forEach(t),oJe=r(HCe," \u2014 "),lk=n(HCe,"A",{href:!0});var PNr=s(lk);rJe=r(PNr,"LukeTokenizer"),PNr.forEach(t),tJe=r(HCe," (LUKE model)"),HCe.forEach(t),aJe=i(y),bs=n(y,"LI",{});var x8=s(bs);NJ=n(x8,"STRONG",{});var $Nr=s(NJ);nJe=r($Nr,"lxmert"),$Nr.forEach(t),sJe=r(x8," \u2014 "),ik=n(x8,"A",{href:!0});var INr=s(ik);lJe=r(INr,"LxmertTokenizer"),INr.forEach(t),iJe=r(x8," or "),dk=n(x8,"A",{href:!0});var NNr=s(dk);dJe=r(NNr,"LxmertTokenizerFast"),NNr.forEach(t),cJe=r(x8," (LXMERT model)"),x8.forEach(t),fJe=i(y),Hg=n(y,"LI",{});var UCe=s(Hg);DJ=n(UCe,"STRONG",{});var DNr=s(DJ);mJe=r(DNr,"m2m_100"),DNr.forEach(t),gJe=r(UCe," \u2014 "),ck=n(UCe,"A",{href:!0});var jNr=s(ck);hJe=r(jNr,"M2M100Tokenizer"),jNr.forEach(t),pJe=r(UCe," (M2M100 model)"),UCe.forEach(t),_Je=i(y),Ug=n(y,"LI",{});var JCe=s(Ug);jJ=n(JCe,"STRONG",{});var qNr=s(jJ);uJe=r(qNr,"marian"),qNr.forEach(t),bJe=r(JCe," \u2014 "),fk=n(JCe,"A",{href:!0});var GNr=s(fk);vJe=r(GNr,"MarianTokenizer"),GNr.forEach(t),TJe=r(JCe," (Marian model)"),JCe.forEach(t),FJe=i(y),vs=n(y,"LI",{});var k8=s(vs);qJ=n(k8,"STRONG",{});var ONr=s(qJ);CJe=r(ONr,"mbart"),ONr.forEach(t),MJe=r(k8," \u2014 "),mk=n(k8,"A",{href:!0});var XNr=s(mk);EJe=r(XNr,"MBartTokenizer"),XNr.forEach(t),yJe=r(k8," or "),gk=n(k8,"A",{href:!0});var VNr=s(gk);wJe=r(VNr,"MBartTokenizerFast"),VNr.forEach(t),AJe=r(k8," (mBART model)"),k8.forEach(t),LJe=i(y),Ts=n(y,"LI",{});var R8=s(Ts);GJ=n(R8,"STRONG",{});var zNr=s(GJ);BJe=r(zNr,"mbart50"),zNr.forEach(t),xJe=r(R8," \u2014 "),hk=n(R8,"A",{href:!0});var WNr=s(hk);kJe=r(WNr,"MBart50Tokenizer"),WNr.forEach(t),RJe=r(R8," or "),pk=n(R8,"A",{href:!0});var QNr=s(pk);SJe=r(QNr,"MBart50TokenizerFast"),QNr.forEach(t),PJe=r(R8," (mBART-50 model)"),R8.forEach(t),$Je=i(y),Jg=n(y,"LI",{});var YCe=s(Jg);OJ=n(YCe,"STRONG",{});var HNr=s(OJ);IJe=r(HNr,"mluke"),HNr.forEach(t),NJe=r(YCe," \u2014 "),_k=n(YCe,"A",{href:!0});var UNr=s(_k);DJe=r(UNr,"MLukeTokenizer"),UNr.forEach(t),jJe=r(YCe," (mLUKE model)"),YCe.forEach(t),qJe=i(y),Fs=n(y,"LI",{});var S8=s(Fs);XJ=n(S8,"STRONG",{});var JNr=s(XJ);GJe=r(JNr,"mobilebert"),JNr.forEach(t),OJe=r(S8," \u2014 "),uk=n(S8,"A",{href:!0});var YNr=s(uk);XJe=r(YNr,"MobileBertTokenizer"),YNr.forEach(t),VJe=r(S8," or "),bk=n(S8,"A",{href:!0});var KNr=s(bk);zJe=r(KNr,"MobileBertTokenizerFast"),KNr.forEach(t),WJe=r(S8," (MobileBERT model)"),S8.forEach(t),QJe=i(y),Cs=n(y,"LI",{});var P8=s(Cs);VJ=n(P8,"STRONG",{});var ZNr=s(VJ);HJe=r(ZNr,"mpnet"),ZNr.forEach(t),UJe=r(P8," \u2014 "),vk=n(P8,"A",{href:!0});var eDr=s(vk);JJe=r(eDr,"MPNetTokenizer"),eDr.forEach(t),YJe=r(P8," or "),Tk=n(P8,"A",{href:!0});var oDr=s(Tk);KJe=r(oDr,"MPNetTokenizerFast"),oDr.forEach(t),ZJe=r(P8," (MPNet model)"),P8.forEach(t),eYe=i(y),Ms=n(y,"LI",{});var $8=s(Ms);zJ=n($8,"STRONG",{});var rDr=s(zJ);oYe=r(rDr,"mt5"),rDr.forEach(t),rYe=r($8," \u2014 "),Fk=n($8,"A",{href:!0});var tDr=s(Fk);tYe=r(tDr,"MT5Tokenizer"),tDr.forEach(t),aYe=r($8," or "),Ck=n($8,"A",{href:!0});var aDr=s(Ck);nYe=r(aDr,"MT5TokenizerFast"),aDr.forEach(t),sYe=r($8," (mT5 model)"),$8.forEach(t),lYe=i(y),Es=n(y,"LI",{});var I8=s(Es);WJ=n(I8,"STRONG",{});var nDr=s(WJ);iYe=r(nDr,"openai-gpt"),nDr.forEach(t),dYe=r(I8," \u2014 "),Mk=n(I8,"A",{href:!0});var sDr=s(Mk);cYe=r(sDr,"OpenAIGPTTokenizer"),sDr.forEach(t),fYe=r(I8," or "),Ek=n(I8,"A",{href:!0});var lDr=s(Ek);mYe=r(lDr,"OpenAIGPTTokenizerFast"),lDr.forEach(t),gYe=r(I8," (OpenAI GPT model)"),I8.forEach(t),hYe=i(y),ys=n(y,"LI",{});var N8=s(ys);QJ=n(N8,"STRONG",{});var iDr=s(QJ);pYe=r(iDr,"pegasus"),iDr.forEach(t),_Ye=r(N8," \u2014 "),yk=n(N8,"A",{href:!0});var dDr=s(yk);uYe=r(dDr,"PegasusTokenizer"),dDr.forEach(t),bYe=r(N8," or "),wk=n(N8,"A",{href:!0});var cDr=s(wk);vYe=r(cDr,"PegasusTokenizerFast"),cDr.forEach(t),TYe=r(N8," (Pegasus model)"),N8.forEach(t),FYe=i(y),Yg=n(y,"LI",{});var KCe=s(Yg);HJ=n(KCe,"STRONG",{});var fDr=s(HJ);CYe=r(fDr,"perceiver"),fDr.forEach(t),MYe=r(KCe," \u2014 "),Ak=n(KCe,"A",{href:!0});var mDr=s(Ak);EYe=r(mDr,"PerceiverTokenizer"),mDr.forEach(t),yYe=r(KCe," (Perceiver model)"),KCe.forEach(t),wYe=i(y),Kg=n(y,"LI",{});var ZCe=s(Kg);UJ=n(ZCe,"STRONG",{});var gDr=s(UJ);AYe=r(gDr,"phobert"),gDr.forEach(t),LYe=r(ZCe," \u2014 "),Lk=n(ZCe,"A",{href:!0});var hDr=s(Lk);BYe=r(hDr,"PhobertTokenizer"),hDr.forEach(t),xYe=r(ZCe," (PhoBERT model)"),ZCe.forEach(t),kYe=i(y),Zg=n(y,"LI",{});var eMe=s(Zg);JJ=n(eMe,"STRONG",{});var pDr=s(JJ);RYe=r(pDr,"plbart"),pDr.forEach(t),SYe=r(eMe," \u2014 "),Bk=n(eMe,"A",{href:!0});var _Dr=s(Bk);PYe=r(_Dr,"PLBartTokenizer"),_Dr.forEach(t),$Ye=r(eMe," (PLBart model)"),eMe.forEach(t),IYe=i(y),eh=n(y,"LI",{});var oMe=s(eh);YJ=n(oMe,"STRONG",{});var uDr=s(YJ);NYe=r(uDr,"prophetnet"),uDr.forEach(t),DYe=r(oMe," \u2014 "),xk=n(oMe,"A",{href:!0});var bDr=s(xk);jYe=r(bDr,"ProphetNetTokenizer"),bDr.forEach(t),qYe=r(oMe," (ProphetNet model)"),oMe.forEach(t),GYe=i(y),ws=n(y,"LI",{});var D8=s(ws);KJ=n(D8,"STRONG",{});var vDr=s(KJ);OYe=r(vDr,"qdqbert"),vDr.forEach(t),XYe=r(D8," \u2014 "),kk=n(D8,"A",{href:!0});var TDr=s(kk);VYe=r(TDr,"BertTokenizer"),TDr.forEach(t),zYe=r(D8," or "),Rk=n(D8,"A",{href:!0});var FDr=s(Rk);WYe=r(FDr,"BertTokenizerFast"),FDr.forEach(t),QYe=r(D8," (QDQBert model)"),D8.forEach(t),HYe=i(y),oh=n(y,"LI",{});var rMe=s(oh);ZJ=n(rMe,"STRONG",{});var CDr=s(ZJ);UYe=r(CDr,"rag"),CDr.forEach(t),JYe=r(rMe," \u2014 "),Sk=n(rMe,"A",{href:!0});var MDr=s(Sk);YYe=r(MDr,"RagTokenizer"),MDr.forEach(t),KYe=r(rMe," (RAG model)"),rMe.forEach(t),ZYe=i(y),As=n(y,"LI",{});var j8=s(As);eY=n(j8,"STRONG",{});var EDr=s(eY);eKe=r(EDr,"realm"),EDr.forEach(t),oKe=r(j8," \u2014 "),Pk=n(j8,"A",{href:!0});var yDr=s(Pk);rKe=r(yDr,"RealmTokenizer"),yDr.forEach(t),tKe=r(j8," or "),$k=n(j8,"A",{href:!0});var wDr=s($k);aKe=r(wDr,"RealmTokenizerFast"),wDr.forEach(t),nKe=r(j8," (Realm model)"),j8.forEach(t),sKe=i(y),Ls=n(y,"LI",{});var q8=s(Ls);oY=n(q8,"STRONG",{});var ADr=s(oY);lKe=r(ADr,"reformer"),ADr.forEach(t),iKe=r(q8," \u2014 "),Ik=n(q8,"A",{href:!0});var LDr=s(Ik);dKe=r(LDr,"ReformerTokenizer"),LDr.forEach(t),cKe=r(q8," or "),Nk=n(q8,"A",{href:!0});var BDr=s(Nk);fKe=r(BDr,"ReformerTokenizerFast"),BDr.forEach(t),mKe=r(q8," (Reformer model)"),q8.forEach(t),gKe=i(y),Bs=n(y,"LI",{});var G8=s(Bs);rY=n(G8,"STRONG",{});var xDr=s(rY);hKe=r(xDr,"rembert"),xDr.forEach(t),pKe=r(G8," \u2014 "),Dk=n(G8,"A",{href:!0});var kDr=s(Dk);_Ke=r(kDr,"RemBertTokenizer"),kDr.forEach(t),uKe=r(G8," or "),jk=n(G8,"A",{href:!0});var RDr=s(jk);bKe=r(RDr,"RemBertTokenizerFast"),RDr.forEach(t),vKe=r(G8," (RemBERT model)"),G8.forEach(t),TKe=i(y),xs=n(y,"LI",{});var O8=s(xs);tY=n(O8,"STRONG",{});var SDr=s(tY);FKe=r(SDr,"retribert"),SDr.forEach(t),CKe=r(O8," \u2014 "),qk=n(O8,"A",{href:!0});var PDr=s(qk);MKe=r(PDr,"RetriBertTokenizer"),PDr.forEach(t),EKe=r(O8," or "),Gk=n(O8,"A",{href:!0});var $Dr=s(Gk);yKe=r($Dr,"RetriBertTokenizerFast"),$Dr.forEach(t),wKe=r(O8," (RetriBERT model)"),O8.forEach(t),AKe=i(y),ks=n(y,"LI",{});var X8=s(ks);aY=n(X8,"STRONG",{});var IDr=s(aY);LKe=r(IDr,"roberta"),IDr.forEach(t),BKe=r(X8," \u2014 "),Ok=n(X8,"A",{href:!0});var NDr=s(Ok);xKe=r(NDr,"RobertaTokenizer"),NDr.forEach(t),kKe=r(X8," or "),Xk=n(X8,"A",{href:!0});var DDr=s(Xk);RKe=r(DDr,"RobertaTokenizerFast"),DDr.forEach(t),SKe=r(X8," (RoBERTa model)"),X8.forEach(t),PKe=i(y),Rs=n(y,"LI",{});var V8=s(Rs);nY=n(V8,"STRONG",{});var jDr=s(nY);$Ke=r(jDr,"roformer"),jDr.forEach(t),IKe=r(V8," \u2014 "),Vk=n(V8,"A",{href:!0});var qDr=s(Vk);NKe=r(qDr,"RoFormerTokenizer"),qDr.forEach(t),DKe=r(V8," or "),zk=n(V8,"A",{href:!0});var GDr=s(zk);jKe=r(GDr,"RoFormerTokenizerFast"),GDr.forEach(t),qKe=r(V8," (RoFormer model)"),V8.forEach(t),GKe=i(y),rh=n(y,"LI",{});var tMe=s(rh);sY=n(tMe,"STRONG",{});var ODr=s(sY);OKe=r(ODr,"speech_to_text"),ODr.forEach(t),XKe=r(tMe," \u2014 "),Wk=n(tMe,"A",{href:!0});var XDr=s(Wk);VKe=r(XDr,"Speech2TextTokenizer"),XDr.forEach(t),zKe=r(tMe," (Speech2Text model)"),tMe.forEach(t),WKe=i(y),th=n(y,"LI",{});var aMe=s(th);lY=n(aMe,"STRONG",{});var VDr=s(lY);QKe=r(VDr,"speech_to_text_2"),VDr.forEach(t),HKe=r(aMe," \u2014 "),Qk=n(aMe,"A",{href:!0});var zDr=s(Qk);UKe=r(zDr,"Speech2Text2Tokenizer"),zDr.forEach(t),JKe=r(aMe," (Speech2Text2 model)"),aMe.forEach(t),YKe=i(y),Ss=n(y,"LI",{});var z8=s(Ss);iY=n(z8,"STRONG",{});var WDr=s(iY);KKe=r(WDr,"splinter"),WDr.forEach(t),ZKe=r(z8," \u2014 "),Hk=n(z8,"A",{href:!0});var QDr=s(Hk);eZe=r(QDr,"SplinterTokenizer"),QDr.forEach(t),oZe=r(z8," or "),Uk=n(z8,"A",{href:!0});var HDr=s(Uk);rZe=r(HDr,"SplinterTokenizerFast"),HDr.forEach(t),tZe=r(z8," (Splinter model)"),z8.forEach(t),aZe=i(y),Ps=n(y,"LI",{});var W8=s(Ps);dY=n(W8,"STRONG",{});var UDr=s(dY);nZe=r(UDr,"squeezebert"),UDr.forEach(t),sZe=r(W8," \u2014 "),Jk=n(W8,"A",{href:!0});var JDr=s(Jk);lZe=r(JDr,"SqueezeBertTokenizer"),JDr.forEach(t),iZe=r(W8," or "),Yk=n(W8,"A",{href:!0});var YDr=s(Yk);dZe=r(YDr,"SqueezeBertTokenizerFast"),YDr.forEach(t),cZe=r(W8," (SqueezeBERT model)"),W8.forEach(t),fZe=i(y),$s=n(y,"LI",{});var Q8=s($s);cY=n(Q8,"STRONG",{});var KDr=s(cY);mZe=r(KDr,"t5"),KDr.forEach(t),gZe=r(Q8," \u2014 "),Kk=n(Q8,"A",{href:!0});var ZDr=s(Kk);hZe=r(ZDr,"T5Tokenizer"),ZDr.forEach(t),pZe=r(Q8," or "),Zk=n(Q8,"A",{href:!0});var ejr=s(Zk);_Ze=r(ejr,"T5TokenizerFast"),ejr.forEach(t),uZe=r(Q8," (T5 model)"),Q8.forEach(t),bZe=i(y),ah=n(y,"LI",{});var nMe=s(ah);fY=n(nMe,"STRONG",{});var ojr=s(fY);vZe=r(ojr,"tapas"),ojr.forEach(t),TZe=r(nMe," \u2014 "),eR=n(nMe,"A",{href:!0});var rjr=s(eR);FZe=r(rjr,"TapasTokenizer"),rjr.forEach(t),CZe=r(nMe," (TAPAS model)"),nMe.forEach(t),MZe=i(y),nh=n(y,"LI",{});var sMe=s(nh);mY=n(sMe,"STRONG",{});var tjr=s(mY);EZe=r(tjr,"transfo-xl"),tjr.forEach(t),yZe=r(sMe," \u2014 "),oR=n(sMe,"A",{href:!0});var ajr=s(oR);wZe=r(ajr,"TransfoXLTokenizer"),ajr.forEach(t),AZe=r(sMe," (Transformer-XL model)"),sMe.forEach(t),LZe=i(y),sh=n(y,"LI",{});var lMe=s(sh);gY=n(lMe,"STRONG",{});var njr=s(gY);BZe=r(njr,"wav2vec2"),njr.forEach(t),xZe=r(lMe," \u2014 "),rR=n(lMe,"A",{href:!0});var sjr=s(rR);kZe=r(sjr,"Wav2Vec2CTCTokenizer"),sjr.forEach(t),RZe=r(lMe," (Wav2Vec2 model)"),lMe.forEach(t),SZe=i(y),lh=n(y,"LI",{});var iMe=s(lh);hY=n(iMe,"STRONG",{});var ljr=s(hY);PZe=r(ljr,"wav2vec2_phoneme"),ljr.forEach(t),$Ze=r(iMe," \u2014 "),tR=n(iMe,"A",{href:!0});var ijr=s(tR);IZe=r(ijr,"Wav2Vec2PhonemeCTCTokenizer"),ijr.forEach(t),NZe=r(iMe," (Wav2Vec2Phoneme model)"),iMe.forEach(t),DZe=i(y),Is=n(y,"LI",{});var H8=s(Is);pY=n(H8,"STRONG",{});var djr=s(pY);jZe=r(djr,"xglm"),djr.forEach(t),qZe=r(H8," \u2014 "),aR=n(H8,"A",{href:!0});var cjr=s(aR);GZe=r(cjr,"XGLMTokenizer"),cjr.forEach(t),OZe=r(H8," or "),nR=n(H8,"A",{href:!0});var fjr=s(nR);XZe=r(fjr,"XGLMTokenizerFast"),fjr.forEach(t),VZe=r(H8," (XGLM model)"),H8.forEach(t),zZe=i(y),ih=n(y,"LI",{});var dMe=s(ih);_Y=n(dMe,"STRONG",{});var mjr=s(_Y);WZe=r(mjr,"xlm"),mjr.forEach(t),QZe=r(dMe," \u2014 "),sR=n(dMe,"A",{href:!0});var gjr=s(sR);HZe=r(gjr,"XLMTokenizer"),gjr.forEach(t),UZe=r(dMe," (XLM model)"),dMe.forEach(t),JZe=i(y),dh=n(y,"LI",{});var cMe=s(dh);uY=n(cMe,"STRONG",{});var hjr=s(uY);YZe=r(hjr,"xlm-prophetnet"),hjr.forEach(t),KZe=r(cMe," \u2014 "),lR=n(cMe,"A",{href:!0});var pjr=s(lR);ZZe=r(pjr,"XLMProphetNetTokenizer"),pjr.forEach(t),eeo=r(cMe," (XLMProphetNet model)"),cMe.forEach(t),oeo=i(y),Ns=n(y,"LI",{});var U8=s(Ns);bY=n(U8,"STRONG",{});var _jr=s(bY);reo=r(_jr,"xlm-roberta"),_jr.forEach(t),teo=r(U8," \u2014 "),iR=n(U8,"A",{href:!0});var ujr=s(iR);aeo=r(ujr,"XLMRobertaTokenizer"),ujr.forEach(t),neo=r(U8," or "),dR=n(U8,"A",{href:!0});var bjr=s(dR);seo=r(bjr,"XLMRobertaTokenizerFast"),bjr.forEach(t),leo=r(U8," (XLM-RoBERTa model)"),U8.forEach(t),ieo=i(y),Ds=n(y,"LI",{});var J8=s(Ds);vY=n(J8,"STRONG",{});var vjr=s(vY);deo=r(vjr,"xlnet"),vjr.forEach(t),ceo=r(J8," \u2014 "),cR=n(J8,"A",{href:!0});var Tjr=s(cR);feo=r(Tjr,"XLNetTokenizer"),Tjr.forEach(t),meo=r(J8," or "),fR=n(J8,"A",{href:!0});var Fjr=s(fR);geo=r(Fjr,"XLNetTokenizerFast"),Fjr.forEach(t),heo=r(J8," (XLNet model)"),J8.forEach(t),y.forEach(t),peo=i(ha),TY=n(ha,"P",{});var Cjr=s(TY);_eo=r(Cjr,"Examples:"),Cjr.forEach(t),ueo=i(ha),m(y3.$$.fragment,ha),ha.forEach(t),beo=i(Xs),ch=n(Xs,"DIV",{class:!0});var FSe=s(ch);m(w3.$$.fragment,FSe),veo=i(FSe),FY=n(FSe,"P",{});var Mjr=s(FY);Teo=r(Mjr,"Register a new tokenizer in this mapping."),Mjr.forEach(t),FSe.forEach(t),Xs.forEach(t),uke=i(c),Qi=n(c,"H2",{class:!0});var CSe=s(Qi);fh=n(CSe,"A",{id:!0,class:!0,href:!0});var Ejr=s(fh);CY=n(Ejr,"SPAN",{});var yjr=s(CY);m(A3.$$.fragment,yjr),yjr.forEach(t),Ejr.forEach(t),Feo=i(CSe),MY=n(CSe,"SPAN",{});var wjr=s(MY);Ceo=r(wjr,"AutoFeatureExtractor"),wjr.forEach(t),CSe.forEach(t),bke=i(c),Ho=n(c,"DIV",{class:!0});var Vs=s(Ho);m(L3.$$.fragment,Vs),Meo=i(Vs),B3=n(Vs,"P",{});var MSe=s(B3);Eeo=r(MSe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),mR=n(MSe,"A",{href:!0});var Ajr=s(mR);yeo=r(Ajr,"AutoFeatureExtractor.from_pretrained()"),Ajr.forEach(t),weo=r(MSe," class method."),MSe.forEach(t),Aeo=i(Vs),x3=n(Vs,"P",{});var ESe=s(x3);Leo=r(ESe,"This class cannot be instantiated directly using "),EY=n(ESe,"CODE",{});var Ljr=s(EY);Beo=r(Ljr,"__init__()"),Ljr.forEach(t),xeo=r(ESe," (throws an error)."),ESe.forEach(t),keo=i(Vs),$e=n(Vs,"DIV",{class:!0});var Dt=s($e);m(k3.$$.fragment,Dt),Reo=i(Dt),yY=n(Dt,"P",{});var Bjr=s(yY);Seo=r(Bjr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Bjr.forEach(t),Peo=i(Dt),Xa=n(Dt,"P",{});var cE=s(Xa);$eo=r(cE,"The feature extractor class to instantiate is selected based on the "),wY=n(cE,"CODE",{});var xjr=s(wY);Ieo=r(xjr,"model_type"),xjr.forEach(t),Neo=r(cE,` property of the config object
(either passed as an argument or loaded from `),AY=n(cE,"CODE",{});var kjr=s(AY);Deo=r(kjr,"pretrained_model_name_or_path"),kjr.forEach(t),jeo=r(cE,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),LY=n(cE,"CODE",{});var Rjr=s(LY);qeo=r(Rjr,"pretrained_model_name_or_path"),Rjr.forEach(t),Geo=r(cE,":"),cE.forEach(t),Oeo=i(Dt),re=n(Dt,"UL",{});var ne=s(re);mh=n(ne,"LI",{});var fMe=s(mh);BY=n(fMe,"STRONG",{});var Sjr=s(BY);Xeo=r(Sjr,"beit"),Sjr.forEach(t),Veo=r(fMe," \u2014 "),gR=n(fMe,"A",{href:!0});var Pjr=s(gR);zeo=r(Pjr,"BeitFeatureExtractor"),Pjr.forEach(t),Weo=r(fMe," (BEiT model)"),fMe.forEach(t),Qeo=i(ne),gh=n(ne,"LI",{});var mMe=s(gh);xY=n(mMe,"STRONG",{});var $jr=s(xY);Heo=r($jr,"clip"),$jr.forEach(t),Ueo=r(mMe," \u2014 "),hR=n(mMe,"A",{href:!0});var Ijr=s(hR);Jeo=r(Ijr,"CLIPFeatureExtractor"),Ijr.forEach(t),Yeo=r(mMe," (CLIP model)"),mMe.forEach(t),Keo=i(ne),hh=n(ne,"LI",{});var gMe=s(hh);kY=n(gMe,"STRONG",{});var Njr=s(kY);Zeo=r(Njr,"convnext"),Njr.forEach(t),eoo=r(gMe," \u2014 "),pR=n(gMe,"A",{href:!0});var Djr=s(pR);ooo=r(Djr,"ConvNextFeatureExtractor"),Djr.forEach(t),roo=r(gMe," (ConvNext model)"),gMe.forEach(t),too=i(ne),ph=n(ne,"LI",{});var hMe=s(ph);RY=n(hMe,"STRONG",{});var jjr=s(RY);aoo=r(jjr,"deit"),jjr.forEach(t),noo=r(hMe," \u2014 "),_R=n(hMe,"A",{href:!0});var qjr=s(_R);soo=r(qjr,"DeiTFeatureExtractor"),qjr.forEach(t),loo=r(hMe," (DeiT model)"),hMe.forEach(t),ioo=i(ne),_h=n(ne,"LI",{});var pMe=s(_h);SY=n(pMe,"STRONG",{});var Gjr=s(SY);doo=r(Gjr,"detr"),Gjr.forEach(t),coo=r(pMe," \u2014 "),uR=n(pMe,"A",{href:!0});var Ojr=s(uR);foo=r(Ojr,"DetrFeatureExtractor"),Ojr.forEach(t),moo=r(pMe," (DETR model)"),pMe.forEach(t),goo=i(ne),uh=n(ne,"LI",{});var _Me=s(uh);PY=n(_Me,"STRONG",{});var Xjr=s(PY);hoo=r(Xjr,"hubert"),Xjr.forEach(t),poo=r(_Me," \u2014 "),bR=n(_Me,"A",{href:!0});var Vjr=s(bR);_oo=r(Vjr,"Wav2Vec2FeatureExtractor"),Vjr.forEach(t),uoo=r(_Me," (Hubert model)"),_Me.forEach(t),boo=i(ne),bh=n(ne,"LI",{});var uMe=s(bh);$Y=n(uMe,"STRONG",{});var zjr=s($Y);voo=r(zjr,"layoutlmv2"),zjr.forEach(t),Too=r(uMe," \u2014 "),vR=n(uMe,"A",{href:!0});var Wjr=s(vR);Foo=r(Wjr,"LayoutLMv2FeatureExtractor"),Wjr.forEach(t),Coo=r(uMe," (LayoutLMv2 model)"),uMe.forEach(t),Moo=i(ne),vh=n(ne,"LI",{});var bMe=s(vh);IY=n(bMe,"STRONG",{});var Qjr=s(IY);Eoo=r(Qjr,"maskformer"),Qjr.forEach(t),yoo=r(bMe," \u2014 "),TR=n(bMe,"A",{href:!0});var Hjr=s(TR);woo=r(Hjr,"MaskFormerFeatureExtractor"),Hjr.forEach(t),Aoo=r(bMe," (MaskFormer model)"),bMe.forEach(t),Loo=i(ne),Th=n(ne,"LI",{});var vMe=s(Th);NY=n(vMe,"STRONG",{});var Ujr=s(NY);Boo=r(Ujr,"perceiver"),Ujr.forEach(t),xoo=r(vMe," \u2014 "),FR=n(vMe,"A",{href:!0});var Jjr=s(FR);koo=r(Jjr,"PerceiverFeatureExtractor"),Jjr.forEach(t),Roo=r(vMe," (Perceiver model)"),vMe.forEach(t),Soo=i(ne),Fh=n(ne,"LI",{});var TMe=s(Fh);DY=n(TMe,"STRONG",{});var Yjr=s(DY);Poo=r(Yjr,"poolformer"),Yjr.forEach(t),$oo=r(TMe," \u2014 "),CR=n(TMe,"A",{href:!0});var Kjr=s(CR);Ioo=r(Kjr,"PoolFormerFeatureExtractor"),Kjr.forEach(t),Noo=r(TMe," (PoolFormer model)"),TMe.forEach(t),Doo=i(ne),Ch=n(ne,"LI",{});var FMe=s(Ch);jY=n(FMe,"STRONG",{});var Zjr=s(jY);joo=r(Zjr,"resnet"),Zjr.forEach(t),qoo=r(FMe," \u2014 "),MR=n(FMe,"A",{href:!0});var eqr=s(MR);Goo=r(eqr,"ConvNextFeatureExtractor"),eqr.forEach(t),Ooo=r(FMe," (ResNet model)"),FMe.forEach(t),Xoo=i(ne),Mh=n(ne,"LI",{});var CMe=s(Mh);qY=n(CMe,"STRONG",{});var oqr=s(qY);Voo=r(oqr,"segformer"),oqr.forEach(t),zoo=r(CMe," \u2014 "),ER=n(CMe,"A",{href:!0});var rqr=s(ER);Woo=r(rqr,"SegformerFeatureExtractor"),rqr.forEach(t),Qoo=r(CMe," (SegFormer model)"),CMe.forEach(t),Hoo=i(ne),Eh=n(ne,"LI",{});var MMe=s(Eh);GY=n(MMe,"STRONG",{});var tqr=s(GY);Uoo=r(tqr,"speech_to_text"),tqr.forEach(t),Joo=r(MMe," \u2014 "),yR=n(MMe,"A",{href:!0});var aqr=s(yR);Yoo=r(aqr,"Speech2TextFeatureExtractor"),aqr.forEach(t),Koo=r(MMe," (Speech2Text model)"),MMe.forEach(t),Zoo=i(ne),yh=n(ne,"LI",{});var EMe=s(yh);OY=n(EMe,"STRONG",{});var nqr=s(OY);ero=r(nqr,"swin"),nqr.forEach(t),oro=r(EMe," \u2014 "),wR=n(EMe,"A",{href:!0});var sqr=s(wR);rro=r(sqr,"ViTFeatureExtractor"),sqr.forEach(t),tro=r(EMe," (Swin model)"),EMe.forEach(t),aro=i(ne),wh=n(ne,"LI",{});var yMe=s(wh);XY=n(yMe,"STRONG",{});var lqr=s(XY);nro=r(lqr,"van"),lqr.forEach(t),sro=r(yMe," \u2014 "),AR=n(yMe,"A",{href:!0});var iqr=s(AR);lro=r(iqr,"ConvNextFeatureExtractor"),iqr.forEach(t),iro=r(yMe," (VAN model)"),yMe.forEach(t),dro=i(ne),Ah=n(ne,"LI",{});var wMe=s(Ah);VY=n(wMe,"STRONG",{});var dqr=s(VY);cro=r(dqr,"vit"),dqr.forEach(t),fro=r(wMe," \u2014 "),LR=n(wMe,"A",{href:!0});var cqr=s(LR);mro=r(cqr,"ViTFeatureExtractor"),cqr.forEach(t),gro=r(wMe," (ViT model)"),wMe.forEach(t),hro=i(ne),Lh=n(ne,"LI",{});var AMe=s(Lh);zY=n(AMe,"STRONG",{});var fqr=s(zY);pro=r(fqr,"vit_mae"),fqr.forEach(t),_ro=r(AMe," \u2014 "),BR=n(AMe,"A",{href:!0});var mqr=s(BR);uro=r(mqr,"ViTFeatureExtractor"),mqr.forEach(t),bro=r(AMe," (ViTMAE model)"),AMe.forEach(t),vro=i(ne),Bh=n(ne,"LI",{});var LMe=s(Bh);WY=n(LMe,"STRONG",{});var gqr=s(WY);Tro=r(gqr,"wav2vec2"),gqr.forEach(t),Fro=r(LMe," \u2014 "),xR=n(LMe,"A",{href:!0});var hqr=s(xR);Cro=r(hqr,"Wav2Vec2FeatureExtractor"),hqr.forEach(t),Mro=r(LMe," (Wav2Vec2 model)"),LMe.forEach(t),ne.forEach(t),Ero=i(Dt),m(xh.$$.fragment,Dt),yro=i(Dt),QY=n(Dt,"P",{});var pqr=s(QY);wro=r(pqr,"Examples:"),pqr.forEach(t),Aro=i(Dt),m(R3.$$.fragment,Dt),Dt.forEach(t),Lro=i(Vs),kh=n(Vs,"DIV",{class:!0});var ySe=s(kh);m(S3.$$.fragment,ySe),Bro=i(ySe),HY=n(ySe,"P",{});var _qr=s(HY);xro=r(_qr,"Register a new feature extractor for this class."),_qr.forEach(t),ySe.forEach(t),Vs.forEach(t),vke=i(c),Hi=n(c,"H2",{class:!0});var wSe=s(Hi);Rh=n(wSe,"A",{id:!0,class:!0,href:!0});var uqr=s(Rh);UY=n(uqr,"SPAN",{});var bqr=s(UY);m(P3.$$.fragment,bqr),bqr.forEach(t),uqr.forEach(t),kro=i(wSe),JY=n(wSe,"SPAN",{});var vqr=s(JY);Rro=r(vqr,"AutoProcessor"),vqr.forEach(t),wSe.forEach(t),Tke=i(c),Uo=n(c,"DIV",{class:!0});var zs=s(Uo);m($3.$$.fragment,zs),Sro=i(zs),I3=n(zs,"P",{});var ASe=s(I3);Pro=r(ASe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),kR=n(ASe,"A",{href:!0});var Tqr=s(kR);$ro=r(Tqr,"AutoProcessor.from_pretrained()"),Tqr.forEach(t),Iro=r(ASe," class method."),ASe.forEach(t),Nro=i(zs),N3=n(zs,"P",{});var LSe=s(N3);Dro=r(LSe,"This class cannot be instantiated directly using "),YY=n(LSe,"CODE",{});var Fqr=s(YY);jro=r(Fqr,"__init__()"),Fqr.forEach(t),qro=r(LSe," (throws an error)."),LSe.forEach(t),Gro=i(zs),Ie=n(zs,"DIV",{class:!0});var jt=s(Ie);m(D3.$$.fragment,jt),Oro=i(jt),KY=n(jt,"P",{});var Cqr=s(KY);Xro=r(Cqr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Cqr.forEach(t),Vro=i(jt),Ui=n(jt,"P",{});var Kz=s(Ui);zro=r(Kz,"The processor class to instantiate is selected based on the "),ZY=n(Kz,"CODE",{});var Mqr=s(ZY);Wro=r(Mqr,"model_type"),Mqr.forEach(t),Qro=r(Kz,` property of the config object (either
passed as an argument or loaded from `),eK=n(Kz,"CODE",{});var Eqr=s(eK);Hro=r(Eqr,"pretrained_model_name_or_path"),Eqr.forEach(t),Uro=r(Kz," if possible):"),Kz.forEach(t),Jro=i(jt),xe=n(jt,"UL",{});var jo=s(xe);Sh=n(jo,"LI",{});var BMe=s(Sh);oK=n(BMe,"STRONG",{});var yqr=s(oK);Yro=r(yqr,"clip"),yqr.forEach(t),Kro=r(BMe," \u2014 "),RR=n(BMe,"A",{href:!0});var wqr=s(RR);Zro=r(wqr,"CLIPProcessor"),wqr.forEach(t),eto=r(BMe," (CLIP model)"),BMe.forEach(t),oto=i(jo),Ph=n(jo,"LI",{});var xMe=s(Ph);rK=n(xMe,"STRONG",{});var Aqr=s(rK);rto=r(Aqr,"layoutlmv2"),Aqr.forEach(t),tto=r(xMe," \u2014 "),SR=n(xMe,"A",{href:!0});var Lqr=s(SR);ato=r(Lqr,"LayoutLMv2Processor"),Lqr.forEach(t),nto=r(xMe," (LayoutLMv2 model)"),xMe.forEach(t),sto=i(jo),$h=n(jo,"LI",{});var kMe=s($h);tK=n(kMe,"STRONG",{});var Bqr=s(tK);lto=r(Bqr,"layoutxlm"),Bqr.forEach(t),ito=r(kMe," \u2014 "),PR=n(kMe,"A",{href:!0});var xqr=s(PR);dto=r(xqr,"LayoutXLMProcessor"),xqr.forEach(t),cto=r(kMe," (LayoutXLM model)"),kMe.forEach(t),fto=i(jo),Ih=n(jo,"LI",{});var RMe=s(Ih);aK=n(RMe,"STRONG",{});var kqr=s(aK);mto=r(kqr,"speech_to_text"),kqr.forEach(t),gto=r(RMe," \u2014 "),$R=n(RMe,"A",{href:!0});var Rqr=s($R);hto=r(Rqr,"Speech2TextProcessor"),Rqr.forEach(t),pto=r(RMe," (Speech2Text model)"),RMe.forEach(t),_to=i(jo),Nh=n(jo,"LI",{});var SMe=s(Nh);nK=n(SMe,"STRONG",{});var Sqr=s(nK);uto=r(Sqr,"speech_to_text_2"),Sqr.forEach(t),bto=r(SMe," \u2014 "),IR=n(SMe,"A",{href:!0});var Pqr=s(IR);vto=r(Pqr,"Speech2Text2Processor"),Pqr.forEach(t),Tto=r(SMe," (Speech2Text2 model)"),SMe.forEach(t),Fto=i(jo),Dh=n(jo,"LI",{});var PMe=s(Dh);sK=n(PMe,"STRONG",{});var $qr=s(sK);Cto=r($qr,"trocr"),$qr.forEach(t),Mto=r(PMe," \u2014 "),NR=n(PMe,"A",{href:!0});var Iqr=s(NR);Eto=r(Iqr,"TrOCRProcessor"),Iqr.forEach(t),yto=r(PMe," (TrOCR model)"),PMe.forEach(t),wto=i(jo),jh=n(jo,"LI",{});var $Me=s(jh);lK=n($Me,"STRONG",{});var Nqr=s(lK);Ato=r(Nqr,"vision-text-dual-encoder"),Nqr.forEach(t),Lto=r($Me," \u2014 "),DR=n($Me,"A",{href:!0});var Dqr=s(DR);Bto=r(Dqr,"VisionTextDualEncoderProcessor"),Dqr.forEach(t),xto=r($Me," (VisionTextDualEncoder model)"),$Me.forEach(t),kto=i(jo),qh=n(jo,"LI",{});var IMe=s(qh);iK=n(IMe,"STRONG",{});var jqr=s(iK);Rto=r(jqr,"wav2vec2"),jqr.forEach(t),Sto=r(IMe," \u2014 "),jR=n(IMe,"A",{href:!0});var qqr=s(jR);Pto=r(qqr,"Wav2Vec2Processor"),qqr.forEach(t),$to=r(IMe," (Wav2Vec2 model)"),IMe.forEach(t),jo.forEach(t),Ito=i(jt),m(Gh.$$.fragment,jt),Nto=i(jt),dK=n(jt,"P",{});var Gqr=s(dK);Dto=r(Gqr,"Examples:"),Gqr.forEach(t),jto=i(jt),m(j3.$$.fragment,jt),jt.forEach(t),qto=i(zs),Oh=n(zs,"DIV",{class:!0});var BSe=s(Oh);m(q3.$$.fragment,BSe),Gto=i(BSe),cK=n(BSe,"P",{});var Oqr=s(cK);Oto=r(Oqr,"Register a new processor for this class."),Oqr.forEach(t),BSe.forEach(t),zs.forEach(t),Fke=i(c),Ji=n(c,"H2",{class:!0});var xSe=s(Ji);Xh=n(xSe,"A",{id:!0,class:!0,href:!0});var Xqr=s(Xh);fK=n(Xqr,"SPAN",{});var Vqr=s(fK);m(G3.$$.fragment,Vqr),Vqr.forEach(t),Xqr.forEach(t),Xto=i(xSe),mK=n(xSe,"SPAN",{});var zqr=s(mK);Vto=r(zqr,"AutoModel"),zqr.forEach(t),xSe.forEach(t),Cke=i(c),Jo=n(c,"DIV",{class:!0});var Ws=s(Jo);m(O3.$$.fragment,Ws),zto=i(Ws),Yi=n(Ws,"P",{});var Zz=s(Yi);Wto=r(Zz,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gK=n(Zz,"CODE",{});var Wqr=s(gK);Qto=r(Wqr,"from_pretrained()"),Wqr.forEach(t),Hto=r(Zz,"class method or the "),hK=n(Zz,"CODE",{});var Qqr=s(hK);Uto=r(Qqr,"from_config()"),Qqr.forEach(t),Jto=r(Zz,`class
method.`),Zz.forEach(t),Yto=i(Ws),X3=n(Ws,"P",{});var kSe=s(X3);Kto=r(kSe,"This class cannot be instantiated directly using "),pK=n(kSe,"CODE",{});var Hqr=s(pK);Zto=r(Hqr,"__init__()"),Hqr.forEach(t),eao=r(kSe," (throws an error)."),kSe.forEach(t),oao=i(Ws),Vr=n(Ws,"DIV",{class:!0});var Qs=s(Vr);m(V3.$$.fragment,Qs),rao=i(Qs),_K=n(Qs,"P",{});var Uqr=s(_K);tao=r(Uqr,"Instantiates one of the base model classes of the library from a configuration."),Uqr.forEach(t),aao=i(Qs),Ki=n(Qs,"P",{});var eW=s(Ki);nao=r(eW,`Note:
Loading a model from its configuration file does `),uK=n(eW,"STRONG",{});var Jqr=s(uK);sao=r(Jqr,"not"),Jqr.forEach(t),lao=r(eW,` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=n(eW,"CODE",{});var Yqr=s(bK);iao=r(Yqr,"from_pretrained()"),Yqr.forEach(t),dao=r(eW,"to load the model weights."),eW.forEach(t),cao=i(Qs),vK=n(Qs,"P",{});var Kqr=s(vK);fao=r(Kqr,"Examples:"),Kqr.forEach(t),mao=i(Qs),m(z3.$$.fragment,Qs),Qs.forEach(t),gao=i(Ws),Ne=n(Ws,"DIV",{class:!0});var qt=s(Ne);m(W3.$$.fragment,qt),hao=i(qt),TK=n(qt,"P",{});var Zqr=s(TK);pao=r(Zqr,"Instantiate one of the base model classes of the library from a pretrained model."),Zqr.forEach(t),_ao=i(qt),Va=n(qt,"P",{});var fE=s(Va);uao=r(fE,"The model class to instantiate is selected based on the "),FK=n(fE,"CODE",{});var eGr=s(FK);bao=r(eGr,"model_type"),eGr.forEach(t),vao=r(fE,` property of the config object (either
passed as an argument or loaded from `),CK=n(fE,"CODE",{});var oGr=s(CK);Tao=r(oGr,"pretrained_model_name_or_path"),oGr.forEach(t),Fao=r(fE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MK=n(fE,"CODE",{});var rGr=s(MK);Cao=r(rGr,"pretrained_model_name_or_path"),rGr.forEach(t),Mao=r(fE,":"),fE.forEach(t),Eao=i(qt),F=n(qt,"UL",{});var C=s(F);Vh=n(C,"LI",{});var NMe=s(Vh);EK=n(NMe,"STRONG",{});var tGr=s(EK);yao=r(tGr,"albert"),tGr.forEach(t),wao=r(NMe," \u2014 "),qR=n(NMe,"A",{href:!0});var aGr=s(qR);Aao=r(aGr,"AlbertModel"),aGr.forEach(t),Lao=r(NMe," (ALBERT model)"),NMe.forEach(t),Bao=i(C),zh=n(C,"LI",{});var DMe=s(zh);yK=n(DMe,"STRONG",{});var nGr=s(yK);xao=r(nGr,"bart"),nGr.forEach(t),kao=r(DMe," \u2014 "),GR=n(DMe,"A",{href:!0});var sGr=s(GR);Rao=r(sGr,"BartModel"),sGr.forEach(t),Sao=r(DMe," (BART model)"),DMe.forEach(t),Pao=i(C),Wh=n(C,"LI",{});var jMe=s(Wh);wK=n(jMe,"STRONG",{});var lGr=s(wK);$ao=r(lGr,"beit"),lGr.forEach(t),Iao=r(jMe," \u2014 "),OR=n(jMe,"A",{href:!0});var iGr=s(OR);Nao=r(iGr,"BeitModel"),iGr.forEach(t),Dao=r(jMe," (BEiT model)"),jMe.forEach(t),jao=i(C),Qh=n(C,"LI",{});var qMe=s(Qh);AK=n(qMe,"STRONG",{});var dGr=s(AK);qao=r(dGr,"bert"),dGr.forEach(t),Gao=r(qMe," \u2014 "),XR=n(qMe,"A",{href:!0});var cGr=s(XR);Oao=r(cGr,"BertModel"),cGr.forEach(t),Xao=r(qMe," (BERT model)"),qMe.forEach(t),Vao=i(C),Hh=n(C,"LI",{});var GMe=s(Hh);LK=n(GMe,"STRONG",{});var fGr=s(LK);zao=r(fGr,"bert-generation"),fGr.forEach(t),Wao=r(GMe," \u2014 "),VR=n(GMe,"A",{href:!0});var mGr=s(VR);Qao=r(mGr,"BertGenerationEncoder"),mGr.forEach(t),Hao=r(GMe," (Bert Generation model)"),GMe.forEach(t),Uao=i(C),Uh=n(C,"LI",{});var OMe=s(Uh);BK=n(OMe,"STRONG",{});var gGr=s(BK);Jao=r(gGr,"big_bird"),gGr.forEach(t),Yao=r(OMe," \u2014 "),zR=n(OMe,"A",{href:!0});var hGr=s(zR);Kao=r(hGr,"BigBirdModel"),hGr.forEach(t),Zao=r(OMe," (BigBird model)"),OMe.forEach(t),eno=i(C),Jh=n(C,"LI",{});var XMe=s(Jh);xK=n(XMe,"STRONG",{});var pGr=s(xK);ono=r(pGr,"bigbird_pegasus"),pGr.forEach(t),rno=r(XMe," \u2014 "),WR=n(XMe,"A",{href:!0});var _Gr=s(WR);tno=r(_Gr,"BigBirdPegasusModel"),_Gr.forEach(t),ano=r(XMe," (BigBirdPegasus model)"),XMe.forEach(t),nno=i(C),Yh=n(C,"LI",{});var VMe=s(Yh);kK=n(VMe,"STRONG",{});var uGr=s(kK);sno=r(uGr,"blenderbot"),uGr.forEach(t),lno=r(VMe," \u2014 "),QR=n(VMe,"A",{href:!0});var bGr=s(QR);ino=r(bGr,"BlenderbotModel"),bGr.forEach(t),dno=r(VMe," (Blenderbot model)"),VMe.forEach(t),cno=i(C),Kh=n(C,"LI",{});var zMe=s(Kh);RK=n(zMe,"STRONG",{});var vGr=s(RK);fno=r(vGr,"blenderbot-small"),vGr.forEach(t),mno=r(zMe," \u2014 "),HR=n(zMe,"A",{href:!0});var TGr=s(HR);gno=r(TGr,"BlenderbotSmallModel"),TGr.forEach(t),hno=r(zMe," (BlenderbotSmall model)"),zMe.forEach(t),pno=i(C),Zh=n(C,"LI",{});var WMe=s(Zh);SK=n(WMe,"STRONG",{});var FGr=s(SK);_no=r(FGr,"camembert"),FGr.forEach(t),uno=r(WMe," \u2014 "),UR=n(WMe,"A",{href:!0});var CGr=s(UR);bno=r(CGr,"CamembertModel"),CGr.forEach(t),vno=r(WMe," (CamemBERT model)"),WMe.forEach(t),Tno=i(C),ep=n(C,"LI",{});var QMe=s(ep);PK=n(QMe,"STRONG",{});var MGr=s(PK);Fno=r(MGr,"canine"),MGr.forEach(t),Cno=r(QMe," \u2014 "),JR=n(QMe,"A",{href:!0});var EGr=s(JR);Mno=r(EGr,"CanineModel"),EGr.forEach(t),Eno=r(QMe," (Canine model)"),QMe.forEach(t),yno=i(C),op=n(C,"LI",{});var HMe=s(op);$K=n(HMe,"STRONG",{});var yGr=s($K);wno=r(yGr,"clip"),yGr.forEach(t),Ano=r(HMe," \u2014 "),YR=n(HMe,"A",{href:!0});var wGr=s(YR);Lno=r(wGr,"CLIPModel"),wGr.forEach(t),Bno=r(HMe," (CLIP model)"),HMe.forEach(t),xno=i(C),rp=n(C,"LI",{});var UMe=s(rp);IK=n(UMe,"STRONG",{});var AGr=s(IK);kno=r(AGr,"convbert"),AGr.forEach(t),Rno=r(UMe," \u2014 "),KR=n(UMe,"A",{href:!0});var LGr=s(KR);Sno=r(LGr,"ConvBertModel"),LGr.forEach(t),Pno=r(UMe," (ConvBERT model)"),UMe.forEach(t),$no=i(C),tp=n(C,"LI",{});var JMe=s(tp);NK=n(JMe,"STRONG",{});var BGr=s(NK);Ino=r(BGr,"convnext"),BGr.forEach(t),Nno=r(JMe," \u2014 "),ZR=n(JMe,"A",{href:!0});var xGr=s(ZR);Dno=r(xGr,"ConvNextModel"),xGr.forEach(t),jno=r(JMe," (ConvNext model)"),JMe.forEach(t),qno=i(C),ap=n(C,"LI",{});var YMe=s(ap);DK=n(YMe,"STRONG",{});var kGr=s(DK);Gno=r(kGr,"ctrl"),kGr.forEach(t),Ono=r(YMe," \u2014 "),eS=n(YMe,"A",{href:!0});var RGr=s(eS);Xno=r(RGr,"CTRLModel"),RGr.forEach(t),Vno=r(YMe," (CTRL model)"),YMe.forEach(t),zno=i(C),np=n(C,"LI",{});var KMe=s(np);jK=n(KMe,"STRONG",{});var SGr=s(jK);Wno=r(SGr,"data2vec-audio"),SGr.forEach(t),Qno=r(KMe," \u2014 "),oS=n(KMe,"A",{href:!0});var PGr=s(oS);Hno=r(PGr,"Data2VecAudioModel"),PGr.forEach(t),Uno=r(KMe," (Data2VecAudio model)"),KMe.forEach(t),Jno=i(C),sp=n(C,"LI",{});var ZMe=s(sp);qK=n(ZMe,"STRONG",{});var $Gr=s(qK);Yno=r($Gr,"data2vec-text"),$Gr.forEach(t),Kno=r(ZMe," \u2014 "),rS=n(ZMe,"A",{href:!0});var IGr=s(rS);Zno=r(IGr,"Data2VecTextModel"),IGr.forEach(t),eso=r(ZMe," (Data2VecText model)"),ZMe.forEach(t),oso=i(C),lp=n(C,"LI",{});var e4e=s(lp);GK=n(e4e,"STRONG",{});var NGr=s(GK);rso=r(NGr,"deberta"),NGr.forEach(t),tso=r(e4e," \u2014 "),tS=n(e4e,"A",{href:!0});var DGr=s(tS);aso=r(DGr,"DebertaModel"),DGr.forEach(t),nso=r(e4e," (DeBERTa model)"),e4e.forEach(t),sso=i(C),ip=n(C,"LI",{});var o4e=s(ip);OK=n(o4e,"STRONG",{});var jGr=s(OK);lso=r(jGr,"deberta-v2"),jGr.forEach(t),iso=r(o4e," \u2014 "),aS=n(o4e,"A",{href:!0});var qGr=s(aS);dso=r(qGr,"DebertaV2Model"),qGr.forEach(t),cso=r(o4e," (DeBERTa-v2 model)"),o4e.forEach(t),fso=i(C),dp=n(C,"LI",{});var r4e=s(dp);XK=n(r4e,"STRONG",{});var GGr=s(XK);mso=r(GGr,"decision_transformer"),GGr.forEach(t),gso=r(r4e," \u2014 "),nS=n(r4e,"A",{href:!0});var OGr=s(nS);hso=r(OGr,"DecisionTransformerModel"),OGr.forEach(t),pso=r(r4e," (Decision Transformer model)"),r4e.forEach(t),_so=i(C),cp=n(C,"LI",{});var t4e=s(cp);VK=n(t4e,"STRONG",{});var XGr=s(VK);uso=r(XGr,"deit"),XGr.forEach(t),bso=r(t4e," \u2014 "),sS=n(t4e,"A",{href:!0});var VGr=s(sS);vso=r(VGr,"DeiTModel"),VGr.forEach(t),Tso=r(t4e," (DeiT model)"),t4e.forEach(t),Fso=i(C),fp=n(C,"LI",{});var a4e=s(fp);zK=n(a4e,"STRONG",{});var zGr=s(zK);Cso=r(zGr,"detr"),zGr.forEach(t),Mso=r(a4e," \u2014 "),lS=n(a4e,"A",{href:!0});var WGr=s(lS);Eso=r(WGr,"DetrModel"),WGr.forEach(t),yso=r(a4e," (DETR model)"),a4e.forEach(t),wso=i(C),mp=n(C,"LI",{});var n4e=s(mp);WK=n(n4e,"STRONG",{});var QGr=s(WK);Aso=r(QGr,"distilbert"),QGr.forEach(t),Lso=r(n4e," \u2014 "),iS=n(n4e,"A",{href:!0});var HGr=s(iS);Bso=r(HGr,"DistilBertModel"),HGr.forEach(t),xso=r(n4e," (DistilBERT model)"),n4e.forEach(t),kso=i(C),gp=n(C,"LI",{});var s4e=s(gp);QK=n(s4e,"STRONG",{});var UGr=s(QK);Rso=r(UGr,"dpr"),UGr.forEach(t),Sso=r(s4e," \u2014 "),dS=n(s4e,"A",{href:!0});var JGr=s(dS);Pso=r(JGr,"DPRQuestionEncoder"),JGr.forEach(t),$so=r(s4e," (DPR model)"),s4e.forEach(t),Iso=i(C),hp=n(C,"LI",{});var l4e=s(hp);HK=n(l4e,"STRONG",{});var YGr=s(HK);Nso=r(YGr,"electra"),YGr.forEach(t),Dso=r(l4e," \u2014 "),cS=n(l4e,"A",{href:!0});var KGr=s(cS);jso=r(KGr,"ElectraModel"),KGr.forEach(t),qso=r(l4e," (ELECTRA model)"),l4e.forEach(t),Gso=i(C),pp=n(C,"LI",{});var i4e=s(pp);UK=n(i4e,"STRONG",{});var ZGr=s(UK);Oso=r(ZGr,"flaubert"),ZGr.forEach(t),Xso=r(i4e," \u2014 "),fS=n(i4e,"A",{href:!0});var eOr=s(fS);Vso=r(eOr,"FlaubertModel"),eOr.forEach(t),zso=r(i4e," (FlauBERT model)"),i4e.forEach(t),Wso=i(C),_p=n(C,"LI",{});var d4e=s(_p);JK=n(d4e,"STRONG",{});var oOr=s(JK);Qso=r(oOr,"fnet"),oOr.forEach(t),Hso=r(d4e," \u2014 "),mS=n(d4e,"A",{href:!0});var rOr=s(mS);Uso=r(rOr,"FNetModel"),rOr.forEach(t),Jso=r(d4e," (FNet model)"),d4e.forEach(t),Yso=i(C),up=n(C,"LI",{});var c4e=s(up);YK=n(c4e,"STRONG",{});var tOr=s(YK);Kso=r(tOr,"fsmt"),tOr.forEach(t),Zso=r(c4e," \u2014 "),gS=n(c4e,"A",{href:!0});var aOr=s(gS);elo=r(aOr,"FSMTModel"),aOr.forEach(t),olo=r(c4e," (FairSeq Machine-Translation model)"),c4e.forEach(t),rlo=i(C),js=n(C,"LI",{});var Y8=s(js);KK=n(Y8,"STRONG",{});var nOr=s(KK);tlo=r(nOr,"funnel"),nOr.forEach(t),alo=r(Y8," \u2014 "),hS=n(Y8,"A",{href:!0});var sOr=s(hS);nlo=r(sOr,"FunnelModel"),sOr.forEach(t),slo=r(Y8," or "),pS=n(Y8,"A",{href:!0});var lOr=s(pS);llo=r(lOr,"FunnelBaseModel"),lOr.forEach(t),ilo=r(Y8," (Funnel Transformer model)"),Y8.forEach(t),dlo=i(C),bp=n(C,"LI",{});var f4e=s(bp);ZK=n(f4e,"STRONG",{});var iOr=s(ZK);clo=r(iOr,"glpn"),iOr.forEach(t),flo=r(f4e," \u2014 "),_S=n(f4e,"A",{href:!0});var dOr=s(_S);mlo=r(dOr,"GLPNModel"),dOr.forEach(t),glo=r(f4e," (GLPN model)"),f4e.forEach(t),hlo=i(C),vp=n(C,"LI",{});var m4e=s(vp);eZ=n(m4e,"STRONG",{});var cOr=s(eZ);plo=r(cOr,"gpt2"),cOr.forEach(t),_lo=r(m4e," \u2014 "),uS=n(m4e,"A",{href:!0});var fOr=s(uS);ulo=r(fOr,"GPT2Model"),fOr.forEach(t),blo=r(m4e," (OpenAI GPT-2 model)"),m4e.forEach(t),vlo=i(C),Tp=n(C,"LI",{});var g4e=s(Tp);oZ=n(g4e,"STRONG",{});var mOr=s(oZ);Tlo=r(mOr,"gpt_neo"),mOr.forEach(t),Flo=r(g4e," \u2014 "),bS=n(g4e,"A",{href:!0});var gOr=s(bS);Clo=r(gOr,"GPTNeoModel"),gOr.forEach(t),Mlo=r(g4e," (GPT Neo model)"),g4e.forEach(t),Elo=i(C),Fp=n(C,"LI",{});var h4e=s(Fp);rZ=n(h4e,"STRONG",{});var hOr=s(rZ);ylo=r(hOr,"gptj"),hOr.forEach(t),wlo=r(h4e," \u2014 "),vS=n(h4e,"A",{href:!0});var pOr=s(vS);Alo=r(pOr,"GPTJModel"),pOr.forEach(t),Llo=r(h4e," (GPT-J model)"),h4e.forEach(t),Blo=i(C),Cp=n(C,"LI",{});var p4e=s(Cp);tZ=n(p4e,"STRONG",{});var _Or=s(tZ);xlo=r(_Or,"hubert"),_Or.forEach(t),klo=r(p4e," \u2014 "),TS=n(p4e,"A",{href:!0});var uOr=s(TS);Rlo=r(uOr,"HubertModel"),uOr.forEach(t),Slo=r(p4e," (Hubert model)"),p4e.forEach(t),Plo=i(C),Mp=n(C,"LI",{});var _4e=s(Mp);aZ=n(_4e,"STRONG",{});var bOr=s(aZ);$lo=r(bOr,"ibert"),bOr.forEach(t),Ilo=r(_4e," \u2014 "),FS=n(_4e,"A",{href:!0});var vOr=s(FS);Nlo=r(vOr,"IBertModel"),vOr.forEach(t),Dlo=r(_4e," (I-BERT model)"),_4e.forEach(t),jlo=i(C),Ep=n(C,"LI",{});var u4e=s(Ep);nZ=n(u4e,"STRONG",{});var TOr=s(nZ);qlo=r(TOr,"imagegpt"),TOr.forEach(t),Glo=r(u4e," \u2014 "),CS=n(u4e,"A",{href:!0});var FOr=s(CS);Olo=r(FOr,"ImageGPTModel"),FOr.forEach(t),Xlo=r(u4e," (ImageGPT model)"),u4e.forEach(t),Vlo=i(C),yp=n(C,"LI",{});var b4e=s(yp);sZ=n(b4e,"STRONG",{});var COr=s(sZ);zlo=r(COr,"layoutlm"),COr.forEach(t),Wlo=r(b4e," \u2014 "),MS=n(b4e,"A",{href:!0});var MOr=s(MS);Qlo=r(MOr,"LayoutLMModel"),MOr.forEach(t),Hlo=r(b4e," (LayoutLM model)"),b4e.forEach(t),Ulo=i(C),wp=n(C,"LI",{});var v4e=s(wp);lZ=n(v4e,"STRONG",{});var EOr=s(lZ);Jlo=r(EOr,"layoutlmv2"),EOr.forEach(t),Ylo=r(v4e," \u2014 "),ES=n(v4e,"A",{href:!0});var yOr=s(ES);Klo=r(yOr,"LayoutLMv2Model"),yOr.forEach(t),Zlo=r(v4e," (LayoutLMv2 model)"),v4e.forEach(t),eio=i(C),Ap=n(C,"LI",{});var T4e=s(Ap);iZ=n(T4e,"STRONG",{});var wOr=s(iZ);oio=r(wOr,"led"),wOr.forEach(t),rio=r(T4e," \u2014 "),yS=n(T4e,"A",{href:!0});var AOr=s(yS);tio=r(AOr,"LEDModel"),AOr.forEach(t),aio=r(T4e," (LED model)"),T4e.forEach(t),nio=i(C),Lp=n(C,"LI",{});var F4e=s(Lp);dZ=n(F4e,"STRONG",{});var LOr=s(dZ);sio=r(LOr,"longformer"),LOr.forEach(t),lio=r(F4e," \u2014 "),wS=n(F4e,"A",{href:!0});var BOr=s(wS);iio=r(BOr,"LongformerModel"),BOr.forEach(t),dio=r(F4e," (Longformer model)"),F4e.forEach(t),cio=i(C),Bp=n(C,"LI",{});var C4e=s(Bp);cZ=n(C4e,"STRONG",{});var xOr=s(cZ);fio=r(xOr,"luke"),xOr.forEach(t),mio=r(C4e," \u2014 "),AS=n(C4e,"A",{href:!0});var kOr=s(AS);gio=r(kOr,"LukeModel"),kOr.forEach(t),hio=r(C4e," (LUKE model)"),C4e.forEach(t),pio=i(C),xp=n(C,"LI",{});var M4e=s(xp);fZ=n(M4e,"STRONG",{});var ROr=s(fZ);_io=r(ROr,"lxmert"),ROr.forEach(t),uio=r(M4e," \u2014 "),LS=n(M4e,"A",{href:!0});var SOr=s(LS);bio=r(SOr,"LxmertModel"),SOr.forEach(t),vio=r(M4e," (LXMERT model)"),M4e.forEach(t),Tio=i(C),kp=n(C,"LI",{});var E4e=s(kp);mZ=n(E4e,"STRONG",{});var POr=s(mZ);Fio=r(POr,"m2m_100"),POr.forEach(t),Cio=r(E4e," \u2014 "),BS=n(E4e,"A",{href:!0});var $Or=s(BS);Mio=r($Or,"M2M100Model"),$Or.forEach(t),Eio=r(E4e," (M2M100 model)"),E4e.forEach(t),yio=i(C),Rp=n(C,"LI",{});var y4e=s(Rp);gZ=n(y4e,"STRONG",{});var IOr=s(gZ);wio=r(IOr,"marian"),IOr.forEach(t),Aio=r(y4e," \u2014 "),xS=n(y4e,"A",{href:!0});var NOr=s(xS);Lio=r(NOr,"MarianModel"),NOr.forEach(t),Bio=r(y4e," (Marian model)"),y4e.forEach(t),xio=i(C),Sp=n(C,"LI",{});var w4e=s(Sp);hZ=n(w4e,"STRONG",{});var DOr=s(hZ);kio=r(DOr,"maskformer"),DOr.forEach(t),Rio=r(w4e," \u2014 "),kS=n(w4e,"A",{href:!0});var jOr=s(kS);Sio=r(jOr,"MaskFormerModel"),jOr.forEach(t),Pio=r(w4e," (MaskFormer model)"),w4e.forEach(t),$io=i(C),Pp=n(C,"LI",{});var A4e=s(Pp);pZ=n(A4e,"STRONG",{});var qOr=s(pZ);Iio=r(qOr,"mbart"),qOr.forEach(t),Nio=r(A4e," \u2014 "),RS=n(A4e,"A",{href:!0});var GOr=s(RS);Dio=r(GOr,"MBartModel"),GOr.forEach(t),jio=r(A4e," (mBART model)"),A4e.forEach(t),qio=i(C),$p=n(C,"LI",{});var L4e=s($p);_Z=n(L4e,"STRONG",{});var OOr=s(_Z);Gio=r(OOr,"megatron-bert"),OOr.forEach(t),Oio=r(L4e," \u2014 "),SS=n(L4e,"A",{href:!0});var XOr=s(SS);Xio=r(XOr,"MegatronBertModel"),XOr.forEach(t),Vio=r(L4e," (MegatronBert model)"),L4e.forEach(t),zio=i(C),Ip=n(C,"LI",{});var B4e=s(Ip);uZ=n(B4e,"STRONG",{});var VOr=s(uZ);Wio=r(VOr,"mobilebert"),VOr.forEach(t),Qio=r(B4e," \u2014 "),PS=n(B4e,"A",{href:!0});var zOr=s(PS);Hio=r(zOr,"MobileBertModel"),zOr.forEach(t),Uio=r(B4e," (MobileBERT model)"),B4e.forEach(t),Jio=i(C),Np=n(C,"LI",{});var x4e=s(Np);bZ=n(x4e,"STRONG",{});var WOr=s(bZ);Yio=r(WOr,"mpnet"),WOr.forEach(t),Kio=r(x4e," \u2014 "),$S=n(x4e,"A",{href:!0});var QOr=s($S);Zio=r(QOr,"MPNetModel"),QOr.forEach(t),edo=r(x4e," (MPNet model)"),x4e.forEach(t),odo=i(C),Dp=n(C,"LI",{});var k4e=s(Dp);vZ=n(k4e,"STRONG",{});var HOr=s(vZ);rdo=r(HOr,"mt5"),HOr.forEach(t),tdo=r(k4e," \u2014 "),IS=n(k4e,"A",{href:!0});var UOr=s(IS);ado=r(UOr,"MT5Model"),UOr.forEach(t),ndo=r(k4e," (mT5 model)"),k4e.forEach(t),sdo=i(C),jp=n(C,"LI",{});var R4e=s(jp);TZ=n(R4e,"STRONG",{});var JOr=s(TZ);ldo=r(JOr,"nystromformer"),JOr.forEach(t),ido=r(R4e," \u2014 "),NS=n(R4e,"A",{href:!0});var YOr=s(NS);ddo=r(YOr,"NystromformerModel"),YOr.forEach(t),cdo=r(R4e," (Nystromformer model)"),R4e.forEach(t),fdo=i(C),qp=n(C,"LI",{});var S4e=s(qp);FZ=n(S4e,"STRONG",{});var KOr=s(FZ);mdo=r(KOr,"openai-gpt"),KOr.forEach(t),gdo=r(S4e," \u2014 "),DS=n(S4e,"A",{href:!0});var ZOr=s(DS);hdo=r(ZOr,"OpenAIGPTModel"),ZOr.forEach(t),pdo=r(S4e," (OpenAI GPT model)"),S4e.forEach(t),_do=i(C),Gp=n(C,"LI",{});var P4e=s(Gp);CZ=n(P4e,"STRONG",{});var eXr=s(CZ);udo=r(eXr,"pegasus"),eXr.forEach(t),bdo=r(P4e," \u2014 "),jS=n(P4e,"A",{href:!0});var oXr=s(jS);vdo=r(oXr,"PegasusModel"),oXr.forEach(t),Tdo=r(P4e," (Pegasus model)"),P4e.forEach(t),Fdo=i(C),Op=n(C,"LI",{});var $4e=s(Op);MZ=n($4e,"STRONG",{});var rXr=s(MZ);Cdo=r(rXr,"perceiver"),rXr.forEach(t),Mdo=r($4e," \u2014 "),qS=n($4e,"A",{href:!0});var tXr=s(qS);Edo=r(tXr,"PerceiverModel"),tXr.forEach(t),ydo=r($4e," (Perceiver model)"),$4e.forEach(t),wdo=i(C),Xp=n(C,"LI",{});var I4e=s(Xp);EZ=n(I4e,"STRONG",{});var aXr=s(EZ);Ado=r(aXr,"plbart"),aXr.forEach(t),Ldo=r(I4e," \u2014 "),GS=n(I4e,"A",{href:!0});var nXr=s(GS);Bdo=r(nXr,"PLBartModel"),nXr.forEach(t),xdo=r(I4e," (PLBart model)"),I4e.forEach(t),kdo=i(C),Vp=n(C,"LI",{});var N4e=s(Vp);yZ=n(N4e,"STRONG",{});var sXr=s(yZ);Rdo=r(sXr,"poolformer"),sXr.forEach(t),Sdo=r(N4e," \u2014 "),OS=n(N4e,"A",{href:!0});var lXr=s(OS);Pdo=r(lXr,"PoolFormerModel"),lXr.forEach(t),$do=r(N4e," (PoolFormer model)"),N4e.forEach(t),Ido=i(C),zp=n(C,"LI",{});var D4e=s(zp);wZ=n(D4e,"STRONG",{});var iXr=s(wZ);Ndo=r(iXr,"prophetnet"),iXr.forEach(t),Ddo=r(D4e," \u2014 "),XS=n(D4e,"A",{href:!0});var dXr=s(XS);jdo=r(dXr,"ProphetNetModel"),dXr.forEach(t),qdo=r(D4e," (ProphetNet model)"),D4e.forEach(t),Gdo=i(C),Wp=n(C,"LI",{});var j4e=s(Wp);AZ=n(j4e,"STRONG",{});var cXr=s(AZ);Odo=r(cXr,"qdqbert"),cXr.forEach(t),Xdo=r(j4e," \u2014 "),VS=n(j4e,"A",{href:!0});var fXr=s(VS);Vdo=r(fXr,"QDQBertModel"),fXr.forEach(t),zdo=r(j4e," (QDQBert model)"),j4e.forEach(t),Wdo=i(C),Qp=n(C,"LI",{});var q4e=s(Qp);LZ=n(q4e,"STRONG",{});var mXr=s(LZ);Qdo=r(mXr,"reformer"),mXr.forEach(t),Hdo=r(q4e," \u2014 "),zS=n(q4e,"A",{href:!0});var gXr=s(zS);Udo=r(gXr,"ReformerModel"),gXr.forEach(t),Jdo=r(q4e," (Reformer model)"),q4e.forEach(t),Ydo=i(C),Hp=n(C,"LI",{});var G4e=s(Hp);BZ=n(G4e,"STRONG",{});var hXr=s(BZ);Kdo=r(hXr,"rembert"),hXr.forEach(t),Zdo=r(G4e," \u2014 "),WS=n(G4e,"A",{href:!0});var pXr=s(WS);eco=r(pXr,"RemBertModel"),pXr.forEach(t),oco=r(G4e," (RemBERT model)"),G4e.forEach(t),rco=i(C),Up=n(C,"LI",{});var O4e=s(Up);xZ=n(O4e,"STRONG",{});var _Xr=s(xZ);tco=r(_Xr,"resnet"),_Xr.forEach(t),aco=r(O4e," \u2014 "),QS=n(O4e,"A",{href:!0});var uXr=s(QS);nco=r(uXr,"ResNetModel"),uXr.forEach(t),sco=r(O4e," (ResNet model)"),O4e.forEach(t),lco=i(C),Jp=n(C,"LI",{});var X4e=s(Jp);kZ=n(X4e,"STRONG",{});var bXr=s(kZ);ico=r(bXr,"retribert"),bXr.forEach(t),dco=r(X4e," \u2014 "),HS=n(X4e,"A",{href:!0});var vXr=s(HS);cco=r(vXr,"RetriBertModel"),vXr.forEach(t),fco=r(X4e," (RetriBERT model)"),X4e.forEach(t),mco=i(C),Yp=n(C,"LI",{});var V4e=s(Yp);RZ=n(V4e,"STRONG",{});var TXr=s(RZ);gco=r(TXr,"roberta"),TXr.forEach(t),hco=r(V4e," \u2014 "),US=n(V4e,"A",{href:!0});var FXr=s(US);pco=r(FXr,"RobertaModel"),FXr.forEach(t),_co=r(V4e," (RoBERTa model)"),V4e.forEach(t),uco=i(C),Kp=n(C,"LI",{});var z4e=s(Kp);SZ=n(z4e,"STRONG",{});var CXr=s(SZ);bco=r(CXr,"roformer"),CXr.forEach(t),vco=r(z4e," \u2014 "),JS=n(z4e,"A",{href:!0});var MXr=s(JS);Tco=r(MXr,"RoFormerModel"),MXr.forEach(t),Fco=r(z4e," (RoFormer model)"),z4e.forEach(t),Cco=i(C),Zp=n(C,"LI",{});var W4e=s(Zp);PZ=n(W4e,"STRONG",{});var EXr=s(PZ);Mco=r(EXr,"segformer"),EXr.forEach(t),Eco=r(W4e," \u2014 "),YS=n(W4e,"A",{href:!0});var yXr=s(YS);yco=r(yXr,"SegformerModel"),yXr.forEach(t),wco=r(W4e," (SegFormer model)"),W4e.forEach(t),Aco=i(C),e_=n(C,"LI",{});var Q4e=s(e_);$Z=n(Q4e,"STRONG",{});var wXr=s($Z);Lco=r(wXr,"sew"),wXr.forEach(t),Bco=r(Q4e," \u2014 "),KS=n(Q4e,"A",{href:!0});var AXr=s(KS);xco=r(AXr,"SEWModel"),AXr.forEach(t),kco=r(Q4e," (SEW model)"),Q4e.forEach(t),Rco=i(C),o_=n(C,"LI",{});var H4e=s(o_);IZ=n(H4e,"STRONG",{});var LXr=s(IZ);Sco=r(LXr,"sew-d"),LXr.forEach(t),Pco=r(H4e," \u2014 "),ZS=n(H4e,"A",{href:!0});var BXr=s(ZS);$co=r(BXr,"SEWDModel"),BXr.forEach(t),Ico=r(H4e," (SEW-D model)"),H4e.forEach(t),Nco=i(C),r_=n(C,"LI",{});var U4e=s(r_);NZ=n(U4e,"STRONG",{});var xXr=s(NZ);Dco=r(xXr,"speech_to_text"),xXr.forEach(t),jco=r(U4e," \u2014 "),eP=n(U4e,"A",{href:!0});var kXr=s(eP);qco=r(kXr,"Speech2TextModel"),kXr.forEach(t),Gco=r(U4e," (Speech2Text model)"),U4e.forEach(t),Oco=i(C),t_=n(C,"LI",{});var J4e=s(t_);DZ=n(J4e,"STRONG",{});var RXr=s(DZ);Xco=r(RXr,"splinter"),RXr.forEach(t),Vco=r(J4e," \u2014 "),oP=n(J4e,"A",{href:!0});var SXr=s(oP);zco=r(SXr,"SplinterModel"),SXr.forEach(t),Wco=r(J4e," (Splinter model)"),J4e.forEach(t),Qco=i(C),a_=n(C,"LI",{});var Y4e=s(a_);jZ=n(Y4e,"STRONG",{});var PXr=s(jZ);Hco=r(PXr,"squeezebert"),PXr.forEach(t),Uco=r(Y4e," \u2014 "),rP=n(Y4e,"A",{href:!0});var $Xr=s(rP);Jco=r($Xr,"SqueezeBertModel"),$Xr.forEach(t),Yco=r(Y4e," (SqueezeBERT model)"),Y4e.forEach(t),Kco=i(C),n_=n(C,"LI",{});var K4e=s(n_);qZ=n(K4e,"STRONG",{});var IXr=s(qZ);Zco=r(IXr,"swin"),IXr.forEach(t),efo=r(K4e," \u2014 "),tP=n(K4e,"A",{href:!0});var NXr=s(tP);ofo=r(NXr,"SwinModel"),NXr.forEach(t),rfo=r(K4e," (Swin model)"),K4e.forEach(t),tfo=i(C),s_=n(C,"LI",{});var Z4e=s(s_);GZ=n(Z4e,"STRONG",{});var DXr=s(GZ);afo=r(DXr,"t5"),DXr.forEach(t),nfo=r(Z4e," \u2014 "),aP=n(Z4e,"A",{href:!0});var jXr=s(aP);sfo=r(jXr,"T5Model"),jXr.forEach(t),lfo=r(Z4e," (T5 model)"),Z4e.forEach(t),ifo=i(C),l_=n(C,"LI",{});var eEe=s(l_);OZ=n(eEe,"STRONG",{});var qXr=s(OZ);dfo=r(qXr,"tapas"),qXr.forEach(t),cfo=r(eEe," \u2014 "),nP=n(eEe,"A",{href:!0});var GXr=s(nP);ffo=r(GXr,"TapasModel"),GXr.forEach(t),mfo=r(eEe," (TAPAS model)"),eEe.forEach(t),gfo=i(C),i_=n(C,"LI",{});var oEe=s(i_);XZ=n(oEe,"STRONG",{});var OXr=s(XZ);hfo=r(OXr,"transfo-xl"),OXr.forEach(t),pfo=r(oEe," \u2014 "),sP=n(oEe,"A",{href:!0});var XXr=s(sP);_fo=r(XXr,"TransfoXLModel"),XXr.forEach(t),ufo=r(oEe," (Transformer-XL model)"),oEe.forEach(t),bfo=i(C),d_=n(C,"LI",{});var rEe=s(d_);VZ=n(rEe,"STRONG",{});var VXr=s(VZ);vfo=r(VXr,"unispeech"),VXr.forEach(t),Tfo=r(rEe," \u2014 "),lP=n(rEe,"A",{href:!0});var zXr=s(lP);Ffo=r(zXr,"UniSpeechModel"),zXr.forEach(t),Cfo=r(rEe," (UniSpeech model)"),rEe.forEach(t),Mfo=i(C),c_=n(C,"LI",{});var tEe=s(c_);zZ=n(tEe,"STRONG",{});var WXr=s(zZ);Efo=r(WXr,"unispeech-sat"),WXr.forEach(t),yfo=r(tEe," \u2014 "),iP=n(tEe,"A",{href:!0});var QXr=s(iP);wfo=r(QXr,"UniSpeechSatModel"),QXr.forEach(t),Afo=r(tEe," (UniSpeechSat model)"),tEe.forEach(t),Lfo=i(C),f_=n(C,"LI",{});var aEe=s(f_);WZ=n(aEe,"STRONG",{});var HXr=s(WZ);Bfo=r(HXr,"van"),HXr.forEach(t),xfo=r(aEe," \u2014 "),dP=n(aEe,"A",{href:!0});var UXr=s(dP);kfo=r(UXr,"VanModel"),UXr.forEach(t),Rfo=r(aEe," (VAN model)"),aEe.forEach(t),Sfo=i(C),m_=n(C,"LI",{});var nEe=s(m_);QZ=n(nEe,"STRONG",{});var JXr=s(QZ);Pfo=r(JXr,"vilt"),JXr.forEach(t),$fo=r(nEe," \u2014 "),cP=n(nEe,"A",{href:!0});var YXr=s(cP);Ifo=r(YXr,"ViltModel"),YXr.forEach(t),Nfo=r(nEe," (ViLT model)"),nEe.forEach(t),Dfo=i(C),g_=n(C,"LI",{});var sEe=s(g_);HZ=n(sEe,"STRONG",{});var KXr=s(HZ);jfo=r(KXr,"vision-text-dual-encoder"),KXr.forEach(t),qfo=r(sEe," \u2014 "),fP=n(sEe,"A",{href:!0});var ZXr=s(fP);Gfo=r(ZXr,"VisionTextDualEncoderModel"),ZXr.forEach(t),Ofo=r(sEe," (VisionTextDualEncoder model)"),sEe.forEach(t),Xfo=i(C),h_=n(C,"LI",{});var lEe=s(h_);UZ=n(lEe,"STRONG",{});var eVr=s(UZ);Vfo=r(eVr,"visual_bert"),eVr.forEach(t),zfo=r(lEe," \u2014 "),mP=n(lEe,"A",{href:!0});var oVr=s(mP);Wfo=r(oVr,"VisualBertModel"),oVr.forEach(t),Qfo=r(lEe," (VisualBert model)"),lEe.forEach(t),Hfo=i(C),p_=n(C,"LI",{});var iEe=s(p_);JZ=n(iEe,"STRONG",{});var rVr=s(JZ);Ufo=r(rVr,"vit"),rVr.forEach(t),Jfo=r(iEe," \u2014 "),gP=n(iEe,"A",{href:!0});var tVr=s(gP);Yfo=r(tVr,"ViTModel"),tVr.forEach(t),Kfo=r(iEe," (ViT model)"),iEe.forEach(t),Zfo=i(C),__=n(C,"LI",{});var dEe=s(__);YZ=n(dEe,"STRONG",{});var aVr=s(YZ);emo=r(aVr,"vit_mae"),aVr.forEach(t),omo=r(dEe," \u2014 "),hP=n(dEe,"A",{href:!0});var nVr=s(hP);rmo=r(nVr,"ViTMAEModel"),nVr.forEach(t),tmo=r(dEe," (ViTMAE model)"),dEe.forEach(t),amo=i(C),u_=n(C,"LI",{});var cEe=s(u_);KZ=n(cEe,"STRONG",{});var sVr=s(KZ);nmo=r(sVr,"wav2vec2"),sVr.forEach(t),smo=r(cEe," \u2014 "),pP=n(cEe,"A",{href:!0});var lVr=s(pP);lmo=r(lVr,"Wav2Vec2Model"),lVr.forEach(t),imo=r(cEe," (Wav2Vec2 model)"),cEe.forEach(t),dmo=i(C),b_=n(C,"LI",{});var fEe=s(b_);ZZ=n(fEe,"STRONG",{});var iVr=s(ZZ);cmo=r(iVr,"wavlm"),iVr.forEach(t),fmo=r(fEe," \u2014 "),_P=n(fEe,"A",{href:!0});var dVr=s(_P);mmo=r(dVr,"WavLMModel"),dVr.forEach(t),gmo=r(fEe," (WavLM model)"),fEe.forEach(t),hmo=i(C),v_=n(C,"LI",{});var mEe=s(v_);eee=n(mEe,"STRONG",{});var cVr=s(eee);pmo=r(cVr,"xglm"),cVr.forEach(t),_mo=r(mEe," \u2014 "),uP=n(mEe,"A",{href:!0});var fVr=s(uP);umo=r(fVr,"XGLMModel"),fVr.forEach(t),bmo=r(mEe," (XGLM model)"),mEe.forEach(t),vmo=i(C),T_=n(C,"LI",{});var gEe=s(T_);oee=n(gEe,"STRONG",{});var mVr=s(oee);Tmo=r(mVr,"xlm"),mVr.forEach(t),Fmo=r(gEe," \u2014 "),bP=n(gEe,"A",{href:!0});var gVr=s(bP);Cmo=r(gVr,"XLMModel"),gVr.forEach(t),Mmo=r(gEe," (XLM model)"),gEe.forEach(t),Emo=i(C),F_=n(C,"LI",{});var hEe=s(F_);ree=n(hEe,"STRONG",{});var hVr=s(ree);ymo=r(hVr,"xlm-prophetnet"),hVr.forEach(t),wmo=r(hEe," \u2014 "),vP=n(hEe,"A",{href:!0});var pVr=s(vP);Amo=r(pVr,"XLMProphetNetModel"),pVr.forEach(t),Lmo=r(hEe," (XLMProphetNet model)"),hEe.forEach(t),Bmo=i(C),C_=n(C,"LI",{});var pEe=s(C_);tee=n(pEe,"STRONG",{});var _Vr=s(tee);xmo=r(_Vr,"xlm-roberta"),_Vr.forEach(t),kmo=r(pEe," \u2014 "),TP=n(pEe,"A",{href:!0});var uVr=s(TP);Rmo=r(uVr,"XLMRobertaModel"),uVr.forEach(t),Smo=r(pEe," (XLM-RoBERTa model)"),pEe.forEach(t),Pmo=i(C),M_=n(C,"LI",{});var _Ee=s(M_);aee=n(_Ee,"STRONG",{});var bVr=s(aee);$mo=r(bVr,"xlm-roberta-xl"),bVr.forEach(t),Imo=r(_Ee," \u2014 "),FP=n(_Ee,"A",{href:!0});var vVr=s(FP);Nmo=r(vVr,"XLMRobertaXLModel"),vVr.forEach(t),Dmo=r(_Ee," (XLM-RoBERTa-XL model)"),_Ee.forEach(t),jmo=i(C),E_=n(C,"LI",{});var uEe=s(E_);nee=n(uEe,"STRONG",{});var TVr=s(nee);qmo=r(TVr,"xlnet"),TVr.forEach(t),Gmo=r(uEe," \u2014 "),CP=n(uEe,"A",{href:!0});var FVr=s(CP);Omo=r(FVr,"XLNetModel"),FVr.forEach(t),Xmo=r(uEe," (XLNet model)"),uEe.forEach(t),Vmo=i(C),y_=n(C,"LI",{});var bEe=s(y_);see=n(bEe,"STRONG",{});var CVr=s(see);zmo=r(CVr,"yoso"),CVr.forEach(t),Wmo=r(bEe," \u2014 "),MP=n(bEe,"A",{href:!0});var MVr=s(MP);Qmo=r(MVr,"YosoModel"),MVr.forEach(t),Hmo=r(bEe," (YOSO model)"),bEe.forEach(t),C.forEach(t),Umo=i(qt),w_=n(qt,"P",{});var vEe=s(w_);Jmo=r(vEe,"The model is set in evaluation mode by default using "),lee=n(vEe,"CODE",{});var EVr=s(lee);Ymo=r(EVr,"model.eval()"),EVr.forEach(t),Kmo=r(vEe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iee=n(vEe,"CODE",{});var yVr=s(iee);Zmo=r(yVr,"model.train()"),yVr.forEach(t),vEe.forEach(t),ego=i(qt),dee=n(qt,"P",{});var wVr=s(dee);ogo=r(wVr,"Examples:"),wVr.forEach(t),rgo=i(qt),m(Q3.$$.fragment,qt),qt.forEach(t),Ws.forEach(t),Mke=i(c),Zi=n(c,"H2",{class:!0});var RSe=s(Zi);A_=n(RSe,"A",{id:!0,class:!0,href:!0});var AVr=s(A_);cee=n(AVr,"SPAN",{});var LVr=s(cee);m(H3.$$.fragment,LVr),LVr.forEach(t),AVr.forEach(t),tgo=i(RSe),fee=n(RSe,"SPAN",{});var BVr=s(fee);ago=r(BVr,"AutoModelForPreTraining"),BVr.forEach(t),RSe.forEach(t),Eke=i(c),Yo=n(c,"DIV",{class:!0});var Hs=s(Yo);m(U3.$$.fragment,Hs),ngo=i(Hs),ed=n(Hs,"P",{});var oW=s(ed);sgo=r(oW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mee=n(oW,"CODE",{});var xVr=s(mee);lgo=r(xVr,"from_pretrained()"),xVr.forEach(t),igo=r(oW,"class method or the "),gee=n(oW,"CODE",{});var kVr=s(gee);dgo=r(kVr,"from_config()"),kVr.forEach(t),cgo=r(oW,`class
method.`),oW.forEach(t),fgo=i(Hs),J3=n(Hs,"P",{});var SSe=s(J3);mgo=r(SSe,"This class cannot be instantiated directly using "),hee=n(SSe,"CODE",{});var RVr=s(hee);ggo=r(RVr,"__init__()"),RVr.forEach(t),hgo=r(SSe," (throws an error)."),SSe.forEach(t),pgo=i(Hs),zr=n(Hs,"DIV",{class:!0});var Us=s(zr);m(Y3.$$.fragment,Us),_go=i(Us),pee=n(Us,"P",{});var SVr=s(pee);ugo=r(SVr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),SVr.forEach(t),bgo=i(Us),od=n(Us,"P",{});var rW=s(od);vgo=r(rW,`Note:
Loading a model from its configuration file does `),_ee=n(rW,"STRONG",{});var PVr=s(_ee);Tgo=r(PVr,"not"),PVr.forEach(t),Fgo=r(rW,` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=n(rW,"CODE",{});var $Vr=s(uee);Cgo=r($Vr,"from_pretrained()"),$Vr.forEach(t),Mgo=r(rW,"to load the model weights."),rW.forEach(t),Ego=i(Us),bee=n(Us,"P",{});var IVr=s(bee);ygo=r(IVr,"Examples:"),IVr.forEach(t),wgo=i(Us),m(K3.$$.fragment,Us),Us.forEach(t),Ago=i(Hs),De=n(Hs,"DIV",{class:!0});var Gt=s(De);m(Z3.$$.fragment,Gt),Lgo=i(Gt),vee=n(Gt,"P",{});var NVr=s(vee);Bgo=r(NVr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),NVr.forEach(t),xgo=i(Gt),za=n(Gt,"P",{});var mE=s(za);kgo=r(mE,"The model class to instantiate is selected based on the "),Tee=n(mE,"CODE",{});var DVr=s(Tee);Rgo=r(DVr,"model_type"),DVr.forEach(t),Sgo=r(mE,` property of the config object (either
passed as an argument or loaded from `),Fee=n(mE,"CODE",{});var jVr=s(Fee);Pgo=r(jVr,"pretrained_model_name_or_path"),jVr.forEach(t),$go=r(mE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cee=n(mE,"CODE",{});var qVr=s(Cee);Igo=r(qVr,"pretrained_model_name_or_path"),qVr.forEach(t),Ngo=r(mE,":"),mE.forEach(t),Dgo=i(Gt),k=n(Gt,"UL",{});var S=s(k);L_=n(S,"LI",{});var TEe=s(L_);Mee=n(TEe,"STRONG",{});var GVr=s(Mee);jgo=r(GVr,"albert"),GVr.forEach(t),qgo=r(TEe," \u2014 "),EP=n(TEe,"A",{href:!0});var OVr=s(EP);Ggo=r(OVr,"AlbertForPreTraining"),OVr.forEach(t),Ogo=r(TEe," (ALBERT model)"),TEe.forEach(t),Xgo=i(S),B_=n(S,"LI",{});var FEe=s(B_);Eee=n(FEe,"STRONG",{});var XVr=s(Eee);Vgo=r(XVr,"bart"),XVr.forEach(t),zgo=r(FEe," \u2014 "),yP=n(FEe,"A",{href:!0});var VVr=s(yP);Wgo=r(VVr,"BartForConditionalGeneration"),VVr.forEach(t),Qgo=r(FEe," (BART model)"),FEe.forEach(t),Hgo=i(S),x_=n(S,"LI",{});var CEe=s(x_);yee=n(CEe,"STRONG",{});var zVr=s(yee);Ugo=r(zVr,"bert"),zVr.forEach(t),Jgo=r(CEe," \u2014 "),wP=n(CEe,"A",{href:!0});var WVr=s(wP);Ygo=r(WVr,"BertForPreTraining"),WVr.forEach(t),Kgo=r(CEe," (BERT model)"),CEe.forEach(t),Zgo=i(S),k_=n(S,"LI",{});var MEe=s(k_);wee=n(MEe,"STRONG",{});var QVr=s(wee);eho=r(QVr,"big_bird"),QVr.forEach(t),oho=r(MEe," \u2014 "),AP=n(MEe,"A",{href:!0});var HVr=s(AP);rho=r(HVr,"BigBirdForPreTraining"),HVr.forEach(t),tho=r(MEe," (BigBird model)"),MEe.forEach(t),aho=i(S),R_=n(S,"LI",{});var EEe=s(R_);Aee=n(EEe,"STRONG",{});var UVr=s(Aee);nho=r(UVr,"camembert"),UVr.forEach(t),sho=r(EEe," \u2014 "),LP=n(EEe,"A",{href:!0});var JVr=s(LP);lho=r(JVr,"CamembertForMaskedLM"),JVr.forEach(t),iho=r(EEe," (CamemBERT model)"),EEe.forEach(t),dho=i(S),S_=n(S,"LI",{});var yEe=s(S_);Lee=n(yEe,"STRONG",{});var YVr=s(Lee);cho=r(YVr,"ctrl"),YVr.forEach(t),fho=r(yEe," \u2014 "),BP=n(yEe,"A",{href:!0});var KVr=s(BP);mho=r(KVr,"CTRLLMHeadModel"),KVr.forEach(t),gho=r(yEe," (CTRL model)"),yEe.forEach(t),hho=i(S),P_=n(S,"LI",{});var wEe=s(P_);Bee=n(wEe,"STRONG",{});var ZVr=s(Bee);pho=r(ZVr,"data2vec-text"),ZVr.forEach(t),_ho=r(wEe," \u2014 "),xP=n(wEe,"A",{href:!0});var ezr=s(xP);uho=r(ezr,"Data2VecTextForMaskedLM"),ezr.forEach(t),bho=r(wEe," (Data2VecText model)"),wEe.forEach(t),vho=i(S),$_=n(S,"LI",{});var AEe=s($_);xee=n(AEe,"STRONG",{});var ozr=s(xee);Tho=r(ozr,"deberta"),ozr.forEach(t),Fho=r(AEe," \u2014 "),kP=n(AEe,"A",{href:!0});var rzr=s(kP);Cho=r(rzr,"DebertaForMaskedLM"),rzr.forEach(t),Mho=r(AEe," (DeBERTa model)"),AEe.forEach(t),Eho=i(S),I_=n(S,"LI",{});var LEe=s(I_);kee=n(LEe,"STRONG",{});var tzr=s(kee);yho=r(tzr,"deberta-v2"),tzr.forEach(t),who=r(LEe," \u2014 "),RP=n(LEe,"A",{href:!0});var azr=s(RP);Aho=r(azr,"DebertaV2ForMaskedLM"),azr.forEach(t),Lho=r(LEe," (DeBERTa-v2 model)"),LEe.forEach(t),Bho=i(S),N_=n(S,"LI",{});var BEe=s(N_);Ree=n(BEe,"STRONG",{});var nzr=s(Ree);xho=r(nzr,"distilbert"),nzr.forEach(t),kho=r(BEe," \u2014 "),SP=n(BEe,"A",{href:!0});var szr=s(SP);Rho=r(szr,"DistilBertForMaskedLM"),szr.forEach(t),Sho=r(BEe," (DistilBERT model)"),BEe.forEach(t),Pho=i(S),D_=n(S,"LI",{});var xEe=s(D_);See=n(xEe,"STRONG",{});var lzr=s(See);$ho=r(lzr,"electra"),lzr.forEach(t),Iho=r(xEe," \u2014 "),PP=n(xEe,"A",{href:!0});var izr=s(PP);Nho=r(izr,"ElectraForPreTraining"),izr.forEach(t),Dho=r(xEe," (ELECTRA model)"),xEe.forEach(t),jho=i(S),j_=n(S,"LI",{});var kEe=s(j_);Pee=n(kEe,"STRONG",{});var dzr=s(Pee);qho=r(dzr,"flaubert"),dzr.forEach(t),Gho=r(kEe," \u2014 "),$P=n(kEe,"A",{href:!0});var czr=s($P);Oho=r(czr,"FlaubertWithLMHeadModel"),czr.forEach(t),Xho=r(kEe," (FlauBERT model)"),kEe.forEach(t),Vho=i(S),q_=n(S,"LI",{});var REe=s(q_);$ee=n(REe,"STRONG",{});var fzr=s($ee);zho=r(fzr,"fnet"),fzr.forEach(t),Who=r(REe," \u2014 "),IP=n(REe,"A",{href:!0});var mzr=s(IP);Qho=r(mzr,"FNetForPreTraining"),mzr.forEach(t),Hho=r(REe," (FNet model)"),REe.forEach(t),Uho=i(S),G_=n(S,"LI",{});var SEe=s(G_);Iee=n(SEe,"STRONG",{});var gzr=s(Iee);Jho=r(gzr,"fsmt"),gzr.forEach(t),Yho=r(SEe," \u2014 "),NP=n(SEe,"A",{href:!0});var hzr=s(NP);Kho=r(hzr,"FSMTForConditionalGeneration"),hzr.forEach(t),Zho=r(SEe," (FairSeq Machine-Translation model)"),SEe.forEach(t),epo=i(S),O_=n(S,"LI",{});var PEe=s(O_);Nee=n(PEe,"STRONG",{});var pzr=s(Nee);opo=r(pzr,"funnel"),pzr.forEach(t),rpo=r(PEe," \u2014 "),DP=n(PEe,"A",{href:!0});var _zr=s(DP);tpo=r(_zr,"FunnelForPreTraining"),_zr.forEach(t),apo=r(PEe," (Funnel Transformer model)"),PEe.forEach(t),npo=i(S),X_=n(S,"LI",{});var $Ee=s(X_);Dee=n($Ee,"STRONG",{});var uzr=s(Dee);spo=r(uzr,"gpt2"),uzr.forEach(t),lpo=r($Ee," \u2014 "),jP=n($Ee,"A",{href:!0});var bzr=s(jP);ipo=r(bzr,"GPT2LMHeadModel"),bzr.forEach(t),dpo=r($Ee," (OpenAI GPT-2 model)"),$Ee.forEach(t),cpo=i(S),V_=n(S,"LI",{});var IEe=s(V_);jee=n(IEe,"STRONG",{});var vzr=s(jee);fpo=r(vzr,"ibert"),vzr.forEach(t),mpo=r(IEe," \u2014 "),qP=n(IEe,"A",{href:!0});var Tzr=s(qP);gpo=r(Tzr,"IBertForMaskedLM"),Tzr.forEach(t),hpo=r(IEe," (I-BERT model)"),IEe.forEach(t),ppo=i(S),z_=n(S,"LI",{});var NEe=s(z_);qee=n(NEe,"STRONG",{});var Fzr=s(qee);_po=r(Fzr,"layoutlm"),Fzr.forEach(t),upo=r(NEe," \u2014 "),GP=n(NEe,"A",{href:!0});var Czr=s(GP);bpo=r(Czr,"LayoutLMForMaskedLM"),Czr.forEach(t),vpo=r(NEe," (LayoutLM model)"),NEe.forEach(t),Tpo=i(S),W_=n(S,"LI",{});var DEe=s(W_);Gee=n(DEe,"STRONG",{});var Mzr=s(Gee);Fpo=r(Mzr,"longformer"),Mzr.forEach(t),Cpo=r(DEe," \u2014 "),OP=n(DEe,"A",{href:!0});var Ezr=s(OP);Mpo=r(Ezr,"LongformerForMaskedLM"),Ezr.forEach(t),Epo=r(DEe," (Longformer model)"),DEe.forEach(t),ypo=i(S),Q_=n(S,"LI",{});var jEe=s(Q_);Oee=n(jEe,"STRONG",{});var yzr=s(Oee);wpo=r(yzr,"lxmert"),yzr.forEach(t),Apo=r(jEe," \u2014 "),XP=n(jEe,"A",{href:!0});var wzr=s(XP);Lpo=r(wzr,"LxmertForPreTraining"),wzr.forEach(t),Bpo=r(jEe," (LXMERT model)"),jEe.forEach(t),xpo=i(S),H_=n(S,"LI",{});var qEe=s(H_);Xee=n(qEe,"STRONG",{});var Azr=s(Xee);kpo=r(Azr,"megatron-bert"),Azr.forEach(t),Rpo=r(qEe," \u2014 "),VP=n(qEe,"A",{href:!0});var Lzr=s(VP);Spo=r(Lzr,"MegatronBertForPreTraining"),Lzr.forEach(t),Ppo=r(qEe," (MegatronBert model)"),qEe.forEach(t),$po=i(S),U_=n(S,"LI",{});var GEe=s(U_);Vee=n(GEe,"STRONG",{});var Bzr=s(Vee);Ipo=r(Bzr,"mobilebert"),Bzr.forEach(t),Npo=r(GEe," \u2014 "),zP=n(GEe,"A",{href:!0});var xzr=s(zP);Dpo=r(xzr,"MobileBertForPreTraining"),xzr.forEach(t),jpo=r(GEe," (MobileBERT model)"),GEe.forEach(t),qpo=i(S),J_=n(S,"LI",{});var OEe=s(J_);zee=n(OEe,"STRONG",{});var kzr=s(zee);Gpo=r(kzr,"mpnet"),kzr.forEach(t),Opo=r(OEe," \u2014 "),WP=n(OEe,"A",{href:!0});var Rzr=s(WP);Xpo=r(Rzr,"MPNetForMaskedLM"),Rzr.forEach(t),Vpo=r(OEe," (MPNet model)"),OEe.forEach(t),zpo=i(S),Y_=n(S,"LI",{});var XEe=s(Y_);Wee=n(XEe,"STRONG",{});var Szr=s(Wee);Wpo=r(Szr,"openai-gpt"),Szr.forEach(t),Qpo=r(XEe," \u2014 "),QP=n(XEe,"A",{href:!0});var Pzr=s(QP);Hpo=r(Pzr,"OpenAIGPTLMHeadModel"),Pzr.forEach(t),Upo=r(XEe," (OpenAI GPT model)"),XEe.forEach(t),Jpo=i(S),K_=n(S,"LI",{});var VEe=s(K_);Qee=n(VEe,"STRONG",{});var $zr=s(Qee);Ypo=r($zr,"retribert"),$zr.forEach(t),Kpo=r(VEe," \u2014 "),HP=n(VEe,"A",{href:!0});var Izr=s(HP);Zpo=r(Izr,"RetriBertModel"),Izr.forEach(t),e_o=r(VEe," (RetriBERT model)"),VEe.forEach(t),o_o=i(S),Z_=n(S,"LI",{});var zEe=s(Z_);Hee=n(zEe,"STRONG",{});var Nzr=s(Hee);r_o=r(Nzr,"roberta"),Nzr.forEach(t),t_o=r(zEe," \u2014 "),UP=n(zEe,"A",{href:!0});var Dzr=s(UP);a_o=r(Dzr,"RobertaForMaskedLM"),Dzr.forEach(t),n_o=r(zEe," (RoBERTa model)"),zEe.forEach(t),s_o=i(S),eu=n(S,"LI",{});var WEe=s(eu);Uee=n(WEe,"STRONG",{});var jzr=s(Uee);l_o=r(jzr,"squeezebert"),jzr.forEach(t),i_o=r(WEe," \u2014 "),JP=n(WEe,"A",{href:!0});var qzr=s(JP);d_o=r(qzr,"SqueezeBertForMaskedLM"),qzr.forEach(t),c_o=r(WEe," (SqueezeBERT model)"),WEe.forEach(t),f_o=i(S),ou=n(S,"LI",{});var QEe=s(ou);Jee=n(QEe,"STRONG",{});var Gzr=s(Jee);m_o=r(Gzr,"t5"),Gzr.forEach(t),g_o=r(QEe," \u2014 "),YP=n(QEe,"A",{href:!0});var Ozr=s(YP);h_o=r(Ozr,"T5ForConditionalGeneration"),Ozr.forEach(t),p_o=r(QEe," (T5 model)"),QEe.forEach(t),__o=i(S),ru=n(S,"LI",{});var HEe=s(ru);Yee=n(HEe,"STRONG",{});var Xzr=s(Yee);u_o=r(Xzr,"tapas"),Xzr.forEach(t),b_o=r(HEe," \u2014 "),KP=n(HEe,"A",{href:!0});var Vzr=s(KP);v_o=r(Vzr,"TapasForMaskedLM"),Vzr.forEach(t),T_o=r(HEe," (TAPAS model)"),HEe.forEach(t),F_o=i(S),tu=n(S,"LI",{});var UEe=s(tu);Kee=n(UEe,"STRONG",{});var zzr=s(Kee);C_o=r(zzr,"transfo-xl"),zzr.forEach(t),M_o=r(UEe," \u2014 "),ZP=n(UEe,"A",{href:!0});var Wzr=s(ZP);E_o=r(Wzr,"TransfoXLLMHeadModel"),Wzr.forEach(t),y_o=r(UEe," (Transformer-XL model)"),UEe.forEach(t),w_o=i(S),au=n(S,"LI",{});var JEe=s(au);Zee=n(JEe,"STRONG",{});var Qzr=s(Zee);A_o=r(Qzr,"unispeech"),Qzr.forEach(t),L_o=r(JEe," \u2014 "),e$=n(JEe,"A",{href:!0});var Hzr=s(e$);B_o=r(Hzr,"UniSpeechForPreTraining"),Hzr.forEach(t),x_o=r(JEe," (UniSpeech model)"),JEe.forEach(t),k_o=i(S),nu=n(S,"LI",{});var YEe=s(nu);eoe=n(YEe,"STRONG",{});var Uzr=s(eoe);R_o=r(Uzr,"unispeech-sat"),Uzr.forEach(t),S_o=r(YEe," \u2014 "),o$=n(YEe,"A",{href:!0});var Jzr=s(o$);P_o=r(Jzr,"UniSpeechSatForPreTraining"),Jzr.forEach(t),$_o=r(YEe," (UniSpeechSat model)"),YEe.forEach(t),I_o=i(S),su=n(S,"LI",{});var KEe=s(su);ooe=n(KEe,"STRONG",{});var Yzr=s(ooe);N_o=r(Yzr,"visual_bert"),Yzr.forEach(t),D_o=r(KEe," \u2014 "),r$=n(KEe,"A",{href:!0});var Kzr=s(r$);j_o=r(Kzr,"VisualBertForPreTraining"),Kzr.forEach(t),q_o=r(KEe," (VisualBert model)"),KEe.forEach(t),G_o=i(S),lu=n(S,"LI",{});var ZEe=s(lu);roe=n(ZEe,"STRONG",{});var Zzr=s(roe);O_o=r(Zzr,"vit_mae"),Zzr.forEach(t),X_o=r(ZEe," \u2014 "),t$=n(ZEe,"A",{href:!0});var eWr=s(t$);V_o=r(eWr,"ViTMAEForPreTraining"),eWr.forEach(t),z_o=r(ZEe," (ViTMAE model)"),ZEe.forEach(t),W_o=i(S),iu=n(S,"LI",{});var e3e=s(iu);toe=n(e3e,"STRONG",{});var oWr=s(toe);Q_o=r(oWr,"wav2vec2"),oWr.forEach(t),H_o=r(e3e," \u2014 "),a$=n(e3e,"A",{href:!0});var rWr=s(a$);U_o=r(rWr,"Wav2Vec2ForPreTraining"),rWr.forEach(t),J_o=r(e3e," (Wav2Vec2 model)"),e3e.forEach(t),Y_o=i(S),du=n(S,"LI",{});var o3e=s(du);aoe=n(o3e,"STRONG",{});var tWr=s(aoe);K_o=r(tWr,"xlm"),tWr.forEach(t),Z_o=r(o3e," \u2014 "),n$=n(o3e,"A",{href:!0});var aWr=s(n$);euo=r(aWr,"XLMWithLMHeadModel"),aWr.forEach(t),ouo=r(o3e," (XLM model)"),o3e.forEach(t),ruo=i(S),cu=n(S,"LI",{});var r3e=s(cu);noe=n(r3e,"STRONG",{});var nWr=s(noe);tuo=r(nWr,"xlm-roberta"),nWr.forEach(t),auo=r(r3e," \u2014 "),s$=n(r3e,"A",{href:!0});var sWr=s(s$);nuo=r(sWr,"XLMRobertaForMaskedLM"),sWr.forEach(t),suo=r(r3e," (XLM-RoBERTa model)"),r3e.forEach(t),luo=i(S),fu=n(S,"LI",{});var t3e=s(fu);soe=n(t3e,"STRONG",{});var lWr=s(soe);iuo=r(lWr,"xlm-roberta-xl"),lWr.forEach(t),duo=r(t3e," \u2014 "),l$=n(t3e,"A",{href:!0});var iWr=s(l$);cuo=r(iWr,"XLMRobertaXLForMaskedLM"),iWr.forEach(t),fuo=r(t3e," (XLM-RoBERTa-XL model)"),t3e.forEach(t),muo=i(S),mu=n(S,"LI",{});var a3e=s(mu);loe=n(a3e,"STRONG",{});var dWr=s(loe);guo=r(dWr,"xlnet"),dWr.forEach(t),huo=r(a3e," \u2014 "),i$=n(a3e,"A",{href:!0});var cWr=s(i$);puo=r(cWr,"XLNetLMHeadModel"),cWr.forEach(t),_uo=r(a3e," (XLNet model)"),a3e.forEach(t),S.forEach(t),uuo=i(Gt),gu=n(Gt,"P",{});var n3e=s(gu);buo=r(n3e,"The model is set in evaluation mode by default using "),ioe=n(n3e,"CODE",{});var fWr=s(ioe);vuo=r(fWr,"model.eval()"),fWr.forEach(t),Tuo=r(n3e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),doe=n(n3e,"CODE",{});var mWr=s(doe);Fuo=r(mWr,"model.train()"),mWr.forEach(t),n3e.forEach(t),Cuo=i(Gt),coe=n(Gt,"P",{});var gWr=s(coe);Muo=r(gWr,"Examples:"),gWr.forEach(t),Euo=i(Gt),m(ey.$$.fragment,Gt),Gt.forEach(t),Hs.forEach(t),yke=i(c),rd=n(c,"H2",{class:!0});var PSe=s(rd);hu=n(PSe,"A",{id:!0,class:!0,href:!0});var hWr=s(hu);foe=n(hWr,"SPAN",{});var pWr=s(foe);m(oy.$$.fragment,pWr),pWr.forEach(t),hWr.forEach(t),yuo=i(PSe),moe=n(PSe,"SPAN",{});var _Wr=s(moe);wuo=r(_Wr,"AutoModelForCausalLM"),_Wr.forEach(t),PSe.forEach(t),wke=i(c),Ko=n(c,"DIV",{class:!0});var Js=s(Ko);m(ry.$$.fragment,Js),Auo=i(Js),td=n(Js,"P",{});var tW=s(td);Luo=r(tW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),goe=n(tW,"CODE",{});var uWr=s(goe);Buo=r(uWr,"from_pretrained()"),uWr.forEach(t),xuo=r(tW,"class method or the "),hoe=n(tW,"CODE",{});var bWr=s(hoe);kuo=r(bWr,"from_config()"),bWr.forEach(t),Ruo=r(tW,`class
method.`),tW.forEach(t),Suo=i(Js),ty=n(Js,"P",{});var $Se=s(ty);Puo=r($Se,"This class cannot be instantiated directly using "),poe=n($Se,"CODE",{});var vWr=s(poe);$uo=r(vWr,"__init__()"),vWr.forEach(t),Iuo=r($Se," (throws an error)."),$Se.forEach(t),Nuo=i(Js),Wr=n(Js,"DIV",{class:!0});var Ys=s(Wr);m(ay.$$.fragment,Ys),Duo=i(Ys),_oe=n(Ys,"P",{});var TWr=s(_oe);juo=r(TWr,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),TWr.forEach(t),quo=i(Ys),ad=n(Ys,"P",{});var aW=s(ad);Guo=r(aW,`Note:
Loading a model from its configuration file does `),uoe=n(aW,"STRONG",{});var FWr=s(uoe);Ouo=r(FWr,"not"),FWr.forEach(t),Xuo=r(aW,` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=n(aW,"CODE",{});var CWr=s(boe);Vuo=r(CWr,"from_pretrained()"),CWr.forEach(t),zuo=r(aW,"to load the model weights."),aW.forEach(t),Wuo=i(Ys),voe=n(Ys,"P",{});var MWr=s(voe);Quo=r(MWr,"Examples:"),MWr.forEach(t),Huo=i(Ys),m(ny.$$.fragment,Ys),Ys.forEach(t),Uuo=i(Js),je=n(Js,"DIV",{class:!0});var Ot=s(je);m(sy.$$.fragment,Ot),Juo=i(Ot),Toe=n(Ot,"P",{});var EWr=s(Toe);Yuo=r(EWr,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),EWr.forEach(t),Kuo=i(Ot),Wa=n(Ot,"P",{});var gE=s(Wa);Zuo=r(gE,"The model class to instantiate is selected based on the "),Foe=n(gE,"CODE",{});var yWr=s(Foe);e5o=r(yWr,"model_type"),yWr.forEach(t),o5o=r(gE,` property of the config object (either
passed as an argument or loaded from `),Coe=n(gE,"CODE",{});var wWr=s(Coe);r5o=r(wWr,"pretrained_model_name_or_path"),wWr.forEach(t),t5o=r(gE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Moe=n(gE,"CODE",{});var AWr=s(Moe);a5o=r(AWr,"pretrained_model_name_or_path"),AWr.forEach(t),n5o=r(gE,":"),gE.forEach(t),s5o=i(Ot),$=n(Ot,"UL",{});var N=s($);pu=n(N,"LI",{});var s3e=s(pu);Eoe=n(s3e,"STRONG",{});var LWr=s(Eoe);l5o=r(LWr,"bart"),LWr.forEach(t),i5o=r(s3e," \u2014 "),d$=n(s3e,"A",{href:!0});var BWr=s(d$);d5o=r(BWr,"BartForCausalLM"),BWr.forEach(t),c5o=r(s3e," (BART model)"),s3e.forEach(t),f5o=i(N),_u=n(N,"LI",{});var l3e=s(_u);yoe=n(l3e,"STRONG",{});var xWr=s(yoe);m5o=r(xWr,"bert"),xWr.forEach(t),g5o=r(l3e," \u2014 "),c$=n(l3e,"A",{href:!0});var kWr=s(c$);h5o=r(kWr,"BertLMHeadModel"),kWr.forEach(t),p5o=r(l3e," (BERT model)"),l3e.forEach(t),_5o=i(N),uu=n(N,"LI",{});var i3e=s(uu);woe=n(i3e,"STRONG",{});var RWr=s(woe);u5o=r(RWr,"bert-generation"),RWr.forEach(t),b5o=r(i3e," \u2014 "),f$=n(i3e,"A",{href:!0});var SWr=s(f$);v5o=r(SWr,"BertGenerationDecoder"),SWr.forEach(t),T5o=r(i3e," (Bert Generation model)"),i3e.forEach(t),F5o=i(N),bu=n(N,"LI",{});var d3e=s(bu);Aoe=n(d3e,"STRONG",{});var PWr=s(Aoe);C5o=r(PWr,"big_bird"),PWr.forEach(t),M5o=r(d3e," \u2014 "),m$=n(d3e,"A",{href:!0});var $Wr=s(m$);E5o=r($Wr,"BigBirdForCausalLM"),$Wr.forEach(t),y5o=r(d3e," (BigBird model)"),d3e.forEach(t),w5o=i(N),vu=n(N,"LI",{});var c3e=s(vu);Loe=n(c3e,"STRONG",{});var IWr=s(Loe);A5o=r(IWr,"bigbird_pegasus"),IWr.forEach(t),L5o=r(c3e," \u2014 "),g$=n(c3e,"A",{href:!0});var NWr=s(g$);B5o=r(NWr,"BigBirdPegasusForCausalLM"),NWr.forEach(t),x5o=r(c3e," (BigBirdPegasus model)"),c3e.forEach(t),k5o=i(N),Tu=n(N,"LI",{});var f3e=s(Tu);Boe=n(f3e,"STRONG",{});var DWr=s(Boe);R5o=r(DWr,"blenderbot"),DWr.forEach(t),S5o=r(f3e," \u2014 "),h$=n(f3e,"A",{href:!0});var jWr=s(h$);P5o=r(jWr,"BlenderbotForCausalLM"),jWr.forEach(t),$5o=r(f3e," (Blenderbot model)"),f3e.forEach(t),I5o=i(N),Fu=n(N,"LI",{});var m3e=s(Fu);xoe=n(m3e,"STRONG",{});var qWr=s(xoe);N5o=r(qWr,"blenderbot-small"),qWr.forEach(t),D5o=r(m3e," \u2014 "),p$=n(m3e,"A",{href:!0});var GWr=s(p$);j5o=r(GWr,"BlenderbotSmallForCausalLM"),GWr.forEach(t),q5o=r(m3e," (BlenderbotSmall model)"),m3e.forEach(t),G5o=i(N),Cu=n(N,"LI",{});var g3e=s(Cu);koe=n(g3e,"STRONG",{});var OWr=s(koe);O5o=r(OWr,"camembert"),OWr.forEach(t),X5o=r(g3e," \u2014 "),_$=n(g3e,"A",{href:!0});var XWr=s(_$);V5o=r(XWr,"CamembertForCausalLM"),XWr.forEach(t),z5o=r(g3e," (CamemBERT model)"),g3e.forEach(t),W5o=i(N),Mu=n(N,"LI",{});var h3e=s(Mu);Roe=n(h3e,"STRONG",{});var VWr=s(Roe);Q5o=r(VWr,"ctrl"),VWr.forEach(t),H5o=r(h3e," \u2014 "),u$=n(h3e,"A",{href:!0});var zWr=s(u$);U5o=r(zWr,"CTRLLMHeadModel"),zWr.forEach(t),J5o=r(h3e," (CTRL model)"),h3e.forEach(t),Y5o=i(N),Eu=n(N,"LI",{});var p3e=s(Eu);Soe=n(p3e,"STRONG",{});var WWr=s(Soe);K5o=r(WWr,"data2vec-text"),WWr.forEach(t),Z5o=r(p3e," \u2014 "),b$=n(p3e,"A",{href:!0});var QWr=s(b$);e2o=r(QWr,"Data2VecTextForCausalLM"),QWr.forEach(t),o2o=r(p3e," (Data2VecText model)"),p3e.forEach(t),r2o=i(N),yu=n(N,"LI",{});var _3e=s(yu);Poe=n(_3e,"STRONG",{});var HWr=s(Poe);t2o=r(HWr,"electra"),HWr.forEach(t),a2o=r(_3e," \u2014 "),v$=n(_3e,"A",{href:!0});var UWr=s(v$);n2o=r(UWr,"ElectraForCausalLM"),UWr.forEach(t),s2o=r(_3e," (ELECTRA model)"),_3e.forEach(t),l2o=i(N),wu=n(N,"LI",{});var u3e=s(wu);$oe=n(u3e,"STRONG",{});var JWr=s($oe);i2o=r(JWr,"gpt2"),JWr.forEach(t),d2o=r(u3e," \u2014 "),T$=n(u3e,"A",{href:!0});var YWr=s(T$);c2o=r(YWr,"GPT2LMHeadModel"),YWr.forEach(t),f2o=r(u3e," (OpenAI GPT-2 model)"),u3e.forEach(t),m2o=i(N),Au=n(N,"LI",{});var b3e=s(Au);Ioe=n(b3e,"STRONG",{});var KWr=s(Ioe);g2o=r(KWr,"gpt_neo"),KWr.forEach(t),h2o=r(b3e," \u2014 "),F$=n(b3e,"A",{href:!0});var ZWr=s(F$);p2o=r(ZWr,"GPTNeoForCausalLM"),ZWr.forEach(t),_2o=r(b3e," (GPT Neo model)"),b3e.forEach(t),u2o=i(N),Lu=n(N,"LI",{});var v3e=s(Lu);Noe=n(v3e,"STRONG",{});var eQr=s(Noe);b2o=r(eQr,"gptj"),eQr.forEach(t),v2o=r(v3e," \u2014 "),C$=n(v3e,"A",{href:!0});var oQr=s(C$);T2o=r(oQr,"GPTJForCausalLM"),oQr.forEach(t),F2o=r(v3e," (GPT-J model)"),v3e.forEach(t),C2o=i(N),Bu=n(N,"LI",{});var T3e=s(Bu);Doe=n(T3e,"STRONG",{});var rQr=s(Doe);M2o=r(rQr,"marian"),rQr.forEach(t),E2o=r(T3e," \u2014 "),M$=n(T3e,"A",{href:!0});var tQr=s(M$);y2o=r(tQr,"MarianForCausalLM"),tQr.forEach(t),w2o=r(T3e," (Marian model)"),T3e.forEach(t),A2o=i(N),xu=n(N,"LI",{});var F3e=s(xu);joe=n(F3e,"STRONG",{});var aQr=s(joe);L2o=r(aQr,"mbart"),aQr.forEach(t),B2o=r(F3e," \u2014 "),E$=n(F3e,"A",{href:!0});var nQr=s(E$);x2o=r(nQr,"MBartForCausalLM"),nQr.forEach(t),k2o=r(F3e," (mBART model)"),F3e.forEach(t),R2o=i(N),ku=n(N,"LI",{});var C3e=s(ku);qoe=n(C3e,"STRONG",{});var sQr=s(qoe);S2o=r(sQr,"megatron-bert"),sQr.forEach(t),P2o=r(C3e," \u2014 "),y$=n(C3e,"A",{href:!0});var lQr=s(y$);$2o=r(lQr,"MegatronBertForCausalLM"),lQr.forEach(t),I2o=r(C3e," (MegatronBert model)"),C3e.forEach(t),N2o=i(N),Ru=n(N,"LI",{});var M3e=s(Ru);Goe=n(M3e,"STRONG",{});var iQr=s(Goe);D2o=r(iQr,"openai-gpt"),iQr.forEach(t),j2o=r(M3e," \u2014 "),w$=n(M3e,"A",{href:!0});var dQr=s(w$);q2o=r(dQr,"OpenAIGPTLMHeadModel"),dQr.forEach(t),G2o=r(M3e," (OpenAI GPT model)"),M3e.forEach(t),O2o=i(N),Su=n(N,"LI",{});var E3e=s(Su);Ooe=n(E3e,"STRONG",{});var cQr=s(Ooe);X2o=r(cQr,"pegasus"),cQr.forEach(t),V2o=r(E3e," \u2014 "),A$=n(E3e,"A",{href:!0});var fQr=s(A$);z2o=r(fQr,"PegasusForCausalLM"),fQr.forEach(t),W2o=r(E3e," (Pegasus model)"),E3e.forEach(t),Q2o=i(N),Pu=n(N,"LI",{});var y3e=s(Pu);Xoe=n(y3e,"STRONG",{});var mQr=s(Xoe);H2o=r(mQr,"plbart"),mQr.forEach(t),U2o=r(y3e," \u2014 "),L$=n(y3e,"A",{href:!0});var gQr=s(L$);J2o=r(gQr,"PLBartForCausalLM"),gQr.forEach(t),Y2o=r(y3e," (PLBart model)"),y3e.forEach(t),K2o=i(N),$u=n(N,"LI",{});var w3e=s($u);Voe=n(w3e,"STRONG",{});var hQr=s(Voe);Z2o=r(hQr,"prophetnet"),hQr.forEach(t),e1o=r(w3e," \u2014 "),B$=n(w3e,"A",{href:!0});var pQr=s(B$);o1o=r(pQr,"ProphetNetForCausalLM"),pQr.forEach(t),r1o=r(w3e," (ProphetNet model)"),w3e.forEach(t),t1o=i(N),Iu=n(N,"LI",{});var A3e=s(Iu);zoe=n(A3e,"STRONG",{});var _Qr=s(zoe);a1o=r(_Qr,"qdqbert"),_Qr.forEach(t),n1o=r(A3e," \u2014 "),x$=n(A3e,"A",{href:!0});var uQr=s(x$);s1o=r(uQr,"QDQBertLMHeadModel"),uQr.forEach(t),l1o=r(A3e," (QDQBert model)"),A3e.forEach(t),i1o=i(N),Nu=n(N,"LI",{});var L3e=s(Nu);Woe=n(L3e,"STRONG",{});var bQr=s(Woe);d1o=r(bQr,"reformer"),bQr.forEach(t),c1o=r(L3e," \u2014 "),k$=n(L3e,"A",{href:!0});var vQr=s(k$);f1o=r(vQr,"ReformerModelWithLMHead"),vQr.forEach(t),m1o=r(L3e," (Reformer model)"),L3e.forEach(t),g1o=i(N),Du=n(N,"LI",{});var B3e=s(Du);Qoe=n(B3e,"STRONG",{});var TQr=s(Qoe);h1o=r(TQr,"rembert"),TQr.forEach(t),p1o=r(B3e," \u2014 "),R$=n(B3e,"A",{href:!0});var FQr=s(R$);_1o=r(FQr,"RemBertForCausalLM"),FQr.forEach(t),u1o=r(B3e," (RemBERT model)"),B3e.forEach(t),b1o=i(N),ju=n(N,"LI",{});var x3e=s(ju);Hoe=n(x3e,"STRONG",{});var CQr=s(Hoe);v1o=r(CQr,"roberta"),CQr.forEach(t),T1o=r(x3e," \u2014 "),S$=n(x3e,"A",{href:!0});var MQr=s(S$);F1o=r(MQr,"RobertaForCausalLM"),MQr.forEach(t),C1o=r(x3e," (RoBERTa model)"),x3e.forEach(t),M1o=i(N),qu=n(N,"LI",{});var k3e=s(qu);Uoe=n(k3e,"STRONG",{});var EQr=s(Uoe);E1o=r(EQr,"roformer"),EQr.forEach(t),y1o=r(k3e," \u2014 "),P$=n(k3e,"A",{href:!0});var yQr=s(P$);w1o=r(yQr,"RoFormerForCausalLM"),yQr.forEach(t),A1o=r(k3e," (RoFormer model)"),k3e.forEach(t),L1o=i(N),Gu=n(N,"LI",{});var R3e=s(Gu);Joe=n(R3e,"STRONG",{});var wQr=s(Joe);B1o=r(wQr,"speech_to_text_2"),wQr.forEach(t),x1o=r(R3e," \u2014 "),$$=n(R3e,"A",{href:!0});var AQr=s($$);k1o=r(AQr,"Speech2Text2ForCausalLM"),AQr.forEach(t),R1o=r(R3e," (Speech2Text2 model)"),R3e.forEach(t),S1o=i(N),Ou=n(N,"LI",{});var S3e=s(Ou);Yoe=n(S3e,"STRONG",{});var LQr=s(Yoe);P1o=r(LQr,"transfo-xl"),LQr.forEach(t),$1o=r(S3e," \u2014 "),I$=n(S3e,"A",{href:!0});var BQr=s(I$);I1o=r(BQr,"TransfoXLLMHeadModel"),BQr.forEach(t),N1o=r(S3e," (Transformer-XL model)"),S3e.forEach(t),D1o=i(N),Xu=n(N,"LI",{});var P3e=s(Xu);Koe=n(P3e,"STRONG",{});var xQr=s(Koe);j1o=r(xQr,"trocr"),xQr.forEach(t),q1o=r(P3e," \u2014 "),N$=n(P3e,"A",{href:!0});var kQr=s(N$);G1o=r(kQr,"TrOCRForCausalLM"),kQr.forEach(t),O1o=r(P3e," (TrOCR model)"),P3e.forEach(t),X1o=i(N),Vu=n(N,"LI",{});var $3e=s(Vu);Zoe=n($3e,"STRONG",{});var RQr=s(Zoe);V1o=r(RQr,"xglm"),RQr.forEach(t),z1o=r($3e," \u2014 "),D$=n($3e,"A",{href:!0});var SQr=s(D$);W1o=r(SQr,"XGLMForCausalLM"),SQr.forEach(t),Q1o=r($3e," (XGLM model)"),$3e.forEach(t),H1o=i(N),zu=n(N,"LI",{});var I3e=s(zu);ere=n(I3e,"STRONG",{});var PQr=s(ere);U1o=r(PQr,"xlm"),PQr.forEach(t),J1o=r(I3e," \u2014 "),j$=n(I3e,"A",{href:!0});var $Qr=s(j$);Y1o=r($Qr,"XLMWithLMHeadModel"),$Qr.forEach(t),K1o=r(I3e," (XLM model)"),I3e.forEach(t),Z1o=i(N),Wu=n(N,"LI",{});var N3e=s(Wu);ore=n(N3e,"STRONG",{});var IQr=s(ore);ebo=r(IQr,"xlm-prophetnet"),IQr.forEach(t),obo=r(N3e," \u2014 "),q$=n(N3e,"A",{href:!0});var NQr=s(q$);rbo=r(NQr,"XLMProphetNetForCausalLM"),NQr.forEach(t),tbo=r(N3e," (XLMProphetNet model)"),N3e.forEach(t),abo=i(N),Qu=n(N,"LI",{});var D3e=s(Qu);rre=n(D3e,"STRONG",{});var DQr=s(rre);nbo=r(DQr,"xlm-roberta"),DQr.forEach(t),sbo=r(D3e," \u2014 "),G$=n(D3e,"A",{href:!0});var jQr=s(G$);lbo=r(jQr,"XLMRobertaForCausalLM"),jQr.forEach(t),ibo=r(D3e," (XLM-RoBERTa model)"),D3e.forEach(t),dbo=i(N),Hu=n(N,"LI",{});var j3e=s(Hu);tre=n(j3e,"STRONG",{});var qQr=s(tre);cbo=r(qQr,"xlm-roberta-xl"),qQr.forEach(t),fbo=r(j3e," \u2014 "),O$=n(j3e,"A",{href:!0});var GQr=s(O$);mbo=r(GQr,"XLMRobertaXLForCausalLM"),GQr.forEach(t),gbo=r(j3e," (XLM-RoBERTa-XL model)"),j3e.forEach(t),hbo=i(N),Uu=n(N,"LI",{});var q3e=s(Uu);are=n(q3e,"STRONG",{});var OQr=s(are);pbo=r(OQr,"xlnet"),OQr.forEach(t),_bo=r(q3e," \u2014 "),X$=n(q3e,"A",{href:!0});var XQr=s(X$);ubo=r(XQr,"XLNetLMHeadModel"),XQr.forEach(t),bbo=r(q3e," (XLNet model)"),q3e.forEach(t),N.forEach(t),vbo=i(Ot),Ju=n(Ot,"P",{});var G3e=s(Ju);Tbo=r(G3e,"The model is set in evaluation mode by default using "),nre=n(G3e,"CODE",{});var VQr=s(nre);Fbo=r(VQr,"model.eval()"),VQr.forEach(t),Cbo=r(G3e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sre=n(G3e,"CODE",{});var zQr=s(sre);Mbo=r(zQr,"model.train()"),zQr.forEach(t),G3e.forEach(t),Ebo=i(Ot),lre=n(Ot,"P",{});var WQr=s(lre);ybo=r(WQr,"Examples:"),WQr.forEach(t),wbo=i(Ot),m(ly.$$.fragment,Ot),Ot.forEach(t),Js.forEach(t),Ake=i(c),nd=n(c,"H2",{class:!0});var ISe=s(nd);Yu=n(ISe,"A",{id:!0,class:!0,href:!0});var QQr=s(Yu);ire=n(QQr,"SPAN",{});var HQr=s(ire);m(iy.$$.fragment,HQr),HQr.forEach(t),QQr.forEach(t),Abo=i(ISe),dre=n(ISe,"SPAN",{});var UQr=s(dre);Lbo=r(UQr,"AutoModelForMaskedLM"),UQr.forEach(t),ISe.forEach(t),Lke=i(c),Zo=n(c,"DIV",{class:!0});var Ks=s(Zo);m(dy.$$.fragment,Ks),Bbo=i(Ks),sd=n(Ks,"P",{});var nW=s(sd);xbo=r(nW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cre=n(nW,"CODE",{});var JQr=s(cre);kbo=r(JQr,"from_pretrained()"),JQr.forEach(t),Rbo=r(nW,"class method or the "),fre=n(nW,"CODE",{});var YQr=s(fre);Sbo=r(YQr,"from_config()"),YQr.forEach(t),Pbo=r(nW,`class
method.`),nW.forEach(t),$bo=i(Ks),cy=n(Ks,"P",{});var NSe=s(cy);Ibo=r(NSe,"This class cannot be instantiated directly using "),mre=n(NSe,"CODE",{});var KQr=s(mre);Nbo=r(KQr,"__init__()"),KQr.forEach(t),Dbo=r(NSe," (throws an error)."),NSe.forEach(t),jbo=i(Ks),Qr=n(Ks,"DIV",{class:!0});var Zs=s(Qr);m(fy.$$.fragment,Zs),qbo=i(Zs),gre=n(Zs,"P",{});var ZQr=s(gre);Gbo=r(ZQr,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ZQr.forEach(t),Obo=i(Zs),ld=n(Zs,"P",{});var sW=s(ld);Xbo=r(sW,`Note:
Loading a model from its configuration file does `),hre=n(sW,"STRONG",{});var eHr=s(hre);Vbo=r(eHr,"not"),eHr.forEach(t),zbo=r(sW,` load the model weights. It only affects the
model\u2019s configuration. Use `),pre=n(sW,"CODE",{});var oHr=s(pre);Wbo=r(oHr,"from_pretrained()"),oHr.forEach(t),Qbo=r(sW,"to load the model weights."),sW.forEach(t),Hbo=i(Zs),_re=n(Zs,"P",{});var rHr=s(_re);Ubo=r(rHr,"Examples:"),rHr.forEach(t),Jbo=i(Zs),m(my.$$.fragment,Zs),Zs.forEach(t),Ybo=i(Ks),qe=n(Ks,"DIV",{class:!0});var Xt=s(qe);m(gy.$$.fragment,Xt),Kbo=i(Xt),ure=n(Xt,"P",{});var tHr=s(ure);Zbo=r(tHr,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),tHr.forEach(t),evo=i(Xt),Qa=n(Xt,"P",{});var hE=s(Qa);ovo=r(hE,"The model class to instantiate is selected based on the "),bre=n(hE,"CODE",{});var aHr=s(bre);rvo=r(aHr,"model_type"),aHr.forEach(t),tvo=r(hE,` property of the config object (either
passed as an argument or loaded from `),vre=n(hE,"CODE",{});var nHr=s(vre);avo=r(nHr,"pretrained_model_name_or_path"),nHr.forEach(t),nvo=r(hE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tre=n(hE,"CODE",{});var sHr=s(Tre);svo=r(sHr,"pretrained_model_name_or_path"),sHr.forEach(t),lvo=r(hE,":"),hE.forEach(t),ivo=i(Xt),I=n(Xt,"UL",{});var D=s(I);Ku=n(D,"LI",{});var O3e=s(Ku);Fre=n(O3e,"STRONG",{});var lHr=s(Fre);dvo=r(lHr,"albert"),lHr.forEach(t),cvo=r(O3e," \u2014 "),V$=n(O3e,"A",{href:!0});var iHr=s(V$);fvo=r(iHr,"AlbertForMaskedLM"),iHr.forEach(t),mvo=r(O3e," (ALBERT model)"),O3e.forEach(t),gvo=i(D),Zu=n(D,"LI",{});var X3e=s(Zu);Cre=n(X3e,"STRONG",{});var dHr=s(Cre);hvo=r(dHr,"bart"),dHr.forEach(t),pvo=r(X3e," \u2014 "),z$=n(X3e,"A",{href:!0});var cHr=s(z$);_vo=r(cHr,"BartForConditionalGeneration"),cHr.forEach(t),uvo=r(X3e," (BART model)"),X3e.forEach(t),bvo=i(D),e5=n(D,"LI",{});var V3e=s(e5);Mre=n(V3e,"STRONG",{});var fHr=s(Mre);vvo=r(fHr,"bert"),fHr.forEach(t),Tvo=r(V3e," \u2014 "),W$=n(V3e,"A",{href:!0});var mHr=s(W$);Fvo=r(mHr,"BertForMaskedLM"),mHr.forEach(t),Cvo=r(V3e," (BERT model)"),V3e.forEach(t),Mvo=i(D),o5=n(D,"LI",{});var z3e=s(o5);Ere=n(z3e,"STRONG",{});var gHr=s(Ere);Evo=r(gHr,"big_bird"),gHr.forEach(t),yvo=r(z3e," \u2014 "),Q$=n(z3e,"A",{href:!0});var hHr=s(Q$);wvo=r(hHr,"BigBirdForMaskedLM"),hHr.forEach(t),Avo=r(z3e," (BigBird model)"),z3e.forEach(t),Lvo=i(D),r5=n(D,"LI",{});var W3e=s(r5);yre=n(W3e,"STRONG",{});var pHr=s(yre);Bvo=r(pHr,"camembert"),pHr.forEach(t),xvo=r(W3e," \u2014 "),H$=n(W3e,"A",{href:!0});var _Hr=s(H$);kvo=r(_Hr,"CamembertForMaskedLM"),_Hr.forEach(t),Rvo=r(W3e," (CamemBERT model)"),W3e.forEach(t),Svo=i(D),t5=n(D,"LI",{});var Q3e=s(t5);wre=n(Q3e,"STRONG",{});var uHr=s(wre);Pvo=r(uHr,"convbert"),uHr.forEach(t),$vo=r(Q3e," \u2014 "),U$=n(Q3e,"A",{href:!0});var bHr=s(U$);Ivo=r(bHr,"ConvBertForMaskedLM"),bHr.forEach(t),Nvo=r(Q3e," (ConvBERT model)"),Q3e.forEach(t),Dvo=i(D),a5=n(D,"LI",{});var H3e=s(a5);Are=n(H3e,"STRONG",{});var vHr=s(Are);jvo=r(vHr,"data2vec-text"),vHr.forEach(t),qvo=r(H3e," \u2014 "),J$=n(H3e,"A",{href:!0});var THr=s(J$);Gvo=r(THr,"Data2VecTextForMaskedLM"),THr.forEach(t),Ovo=r(H3e," (Data2VecText model)"),H3e.forEach(t),Xvo=i(D),n5=n(D,"LI",{});var U3e=s(n5);Lre=n(U3e,"STRONG",{});var FHr=s(Lre);Vvo=r(FHr,"deberta"),FHr.forEach(t),zvo=r(U3e," \u2014 "),Y$=n(U3e,"A",{href:!0});var CHr=s(Y$);Wvo=r(CHr,"DebertaForMaskedLM"),CHr.forEach(t),Qvo=r(U3e," (DeBERTa model)"),U3e.forEach(t),Hvo=i(D),s5=n(D,"LI",{});var J3e=s(s5);Bre=n(J3e,"STRONG",{});var MHr=s(Bre);Uvo=r(MHr,"deberta-v2"),MHr.forEach(t),Jvo=r(J3e," \u2014 "),K$=n(J3e,"A",{href:!0});var EHr=s(K$);Yvo=r(EHr,"DebertaV2ForMaskedLM"),EHr.forEach(t),Kvo=r(J3e," (DeBERTa-v2 model)"),J3e.forEach(t),Zvo=i(D),l5=n(D,"LI",{});var Y3e=s(l5);xre=n(Y3e,"STRONG",{});var yHr=s(xre);e6o=r(yHr,"distilbert"),yHr.forEach(t),o6o=r(Y3e," \u2014 "),Z$=n(Y3e,"A",{href:!0});var wHr=s(Z$);r6o=r(wHr,"DistilBertForMaskedLM"),wHr.forEach(t),t6o=r(Y3e," (DistilBERT model)"),Y3e.forEach(t),a6o=i(D),i5=n(D,"LI",{});var K3e=s(i5);kre=n(K3e,"STRONG",{});var AHr=s(kre);n6o=r(AHr,"electra"),AHr.forEach(t),s6o=r(K3e," \u2014 "),eI=n(K3e,"A",{href:!0});var LHr=s(eI);l6o=r(LHr,"ElectraForMaskedLM"),LHr.forEach(t),i6o=r(K3e," (ELECTRA model)"),K3e.forEach(t),d6o=i(D),d5=n(D,"LI",{});var Z3e=s(d5);Rre=n(Z3e,"STRONG",{});var BHr=s(Rre);c6o=r(BHr,"flaubert"),BHr.forEach(t),f6o=r(Z3e," \u2014 "),oI=n(Z3e,"A",{href:!0});var xHr=s(oI);m6o=r(xHr,"FlaubertWithLMHeadModel"),xHr.forEach(t),g6o=r(Z3e," (FlauBERT model)"),Z3e.forEach(t),h6o=i(D),c5=n(D,"LI",{});var eye=s(c5);Sre=n(eye,"STRONG",{});var kHr=s(Sre);p6o=r(kHr,"fnet"),kHr.forEach(t),_6o=r(eye," \u2014 "),rI=n(eye,"A",{href:!0});var RHr=s(rI);u6o=r(RHr,"FNetForMaskedLM"),RHr.forEach(t),b6o=r(eye," (FNet model)"),eye.forEach(t),v6o=i(D),f5=n(D,"LI",{});var oye=s(f5);Pre=n(oye,"STRONG",{});var SHr=s(Pre);T6o=r(SHr,"funnel"),SHr.forEach(t),F6o=r(oye," \u2014 "),tI=n(oye,"A",{href:!0});var PHr=s(tI);C6o=r(PHr,"FunnelForMaskedLM"),PHr.forEach(t),M6o=r(oye," (Funnel Transformer model)"),oye.forEach(t),E6o=i(D),m5=n(D,"LI",{});var rye=s(m5);$re=n(rye,"STRONG",{});var $Hr=s($re);y6o=r($Hr,"ibert"),$Hr.forEach(t),w6o=r(rye," \u2014 "),aI=n(rye,"A",{href:!0});var IHr=s(aI);A6o=r(IHr,"IBertForMaskedLM"),IHr.forEach(t),L6o=r(rye," (I-BERT model)"),rye.forEach(t),B6o=i(D),g5=n(D,"LI",{});var tye=s(g5);Ire=n(tye,"STRONG",{});var NHr=s(Ire);x6o=r(NHr,"layoutlm"),NHr.forEach(t),k6o=r(tye," \u2014 "),nI=n(tye,"A",{href:!0});var DHr=s(nI);R6o=r(DHr,"LayoutLMForMaskedLM"),DHr.forEach(t),S6o=r(tye," (LayoutLM model)"),tye.forEach(t),P6o=i(D),h5=n(D,"LI",{});var aye=s(h5);Nre=n(aye,"STRONG",{});var jHr=s(Nre);$6o=r(jHr,"longformer"),jHr.forEach(t),I6o=r(aye," \u2014 "),sI=n(aye,"A",{href:!0});var qHr=s(sI);N6o=r(qHr,"LongformerForMaskedLM"),qHr.forEach(t),D6o=r(aye," (Longformer model)"),aye.forEach(t),j6o=i(D),p5=n(D,"LI",{});var nye=s(p5);Dre=n(nye,"STRONG",{});var GHr=s(Dre);q6o=r(GHr,"mbart"),GHr.forEach(t),G6o=r(nye," \u2014 "),lI=n(nye,"A",{href:!0});var OHr=s(lI);O6o=r(OHr,"MBartForConditionalGeneration"),OHr.forEach(t),X6o=r(nye," (mBART model)"),nye.forEach(t),V6o=i(D),_5=n(D,"LI",{});var sye=s(_5);jre=n(sye,"STRONG",{});var XHr=s(jre);z6o=r(XHr,"megatron-bert"),XHr.forEach(t),W6o=r(sye," \u2014 "),iI=n(sye,"A",{href:!0});var VHr=s(iI);Q6o=r(VHr,"MegatronBertForMaskedLM"),VHr.forEach(t),H6o=r(sye," (MegatronBert model)"),sye.forEach(t),U6o=i(D),u5=n(D,"LI",{});var lye=s(u5);qre=n(lye,"STRONG",{});var zHr=s(qre);J6o=r(zHr,"mobilebert"),zHr.forEach(t),Y6o=r(lye," \u2014 "),dI=n(lye,"A",{href:!0});var WHr=s(dI);K6o=r(WHr,"MobileBertForMaskedLM"),WHr.forEach(t),Z6o=r(lye," (MobileBERT model)"),lye.forEach(t),eTo=i(D),b5=n(D,"LI",{});var iye=s(b5);Gre=n(iye,"STRONG",{});var QHr=s(Gre);oTo=r(QHr,"mpnet"),QHr.forEach(t),rTo=r(iye," \u2014 "),cI=n(iye,"A",{href:!0});var HHr=s(cI);tTo=r(HHr,"MPNetForMaskedLM"),HHr.forEach(t),aTo=r(iye," (MPNet model)"),iye.forEach(t),nTo=i(D),v5=n(D,"LI",{});var dye=s(v5);Ore=n(dye,"STRONG",{});var UHr=s(Ore);sTo=r(UHr,"nystromformer"),UHr.forEach(t),lTo=r(dye," \u2014 "),fI=n(dye,"A",{href:!0});var JHr=s(fI);iTo=r(JHr,"NystromformerForMaskedLM"),JHr.forEach(t),dTo=r(dye," (Nystromformer model)"),dye.forEach(t),cTo=i(D),T5=n(D,"LI",{});var cye=s(T5);Xre=n(cye,"STRONG",{});var YHr=s(Xre);fTo=r(YHr,"perceiver"),YHr.forEach(t),mTo=r(cye," \u2014 "),mI=n(cye,"A",{href:!0});var KHr=s(mI);gTo=r(KHr,"PerceiverForMaskedLM"),KHr.forEach(t),hTo=r(cye," (Perceiver model)"),cye.forEach(t),pTo=i(D),F5=n(D,"LI",{});var fye=s(F5);Vre=n(fye,"STRONG",{});var ZHr=s(Vre);_To=r(ZHr,"qdqbert"),ZHr.forEach(t),uTo=r(fye," \u2014 "),gI=n(fye,"A",{href:!0});var eUr=s(gI);bTo=r(eUr,"QDQBertForMaskedLM"),eUr.forEach(t),vTo=r(fye," (QDQBert model)"),fye.forEach(t),TTo=i(D),C5=n(D,"LI",{});var mye=s(C5);zre=n(mye,"STRONG",{});var oUr=s(zre);FTo=r(oUr,"reformer"),oUr.forEach(t),CTo=r(mye," \u2014 "),hI=n(mye,"A",{href:!0});var rUr=s(hI);MTo=r(rUr,"ReformerForMaskedLM"),rUr.forEach(t),ETo=r(mye," (Reformer model)"),mye.forEach(t),yTo=i(D),M5=n(D,"LI",{});var gye=s(M5);Wre=n(gye,"STRONG",{});var tUr=s(Wre);wTo=r(tUr,"rembert"),tUr.forEach(t),ATo=r(gye," \u2014 "),pI=n(gye,"A",{href:!0});var aUr=s(pI);LTo=r(aUr,"RemBertForMaskedLM"),aUr.forEach(t),BTo=r(gye," (RemBERT model)"),gye.forEach(t),xTo=i(D),E5=n(D,"LI",{});var hye=s(E5);Qre=n(hye,"STRONG",{});var nUr=s(Qre);kTo=r(nUr,"roberta"),nUr.forEach(t),RTo=r(hye," \u2014 "),_I=n(hye,"A",{href:!0});var sUr=s(_I);STo=r(sUr,"RobertaForMaskedLM"),sUr.forEach(t),PTo=r(hye," (RoBERTa model)"),hye.forEach(t),$To=i(D),y5=n(D,"LI",{});var pye=s(y5);Hre=n(pye,"STRONG",{});var lUr=s(Hre);ITo=r(lUr,"roformer"),lUr.forEach(t),NTo=r(pye," \u2014 "),uI=n(pye,"A",{href:!0});var iUr=s(uI);DTo=r(iUr,"RoFormerForMaskedLM"),iUr.forEach(t),jTo=r(pye," (RoFormer model)"),pye.forEach(t),qTo=i(D),w5=n(D,"LI",{});var _ye=s(w5);Ure=n(_ye,"STRONG",{});var dUr=s(Ure);GTo=r(dUr,"squeezebert"),dUr.forEach(t),OTo=r(_ye," \u2014 "),bI=n(_ye,"A",{href:!0});var cUr=s(bI);XTo=r(cUr,"SqueezeBertForMaskedLM"),cUr.forEach(t),VTo=r(_ye," (SqueezeBERT model)"),_ye.forEach(t),zTo=i(D),A5=n(D,"LI",{});var uye=s(A5);Jre=n(uye,"STRONG",{});var fUr=s(Jre);WTo=r(fUr,"tapas"),fUr.forEach(t),QTo=r(uye," \u2014 "),vI=n(uye,"A",{href:!0});var mUr=s(vI);HTo=r(mUr,"TapasForMaskedLM"),mUr.forEach(t),UTo=r(uye," (TAPAS model)"),uye.forEach(t),JTo=i(D),L5=n(D,"LI",{});var bye=s(L5);Yre=n(bye,"STRONG",{});var gUr=s(Yre);YTo=r(gUr,"wav2vec2"),gUr.forEach(t),KTo=r(bye," \u2014 "),Kre=n(bye,"CODE",{});var hUr=s(Kre);ZTo=r(hUr,"Wav2Vec2ForMaskedLM"),hUr.forEach(t),eFo=r(bye,"(Wav2Vec2 model)"),bye.forEach(t),oFo=i(D),B5=n(D,"LI",{});var vye=s(B5);Zre=n(vye,"STRONG",{});var pUr=s(Zre);rFo=r(pUr,"xlm"),pUr.forEach(t),tFo=r(vye," \u2014 "),TI=n(vye,"A",{href:!0});var _Ur=s(TI);aFo=r(_Ur,"XLMWithLMHeadModel"),_Ur.forEach(t),nFo=r(vye," (XLM model)"),vye.forEach(t),sFo=i(D),x5=n(D,"LI",{});var Tye=s(x5);ete=n(Tye,"STRONG",{});var uUr=s(ete);lFo=r(uUr,"xlm-roberta"),uUr.forEach(t),iFo=r(Tye," \u2014 "),FI=n(Tye,"A",{href:!0});var bUr=s(FI);dFo=r(bUr,"XLMRobertaForMaskedLM"),bUr.forEach(t),cFo=r(Tye," (XLM-RoBERTa model)"),Tye.forEach(t),fFo=i(D),k5=n(D,"LI",{});var Fye=s(k5);ote=n(Fye,"STRONG",{});var vUr=s(ote);mFo=r(vUr,"xlm-roberta-xl"),vUr.forEach(t),gFo=r(Fye," \u2014 "),CI=n(Fye,"A",{href:!0});var TUr=s(CI);hFo=r(TUr,"XLMRobertaXLForMaskedLM"),TUr.forEach(t),pFo=r(Fye," (XLM-RoBERTa-XL model)"),Fye.forEach(t),_Fo=i(D),R5=n(D,"LI",{});var Cye=s(R5);rte=n(Cye,"STRONG",{});var FUr=s(rte);uFo=r(FUr,"yoso"),FUr.forEach(t),bFo=r(Cye," \u2014 "),MI=n(Cye,"A",{href:!0});var CUr=s(MI);vFo=r(CUr,"YosoForMaskedLM"),CUr.forEach(t),TFo=r(Cye," (YOSO model)"),Cye.forEach(t),D.forEach(t),FFo=i(Xt),S5=n(Xt,"P",{});var Mye=s(S5);CFo=r(Mye,"The model is set in evaluation mode by default using "),tte=n(Mye,"CODE",{});var MUr=s(tte);MFo=r(MUr,"model.eval()"),MUr.forEach(t),EFo=r(Mye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ate=n(Mye,"CODE",{});var EUr=s(ate);yFo=r(EUr,"model.train()"),EUr.forEach(t),Mye.forEach(t),wFo=i(Xt),nte=n(Xt,"P",{});var yUr=s(nte);AFo=r(yUr,"Examples:"),yUr.forEach(t),LFo=i(Xt),m(hy.$$.fragment,Xt),Xt.forEach(t),Ks.forEach(t),Bke=i(c),id=n(c,"H2",{class:!0});var DSe=s(id);P5=n(DSe,"A",{id:!0,class:!0,href:!0});var wUr=s(P5);ste=n(wUr,"SPAN",{});var AUr=s(ste);m(py.$$.fragment,AUr),AUr.forEach(t),wUr.forEach(t),BFo=i(DSe),lte=n(DSe,"SPAN",{});var LUr=s(lte);xFo=r(LUr,"AutoModelForSeq2SeqLM"),LUr.forEach(t),DSe.forEach(t),xke=i(c),er=n(c,"DIV",{class:!0});var el=s(er);m(_y.$$.fragment,el),kFo=i(el),dd=n(el,"P",{});var lW=s(dd);RFo=r(lW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ite=n(lW,"CODE",{});var BUr=s(ite);SFo=r(BUr,"from_pretrained()"),BUr.forEach(t),PFo=r(lW,"class method or the "),dte=n(lW,"CODE",{});var xUr=s(dte);$Fo=r(xUr,"from_config()"),xUr.forEach(t),IFo=r(lW,`class
method.`),lW.forEach(t),NFo=i(el),uy=n(el,"P",{});var jSe=s(uy);DFo=r(jSe,"This class cannot be instantiated directly using "),cte=n(jSe,"CODE",{});var kUr=s(cte);jFo=r(kUr,"__init__()"),kUr.forEach(t),qFo=r(jSe," (throws an error)."),jSe.forEach(t),GFo=i(el),Hr=n(el,"DIV",{class:!0});var ol=s(Hr);m(by.$$.fragment,ol),OFo=i(ol),fte=n(ol,"P",{});var RUr=s(fte);XFo=r(RUr,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),RUr.forEach(t),VFo=i(ol),cd=n(ol,"P",{});var iW=s(cd);zFo=r(iW,`Note:
Loading a model from its configuration file does `),mte=n(iW,"STRONG",{});var SUr=s(mte);WFo=r(SUr,"not"),SUr.forEach(t),QFo=r(iW,` load the model weights. It only affects the
model\u2019s configuration. Use `),gte=n(iW,"CODE",{});var PUr=s(gte);HFo=r(PUr,"from_pretrained()"),PUr.forEach(t),UFo=r(iW,"to load the model weights."),iW.forEach(t),JFo=i(ol),hte=n(ol,"P",{});var $Ur=s(hte);YFo=r($Ur,"Examples:"),$Ur.forEach(t),KFo=i(ol),m(vy.$$.fragment,ol),ol.forEach(t),ZFo=i(el),Ge=n(el,"DIV",{class:!0});var Vt=s(Ge);m(Ty.$$.fragment,Vt),eCo=i(Vt),pte=n(Vt,"P",{});var IUr=s(pte);oCo=r(IUr,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),IUr.forEach(t),rCo=i(Vt),Ha=n(Vt,"P",{});var pE=s(Ha);tCo=r(pE,"The model class to instantiate is selected based on the "),_te=n(pE,"CODE",{});var NUr=s(_te);aCo=r(NUr,"model_type"),NUr.forEach(t),nCo=r(pE,` property of the config object (either
passed as an argument or loaded from `),ute=n(pE,"CODE",{});var DUr=s(ute);sCo=r(DUr,"pretrained_model_name_or_path"),DUr.forEach(t),lCo=r(pE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bte=n(pE,"CODE",{});var jUr=s(bte);iCo=r(jUr,"pretrained_model_name_or_path"),jUr.forEach(t),dCo=r(pE,":"),pE.forEach(t),cCo=i(Vt),se=n(Vt,"UL",{});var ie=s(se);$5=n(ie,"LI",{});var Eye=s($5);vte=n(Eye,"STRONG",{});var qUr=s(vte);fCo=r(qUr,"bart"),qUr.forEach(t),mCo=r(Eye," \u2014 "),EI=n(Eye,"A",{href:!0});var GUr=s(EI);gCo=r(GUr,"BartForConditionalGeneration"),GUr.forEach(t),hCo=r(Eye," (BART model)"),Eye.forEach(t),pCo=i(ie),I5=n(ie,"LI",{});var yye=s(I5);Tte=n(yye,"STRONG",{});var OUr=s(Tte);_Co=r(OUr,"bigbird_pegasus"),OUr.forEach(t),uCo=r(yye," \u2014 "),yI=n(yye,"A",{href:!0});var XUr=s(yI);bCo=r(XUr,"BigBirdPegasusForConditionalGeneration"),XUr.forEach(t),vCo=r(yye," (BigBirdPegasus model)"),yye.forEach(t),TCo=i(ie),N5=n(ie,"LI",{});var wye=s(N5);Fte=n(wye,"STRONG",{});var VUr=s(Fte);FCo=r(VUr,"blenderbot"),VUr.forEach(t),CCo=r(wye," \u2014 "),wI=n(wye,"A",{href:!0});var zUr=s(wI);MCo=r(zUr,"BlenderbotForConditionalGeneration"),zUr.forEach(t),ECo=r(wye," (Blenderbot model)"),wye.forEach(t),yCo=i(ie),D5=n(ie,"LI",{});var Aye=s(D5);Cte=n(Aye,"STRONG",{});var WUr=s(Cte);wCo=r(WUr,"blenderbot-small"),WUr.forEach(t),ACo=r(Aye," \u2014 "),AI=n(Aye,"A",{href:!0});var QUr=s(AI);LCo=r(QUr,"BlenderbotSmallForConditionalGeneration"),QUr.forEach(t),BCo=r(Aye," (BlenderbotSmall model)"),Aye.forEach(t),xCo=i(ie),j5=n(ie,"LI",{});var Lye=s(j5);Mte=n(Lye,"STRONG",{});var HUr=s(Mte);kCo=r(HUr,"encoder-decoder"),HUr.forEach(t),RCo=r(Lye," \u2014 "),LI=n(Lye,"A",{href:!0});var UUr=s(LI);SCo=r(UUr,"EncoderDecoderModel"),UUr.forEach(t),PCo=r(Lye," (Encoder decoder model)"),Lye.forEach(t),$Co=i(ie),q5=n(ie,"LI",{});var Bye=s(q5);Ete=n(Bye,"STRONG",{});var JUr=s(Ete);ICo=r(JUr,"fsmt"),JUr.forEach(t),NCo=r(Bye," \u2014 "),BI=n(Bye,"A",{href:!0});var YUr=s(BI);DCo=r(YUr,"FSMTForConditionalGeneration"),YUr.forEach(t),jCo=r(Bye," (FairSeq Machine-Translation model)"),Bye.forEach(t),qCo=i(ie),G5=n(ie,"LI",{});var xye=s(G5);yte=n(xye,"STRONG",{});var KUr=s(yte);GCo=r(KUr,"led"),KUr.forEach(t),OCo=r(xye," \u2014 "),xI=n(xye,"A",{href:!0});var ZUr=s(xI);XCo=r(ZUr,"LEDForConditionalGeneration"),ZUr.forEach(t),VCo=r(xye," (LED model)"),xye.forEach(t),zCo=i(ie),O5=n(ie,"LI",{});var kye=s(O5);wte=n(kye,"STRONG",{});var eJr=s(wte);WCo=r(eJr,"m2m_100"),eJr.forEach(t),QCo=r(kye," \u2014 "),kI=n(kye,"A",{href:!0});var oJr=s(kI);HCo=r(oJr,"M2M100ForConditionalGeneration"),oJr.forEach(t),UCo=r(kye," (M2M100 model)"),kye.forEach(t),JCo=i(ie),X5=n(ie,"LI",{});var Rye=s(X5);Ate=n(Rye,"STRONG",{});var rJr=s(Ate);YCo=r(rJr,"marian"),rJr.forEach(t),KCo=r(Rye," \u2014 "),RI=n(Rye,"A",{href:!0});var tJr=s(RI);ZCo=r(tJr,"MarianMTModel"),tJr.forEach(t),eMo=r(Rye," (Marian model)"),Rye.forEach(t),oMo=i(ie),V5=n(ie,"LI",{});var Sye=s(V5);Lte=n(Sye,"STRONG",{});var aJr=s(Lte);rMo=r(aJr,"mbart"),aJr.forEach(t),tMo=r(Sye," \u2014 "),SI=n(Sye,"A",{href:!0});var nJr=s(SI);aMo=r(nJr,"MBartForConditionalGeneration"),nJr.forEach(t),nMo=r(Sye," (mBART model)"),Sye.forEach(t),sMo=i(ie),z5=n(ie,"LI",{});var Pye=s(z5);Bte=n(Pye,"STRONG",{});var sJr=s(Bte);lMo=r(sJr,"mt5"),sJr.forEach(t),iMo=r(Pye," \u2014 "),PI=n(Pye,"A",{href:!0});var lJr=s(PI);dMo=r(lJr,"MT5ForConditionalGeneration"),lJr.forEach(t),cMo=r(Pye," (mT5 model)"),Pye.forEach(t),fMo=i(ie),W5=n(ie,"LI",{});var $ye=s(W5);xte=n($ye,"STRONG",{});var iJr=s(xte);mMo=r(iJr,"pegasus"),iJr.forEach(t),gMo=r($ye," \u2014 "),$I=n($ye,"A",{href:!0});var dJr=s($I);hMo=r(dJr,"PegasusForConditionalGeneration"),dJr.forEach(t),pMo=r($ye," (Pegasus model)"),$ye.forEach(t),_Mo=i(ie),Q5=n(ie,"LI",{});var Iye=s(Q5);kte=n(Iye,"STRONG",{});var cJr=s(kte);uMo=r(cJr,"plbart"),cJr.forEach(t),bMo=r(Iye," \u2014 "),II=n(Iye,"A",{href:!0});var fJr=s(II);vMo=r(fJr,"PLBartForConditionalGeneration"),fJr.forEach(t),TMo=r(Iye," (PLBart model)"),Iye.forEach(t),FMo=i(ie),H5=n(ie,"LI",{});var Nye=s(H5);Rte=n(Nye,"STRONG",{});var mJr=s(Rte);CMo=r(mJr,"prophetnet"),mJr.forEach(t),MMo=r(Nye," \u2014 "),NI=n(Nye,"A",{href:!0});var gJr=s(NI);EMo=r(gJr,"ProphetNetForConditionalGeneration"),gJr.forEach(t),yMo=r(Nye," (ProphetNet model)"),Nye.forEach(t),wMo=i(ie),U5=n(ie,"LI",{});var Dye=s(U5);Ste=n(Dye,"STRONG",{});var hJr=s(Ste);AMo=r(hJr,"t5"),hJr.forEach(t),LMo=r(Dye," \u2014 "),DI=n(Dye,"A",{href:!0});var pJr=s(DI);BMo=r(pJr,"T5ForConditionalGeneration"),pJr.forEach(t),xMo=r(Dye," (T5 model)"),Dye.forEach(t),kMo=i(ie),J5=n(ie,"LI",{});var jye=s(J5);Pte=n(jye,"STRONG",{});var _Jr=s(Pte);RMo=r(_Jr,"xlm-prophetnet"),_Jr.forEach(t),SMo=r(jye," \u2014 "),jI=n(jye,"A",{href:!0});var uJr=s(jI);PMo=r(uJr,"XLMProphetNetForConditionalGeneration"),uJr.forEach(t),$Mo=r(jye," (XLMProphetNet model)"),jye.forEach(t),ie.forEach(t),IMo=i(Vt),Y5=n(Vt,"P",{});var qye=s(Y5);NMo=r(qye,"The model is set in evaluation mode by default using "),$te=n(qye,"CODE",{});var bJr=s($te);DMo=r(bJr,"model.eval()"),bJr.forEach(t),jMo=r(qye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ite=n(qye,"CODE",{});var vJr=s(Ite);qMo=r(vJr,"model.train()"),vJr.forEach(t),qye.forEach(t),GMo=i(Vt),Nte=n(Vt,"P",{});var TJr=s(Nte);OMo=r(TJr,"Examples:"),TJr.forEach(t),XMo=i(Vt),m(Fy.$$.fragment,Vt),Vt.forEach(t),el.forEach(t),kke=i(c),fd=n(c,"H2",{class:!0});var qSe=s(fd);K5=n(qSe,"A",{id:!0,class:!0,href:!0});var FJr=s(K5);Dte=n(FJr,"SPAN",{});var CJr=s(Dte);m(Cy.$$.fragment,CJr),CJr.forEach(t),FJr.forEach(t),VMo=i(qSe),jte=n(qSe,"SPAN",{});var MJr=s(jte);zMo=r(MJr,"AutoModelForSequenceClassification"),MJr.forEach(t),qSe.forEach(t),Rke=i(c),or=n(c,"DIV",{class:!0});var rl=s(or);m(My.$$.fragment,rl),WMo=i(rl),md=n(rl,"P",{});var dW=s(md);QMo=r(dW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qte=n(dW,"CODE",{});var EJr=s(qte);HMo=r(EJr,"from_pretrained()"),EJr.forEach(t),UMo=r(dW,"class method or the "),Gte=n(dW,"CODE",{});var yJr=s(Gte);JMo=r(yJr,"from_config()"),yJr.forEach(t),YMo=r(dW,`class
method.`),dW.forEach(t),KMo=i(rl),Ey=n(rl,"P",{});var GSe=s(Ey);ZMo=r(GSe,"This class cannot be instantiated directly using "),Ote=n(GSe,"CODE",{});var wJr=s(Ote);e4o=r(wJr,"__init__()"),wJr.forEach(t),o4o=r(GSe," (throws an error)."),GSe.forEach(t),r4o=i(rl),Ur=n(rl,"DIV",{class:!0});var tl=s(Ur);m(yy.$$.fragment,tl),t4o=i(tl),Xte=n(tl,"P",{});var AJr=s(Xte);a4o=r(AJr,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),AJr.forEach(t),n4o=i(tl),gd=n(tl,"P",{});var cW=s(gd);s4o=r(cW,`Note:
Loading a model from its configuration file does `),Vte=n(cW,"STRONG",{});var LJr=s(Vte);l4o=r(LJr,"not"),LJr.forEach(t),i4o=r(cW,` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=n(cW,"CODE",{});var BJr=s(zte);d4o=r(BJr,"from_pretrained()"),BJr.forEach(t),c4o=r(cW,"to load the model weights."),cW.forEach(t),f4o=i(tl),Wte=n(tl,"P",{});var xJr=s(Wte);m4o=r(xJr,"Examples:"),xJr.forEach(t),g4o=i(tl),m(wy.$$.fragment,tl),tl.forEach(t),h4o=i(rl),Oe=n(rl,"DIV",{class:!0});var zt=s(Oe);m(Ay.$$.fragment,zt),p4o=i(zt),Qte=n(zt,"P",{});var kJr=s(Qte);_4o=r(kJr,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),kJr.forEach(t),u4o=i(zt),Ua=n(zt,"P",{});var _E=s(Ua);b4o=r(_E,"The model class to instantiate is selected based on the "),Hte=n(_E,"CODE",{});var RJr=s(Hte);v4o=r(RJr,"model_type"),RJr.forEach(t),T4o=r(_E,` property of the config object (either
passed as an argument or loaded from `),Ute=n(_E,"CODE",{});var SJr=s(Ute);F4o=r(SJr,"pretrained_model_name_or_path"),SJr.forEach(t),C4o=r(_E,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jte=n(_E,"CODE",{});var PJr=s(Jte);M4o=r(PJr,"pretrained_model_name_or_path"),PJr.forEach(t),E4o=r(_E,":"),_E.forEach(t),y4o=i(zt),A=n(zt,"UL",{});var L=s(A);Z5=n(L,"LI",{});var Gye=s(Z5);Yte=n(Gye,"STRONG",{});var $Jr=s(Yte);w4o=r($Jr,"albert"),$Jr.forEach(t),A4o=r(Gye," \u2014 "),qI=n(Gye,"A",{href:!0});var IJr=s(qI);L4o=r(IJr,"AlbertForSequenceClassification"),IJr.forEach(t),B4o=r(Gye," (ALBERT model)"),Gye.forEach(t),x4o=i(L),e2=n(L,"LI",{});var Oye=s(e2);Kte=n(Oye,"STRONG",{});var NJr=s(Kte);k4o=r(NJr,"bart"),NJr.forEach(t),R4o=r(Oye," \u2014 "),GI=n(Oye,"A",{href:!0});var DJr=s(GI);S4o=r(DJr,"BartForSequenceClassification"),DJr.forEach(t),P4o=r(Oye," (BART model)"),Oye.forEach(t),$4o=i(L),o2=n(L,"LI",{});var Xye=s(o2);Zte=n(Xye,"STRONG",{});var jJr=s(Zte);I4o=r(jJr,"bert"),jJr.forEach(t),N4o=r(Xye," \u2014 "),OI=n(Xye,"A",{href:!0});var qJr=s(OI);D4o=r(qJr,"BertForSequenceClassification"),qJr.forEach(t),j4o=r(Xye," (BERT model)"),Xye.forEach(t),q4o=i(L),r2=n(L,"LI",{});var Vye=s(r2);eae=n(Vye,"STRONG",{});var GJr=s(eae);G4o=r(GJr,"big_bird"),GJr.forEach(t),O4o=r(Vye," \u2014 "),XI=n(Vye,"A",{href:!0});var OJr=s(XI);X4o=r(OJr,"BigBirdForSequenceClassification"),OJr.forEach(t),V4o=r(Vye," (BigBird model)"),Vye.forEach(t),z4o=i(L),t2=n(L,"LI",{});var zye=s(t2);oae=n(zye,"STRONG",{});var XJr=s(oae);W4o=r(XJr,"bigbird_pegasus"),XJr.forEach(t),Q4o=r(zye," \u2014 "),VI=n(zye,"A",{href:!0});var VJr=s(VI);H4o=r(VJr,"BigBirdPegasusForSequenceClassification"),VJr.forEach(t),U4o=r(zye," (BigBirdPegasus model)"),zye.forEach(t),J4o=i(L),a2=n(L,"LI",{});var Wye=s(a2);rae=n(Wye,"STRONG",{});var zJr=s(rae);Y4o=r(zJr,"camembert"),zJr.forEach(t),K4o=r(Wye," \u2014 "),zI=n(Wye,"A",{href:!0});var WJr=s(zI);Z4o=r(WJr,"CamembertForSequenceClassification"),WJr.forEach(t),eEo=r(Wye," (CamemBERT model)"),Wye.forEach(t),oEo=i(L),n2=n(L,"LI",{});var Qye=s(n2);tae=n(Qye,"STRONG",{});var QJr=s(tae);rEo=r(QJr,"canine"),QJr.forEach(t),tEo=r(Qye," \u2014 "),WI=n(Qye,"A",{href:!0});var HJr=s(WI);aEo=r(HJr,"CanineForSequenceClassification"),HJr.forEach(t),nEo=r(Qye," (Canine model)"),Qye.forEach(t),sEo=i(L),s2=n(L,"LI",{});var Hye=s(s2);aae=n(Hye,"STRONG",{});var UJr=s(aae);lEo=r(UJr,"convbert"),UJr.forEach(t),iEo=r(Hye," \u2014 "),QI=n(Hye,"A",{href:!0});var JJr=s(QI);dEo=r(JJr,"ConvBertForSequenceClassification"),JJr.forEach(t),cEo=r(Hye," (ConvBERT model)"),Hye.forEach(t),fEo=i(L),l2=n(L,"LI",{});var Uye=s(l2);nae=n(Uye,"STRONG",{});var YJr=s(nae);mEo=r(YJr,"ctrl"),YJr.forEach(t),gEo=r(Uye," \u2014 "),HI=n(Uye,"A",{href:!0});var KJr=s(HI);hEo=r(KJr,"CTRLForSequenceClassification"),KJr.forEach(t),pEo=r(Uye," (CTRL model)"),Uye.forEach(t),_Eo=i(L),i2=n(L,"LI",{});var Jye=s(i2);sae=n(Jye,"STRONG",{});var ZJr=s(sae);uEo=r(ZJr,"data2vec-text"),ZJr.forEach(t),bEo=r(Jye," \u2014 "),UI=n(Jye,"A",{href:!0});var eYr=s(UI);vEo=r(eYr,"Data2VecTextForSequenceClassification"),eYr.forEach(t),TEo=r(Jye," (Data2VecText model)"),Jye.forEach(t),FEo=i(L),d2=n(L,"LI",{});var Yye=s(d2);lae=n(Yye,"STRONG",{});var oYr=s(lae);CEo=r(oYr,"deberta"),oYr.forEach(t),MEo=r(Yye," \u2014 "),JI=n(Yye,"A",{href:!0});var rYr=s(JI);EEo=r(rYr,"DebertaForSequenceClassification"),rYr.forEach(t),yEo=r(Yye," (DeBERTa model)"),Yye.forEach(t),wEo=i(L),c2=n(L,"LI",{});var Kye=s(c2);iae=n(Kye,"STRONG",{});var tYr=s(iae);AEo=r(tYr,"deberta-v2"),tYr.forEach(t),LEo=r(Kye," \u2014 "),YI=n(Kye,"A",{href:!0});var aYr=s(YI);BEo=r(aYr,"DebertaV2ForSequenceClassification"),aYr.forEach(t),xEo=r(Kye," (DeBERTa-v2 model)"),Kye.forEach(t),kEo=i(L),f2=n(L,"LI",{});var Zye=s(f2);dae=n(Zye,"STRONG",{});var nYr=s(dae);REo=r(nYr,"distilbert"),nYr.forEach(t),SEo=r(Zye," \u2014 "),KI=n(Zye,"A",{href:!0});var sYr=s(KI);PEo=r(sYr,"DistilBertForSequenceClassification"),sYr.forEach(t),$Eo=r(Zye," (DistilBERT model)"),Zye.forEach(t),IEo=i(L),m2=n(L,"LI",{});var ewe=s(m2);cae=n(ewe,"STRONG",{});var lYr=s(cae);NEo=r(lYr,"electra"),lYr.forEach(t),DEo=r(ewe," \u2014 "),ZI=n(ewe,"A",{href:!0});var iYr=s(ZI);jEo=r(iYr,"ElectraForSequenceClassification"),iYr.forEach(t),qEo=r(ewe," (ELECTRA model)"),ewe.forEach(t),GEo=i(L),g2=n(L,"LI",{});var owe=s(g2);fae=n(owe,"STRONG",{});var dYr=s(fae);OEo=r(dYr,"flaubert"),dYr.forEach(t),XEo=r(owe," \u2014 "),eN=n(owe,"A",{href:!0});var cYr=s(eN);VEo=r(cYr,"FlaubertForSequenceClassification"),cYr.forEach(t),zEo=r(owe," (FlauBERT model)"),owe.forEach(t),WEo=i(L),h2=n(L,"LI",{});var rwe=s(h2);mae=n(rwe,"STRONG",{});var fYr=s(mae);QEo=r(fYr,"fnet"),fYr.forEach(t),HEo=r(rwe," \u2014 "),oN=n(rwe,"A",{href:!0});var mYr=s(oN);UEo=r(mYr,"FNetForSequenceClassification"),mYr.forEach(t),JEo=r(rwe," (FNet model)"),rwe.forEach(t),YEo=i(L),p2=n(L,"LI",{});var twe=s(p2);gae=n(twe,"STRONG",{});var gYr=s(gae);KEo=r(gYr,"funnel"),gYr.forEach(t),ZEo=r(twe," \u2014 "),rN=n(twe,"A",{href:!0});var hYr=s(rN);e3o=r(hYr,"FunnelForSequenceClassification"),hYr.forEach(t),o3o=r(twe," (Funnel Transformer model)"),twe.forEach(t),r3o=i(L),_2=n(L,"LI",{});var awe=s(_2);hae=n(awe,"STRONG",{});var pYr=s(hae);t3o=r(pYr,"gpt2"),pYr.forEach(t),a3o=r(awe," \u2014 "),tN=n(awe,"A",{href:!0});var _Yr=s(tN);n3o=r(_Yr,"GPT2ForSequenceClassification"),_Yr.forEach(t),s3o=r(awe," (OpenAI GPT-2 model)"),awe.forEach(t),l3o=i(L),u2=n(L,"LI",{});var nwe=s(u2);pae=n(nwe,"STRONG",{});var uYr=s(pae);i3o=r(uYr,"gpt_neo"),uYr.forEach(t),d3o=r(nwe," \u2014 "),aN=n(nwe,"A",{href:!0});var bYr=s(aN);c3o=r(bYr,"GPTNeoForSequenceClassification"),bYr.forEach(t),f3o=r(nwe," (GPT Neo model)"),nwe.forEach(t),m3o=i(L),b2=n(L,"LI",{});var swe=s(b2);_ae=n(swe,"STRONG",{});var vYr=s(_ae);g3o=r(vYr,"gptj"),vYr.forEach(t),h3o=r(swe," \u2014 "),nN=n(swe,"A",{href:!0});var TYr=s(nN);p3o=r(TYr,"GPTJForSequenceClassification"),TYr.forEach(t),_3o=r(swe," (GPT-J model)"),swe.forEach(t),u3o=i(L),v2=n(L,"LI",{});var lwe=s(v2);uae=n(lwe,"STRONG",{});var FYr=s(uae);b3o=r(FYr,"ibert"),FYr.forEach(t),v3o=r(lwe," \u2014 "),sN=n(lwe,"A",{href:!0});var CYr=s(sN);T3o=r(CYr,"IBertForSequenceClassification"),CYr.forEach(t),F3o=r(lwe," (I-BERT model)"),lwe.forEach(t),C3o=i(L),T2=n(L,"LI",{});var iwe=s(T2);bae=n(iwe,"STRONG",{});var MYr=s(bae);M3o=r(MYr,"layoutlm"),MYr.forEach(t),E3o=r(iwe," \u2014 "),lN=n(iwe,"A",{href:!0});var EYr=s(lN);y3o=r(EYr,"LayoutLMForSequenceClassification"),EYr.forEach(t),w3o=r(iwe," (LayoutLM model)"),iwe.forEach(t),A3o=i(L),F2=n(L,"LI",{});var dwe=s(F2);vae=n(dwe,"STRONG",{});var yYr=s(vae);L3o=r(yYr,"layoutlmv2"),yYr.forEach(t),B3o=r(dwe," \u2014 "),iN=n(dwe,"A",{href:!0});var wYr=s(iN);x3o=r(wYr,"LayoutLMv2ForSequenceClassification"),wYr.forEach(t),k3o=r(dwe," (LayoutLMv2 model)"),dwe.forEach(t),R3o=i(L),C2=n(L,"LI",{});var cwe=s(C2);Tae=n(cwe,"STRONG",{});var AYr=s(Tae);S3o=r(AYr,"led"),AYr.forEach(t),P3o=r(cwe," \u2014 "),dN=n(cwe,"A",{href:!0});var LYr=s(dN);$3o=r(LYr,"LEDForSequenceClassification"),LYr.forEach(t),I3o=r(cwe," (LED model)"),cwe.forEach(t),N3o=i(L),M2=n(L,"LI",{});var fwe=s(M2);Fae=n(fwe,"STRONG",{});var BYr=s(Fae);D3o=r(BYr,"longformer"),BYr.forEach(t),j3o=r(fwe," \u2014 "),cN=n(fwe,"A",{href:!0});var xYr=s(cN);q3o=r(xYr,"LongformerForSequenceClassification"),xYr.forEach(t),G3o=r(fwe," (Longformer model)"),fwe.forEach(t),O3o=i(L),E2=n(L,"LI",{});var mwe=s(E2);Cae=n(mwe,"STRONG",{});var kYr=s(Cae);X3o=r(kYr,"mbart"),kYr.forEach(t),V3o=r(mwe," \u2014 "),fN=n(mwe,"A",{href:!0});var RYr=s(fN);z3o=r(RYr,"MBartForSequenceClassification"),RYr.forEach(t),W3o=r(mwe," (mBART model)"),mwe.forEach(t),Q3o=i(L),y2=n(L,"LI",{});var gwe=s(y2);Mae=n(gwe,"STRONG",{});var SYr=s(Mae);H3o=r(SYr,"megatron-bert"),SYr.forEach(t),U3o=r(gwe," \u2014 "),mN=n(gwe,"A",{href:!0});var PYr=s(mN);J3o=r(PYr,"MegatronBertForSequenceClassification"),PYr.forEach(t),Y3o=r(gwe," (MegatronBert model)"),gwe.forEach(t),K3o=i(L),w2=n(L,"LI",{});var hwe=s(w2);Eae=n(hwe,"STRONG",{});var $Yr=s(Eae);Z3o=r($Yr,"mobilebert"),$Yr.forEach(t),eyo=r(hwe," \u2014 "),gN=n(hwe,"A",{href:!0});var IYr=s(gN);oyo=r(IYr,"MobileBertForSequenceClassification"),IYr.forEach(t),ryo=r(hwe," (MobileBERT model)"),hwe.forEach(t),tyo=i(L),A2=n(L,"LI",{});var pwe=s(A2);yae=n(pwe,"STRONG",{});var NYr=s(yae);ayo=r(NYr,"mpnet"),NYr.forEach(t),nyo=r(pwe," \u2014 "),hN=n(pwe,"A",{href:!0});var DYr=s(hN);syo=r(DYr,"MPNetForSequenceClassification"),DYr.forEach(t),lyo=r(pwe," (MPNet model)"),pwe.forEach(t),iyo=i(L),L2=n(L,"LI",{});var _we=s(L2);wae=n(_we,"STRONG",{});var jYr=s(wae);dyo=r(jYr,"nystromformer"),jYr.forEach(t),cyo=r(_we," \u2014 "),pN=n(_we,"A",{href:!0});var qYr=s(pN);fyo=r(qYr,"NystromformerForSequenceClassification"),qYr.forEach(t),myo=r(_we," (Nystromformer model)"),_we.forEach(t),gyo=i(L),B2=n(L,"LI",{});var uwe=s(B2);Aae=n(uwe,"STRONG",{});var GYr=s(Aae);hyo=r(GYr,"openai-gpt"),GYr.forEach(t),pyo=r(uwe," \u2014 "),_N=n(uwe,"A",{href:!0});var OYr=s(_N);_yo=r(OYr,"OpenAIGPTForSequenceClassification"),OYr.forEach(t),uyo=r(uwe," (OpenAI GPT model)"),uwe.forEach(t),byo=i(L),x2=n(L,"LI",{});var bwe=s(x2);Lae=n(bwe,"STRONG",{});var XYr=s(Lae);vyo=r(XYr,"perceiver"),XYr.forEach(t),Tyo=r(bwe," \u2014 "),uN=n(bwe,"A",{href:!0});var VYr=s(uN);Fyo=r(VYr,"PerceiverForSequenceClassification"),VYr.forEach(t),Cyo=r(bwe," (Perceiver model)"),bwe.forEach(t),Myo=i(L),k2=n(L,"LI",{});var vwe=s(k2);Bae=n(vwe,"STRONG",{});var zYr=s(Bae);Eyo=r(zYr,"plbart"),zYr.forEach(t),yyo=r(vwe," \u2014 "),bN=n(vwe,"A",{href:!0});var WYr=s(bN);wyo=r(WYr,"PLBartForSequenceClassification"),WYr.forEach(t),Ayo=r(vwe," (PLBart model)"),vwe.forEach(t),Lyo=i(L),R2=n(L,"LI",{});var Twe=s(R2);xae=n(Twe,"STRONG",{});var QYr=s(xae);Byo=r(QYr,"qdqbert"),QYr.forEach(t),xyo=r(Twe," \u2014 "),vN=n(Twe,"A",{href:!0});var HYr=s(vN);kyo=r(HYr,"QDQBertForSequenceClassification"),HYr.forEach(t),Ryo=r(Twe," (QDQBert model)"),Twe.forEach(t),Syo=i(L),S2=n(L,"LI",{});var Fwe=s(S2);kae=n(Fwe,"STRONG",{});var UYr=s(kae);Pyo=r(UYr,"reformer"),UYr.forEach(t),$yo=r(Fwe," \u2014 "),TN=n(Fwe,"A",{href:!0});var JYr=s(TN);Iyo=r(JYr,"ReformerForSequenceClassification"),JYr.forEach(t),Nyo=r(Fwe," (Reformer model)"),Fwe.forEach(t),Dyo=i(L),P2=n(L,"LI",{});var Cwe=s(P2);Rae=n(Cwe,"STRONG",{});var YYr=s(Rae);jyo=r(YYr,"rembert"),YYr.forEach(t),qyo=r(Cwe," \u2014 "),FN=n(Cwe,"A",{href:!0});var KYr=s(FN);Gyo=r(KYr,"RemBertForSequenceClassification"),KYr.forEach(t),Oyo=r(Cwe," (RemBERT model)"),Cwe.forEach(t),Xyo=i(L),$2=n(L,"LI",{});var Mwe=s($2);Sae=n(Mwe,"STRONG",{});var ZYr=s(Sae);Vyo=r(ZYr,"roberta"),ZYr.forEach(t),zyo=r(Mwe," \u2014 "),CN=n(Mwe,"A",{href:!0});var eKr=s(CN);Wyo=r(eKr,"RobertaForSequenceClassification"),eKr.forEach(t),Qyo=r(Mwe," (RoBERTa model)"),Mwe.forEach(t),Hyo=i(L),I2=n(L,"LI",{});var Ewe=s(I2);Pae=n(Ewe,"STRONG",{});var oKr=s(Pae);Uyo=r(oKr,"roformer"),oKr.forEach(t),Jyo=r(Ewe," \u2014 "),MN=n(Ewe,"A",{href:!0});var rKr=s(MN);Yyo=r(rKr,"RoFormerForSequenceClassification"),rKr.forEach(t),Kyo=r(Ewe," (RoFormer model)"),Ewe.forEach(t),Zyo=i(L),N2=n(L,"LI",{});var ywe=s(N2);$ae=n(ywe,"STRONG",{});var tKr=s($ae);ewo=r(tKr,"squeezebert"),tKr.forEach(t),owo=r(ywe," \u2014 "),EN=n(ywe,"A",{href:!0});var aKr=s(EN);rwo=r(aKr,"SqueezeBertForSequenceClassification"),aKr.forEach(t),two=r(ywe," (SqueezeBERT model)"),ywe.forEach(t),awo=i(L),D2=n(L,"LI",{});var wwe=s(D2);Iae=n(wwe,"STRONG",{});var nKr=s(Iae);nwo=r(nKr,"tapas"),nKr.forEach(t),swo=r(wwe," \u2014 "),yN=n(wwe,"A",{href:!0});var sKr=s(yN);lwo=r(sKr,"TapasForSequenceClassification"),sKr.forEach(t),iwo=r(wwe," (TAPAS model)"),wwe.forEach(t),dwo=i(L),j2=n(L,"LI",{});var Awe=s(j2);Nae=n(Awe,"STRONG",{});var lKr=s(Nae);cwo=r(lKr,"transfo-xl"),lKr.forEach(t),fwo=r(Awe," \u2014 "),wN=n(Awe,"A",{href:!0});var iKr=s(wN);mwo=r(iKr,"TransfoXLForSequenceClassification"),iKr.forEach(t),gwo=r(Awe," (Transformer-XL model)"),Awe.forEach(t),hwo=i(L),q2=n(L,"LI",{});var Lwe=s(q2);Dae=n(Lwe,"STRONG",{});var dKr=s(Dae);pwo=r(dKr,"xlm"),dKr.forEach(t),_wo=r(Lwe," \u2014 "),AN=n(Lwe,"A",{href:!0});var cKr=s(AN);uwo=r(cKr,"XLMForSequenceClassification"),cKr.forEach(t),bwo=r(Lwe," (XLM model)"),Lwe.forEach(t),vwo=i(L),G2=n(L,"LI",{});var Bwe=s(G2);jae=n(Bwe,"STRONG",{});var fKr=s(jae);Two=r(fKr,"xlm-roberta"),fKr.forEach(t),Fwo=r(Bwe," \u2014 "),LN=n(Bwe,"A",{href:!0});var mKr=s(LN);Cwo=r(mKr,"XLMRobertaForSequenceClassification"),mKr.forEach(t),Mwo=r(Bwe," (XLM-RoBERTa model)"),Bwe.forEach(t),Ewo=i(L),O2=n(L,"LI",{});var xwe=s(O2);qae=n(xwe,"STRONG",{});var gKr=s(qae);ywo=r(gKr,"xlm-roberta-xl"),gKr.forEach(t),wwo=r(xwe," \u2014 "),BN=n(xwe,"A",{href:!0});var hKr=s(BN);Awo=r(hKr,"XLMRobertaXLForSequenceClassification"),hKr.forEach(t),Lwo=r(xwe," (XLM-RoBERTa-XL model)"),xwe.forEach(t),Bwo=i(L),X2=n(L,"LI",{});var kwe=s(X2);Gae=n(kwe,"STRONG",{});var pKr=s(Gae);xwo=r(pKr,"xlnet"),pKr.forEach(t),kwo=r(kwe," \u2014 "),xN=n(kwe,"A",{href:!0});var _Kr=s(xN);Rwo=r(_Kr,"XLNetForSequenceClassification"),_Kr.forEach(t),Swo=r(kwe," (XLNet model)"),kwe.forEach(t),Pwo=i(L),V2=n(L,"LI",{});var Rwe=s(V2);Oae=n(Rwe,"STRONG",{});var uKr=s(Oae);$wo=r(uKr,"yoso"),uKr.forEach(t),Iwo=r(Rwe," \u2014 "),kN=n(Rwe,"A",{href:!0});var bKr=s(kN);Nwo=r(bKr,"YosoForSequenceClassification"),bKr.forEach(t),Dwo=r(Rwe," (YOSO model)"),Rwe.forEach(t),L.forEach(t),jwo=i(zt),z2=n(zt,"P",{});var Swe=s(z2);qwo=r(Swe,"The model is set in evaluation mode by default using "),Xae=n(Swe,"CODE",{});var vKr=s(Xae);Gwo=r(vKr,"model.eval()"),vKr.forEach(t),Owo=r(Swe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vae=n(Swe,"CODE",{});var TKr=s(Vae);Xwo=r(TKr,"model.train()"),TKr.forEach(t),Swe.forEach(t),Vwo=i(zt),zae=n(zt,"P",{});var FKr=s(zae);zwo=r(FKr,"Examples:"),FKr.forEach(t),Wwo=i(zt),m(Ly.$$.fragment,zt),zt.forEach(t),rl.forEach(t),Ske=i(c),hd=n(c,"H2",{class:!0});var OSe=s(hd);W2=n(OSe,"A",{id:!0,class:!0,href:!0});var CKr=s(W2);Wae=n(CKr,"SPAN",{});var MKr=s(Wae);m(By.$$.fragment,MKr),MKr.forEach(t),CKr.forEach(t),Qwo=i(OSe),Qae=n(OSe,"SPAN",{});var EKr=s(Qae);Hwo=r(EKr,"AutoModelForMultipleChoice"),EKr.forEach(t),OSe.forEach(t),Pke=i(c),rr=n(c,"DIV",{class:!0});var al=s(rr);m(xy.$$.fragment,al),Uwo=i(al),pd=n(al,"P",{});var fW=s(pd);Jwo=r(fW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hae=n(fW,"CODE",{});var yKr=s(Hae);Ywo=r(yKr,"from_pretrained()"),yKr.forEach(t),Kwo=r(fW,"class method or the "),Uae=n(fW,"CODE",{});var wKr=s(Uae);Zwo=r(wKr,"from_config()"),wKr.forEach(t),eAo=r(fW,`class
method.`),fW.forEach(t),oAo=i(al),ky=n(al,"P",{});var XSe=s(ky);rAo=r(XSe,"This class cannot be instantiated directly using "),Jae=n(XSe,"CODE",{});var AKr=s(Jae);tAo=r(AKr,"__init__()"),AKr.forEach(t),aAo=r(XSe," (throws an error)."),XSe.forEach(t),nAo=i(al),Jr=n(al,"DIV",{class:!0});var nl=s(Jr);m(Ry.$$.fragment,nl),sAo=i(nl),Yae=n(nl,"P",{});var LKr=s(Yae);lAo=r(LKr,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),LKr.forEach(t),iAo=i(nl),_d=n(nl,"P",{});var mW=s(_d);dAo=r(mW,`Note:
Loading a model from its configuration file does `),Kae=n(mW,"STRONG",{});var BKr=s(Kae);cAo=r(BKr,"not"),BKr.forEach(t),fAo=r(mW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=n(mW,"CODE",{});var xKr=s(Zae);mAo=r(xKr,"from_pretrained()"),xKr.forEach(t),gAo=r(mW,"to load the model weights."),mW.forEach(t),hAo=i(nl),ene=n(nl,"P",{});var kKr=s(ene);pAo=r(kKr,"Examples:"),kKr.forEach(t),_Ao=i(nl),m(Sy.$$.fragment,nl),nl.forEach(t),uAo=i(al),Xe=n(al,"DIV",{class:!0});var Wt=s(Xe);m(Py.$$.fragment,Wt),bAo=i(Wt),one=n(Wt,"P",{});var RKr=s(one);vAo=r(RKr,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),RKr.forEach(t),TAo=i(Wt),Ja=n(Wt,"P",{});var uE=s(Ja);FAo=r(uE,"The model class to instantiate is selected based on the "),rne=n(uE,"CODE",{});var SKr=s(rne);CAo=r(SKr,"model_type"),SKr.forEach(t),MAo=r(uE,` property of the config object (either
passed as an argument or loaded from `),tne=n(uE,"CODE",{});var PKr=s(tne);EAo=r(PKr,"pretrained_model_name_or_path"),PKr.forEach(t),yAo=r(uE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ane=n(uE,"CODE",{});var $Kr=s(ane);wAo=r($Kr,"pretrained_model_name_or_path"),$Kr.forEach(t),AAo=r(uE,":"),uE.forEach(t),LAo=i(Wt),G=n(Wt,"UL",{});var O=s(G);Q2=n(O,"LI",{});var Pwe=s(Q2);nne=n(Pwe,"STRONG",{});var IKr=s(nne);BAo=r(IKr,"albert"),IKr.forEach(t),xAo=r(Pwe," \u2014 "),RN=n(Pwe,"A",{href:!0});var NKr=s(RN);kAo=r(NKr,"AlbertForMultipleChoice"),NKr.forEach(t),RAo=r(Pwe," (ALBERT model)"),Pwe.forEach(t),SAo=i(O),H2=n(O,"LI",{});var $we=s(H2);sne=n($we,"STRONG",{});var DKr=s(sne);PAo=r(DKr,"bert"),DKr.forEach(t),$Ao=r($we," \u2014 "),SN=n($we,"A",{href:!0});var jKr=s(SN);IAo=r(jKr,"BertForMultipleChoice"),jKr.forEach(t),NAo=r($we," (BERT model)"),$we.forEach(t),DAo=i(O),U2=n(O,"LI",{});var Iwe=s(U2);lne=n(Iwe,"STRONG",{});var qKr=s(lne);jAo=r(qKr,"big_bird"),qKr.forEach(t),qAo=r(Iwe," \u2014 "),PN=n(Iwe,"A",{href:!0});var GKr=s(PN);GAo=r(GKr,"BigBirdForMultipleChoice"),GKr.forEach(t),OAo=r(Iwe," (BigBird model)"),Iwe.forEach(t),XAo=i(O),J2=n(O,"LI",{});var Nwe=s(J2);ine=n(Nwe,"STRONG",{});var OKr=s(ine);VAo=r(OKr,"camembert"),OKr.forEach(t),zAo=r(Nwe," \u2014 "),$N=n(Nwe,"A",{href:!0});var XKr=s($N);WAo=r(XKr,"CamembertForMultipleChoice"),XKr.forEach(t),QAo=r(Nwe," (CamemBERT model)"),Nwe.forEach(t),HAo=i(O),Y2=n(O,"LI",{});var Dwe=s(Y2);dne=n(Dwe,"STRONG",{});var VKr=s(dne);UAo=r(VKr,"canine"),VKr.forEach(t),JAo=r(Dwe," \u2014 "),IN=n(Dwe,"A",{href:!0});var zKr=s(IN);YAo=r(zKr,"CanineForMultipleChoice"),zKr.forEach(t),KAo=r(Dwe," (Canine model)"),Dwe.forEach(t),ZAo=i(O),K2=n(O,"LI",{});var jwe=s(K2);cne=n(jwe,"STRONG",{});var WKr=s(cne);e0o=r(WKr,"convbert"),WKr.forEach(t),o0o=r(jwe," \u2014 "),NN=n(jwe,"A",{href:!0});var QKr=s(NN);r0o=r(QKr,"ConvBertForMultipleChoice"),QKr.forEach(t),t0o=r(jwe," (ConvBERT model)"),jwe.forEach(t),a0o=i(O),Z2=n(O,"LI",{});var qwe=s(Z2);fne=n(qwe,"STRONG",{});var HKr=s(fne);n0o=r(HKr,"data2vec-text"),HKr.forEach(t),s0o=r(qwe," \u2014 "),DN=n(qwe,"A",{href:!0});var UKr=s(DN);l0o=r(UKr,"Data2VecTextForMultipleChoice"),UKr.forEach(t),i0o=r(qwe," (Data2VecText model)"),qwe.forEach(t),d0o=i(O),e1=n(O,"LI",{});var Gwe=s(e1);mne=n(Gwe,"STRONG",{});var JKr=s(mne);c0o=r(JKr,"distilbert"),JKr.forEach(t),f0o=r(Gwe," \u2014 "),jN=n(Gwe,"A",{href:!0});var YKr=s(jN);m0o=r(YKr,"DistilBertForMultipleChoice"),YKr.forEach(t),g0o=r(Gwe," (DistilBERT model)"),Gwe.forEach(t),h0o=i(O),o1=n(O,"LI",{});var Owe=s(o1);gne=n(Owe,"STRONG",{});var KKr=s(gne);p0o=r(KKr,"electra"),KKr.forEach(t),_0o=r(Owe," \u2014 "),qN=n(Owe,"A",{href:!0});var ZKr=s(qN);u0o=r(ZKr,"ElectraForMultipleChoice"),ZKr.forEach(t),b0o=r(Owe," (ELECTRA model)"),Owe.forEach(t),v0o=i(O),r1=n(O,"LI",{});var Xwe=s(r1);hne=n(Xwe,"STRONG",{});var eZr=s(hne);T0o=r(eZr,"flaubert"),eZr.forEach(t),F0o=r(Xwe," \u2014 "),GN=n(Xwe,"A",{href:!0});var oZr=s(GN);C0o=r(oZr,"FlaubertForMultipleChoice"),oZr.forEach(t),M0o=r(Xwe," (FlauBERT model)"),Xwe.forEach(t),E0o=i(O),t1=n(O,"LI",{});var Vwe=s(t1);pne=n(Vwe,"STRONG",{});var rZr=s(pne);y0o=r(rZr,"fnet"),rZr.forEach(t),w0o=r(Vwe," \u2014 "),ON=n(Vwe,"A",{href:!0});var tZr=s(ON);A0o=r(tZr,"FNetForMultipleChoice"),tZr.forEach(t),L0o=r(Vwe," (FNet model)"),Vwe.forEach(t),B0o=i(O),a1=n(O,"LI",{});var zwe=s(a1);_ne=n(zwe,"STRONG",{});var aZr=s(_ne);x0o=r(aZr,"funnel"),aZr.forEach(t),k0o=r(zwe," \u2014 "),XN=n(zwe,"A",{href:!0});var nZr=s(XN);R0o=r(nZr,"FunnelForMultipleChoice"),nZr.forEach(t),S0o=r(zwe," (Funnel Transformer model)"),zwe.forEach(t),P0o=i(O),n1=n(O,"LI",{});var Wwe=s(n1);une=n(Wwe,"STRONG",{});var sZr=s(une);$0o=r(sZr,"ibert"),sZr.forEach(t),I0o=r(Wwe," \u2014 "),VN=n(Wwe,"A",{href:!0});var lZr=s(VN);N0o=r(lZr,"IBertForMultipleChoice"),lZr.forEach(t),D0o=r(Wwe," (I-BERT model)"),Wwe.forEach(t),j0o=i(O),s1=n(O,"LI",{});var Qwe=s(s1);bne=n(Qwe,"STRONG",{});var iZr=s(bne);q0o=r(iZr,"longformer"),iZr.forEach(t),G0o=r(Qwe," \u2014 "),zN=n(Qwe,"A",{href:!0});var dZr=s(zN);O0o=r(dZr,"LongformerForMultipleChoice"),dZr.forEach(t),X0o=r(Qwe," (Longformer model)"),Qwe.forEach(t),V0o=i(O),l1=n(O,"LI",{});var Hwe=s(l1);vne=n(Hwe,"STRONG",{});var cZr=s(vne);z0o=r(cZr,"megatron-bert"),cZr.forEach(t),W0o=r(Hwe," \u2014 "),WN=n(Hwe,"A",{href:!0});var fZr=s(WN);Q0o=r(fZr,"MegatronBertForMultipleChoice"),fZr.forEach(t),H0o=r(Hwe," (MegatronBert model)"),Hwe.forEach(t),U0o=i(O),i1=n(O,"LI",{});var Uwe=s(i1);Tne=n(Uwe,"STRONG",{});var mZr=s(Tne);J0o=r(mZr,"mobilebert"),mZr.forEach(t),Y0o=r(Uwe," \u2014 "),QN=n(Uwe,"A",{href:!0});var gZr=s(QN);K0o=r(gZr,"MobileBertForMultipleChoice"),gZr.forEach(t),Z0o=r(Uwe," (MobileBERT model)"),Uwe.forEach(t),eLo=i(O),d1=n(O,"LI",{});var Jwe=s(d1);Fne=n(Jwe,"STRONG",{});var hZr=s(Fne);oLo=r(hZr,"mpnet"),hZr.forEach(t),rLo=r(Jwe," \u2014 "),HN=n(Jwe,"A",{href:!0});var pZr=s(HN);tLo=r(pZr,"MPNetForMultipleChoice"),pZr.forEach(t),aLo=r(Jwe," (MPNet model)"),Jwe.forEach(t),nLo=i(O),c1=n(O,"LI",{});var Ywe=s(c1);Cne=n(Ywe,"STRONG",{});var _Zr=s(Cne);sLo=r(_Zr,"nystromformer"),_Zr.forEach(t),lLo=r(Ywe," \u2014 "),UN=n(Ywe,"A",{href:!0});var uZr=s(UN);iLo=r(uZr,"NystromformerForMultipleChoice"),uZr.forEach(t),dLo=r(Ywe," (Nystromformer model)"),Ywe.forEach(t),cLo=i(O),f1=n(O,"LI",{});var Kwe=s(f1);Mne=n(Kwe,"STRONG",{});var bZr=s(Mne);fLo=r(bZr,"qdqbert"),bZr.forEach(t),mLo=r(Kwe," \u2014 "),JN=n(Kwe,"A",{href:!0});var vZr=s(JN);gLo=r(vZr,"QDQBertForMultipleChoice"),vZr.forEach(t),hLo=r(Kwe," (QDQBert model)"),Kwe.forEach(t),pLo=i(O),m1=n(O,"LI",{});var Zwe=s(m1);Ene=n(Zwe,"STRONG",{});var TZr=s(Ene);_Lo=r(TZr,"rembert"),TZr.forEach(t),uLo=r(Zwe," \u2014 "),YN=n(Zwe,"A",{href:!0});var FZr=s(YN);bLo=r(FZr,"RemBertForMultipleChoice"),FZr.forEach(t),vLo=r(Zwe," (RemBERT model)"),Zwe.forEach(t),TLo=i(O),g1=n(O,"LI",{});var eAe=s(g1);yne=n(eAe,"STRONG",{});var CZr=s(yne);FLo=r(CZr,"roberta"),CZr.forEach(t),CLo=r(eAe," \u2014 "),KN=n(eAe,"A",{href:!0});var MZr=s(KN);MLo=r(MZr,"RobertaForMultipleChoice"),MZr.forEach(t),ELo=r(eAe," (RoBERTa model)"),eAe.forEach(t),yLo=i(O),h1=n(O,"LI",{});var oAe=s(h1);wne=n(oAe,"STRONG",{});var EZr=s(wne);wLo=r(EZr,"roformer"),EZr.forEach(t),ALo=r(oAe," \u2014 "),ZN=n(oAe,"A",{href:!0});var yZr=s(ZN);LLo=r(yZr,"RoFormerForMultipleChoice"),yZr.forEach(t),BLo=r(oAe," (RoFormer model)"),oAe.forEach(t),xLo=i(O),p1=n(O,"LI",{});var rAe=s(p1);Ane=n(rAe,"STRONG",{});var wZr=s(Ane);kLo=r(wZr,"squeezebert"),wZr.forEach(t),RLo=r(rAe," \u2014 "),eD=n(rAe,"A",{href:!0});var AZr=s(eD);SLo=r(AZr,"SqueezeBertForMultipleChoice"),AZr.forEach(t),PLo=r(rAe," (SqueezeBERT model)"),rAe.forEach(t),$Lo=i(O),_1=n(O,"LI",{});var tAe=s(_1);Lne=n(tAe,"STRONG",{});var LZr=s(Lne);ILo=r(LZr,"xlm"),LZr.forEach(t),NLo=r(tAe," \u2014 "),oD=n(tAe,"A",{href:!0});var BZr=s(oD);DLo=r(BZr,"XLMForMultipleChoice"),BZr.forEach(t),jLo=r(tAe," (XLM model)"),tAe.forEach(t),qLo=i(O),u1=n(O,"LI",{});var aAe=s(u1);Bne=n(aAe,"STRONG",{});var xZr=s(Bne);GLo=r(xZr,"xlm-roberta"),xZr.forEach(t),OLo=r(aAe," \u2014 "),rD=n(aAe,"A",{href:!0});var kZr=s(rD);XLo=r(kZr,"XLMRobertaForMultipleChoice"),kZr.forEach(t),VLo=r(aAe," (XLM-RoBERTa model)"),aAe.forEach(t),zLo=i(O),b1=n(O,"LI",{});var nAe=s(b1);xne=n(nAe,"STRONG",{});var RZr=s(xne);WLo=r(RZr,"xlm-roberta-xl"),RZr.forEach(t),QLo=r(nAe," \u2014 "),tD=n(nAe,"A",{href:!0});var SZr=s(tD);HLo=r(SZr,"XLMRobertaXLForMultipleChoice"),SZr.forEach(t),ULo=r(nAe," (XLM-RoBERTa-XL model)"),nAe.forEach(t),JLo=i(O),v1=n(O,"LI",{});var sAe=s(v1);kne=n(sAe,"STRONG",{});var PZr=s(kne);YLo=r(PZr,"xlnet"),PZr.forEach(t),KLo=r(sAe," \u2014 "),aD=n(sAe,"A",{href:!0});var $Zr=s(aD);ZLo=r($Zr,"XLNetForMultipleChoice"),$Zr.forEach(t),e7o=r(sAe," (XLNet model)"),sAe.forEach(t),o7o=i(O),T1=n(O,"LI",{});var lAe=s(T1);Rne=n(lAe,"STRONG",{});var IZr=s(Rne);r7o=r(IZr,"yoso"),IZr.forEach(t),t7o=r(lAe," \u2014 "),nD=n(lAe,"A",{href:!0});var NZr=s(nD);a7o=r(NZr,"YosoForMultipleChoice"),NZr.forEach(t),n7o=r(lAe," (YOSO model)"),lAe.forEach(t),O.forEach(t),s7o=i(Wt),F1=n(Wt,"P",{});var iAe=s(F1);l7o=r(iAe,"The model is set in evaluation mode by default using "),Sne=n(iAe,"CODE",{});var DZr=s(Sne);i7o=r(DZr,"model.eval()"),DZr.forEach(t),d7o=r(iAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pne=n(iAe,"CODE",{});var jZr=s(Pne);c7o=r(jZr,"model.train()"),jZr.forEach(t),iAe.forEach(t),f7o=i(Wt),$ne=n(Wt,"P",{});var qZr=s($ne);m7o=r(qZr,"Examples:"),qZr.forEach(t),g7o=i(Wt),m($y.$$.fragment,Wt),Wt.forEach(t),al.forEach(t),$ke=i(c),ud=n(c,"H2",{class:!0});var VSe=s(ud);C1=n(VSe,"A",{id:!0,class:!0,href:!0});var GZr=s(C1);Ine=n(GZr,"SPAN",{});var OZr=s(Ine);m(Iy.$$.fragment,OZr),OZr.forEach(t),GZr.forEach(t),h7o=i(VSe),Nne=n(VSe,"SPAN",{});var XZr=s(Nne);p7o=r(XZr,"AutoModelForNextSentencePrediction"),XZr.forEach(t),VSe.forEach(t),Ike=i(c),tr=n(c,"DIV",{class:!0});var sl=s(tr);m(Ny.$$.fragment,sl),_7o=i(sl),bd=n(sl,"P",{});var gW=s(bd);u7o=r(gW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Dne=n(gW,"CODE",{});var VZr=s(Dne);b7o=r(VZr,"from_pretrained()"),VZr.forEach(t),v7o=r(gW,"class method or the "),jne=n(gW,"CODE",{});var zZr=s(jne);T7o=r(zZr,"from_config()"),zZr.forEach(t),F7o=r(gW,`class
method.`),gW.forEach(t),C7o=i(sl),Dy=n(sl,"P",{});var zSe=s(Dy);M7o=r(zSe,"This class cannot be instantiated directly using "),qne=n(zSe,"CODE",{});var WZr=s(qne);E7o=r(WZr,"__init__()"),WZr.forEach(t),y7o=r(zSe," (throws an error)."),zSe.forEach(t),w7o=i(sl),Yr=n(sl,"DIV",{class:!0});var ll=s(Yr);m(jy.$$.fragment,ll),A7o=i(ll),Gne=n(ll,"P",{});var QZr=s(Gne);L7o=r(QZr,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),QZr.forEach(t),B7o=i(ll),vd=n(ll,"P",{});var hW=s(vd);x7o=r(hW,`Note:
Loading a model from its configuration file does `),One=n(hW,"STRONG",{});var HZr=s(One);k7o=r(HZr,"not"),HZr.forEach(t),R7o=r(hW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xne=n(hW,"CODE",{});var UZr=s(Xne);S7o=r(UZr,"from_pretrained()"),UZr.forEach(t),P7o=r(hW,"to load the model weights."),hW.forEach(t),$7o=i(ll),Vne=n(ll,"P",{});var JZr=s(Vne);I7o=r(JZr,"Examples:"),JZr.forEach(t),N7o=i(ll),m(qy.$$.fragment,ll),ll.forEach(t),D7o=i(sl),Ve=n(sl,"DIV",{class:!0});var Qt=s(Ve);m(Gy.$$.fragment,Qt),j7o=i(Qt),zne=n(Qt,"P",{});var YZr=s(zne);q7o=r(YZr,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),YZr.forEach(t),G7o=i(Qt),Ya=n(Qt,"P",{});var bE=s(Ya);O7o=r(bE,"The model class to instantiate is selected based on the "),Wne=n(bE,"CODE",{});var KZr=s(Wne);X7o=r(KZr,"model_type"),KZr.forEach(t),V7o=r(bE,` property of the config object (either
passed as an argument or loaded from `),Qne=n(bE,"CODE",{});var ZZr=s(Qne);z7o=r(ZZr,"pretrained_model_name_or_path"),ZZr.forEach(t),W7o=r(bE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hne=n(bE,"CODE",{});var eet=s(Hne);Q7o=r(eet,"pretrained_model_name_or_path"),eet.forEach(t),H7o=r(bE,":"),bE.forEach(t),U7o=i(Qt),da=n(Qt,"UL",{});var il=s(da);M1=n(il,"LI",{});var dAe=s(M1);Une=n(dAe,"STRONG",{});var oet=s(Une);J7o=r(oet,"bert"),oet.forEach(t),Y7o=r(dAe," \u2014 "),sD=n(dAe,"A",{href:!0});var ret=s(sD);K7o=r(ret,"BertForNextSentencePrediction"),ret.forEach(t),Z7o=r(dAe," (BERT model)"),dAe.forEach(t),e8o=i(il),E1=n(il,"LI",{});var cAe=s(E1);Jne=n(cAe,"STRONG",{});var tet=s(Jne);o8o=r(tet,"fnet"),tet.forEach(t),r8o=r(cAe," \u2014 "),lD=n(cAe,"A",{href:!0});var aet=s(lD);t8o=r(aet,"FNetForNextSentencePrediction"),aet.forEach(t),a8o=r(cAe," (FNet model)"),cAe.forEach(t),n8o=i(il),y1=n(il,"LI",{});var fAe=s(y1);Yne=n(fAe,"STRONG",{});var net=s(Yne);s8o=r(net,"megatron-bert"),net.forEach(t),l8o=r(fAe," \u2014 "),iD=n(fAe,"A",{href:!0});var set=s(iD);i8o=r(set,"MegatronBertForNextSentencePrediction"),set.forEach(t),d8o=r(fAe," (MegatronBert model)"),fAe.forEach(t),c8o=i(il),w1=n(il,"LI",{});var mAe=s(w1);Kne=n(mAe,"STRONG",{});var iet=s(Kne);f8o=r(iet,"mobilebert"),iet.forEach(t),m8o=r(mAe," \u2014 "),dD=n(mAe,"A",{href:!0});var det=s(dD);g8o=r(det,"MobileBertForNextSentencePrediction"),det.forEach(t),h8o=r(mAe," (MobileBERT model)"),mAe.forEach(t),p8o=i(il),A1=n(il,"LI",{});var gAe=s(A1);Zne=n(gAe,"STRONG",{});var cet=s(Zne);_8o=r(cet,"qdqbert"),cet.forEach(t),u8o=r(gAe," \u2014 "),cD=n(gAe,"A",{href:!0});var fet=s(cD);b8o=r(fet,"QDQBertForNextSentencePrediction"),fet.forEach(t),v8o=r(gAe," (QDQBert model)"),gAe.forEach(t),il.forEach(t),T8o=i(Qt),L1=n(Qt,"P",{});var hAe=s(L1);F8o=r(hAe,"The model is set in evaluation mode by default using "),ese=n(hAe,"CODE",{});var met=s(ese);C8o=r(met,"model.eval()"),met.forEach(t),M8o=r(hAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ose=n(hAe,"CODE",{});var get=s(ose);E8o=r(get,"model.train()"),get.forEach(t),hAe.forEach(t),y8o=i(Qt),rse=n(Qt,"P",{});var het=s(rse);w8o=r(het,"Examples:"),het.forEach(t),A8o=i(Qt),m(Oy.$$.fragment,Qt),Qt.forEach(t),sl.forEach(t),Nke=i(c),Td=n(c,"H2",{class:!0});var WSe=s(Td);B1=n(WSe,"A",{id:!0,class:!0,href:!0});var pet=s(B1);tse=n(pet,"SPAN",{});var _et=s(tse);m(Xy.$$.fragment,_et),_et.forEach(t),pet.forEach(t),L8o=i(WSe),ase=n(WSe,"SPAN",{});var uet=s(ase);B8o=r(uet,"AutoModelForTokenClassification"),uet.forEach(t),WSe.forEach(t),Dke=i(c),ar=n(c,"DIV",{class:!0});var dl=s(ar);m(Vy.$$.fragment,dl),x8o=i(dl),Fd=n(dl,"P",{});var pW=s(Fd);k8o=r(pW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),nse=n(pW,"CODE",{});var bet=s(nse);R8o=r(bet,"from_pretrained()"),bet.forEach(t),S8o=r(pW,"class method or the "),sse=n(pW,"CODE",{});var vet=s(sse);P8o=r(vet,"from_config()"),vet.forEach(t),$8o=r(pW,`class
method.`),pW.forEach(t),I8o=i(dl),zy=n(dl,"P",{});var QSe=s(zy);N8o=r(QSe,"This class cannot be instantiated directly using "),lse=n(QSe,"CODE",{});var Tet=s(lse);D8o=r(Tet,"__init__()"),Tet.forEach(t),j8o=r(QSe," (throws an error)."),QSe.forEach(t),q8o=i(dl),Kr=n(dl,"DIV",{class:!0});var cl=s(Kr);m(Wy.$$.fragment,cl),G8o=i(cl),ise=n(cl,"P",{});var Fet=s(ise);O8o=r(Fet,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Fet.forEach(t),X8o=i(cl),Cd=n(cl,"P",{});var _W=s(Cd);V8o=r(_W,`Note:
Loading a model from its configuration file does `),dse=n(_W,"STRONG",{});var Cet=s(dse);z8o=r(Cet,"not"),Cet.forEach(t),W8o=r(_W,` load the model weights. It only affects the
model\u2019s configuration. Use `),cse=n(_W,"CODE",{});var Met=s(cse);Q8o=r(Met,"from_pretrained()"),Met.forEach(t),H8o=r(_W,"to load the model weights."),_W.forEach(t),U8o=i(cl),fse=n(cl,"P",{});var Eet=s(fse);J8o=r(Eet,"Examples:"),Eet.forEach(t),Y8o=i(cl),m(Qy.$$.fragment,cl),cl.forEach(t),K8o=i(dl),ze=n(dl,"DIV",{class:!0});var Ht=s(ze);m(Hy.$$.fragment,Ht),Z8o=i(Ht),mse=n(Ht,"P",{});var yet=s(mse);e9o=r(yet,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),yet.forEach(t),o9o=i(Ht),Ka=n(Ht,"P",{});var vE=s(Ka);r9o=r(vE,"The model class to instantiate is selected based on the "),gse=n(vE,"CODE",{});var wet=s(gse);t9o=r(wet,"model_type"),wet.forEach(t),a9o=r(vE,` property of the config object (either
passed as an argument or loaded from `),hse=n(vE,"CODE",{});var Aet=s(hse);n9o=r(Aet,"pretrained_model_name_or_path"),Aet.forEach(t),s9o=r(vE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pse=n(vE,"CODE",{});var Let=s(pse);l9o=r(Let,"pretrained_model_name_or_path"),Let.forEach(t),i9o=r(vE,":"),vE.forEach(t),d9o=i(Ht),j=n(Ht,"UL",{});var q=s(j);x1=n(q,"LI",{});var pAe=s(x1);_se=n(pAe,"STRONG",{});var Bet=s(_se);c9o=r(Bet,"albert"),Bet.forEach(t),f9o=r(pAe," \u2014 "),fD=n(pAe,"A",{href:!0});var xet=s(fD);m9o=r(xet,"AlbertForTokenClassification"),xet.forEach(t),g9o=r(pAe," (ALBERT model)"),pAe.forEach(t),h9o=i(q),k1=n(q,"LI",{});var _Ae=s(k1);use=n(_Ae,"STRONG",{});var ket=s(use);p9o=r(ket,"bert"),ket.forEach(t),_9o=r(_Ae," \u2014 "),mD=n(_Ae,"A",{href:!0});var Ret=s(mD);u9o=r(Ret,"BertForTokenClassification"),Ret.forEach(t),b9o=r(_Ae," (BERT model)"),_Ae.forEach(t),v9o=i(q),R1=n(q,"LI",{});var uAe=s(R1);bse=n(uAe,"STRONG",{});var Set=s(bse);T9o=r(Set,"big_bird"),Set.forEach(t),F9o=r(uAe," \u2014 "),gD=n(uAe,"A",{href:!0});var Pet=s(gD);C9o=r(Pet,"BigBirdForTokenClassification"),Pet.forEach(t),M9o=r(uAe," (BigBird model)"),uAe.forEach(t),E9o=i(q),S1=n(q,"LI",{});var bAe=s(S1);vse=n(bAe,"STRONG",{});var $et=s(vse);y9o=r($et,"camembert"),$et.forEach(t),w9o=r(bAe," \u2014 "),hD=n(bAe,"A",{href:!0});var Iet=s(hD);A9o=r(Iet,"CamembertForTokenClassification"),Iet.forEach(t),L9o=r(bAe," (CamemBERT model)"),bAe.forEach(t),B9o=i(q),P1=n(q,"LI",{});var vAe=s(P1);Tse=n(vAe,"STRONG",{});var Net=s(Tse);x9o=r(Net,"canine"),Net.forEach(t),k9o=r(vAe," \u2014 "),pD=n(vAe,"A",{href:!0});var Det=s(pD);R9o=r(Det,"CanineForTokenClassification"),Det.forEach(t),S9o=r(vAe," (Canine model)"),vAe.forEach(t),P9o=i(q),$1=n(q,"LI",{});var TAe=s($1);Fse=n(TAe,"STRONG",{});var jet=s(Fse);$9o=r(jet,"convbert"),jet.forEach(t),I9o=r(TAe," \u2014 "),_D=n(TAe,"A",{href:!0});var qet=s(_D);N9o=r(qet,"ConvBertForTokenClassification"),qet.forEach(t),D9o=r(TAe," (ConvBERT model)"),TAe.forEach(t),j9o=i(q),I1=n(q,"LI",{});var FAe=s(I1);Cse=n(FAe,"STRONG",{});var Get=s(Cse);q9o=r(Get,"data2vec-text"),Get.forEach(t),G9o=r(FAe," \u2014 "),uD=n(FAe,"A",{href:!0});var Oet=s(uD);O9o=r(Oet,"Data2VecTextForTokenClassification"),Oet.forEach(t),X9o=r(FAe," (Data2VecText model)"),FAe.forEach(t),V9o=i(q),N1=n(q,"LI",{});var CAe=s(N1);Mse=n(CAe,"STRONG",{});var Xet=s(Mse);z9o=r(Xet,"deberta"),Xet.forEach(t),W9o=r(CAe," \u2014 "),bD=n(CAe,"A",{href:!0});var Vet=s(bD);Q9o=r(Vet,"DebertaForTokenClassification"),Vet.forEach(t),H9o=r(CAe," (DeBERTa model)"),CAe.forEach(t),U9o=i(q),D1=n(q,"LI",{});var MAe=s(D1);Ese=n(MAe,"STRONG",{});var zet=s(Ese);J9o=r(zet,"deberta-v2"),zet.forEach(t),Y9o=r(MAe," \u2014 "),vD=n(MAe,"A",{href:!0});var Wet=s(vD);K9o=r(Wet,"DebertaV2ForTokenClassification"),Wet.forEach(t),Z9o=r(MAe," (DeBERTa-v2 model)"),MAe.forEach(t),eBo=i(q),j1=n(q,"LI",{});var EAe=s(j1);yse=n(EAe,"STRONG",{});var Qet=s(yse);oBo=r(Qet,"distilbert"),Qet.forEach(t),rBo=r(EAe," \u2014 "),TD=n(EAe,"A",{href:!0});var Het=s(TD);tBo=r(Het,"DistilBertForTokenClassification"),Het.forEach(t),aBo=r(EAe," (DistilBERT model)"),EAe.forEach(t),nBo=i(q),q1=n(q,"LI",{});var yAe=s(q1);wse=n(yAe,"STRONG",{});var Uet=s(wse);sBo=r(Uet,"electra"),Uet.forEach(t),lBo=r(yAe," \u2014 "),FD=n(yAe,"A",{href:!0});var Jet=s(FD);iBo=r(Jet,"ElectraForTokenClassification"),Jet.forEach(t),dBo=r(yAe," (ELECTRA model)"),yAe.forEach(t),cBo=i(q),G1=n(q,"LI",{});var wAe=s(G1);Ase=n(wAe,"STRONG",{});var Yet=s(Ase);fBo=r(Yet,"flaubert"),Yet.forEach(t),mBo=r(wAe," \u2014 "),CD=n(wAe,"A",{href:!0});var Ket=s(CD);gBo=r(Ket,"FlaubertForTokenClassification"),Ket.forEach(t),hBo=r(wAe," (FlauBERT model)"),wAe.forEach(t),pBo=i(q),O1=n(q,"LI",{});var AAe=s(O1);Lse=n(AAe,"STRONG",{});var Zet=s(Lse);_Bo=r(Zet,"fnet"),Zet.forEach(t),uBo=r(AAe," \u2014 "),MD=n(AAe,"A",{href:!0});var eot=s(MD);bBo=r(eot,"FNetForTokenClassification"),eot.forEach(t),vBo=r(AAe," (FNet model)"),AAe.forEach(t),TBo=i(q),X1=n(q,"LI",{});var LAe=s(X1);Bse=n(LAe,"STRONG",{});var oot=s(Bse);FBo=r(oot,"funnel"),oot.forEach(t),CBo=r(LAe," \u2014 "),ED=n(LAe,"A",{href:!0});var rot=s(ED);MBo=r(rot,"FunnelForTokenClassification"),rot.forEach(t),EBo=r(LAe," (Funnel Transformer model)"),LAe.forEach(t),yBo=i(q),V1=n(q,"LI",{});var BAe=s(V1);xse=n(BAe,"STRONG",{});var tot=s(xse);wBo=r(tot,"gpt2"),tot.forEach(t),ABo=r(BAe," \u2014 "),yD=n(BAe,"A",{href:!0});var aot=s(yD);LBo=r(aot,"GPT2ForTokenClassification"),aot.forEach(t),BBo=r(BAe," (OpenAI GPT-2 model)"),BAe.forEach(t),xBo=i(q),z1=n(q,"LI",{});var xAe=s(z1);kse=n(xAe,"STRONG",{});var not=s(kse);kBo=r(not,"ibert"),not.forEach(t),RBo=r(xAe," \u2014 "),wD=n(xAe,"A",{href:!0});var sot=s(wD);SBo=r(sot,"IBertForTokenClassification"),sot.forEach(t),PBo=r(xAe," (I-BERT model)"),xAe.forEach(t),$Bo=i(q),W1=n(q,"LI",{});var kAe=s(W1);Rse=n(kAe,"STRONG",{});var lot=s(Rse);IBo=r(lot,"layoutlm"),lot.forEach(t),NBo=r(kAe," \u2014 "),AD=n(kAe,"A",{href:!0});var iot=s(AD);DBo=r(iot,"LayoutLMForTokenClassification"),iot.forEach(t),jBo=r(kAe," (LayoutLM model)"),kAe.forEach(t),qBo=i(q),Q1=n(q,"LI",{});var RAe=s(Q1);Sse=n(RAe,"STRONG",{});var dot=s(Sse);GBo=r(dot,"layoutlmv2"),dot.forEach(t),OBo=r(RAe," \u2014 "),LD=n(RAe,"A",{href:!0});var cot=s(LD);XBo=r(cot,"LayoutLMv2ForTokenClassification"),cot.forEach(t),VBo=r(RAe," (LayoutLMv2 model)"),RAe.forEach(t),zBo=i(q),H1=n(q,"LI",{});var SAe=s(H1);Pse=n(SAe,"STRONG",{});var fot=s(Pse);WBo=r(fot,"longformer"),fot.forEach(t),QBo=r(SAe," \u2014 "),BD=n(SAe,"A",{href:!0});var mot=s(BD);HBo=r(mot,"LongformerForTokenClassification"),mot.forEach(t),UBo=r(SAe," (Longformer model)"),SAe.forEach(t),JBo=i(q),U1=n(q,"LI",{});var PAe=s(U1);$se=n(PAe,"STRONG",{});var got=s($se);YBo=r(got,"megatron-bert"),got.forEach(t),KBo=r(PAe," \u2014 "),xD=n(PAe,"A",{href:!0});var hot=s(xD);ZBo=r(hot,"MegatronBertForTokenClassification"),hot.forEach(t),exo=r(PAe," (MegatronBert model)"),PAe.forEach(t),oxo=i(q),J1=n(q,"LI",{});var $Ae=s(J1);Ise=n($Ae,"STRONG",{});var pot=s(Ise);rxo=r(pot,"mobilebert"),pot.forEach(t),txo=r($Ae," \u2014 "),kD=n($Ae,"A",{href:!0});var _ot=s(kD);axo=r(_ot,"MobileBertForTokenClassification"),_ot.forEach(t),nxo=r($Ae," (MobileBERT model)"),$Ae.forEach(t),sxo=i(q),Y1=n(q,"LI",{});var IAe=s(Y1);Nse=n(IAe,"STRONG",{});var uot=s(Nse);lxo=r(uot,"mpnet"),uot.forEach(t),ixo=r(IAe," \u2014 "),RD=n(IAe,"A",{href:!0});var bot=s(RD);dxo=r(bot,"MPNetForTokenClassification"),bot.forEach(t),cxo=r(IAe," (MPNet model)"),IAe.forEach(t),fxo=i(q),K1=n(q,"LI",{});var NAe=s(K1);Dse=n(NAe,"STRONG",{});var vot=s(Dse);mxo=r(vot,"nystromformer"),vot.forEach(t),gxo=r(NAe," \u2014 "),SD=n(NAe,"A",{href:!0});var Tot=s(SD);hxo=r(Tot,"NystromformerForTokenClassification"),Tot.forEach(t),pxo=r(NAe," (Nystromformer model)"),NAe.forEach(t),_xo=i(q),Z1=n(q,"LI",{});var DAe=s(Z1);jse=n(DAe,"STRONG",{});var Fot=s(jse);uxo=r(Fot,"qdqbert"),Fot.forEach(t),bxo=r(DAe," \u2014 "),PD=n(DAe,"A",{href:!0});var Cot=s(PD);vxo=r(Cot,"QDQBertForTokenClassification"),Cot.forEach(t),Txo=r(DAe," (QDQBert model)"),DAe.forEach(t),Fxo=i(q),eb=n(q,"LI",{});var jAe=s(eb);qse=n(jAe,"STRONG",{});var Mot=s(qse);Cxo=r(Mot,"rembert"),Mot.forEach(t),Mxo=r(jAe," \u2014 "),$D=n(jAe,"A",{href:!0});var Eot=s($D);Exo=r(Eot,"RemBertForTokenClassification"),Eot.forEach(t),yxo=r(jAe," (RemBERT model)"),jAe.forEach(t),wxo=i(q),ob=n(q,"LI",{});var qAe=s(ob);Gse=n(qAe,"STRONG",{});var yot=s(Gse);Axo=r(yot,"roberta"),yot.forEach(t),Lxo=r(qAe," \u2014 "),ID=n(qAe,"A",{href:!0});var wot=s(ID);Bxo=r(wot,"RobertaForTokenClassification"),wot.forEach(t),xxo=r(qAe," (RoBERTa model)"),qAe.forEach(t),kxo=i(q),rb=n(q,"LI",{});var GAe=s(rb);Ose=n(GAe,"STRONG",{});var Aot=s(Ose);Rxo=r(Aot,"roformer"),Aot.forEach(t),Sxo=r(GAe," \u2014 "),ND=n(GAe,"A",{href:!0});var Lot=s(ND);Pxo=r(Lot,"RoFormerForTokenClassification"),Lot.forEach(t),$xo=r(GAe," (RoFormer model)"),GAe.forEach(t),Ixo=i(q),tb=n(q,"LI",{});var OAe=s(tb);Xse=n(OAe,"STRONG",{});var Bot=s(Xse);Nxo=r(Bot,"squeezebert"),Bot.forEach(t),Dxo=r(OAe," \u2014 "),DD=n(OAe,"A",{href:!0});var xot=s(DD);jxo=r(xot,"SqueezeBertForTokenClassification"),xot.forEach(t),qxo=r(OAe," (SqueezeBERT model)"),OAe.forEach(t),Gxo=i(q),ab=n(q,"LI",{});var XAe=s(ab);Vse=n(XAe,"STRONG",{});var kot=s(Vse);Oxo=r(kot,"xlm"),kot.forEach(t),Xxo=r(XAe," \u2014 "),jD=n(XAe,"A",{href:!0});var Rot=s(jD);Vxo=r(Rot,"XLMForTokenClassification"),Rot.forEach(t),zxo=r(XAe," (XLM model)"),XAe.forEach(t),Wxo=i(q),nb=n(q,"LI",{});var VAe=s(nb);zse=n(VAe,"STRONG",{});var Sot=s(zse);Qxo=r(Sot,"xlm-roberta"),Sot.forEach(t),Hxo=r(VAe," \u2014 "),qD=n(VAe,"A",{href:!0});var Pot=s(qD);Uxo=r(Pot,"XLMRobertaForTokenClassification"),Pot.forEach(t),Jxo=r(VAe," (XLM-RoBERTa model)"),VAe.forEach(t),Yxo=i(q),sb=n(q,"LI",{});var zAe=s(sb);Wse=n(zAe,"STRONG",{});var $ot=s(Wse);Kxo=r($ot,"xlm-roberta-xl"),$ot.forEach(t),Zxo=r(zAe," \u2014 "),GD=n(zAe,"A",{href:!0});var Iot=s(GD);eko=r(Iot,"XLMRobertaXLForTokenClassification"),Iot.forEach(t),oko=r(zAe," (XLM-RoBERTa-XL model)"),zAe.forEach(t),rko=i(q),lb=n(q,"LI",{});var WAe=s(lb);Qse=n(WAe,"STRONG",{});var Not=s(Qse);tko=r(Not,"xlnet"),Not.forEach(t),ako=r(WAe," \u2014 "),OD=n(WAe,"A",{href:!0});var Dot=s(OD);nko=r(Dot,"XLNetForTokenClassification"),Dot.forEach(t),sko=r(WAe," (XLNet model)"),WAe.forEach(t),lko=i(q),ib=n(q,"LI",{});var QAe=s(ib);Hse=n(QAe,"STRONG",{});var jot=s(Hse);iko=r(jot,"yoso"),jot.forEach(t),dko=r(QAe," \u2014 "),XD=n(QAe,"A",{href:!0});var qot=s(XD);cko=r(qot,"YosoForTokenClassification"),qot.forEach(t),fko=r(QAe," (YOSO model)"),QAe.forEach(t),q.forEach(t),mko=i(Ht),db=n(Ht,"P",{});var HAe=s(db);gko=r(HAe,"The model is set in evaluation mode by default using "),Use=n(HAe,"CODE",{});var Got=s(Use);hko=r(Got,"model.eval()"),Got.forEach(t),pko=r(HAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jse=n(HAe,"CODE",{});var Oot=s(Jse);_ko=r(Oot,"model.train()"),Oot.forEach(t),HAe.forEach(t),uko=i(Ht),Yse=n(Ht,"P",{});var Xot=s(Yse);bko=r(Xot,"Examples:"),Xot.forEach(t),vko=i(Ht),m(Uy.$$.fragment,Ht),Ht.forEach(t),dl.forEach(t),jke=i(c),Md=n(c,"H2",{class:!0});var HSe=s(Md);cb=n(HSe,"A",{id:!0,class:!0,href:!0});var Vot=s(cb);Kse=n(Vot,"SPAN",{});var zot=s(Kse);m(Jy.$$.fragment,zot),zot.forEach(t),Vot.forEach(t),Tko=i(HSe),Zse=n(HSe,"SPAN",{});var Wot=s(Zse);Fko=r(Wot,"AutoModelForQuestionAnswering"),Wot.forEach(t),HSe.forEach(t),qke=i(c),nr=n(c,"DIV",{class:!0});var fl=s(nr);m(Yy.$$.fragment,fl),Cko=i(fl),Ed=n(fl,"P",{});var uW=s(Ed);Mko=r(uW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ele=n(uW,"CODE",{});var Qot=s(ele);Eko=r(Qot,"from_pretrained()"),Qot.forEach(t),yko=r(uW,"class method or the "),ole=n(uW,"CODE",{});var Hot=s(ole);wko=r(Hot,"from_config()"),Hot.forEach(t),Ako=r(uW,`class
method.`),uW.forEach(t),Lko=i(fl),Ky=n(fl,"P",{});var USe=s(Ky);Bko=r(USe,"This class cannot be instantiated directly using "),rle=n(USe,"CODE",{});var Uot=s(rle);xko=r(Uot,"__init__()"),Uot.forEach(t),kko=r(USe," (throws an error)."),USe.forEach(t),Rko=i(fl),Zr=n(fl,"DIV",{class:!0});var ml=s(Zr);m(Zy.$$.fragment,ml),Sko=i(ml),tle=n(ml,"P",{});var Jot=s(tle);Pko=r(Jot,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Jot.forEach(t),$ko=i(ml),yd=n(ml,"P",{});var bW=s(yd);Iko=r(bW,`Note:
Loading a model from its configuration file does `),ale=n(bW,"STRONG",{});var Yot=s(ale);Nko=r(Yot,"not"),Yot.forEach(t),Dko=r(bW,` load the model weights. It only affects the
model\u2019s configuration. Use `),nle=n(bW,"CODE",{});var Kot=s(nle);jko=r(Kot,"from_pretrained()"),Kot.forEach(t),qko=r(bW,"to load the model weights."),bW.forEach(t),Gko=i(ml),sle=n(ml,"P",{});var Zot=s(sle);Oko=r(Zot,"Examples:"),Zot.forEach(t),Xko=i(ml),m(ew.$$.fragment,ml),ml.forEach(t),Vko=i(fl),We=n(fl,"DIV",{class:!0});var Ut=s(We);m(ow.$$.fragment,Ut),zko=i(Ut),lle=n(Ut,"P",{});var ert=s(lle);Wko=r(ert,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ert.forEach(t),Qko=i(Ut),Za=n(Ut,"P",{});var TE=s(Za);Hko=r(TE,"The model class to instantiate is selected based on the "),ile=n(TE,"CODE",{});var ort=s(ile);Uko=r(ort,"model_type"),ort.forEach(t),Jko=r(TE,` property of the config object (either
passed as an argument or loaded from `),dle=n(TE,"CODE",{});var rrt=s(dle);Yko=r(rrt,"pretrained_model_name_or_path"),rrt.forEach(t),Kko=r(TE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cle=n(TE,"CODE",{});var trt=s(cle);Zko=r(trt,"pretrained_model_name_or_path"),trt.forEach(t),eRo=r(TE,":"),TE.forEach(t),oRo=i(Ut),R=n(Ut,"UL",{});var P=s(R);fb=n(P,"LI",{});var UAe=s(fb);fle=n(UAe,"STRONG",{});var art=s(fle);rRo=r(art,"albert"),art.forEach(t),tRo=r(UAe," \u2014 "),VD=n(UAe,"A",{href:!0});var nrt=s(VD);aRo=r(nrt,"AlbertForQuestionAnswering"),nrt.forEach(t),nRo=r(UAe," (ALBERT model)"),UAe.forEach(t),sRo=i(P),mb=n(P,"LI",{});var JAe=s(mb);mle=n(JAe,"STRONG",{});var srt=s(mle);lRo=r(srt,"bart"),srt.forEach(t),iRo=r(JAe," \u2014 "),zD=n(JAe,"A",{href:!0});var lrt=s(zD);dRo=r(lrt,"BartForQuestionAnswering"),lrt.forEach(t),cRo=r(JAe," (BART model)"),JAe.forEach(t),fRo=i(P),gb=n(P,"LI",{});var YAe=s(gb);gle=n(YAe,"STRONG",{});var irt=s(gle);mRo=r(irt,"bert"),irt.forEach(t),gRo=r(YAe," \u2014 "),WD=n(YAe,"A",{href:!0});var drt=s(WD);hRo=r(drt,"BertForQuestionAnswering"),drt.forEach(t),pRo=r(YAe," (BERT model)"),YAe.forEach(t),_Ro=i(P),hb=n(P,"LI",{});var KAe=s(hb);hle=n(KAe,"STRONG",{});var crt=s(hle);uRo=r(crt,"big_bird"),crt.forEach(t),bRo=r(KAe," \u2014 "),QD=n(KAe,"A",{href:!0});var frt=s(QD);vRo=r(frt,"BigBirdForQuestionAnswering"),frt.forEach(t),TRo=r(KAe," (BigBird model)"),KAe.forEach(t),FRo=i(P),pb=n(P,"LI",{});var ZAe=s(pb);ple=n(ZAe,"STRONG",{});var mrt=s(ple);CRo=r(mrt,"bigbird_pegasus"),mrt.forEach(t),MRo=r(ZAe," \u2014 "),HD=n(ZAe,"A",{href:!0});var grt=s(HD);ERo=r(grt,"BigBirdPegasusForQuestionAnswering"),grt.forEach(t),yRo=r(ZAe," (BigBirdPegasus model)"),ZAe.forEach(t),wRo=i(P),_b=n(P,"LI",{});var e0e=s(_b);_le=n(e0e,"STRONG",{});var hrt=s(_le);ARo=r(hrt,"camembert"),hrt.forEach(t),LRo=r(e0e," \u2014 "),UD=n(e0e,"A",{href:!0});var prt=s(UD);BRo=r(prt,"CamembertForQuestionAnswering"),prt.forEach(t),xRo=r(e0e," (CamemBERT model)"),e0e.forEach(t),kRo=i(P),ub=n(P,"LI",{});var o0e=s(ub);ule=n(o0e,"STRONG",{});var _rt=s(ule);RRo=r(_rt,"canine"),_rt.forEach(t),SRo=r(o0e," \u2014 "),JD=n(o0e,"A",{href:!0});var urt=s(JD);PRo=r(urt,"CanineForQuestionAnswering"),urt.forEach(t),$Ro=r(o0e," (Canine model)"),o0e.forEach(t),IRo=i(P),bb=n(P,"LI",{});var r0e=s(bb);ble=n(r0e,"STRONG",{});var brt=s(ble);NRo=r(brt,"convbert"),brt.forEach(t),DRo=r(r0e," \u2014 "),YD=n(r0e,"A",{href:!0});var vrt=s(YD);jRo=r(vrt,"ConvBertForQuestionAnswering"),vrt.forEach(t),qRo=r(r0e," (ConvBERT model)"),r0e.forEach(t),GRo=i(P),vb=n(P,"LI",{});var t0e=s(vb);vle=n(t0e,"STRONG",{});var Trt=s(vle);ORo=r(Trt,"data2vec-text"),Trt.forEach(t),XRo=r(t0e," \u2014 "),KD=n(t0e,"A",{href:!0});var Frt=s(KD);VRo=r(Frt,"Data2VecTextForQuestionAnswering"),Frt.forEach(t),zRo=r(t0e," (Data2VecText model)"),t0e.forEach(t),WRo=i(P),Tb=n(P,"LI",{});var a0e=s(Tb);Tle=n(a0e,"STRONG",{});var Crt=s(Tle);QRo=r(Crt,"deberta"),Crt.forEach(t),HRo=r(a0e," \u2014 "),ZD=n(a0e,"A",{href:!0});var Mrt=s(ZD);URo=r(Mrt,"DebertaForQuestionAnswering"),Mrt.forEach(t),JRo=r(a0e," (DeBERTa model)"),a0e.forEach(t),YRo=i(P),Fb=n(P,"LI",{});var n0e=s(Fb);Fle=n(n0e,"STRONG",{});var Ert=s(Fle);KRo=r(Ert,"deberta-v2"),Ert.forEach(t),ZRo=r(n0e," \u2014 "),ej=n(n0e,"A",{href:!0});var yrt=s(ej);eSo=r(yrt,"DebertaV2ForQuestionAnswering"),yrt.forEach(t),oSo=r(n0e," (DeBERTa-v2 model)"),n0e.forEach(t),rSo=i(P),Cb=n(P,"LI",{});var s0e=s(Cb);Cle=n(s0e,"STRONG",{});var wrt=s(Cle);tSo=r(wrt,"distilbert"),wrt.forEach(t),aSo=r(s0e," \u2014 "),oj=n(s0e,"A",{href:!0});var Art=s(oj);nSo=r(Art,"DistilBertForQuestionAnswering"),Art.forEach(t),sSo=r(s0e," (DistilBERT model)"),s0e.forEach(t),lSo=i(P),Mb=n(P,"LI",{});var l0e=s(Mb);Mle=n(l0e,"STRONG",{});var Lrt=s(Mle);iSo=r(Lrt,"electra"),Lrt.forEach(t),dSo=r(l0e," \u2014 "),rj=n(l0e,"A",{href:!0});var Brt=s(rj);cSo=r(Brt,"ElectraForQuestionAnswering"),Brt.forEach(t),fSo=r(l0e," (ELECTRA model)"),l0e.forEach(t),mSo=i(P),Eb=n(P,"LI",{});var i0e=s(Eb);Ele=n(i0e,"STRONG",{});var xrt=s(Ele);gSo=r(xrt,"flaubert"),xrt.forEach(t),hSo=r(i0e," \u2014 "),tj=n(i0e,"A",{href:!0});var krt=s(tj);pSo=r(krt,"FlaubertForQuestionAnsweringSimple"),krt.forEach(t),_So=r(i0e," (FlauBERT model)"),i0e.forEach(t),uSo=i(P),yb=n(P,"LI",{});var d0e=s(yb);yle=n(d0e,"STRONG",{});var Rrt=s(yle);bSo=r(Rrt,"fnet"),Rrt.forEach(t),vSo=r(d0e," \u2014 "),aj=n(d0e,"A",{href:!0});var Srt=s(aj);TSo=r(Srt,"FNetForQuestionAnswering"),Srt.forEach(t),FSo=r(d0e," (FNet model)"),d0e.forEach(t),CSo=i(P),wb=n(P,"LI",{});var c0e=s(wb);wle=n(c0e,"STRONG",{});var Prt=s(wle);MSo=r(Prt,"funnel"),Prt.forEach(t),ESo=r(c0e," \u2014 "),nj=n(c0e,"A",{href:!0});var $rt=s(nj);ySo=r($rt,"FunnelForQuestionAnswering"),$rt.forEach(t),wSo=r(c0e," (Funnel Transformer model)"),c0e.forEach(t),ASo=i(P),Ab=n(P,"LI",{});var f0e=s(Ab);Ale=n(f0e,"STRONG",{});var Irt=s(Ale);LSo=r(Irt,"gptj"),Irt.forEach(t),BSo=r(f0e," \u2014 "),sj=n(f0e,"A",{href:!0});var Nrt=s(sj);xSo=r(Nrt,"GPTJForQuestionAnswering"),Nrt.forEach(t),kSo=r(f0e," (GPT-J model)"),f0e.forEach(t),RSo=i(P),Lb=n(P,"LI",{});var m0e=s(Lb);Lle=n(m0e,"STRONG",{});var Drt=s(Lle);SSo=r(Drt,"ibert"),Drt.forEach(t),PSo=r(m0e," \u2014 "),lj=n(m0e,"A",{href:!0});var jrt=s(lj);$So=r(jrt,"IBertForQuestionAnswering"),jrt.forEach(t),ISo=r(m0e," (I-BERT model)"),m0e.forEach(t),NSo=i(P),Bb=n(P,"LI",{});var g0e=s(Bb);Ble=n(g0e,"STRONG",{});var qrt=s(Ble);DSo=r(qrt,"layoutlmv2"),qrt.forEach(t),jSo=r(g0e," \u2014 "),ij=n(g0e,"A",{href:!0});var Grt=s(ij);qSo=r(Grt,"LayoutLMv2ForQuestionAnswering"),Grt.forEach(t),GSo=r(g0e," (LayoutLMv2 model)"),g0e.forEach(t),OSo=i(P),xb=n(P,"LI",{});var h0e=s(xb);xle=n(h0e,"STRONG",{});var Ort=s(xle);XSo=r(Ort,"led"),Ort.forEach(t),VSo=r(h0e," \u2014 "),dj=n(h0e,"A",{href:!0});var Xrt=s(dj);zSo=r(Xrt,"LEDForQuestionAnswering"),Xrt.forEach(t),WSo=r(h0e," (LED model)"),h0e.forEach(t),QSo=i(P),kb=n(P,"LI",{});var p0e=s(kb);kle=n(p0e,"STRONG",{});var Vrt=s(kle);HSo=r(Vrt,"longformer"),Vrt.forEach(t),USo=r(p0e," \u2014 "),cj=n(p0e,"A",{href:!0});var zrt=s(cj);JSo=r(zrt,"LongformerForQuestionAnswering"),zrt.forEach(t),YSo=r(p0e," (Longformer model)"),p0e.forEach(t),KSo=i(P),Rb=n(P,"LI",{});var _0e=s(Rb);Rle=n(_0e,"STRONG",{});var Wrt=s(Rle);ZSo=r(Wrt,"lxmert"),Wrt.forEach(t),ePo=r(_0e," \u2014 "),fj=n(_0e,"A",{href:!0});var Qrt=s(fj);oPo=r(Qrt,"LxmertForQuestionAnswering"),Qrt.forEach(t),rPo=r(_0e," (LXMERT model)"),_0e.forEach(t),tPo=i(P),Sb=n(P,"LI",{});var u0e=s(Sb);Sle=n(u0e,"STRONG",{});var Hrt=s(Sle);aPo=r(Hrt,"mbart"),Hrt.forEach(t),nPo=r(u0e," \u2014 "),mj=n(u0e,"A",{href:!0});var Urt=s(mj);sPo=r(Urt,"MBartForQuestionAnswering"),Urt.forEach(t),lPo=r(u0e," (mBART model)"),u0e.forEach(t),iPo=i(P),Pb=n(P,"LI",{});var b0e=s(Pb);Ple=n(b0e,"STRONG",{});var Jrt=s(Ple);dPo=r(Jrt,"megatron-bert"),Jrt.forEach(t),cPo=r(b0e," \u2014 "),gj=n(b0e,"A",{href:!0});var Yrt=s(gj);fPo=r(Yrt,"MegatronBertForQuestionAnswering"),Yrt.forEach(t),mPo=r(b0e," (MegatronBert model)"),b0e.forEach(t),gPo=i(P),$b=n(P,"LI",{});var v0e=s($b);$le=n(v0e,"STRONG",{});var Krt=s($le);hPo=r(Krt,"mobilebert"),Krt.forEach(t),pPo=r(v0e," \u2014 "),hj=n(v0e,"A",{href:!0});var Zrt=s(hj);_Po=r(Zrt,"MobileBertForQuestionAnswering"),Zrt.forEach(t),uPo=r(v0e," (MobileBERT model)"),v0e.forEach(t),bPo=i(P),Ib=n(P,"LI",{});var T0e=s(Ib);Ile=n(T0e,"STRONG",{});var ett=s(Ile);vPo=r(ett,"mpnet"),ett.forEach(t),TPo=r(T0e," \u2014 "),pj=n(T0e,"A",{href:!0});var ott=s(pj);FPo=r(ott,"MPNetForQuestionAnswering"),ott.forEach(t),CPo=r(T0e," (MPNet model)"),T0e.forEach(t),MPo=i(P),Nb=n(P,"LI",{});var F0e=s(Nb);Nle=n(F0e,"STRONG",{});var rtt=s(Nle);EPo=r(rtt,"nystromformer"),rtt.forEach(t),yPo=r(F0e," \u2014 "),_j=n(F0e,"A",{href:!0});var ttt=s(_j);wPo=r(ttt,"NystromformerForQuestionAnswering"),ttt.forEach(t),APo=r(F0e," (Nystromformer model)"),F0e.forEach(t),LPo=i(P),Db=n(P,"LI",{});var C0e=s(Db);Dle=n(C0e,"STRONG",{});var att=s(Dle);BPo=r(att,"qdqbert"),att.forEach(t),xPo=r(C0e," \u2014 "),uj=n(C0e,"A",{href:!0});var ntt=s(uj);kPo=r(ntt,"QDQBertForQuestionAnswering"),ntt.forEach(t),RPo=r(C0e," (QDQBert model)"),C0e.forEach(t),SPo=i(P),jb=n(P,"LI",{});var M0e=s(jb);jle=n(M0e,"STRONG",{});var stt=s(jle);PPo=r(stt,"reformer"),stt.forEach(t),$Po=r(M0e," \u2014 "),bj=n(M0e,"A",{href:!0});var ltt=s(bj);IPo=r(ltt,"ReformerForQuestionAnswering"),ltt.forEach(t),NPo=r(M0e," (Reformer model)"),M0e.forEach(t),DPo=i(P),qb=n(P,"LI",{});var E0e=s(qb);qle=n(E0e,"STRONG",{});var itt=s(qle);jPo=r(itt,"rembert"),itt.forEach(t),qPo=r(E0e," \u2014 "),vj=n(E0e,"A",{href:!0});var dtt=s(vj);GPo=r(dtt,"RemBertForQuestionAnswering"),dtt.forEach(t),OPo=r(E0e," (RemBERT model)"),E0e.forEach(t),XPo=i(P),Gb=n(P,"LI",{});var y0e=s(Gb);Gle=n(y0e,"STRONG",{});var ctt=s(Gle);VPo=r(ctt,"roberta"),ctt.forEach(t),zPo=r(y0e," \u2014 "),Tj=n(y0e,"A",{href:!0});var ftt=s(Tj);WPo=r(ftt,"RobertaForQuestionAnswering"),ftt.forEach(t),QPo=r(y0e," (RoBERTa model)"),y0e.forEach(t),HPo=i(P),Ob=n(P,"LI",{});var w0e=s(Ob);Ole=n(w0e,"STRONG",{});var mtt=s(Ole);UPo=r(mtt,"roformer"),mtt.forEach(t),JPo=r(w0e," \u2014 "),Fj=n(w0e,"A",{href:!0});var gtt=s(Fj);YPo=r(gtt,"RoFormerForQuestionAnswering"),gtt.forEach(t),KPo=r(w0e," (RoFormer model)"),w0e.forEach(t),ZPo=i(P),Xb=n(P,"LI",{});var A0e=s(Xb);Xle=n(A0e,"STRONG",{});var htt=s(Xle);e$o=r(htt,"splinter"),htt.forEach(t),o$o=r(A0e," \u2014 "),Cj=n(A0e,"A",{href:!0});var ptt=s(Cj);r$o=r(ptt,"SplinterForQuestionAnswering"),ptt.forEach(t),t$o=r(A0e," (Splinter model)"),A0e.forEach(t),a$o=i(P),Vb=n(P,"LI",{});var L0e=s(Vb);Vle=n(L0e,"STRONG",{});var _tt=s(Vle);n$o=r(_tt,"squeezebert"),_tt.forEach(t),s$o=r(L0e," \u2014 "),Mj=n(L0e,"A",{href:!0});var utt=s(Mj);l$o=r(utt,"SqueezeBertForQuestionAnswering"),utt.forEach(t),i$o=r(L0e," (SqueezeBERT model)"),L0e.forEach(t),d$o=i(P),zb=n(P,"LI",{});var B0e=s(zb);zle=n(B0e,"STRONG",{});var btt=s(zle);c$o=r(btt,"xlm"),btt.forEach(t),f$o=r(B0e," \u2014 "),Ej=n(B0e,"A",{href:!0});var vtt=s(Ej);m$o=r(vtt,"XLMForQuestionAnsweringSimple"),vtt.forEach(t),g$o=r(B0e," (XLM model)"),B0e.forEach(t),h$o=i(P),Wb=n(P,"LI",{});var x0e=s(Wb);Wle=n(x0e,"STRONG",{});var Ttt=s(Wle);p$o=r(Ttt,"xlm-roberta"),Ttt.forEach(t),_$o=r(x0e," \u2014 "),yj=n(x0e,"A",{href:!0});var Ftt=s(yj);u$o=r(Ftt,"XLMRobertaForQuestionAnswering"),Ftt.forEach(t),b$o=r(x0e," (XLM-RoBERTa model)"),x0e.forEach(t),v$o=i(P),Qb=n(P,"LI",{});var k0e=s(Qb);Qle=n(k0e,"STRONG",{});var Ctt=s(Qle);T$o=r(Ctt,"xlm-roberta-xl"),Ctt.forEach(t),F$o=r(k0e," \u2014 "),wj=n(k0e,"A",{href:!0});var Mtt=s(wj);C$o=r(Mtt,"XLMRobertaXLForQuestionAnswering"),Mtt.forEach(t),M$o=r(k0e," (XLM-RoBERTa-XL model)"),k0e.forEach(t),E$o=i(P),Hb=n(P,"LI",{});var R0e=s(Hb);Hle=n(R0e,"STRONG",{});var Ett=s(Hle);y$o=r(Ett,"xlnet"),Ett.forEach(t),w$o=r(R0e," \u2014 "),Aj=n(R0e,"A",{href:!0});var ytt=s(Aj);A$o=r(ytt,"XLNetForQuestionAnsweringSimple"),ytt.forEach(t),L$o=r(R0e," (XLNet model)"),R0e.forEach(t),B$o=i(P),Ub=n(P,"LI",{});var S0e=s(Ub);Ule=n(S0e,"STRONG",{});var wtt=s(Ule);x$o=r(wtt,"yoso"),wtt.forEach(t),k$o=r(S0e," \u2014 "),Lj=n(S0e,"A",{href:!0});var Att=s(Lj);R$o=r(Att,"YosoForQuestionAnswering"),Att.forEach(t),S$o=r(S0e," (YOSO model)"),S0e.forEach(t),P.forEach(t),P$o=i(Ut),Jb=n(Ut,"P",{});var P0e=s(Jb);$$o=r(P0e,"The model is set in evaluation mode by default using "),Jle=n(P0e,"CODE",{});var Ltt=s(Jle);I$o=r(Ltt,"model.eval()"),Ltt.forEach(t),N$o=r(P0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yle=n(P0e,"CODE",{});var Btt=s(Yle);D$o=r(Btt,"model.train()"),Btt.forEach(t),P0e.forEach(t),j$o=i(Ut),Kle=n(Ut,"P",{});var xtt=s(Kle);q$o=r(xtt,"Examples:"),xtt.forEach(t),G$o=i(Ut),m(rw.$$.fragment,Ut),Ut.forEach(t),fl.forEach(t),Gke=i(c),wd=n(c,"H2",{class:!0});var JSe=s(wd);Yb=n(JSe,"A",{id:!0,class:!0,href:!0});var ktt=s(Yb);Zle=n(ktt,"SPAN",{});var Rtt=s(Zle);m(tw.$$.fragment,Rtt),Rtt.forEach(t),ktt.forEach(t),O$o=i(JSe),eie=n(JSe,"SPAN",{});var Stt=s(eie);X$o=r(Stt,"AutoModelForTableQuestionAnswering"),Stt.forEach(t),JSe.forEach(t),Oke=i(c),sr=n(c,"DIV",{class:!0});var gl=s(sr);m(aw.$$.fragment,gl),V$o=i(gl),Ad=n(gl,"P",{});var vW=s(Ad);z$o=r(vW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),oie=n(vW,"CODE",{});var Ptt=s(oie);W$o=r(Ptt,"from_pretrained()"),Ptt.forEach(t),Q$o=r(vW,"class method or the "),rie=n(vW,"CODE",{});var $tt=s(rie);H$o=r($tt,"from_config()"),$tt.forEach(t),U$o=r(vW,`class
method.`),vW.forEach(t),J$o=i(gl),nw=n(gl,"P",{});var YSe=s(nw);Y$o=r(YSe,"This class cannot be instantiated directly using "),tie=n(YSe,"CODE",{});var Itt=s(tie);K$o=r(Itt,"__init__()"),Itt.forEach(t),Z$o=r(YSe," (throws an error)."),YSe.forEach(t),eIo=i(gl),et=n(gl,"DIV",{class:!0});var hl=s(et);m(sw.$$.fragment,hl),oIo=i(hl),aie=n(hl,"P",{});var Ntt=s(aie);rIo=r(Ntt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Ntt.forEach(t),tIo=i(hl),Ld=n(hl,"P",{});var TW=s(Ld);aIo=r(TW,`Note:
Loading a model from its configuration file does `),nie=n(TW,"STRONG",{});var Dtt=s(nie);nIo=r(Dtt,"not"),Dtt.forEach(t),sIo=r(TW,` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=n(TW,"CODE",{});var jtt=s(sie);lIo=r(jtt,"from_pretrained()"),jtt.forEach(t),iIo=r(TW,"to load the model weights."),TW.forEach(t),dIo=i(hl),lie=n(hl,"P",{});var qtt=s(lie);cIo=r(qtt,"Examples:"),qtt.forEach(t),fIo=i(hl),m(lw.$$.fragment,hl),hl.forEach(t),mIo=i(gl),Qe=n(gl,"DIV",{class:!0});var Jt=s(Qe);m(iw.$$.fragment,Jt),gIo=i(Jt),iie=n(Jt,"P",{});var Gtt=s(iie);hIo=r(Gtt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Gtt.forEach(t),pIo=i(Jt),en=n(Jt,"P",{});var FE=s(en);_Io=r(FE,"The model class to instantiate is selected based on the "),die=n(FE,"CODE",{});var Ott=s(die);uIo=r(Ott,"model_type"),Ott.forEach(t),bIo=r(FE,` property of the config object (either
passed as an argument or loaded from `),cie=n(FE,"CODE",{});var Xtt=s(cie);vIo=r(Xtt,"pretrained_model_name_or_path"),Xtt.forEach(t),TIo=r(FE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fie=n(FE,"CODE",{});var Vtt=s(fie);FIo=r(Vtt,"pretrained_model_name_or_path"),Vtt.forEach(t),CIo=r(FE,":"),FE.forEach(t),MIo=i(Jt),mie=n(Jt,"UL",{});var ztt=s(mie);Kb=n(ztt,"LI",{});var $0e=s(Kb);gie=n($0e,"STRONG",{});var Wtt=s(gie);EIo=r(Wtt,"tapas"),Wtt.forEach(t),yIo=r($0e," \u2014 "),Bj=n($0e,"A",{href:!0});var Qtt=s(Bj);wIo=r(Qtt,"TapasForQuestionAnswering"),Qtt.forEach(t),AIo=r($0e," (TAPAS model)"),$0e.forEach(t),ztt.forEach(t),LIo=i(Jt),Zb=n(Jt,"P",{});var I0e=s(Zb);BIo=r(I0e,"The model is set in evaluation mode by default using "),hie=n(I0e,"CODE",{});var Htt=s(hie);xIo=r(Htt,"model.eval()"),Htt.forEach(t),kIo=r(I0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pie=n(I0e,"CODE",{});var Utt=s(pie);RIo=r(Utt,"model.train()"),Utt.forEach(t),I0e.forEach(t),SIo=i(Jt),_ie=n(Jt,"P",{});var Jtt=s(_ie);PIo=r(Jtt,"Examples:"),Jtt.forEach(t),$Io=i(Jt),m(dw.$$.fragment,Jt),Jt.forEach(t),gl.forEach(t),Xke=i(c),Bd=n(c,"H2",{class:!0});var KSe=s(Bd);ev=n(KSe,"A",{id:!0,class:!0,href:!0});var Ytt=s(ev);uie=n(Ytt,"SPAN",{});var Ktt=s(uie);m(cw.$$.fragment,Ktt),Ktt.forEach(t),Ytt.forEach(t),IIo=i(KSe),bie=n(KSe,"SPAN",{});var Ztt=s(bie);NIo=r(Ztt,"AutoModelForImageClassification"),Ztt.forEach(t),KSe.forEach(t),Vke=i(c),lr=n(c,"DIV",{class:!0});var pl=s(lr);m(fw.$$.fragment,pl),DIo=i(pl),xd=n(pl,"P",{});var FW=s(xd);jIo=r(FW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),vie=n(FW,"CODE",{});var eat=s(vie);qIo=r(eat,"from_pretrained()"),eat.forEach(t),GIo=r(FW,"class method or the "),Tie=n(FW,"CODE",{});var oat=s(Tie);OIo=r(oat,"from_config()"),oat.forEach(t),XIo=r(FW,`class
method.`),FW.forEach(t),VIo=i(pl),mw=n(pl,"P",{});var ZSe=s(mw);zIo=r(ZSe,"This class cannot be instantiated directly using "),Fie=n(ZSe,"CODE",{});var rat=s(Fie);WIo=r(rat,"__init__()"),rat.forEach(t),QIo=r(ZSe," (throws an error)."),ZSe.forEach(t),HIo=i(pl),ot=n(pl,"DIV",{class:!0});var _l=s(ot);m(gw.$$.fragment,_l),UIo=i(_l),Cie=n(_l,"P",{});var tat=s(Cie);JIo=r(tat,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),tat.forEach(t),YIo=i(_l),kd=n(_l,"P",{});var CW=s(kd);KIo=r(CW,`Note:
Loading a model from its configuration file does `),Mie=n(CW,"STRONG",{});var aat=s(Mie);ZIo=r(aat,"not"),aat.forEach(t),eNo=r(CW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eie=n(CW,"CODE",{});var nat=s(Eie);oNo=r(nat,"from_pretrained()"),nat.forEach(t),rNo=r(CW,"to load the model weights."),CW.forEach(t),tNo=i(_l),yie=n(_l,"P",{});var sat=s(yie);aNo=r(sat,"Examples:"),sat.forEach(t),nNo=i(_l),m(hw.$$.fragment,_l),_l.forEach(t),sNo=i(pl),He=n(pl,"DIV",{class:!0});var Yt=s(He);m(pw.$$.fragment,Yt),lNo=i(Yt),wie=n(Yt,"P",{});var lat=s(wie);iNo=r(lat,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lat.forEach(t),dNo=i(Yt),on=n(Yt,"P",{});var CE=s(on);cNo=r(CE,"The model class to instantiate is selected based on the "),Aie=n(CE,"CODE",{});var iat=s(Aie);fNo=r(iat,"model_type"),iat.forEach(t),mNo=r(CE,` property of the config object (either
passed as an argument or loaded from `),Lie=n(CE,"CODE",{});var dat=s(Lie);gNo=r(dat,"pretrained_model_name_or_path"),dat.forEach(t),hNo=r(CE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bie=n(CE,"CODE",{});var cat=s(Bie);pNo=r(cat,"pretrained_model_name_or_path"),cat.forEach(t),_No=r(CE,":"),CE.forEach(t),uNo=i(Yt),me=n(Yt,"UL",{});var Te=s(me);ov=n(Te,"LI",{});var N0e=s(ov);xie=n(N0e,"STRONG",{});var fat=s(xie);bNo=r(fat,"beit"),fat.forEach(t),vNo=r(N0e," \u2014 "),xj=n(N0e,"A",{href:!0});var mat=s(xj);TNo=r(mat,"BeitForImageClassification"),mat.forEach(t),FNo=r(N0e," (BEiT model)"),N0e.forEach(t),CNo=i(Te),rv=n(Te,"LI",{});var D0e=s(rv);kie=n(D0e,"STRONG",{});var gat=s(kie);MNo=r(gat,"convnext"),gat.forEach(t),ENo=r(D0e," \u2014 "),kj=n(D0e,"A",{href:!0});var hat=s(kj);yNo=r(hat,"ConvNextForImageClassification"),hat.forEach(t),wNo=r(D0e," (ConvNext model)"),D0e.forEach(t),ANo=i(Te),qs=n(Te,"LI",{});var K8=s(qs);Rie=n(K8,"STRONG",{});var pat=s(Rie);LNo=r(pat,"deit"),pat.forEach(t),BNo=r(K8," \u2014 "),Rj=n(K8,"A",{href:!0});var _at=s(Rj);xNo=r(_at,"DeiTForImageClassification"),_at.forEach(t),kNo=r(K8," or "),Sj=n(K8,"A",{href:!0});var uat=s(Sj);RNo=r(uat,"DeiTForImageClassificationWithTeacher"),uat.forEach(t),SNo=r(K8," (DeiT model)"),K8.forEach(t),PNo=i(Te),tv=n(Te,"LI",{});var j0e=s(tv);Sie=n(j0e,"STRONG",{});var bat=s(Sie);$No=r(bat,"imagegpt"),bat.forEach(t),INo=r(j0e," \u2014 "),Pj=n(j0e,"A",{href:!0});var vat=s(Pj);NNo=r(vat,"ImageGPTForImageClassification"),vat.forEach(t),DNo=r(j0e," (ImageGPT model)"),j0e.forEach(t),jNo=i(Te),ma=n(Te,"LI",{});var Pf=s(ma);Pie=n(Pf,"STRONG",{});var Tat=s(Pie);qNo=r(Tat,"perceiver"),Tat.forEach(t),GNo=r(Pf," \u2014 "),$j=n(Pf,"A",{href:!0});var Fat=s($j);ONo=r(Fat,"PerceiverForImageClassificationLearned"),Fat.forEach(t),XNo=r(Pf," or "),Ij=n(Pf,"A",{href:!0});var Cat=s(Ij);VNo=r(Cat,"PerceiverForImageClassificationFourier"),Cat.forEach(t),zNo=r(Pf," or "),Nj=n(Pf,"A",{href:!0});var Mat=s(Nj);WNo=r(Mat,"PerceiverForImageClassificationConvProcessing"),Mat.forEach(t),QNo=r(Pf," (Perceiver model)"),Pf.forEach(t),HNo=i(Te),av=n(Te,"LI",{});var q0e=s(av);$ie=n(q0e,"STRONG",{});var Eat=s($ie);UNo=r(Eat,"poolformer"),Eat.forEach(t),JNo=r(q0e," \u2014 "),Dj=n(q0e,"A",{href:!0});var yat=s(Dj);YNo=r(yat,"PoolFormerForImageClassification"),yat.forEach(t),KNo=r(q0e," (PoolFormer model)"),q0e.forEach(t),ZNo=i(Te),nv=n(Te,"LI",{});var G0e=s(nv);Iie=n(G0e,"STRONG",{});var wat=s(Iie);eDo=r(wat,"resnet"),wat.forEach(t),oDo=r(G0e," \u2014 "),jj=n(G0e,"A",{href:!0});var Aat=s(jj);rDo=r(Aat,"ResNetForImageClassification"),Aat.forEach(t),tDo=r(G0e," (ResNet model)"),G0e.forEach(t),aDo=i(Te),sv=n(Te,"LI",{});var O0e=s(sv);Nie=n(O0e,"STRONG",{});var Lat=s(Nie);nDo=r(Lat,"segformer"),Lat.forEach(t),sDo=r(O0e," \u2014 "),qj=n(O0e,"A",{href:!0});var Bat=s(qj);lDo=r(Bat,"SegformerForImageClassification"),Bat.forEach(t),iDo=r(O0e," (SegFormer model)"),O0e.forEach(t),dDo=i(Te),lv=n(Te,"LI",{});var X0e=s(lv);Die=n(X0e,"STRONG",{});var xat=s(Die);cDo=r(xat,"swin"),xat.forEach(t),fDo=r(X0e," \u2014 "),Gj=n(X0e,"A",{href:!0});var kat=s(Gj);mDo=r(kat,"SwinForImageClassification"),kat.forEach(t),gDo=r(X0e," (Swin model)"),X0e.forEach(t),hDo=i(Te),iv=n(Te,"LI",{});var V0e=s(iv);jie=n(V0e,"STRONG",{});var Rat=s(jie);pDo=r(Rat,"van"),Rat.forEach(t),_Do=r(V0e," \u2014 "),Oj=n(V0e,"A",{href:!0});var Sat=s(Oj);uDo=r(Sat,"VanForImageClassification"),Sat.forEach(t),bDo=r(V0e," (VAN model)"),V0e.forEach(t),vDo=i(Te),dv=n(Te,"LI",{});var z0e=s(dv);qie=n(z0e,"STRONG",{});var Pat=s(qie);TDo=r(Pat,"vit"),Pat.forEach(t),FDo=r(z0e," \u2014 "),Xj=n(z0e,"A",{href:!0});var $at=s(Xj);CDo=r($at,"ViTForImageClassification"),$at.forEach(t),MDo=r(z0e," (ViT model)"),z0e.forEach(t),Te.forEach(t),EDo=i(Yt),cv=n(Yt,"P",{});var W0e=s(cv);yDo=r(W0e,"The model is set in evaluation mode by default using "),Gie=n(W0e,"CODE",{});var Iat=s(Gie);wDo=r(Iat,"model.eval()"),Iat.forEach(t),ADo=r(W0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oie=n(W0e,"CODE",{});var Nat=s(Oie);LDo=r(Nat,"model.train()"),Nat.forEach(t),W0e.forEach(t),BDo=i(Yt),Xie=n(Yt,"P",{});var Dat=s(Xie);xDo=r(Dat,"Examples:"),Dat.forEach(t),kDo=i(Yt),m(_w.$$.fragment,Yt),Yt.forEach(t),pl.forEach(t),zke=i(c),Rd=n(c,"H2",{class:!0});var ePe=s(Rd);fv=n(ePe,"A",{id:!0,class:!0,href:!0});var jat=s(fv);Vie=n(jat,"SPAN",{});var qat=s(Vie);m(uw.$$.fragment,qat),qat.forEach(t),jat.forEach(t),RDo=i(ePe),zie=n(ePe,"SPAN",{});var Gat=s(zie);SDo=r(Gat,"AutoModelForVision2Seq"),Gat.forEach(t),ePe.forEach(t),Wke=i(c),ir=n(c,"DIV",{class:!0});var ul=s(ir);m(bw.$$.fragment,ul),PDo=i(ul),Sd=n(ul,"P",{});var MW=s(Sd);$Do=r(MW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wie=n(MW,"CODE",{});var Oat=s(Wie);IDo=r(Oat,"from_pretrained()"),Oat.forEach(t),NDo=r(MW,"class method or the "),Qie=n(MW,"CODE",{});var Xat=s(Qie);DDo=r(Xat,"from_config()"),Xat.forEach(t),jDo=r(MW,`class
method.`),MW.forEach(t),qDo=i(ul),vw=n(ul,"P",{});var oPe=s(vw);GDo=r(oPe,"This class cannot be instantiated directly using "),Hie=n(oPe,"CODE",{});var Vat=s(Hie);ODo=r(Vat,"__init__()"),Vat.forEach(t),XDo=r(oPe," (throws an error)."),oPe.forEach(t),VDo=i(ul),rt=n(ul,"DIV",{class:!0});var bl=s(rt);m(Tw.$$.fragment,bl),zDo=i(bl),Uie=n(bl,"P",{});var zat=s(Uie);WDo=r(zat,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zat.forEach(t),QDo=i(bl),Pd=n(bl,"P",{});var EW=s(Pd);HDo=r(EW,`Note:
Loading a model from its configuration file does `),Jie=n(EW,"STRONG",{});var Wat=s(Jie);UDo=r(Wat,"not"),Wat.forEach(t),JDo=r(EW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yie=n(EW,"CODE",{});var Qat=s(Yie);YDo=r(Qat,"from_pretrained()"),Qat.forEach(t),KDo=r(EW,"to load the model weights."),EW.forEach(t),ZDo=i(bl),Kie=n(bl,"P",{});var Hat=s(Kie);ejo=r(Hat,"Examples:"),Hat.forEach(t),ojo=i(bl),m(Fw.$$.fragment,bl),bl.forEach(t),rjo=i(ul),Ue=n(ul,"DIV",{class:!0});var Kt=s(Ue);m(Cw.$$.fragment,Kt),tjo=i(Kt),Zie=n(Kt,"P",{});var Uat=s(Zie);ajo=r(Uat,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Uat.forEach(t),njo=i(Kt),rn=n(Kt,"P",{});var ME=s(rn);sjo=r(ME,"The model class to instantiate is selected based on the "),ede=n(ME,"CODE",{});var Jat=s(ede);ljo=r(Jat,"model_type"),Jat.forEach(t),ijo=r(ME,` property of the config object (either
passed as an argument or loaded from `),ode=n(ME,"CODE",{});var Yat=s(ode);djo=r(Yat,"pretrained_model_name_or_path"),Yat.forEach(t),cjo=r(ME,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rde=n(ME,"CODE",{});var Kat=s(rde);fjo=r(Kat,"pretrained_model_name_or_path"),Kat.forEach(t),mjo=r(ME,":"),ME.forEach(t),gjo=i(Kt),tde=n(Kt,"UL",{});var Zat=s(tde);mv=n(Zat,"LI",{});var Q0e=s(mv);ade=n(Q0e,"STRONG",{});var ent=s(ade);hjo=r(ent,"vision-encoder-decoder"),ent.forEach(t),pjo=r(Q0e," \u2014 "),Vj=n(Q0e,"A",{href:!0});var ont=s(Vj);_jo=r(ont,"VisionEncoderDecoderModel"),ont.forEach(t),ujo=r(Q0e," (Vision Encoder decoder model)"),Q0e.forEach(t),Zat.forEach(t),bjo=i(Kt),gv=n(Kt,"P",{});var H0e=s(gv);vjo=r(H0e,"The model is set in evaluation mode by default using "),nde=n(H0e,"CODE",{});var rnt=s(nde);Tjo=r(rnt,"model.eval()"),rnt.forEach(t),Fjo=r(H0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sde=n(H0e,"CODE",{});var tnt=s(sde);Cjo=r(tnt,"model.train()"),tnt.forEach(t),H0e.forEach(t),Mjo=i(Kt),lde=n(Kt,"P",{});var ant=s(lde);Ejo=r(ant,"Examples:"),ant.forEach(t),yjo=i(Kt),m(Mw.$$.fragment,Kt),Kt.forEach(t),ul.forEach(t),Qke=i(c),$d=n(c,"H2",{class:!0});var rPe=s($d);hv=n(rPe,"A",{id:!0,class:!0,href:!0});var nnt=s(hv);ide=n(nnt,"SPAN",{});var snt=s(ide);m(Ew.$$.fragment,snt),snt.forEach(t),nnt.forEach(t),wjo=i(rPe),dde=n(rPe,"SPAN",{});var lnt=s(dde);Ajo=r(lnt,"AutoModelForAudioClassification"),lnt.forEach(t),rPe.forEach(t),Hke=i(c),dr=n(c,"DIV",{class:!0});var vl=s(dr);m(yw.$$.fragment,vl),Ljo=i(vl),Id=n(vl,"P",{});var yW=s(Id);Bjo=r(yW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),cde=n(yW,"CODE",{});var int=s(cde);xjo=r(int,"from_pretrained()"),int.forEach(t),kjo=r(yW,"class method or the "),fde=n(yW,"CODE",{});var dnt=s(fde);Rjo=r(dnt,"from_config()"),dnt.forEach(t),Sjo=r(yW,`class
method.`),yW.forEach(t),Pjo=i(vl),ww=n(vl,"P",{});var tPe=s(ww);$jo=r(tPe,"This class cannot be instantiated directly using "),mde=n(tPe,"CODE",{});var cnt=s(mde);Ijo=r(cnt,"__init__()"),cnt.forEach(t),Njo=r(tPe," (throws an error)."),tPe.forEach(t),Djo=i(vl),tt=n(vl,"DIV",{class:!0});var Tl=s(tt);m(Aw.$$.fragment,Tl),jjo=i(Tl),gde=n(Tl,"P",{});var fnt=s(gde);qjo=r(fnt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),fnt.forEach(t),Gjo=i(Tl),Nd=n(Tl,"P",{});var wW=s(Nd);Ojo=r(wW,`Note:
Loading a model from its configuration file does `),hde=n(wW,"STRONG",{});var mnt=s(hde);Xjo=r(mnt,"not"),mnt.forEach(t),Vjo=r(wW,` load the model weights. It only affects the
model\u2019s configuration. Use `),pde=n(wW,"CODE",{});var gnt=s(pde);zjo=r(gnt,"from_pretrained()"),gnt.forEach(t),Wjo=r(wW,"to load the model weights."),wW.forEach(t),Qjo=i(Tl),_de=n(Tl,"P",{});var hnt=s(_de);Hjo=r(hnt,"Examples:"),hnt.forEach(t),Ujo=i(Tl),m(Lw.$$.fragment,Tl),Tl.forEach(t),Jjo=i(vl),Je=n(vl,"DIV",{class:!0});var Zt=s(Je);m(Bw.$$.fragment,Zt),Yjo=i(Zt),ude=n(Zt,"P",{});var pnt=s(ude);Kjo=r(pnt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),pnt.forEach(t),Zjo=i(Zt),tn=n(Zt,"P",{});var EE=s(tn);eqo=r(EE,"The model class to instantiate is selected based on the "),bde=n(EE,"CODE",{});var _nt=s(bde);oqo=r(_nt,"model_type"),_nt.forEach(t),rqo=r(EE,` property of the config object (either
passed as an argument or loaded from `),vde=n(EE,"CODE",{});var unt=s(vde);tqo=r(unt,"pretrained_model_name_or_path"),unt.forEach(t),aqo=r(EE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tde=n(EE,"CODE",{});var bnt=s(Tde);nqo=r(bnt,"pretrained_model_name_or_path"),bnt.forEach(t),sqo=r(EE,":"),EE.forEach(t),lqo=i(Zt),ke=n(Zt,"UL",{});var qo=s(ke);pv=n(qo,"LI",{});var U0e=s(pv);Fde=n(U0e,"STRONG",{});var vnt=s(Fde);iqo=r(vnt,"data2vec-audio"),vnt.forEach(t),dqo=r(U0e," \u2014 "),zj=n(U0e,"A",{href:!0});var Tnt=s(zj);cqo=r(Tnt,"Data2VecAudioForSequenceClassification"),Tnt.forEach(t),fqo=r(U0e," (Data2VecAudio model)"),U0e.forEach(t),mqo=i(qo),_v=n(qo,"LI",{});var J0e=s(_v);Cde=n(J0e,"STRONG",{});var Fnt=s(Cde);gqo=r(Fnt,"hubert"),Fnt.forEach(t),hqo=r(J0e," \u2014 "),Wj=n(J0e,"A",{href:!0});var Cnt=s(Wj);pqo=r(Cnt,"HubertForSequenceClassification"),Cnt.forEach(t),_qo=r(J0e," (Hubert model)"),J0e.forEach(t),uqo=i(qo),uv=n(qo,"LI",{});var Y0e=s(uv);Mde=n(Y0e,"STRONG",{});var Mnt=s(Mde);bqo=r(Mnt,"sew"),Mnt.forEach(t),vqo=r(Y0e," \u2014 "),Qj=n(Y0e,"A",{href:!0});var Ent=s(Qj);Tqo=r(Ent,"SEWForSequenceClassification"),Ent.forEach(t),Fqo=r(Y0e," (SEW model)"),Y0e.forEach(t),Cqo=i(qo),bv=n(qo,"LI",{});var K0e=s(bv);Ede=n(K0e,"STRONG",{});var ynt=s(Ede);Mqo=r(ynt,"sew-d"),ynt.forEach(t),Eqo=r(K0e," \u2014 "),Hj=n(K0e,"A",{href:!0});var wnt=s(Hj);yqo=r(wnt,"SEWDForSequenceClassification"),wnt.forEach(t),wqo=r(K0e," (SEW-D model)"),K0e.forEach(t),Aqo=i(qo),vv=n(qo,"LI",{});var Z0e=s(vv);yde=n(Z0e,"STRONG",{});var Ant=s(yde);Lqo=r(Ant,"unispeech"),Ant.forEach(t),Bqo=r(Z0e," \u2014 "),Uj=n(Z0e,"A",{href:!0});var Lnt=s(Uj);xqo=r(Lnt,"UniSpeechForSequenceClassification"),Lnt.forEach(t),kqo=r(Z0e," (UniSpeech model)"),Z0e.forEach(t),Rqo=i(qo),Tv=n(qo,"LI",{});var eLe=s(Tv);wde=n(eLe,"STRONG",{});var Bnt=s(wde);Sqo=r(Bnt,"unispeech-sat"),Bnt.forEach(t),Pqo=r(eLe," \u2014 "),Jj=n(eLe,"A",{href:!0});var xnt=s(Jj);$qo=r(xnt,"UniSpeechSatForSequenceClassification"),xnt.forEach(t),Iqo=r(eLe," (UniSpeechSat model)"),eLe.forEach(t),Nqo=i(qo),Fv=n(qo,"LI",{});var oLe=s(Fv);Ade=n(oLe,"STRONG",{});var knt=s(Ade);Dqo=r(knt,"wav2vec2"),knt.forEach(t),jqo=r(oLe," \u2014 "),Yj=n(oLe,"A",{href:!0});var Rnt=s(Yj);qqo=r(Rnt,"Wav2Vec2ForSequenceClassification"),Rnt.forEach(t),Gqo=r(oLe," (Wav2Vec2 model)"),oLe.forEach(t),Oqo=i(qo),Cv=n(qo,"LI",{});var rLe=s(Cv);Lde=n(rLe,"STRONG",{});var Snt=s(Lde);Xqo=r(Snt,"wavlm"),Snt.forEach(t),Vqo=r(rLe," \u2014 "),Kj=n(rLe,"A",{href:!0});var Pnt=s(Kj);zqo=r(Pnt,"WavLMForSequenceClassification"),Pnt.forEach(t),Wqo=r(rLe," (WavLM model)"),rLe.forEach(t),qo.forEach(t),Qqo=i(Zt),Mv=n(Zt,"P",{});var tLe=s(Mv);Hqo=r(tLe,"The model is set in evaluation mode by default using "),Bde=n(tLe,"CODE",{});var $nt=s(Bde);Uqo=r($nt,"model.eval()"),$nt.forEach(t),Jqo=r(tLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xde=n(tLe,"CODE",{});var Int=s(xde);Yqo=r(Int,"model.train()"),Int.forEach(t),tLe.forEach(t),Kqo=i(Zt),kde=n(Zt,"P",{});var Nnt=s(kde);Zqo=r(Nnt,"Examples:"),Nnt.forEach(t),eGo=i(Zt),m(xw.$$.fragment,Zt),Zt.forEach(t),vl.forEach(t),Uke=i(c),Dd=n(c,"H2",{class:!0});var aPe=s(Dd);Ev=n(aPe,"A",{id:!0,class:!0,href:!0});var Dnt=s(Ev);Rde=n(Dnt,"SPAN",{});var jnt=s(Rde);m(kw.$$.fragment,jnt),jnt.forEach(t),Dnt.forEach(t),oGo=i(aPe),Sde=n(aPe,"SPAN",{});var qnt=s(Sde);rGo=r(qnt,"AutoModelForAudioFrameClassification"),qnt.forEach(t),aPe.forEach(t),Jke=i(c),cr=n(c,"DIV",{class:!0});var Fl=s(cr);m(Rw.$$.fragment,Fl),tGo=i(Fl),jd=n(Fl,"P",{});var AW=s(jd);aGo=r(AW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Pde=n(AW,"CODE",{});var Gnt=s(Pde);nGo=r(Gnt,"from_pretrained()"),Gnt.forEach(t),sGo=r(AW,"class method or the "),$de=n(AW,"CODE",{});var Ont=s($de);lGo=r(Ont,"from_config()"),Ont.forEach(t),iGo=r(AW,`class
method.`),AW.forEach(t),dGo=i(Fl),Sw=n(Fl,"P",{});var nPe=s(Sw);cGo=r(nPe,"This class cannot be instantiated directly using "),Ide=n(nPe,"CODE",{});var Xnt=s(Ide);fGo=r(Xnt,"__init__()"),Xnt.forEach(t),mGo=r(nPe," (throws an error)."),nPe.forEach(t),gGo=i(Fl),at=n(Fl,"DIV",{class:!0});var Cl=s(at);m(Pw.$$.fragment,Cl),hGo=i(Cl),Nde=n(Cl,"P",{});var Vnt=s(Nde);pGo=r(Vnt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Vnt.forEach(t),_Go=i(Cl),qd=n(Cl,"P",{});var LW=s(qd);uGo=r(LW,`Note:
Loading a model from its configuration file does `),Dde=n(LW,"STRONG",{});var znt=s(Dde);bGo=r(znt,"not"),znt.forEach(t),vGo=r(LW,` load the model weights. It only affects the
model\u2019s configuration. Use `),jde=n(LW,"CODE",{});var Wnt=s(jde);TGo=r(Wnt,"from_pretrained()"),Wnt.forEach(t),FGo=r(LW,"to load the model weights."),LW.forEach(t),CGo=i(Cl),qde=n(Cl,"P",{});var Qnt=s(qde);MGo=r(Qnt,"Examples:"),Qnt.forEach(t),EGo=i(Cl),m($w.$$.fragment,Cl),Cl.forEach(t),yGo=i(Fl),Ye=n(Fl,"DIV",{class:!0});var ea=s(Ye);m(Iw.$$.fragment,ea),wGo=i(ea),Gde=n(ea,"P",{});var Hnt=s(Gde);AGo=r(Hnt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Hnt.forEach(t),LGo=i(ea),an=n(ea,"P",{});var yE=s(an);BGo=r(yE,"The model class to instantiate is selected based on the "),Ode=n(yE,"CODE",{});var Unt=s(Ode);xGo=r(Unt,"model_type"),Unt.forEach(t),kGo=r(yE,` property of the config object (either
passed as an argument or loaded from `),Xde=n(yE,"CODE",{});var Jnt=s(Xde);RGo=r(Jnt,"pretrained_model_name_or_path"),Jnt.forEach(t),SGo=r(yE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vde=n(yE,"CODE",{});var Ynt=s(Vde);PGo=r(Ynt,"pretrained_model_name_or_path"),Ynt.forEach(t),$Go=r(yE,":"),yE.forEach(t),IGo=i(ea),nn=n(ea,"UL",{});var wE=s(nn);yv=n(wE,"LI",{});var aLe=s(yv);zde=n(aLe,"STRONG",{});var Knt=s(zde);NGo=r(Knt,"data2vec-audio"),Knt.forEach(t),DGo=r(aLe," \u2014 "),Zj=n(aLe,"A",{href:!0});var Znt=s(Zj);jGo=r(Znt,"Data2VecAudioForAudioFrameClassification"),Znt.forEach(t),qGo=r(aLe," (Data2VecAudio model)"),aLe.forEach(t),GGo=i(wE),wv=n(wE,"LI",{});var nLe=s(wv);Wde=n(nLe,"STRONG",{});var est=s(Wde);OGo=r(est,"unispeech-sat"),est.forEach(t),XGo=r(nLe," \u2014 "),eq=n(nLe,"A",{href:!0});var ost=s(eq);VGo=r(ost,"UniSpeechSatForAudioFrameClassification"),ost.forEach(t),zGo=r(nLe," (UniSpeechSat model)"),nLe.forEach(t),WGo=i(wE),Av=n(wE,"LI",{});var sLe=s(Av);Qde=n(sLe,"STRONG",{});var rst=s(Qde);QGo=r(rst,"wav2vec2"),rst.forEach(t),HGo=r(sLe," \u2014 "),oq=n(sLe,"A",{href:!0});var tst=s(oq);UGo=r(tst,"Wav2Vec2ForAudioFrameClassification"),tst.forEach(t),JGo=r(sLe," (Wav2Vec2 model)"),sLe.forEach(t),YGo=i(wE),Lv=n(wE,"LI",{});var lLe=s(Lv);Hde=n(lLe,"STRONG",{});var ast=s(Hde);KGo=r(ast,"wavlm"),ast.forEach(t),ZGo=r(lLe," \u2014 "),rq=n(lLe,"A",{href:!0});var nst=s(rq);eOo=r(nst,"WavLMForAudioFrameClassification"),nst.forEach(t),oOo=r(lLe," (WavLM model)"),lLe.forEach(t),wE.forEach(t),rOo=i(ea),Bv=n(ea,"P",{});var iLe=s(Bv);tOo=r(iLe,"The model is set in evaluation mode by default using "),Ude=n(iLe,"CODE",{});var sst=s(Ude);aOo=r(sst,"model.eval()"),sst.forEach(t),nOo=r(iLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jde=n(iLe,"CODE",{});var lst=s(Jde);sOo=r(lst,"model.train()"),lst.forEach(t),iLe.forEach(t),lOo=i(ea),Yde=n(ea,"P",{});var ist=s(Yde);iOo=r(ist,"Examples:"),ist.forEach(t),dOo=i(ea),m(Nw.$$.fragment,ea),ea.forEach(t),Fl.forEach(t),Yke=i(c),Gd=n(c,"H2",{class:!0});var sPe=s(Gd);xv=n(sPe,"A",{id:!0,class:!0,href:!0});var dst=s(xv);Kde=n(dst,"SPAN",{});var cst=s(Kde);m(Dw.$$.fragment,cst),cst.forEach(t),dst.forEach(t),cOo=i(sPe),Zde=n(sPe,"SPAN",{});var fst=s(Zde);fOo=r(fst,"AutoModelForCTC"),fst.forEach(t),sPe.forEach(t),Kke=i(c),fr=n(c,"DIV",{class:!0});var Ml=s(fr);m(jw.$$.fragment,Ml),mOo=i(Ml),Od=n(Ml,"P",{});var BW=s(Od);gOo=r(BW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),ece=n(BW,"CODE",{});var mst=s(ece);hOo=r(mst,"from_pretrained()"),mst.forEach(t),pOo=r(BW,"class method or the "),oce=n(BW,"CODE",{});var gst=s(oce);_Oo=r(gst,"from_config()"),gst.forEach(t),uOo=r(BW,`class
method.`),BW.forEach(t),bOo=i(Ml),qw=n(Ml,"P",{});var lPe=s(qw);vOo=r(lPe,"This class cannot be instantiated directly using "),rce=n(lPe,"CODE",{});var hst=s(rce);TOo=r(hst,"__init__()"),hst.forEach(t),FOo=r(lPe," (throws an error)."),lPe.forEach(t),COo=i(Ml),nt=n(Ml,"DIV",{class:!0});var El=s(nt);m(Gw.$$.fragment,El),MOo=i(El),tce=n(El,"P",{});var pst=s(tce);EOo=r(pst,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),pst.forEach(t),yOo=i(El),Xd=n(El,"P",{});var xW=s(Xd);wOo=r(xW,`Note:
Loading a model from its configuration file does `),ace=n(xW,"STRONG",{});var _st=s(ace);AOo=r(_st,"not"),_st.forEach(t),LOo=r(xW,` load the model weights. It only affects the
model\u2019s configuration. Use `),nce=n(xW,"CODE",{});var ust=s(nce);BOo=r(ust,"from_pretrained()"),ust.forEach(t),xOo=r(xW,"to load the model weights."),xW.forEach(t),kOo=i(El),sce=n(El,"P",{});var bst=s(sce);ROo=r(bst,"Examples:"),bst.forEach(t),SOo=i(El),m(Ow.$$.fragment,El),El.forEach(t),POo=i(Ml),Ke=n(Ml,"DIV",{class:!0});var oa=s(Ke);m(Xw.$$.fragment,oa),$Oo=i(oa),lce=n(oa,"P",{});var vst=s(lce);IOo=r(vst,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),vst.forEach(t),NOo=i(oa),sn=n(oa,"P",{});var AE=s(sn);DOo=r(AE,"The model class to instantiate is selected based on the "),ice=n(AE,"CODE",{});var Tst=s(ice);jOo=r(Tst,"model_type"),Tst.forEach(t),qOo=r(AE,` property of the config object (either
passed as an argument or loaded from `),dce=n(AE,"CODE",{});var Fst=s(dce);GOo=r(Fst,"pretrained_model_name_or_path"),Fst.forEach(t),OOo=r(AE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cce=n(AE,"CODE",{});var Cst=s(cce);XOo=r(Cst,"pretrained_model_name_or_path"),Cst.forEach(t),VOo=r(AE,":"),AE.forEach(t),zOo=i(oa),Re=n(oa,"UL",{});var Go=s(Re);kv=n(Go,"LI",{});var dLe=s(kv);fce=n(dLe,"STRONG",{});var Mst=s(fce);WOo=r(Mst,"data2vec-audio"),Mst.forEach(t),QOo=r(dLe," \u2014 "),tq=n(dLe,"A",{href:!0});var Est=s(tq);HOo=r(Est,"Data2VecAudioForCTC"),Est.forEach(t),UOo=r(dLe," (Data2VecAudio model)"),dLe.forEach(t),JOo=i(Go),Rv=n(Go,"LI",{});var cLe=s(Rv);mce=n(cLe,"STRONG",{});var yst=s(mce);YOo=r(yst,"hubert"),yst.forEach(t),KOo=r(cLe," \u2014 "),aq=n(cLe,"A",{href:!0});var wst=s(aq);ZOo=r(wst,"HubertForCTC"),wst.forEach(t),eXo=r(cLe," (Hubert model)"),cLe.forEach(t),oXo=i(Go),Sv=n(Go,"LI",{});var fLe=s(Sv);gce=n(fLe,"STRONG",{});var Ast=s(gce);rXo=r(Ast,"sew"),Ast.forEach(t),tXo=r(fLe," \u2014 "),nq=n(fLe,"A",{href:!0});var Lst=s(nq);aXo=r(Lst,"SEWForCTC"),Lst.forEach(t),nXo=r(fLe," (SEW model)"),fLe.forEach(t),sXo=i(Go),Pv=n(Go,"LI",{});var mLe=s(Pv);hce=n(mLe,"STRONG",{});var Bst=s(hce);lXo=r(Bst,"sew-d"),Bst.forEach(t),iXo=r(mLe," \u2014 "),sq=n(mLe,"A",{href:!0});var xst=s(sq);dXo=r(xst,"SEWDForCTC"),xst.forEach(t),cXo=r(mLe," (SEW-D model)"),mLe.forEach(t),fXo=i(Go),$v=n(Go,"LI",{});var gLe=s($v);pce=n(gLe,"STRONG",{});var kst=s(pce);mXo=r(kst,"unispeech"),kst.forEach(t),gXo=r(gLe," \u2014 "),lq=n(gLe,"A",{href:!0});var Rst=s(lq);hXo=r(Rst,"UniSpeechForCTC"),Rst.forEach(t),pXo=r(gLe," (UniSpeech model)"),gLe.forEach(t),_Xo=i(Go),Iv=n(Go,"LI",{});var hLe=s(Iv);_ce=n(hLe,"STRONG",{});var Sst=s(_ce);uXo=r(Sst,"unispeech-sat"),Sst.forEach(t),bXo=r(hLe," \u2014 "),iq=n(hLe,"A",{href:!0});var Pst=s(iq);vXo=r(Pst,"UniSpeechSatForCTC"),Pst.forEach(t),TXo=r(hLe," (UniSpeechSat model)"),hLe.forEach(t),FXo=i(Go),Nv=n(Go,"LI",{});var pLe=s(Nv);uce=n(pLe,"STRONG",{});var $st=s(uce);CXo=r($st,"wav2vec2"),$st.forEach(t),MXo=r(pLe," \u2014 "),dq=n(pLe,"A",{href:!0});var Ist=s(dq);EXo=r(Ist,"Wav2Vec2ForCTC"),Ist.forEach(t),yXo=r(pLe," (Wav2Vec2 model)"),pLe.forEach(t),wXo=i(Go),Dv=n(Go,"LI",{});var _Le=s(Dv);bce=n(_Le,"STRONG",{});var Nst=s(bce);AXo=r(Nst,"wavlm"),Nst.forEach(t),LXo=r(_Le," \u2014 "),cq=n(_Le,"A",{href:!0});var Dst=s(cq);BXo=r(Dst,"WavLMForCTC"),Dst.forEach(t),xXo=r(_Le," (WavLM model)"),_Le.forEach(t),Go.forEach(t),kXo=i(oa),jv=n(oa,"P",{});var uLe=s(jv);RXo=r(uLe,"The model is set in evaluation mode by default using "),vce=n(uLe,"CODE",{});var jst=s(vce);SXo=r(jst,"model.eval()"),jst.forEach(t),PXo=r(uLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tce=n(uLe,"CODE",{});var qst=s(Tce);$Xo=r(qst,"model.train()"),qst.forEach(t),uLe.forEach(t),IXo=i(oa),Fce=n(oa,"P",{});var Gst=s(Fce);NXo=r(Gst,"Examples:"),Gst.forEach(t),DXo=i(oa),m(Vw.$$.fragment,oa),oa.forEach(t),Ml.forEach(t),Zke=i(c),Vd=n(c,"H2",{class:!0});var iPe=s(Vd);qv=n(iPe,"A",{id:!0,class:!0,href:!0});var Ost=s(qv);Cce=n(Ost,"SPAN",{});var Xst=s(Cce);m(zw.$$.fragment,Xst),Xst.forEach(t),Ost.forEach(t),jXo=i(iPe),Mce=n(iPe,"SPAN",{});var Vst=s(Mce);qXo=r(Vst,"AutoModelForSpeechSeq2Seq"),Vst.forEach(t),iPe.forEach(t),eRe=i(c),mr=n(c,"DIV",{class:!0});var yl=s(mr);m(Ww.$$.fragment,yl),GXo=i(yl),zd=n(yl,"P",{});var kW=s(zd);OXo=r(kW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Ece=n(kW,"CODE",{});var zst=s(Ece);XXo=r(zst,"from_pretrained()"),zst.forEach(t),VXo=r(kW,"class method or the "),yce=n(kW,"CODE",{});var Wst=s(yce);zXo=r(Wst,"from_config()"),Wst.forEach(t),WXo=r(kW,`class
method.`),kW.forEach(t),QXo=i(yl),Qw=n(yl,"P",{});var dPe=s(Qw);HXo=r(dPe,"This class cannot be instantiated directly using "),wce=n(dPe,"CODE",{});var Qst=s(wce);UXo=r(Qst,"__init__()"),Qst.forEach(t),JXo=r(dPe," (throws an error)."),dPe.forEach(t),YXo=i(yl),st=n(yl,"DIV",{class:!0});var wl=s(st);m(Hw.$$.fragment,wl),KXo=i(wl),Ace=n(wl,"P",{});var Hst=s(Ace);ZXo=r(Hst,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Hst.forEach(t),eVo=i(wl),Wd=n(wl,"P",{});var RW=s(Wd);oVo=r(RW,`Note:
Loading a model from its configuration file does `),Lce=n(RW,"STRONG",{});var Ust=s(Lce);rVo=r(Ust,"not"),Ust.forEach(t),tVo=r(RW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bce=n(RW,"CODE",{});var Jst=s(Bce);aVo=r(Jst,"from_pretrained()"),Jst.forEach(t),nVo=r(RW,"to load the model weights."),RW.forEach(t),sVo=i(wl),xce=n(wl,"P",{});var Yst=s(xce);lVo=r(Yst,"Examples:"),Yst.forEach(t),iVo=i(wl),m(Uw.$$.fragment,wl),wl.forEach(t),dVo=i(yl),Ze=n(yl,"DIV",{class:!0});var ra=s(Ze);m(Jw.$$.fragment,ra),cVo=i(ra),kce=n(ra,"P",{});var Kst=s(kce);fVo=r(Kst,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Kst.forEach(t),mVo=i(ra),ln=n(ra,"P",{});var LE=s(ln);gVo=r(LE,"The model class to instantiate is selected based on the "),Rce=n(LE,"CODE",{});var Zst=s(Rce);hVo=r(Zst,"model_type"),Zst.forEach(t),pVo=r(LE,` property of the config object (either
passed as an argument or loaded from `),Sce=n(LE,"CODE",{});var elt=s(Sce);_Vo=r(elt,"pretrained_model_name_or_path"),elt.forEach(t),uVo=r(LE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pce=n(LE,"CODE",{});var olt=s(Pce);bVo=r(olt,"pretrained_model_name_or_path"),olt.forEach(t),vVo=r(LE,":"),LE.forEach(t),TVo=i(ra),Yw=n(ra,"UL",{});var cPe=s(Yw);Gv=n(cPe,"LI",{});var bLe=s(Gv);$ce=n(bLe,"STRONG",{});var rlt=s($ce);FVo=r(rlt,"speech-encoder-decoder"),rlt.forEach(t),CVo=r(bLe," \u2014 "),fq=n(bLe,"A",{href:!0});var tlt=s(fq);MVo=r(tlt,"SpeechEncoderDecoderModel"),tlt.forEach(t),EVo=r(bLe," (Speech Encoder decoder model)"),bLe.forEach(t),yVo=i(cPe),Ov=n(cPe,"LI",{});var vLe=s(Ov);Ice=n(vLe,"STRONG",{});var alt=s(Ice);wVo=r(alt,"speech_to_text"),alt.forEach(t),AVo=r(vLe," \u2014 "),mq=n(vLe,"A",{href:!0});var nlt=s(mq);LVo=r(nlt,"Speech2TextForConditionalGeneration"),nlt.forEach(t),BVo=r(vLe," (Speech2Text model)"),vLe.forEach(t),cPe.forEach(t),xVo=i(ra),Xv=n(ra,"P",{});var TLe=s(Xv);kVo=r(TLe,"The model is set in evaluation mode by default using "),Nce=n(TLe,"CODE",{});var slt=s(Nce);RVo=r(slt,"model.eval()"),slt.forEach(t),SVo=r(TLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dce=n(TLe,"CODE",{});var llt=s(Dce);PVo=r(llt,"model.train()"),llt.forEach(t),TLe.forEach(t),$Vo=i(ra),jce=n(ra,"P",{});var ilt=s(jce);IVo=r(ilt,"Examples:"),ilt.forEach(t),NVo=i(ra),m(Kw.$$.fragment,ra),ra.forEach(t),yl.forEach(t),oRe=i(c),Qd=n(c,"H2",{class:!0});var fPe=s(Qd);Vv=n(fPe,"A",{id:!0,class:!0,href:!0});var dlt=s(Vv);qce=n(dlt,"SPAN",{});var clt=s(qce);m(Zw.$$.fragment,clt),clt.forEach(t),dlt.forEach(t),DVo=i(fPe),Gce=n(fPe,"SPAN",{});var flt=s(Gce);jVo=r(flt,"AutoModelForAudioXVector"),flt.forEach(t),fPe.forEach(t),rRe=i(c),gr=n(c,"DIV",{class:!0});var Al=s(gr);m(eA.$$.fragment,Al),qVo=i(Al),Hd=n(Al,"P",{});var SW=s(Hd);GVo=r(SW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Oce=n(SW,"CODE",{});var mlt=s(Oce);OVo=r(mlt,"from_pretrained()"),mlt.forEach(t),XVo=r(SW,"class method or the "),Xce=n(SW,"CODE",{});var glt=s(Xce);VVo=r(glt,"from_config()"),glt.forEach(t),zVo=r(SW,`class
method.`),SW.forEach(t),WVo=i(Al),oA=n(Al,"P",{});var mPe=s(oA);QVo=r(mPe,"This class cannot be instantiated directly using "),Vce=n(mPe,"CODE",{});var hlt=s(Vce);HVo=r(hlt,"__init__()"),hlt.forEach(t),UVo=r(mPe," (throws an error)."),mPe.forEach(t),JVo=i(Al),lt=n(Al,"DIV",{class:!0});var Ll=s(lt);m(rA.$$.fragment,Ll),YVo=i(Ll),zce=n(Ll,"P",{});var plt=s(zce);KVo=r(plt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),plt.forEach(t),ZVo=i(Ll),Ud=n(Ll,"P",{});var PW=s(Ud);ezo=r(PW,`Note:
Loading a model from its configuration file does `),Wce=n(PW,"STRONG",{});var _lt=s(Wce);ozo=r(_lt,"not"),_lt.forEach(t),rzo=r(PW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qce=n(PW,"CODE",{});var ult=s(Qce);tzo=r(ult,"from_pretrained()"),ult.forEach(t),azo=r(PW,"to load the model weights."),PW.forEach(t),nzo=i(Ll),Hce=n(Ll,"P",{});var blt=s(Hce);szo=r(blt,"Examples:"),blt.forEach(t),lzo=i(Ll),m(tA.$$.fragment,Ll),Ll.forEach(t),izo=i(Al),eo=n(Al,"DIV",{class:!0});var ta=s(eo);m(aA.$$.fragment,ta),dzo=i(ta),Uce=n(ta,"P",{});var vlt=s(Uce);czo=r(vlt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),vlt.forEach(t),fzo=i(ta),dn=n(ta,"P",{});var BE=s(dn);mzo=r(BE,"The model class to instantiate is selected based on the "),Jce=n(BE,"CODE",{});var Tlt=s(Jce);gzo=r(Tlt,"model_type"),Tlt.forEach(t),hzo=r(BE,` property of the config object (either
passed as an argument or loaded from `),Yce=n(BE,"CODE",{});var Flt=s(Yce);pzo=r(Flt,"pretrained_model_name_or_path"),Flt.forEach(t),_zo=r(BE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kce=n(BE,"CODE",{});var Clt=s(Kce);uzo=r(Clt,"pretrained_model_name_or_path"),Clt.forEach(t),bzo=r(BE,":"),BE.forEach(t),vzo=i(ta),cn=n(ta,"UL",{});var xE=s(cn);zv=n(xE,"LI",{});var FLe=s(zv);Zce=n(FLe,"STRONG",{});var Mlt=s(Zce);Tzo=r(Mlt,"data2vec-audio"),Mlt.forEach(t),Fzo=r(FLe," \u2014 "),gq=n(FLe,"A",{href:!0});var Elt=s(gq);Czo=r(Elt,"Data2VecAudioForXVector"),Elt.forEach(t),Mzo=r(FLe," (Data2VecAudio model)"),FLe.forEach(t),Ezo=i(xE),Wv=n(xE,"LI",{});var CLe=s(Wv);efe=n(CLe,"STRONG",{});var ylt=s(efe);yzo=r(ylt,"unispeech-sat"),ylt.forEach(t),wzo=r(CLe," \u2014 "),hq=n(CLe,"A",{href:!0});var wlt=s(hq);Azo=r(wlt,"UniSpeechSatForXVector"),wlt.forEach(t),Lzo=r(CLe," (UniSpeechSat model)"),CLe.forEach(t),Bzo=i(xE),Qv=n(xE,"LI",{});var MLe=s(Qv);ofe=n(MLe,"STRONG",{});var Alt=s(ofe);xzo=r(Alt,"wav2vec2"),Alt.forEach(t),kzo=r(MLe," \u2014 "),pq=n(MLe,"A",{href:!0});var Llt=s(pq);Rzo=r(Llt,"Wav2Vec2ForXVector"),Llt.forEach(t),Szo=r(MLe," (Wav2Vec2 model)"),MLe.forEach(t),Pzo=i(xE),Hv=n(xE,"LI",{});var ELe=s(Hv);rfe=n(ELe,"STRONG",{});var Blt=s(rfe);$zo=r(Blt,"wavlm"),Blt.forEach(t),Izo=r(ELe," \u2014 "),_q=n(ELe,"A",{href:!0});var xlt=s(_q);Nzo=r(xlt,"WavLMForXVector"),xlt.forEach(t),Dzo=r(ELe," (WavLM model)"),ELe.forEach(t),xE.forEach(t),jzo=i(ta),Uv=n(ta,"P",{});var yLe=s(Uv);qzo=r(yLe,"The model is set in evaluation mode by default using "),tfe=n(yLe,"CODE",{});var klt=s(tfe);Gzo=r(klt,"model.eval()"),klt.forEach(t),Ozo=r(yLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),afe=n(yLe,"CODE",{});var Rlt=s(afe);Xzo=r(Rlt,"model.train()"),Rlt.forEach(t),yLe.forEach(t),Vzo=i(ta),nfe=n(ta,"P",{});var Slt=s(nfe);zzo=r(Slt,"Examples:"),Slt.forEach(t),Wzo=i(ta),m(nA.$$.fragment,ta),ta.forEach(t),Al.forEach(t),tRe=i(c),Jd=n(c,"H2",{class:!0});var gPe=s(Jd);Jv=n(gPe,"A",{id:!0,class:!0,href:!0});var Plt=s(Jv);sfe=n(Plt,"SPAN",{});var $lt=s(sfe);m(sA.$$.fragment,$lt),$lt.forEach(t),Plt.forEach(t),Qzo=i(gPe),lfe=n(gPe,"SPAN",{});var Ilt=s(lfe);Hzo=r(Ilt,"AutoModelForMaskedImageModeling"),Ilt.forEach(t),gPe.forEach(t),aRe=i(c),hr=n(c,"DIV",{class:!0});var Bl=s(hr);m(lA.$$.fragment,Bl),Uzo=i(Bl),Yd=n(Bl,"P",{});var $W=s(Yd);Jzo=r($W,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),ife=n($W,"CODE",{});var Nlt=s(ife);Yzo=r(Nlt,"from_pretrained()"),Nlt.forEach(t),Kzo=r($W,"class method or the "),dfe=n($W,"CODE",{});var Dlt=s(dfe);Zzo=r(Dlt,"from_config()"),Dlt.forEach(t),eWo=r($W,`class
method.`),$W.forEach(t),oWo=i(Bl),iA=n(Bl,"P",{});var hPe=s(iA);rWo=r(hPe,"This class cannot be instantiated directly using "),cfe=n(hPe,"CODE",{});var jlt=s(cfe);tWo=r(jlt,"__init__()"),jlt.forEach(t),aWo=r(hPe," (throws an error)."),hPe.forEach(t),nWo=i(Bl),it=n(Bl,"DIV",{class:!0});var xl=s(it);m(dA.$$.fragment,xl),sWo=i(xl),ffe=n(xl,"P",{});var qlt=s(ffe);lWo=r(qlt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),qlt.forEach(t),iWo=i(xl),Kd=n(xl,"P",{});var IW=s(Kd);dWo=r(IW,`Note:
Loading a model from its configuration file does `),mfe=n(IW,"STRONG",{});var Glt=s(mfe);cWo=r(Glt,"not"),Glt.forEach(t),fWo=r(IW,` load the model weights. It only affects the
model\u2019s configuration. Use `),gfe=n(IW,"CODE",{});var Olt=s(gfe);mWo=r(Olt,"from_pretrained()"),Olt.forEach(t),gWo=r(IW,"to load the model weights."),IW.forEach(t),hWo=i(xl),hfe=n(xl,"P",{});var Xlt=s(hfe);pWo=r(Xlt,"Examples:"),Xlt.forEach(t),_Wo=i(xl),m(cA.$$.fragment,xl),xl.forEach(t),uWo=i(Bl),oo=n(Bl,"DIV",{class:!0});var aa=s(oo);m(fA.$$.fragment,aa),bWo=i(aa),pfe=n(aa,"P",{});var Vlt=s(pfe);vWo=r(Vlt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Vlt.forEach(t),TWo=i(aa),fn=n(aa,"P",{});var kE=s(fn);FWo=r(kE,"The model class to instantiate is selected based on the "),_fe=n(kE,"CODE",{});var zlt=s(_fe);CWo=r(zlt,"model_type"),zlt.forEach(t),MWo=r(kE,` property of the config object (either
passed as an argument or loaded from `),ufe=n(kE,"CODE",{});var Wlt=s(ufe);EWo=r(Wlt,"pretrained_model_name_or_path"),Wlt.forEach(t),yWo=r(kE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bfe=n(kE,"CODE",{});var Qlt=s(bfe);wWo=r(Qlt,"pretrained_model_name_or_path"),Qlt.forEach(t),AWo=r(kE,":"),kE.forEach(t),LWo=i(aa),Zd=n(aa,"UL",{});var NW=s(Zd);Yv=n(NW,"LI",{});var wLe=s(Yv);vfe=n(wLe,"STRONG",{});var Hlt=s(vfe);BWo=r(Hlt,"deit"),Hlt.forEach(t),xWo=r(wLe," \u2014 "),uq=n(wLe,"A",{href:!0});var Ult=s(uq);kWo=r(Ult,"DeiTForMaskedImageModeling"),Ult.forEach(t),RWo=r(wLe," (DeiT model)"),wLe.forEach(t),SWo=i(NW),Kv=n(NW,"LI",{});var ALe=s(Kv);Tfe=n(ALe,"STRONG",{});var Jlt=s(Tfe);PWo=r(Jlt,"swin"),Jlt.forEach(t),$Wo=r(ALe," \u2014 "),bq=n(ALe,"A",{href:!0});var Ylt=s(bq);IWo=r(Ylt,"SwinForMaskedImageModeling"),Ylt.forEach(t),NWo=r(ALe," (Swin model)"),ALe.forEach(t),DWo=i(NW),Zv=n(NW,"LI",{});var LLe=s(Zv);Ffe=n(LLe,"STRONG",{});var Klt=s(Ffe);jWo=r(Klt,"vit"),Klt.forEach(t),qWo=r(LLe," \u2014 "),vq=n(LLe,"A",{href:!0});var Zlt=s(vq);GWo=r(Zlt,"ViTForMaskedImageModeling"),Zlt.forEach(t),OWo=r(LLe," (ViT model)"),LLe.forEach(t),NW.forEach(t),XWo=i(aa),e6=n(aa,"P",{});var BLe=s(e6);VWo=r(BLe,"The model is set in evaluation mode by default using "),Cfe=n(BLe,"CODE",{});var eit=s(Cfe);zWo=r(eit,"model.eval()"),eit.forEach(t),WWo=r(BLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mfe=n(BLe,"CODE",{});var oit=s(Mfe);QWo=r(oit,"model.train()"),oit.forEach(t),BLe.forEach(t),HWo=i(aa),Efe=n(aa,"P",{});var rit=s(Efe);UWo=r(rit,"Examples:"),rit.forEach(t),JWo=i(aa),m(mA.$$.fragment,aa),aa.forEach(t),Bl.forEach(t),nRe=i(c),ec=n(c,"H2",{class:!0});var pPe=s(ec);o6=n(pPe,"A",{id:!0,class:!0,href:!0});var tit=s(o6);yfe=n(tit,"SPAN",{});var ait=s(yfe);m(gA.$$.fragment,ait),ait.forEach(t),tit.forEach(t),YWo=i(pPe),wfe=n(pPe,"SPAN",{});var nit=s(wfe);KWo=r(nit,"AutoModelForObjectDetection"),nit.forEach(t),pPe.forEach(t),sRe=i(c),pr=n(c,"DIV",{class:!0});var kl=s(pr);m(hA.$$.fragment,kl),ZWo=i(kl),oc=n(kl,"P",{});var DW=s(oc);eQo=r(DW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Afe=n(DW,"CODE",{});var sit=s(Afe);oQo=r(sit,"from_pretrained()"),sit.forEach(t),rQo=r(DW,"class method or the "),Lfe=n(DW,"CODE",{});var lit=s(Lfe);tQo=r(lit,"from_config()"),lit.forEach(t),aQo=r(DW,`class
method.`),DW.forEach(t),nQo=i(kl),pA=n(kl,"P",{});var _Pe=s(pA);sQo=r(_Pe,"This class cannot be instantiated directly using "),Bfe=n(_Pe,"CODE",{});var iit=s(Bfe);lQo=r(iit,"__init__()"),iit.forEach(t),iQo=r(_Pe," (throws an error)."),_Pe.forEach(t),dQo=i(kl),dt=n(kl,"DIV",{class:!0});var Rl=s(dt);m(_A.$$.fragment,Rl),cQo=i(Rl),xfe=n(Rl,"P",{});var dit=s(xfe);fQo=r(dit,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),dit.forEach(t),mQo=i(Rl),rc=n(Rl,"P",{});var jW=s(rc);gQo=r(jW,`Note:
Loading a model from its configuration file does `),kfe=n(jW,"STRONG",{});var cit=s(kfe);hQo=r(cit,"not"),cit.forEach(t),pQo=r(jW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rfe=n(jW,"CODE",{});var fit=s(Rfe);_Qo=r(fit,"from_pretrained()"),fit.forEach(t),uQo=r(jW,"to load the model weights."),jW.forEach(t),bQo=i(Rl),Sfe=n(Rl,"P",{});var mit=s(Sfe);vQo=r(mit,"Examples:"),mit.forEach(t),TQo=i(Rl),m(uA.$$.fragment,Rl),Rl.forEach(t),FQo=i(kl),ro=n(kl,"DIV",{class:!0});var na=s(ro);m(bA.$$.fragment,na),CQo=i(na),Pfe=n(na,"P",{});var git=s(Pfe);MQo=r(git,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),git.forEach(t),EQo=i(na),mn=n(na,"P",{});var RE=s(mn);yQo=r(RE,"The model class to instantiate is selected based on the "),$fe=n(RE,"CODE",{});var hit=s($fe);wQo=r(hit,"model_type"),hit.forEach(t),AQo=r(RE,` property of the config object (either
passed as an argument or loaded from `),Ife=n(RE,"CODE",{});var pit=s(Ife);LQo=r(pit,"pretrained_model_name_or_path"),pit.forEach(t),BQo=r(RE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nfe=n(RE,"CODE",{});var _it=s(Nfe);xQo=r(_it,"pretrained_model_name_or_path"),_it.forEach(t),kQo=r(RE,":"),RE.forEach(t),RQo=i(na),Dfe=n(na,"UL",{});var uit=s(Dfe);r6=n(uit,"LI",{});var xLe=s(r6);jfe=n(xLe,"STRONG",{});var bit=s(jfe);SQo=r(bit,"detr"),bit.forEach(t),PQo=r(xLe," \u2014 "),Tq=n(xLe,"A",{href:!0});var vit=s(Tq);$Qo=r(vit,"DetrForObjectDetection"),vit.forEach(t),IQo=r(xLe," (DETR model)"),xLe.forEach(t),uit.forEach(t),NQo=i(na),t6=n(na,"P",{});var kLe=s(t6);DQo=r(kLe,"The model is set in evaluation mode by default using "),qfe=n(kLe,"CODE",{});var Tit=s(qfe);jQo=r(Tit,"model.eval()"),Tit.forEach(t),qQo=r(kLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gfe=n(kLe,"CODE",{});var Fit=s(Gfe);GQo=r(Fit,"model.train()"),Fit.forEach(t),kLe.forEach(t),OQo=i(na),Ofe=n(na,"P",{});var Cit=s(Ofe);XQo=r(Cit,"Examples:"),Cit.forEach(t),VQo=i(na),m(vA.$$.fragment,na),na.forEach(t),kl.forEach(t),lRe=i(c),tc=n(c,"H2",{class:!0});var uPe=s(tc);a6=n(uPe,"A",{id:!0,class:!0,href:!0});var Mit=s(a6);Xfe=n(Mit,"SPAN",{});var Eit=s(Xfe);m(TA.$$.fragment,Eit),Eit.forEach(t),Mit.forEach(t),zQo=i(uPe),Vfe=n(uPe,"SPAN",{});var yit=s(Vfe);WQo=r(yit,"AutoModelForImageSegmentation"),yit.forEach(t),uPe.forEach(t),iRe=i(c),_r=n(c,"DIV",{class:!0});var Sl=s(_r);m(FA.$$.fragment,Sl),QQo=i(Sl),ac=n(Sl,"P",{});var qW=s(ac);HQo=r(qW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),zfe=n(qW,"CODE",{});var wit=s(zfe);UQo=r(wit,"from_pretrained()"),wit.forEach(t),JQo=r(qW,"class method or the "),Wfe=n(qW,"CODE",{});var Ait=s(Wfe);YQo=r(Ait,"from_config()"),Ait.forEach(t),KQo=r(qW,`class
method.`),qW.forEach(t),ZQo=i(Sl),CA=n(Sl,"P",{});var bPe=s(CA);eHo=r(bPe,"This class cannot be instantiated directly using "),Qfe=n(bPe,"CODE",{});var Lit=s(Qfe);oHo=r(Lit,"__init__()"),Lit.forEach(t),rHo=r(bPe," (throws an error)."),bPe.forEach(t),tHo=i(Sl),ct=n(Sl,"DIV",{class:!0});var Pl=s(ct);m(MA.$$.fragment,Pl),aHo=i(Pl),Hfe=n(Pl,"P",{});var Bit=s(Hfe);nHo=r(Bit,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Bit.forEach(t),sHo=i(Pl),nc=n(Pl,"P",{});var GW=s(nc);lHo=r(GW,`Note:
Loading a model from its configuration file does `),Ufe=n(GW,"STRONG",{});var xit=s(Ufe);iHo=r(xit,"not"),xit.forEach(t),dHo=r(GW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jfe=n(GW,"CODE",{});var kit=s(Jfe);cHo=r(kit,"from_pretrained()"),kit.forEach(t),fHo=r(GW,"to load the model weights."),GW.forEach(t),mHo=i(Pl),Yfe=n(Pl,"P",{});var Rit=s(Yfe);gHo=r(Rit,"Examples:"),Rit.forEach(t),hHo=i(Pl),m(EA.$$.fragment,Pl),Pl.forEach(t),pHo=i(Sl),to=n(Sl,"DIV",{class:!0});var sa=s(to);m(yA.$$.fragment,sa),_Ho=i(sa),Kfe=n(sa,"P",{});var Sit=s(Kfe);uHo=r(Sit,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Sit.forEach(t),bHo=i(sa),gn=n(sa,"P",{});var SE=s(gn);vHo=r(SE,"The model class to instantiate is selected based on the "),Zfe=n(SE,"CODE",{});var Pit=s(Zfe);THo=r(Pit,"model_type"),Pit.forEach(t),FHo=r(SE,` property of the config object (either
passed as an argument or loaded from `),eme=n(SE,"CODE",{});var $it=s(eme);CHo=r($it,"pretrained_model_name_or_path"),$it.forEach(t),MHo=r(SE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ome=n(SE,"CODE",{});var Iit=s(ome);EHo=r(Iit,"pretrained_model_name_or_path"),Iit.forEach(t),yHo=r(SE,":"),SE.forEach(t),wHo=i(sa),rme=n(sa,"UL",{});var Nit=s(rme);n6=n(Nit,"LI",{});var RLe=s(n6);tme=n(RLe,"STRONG",{});var Dit=s(tme);AHo=r(Dit,"detr"),Dit.forEach(t),LHo=r(RLe," \u2014 "),Fq=n(RLe,"A",{href:!0});var jit=s(Fq);BHo=r(jit,"DetrForSegmentation"),jit.forEach(t),xHo=r(RLe," (DETR model)"),RLe.forEach(t),Nit.forEach(t),kHo=i(sa),s6=n(sa,"P",{});var SLe=s(s6);RHo=r(SLe,"The model is set in evaluation mode by default using "),ame=n(SLe,"CODE",{});var qit=s(ame);SHo=r(qit,"model.eval()"),qit.forEach(t),PHo=r(SLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nme=n(SLe,"CODE",{});var Git=s(nme);$Ho=r(Git,"model.train()"),Git.forEach(t),SLe.forEach(t),IHo=i(sa),sme=n(sa,"P",{});var Oit=s(sme);NHo=r(Oit,"Examples:"),Oit.forEach(t),DHo=i(sa),m(wA.$$.fragment,sa),sa.forEach(t),Sl.forEach(t),dRe=i(c),sc=n(c,"H2",{class:!0});var vPe=s(sc);l6=n(vPe,"A",{id:!0,class:!0,href:!0});var Xit=s(l6);lme=n(Xit,"SPAN",{});var Vit=s(lme);m(AA.$$.fragment,Vit),Vit.forEach(t),Xit.forEach(t),jHo=i(vPe),ime=n(vPe,"SPAN",{});var zit=s(ime);qHo=r(zit,"AutoModelForSemanticSegmentation"),zit.forEach(t),vPe.forEach(t),cRe=i(c),ur=n(c,"DIV",{class:!0});var $l=s(ur);m(LA.$$.fragment,$l),GHo=i($l),lc=n($l,"P",{});var OW=s(lc);OHo=r(OW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),dme=n(OW,"CODE",{});var Wit=s(dme);XHo=r(Wit,"from_pretrained()"),Wit.forEach(t),VHo=r(OW,"class method or the "),cme=n(OW,"CODE",{});var Qit=s(cme);zHo=r(Qit,"from_config()"),Qit.forEach(t),WHo=r(OW,`class
method.`),OW.forEach(t),QHo=i($l),BA=n($l,"P",{});var TPe=s(BA);HHo=r(TPe,"This class cannot be instantiated directly using "),fme=n(TPe,"CODE",{});var Hit=s(fme);UHo=r(Hit,"__init__()"),Hit.forEach(t),JHo=r(TPe," (throws an error)."),TPe.forEach(t),YHo=i($l),ft=n($l,"DIV",{class:!0});var Il=s(ft);m(xA.$$.fragment,Il),KHo=i(Il),mme=n(Il,"P",{});var Uit=s(mme);ZHo=r(Uit,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Uit.forEach(t),eUo=i(Il),ic=n(Il,"P",{});var XW=s(ic);oUo=r(XW,`Note:
Loading a model from its configuration file does `),gme=n(XW,"STRONG",{});var Jit=s(gme);rUo=r(Jit,"not"),Jit.forEach(t),tUo=r(XW,` load the model weights. It only affects the
model\u2019s configuration. Use `),hme=n(XW,"CODE",{});var Yit=s(hme);aUo=r(Yit,"from_pretrained()"),Yit.forEach(t),nUo=r(XW,"to load the model weights."),XW.forEach(t),sUo=i(Il),pme=n(Il,"P",{});var Kit=s(pme);lUo=r(Kit,"Examples:"),Kit.forEach(t),iUo=i(Il),m(kA.$$.fragment,Il),Il.forEach(t),dUo=i($l),ao=n($l,"DIV",{class:!0});var la=s(ao);m(RA.$$.fragment,la),cUo=i(la),_me=n(la,"P",{});var Zit=s(_me);fUo=r(Zit,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Zit.forEach(t),mUo=i(la),hn=n(la,"P",{});var PE=s(hn);gUo=r(PE,"The model class to instantiate is selected based on the "),ume=n(PE,"CODE",{});var edt=s(ume);hUo=r(edt,"model_type"),edt.forEach(t),pUo=r(PE,` property of the config object (either
passed as an argument or loaded from `),bme=n(PE,"CODE",{});var odt=s(bme);_Uo=r(odt,"pretrained_model_name_or_path"),odt.forEach(t),uUo=r(PE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vme=n(PE,"CODE",{});var rdt=s(vme);bUo=r(rdt,"pretrained_model_name_or_path"),rdt.forEach(t),vUo=r(PE,":"),PE.forEach(t),TUo=i(la),SA=n(la,"UL",{});var FPe=s(SA);i6=n(FPe,"LI",{});var PLe=s(i6);Tme=n(PLe,"STRONG",{});var tdt=s(Tme);FUo=r(tdt,"beit"),tdt.forEach(t),CUo=r(PLe," \u2014 "),Cq=n(PLe,"A",{href:!0});var adt=s(Cq);MUo=r(adt,"BeitForSemanticSegmentation"),adt.forEach(t),EUo=r(PLe," (BEiT model)"),PLe.forEach(t),yUo=i(FPe),d6=n(FPe,"LI",{});var $Le=s(d6);Fme=n($Le,"STRONG",{});var ndt=s(Fme);wUo=r(ndt,"segformer"),ndt.forEach(t),AUo=r($Le," \u2014 "),Mq=n($Le,"A",{href:!0});var sdt=s(Mq);LUo=r(sdt,"SegformerForSemanticSegmentation"),sdt.forEach(t),BUo=r($Le," (SegFormer model)"),$Le.forEach(t),FPe.forEach(t),xUo=i(la),c6=n(la,"P",{});var ILe=s(c6);kUo=r(ILe,"The model is set in evaluation mode by default using "),Cme=n(ILe,"CODE",{});var ldt=s(Cme);RUo=r(ldt,"model.eval()"),ldt.forEach(t),SUo=r(ILe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mme=n(ILe,"CODE",{});var idt=s(Mme);PUo=r(idt,"model.train()"),idt.forEach(t),ILe.forEach(t),$Uo=i(la),Eme=n(la,"P",{});var ddt=s(Eme);IUo=r(ddt,"Examples:"),ddt.forEach(t),NUo=i(la),m(PA.$$.fragment,la),la.forEach(t),$l.forEach(t),fRe=i(c),dc=n(c,"H2",{class:!0});var CPe=s(dc);f6=n(CPe,"A",{id:!0,class:!0,href:!0});var cdt=s(f6);yme=n(cdt,"SPAN",{});var fdt=s(yme);m($A.$$.fragment,fdt),fdt.forEach(t),cdt.forEach(t),DUo=i(CPe),wme=n(CPe,"SPAN",{});var mdt=s(wme);jUo=r(mdt,"AutoModelForInstanceSegmentation"),mdt.forEach(t),CPe.forEach(t),mRe=i(c),br=n(c,"DIV",{class:!0});var Nl=s(br);m(IA.$$.fragment,Nl),qUo=i(Nl),cc=n(Nl,"P",{});var VW=s(cc);GUo=r(VW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Ame=n(VW,"CODE",{});var gdt=s(Ame);OUo=r(gdt,"from_pretrained()"),gdt.forEach(t),XUo=r(VW,"class method or the "),Lme=n(VW,"CODE",{});var hdt=s(Lme);VUo=r(hdt,"from_config()"),hdt.forEach(t),zUo=r(VW,`class
method.`),VW.forEach(t),WUo=i(Nl),NA=n(Nl,"P",{});var MPe=s(NA);QUo=r(MPe,"This class cannot be instantiated directly using "),Bme=n(MPe,"CODE",{});var pdt=s(Bme);HUo=r(pdt,"__init__()"),pdt.forEach(t),UUo=r(MPe," (throws an error)."),MPe.forEach(t),JUo=i(Nl),mt=n(Nl,"DIV",{class:!0});var Dl=s(mt);m(DA.$$.fragment,Dl),YUo=i(Dl),xme=n(Dl,"P",{});var _dt=s(xme);KUo=r(_dt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),_dt.forEach(t),ZUo=i(Dl),fc=n(Dl,"P",{});var zW=s(fc);eJo=r(zW,`Note:
Loading a model from its configuration file does `),kme=n(zW,"STRONG",{});var udt=s(kme);oJo=r(udt,"not"),udt.forEach(t),rJo=r(zW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rme=n(zW,"CODE",{});var bdt=s(Rme);tJo=r(bdt,"from_pretrained()"),bdt.forEach(t),aJo=r(zW,"to load the model weights."),zW.forEach(t),nJo=i(Dl),Sme=n(Dl,"P",{});var vdt=s(Sme);sJo=r(vdt,"Examples:"),vdt.forEach(t),lJo=i(Dl),m(jA.$$.fragment,Dl),Dl.forEach(t),iJo=i(Nl),no=n(Nl,"DIV",{class:!0});var ia=s(no);m(qA.$$.fragment,ia),dJo=i(ia),Pme=n(ia,"P",{});var Tdt=s(Pme);cJo=r(Tdt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Tdt.forEach(t),fJo=i(ia),pn=n(ia,"P",{});var $E=s(pn);mJo=r($E,"The model class to instantiate is selected based on the "),$me=n($E,"CODE",{});var Fdt=s($me);gJo=r(Fdt,"model_type"),Fdt.forEach(t),hJo=r($E,` property of the config object (either
passed as an argument or loaded from `),Ime=n($E,"CODE",{});var Cdt=s(Ime);pJo=r(Cdt,"pretrained_model_name_or_path"),Cdt.forEach(t),_Jo=r($E,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nme=n($E,"CODE",{});var Mdt=s(Nme);uJo=r(Mdt,"pretrained_model_name_or_path"),Mdt.forEach(t),bJo=r($E,":"),$E.forEach(t),vJo=i(ia),Dme=n(ia,"UL",{});var Edt=s(Dme);m6=n(Edt,"LI",{});var NLe=s(m6);jme=n(NLe,"STRONG",{});var ydt=s(jme);TJo=r(ydt,"maskformer"),ydt.forEach(t),FJo=r(NLe," \u2014 "),Eq=n(NLe,"A",{href:!0});var wdt=s(Eq);CJo=r(wdt,"MaskFormerForInstanceSegmentation"),wdt.forEach(t),MJo=r(NLe," (MaskFormer model)"),NLe.forEach(t),Edt.forEach(t),EJo=i(ia),g6=n(ia,"P",{});var DLe=s(g6);yJo=r(DLe,"The model is set in evaluation mode by default using "),qme=n(DLe,"CODE",{});var Adt=s(qme);wJo=r(Adt,"model.eval()"),Adt.forEach(t),AJo=r(DLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gme=n(DLe,"CODE",{});var Ldt=s(Gme);LJo=r(Ldt,"model.train()"),Ldt.forEach(t),DLe.forEach(t),BJo=i(ia),Ome=n(ia,"P",{});var Bdt=s(Ome);xJo=r(Bdt,"Examples:"),Bdt.forEach(t),kJo=i(ia),m(GA.$$.fragment,ia),ia.forEach(t),Nl.forEach(t),gRe=i(c),mc=n(c,"H2",{class:!0});var EPe=s(mc);h6=n(EPe,"A",{id:!0,class:!0,href:!0});var xdt=s(h6);Xme=n(xdt,"SPAN",{});var kdt=s(Xme);m(OA.$$.fragment,kdt),kdt.forEach(t),xdt.forEach(t),RJo=i(EPe),Vme=n(EPe,"SPAN",{});var Rdt=s(Vme);SJo=r(Rdt,"TFAutoModel"),Rdt.forEach(t),EPe.forEach(t),hRe=i(c),vr=n(c,"DIV",{class:!0});var jl=s(vr);m(XA.$$.fragment,jl),PJo=i(jl),gc=n(jl,"P",{});var WW=s(gc);$Jo=r(WW,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),zme=n(WW,"CODE",{});var Sdt=s(zme);IJo=r(Sdt,"from_pretrained()"),Sdt.forEach(t),NJo=r(WW,"class method or the "),Wme=n(WW,"CODE",{});var Pdt=s(Wme);DJo=r(Pdt,"from_config()"),Pdt.forEach(t),jJo=r(WW,`class
method.`),WW.forEach(t),qJo=i(jl),VA=n(jl,"P",{});var yPe=s(VA);GJo=r(yPe,"This class cannot be instantiated directly using "),Qme=n(yPe,"CODE",{});var $dt=s(Qme);OJo=r($dt,"__init__()"),$dt.forEach(t),XJo=r(yPe," (throws an error)."),yPe.forEach(t),VJo=i(jl),gt=n(jl,"DIV",{class:!0});var ql=s(gt);m(zA.$$.fragment,ql),zJo=i(ql),Hme=n(ql,"P",{});var Idt=s(Hme);WJo=r(Idt,"Instantiates one of the base model classes of the library from a configuration."),Idt.forEach(t),QJo=i(ql),hc=n(ql,"P",{});var QW=s(hc);HJo=r(QW,`Note:
Loading a model from its configuration file does `),Ume=n(QW,"STRONG",{});var Ndt=s(Ume);UJo=r(Ndt,"not"),Ndt.forEach(t),JJo=r(QW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jme=n(QW,"CODE",{});var Ddt=s(Jme);YJo=r(Ddt,"from_pretrained()"),Ddt.forEach(t),KJo=r(QW,"to load the model weights."),QW.forEach(t),ZJo=i(ql),Yme=n(ql,"P",{});var jdt=s(Yme);eYo=r(jdt,"Examples:"),jdt.forEach(t),oYo=i(ql),m(WA.$$.fragment,ql),ql.forEach(t),rYo=i(jl),ho=n(jl,"DIV",{class:!0});var pa=s(ho);m(QA.$$.fragment,pa),tYo=i(pa),Kme=n(pa,"P",{});var qdt=s(Kme);aYo=r(qdt,"Instantiate one of the base model classes of the library from a pretrained model."),qdt.forEach(t),nYo=i(pa),_n=n(pa,"P",{});var IE=s(_n);sYo=r(IE,"The model class to instantiate is selected based on the "),Zme=n(IE,"CODE",{});var Gdt=s(Zme);lYo=r(Gdt,"model_type"),Gdt.forEach(t),iYo=r(IE,` property of the config object (either
passed as an argument or loaded from `),ege=n(IE,"CODE",{});var Odt=s(ege);dYo=r(Odt,"pretrained_model_name_or_path"),Odt.forEach(t),cYo=r(IE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oge=n(IE,"CODE",{});var Xdt=s(oge);fYo=r(Xdt,"pretrained_model_name_or_path"),Xdt.forEach(t),mYo=r(IE,":"),IE.forEach(t),gYo=i(pa),B=n(pa,"UL",{});var x=s(B);p6=n(x,"LI",{});var jLe=s(p6);rge=n(jLe,"STRONG",{});var Vdt=s(rge);hYo=r(Vdt,"albert"),Vdt.forEach(t),pYo=r(jLe," \u2014 "),yq=n(jLe,"A",{href:!0});var zdt=s(yq);_Yo=r(zdt,"TFAlbertModel"),zdt.forEach(t),uYo=r(jLe," (ALBERT model)"),jLe.forEach(t),bYo=i(x),_6=n(x,"LI",{});var qLe=s(_6);tge=n(qLe,"STRONG",{});var Wdt=s(tge);vYo=r(Wdt,"bart"),Wdt.forEach(t),TYo=r(qLe," \u2014 "),wq=n(qLe,"A",{href:!0});var Qdt=s(wq);FYo=r(Qdt,"TFBartModel"),Qdt.forEach(t),CYo=r(qLe," (BART model)"),qLe.forEach(t),MYo=i(x),u6=n(x,"LI",{});var GLe=s(u6);age=n(GLe,"STRONG",{});var Hdt=s(age);EYo=r(Hdt,"bert"),Hdt.forEach(t),yYo=r(GLe," \u2014 "),Aq=n(GLe,"A",{href:!0});var Udt=s(Aq);wYo=r(Udt,"TFBertModel"),Udt.forEach(t),AYo=r(GLe," (BERT model)"),GLe.forEach(t),LYo=i(x),b6=n(x,"LI",{});var OLe=s(b6);nge=n(OLe,"STRONG",{});var Jdt=s(nge);BYo=r(Jdt,"blenderbot"),Jdt.forEach(t),xYo=r(OLe," \u2014 "),Lq=n(OLe,"A",{href:!0});var Ydt=s(Lq);kYo=r(Ydt,"TFBlenderbotModel"),Ydt.forEach(t),RYo=r(OLe," (Blenderbot model)"),OLe.forEach(t),SYo=i(x),v6=n(x,"LI",{});var XLe=s(v6);sge=n(XLe,"STRONG",{});var Kdt=s(sge);PYo=r(Kdt,"blenderbot-small"),Kdt.forEach(t),$Yo=r(XLe," \u2014 "),Bq=n(XLe,"A",{href:!0});var Zdt=s(Bq);IYo=r(Zdt,"TFBlenderbotSmallModel"),Zdt.forEach(t),NYo=r(XLe," (BlenderbotSmall model)"),XLe.forEach(t),DYo=i(x),T6=n(x,"LI",{});var VLe=s(T6);lge=n(VLe,"STRONG",{});var ect=s(lge);jYo=r(ect,"camembert"),ect.forEach(t),qYo=r(VLe," \u2014 "),xq=n(VLe,"A",{href:!0});var oct=s(xq);GYo=r(oct,"TFCamembertModel"),oct.forEach(t),OYo=r(VLe," (CamemBERT model)"),VLe.forEach(t),XYo=i(x),F6=n(x,"LI",{});var zLe=s(F6);ige=n(zLe,"STRONG",{});var rct=s(ige);VYo=r(rct,"clip"),rct.forEach(t),zYo=r(zLe," \u2014 "),kq=n(zLe,"A",{href:!0});var tct=s(kq);WYo=r(tct,"TFCLIPModel"),tct.forEach(t),QYo=r(zLe," (CLIP model)"),zLe.forEach(t),HYo=i(x),C6=n(x,"LI",{});var WLe=s(C6);dge=n(WLe,"STRONG",{});var act=s(dge);UYo=r(act,"convbert"),act.forEach(t),JYo=r(WLe," \u2014 "),Rq=n(WLe,"A",{href:!0});var nct=s(Rq);YYo=r(nct,"TFConvBertModel"),nct.forEach(t),KYo=r(WLe," (ConvBERT model)"),WLe.forEach(t),ZYo=i(x),M6=n(x,"LI",{});var QLe=s(M6);cge=n(QLe,"STRONG",{});var sct=s(cge);eKo=r(sct,"convnext"),sct.forEach(t),oKo=r(QLe," \u2014 "),Sq=n(QLe,"A",{href:!0});var lct=s(Sq);rKo=r(lct,"TFConvNextModel"),lct.forEach(t),tKo=r(QLe," (ConvNext model)"),QLe.forEach(t),aKo=i(x),E6=n(x,"LI",{});var HLe=s(E6);fge=n(HLe,"STRONG",{});var ict=s(fge);nKo=r(ict,"ctrl"),ict.forEach(t),sKo=r(HLe," \u2014 "),Pq=n(HLe,"A",{href:!0});var dct=s(Pq);lKo=r(dct,"TFCTRLModel"),dct.forEach(t),iKo=r(HLe," (CTRL model)"),HLe.forEach(t),dKo=i(x),y6=n(x,"LI",{});var ULe=s(y6);mge=n(ULe,"STRONG",{});var cct=s(mge);cKo=r(cct,"deberta"),cct.forEach(t),fKo=r(ULe," \u2014 "),$q=n(ULe,"A",{href:!0});var fct=s($q);mKo=r(fct,"TFDebertaModel"),fct.forEach(t),gKo=r(ULe," (DeBERTa model)"),ULe.forEach(t),hKo=i(x),w6=n(x,"LI",{});var JLe=s(w6);gge=n(JLe,"STRONG",{});var mct=s(gge);pKo=r(mct,"deberta-v2"),mct.forEach(t),_Ko=r(JLe," \u2014 "),Iq=n(JLe,"A",{href:!0});var gct=s(Iq);uKo=r(gct,"TFDebertaV2Model"),gct.forEach(t),bKo=r(JLe," (DeBERTa-v2 model)"),JLe.forEach(t),vKo=i(x),A6=n(x,"LI",{});var YLe=s(A6);hge=n(YLe,"STRONG",{});var hct=s(hge);TKo=r(hct,"distilbert"),hct.forEach(t),FKo=r(YLe," \u2014 "),Nq=n(YLe,"A",{href:!0});var pct=s(Nq);CKo=r(pct,"TFDistilBertModel"),pct.forEach(t),MKo=r(YLe," (DistilBERT model)"),YLe.forEach(t),EKo=i(x),L6=n(x,"LI",{});var KLe=s(L6);pge=n(KLe,"STRONG",{});var _ct=s(pge);yKo=r(_ct,"dpr"),_ct.forEach(t),wKo=r(KLe," \u2014 "),Dq=n(KLe,"A",{href:!0});var uct=s(Dq);AKo=r(uct,"TFDPRQuestionEncoder"),uct.forEach(t),LKo=r(KLe," (DPR model)"),KLe.forEach(t),BKo=i(x),B6=n(x,"LI",{});var ZLe=s(B6);_ge=n(ZLe,"STRONG",{});var bct=s(_ge);xKo=r(bct,"electra"),bct.forEach(t),kKo=r(ZLe," \u2014 "),jq=n(ZLe,"A",{href:!0});var vct=s(jq);RKo=r(vct,"TFElectraModel"),vct.forEach(t),SKo=r(ZLe," (ELECTRA model)"),ZLe.forEach(t),PKo=i(x),x6=n(x,"LI",{});var e7e=s(x6);uge=n(e7e,"STRONG",{});var Tct=s(uge);$Ko=r(Tct,"flaubert"),Tct.forEach(t),IKo=r(e7e," \u2014 "),qq=n(e7e,"A",{href:!0});var Fct=s(qq);NKo=r(Fct,"TFFlaubertModel"),Fct.forEach(t),DKo=r(e7e," (FlauBERT model)"),e7e.forEach(t),jKo=i(x),Gs=n(x,"LI",{});var Z8=s(Gs);bge=n(Z8,"STRONG",{});var Cct=s(bge);qKo=r(Cct,"funnel"),Cct.forEach(t),GKo=r(Z8," \u2014 "),Gq=n(Z8,"A",{href:!0});var Mct=s(Gq);OKo=r(Mct,"TFFunnelModel"),Mct.forEach(t),XKo=r(Z8," or "),Oq=n(Z8,"A",{href:!0});var Ect=s(Oq);VKo=r(Ect,"TFFunnelBaseModel"),Ect.forEach(t),zKo=r(Z8," (Funnel Transformer model)"),Z8.forEach(t),WKo=i(x),k6=n(x,"LI",{});var o7e=s(k6);vge=n(o7e,"STRONG",{});var yct=s(vge);QKo=r(yct,"gpt2"),yct.forEach(t),HKo=r(o7e," \u2014 "),Xq=n(o7e,"A",{href:!0});var wct=s(Xq);UKo=r(wct,"TFGPT2Model"),wct.forEach(t),JKo=r(o7e," (OpenAI GPT-2 model)"),o7e.forEach(t),YKo=i(x),R6=n(x,"LI",{});var r7e=s(R6);Tge=n(r7e,"STRONG",{});var Act=s(Tge);KKo=r(Act,"hubert"),Act.forEach(t),ZKo=r(r7e," \u2014 "),Vq=n(r7e,"A",{href:!0});var Lct=s(Vq);eZo=r(Lct,"TFHubertModel"),Lct.forEach(t),oZo=r(r7e," (Hubert model)"),r7e.forEach(t),rZo=i(x),S6=n(x,"LI",{});var t7e=s(S6);Fge=n(t7e,"STRONG",{});var Bct=s(Fge);tZo=r(Bct,"layoutlm"),Bct.forEach(t),aZo=r(t7e," \u2014 "),zq=n(t7e,"A",{href:!0});var xct=s(zq);nZo=r(xct,"TFLayoutLMModel"),xct.forEach(t),sZo=r(t7e," (LayoutLM model)"),t7e.forEach(t),lZo=i(x),P6=n(x,"LI",{});var a7e=s(P6);Cge=n(a7e,"STRONG",{});var kct=s(Cge);iZo=r(kct,"led"),kct.forEach(t),dZo=r(a7e," \u2014 "),Wq=n(a7e,"A",{href:!0});var Rct=s(Wq);cZo=r(Rct,"TFLEDModel"),Rct.forEach(t),fZo=r(a7e," (LED model)"),a7e.forEach(t),mZo=i(x),$6=n(x,"LI",{});var n7e=s($6);Mge=n(n7e,"STRONG",{});var Sct=s(Mge);gZo=r(Sct,"longformer"),Sct.forEach(t),hZo=r(n7e," \u2014 "),Qq=n(n7e,"A",{href:!0});var Pct=s(Qq);pZo=r(Pct,"TFLongformerModel"),Pct.forEach(t),_Zo=r(n7e," (Longformer model)"),n7e.forEach(t),uZo=i(x),I6=n(x,"LI",{});var s7e=s(I6);Ege=n(s7e,"STRONG",{});var $ct=s(Ege);bZo=r($ct,"lxmert"),$ct.forEach(t),vZo=r(s7e," \u2014 "),Hq=n(s7e,"A",{href:!0});var Ict=s(Hq);TZo=r(Ict,"TFLxmertModel"),Ict.forEach(t),FZo=r(s7e," (LXMERT model)"),s7e.forEach(t),CZo=i(x),N6=n(x,"LI",{});var l7e=s(N6);yge=n(l7e,"STRONG",{});var Nct=s(yge);MZo=r(Nct,"marian"),Nct.forEach(t),EZo=r(l7e," \u2014 "),Uq=n(l7e,"A",{href:!0});var Dct=s(Uq);yZo=r(Dct,"TFMarianModel"),Dct.forEach(t),wZo=r(l7e," (Marian model)"),l7e.forEach(t),AZo=i(x),D6=n(x,"LI",{});var i7e=s(D6);wge=n(i7e,"STRONG",{});var jct=s(wge);LZo=r(jct,"mbart"),jct.forEach(t),BZo=r(i7e," \u2014 "),Jq=n(i7e,"A",{href:!0});var qct=s(Jq);xZo=r(qct,"TFMBartModel"),qct.forEach(t),kZo=r(i7e," (mBART model)"),i7e.forEach(t),RZo=i(x),j6=n(x,"LI",{});var d7e=s(j6);Age=n(d7e,"STRONG",{});var Gct=s(Age);SZo=r(Gct,"mobilebert"),Gct.forEach(t),PZo=r(d7e," \u2014 "),Yq=n(d7e,"A",{href:!0});var Oct=s(Yq);$Zo=r(Oct,"TFMobileBertModel"),Oct.forEach(t),IZo=r(d7e," (MobileBERT model)"),d7e.forEach(t),NZo=i(x),q6=n(x,"LI",{});var c7e=s(q6);Lge=n(c7e,"STRONG",{});var Xct=s(Lge);DZo=r(Xct,"mpnet"),Xct.forEach(t),jZo=r(c7e," \u2014 "),Kq=n(c7e,"A",{href:!0});var Vct=s(Kq);qZo=r(Vct,"TFMPNetModel"),Vct.forEach(t),GZo=r(c7e," (MPNet model)"),c7e.forEach(t),OZo=i(x),G6=n(x,"LI",{});var f7e=s(G6);Bge=n(f7e,"STRONG",{});var zct=s(Bge);XZo=r(zct,"mt5"),zct.forEach(t),VZo=r(f7e," \u2014 "),Zq=n(f7e,"A",{href:!0});var Wct=s(Zq);zZo=r(Wct,"TFMT5Model"),Wct.forEach(t),WZo=r(f7e," (mT5 model)"),f7e.forEach(t),QZo=i(x),O6=n(x,"LI",{});var m7e=s(O6);xge=n(m7e,"STRONG",{});var Qct=s(xge);HZo=r(Qct,"openai-gpt"),Qct.forEach(t),UZo=r(m7e," \u2014 "),eG=n(m7e,"A",{href:!0});var Hct=s(eG);JZo=r(Hct,"TFOpenAIGPTModel"),Hct.forEach(t),YZo=r(m7e," (OpenAI GPT model)"),m7e.forEach(t),KZo=i(x),X6=n(x,"LI",{});var g7e=s(X6);kge=n(g7e,"STRONG",{});var Uct=s(kge);ZZo=r(Uct,"pegasus"),Uct.forEach(t),eer=r(g7e," \u2014 "),oG=n(g7e,"A",{href:!0});var Jct=s(oG);oer=r(Jct,"TFPegasusModel"),Jct.forEach(t),rer=r(g7e," (Pegasus model)"),g7e.forEach(t),ter=i(x),V6=n(x,"LI",{});var h7e=s(V6);Rge=n(h7e,"STRONG",{});var Yct=s(Rge);aer=r(Yct,"rembert"),Yct.forEach(t),ner=r(h7e," \u2014 "),rG=n(h7e,"A",{href:!0});var Kct=s(rG);ser=r(Kct,"TFRemBertModel"),Kct.forEach(t),ler=r(h7e," (RemBERT model)"),h7e.forEach(t),ier=i(x),z6=n(x,"LI",{});var p7e=s(z6);Sge=n(p7e,"STRONG",{});var Zct=s(Sge);der=r(Zct,"roberta"),Zct.forEach(t),cer=r(p7e," \u2014 "),tG=n(p7e,"A",{href:!0});var eft=s(tG);fer=r(eft,"TFRobertaModel"),eft.forEach(t),mer=r(p7e," (RoBERTa model)"),p7e.forEach(t),ger=i(x),W6=n(x,"LI",{});var _7e=s(W6);Pge=n(_7e,"STRONG",{});var oft=s(Pge);her=r(oft,"roformer"),oft.forEach(t),per=r(_7e," \u2014 "),aG=n(_7e,"A",{href:!0});var rft=s(aG);_er=r(rft,"TFRoFormerModel"),rft.forEach(t),uer=r(_7e," (RoFormer model)"),_7e.forEach(t),ber=i(x),Q6=n(x,"LI",{});var u7e=s(Q6);$ge=n(u7e,"STRONG",{});var tft=s($ge);ver=r(tft,"speech_to_text"),tft.forEach(t),Ter=r(u7e," \u2014 "),nG=n(u7e,"A",{href:!0});var aft=s(nG);Fer=r(aft,"TFSpeech2TextModel"),aft.forEach(t),Cer=r(u7e," (Speech2Text model)"),u7e.forEach(t),Mer=i(x),H6=n(x,"LI",{});var b7e=s(H6);Ige=n(b7e,"STRONG",{});var nft=s(Ige);Eer=r(nft,"t5"),nft.forEach(t),yer=r(b7e," \u2014 "),sG=n(b7e,"A",{href:!0});var sft=s(sG);wer=r(sft,"TFT5Model"),sft.forEach(t),Aer=r(b7e," (T5 model)"),b7e.forEach(t),Ler=i(x),U6=n(x,"LI",{});var v7e=s(U6);Nge=n(v7e,"STRONG",{});var lft=s(Nge);Ber=r(lft,"tapas"),lft.forEach(t),xer=r(v7e," \u2014 "),lG=n(v7e,"A",{href:!0});var ift=s(lG);ker=r(ift,"TFTapasModel"),ift.forEach(t),Rer=r(v7e," (TAPAS model)"),v7e.forEach(t),Ser=i(x),J6=n(x,"LI",{});var T7e=s(J6);Dge=n(T7e,"STRONG",{});var dft=s(Dge);Per=r(dft,"transfo-xl"),dft.forEach(t),$er=r(T7e," \u2014 "),iG=n(T7e,"A",{href:!0});var cft=s(iG);Ier=r(cft,"TFTransfoXLModel"),cft.forEach(t),Ner=r(T7e," (Transformer-XL model)"),T7e.forEach(t),Der=i(x),Y6=n(x,"LI",{});var F7e=s(Y6);jge=n(F7e,"STRONG",{});var fft=s(jge);jer=r(fft,"vit"),fft.forEach(t),qer=r(F7e," \u2014 "),dG=n(F7e,"A",{href:!0});var mft=s(dG);Ger=r(mft,"TFViTModel"),mft.forEach(t),Oer=r(F7e," (ViT model)"),F7e.forEach(t),Xer=i(x),K6=n(x,"LI",{});var C7e=s(K6);qge=n(C7e,"STRONG",{});var gft=s(qge);Ver=r(gft,"vit_mae"),gft.forEach(t),zer=r(C7e," \u2014 "),cG=n(C7e,"A",{href:!0});var hft=s(cG);Wer=r(hft,"TFViTMAEModel"),hft.forEach(t),Qer=r(C7e," (ViTMAE model)"),C7e.forEach(t),Her=i(x),Z6=n(x,"LI",{});var M7e=s(Z6);Gge=n(M7e,"STRONG",{});var pft=s(Gge);Uer=r(pft,"wav2vec2"),pft.forEach(t),Jer=r(M7e," \u2014 "),fG=n(M7e,"A",{href:!0});var _ft=s(fG);Yer=r(_ft,"TFWav2Vec2Model"),_ft.forEach(t),Ker=r(M7e," (Wav2Vec2 model)"),M7e.forEach(t),Zer=i(x),eT=n(x,"LI",{});var E7e=s(eT);Oge=n(E7e,"STRONG",{});var uft=s(Oge);eor=r(uft,"xlm"),uft.forEach(t),oor=r(E7e," \u2014 "),mG=n(E7e,"A",{href:!0});var bft=s(mG);ror=r(bft,"TFXLMModel"),bft.forEach(t),tor=r(E7e," (XLM model)"),E7e.forEach(t),aor=i(x),oT=n(x,"LI",{});var y7e=s(oT);Xge=n(y7e,"STRONG",{});var vft=s(Xge);nor=r(vft,"xlm-roberta"),vft.forEach(t),sor=r(y7e," \u2014 "),gG=n(y7e,"A",{href:!0});var Tft=s(gG);lor=r(Tft,"TFXLMRobertaModel"),Tft.forEach(t),ior=r(y7e," (XLM-RoBERTa model)"),y7e.forEach(t),dor=i(x),rT=n(x,"LI",{});var w7e=s(rT);Vge=n(w7e,"STRONG",{});var Fft=s(Vge);cor=r(Fft,"xlnet"),Fft.forEach(t),mor=r(w7e," \u2014 "),hG=n(w7e,"A",{href:!0});var Cft=s(hG);gor=r(Cft,"TFXLNetModel"),Cft.forEach(t),hor=r(w7e," (XLNet model)"),w7e.forEach(t),x.forEach(t),por=i(pa),zge=n(pa,"P",{});var Mft=s(zge);_or=r(Mft,"Examples:"),Mft.forEach(t),uor=i(pa),m(HA.$$.fragment,pa),pa.forEach(t),jl.forEach(t),pRe=i(c),pc=n(c,"H2",{class:!0});var wPe=s(pc);tT=n(wPe,"A",{id:!0,class:!0,href:!0});var Eft=s(tT);Wge=n(Eft,"SPAN",{});var yft=s(Wge);m(UA.$$.fragment,yft),yft.forEach(t),Eft.forEach(t),bor=i(wPe),Qge=n(wPe,"SPAN",{});var wft=s(Qge);vor=r(wft,"TFAutoModelForPreTraining"),wft.forEach(t),wPe.forEach(t),_Re=i(c),Tr=n(c,"DIV",{class:!0});var Gl=s(Tr);m(JA.$$.fragment,Gl),Tor=i(Gl),_c=n(Gl,"P",{});var HW=s(_c);For=r(HW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Hge=n(HW,"CODE",{});var Aft=s(Hge);Cor=r(Aft,"from_pretrained()"),Aft.forEach(t),Mor=r(HW,"class method or the "),Uge=n(HW,"CODE",{});var Lft=s(Uge);Eor=r(Lft,"from_config()"),Lft.forEach(t),yor=r(HW,`class
method.`),HW.forEach(t),wor=i(Gl),YA=n(Gl,"P",{});var APe=s(YA);Aor=r(APe,"This class cannot be instantiated directly using "),Jge=n(APe,"CODE",{});var Bft=s(Jge);Lor=r(Bft,"__init__()"),Bft.forEach(t),Bor=r(APe," (throws an error)."),APe.forEach(t),xor=i(Gl),ht=n(Gl,"DIV",{class:!0});var Ol=s(ht);m(KA.$$.fragment,Ol),kor=i(Ol),Yge=n(Ol,"P",{});var xft=s(Yge);Ror=r(xft,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xft.forEach(t),Sor=i(Ol),uc=n(Ol,"P",{});var UW=s(uc);Por=r(UW,`Note:
Loading a model from its configuration file does `),Kge=n(UW,"STRONG",{});var kft=s(Kge);$or=r(kft,"not"),kft.forEach(t),Ior=r(UW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zge=n(UW,"CODE",{});var Rft=s(Zge);Nor=r(Rft,"from_pretrained()"),Rft.forEach(t),Dor=r(UW,"to load the model weights."),UW.forEach(t),jor=i(Ol),ehe=n(Ol,"P",{});var Sft=s(ehe);qor=r(Sft,"Examples:"),Sft.forEach(t),Gor=i(Ol),m(ZA.$$.fragment,Ol),Ol.forEach(t),Oor=i(Gl),po=n(Gl,"DIV",{class:!0});var _a=s(po);m(e0.$$.fragment,_a),Xor=i(_a),ohe=n(_a,"P",{});var Pft=s(ohe);Vor=r(Pft,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Pft.forEach(t),zor=i(_a),un=n(_a,"P",{});var NE=s(un);Wor=r(NE,"The model class to instantiate is selected based on the "),rhe=n(NE,"CODE",{});var $ft=s(rhe);Qor=r($ft,"model_type"),$ft.forEach(t),Hor=r(NE,` property of the config object (either
passed as an argument or loaded from `),the=n(NE,"CODE",{});var Ift=s(the);Uor=r(Ift,"pretrained_model_name_or_path"),Ift.forEach(t),Jor=r(NE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ahe=n(NE,"CODE",{});var Nft=s(ahe);Yor=r(Nft,"pretrained_model_name_or_path"),Nft.forEach(t),Kor=r(NE,":"),NE.forEach(t),Zor=i(_a),H=n(_a,"UL",{});var U=s(H);aT=n(U,"LI",{});var A7e=s(aT);nhe=n(A7e,"STRONG",{});var Dft=s(nhe);err=r(Dft,"albert"),Dft.forEach(t),orr=r(A7e," \u2014 "),pG=n(A7e,"A",{href:!0});var jft=s(pG);rrr=r(jft,"TFAlbertForPreTraining"),jft.forEach(t),trr=r(A7e," (ALBERT model)"),A7e.forEach(t),arr=i(U),nT=n(U,"LI",{});var L7e=s(nT);she=n(L7e,"STRONG",{});var qft=s(she);nrr=r(qft,"bart"),qft.forEach(t),srr=r(L7e," \u2014 "),_G=n(L7e,"A",{href:!0});var Gft=s(_G);lrr=r(Gft,"TFBartForConditionalGeneration"),Gft.forEach(t),irr=r(L7e," (BART model)"),L7e.forEach(t),drr=i(U),sT=n(U,"LI",{});var B7e=s(sT);lhe=n(B7e,"STRONG",{});var Oft=s(lhe);crr=r(Oft,"bert"),Oft.forEach(t),frr=r(B7e," \u2014 "),uG=n(B7e,"A",{href:!0});var Xft=s(uG);mrr=r(Xft,"TFBertForPreTraining"),Xft.forEach(t),grr=r(B7e," (BERT model)"),B7e.forEach(t),hrr=i(U),lT=n(U,"LI",{});var x7e=s(lT);ihe=n(x7e,"STRONG",{});var Vft=s(ihe);prr=r(Vft,"camembert"),Vft.forEach(t),_rr=r(x7e," \u2014 "),bG=n(x7e,"A",{href:!0});var zft=s(bG);urr=r(zft,"TFCamembertForMaskedLM"),zft.forEach(t),brr=r(x7e," (CamemBERT model)"),x7e.forEach(t),vrr=i(U),iT=n(U,"LI",{});var k7e=s(iT);dhe=n(k7e,"STRONG",{});var Wft=s(dhe);Trr=r(Wft,"ctrl"),Wft.forEach(t),Frr=r(k7e," \u2014 "),vG=n(k7e,"A",{href:!0});var Qft=s(vG);Crr=r(Qft,"TFCTRLLMHeadModel"),Qft.forEach(t),Mrr=r(k7e," (CTRL model)"),k7e.forEach(t),Err=i(U),dT=n(U,"LI",{});var R7e=s(dT);che=n(R7e,"STRONG",{});var Hft=s(che);yrr=r(Hft,"distilbert"),Hft.forEach(t),wrr=r(R7e," \u2014 "),TG=n(R7e,"A",{href:!0});var Uft=s(TG);Arr=r(Uft,"TFDistilBertForMaskedLM"),Uft.forEach(t),Lrr=r(R7e," (DistilBERT model)"),R7e.forEach(t),Brr=i(U),cT=n(U,"LI",{});var S7e=s(cT);fhe=n(S7e,"STRONG",{});var Jft=s(fhe);xrr=r(Jft,"electra"),Jft.forEach(t),krr=r(S7e," \u2014 "),FG=n(S7e,"A",{href:!0});var Yft=s(FG);Rrr=r(Yft,"TFElectraForPreTraining"),Yft.forEach(t),Srr=r(S7e," (ELECTRA model)"),S7e.forEach(t),Prr=i(U),fT=n(U,"LI",{});var P7e=s(fT);mhe=n(P7e,"STRONG",{});var Kft=s(mhe);$rr=r(Kft,"flaubert"),Kft.forEach(t),Irr=r(P7e," \u2014 "),CG=n(P7e,"A",{href:!0});var Zft=s(CG);Nrr=r(Zft,"TFFlaubertWithLMHeadModel"),Zft.forEach(t),Drr=r(P7e," (FlauBERT model)"),P7e.forEach(t),jrr=i(U),mT=n(U,"LI",{});var $7e=s(mT);ghe=n($7e,"STRONG",{});var emt=s(ghe);qrr=r(emt,"funnel"),emt.forEach(t),Grr=r($7e," \u2014 "),MG=n($7e,"A",{href:!0});var omt=s(MG);Orr=r(omt,"TFFunnelForPreTraining"),omt.forEach(t),Xrr=r($7e," (Funnel Transformer model)"),$7e.forEach(t),Vrr=i(U),gT=n(U,"LI",{});var I7e=s(gT);hhe=n(I7e,"STRONG",{});var rmt=s(hhe);zrr=r(rmt,"gpt2"),rmt.forEach(t),Wrr=r(I7e," \u2014 "),EG=n(I7e,"A",{href:!0});var tmt=s(EG);Qrr=r(tmt,"TFGPT2LMHeadModel"),tmt.forEach(t),Hrr=r(I7e," (OpenAI GPT-2 model)"),I7e.forEach(t),Urr=i(U),hT=n(U,"LI",{});var N7e=s(hT);phe=n(N7e,"STRONG",{});var amt=s(phe);Jrr=r(amt,"layoutlm"),amt.forEach(t),Yrr=r(N7e," \u2014 "),yG=n(N7e,"A",{href:!0});var nmt=s(yG);Krr=r(nmt,"TFLayoutLMForMaskedLM"),nmt.forEach(t),Zrr=r(N7e," (LayoutLM model)"),N7e.forEach(t),etr=i(U),pT=n(U,"LI",{});var D7e=s(pT);_he=n(D7e,"STRONG",{});var smt=s(_he);otr=r(smt,"lxmert"),smt.forEach(t),rtr=r(D7e," \u2014 "),wG=n(D7e,"A",{href:!0});var lmt=s(wG);ttr=r(lmt,"TFLxmertForPreTraining"),lmt.forEach(t),atr=r(D7e," (LXMERT model)"),D7e.forEach(t),ntr=i(U),_T=n(U,"LI",{});var j7e=s(_T);uhe=n(j7e,"STRONG",{});var imt=s(uhe);str=r(imt,"mobilebert"),imt.forEach(t),ltr=r(j7e," \u2014 "),AG=n(j7e,"A",{href:!0});var dmt=s(AG);itr=r(dmt,"TFMobileBertForPreTraining"),dmt.forEach(t),dtr=r(j7e," (MobileBERT model)"),j7e.forEach(t),ctr=i(U),uT=n(U,"LI",{});var q7e=s(uT);bhe=n(q7e,"STRONG",{});var cmt=s(bhe);ftr=r(cmt,"mpnet"),cmt.forEach(t),mtr=r(q7e," \u2014 "),LG=n(q7e,"A",{href:!0});var fmt=s(LG);gtr=r(fmt,"TFMPNetForMaskedLM"),fmt.forEach(t),htr=r(q7e," (MPNet model)"),q7e.forEach(t),ptr=i(U),bT=n(U,"LI",{});var G7e=s(bT);vhe=n(G7e,"STRONG",{});var mmt=s(vhe);_tr=r(mmt,"openai-gpt"),mmt.forEach(t),utr=r(G7e," \u2014 "),BG=n(G7e,"A",{href:!0});var gmt=s(BG);btr=r(gmt,"TFOpenAIGPTLMHeadModel"),gmt.forEach(t),vtr=r(G7e," (OpenAI GPT model)"),G7e.forEach(t),Ttr=i(U),vT=n(U,"LI",{});var O7e=s(vT);The=n(O7e,"STRONG",{});var hmt=s(The);Ftr=r(hmt,"roberta"),hmt.forEach(t),Ctr=r(O7e," \u2014 "),xG=n(O7e,"A",{href:!0});var pmt=s(xG);Mtr=r(pmt,"TFRobertaForMaskedLM"),pmt.forEach(t),Etr=r(O7e," (RoBERTa model)"),O7e.forEach(t),ytr=i(U),TT=n(U,"LI",{});var X7e=s(TT);Fhe=n(X7e,"STRONG",{});var _mt=s(Fhe);wtr=r(_mt,"t5"),_mt.forEach(t),Atr=r(X7e," \u2014 "),kG=n(X7e,"A",{href:!0});var umt=s(kG);Ltr=r(umt,"TFT5ForConditionalGeneration"),umt.forEach(t),Btr=r(X7e," (T5 model)"),X7e.forEach(t),xtr=i(U),FT=n(U,"LI",{});var V7e=s(FT);Che=n(V7e,"STRONG",{});var bmt=s(Che);ktr=r(bmt,"tapas"),bmt.forEach(t),Rtr=r(V7e," \u2014 "),RG=n(V7e,"A",{href:!0});var vmt=s(RG);Str=r(vmt,"TFTapasForMaskedLM"),vmt.forEach(t),Ptr=r(V7e," (TAPAS model)"),V7e.forEach(t),$tr=i(U),CT=n(U,"LI",{});var z7e=s(CT);Mhe=n(z7e,"STRONG",{});var Tmt=s(Mhe);Itr=r(Tmt,"transfo-xl"),Tmt.forEach(t),Ntr=r(z7e," \u2014 "),SG=n(z7e,"A",{href:!0});var Fmt=s(SG);Dtr=r(Fmt,"TFTransfoXLLMHeadModel"),Fmt.forEach(t),jtr=r(z7e," (Transformer-XL model)"),z7e.forEach(t),qtr=i(U),MT=n(U,"LI",{});var W7e=s(MT);Ehe=n(W7e,"STRONG",{});var Cmt=s(Ehe);Gtr=r(Cmt,"vit_mae"),Cmt.forEach(t),Otr=r(W7e," \u2014 "),PG=n(W7e,"A",{href:!0});var Mmt=s(PG);Xtr=r(Mmt,"TFViTMAEForPreTraining"),Mmt.forEach(t),Vtr=r(W7e," (ViTMAE model)"),W7e.forEach(t),ztr=i(U),ET=n(U,"LI",{});var Q7e=s(ET);yhe=n(Q7e,"STRONG",{});var Emt=s(yhe);Wtr=r(Emt,"xlm"),Emt.forEach(t),Qtr=r(Q7e," \u2014 "),$G=n(Q7e,"A",{href:!0});var ymt=s($G);Htr=r(ymt,"TFXLMWithLMHeadModel"),ymt.forEach(t),Utr=r(Q7e," (XLM model)"),Q7e.forEach(t),Jtr=i(U),yT=n(U,"LI",{});var H7e=s(yT);whe=n(H7e,"STRONG",{});var wmt=s(whe);Ytr=r(wmt,"xlm-roberta"),wmt.forEach(t),Ktr=r(H7e," \u2014 "),IG=n(H7e,"A",{href:!0});var Amt=s(IG);Ztr=r(Amt,"TFXLMRobertaForMaskedLM"),Amt.forEach(t),ear=r(H7e," (XLM-RoBERTa model)"),H7e.forEach(t),oar=i(U),wT=n(U,"LI",{});var U7e=s(wT);Ahe=n(U7e,"STRONG",{});var Lmt=s(Ahe);rar=r(Lmt,"xlnet"),Lmt.forEach(t),tar=r(U7e," \u2014 "),NG=n(U7e,"A",{href:!0});var Bmt=s(NG);aar=r(Bmt,"TFXLNetLMHeadModel"),Bmt.forEach(t),nar=r(U7e," (XLNet model)"),U7e.forEach(t),U.forEach(t),sar=i(_a),Lhe=n(_a,"P",{});var xmt=s(Lhe);lar=r(xmt,"Examples:"),xmt.forEach(t),iar=i(_a),m(o0.$$.fragment,_a),_a.forEach(t),Gl.forEach(t),uRe=i(c),bc=n(c,"H2",{class:!0});var LPe=s(bc);AT=n(LPe,"A",{id:!0,class:!0,href:!0});var kmt=s(AT);Bhe=n(kmt,"SPAN",{});var Rmt=s(Bhe);m(r0.$$.fragment,Rmt),Rmt.forEach(t),kmt.forEach(t),dar=i(LPe),xhe=n(LPe,"SPAN",{});var Smt=s(xhe);car=r(Smt,"TFAutoModelForCausalLM"),Smt.forEach(t),LPe.forEach(t),bRe=i(c),Fr=n(c,"DIV",{class:!0});var Xl=s(Fr);m(t0.$$.fragment,Xl),far=i(Xl),vc=n(Xl,"P",{});var JW=s(vc);mar=r(JW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),khe=n(JW,"CODE",{});var Pmt=s(khe);gar=r(Pmt,"from_pretrained()"),Pmt.forEach(t),har=r(JW,"class method or the "),Rhe=n(JW,"CODE",{});var $mt=s(Rhe);par=r($mt,"from_config()"),$mt.forEach(t),_ar=r(JW,`class
method.`),JW.forEach(t),uar=i(Xl),a0=n(Xl,"P",{});var BPe=s(a0);bar=r(BPe,"This class cannot be instantiated directly using "),She=n(BPe,"CODE",{});var Imt=s(She);Tar=r(Imt,"__init__()"),Imt.forEach(t),Far=r(BPe," (throws an error)."),BPe.forEach(t),Car=i(Xl),pt=n(Xl,"DIV",{class:!0});var Vl=s(pt);m(n0.$$.fragment,Vl),Mar=i(Vl),Phe=n(Vl,"P",{});var Nmt=s(Phe);Ear=r(Nmt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Nmt.forEach(t),yar=i(Vl),Tc=n(Vl,"P",{});var YW=s(Tc);war=r(YW,`Note:
Loading a model from its configuration file does `),$he=n(YW,"STRONG",{});var Dmt=s($he);Aar=r(Dmt,"not"),Dmt.forEach(t),Lar=r(YW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ihe=n(YW,"CODE",{});var jmt=s(Ihe);Bar=r(jmt,"from_pretrained()"),jmt.forEach(t),xar=r(YW,"to load the model weights."),YW.forEach(t),kar=i(Vl),Nhe=n(Vl,"P",{});var qmt=s(Nhe);Rar=r(qmt,"Examples:"),qmt.forEach(t),Sar=i(Vl),m(s0.$$.fragment,Vl),Vl.forEach(t),Par=i(Xl),_o=n(Xl,"DIV",{class:!0});var ua=s(_o);m(l0.$$.fragment,ua),$ar=i(ua),Dhe=n(ua,"P",{});var Gmt=s(Dhe);Iar=r(Gmt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Gmt.forEach(t),Nar=i(ua),bn=n(ua,"P",{});var DE=s(bn);Dar=r(DE,"The model class to instantiate is selected based on the "),jhe=n(DE,"CODE",{});var Omt=s(jhe);jar=r(Omt,"model_type"),Omt.forEach(t),qar=r(DE,` property of the config object (either
passed as an argument or loaded from `),qhe=n(DE,"CODE",{});var Xmt=s(qhe);Gar=r(Xmt,"pretrained_model_name_or_path"),Xmt.forEach(t),Oar=r(DE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ghe=n(DE,"CODE",{});var Vmt=s(Ghe);Xar=r(Vmt,"pretrained_model_name_or_path"),Vmt.forEach(t),Var=r(DE,":"),DE.forEach(t),zar=i(ua),ge=n(ua,"UL",{});var Fe=s(ge);LT=n(Fe,"LI",{});var J7e=s(LT);Ohe=n(J7e,"STRONG",{});var zmt=s(Ohe);War=r(zmt,"bert"),zmt.forEach(t),Qar=r(J7e," \u2014 "),DG=n(J7e,"A",{href:!0});var Wmt=s(DG);Har=r(Wmt,"TFBertLMHeadModel"),Wmt.forEach(t),Uar=r(J7e," (BERT model)"),J7e.forEach(t),Jar=i(Fe),BT=n(Fe,"LI",{});var Y7e=s(BT);Xhe=n(Y7e,"STRONG",{});var Qmt=s(Xhe);Yar=r(Qmt,"camembert"),Qmt.forEach(t),Kar=r(Y7e," \u2014 "),jG=n(Y7e,"A",{href:!0});var Hmt=s(jG);Zar=r(Hmt,"TFCamembertForCausalLM"),Hmt.forEach(t),enr=r(Y7e," (CamemBERT model)"),Y7e.forEach(t),onr=i(Fe),xT=n(Fe,"LI",{});var K7e=s(xT);Vhe=n(K7e,"STRONG",{});var Umt=s(Vhe);rnr=r(Umt,"ctrl"),Umt.forEach(t),tnr=r(K7e," \u2014 "),qG=n(K7e,"A",{href:!0});var Jmt=s(qG);anr=r(Jmt,"TFCTRLLMHeadModel"),Jmt.forEach(t),nnr=r(K7e," (CTRL model)"),K7e.forEach(t),snr=i(Fe),kT=n(Fe,"LI",{});var Z7e=s(kT);zhe=n(Z7e,"STRONG",{});var Ymt=s(zhe);lnr=r(Ymt,"gpt2"),Ymt.forEach(t),inr=r(Z7e," \u2014 "),GG=n(Z7e,"A",{href:!0});var Kmt=s(GG);dnr=r(Kmt,"TFGPT2LMHeadModel"),Kmt.forEach(t),cnr=r(Z7e," (OpenAI GPT-2 model)"),Z7e.forEach(t),fnr=i(Fe),RT=n(Fe,"LI",{});var e8e=s(RT);Whe=n(e8e,"STRONG",{});var Zmt=s(Whe);mnr=r(Zmt,"openai-gpt"),Zmt.forEach(t),gnr=r(e8e," \u2014 "),OG=n(e8e,"A",{href:!0});var egt=s(OG);hnr=r(egt,"TFOpenAIGPTLMHeadModel"),egt.forEach(t),pnr=r(e8e," (OpenAI GPT model)"),e8e.forEach(t),_nr=i(Fe),ST=n(Fe,"LI",{});var o8e=s(ST);Qhe=n(o8e,"STRONG",{});var ogt=s(Qhe);unr=r(ogt,"rembert"),ogt.forEach(t),bnr=r(o8e," \u2014 "),XG=n(o8e,"A",{href:!0});var rgt=s(XG);vnr=r(rgt,"TFRemBertForCausalLM"),rgt.forEach(t),Tnr=r(o8e," (RemBERT model)"),o8e.forEach(t),Fnr=i(Fe),PT=n(Fe,"LI",{});var r8e=s(PT);Hhe=n(r8e,"STRONG",{});var tgt=s(Hhe);Cnr=r(tgt,"roberta"),tgt.forEach(t),Mnr=r(r8e," \u2014 "),VG=n(r8e,"A",{href:!0});var agt=s(VG);Enr=r(agt,"TFRobertaForCausalLM"),agt.forEach(t),ynr=r(r8e," (RoBERTa model)"),r8e.forEach(t),wnr=i(Fe),$T=n(Fe,"LI",{});var t8e=s($T);Uhe=n(t8e,"STRONG",{});var ngt=s(Uhe);Anr=r(ngt,"roformer"),ngt.forEach(t),Lnr=r(t8e," \u2014 "),zG=n(t8e,"A",{href:!0});var sgt=s(zG);Bnr=r(sgt,"TFRoFormerForCausalLM"),sgt.forEach(t),xnr=r(t8e," (RoFormer model)"),t8e.forEach(t),knr=i(Fe),IT=n(Fe,"LI",{});var a8e=s(IT);Jhe=n(a8e,"STRONG",{});var lgt=s(Jhe);Rnr=r(lgt,"transfo-xl"),lgt.forEach(t),Snr=r(a8e," \u2014 "),WG=n(a8e,"A",{href:!0});var igt=s(WG);Pnr=r(igt,"TFTransfoXLLMHeadModel"),igt.forEach(t),$nr=r(a8e," (Transformer-XL model)"),a8e.forEach(t),Inr=i(Fe),NT=n(Fe,"LI",{});var n8e=s(NT);Yhe=n(n8e,"STRONG",{});var dgt=s(Yhe);Nnr=r(dgt,"xlm"),dgt.forEach(t),Dnr=r(n8e," \u2014 "),QG=n(n8e,"A",{href:!0});var cgt=s(QG);jnr=r(cgt,"TFXLMWithLMHeadModel"),cgt.forEach(t),qnr=r(n8e," (XLM model)"),n8e.forEach(t),Gnr=i(Fe),DT=n(Fe,"LI",{});var s8e=s(DT);Khe=n(s8e,"STRONG",{});var fgt=s(Khe);Onr=r(fgt,"xlnet"),fgt.forEach(t),Xnr=r(s8e," \u2014 "),HG=n(s8e,"A",{href:!0});var mgt=s(HG);Vnr=r(mgt,"TFXLNetLMHeadModel"),mgt.forEach(t),znr=r(s8e," (XLNet model)"),s8e.forEach(t),Fe.forEach(t),Wnr=i(ua),Zhe=n(ua,"P",{});var ggt=s(Zhe);Qnr=r(ggt,"Examples:"),ggt.forEach(t),Hnr=i(ua),m(i0.$$.fragment,ua),ua.forEach(t),Xl.forEach(t),vRe=i(c),Fc=n(c,"H2",{class:!0});var xPe=s(Fc);jT=n(xPe,"A",{id:!0,class:!0,href:!0});var hgt=s(jT);epe=n(hgt,"SPAN",{});var pgt=s(epe);m(d0.$$.fragment,pgt),pgt.forEach(t),hgt.forEach(t),Unr=i(xPe),ope=n(xPe,"SPAN",{});var _gt=s(ope);Jnr=r(_gt,"TFAutoModelForImageClassification"),_gt.forEach(t),xPe.forEach(t),TRe=i(c),Cr=n(c,"DIV",{class:!0});var zl=s(Cr);m(c0.$$.fragment,zl),Ynr=i(zl),Cc=n(zl,"P",{});var KW=s(Cc);Knr=r(KW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rpe=n(KW,"CODE",{});var ugt=s(rpe);Znr=r(ugt,"from_pretrained()"),ugt.forEach(t),esr=r(KW,"class method or the "),tpe=n(KW,"CODE",{});var bgt=s(tpe);osr=r(bgt,"from_config()"),bgt.forEach(t),rsr=r(KW,`class
method.`),KW.forEach(t),tsr=i(zl),f0=n(zl,"P",{});var kPe=s(f0);asr=r(kPe,"This class cannot be instantiated directly using "),ape=n(kPe,"CODE",{});var vgt=s(ape);nsr=r(vgt,"__init__()"),vgt.forEach(t),ssr=r(kPe," (throws an error)."),kPe.forEach(t),lsr=i(zl),_t=n(zl,"DIV",{class:!0});var Wl=s(_t);m(m0.$$.fragment,Wl),isr=i(Wl),npe=n(Wl,"P",{});var Tgt=s(npe);dsr=r(Tgt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Tgt.forEach(t),csr=i(Wl),Mc=n(Wl,"P",{});var ZW=s(Mc);fsr=r(ZW,`Note:
Loading a model from its configuration file does `),spe=n(ZW,"STRONG",{});var Fgt=s(spe);msr=r(Fgt,"not"),Fgt.forEach(t),gsr=r(ZW,` load the model weights. It only affects the
model\u2019s configuration. Use `),lpe=n(ZW,"CODE",{});var Cgt=s(lpe);hsr=r(Cgt,"from_pretrained()"),Cgt.forEach(t),psr=r(ZW,"to load the model weights."),ZW.forEach(t),_sr=i(Wl),ipe=n(Wl,"P",{});var Mgt=s(ipe);usr=r(Mgt,"Examples:"),Mgt.forEach(t),bsr=i(Wl),m(g0.$$.fragment,Wl),Wl.forEach(t),vsr=i(zl),uo=n(zl,"DIV",{class:!0});var ba=s(uo);m(h0.$$.fragment,ba),Tsr=i(ba),dpe=n(ba,"P",{});var Egt=s(dpe);Fsr=r(Egt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Egt.forEach(t),Csr=i(ba),vn=n(ba,"P",{});var jE=s(vn);Msr=r(jE,"The model class to instantiate is selected based on the "),cpe=n(jE,"CODE",{});var ygt=s(cpe);Esr=r(ygt,"model_type"),ygt.forEach(t),ysr=r(jE,` property of the config object (either
passed as an argument or loaded from `),fpe=n(jE,"CODE",{});var wgt=s(fpe);wsr=r(wgt,"pretrained_model_name_or_path"),wgt.forEach(t),Asr=r(jE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mpe=n(jE,"CODE",{});var Agt=s(mpe);Lsr=r(Agt,"pretrained_model_name_or_path"),Agt.forEach(t),Bsr=r(jE,":"),jE.forEach(t),xsr=i(ba),p0=n(ba,"UL",{});var RPe=s(p0);qT=n(RPe,"LI",{});var l8e=s(qT);gpe=n(l8e,"STRONG",{});var Lgt=s(gpe);ksr=r(Lgt,"convnext"),Lgt.forEach(t),Rsr=r(l8e," \u2014 "),UG=n(l8e,"A",{href:!0});var Bgt=s(UG);Ssr=r(Bgt,"TFConvNextForImageClassification"),Bgt.forEach(t),Psr=r(l8e," (ConvNext model)"),l8e.forEach(t),$sr=i(RPe),GT=n(RPe,"LI",{});var i8e=s(GT);hpe=n(i8e,"STRONG",{});var xgt=s(hpe);Isr=r(xgt,"vit"),xgt.forEach(t),Nsr=r(i8e," \u2014 "),JG=n(i8e,"A",{href:!0});var kgt=s(JG);Dsr=r(kgt,"TFViTForImageClassification"),kgt.forEach(t),jsr=r(i8e," (ViT model)"),i8e.forEach(t),RPe.forEach(t),qsr=i(ba),ppe=n(ba,"P",{});var Rgt=s(ppe);Gsr=r(Rgt,"Examples:"),Rgt.forEach(t),Osr=i(ba),m(_0.$$.fragment,ba),ba.forEach(t),zl.forEach(t),FRe=i(c),Ec=n(c,"H2",{class:!0});var SPe=s(Ec);OT=n(SPe,"A",{id:!0,class:!0,href:!0});var Sgt=s(OT);_pe=n(Sgt,"SPAN",{});var Pgt=s(_pe);m(u0.$$.fragment,Pgt),Pgt.forEach(t),Sgt.forEach(t),Xsr=i(SPe),upe=n(SPe,"SPAN",{});var $gt=s(upe);Vsr=r($gt,"TFAutoModelForMaskedLM"),$gt.forEach(t),SPe.forEach(t),CRe=i(c),Mr=n(c,"DIV",{class:!0});var Ql=s(Mr);m(b0.$$.fragment,Ql),zsr=i(Ql),yc=n(Ql,"P",{});var eQ=s(yc);Wsr=r(eQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),bpe=n(eQ,"CODE",{});var Igt=s(bpe);Qsr=r(Igt,"from_pretrained()"),Igt.forEach(t),Hsr=r(eQ,"class method or the "),vpe=n(eQ,"CODE",{});var Ngt=s(vpe);Usr=r(Ngt,"from_config()"),Ngt.forEach(t),Jsr=r(eQ,`class
method.`),eQ.forEach(t),Ysr=i(Ql),v0=n(Ql,"P",{});var PPe=s(v0);Ksr=r(PPe,"This class cannot be instantiated directly using "),Tpe=n(PPe,"CODE",{});var Dgt=s(Tpe);Zsr=r(Dgt,"__init__()"),Dgt.forEach(t),elr=r(PPe," (throws an error)."),PPe.forEach(t),olr=i(Ql),ut=n(Ql,"DIV",{class:!0});var Hl=s(ut);m(T0.$$.fragment,Hl),rlr=i(Hl),Fpe=n(Hl,"P",{});var jgt=s(Fpe);tlr=r(jgt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),jgt.forEach(t),alr=i(Hl),wc=n(Hl,"P",{});var oQ=s(wc);nlr=r(oQ,`Note:
Loading a model from its configuration file does `),Cpe=n(oQ,"STRONG",{});var qgt=s(Cpe);slr=r(qgt,"not"),qgt.forEach(t),llr=r(oQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mpe=n(oQ,"CODE",{});var Ggt=s(Mpe);ilr=r(Ggt,"from_pretrained()"),Ggt.forEach(t),dlr=r(oQ,"to load the model weights."),oQ.forEach(t),clr=i(Hl),Epe=n(Hl,"P",{});var Ogt=s(Epe);flr=r(Ogt,"Examples:"),Ogt.forEach(t),mlr=i(Hl),m(F0.$$.fragment,Hl),Hl.forEach(t),glr=i(Ql),bo=n(Ql,"DIV",{class:!0});var va=s(bo);m(C0.$$.fragment,va),hlr=i(va),ype=n(va,"P",{});var Xgt=s(ype);plr=r(Xgt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xgt.forEach(t),_lr=i(va),Tn=n(va,"P",{});var qE=s(Tn);ulr=r(qE,"The model class to instantiate is selected based on the "),wpe=n(qE,"CODE",{});var Vgt=s(wpe);blr=r(Vgt,"model_type"),Vgt.forEach(t),vlr=r(qE,` property of the config object (either
passed as an argument or loaded from `),Ape=n(qE,"CODE",{});var zgt=s(Ape);Tlr=r(zgt,"pretrained_model_name_or_path"),zgt.forEach(t),Flr=r(qE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lpe=n(qE,"CODE",{});var Wgt=s(Lpe);Clr=r(Wgt,"pretrained_model_name_or_path"),Wgt.forEach(t),Mlr=r(qE,":"),qE.forEach(t),Elr=i(va),J=n(va,"UL",{});var ee=s(J);XT=n(ee,"LI",{});var d8e=s(XT);Bpe=n(d8e,"STRONG",{});var Qgt=s(Bpe);ylr=r(Qgt,"albert"),Qgt.forEach(t),wlr=r(d8e," \u2014 "),YG=n(d8e,"A",{href:!0});var Hgt=s(YG);Alr=r(Hgt,"TFAlbertForMaskedLM"),Hgt.forEach(t),Llr=r(d8e," (ALBERT model)"),d8e.forEach(t),Blr=i(ee),VT=n(ee,"LI",{});var c8e=s(VT);xpe=n(c8e,"STRONG",{});var Ugt=s(xpe);xlr=r(Ugt,"bert"),Ugt.forEach(t),klr=r(c8e," \u2014 "),KG=n(c8e,"A",{href:!0});var Jgt=s(KG);Rlr=r(Jgt,"TFBertForMaskedLM"),Jgt.forEach(t),Slr=r(c8e," (BERT model)"),c8e.forEach(t),Plr=i(ee),zT=n(ee,"LI",{});var f8e=s(zT);kpe=n(f8e,"STRONG",{});var Ygt=s(kpe);$lr=r(Ygt,"camembert"),Ygt.forEach(t),Ilr=r(f8e," \u2014 "),ZG=n(f8e,"A",{href:!0});var Kgt=s(ZG);Nlr=r(Kgt,"TFCamembertForMaskedLM"),Kgt.forEach(t),Dlr=r(f8e," (CamemBERT model)"),f8e.forEach(t),jlr=i(ee),WT=n(ee,"LI",{});var m8e=s(WT);Rpe=n(m8e,"STRONG",{});var Zgt=s(Rpe);qlr=r(Zgt,"convbert"),Zgt.forEach(t),Glr=r(m8e," \u2014 "),eO=n(m8e,"A",{href:!0});var eht=s(eO);Olr=r(eht,"TFConvBertForMaskedLM"),eht.forEach(t),Xlr=r(m8e," (ConvBERT model)"),m8e.forEach(t),Vlr=i(ee),QT=n(ee,"LI",{});var g8e=s(QT);Spe=n(g8e,"STRONG",{});var oht=s(Spe);zlr=r(oht,"deberta"),oht.forEach(t),Wlr=r(g8e," \u2014 "),oO=n(g8e,"A",{href:!0});var rht=s(oO);Qlr=r(rht,"TFDebertaForMaskedLM"),rht.forEach(t),Hlr=r(g8e," (DeBERTa model)"),g8e.forEach(t),Ulr=i(ee),HT=n(ee,"LI",{});var h8e=s(HT);Ppe=n(h8e,"STRONG",{});var tht=s(Ppe);Jlr=r(tht,"deberta-v2"),tht.forEach(t),Ylr=r(h8e," \u2014 "),rO=n(h8e,"A",{href:!0});var aht=s(rO);Klr=r(aht,"TFDebertaV2ForMaskedLM"),aht.forEach(t),Zlr=r(h8e," (DeBERTa-v2 model)"),h8e.forEach(t),eir=i(ee),UT=n(ee,"LI",{});var p8e=s(UT);$pe=n(p8e,"STRONG",{});var nht=s($pe);oir=r(nht,"distilbert"),nht.forEach(t),rir=r(p8e," \u2014 "),tO=n(p8e,"A",{href:!0});var sht=s(tO);tir=r(sht,"TFDistilBertForMaskedLM"),sht.forEach(t),air=r(p8e," (DistilBERT model)"),p8e.forEach(t),nir=i(ee),JT=n(ee,"LI",{});var _8e=s(JT);Ipe=n(_8e,"STRONG",{});var lht=s(Ipe);sir=r(lht,"electra"),lht.forEach(t),lir=r(_8e," \u2014 "),aO=n(_8e,"A",{href:!0});var iht=s(aO);iir=r(iht,"TFElectraForMaskedLM"),iht.forEach(t),dir=r(_8e," (ELECTRA model)"),_8e.forEach(t),cir=i(ee),YT=n(ee,"LI",{});var u8e=s(YT);Npe=n(u8e,"STRONG",{});var dht=s(Npe);fir=r(dht,"flaubert"),dht.forEach(t),mir=r(u8e," \u2014 "),nO=n(u8e,"A",{href:!0});var cht=s(nO);gir=r(cht,"TFFlaubertWithLMHeadModel"),cht.forEach(t),hir=r(u8e," (FlauBERT model)"),u8e.forEach(t),pir=i(ee),KT=n(ee,"LI",{});var b8e=s(KT);Dpe=n(b8e,"STRONG",{});var fht=s(Dpe);_ir=r(fht,"funnel"),fht.forEach(t),uir=r(b8e," \u2014 "),sO=n(b8e,"A",{href:!0});var mht=s(sO);bir=r(mht,"TFFunnelForMaskedLM"),mht.forEach(t),vir=r(b8e," (Funnel Transformer model)"),b8e.forEach(t),Tir=i(ee),ZT=n(ee,"LI",{});var v8e=s(ZT);jpe=n(v8e,"STRONG",{});var ght=s(jpe);Fir=r(ght,"layoutlm"),ght.forEach(t),Cir=r(v8e," \u2014 "),lO=n(v8e,"A",{href:!0});var hht=s(lO);Mir=r(hht,"TFLayoutLMForMaskedLM"),hht.forEach(t),Eir=r(v8e," (LayoutLM model)"),v8e.forEach(t),yir=i(ee),eF=n(ee,"LI",{});var T8e=s(eF);qpe=n(T8e,"STRONG",{});var pht=s(qpe);wir=r(pht,"longformer"),pht.forEach(t),Air=r(T8e," \u2014 "),iO=n(T8e,"A",{href:!0});var _ht=s(iO);Lir=r(_ht,"TFLongformerForMaskedLM"),_ht.forEach(t),Bir=r(T8e," (Longformer model)"),T8e.forEach(t),xir=i(ee),oF=n(ee,"LI",{});var F8e=s(oF);Gpe=n(F8e,"STRONG",{});var uht=s(Gpe);kir=r(uht,"mobilebert"),uht.forEach(t),Rir=r(F8e," \u2014 "),dO=n(F8e,"A",{href:!0});var bht=s(dO);Sir=r(bht,"TFMobileBertForMaskedLM"),bht.forEach(t),Pir=r(F8e," (MobileBERT model)"),F8e.forEach(t),$ir=i(ee),rF=n(ee,"LI",{});var C8e=s(rF);Ope=n(C8e,"STRONG",{});var vht=s(Ope);Iir=r(vht,"mpnet"),vht.forEach(t),Nir=r(C8e," \u2014 "),cO=n(C8e,"A",{href:!0});var Tht=s(cO);Dir=r(Tht,"TFMPNetForMaskedLM"),Tht.forEach(t),jir=r(C8e," (MPNet model)"),C8e.forEach(t),qir=i(ee),tF=n(ee,"LI",{});var M8e=s(tF);Xpe=n(M8e,"STRONG",{});var Fht=s(Xpe);Gir=r(Fht,"rembert"),Fht.forEach(t),Oir=r(M8e," \u2014 "),fO=n(M8e,"A",{href:!0});var Cht=s(fO);Xir=r(Cht,"TFRemBertForMaskedLM"),Cht.forEach(t),Vir=r(M8e," (RemBERT model)"),M8e.forEach(t),zir=i(ee),aF=n(ee,"LI",{});var E8e=s(aF);Vpe=n(E8e,"STRONG",{});var Mht=s(Vpe);Wir=r(Mht,"roberta"),Mht.forEach(t),Qir=r(E8e," \u2014 "),mO=n(E8e,"A",{href:!0});var Eht=s(mO);Hir=r(Eht,"TFRobertaForMaskedLM"),Eht.forEach(t),Uir=r(E8e," (RoBERTa model)"),E8e.forEach(t),Jir=i(ee),nF=n(ee,"LI",{});var y8e=s(nF);zpe=n(y8e,"STRONG",{});var yht=s(zpe);Yir=r(yht,"roformer"),yht.forEach(t),Kir=r(y8e," \u2014 "),gO=n(y8e,"A",{href:!0});var wht=s(gO);Zir=r(wht,"TFRoFormerForMaskedLM"),wht.forEach(t),edr=r(y8e," (RoFormer model)"),y8e.forEach(t),odr=i(ee),sF=n(ee,"LI",{});var w8e=s(sF);Wpe=n(w8e,"STRONG",{});var Aht=s(Wpe);rdr=r(Aht,"tapas"),Aht.forEach(t),tdr=r(w8e," \u2014 "),hO=n(w8e,"A",{href:!0});var Lht=s(hO);adr=r(Lht,"TFTapasForMaskedLM"),Lht.forEach(t),ndr=r(w8e," (TAPAS model)"),w8e.forEach(t),sdr=i(ee),lF=n(ee,"LI",{});var A8e=s(lF);Qpe=n(A8e,"STRONG",{});var Bht=s(Qpe);ldr=r(Bht,"xlm"),Bht.forEach(t),idr=r(A8e," \u2014 "),pO=n(A8e,"A",{href:!0});var xht=s(pO);ddr=r(xht,"TFXLMWithLMHeadModel"),xht.forEach(t),cdr=r(A8e," (XLM model)"),A8e.forEach(t),fdr=i(ee),iF=n(ee,"LI",{});var L8e=s(iF);Hpe=n(L8e,"STRONG",{});var kht=s(Hpe);mdr=r(kht,"xlm-roberta"),kht.forEach(t),gdr=r(L8e," \u2014 "),_O=n(L8e,"A",{href:!0});var Rht=s(_O);hdr=r(Rht,"TFXLMRobertaForMaskedLM"),Rht.forEach(t),pdr=r(L8e," (XLM-RoBERTa model)"),L8e.forEach(t),ee.forEach(t),_dr=i(va),Upe=n(va,"P",{});var Sht=s(Upe);udr=r(Sht,"Examples:"),Sht.forEach(t),bdr=i(va),m(M0.$$.fragment,va),va.forEach(t),Ql.forEach(t),MRe=i(c),Ac=n(c,"H2",{class:!0});var $Pe=s(Ac);dF=n($Pe,"A",{id:!0,class:!0,href:!0});var Pht=s(dF);Jpe=n(Pht,"SPAN",{});var $ht=s(Jpe);m(E0.$$.fragment,$ht),$ht.forEach(t),Pht.forEach(t),vdr=i($Pe),Ype=n($Pe,"SPAN",{});var Iht=s(Ype);Tdr=r(Iht,"TFAutoModelForSeq2SeqLM"),Iht.forEach(t),$Pe.forEach(t),ERe=i(c),Er=n(c,"DIV",{class:!0});var Ul=s(Er);m(y0.$$.fragment,Ul),Fdr=i(Ul),Lc=n(Ul,"P",{});var rQ=s(Lc);Cdr=r(rQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Kpe=n(rQ,"CODE",{});var Nht=s(Kpe);Mdr=r(Nht,"from_pretrained()"),Nht.forEach(t),Edr=r(rQ,"class method or the "),Zpe=n(rQ,"CODE",{});var Dht=s(Zpe);ydr=r(Dht,"from_config()"),Dht.forEach(t),wdr=r(rQ,`class
method.`),rQ.forEach(t),Adr=i(Ul),w0=n(Ul,"P",{});var IPe=s(w0);Ldr=r(IPe,"This class cannot be instantiated directly using "),e_e=n(IPe,"CODE",{});var jht=s(e_e);Bdr=r(jht,"__init__()"),jht.forEach(t),xdr=r(IPe," (throws an error)."),IPe.forEach(t),kdr=i(Ul),bt=n(Ul,"DIV",{class:!0});var Jl=s(bt);m(A0.$$.fragment,Jl),Rdr=i(Jl),o_e=n(Jl,"P",{});var qht=s(o_e);Sdr=r(qht,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),qht.forEach(t),Pdr=i(Jl),Bc=n(Jl,"P",{});var tQ=s(Bc);$dr=r(tQ,`Note:
Loading a model from its configuration file does `),r_e=n(tQ,"STRONG",{});var Ght=s(r_e);Idr=r(Ght,"not"),Ght.forEach(t),Ndr=r(tQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),t_e=n(tQ,"CODE",{});var Oht=s(t_e);Ddr=r(Oht,"from_pretrained()"),Oht.forEach(t),jdr=r(tQ,"to load the model weights."),tQ.forEach(t),qdr=i(Jl),a_e=n(Jl,"P",{});var Xht=s(a_e);Gdr=r(Xht,"Examples:"),Xht.forEach(t),Odr=i(Jl),m(L0.$$.fragment,Jl),Jl.forEach(t),Xdr=i(Ul),vo=n(Ul,"DIV",{class:!0});var Ta=s(vo);m(B0.$$.fragment,Ta),Vdr=i(Ta),n_e=n(Ta,"P",{});var Vht=s(n_e);zdr=r(Vht,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Vht.forEach(t),Wdr=i(Ta),Fn=n(Ta,"P",{});var GE=s(Fn);Qdr=r(GE,"The model class to instantiate is selected based on the "),s_e=n(GE,"CODE",{});var zht=s(s_e);Hdr=r(zht,"model_type"),zht.forEach(t),Udr=r(GE,` property of the config object (either
passed as an argument or loaded from `),l_e=n(GE,"CODE",{});var Wht=s(l_e);Jdr=r(Wht,"pretrained_model_name_or_path"),Wht.forEach(t),Ydr=r(GE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(GE,"CODE",{});var Qht=s(i_e);Kdr=r(Qht,"pretrained_model_name_or_path"),Qht.forEach(t),Zdr=r(GE,":"),GE.forEach(t),ecr=i(Ta),_e=n(Ta,"UL",{});var ye=s(_e);cF=n(ye,"LI",{});var B8e=s(cF);d_e=n(B8e,"STRONG",{});var Hht=s(d_e);ocr=r(Hht,"bart"),Hht.forEach(t),rcr=r(B8e," \u2014 "),uO=n(B8e,"A",{href:!0});var Uht=s(uO);tcr=r(Uht,"TFBartForConditionalGeneration"),Uht.forEach(t),acr=r(B8e," (BART model)"),B8e.forEach(t),ncr=i(ye),fF=n(ye,"LI",{});var x8e=s(fF);c_e=n(x8e,"STRONG",{});var Jht=s(c_e);scr=r(Jht,"blenderbot"),Jht.forEach(t),lcr=r(x8e," \u2014 "),bO=n(x8e,"A",{href:!0});var Yht=s(bO);icr=r(Yht,"TFBlenderbotForConditionalGeneration"),Yht.forEach(t),dcr=r(x8e," (Blenderbot model)"),x8e.forEach(t),ccr=i(ye),mF=n(ye,"LI",{});var k8e=s(mF);f_e=n(k8e,"STRONG",{});var Kht=s(f_e);fcr=r(Kht,"blenderbot-small"),Kht.forEach(t),mcr=r(k8e," \u2014 "),vO=n(k8e,"A",{href:!0});var Zht=s(vO);gcr=r(Zht,"TFBlenderbotSmallForConditionalGeneration"),Zht.forEach(t),hcr=r(k8e," (BlenderbotSmall model)"),k8e.forEach(t),pcr=i(ye),gF=n(ye,"LI",{});var R8e=s(gF);m_e=n(R8e,"STRONG",{});var ept=s(m_e);_cr=r(ept,"encoder-decoder"),ept.forEach(t),ucr=r(R8e," \u2014 "),TO=n(R8e,"A",{href:!0});var opt=s(TO);bcr=r(opt,"TFEncoderDecoderModel"),opt.forEach(t),vcr=r(R8e," (Encoder decoder model)"),R8e.forEach(t),Tcr=i(ye),hF=n(ye,"LI",{});var S8e=s(hF);g_e=n(S8e,"STRONG",{});var rpt=s(g_e);Fcr=r(rpt,"led"),rpt.forEach(t),Ccr=r(S8e," \u2014 "),FO=n(S8e,"A",{href:!0});var tpt=s(FO);Mcr=r(tpt,"TFLEDForConditionalGeneration"),tpt.forEach(t),Ecr=r(S8e," (LED model)"),S8e.forEach(t),ycr=i(ye),pF=n(ye,"LI",{});var P8e=s(pF);h_e=n(P8e,"STRONG",{});var apt=s(h_e);wcr=r(apt,"marian"),apt.forEach(t),Acr=r(P8e," \u2014 "),CO=n(P8e,"A",{href:!0});var npt=s(CO);Lcr=r(npt,"TFMarianMTModel"),npt.forEach(t),Bcr=r(P8e," (Marian model)"),P8e.forEach(t),xcr=i(ye),_F=n(ye,"LI",{});var $8e=s(_F);p_e=n($8e,"STRONG",{});var spt=s(p_e);kcr=r(spt,"mbart"),spt.forEach(t),Rcr=r($8e," \u2014 "),MO=n($8e,"A",{href:!0});var lpt=s(MO);Scr=r(lpt,"TFMBartForConditionalGeneration"),lpt.forEach(t),Pcr=r($8e," (mBART model)"),$8e.forEach(t),$cr=i(ye),uF=n(ye,"LI",{});var I8e=s(uF);__e=n(I8e,"STRONG",{});var ipt=s(__e);Icr=r(ipt,"mt5"),ipt.forEach(t),Ncr=r(I8e," \u2014 "),EO=n(I8e,"A",{href:!0});var dpt=s(EO);Dcr=r(dpt,"TFMT5ForConditionalGeneration"),dpt.forEach(t),jcr=r(I8e," (mT5 model)"),I8e.forEach(t),qcr=i(ye),bF=n(ye,"LI",{});var N8e=s(bF);u_e=n(N8e,"STRONG",{});var cpt=s(u_e);Gcr=r(cpt,"pegasus"),cpt.forEach(t),Ocr=r(N8e," \u2014 "),yO=n(N8e,"A",{href:!0});var fpt=s(yO);Xcr=r(fpt,"TFPegasusForConditionalGeneration"),fpt.forEach(t),Vcr=r(N8e," (Pegasus model)"),N8e.forEach(t),zcr=i(ye),vF=n(ye,"LI",{});var D8e=s(vF);b_e=n(D8e,"STRONG",{});var mpt=s(b_e);Wcr=r(mpt,"t5"),mpt.forEach(t),Qcr=r(D8e," \u2014 "),wO=n(D8e,"A",{href:!0});var gpt=s(wO);Hcr=r(gpt,"TFT5ForConditionalGeneration"),gpt.forEach(t),Ucr=r(D8e," (T5 model)"),D8e.forEach(t),ye.forEach(t),Jcr=i(Ta),v_e=n(Ta,"P",{});var hpt=s(v_e);Ycr=r(hpt,"Examples:"),hpt.forEach(t),Kcr=i(Ta),m(x0.$$.fragment,Ta),Ta.forEach(t),Ul.forEach(t),yRe=i(c),xc=n(c,"H2",{class:!0});var NPe=s(xc);TF=n(NPe,"A",{id:!0,class:!0,href:!0});var ppt=s(TF);T_e=n(ppt,"SPAN",{});var _pt=s(T_e);m(k0.$$.fragment,_pt),_pt.forEach(t),ppt.forEach(t),Zcr=i(NPe),F_e=n(NPe,"SPAN",{});var upt=s(F_e);efr=r(upt,"TFAutoModelForSequenceClassification"),upt.forEach(t),NPe.forEach(t),wRe=i(c),yr=n(c,"DIV",{class:!0});var Yl=s(yr);m(R0.$$.fragment,Yl),ofr=i(Yl),kc=n(Yl,"P",{});var aQ=s(kc);rfr=r(aQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),C_e=n(aQ,"CODE",{});var bpt=s(C_e);tfr=r(bpt,"from_pretrained()"),bpt.forEach(t),afr=r(aQ,"class method or the "),M_e=n(aQ,"CODE",{});var vpt=s(M_e);nfr=r(vpt,"from_config()"),vpt.forEach(t),sfr=r(aQ,`class
method.`),aQ.forEach(t),lfr=i(Yl),S0=n(Yl,"P",{});var DPe=s(S0);ifr=r(DPe,"This class cannot be instantiated directly using "),E_e=n(DPe,"CODE",{});var Tpt=s(E_e);dfr=r(Tpt,"__init__()"),Tpt.forEach(t),cfr=r(DPe," (throws an error)."),DPe.forEach(t),ffr=i(Yl),vt=n(Yl,"DIV",{class:!0});var Kl=s(vt);m(P0.$$.fragment,Kl),mfr=i(Kl),y_e=n(Kl,"P",{});var Fpt=s(y_e);gfr=r(Fpt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Fpt.forEach(t),hfr=i(Kl),Rc=n(Kl,"P",{});var nQ=s(Rc);pfr=r(nQ,`Note:
Loading a model from its configuration file does `),w_e=n(nQ,"STRONG",{});var Cpt=s(w_e);_fr=r(Cpt,"not"),Cpt.forEach(t),ufr=r(nQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),A_e=n(nQ,"CODE",{});var Mpt=s(A_e);bfr=r(Mpt,"from_pretrained()"),Mpt.forEach(t),vfr=r(nQ,"to load the model weights."),nQ.forEach(t),Tfr=i(Kl),L_e=n(Kl,"P",{});var Ept=s(L_e);Ffr=r(Ept,"Examples:"),Ept.forEach(t),Cfr=i(Kl),m($0.$$.fragment,Kl),Kl.forEach(t),Mfr=i(Yl),To=n(Yl,"DIV",{class:!0});var Fa=s(To);m(I0.$$.fragment,Fa),Efr=i(Fa),B_e=n(Fa,"P",{});var ypt=s(B_e);yfr=r(ypt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ypt.forEach(t),wfr=i(Fa),Cn=n(Fa,"P",{});var OE=s(Cn);Afr=r(OE,"The model class to instantiate is selected based on the "),x_e=n(OE,"CODE",{});var wpt=s(x_e);Lfr=r(wpt,"model_type"),wpt.forEach(t),Bfr=r(OE,` property of the config object (either
passed as an argument or loaded from `),k_e=n(OE,"CODE",{});var Apt=s(k_e);xfr=r(Apt,"pretrained_model_name_or_path"),Apt.forEach(t),kfr=r(OE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R_e=n(OE,"CODE",{});var Lpt=s(R_e);Rfr=r(Lpt,"pretrained_model_name_or_path"),Lpt.forEach(t),Sfr=r(OE,":"),OE.forEach(t),Pfr=i(Fa),V=n(Fa,"UL",{});var W=s(V);FF=n(W,"LI",{});var j8e=s(FF);S_e=n(j8e,"STRONG",{});var Bpt=s(S_e);$fr=r(Bpt,"albert"),Bpt.forEach(t),Ifr=r(j8e," \u2014 "),AO=n(j8e,"A",{href:!0});var xpt=s(AO);Nfr=r(xpt,"TFAlbertForSequenceClassification"),xpt.forEach(t),Dfr=r(j8e," (ALBERT model)"),j8e.forEach(t),jfr=i(W),CF=n(W,"LI",{});var q8e=s(CF);P_e=n(q8e,"STRONG",{});var kpt=s(P_e);qfr=r(kpt,"bert"),kpt.forEach(t),Gfr=r(q8e," \u2014 "),LO=n(q8e,"A",{href:!0});var Rpt=s(LO);Ofr=r(Rpt,"TFBertForSequenceClassification"),Rpt.forEach(t),Xfr=r(q8e," (BERT model)"),q8e.forEach(t),Vfr=i(W),MF=n(W,"LI",{});var G8e=s(MF);$_e=n(G8e,"STRONG",{});var Spt=s($_e);zfr=r(Spt,"camembert"),Spt.forEach(t),Wfr=r(G8e," \u2014 "),BO=n(G8e,"A",{href:!0});var Ppt=s(BO);Qfr=r(Ppt,"TFCamembertForSequenceClassification"),Ppt.forEach(t),Hfr=r(G8e," (CamemBERT model)"),G8e.forEach(t),Ufr=i(W),EF=n(W,"LI",{});var O8e=s(EF);I_e=n(O8e,"STRONG",{});var $pt=s(I_e);Jfr=r($pt,"convbert"),$pt.forEach(t),Yfr=r(O8e," \u2014 "),xO=n(O8e,"A",{href:!0});var Ipt=s(xO);Kfr=r(Ipt,"TFConvBertForSequenceClassification"),Ipt.forEach(t),Zfr=r(O8e," (ConvBERT model)"),O8e.forEach(t),emr=i(W),yF=n(W,"LI",{});var X8e=s(yF);N_e=n(X8e,"STRONG",{});var Npt=s(N_e);omr=r(Npt,"ctrl"),Npt.forEach(t),rmr=r(X8e," \u2014 "),kO=n(X8e,"A",{href:!0});var Dpt=s(kO);tmr=r(Dpt,"TFCTRLForSequenceClassification"),Dpt.forEach(t),amr=r(X8e," (CTRL model)"),X8e.forEach(t),nmr=i(W),wF=n(W,"LI",{});var V8e=s(wF);D_e=n(V8e,"STRONG",{});var jpt=s(D_e);smr=r(jpt,"deberta"),jpt.forEach(t),lmr=r(V8e," \u2014 "),RO=n(V8e,"A",{href:!0});var qpt=s(RO);imr=r(qpt,"TFDebertaForSequenceClassification"),qpt.forEach(t),dmr=r(V8e," (DeBERTa model)"),V8e.forEach(t),cmr=i(W),AF=n(W,"LI",{});var z8e=s(AF);j_e=n(z8e,"STRONG",{});var Gpt=s(j_e);fmr=r(Gpt,"deberta-v2"),Gpt.forEach(t),mmr=r(z8e," \u2014 "),SO=n(z8e,"A",{href:!0});var Opt=s(SO);gmr=r(Opt,"TFDebertaV2ForSequenceClassification"),Opt.forEach(t),hmr=r(z8e," (DeBERTa-v2 model)"),z8e.forEach(t),pmr=i(W),LF=n(W,"LI",{});var W8e=s(LF);q_e=n(W8e,"STRONG",{});var Xpt=s(q_e);_mr=r(Xpt,"distilbert"),Xpt.forEach(t),umr=r(W8e," \u2014 "),PO=n(W8e,"A",{href:!0});var Vpt=s(PO);bmr=r(Vpt,"TFDistilBertForSequenceClassification"),Vpt.forEach(t),vmr=r(W8e," (DistilBERT model)"),W8e.forEach(t),Tmr=i(W),BF=n(W,"LI",{});var Q8e=s(BF);G_e=n(Q8e,"STRONG",{});var zpt=s(G_e);Fmr=r(zpt,"electra"),zpt.forEach(t),Cmr=r(Q8e," \u2014 "),$O=n(Q8e,"A",{href:!0});var Wpt=s($O);Mmr=r(Wpt,"TFElectraForSequenceClassification"),Wpt.forEach(t),Emr=r(Q8e," (ELECTRA model)"),Q8e.forEach(t),ymr=i(W),xF=n(W,"LI",{});var H8e=s(xF);O_e=n(H8e,"STRONG",{});var Qpt=s(O_e);wmr=r(Qpt,"flaubert"),Qpt.forEach(t),Amr=r(H8e," \u2014 "),IO=n(H8e,"A",{href:!0});var Hpt=s(IO);Lmr=r(Hpt,"TFFlaubertForSequenceClassification"),Hpt.forEach(t),Bmr=r(H8e," (FlauBERT model)"),H8e.forEach(t),xmr=i(W),kF=n(W,"LI",{});var U8e=s(kF);X_e=n(U8e,"STRONG",{});var Upt=s(X_e);kmr=r(Upt,"funnel"),Upt.forEach(t),Rmr=r(U8e," \u2014 "),NO=n(U8e,"A",{href:!0});var Jpt=s(NO);Smr=r(Jpt,"TFFunnelForSequenceClassification"),Jpt.forEach(t),Pmr=r(U8e," (Funnel Transformer model)"),U8e.forEach(t),$mr=i(W),RF=n(W,"LI",{});var J8e=s(RF);V_e=n(J8e,"STRONG",{});var Ypt=s(V_e);Imr=r(Ypt,"gpt2"),Ypt.forEach(t),Nmr=r(J8e," \u2014 "),DO=n(J8e,"A",{href:!0});var Kpt=s(DO);Dmr=r(Kpt,"TFGPT2ForSequenceClassification"),Kpt.forEach(t),jmr=r(J8e," (OpenAI GPT-2 model)"),J8e.forEach(t),qmr=i(W),SF=n(W,"LI",{});var Y8e=s(SF);z_e=n(Y8e,"STRONG",{});var Zpt=s(z_e);Gmr=r(Zpt,"layoutlm"),Zpt.forEach(t),Omr=r(Y8e," \u2014 "),jO=n(Y8e,"A",{href:!0});var e_t=s(jO);Xmr=r(e_t,"TFLayoutLMForSequenceClassification"),e_t.forEach(t),Vmr=r(Y8e," (LayoutLM model)"),Y8e.forEach(t),zmr=i(W),PF=n(W,"LI",{});var K8e=s(PF);W_e=n(K8e,"STRONG",{});var o_t=s(W_e);Wmr=r(o_t,"longformer"),o_t.forEach(t),Qmr=r(K8e," \u2014 "),qO=n(K8e,"A",{href:!0});var r_t=s(qO);Hmr=r(r_t,"TFLongformerForSequenceClassification"),r_t.forEach(t),Umr=r(K8e," (Longformer model)"),K8e.forEach(t),Jmr=i(W),$F=n(W,"LI",{});var Z8e=s($F);Q_e=n(Z8e,"STRONG",{});var t_t=s(Q_e);Ymr=r(t_t,"mobilebert"),t_t.forEach(t),Kmr=r(Z8e," \u2014 "),GO=n(Z8e,"A",{href:!0});var a_t=s(GO);Zmr=r(a_t,"TFMobileBertForSequenceClassification"),a_t.forEach(t),egr=r(Z8e," (MobileBERT model)"),Z8e.forEach(t),ogr=i(W),IF=n(W,"LI",{});var e9e=s(IF);H_e=n(e9e,"STRONG",{});var n_t=s(H_e);rgr=r(n_t,"mpnet"),n_t.forEach(t),tgr=r(e9e," \u2014 "),OO=n(e9e,"A",{href:!0});var s_t=s(OO);agr=r(s_t,"TFMPNetForSequenceClassification"),s_t.forEach(t),ngr=r(e9e," (MPNet model)"),e9e.forEach(t),sgr=i(W),NF=n(W,"LI",{});var o9e=s(NF);U_e=n(o9e,"STRONG",{});var l_t=s(U_e);lgr=r(l_t,"openai-gpt"),l_t.forEach(t),igr=r(o9e," \u2014 "),XO=n(o9e,"A",{href:!0});var i_t=s(XO);dgr=r(i_t,"TFOpenAIGPTForSequenceClassification"),i_t.forEach(t),cgr=r(o9e," (OpenAI GPT model)"),o9e.forEach(t),fgr=i(W),DF=n(W,"LI",{});var r9e=s(DF);J_e=n(r9e,"STRONG",{});var d_t=s(J_e);mgr=r(d_t,"rembert"),d_t.forEach(t),ggr=r(r9e," \u2014 "),VO=n(r9e,"A",{href:!0});var c_t=s(VO);hgr=r(c_t,"TFRemBertForSequenceClassification"),c_t.forEach(t),pgr=r(r9e," (RemBERT model)"),r9e.forEach(t),_gr=i(W),jF=n(W,"LI",{});var t9e=s(jF);Y_e=n(t9e,"STRONG",{});var f_t=s(Y_e);ugr=r(f_t,"roberta"),f_t.forEach(t),bgr=r(t9e," \u2014 "),zO=n(t9e,"A",{href:!0});var m_t=s(zO);vgr=r(m_t,"TFRobertaForSequenceClassification"),m_t.forEach(t),Tgr=r(t9e," (RoBERTa model)"),t9e.forEach(t),Fgr=i(W),qF=n(W,"LI",{});var a9e=s(qF);K_e=n(a9e,"STRONG",{});var g_t=s(K_e);Cgr=r(g_t,"roformer"),g_t.forEach(t),Mgr=r(a9e," \u2014 "),WO=n(a9e,"A",{href:!0});var h_t=s(WO);Egr=r(h_t,"TFRoFormerForSequenceClassification"),h_t.forEach(t),ygr=r(a9e," (RoFormer model)"),a9e.forEach(t),wgr=i(W),GF=n(W,"LI",{});var n9e=s(GF);Z_e=n(n9e,"STRONG",{});var p_t=s(Z_e);Agr=r(p_t,"tapas"),p_t.forEach(t),Lgr=r(n9e," \u2014 "),QO=n(n9e,"A",{href:!0});var __t=s(QO);Bgr=r(__t,"TFTapasForSequenceClassification"),__t.forEach(t),xgr=r(n9e," (TAPAS model)"),n9e.forEach(t),kgr=i(W),OF=n(W,"LI",{});var s9e=s(OF);eue=n(s9e,"STRONG",{});var u_t=s(eue);Rgr=r(u_t,"transfo-xl"),u_t.forEach(t),Sgr=r(s9e," \u2014 "),HO=n(s9e,"A",{href:!0});var b_t=s(HO);Pgr=r(b_t,"TFTransfoXLForSequenceClassification"),b_t.forEach(t),$gr=r(s9e," (Transformer-XL model)"),s9e.forEach(t),Igr=i(W),XF=n(W,"LI",{});var l9e=s(XF);oue=n(l9e,"STRONG",{});var v_t=s(oue);Ngr=r(v_t,"xlm"),v_t.forEach(t),Dgr=r(l9e," \u2014 "),UO=n(l9e,"A",{href:!0});var T_t=s(UO);jgr=r(T_t,"TFXLMForSequenceClassification"),T_t.forEach(t),qgr=r(l9e," (XLM model)"),l9e.forEach(t),Ggr=i(W),VF=n(W,"LI",{});var i9e=s(VF);rue=n(i9e,"STRONG",{});var F_t=s(rue);Ogr=r(F_t,"xlm-roberta"),F_t.forEach(t),Xgr=r(i9e," \u2014 "),JO=n(i9e,"A",{href:!0});var C_t=s(JO);Vgr=r(C_t,"TFXLMRobertaForSequenceClassification"),C_t.forEach(t),zgr=r(i9e," (XLM-RoBERTa model)"),i9e.forEach(t),Wgr=i(W),zF=n(W,"LI",{});var d9e=s(zF);tue=n(d9e,"STRONG",{});var M_t=s(tue);Qgr=r(M_t,"xlnet"),M_t.forEach(t),Hgr=r(d9e," \u2014 "),YO=n(d9e,"A",{href:!0});var E_t=s(YO);Ugr=r(E_t,"TFXLNetForSequenceClassification"),E_t.forEach(t),Jgr=r(d9e," (XLNet model)"),d9e.forEach(t),W.forEach(t),Ygr=i(Fa),aue=n(Fa,"P",{});var y_t=s(aue);Kgr=r(y_t,"Examples:"),y_t.forEach(t),Zgr=i(Fa),m(N0.$$.fragment,Fa),Fa.forEach(t),Yl.forEach(t),ARe=i(c),Sc=n(c,"H2",{class:!0});var jPe=s(Sc);WF=n(jPe,"A",{id:!0,class:!0,href:!0});var w_t=s(WF);nue=n(w_t,"SPAN",{});var A_t=s(nue);m(D0.$$.fragment,A_t),A_t.forEach(t),w_t.forEach(t),ehr=i(jPe),sue=n(jPe,"SPAN",{});var L_t=s(sue);ohr=r(L_t,"TFAutoModelForMultipleChoice"),L_t.forEach(t),jPe.forEach(t),LRe=i(c),wr=n(c,"DIV",{class:!0});var Zl=s(wr);m(j0.$$.fragment,Zl),rhr=i(Zl),Pc=n(Zl,"P",{});var sQ=s(Pc);thr=r(sQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lue=n(sQ,"CODE",{});var B_t=s(lue);ahr=r(B_t,"from_pretrained()"),B_t.forEach(t),nhr=r(sQ,"class method or the "),iue=n(sQ,"CODE",{});var x_t=s(iue);shr=r(x_t,"from_config()"),x_t.forEach(t),lhr=r(sQ,`class
method.`),sQ.forEach(t),ihr=i(Zl),q0=n(Zl,"P",{});var qPe=s(q0);dhr=r(qPe,"This class cannot be instantiated directly using "),due=n(qPe,"CODE",{});var k_t=s(due);chr=r(k_t,"__init__()"),k_t.forEach(t),fhr=r(qPe," (throws an error)."),qPe.forEach(t),mhr=i(Zl),Tt=n(Zl,"DIV",{class:!0});var ei=s(Tt);m(G0.$$.fragment,ei),ghr=i(ei),cue=n(ei,"P",{});var R_t=s(cue);hhr=r(R_t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),R_t.forEach(t),phr=i(ei),$c=n(ei,"P",{});var lQ=s($c);_hr=r(lQ,`Note:
Loading a model from its configuration file does `),fue=n(lQ,"STRONG",{});var S_t=s(fue);uhr=r(S_t,"not"),S_t.forEach(t),bhr=r(lQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),mue=n(lQ,"CODE",{});var P_t=s(mue);vhr=r(P_t,"from_pretrained()"),P_t.forEach(t),Thr=r(lQ,"to load the model weights."),lQ.forEach(t),Fhr=i(ei),gue=n(ei,"P",{});var $_t=s(gue);Chr=r($_t,"Examples:"),$_t.forEach(t),Mhr=i(ei),m(O0.$$.fragment,ei),ei.forEach(t),Ehr=i(Zl),Fo=n(Zl,"DIV",{class:!0});var Ca=s(Fo);m(X0.$$.fragment,Ca),yhr=i(Ca),hue=n(Ca,"P",{});var I_t=s(hue);whr=r(I_t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),I_t.forEach(t),Ahr=i(Ca),Mn=n(Ca,"P",{});var XE=s(Mn);Lhr=r(XE,"The model class to instantiate is selected based on the "),pue=n(XE,"CODE",{});var N_t=s(pue);Bhr=r(N_t,"model_type"),N_t.forEach(t),xhr=r(XE,` property of the config object (either
passed as an argument or loaded from `),_ue=n(XE,"CODE",{});var D_t=s(_ue);khr=r(D_t,"pretrained_model_name_or_path"),D_t.forEach(t),Rhr=r(XE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uue=n(XE,"CODE",{});var j_t=s(uue);Shr=r(j_t,"pretrained_model_name_or_path"),j_t.forEach(t),Phr=r(XE,":"),XE.forEach(t),$hr=i(Ca),ae=n(Ca,"UL",{});var le=s(ae);QF=n(le,"LI",{});var c9e=s(QF);bue=n(c9e,"STRONG",{});var q_t=s(bue);Ihr=r(q_t,"albert"),q_t.forEach(t),Nhr=r(c9e," \u2014 "),KO=n(c9e,"A",{href:!0});var G_t=s(KO);Dhr=r(G_t,"TFAlbertForMultipleChoice"),G_t.forEach(t),jhr=r(c9e," (ALBERT model)"),c9e.forEach(t),qhr=i(le),HF=n(le,"LI",{});var f9e=s(HF);vue=n(f9e,"STRONG",{});var O_t=s(vue);Ghr=r(O_t,"bert"),O_t.forEach(t),Ohr=r(f9e," \u2014 "),ZO=n(f9e,"A",{href:!0});var X_t=s(ZO);Xhr=r(X_t,"TFBertForMultipleChoice"),X_t.forEach(t),Vhr=r(f9e," (BERT model)"),f9e.forEach(t),zhr=i(le),UF=n(le,"LI",{});var m9e=s(UF);Tue=n(m9e,"STRONG",{});var V_t=s(Tue);Whr=r(V_t,"camembert"),V_t.forEach(t),Qhr=r(m9e," \u2014 "),eX=n(m9e,"A",{href:!0});var z_t=s(eX);Hhr=r(z_t,"TFCamembertForMultipleChoice"),z_t.forEach(t),Uhr=r(m9e," (CamemBERT model)"),m9e.forEach(t),Jhr=i(le),JF=n(le,"LI",{});var g9e=s(JF);Fue=n(g9e,"STRONG",{});var W_t=s(Fue);Yhr=r(W_t,"convbert"),W_t.forEach(t),Khr=r(g9e," \u2014 "),oX=n(g9e,"A",{href:!0});var Q_t=s(oX);Zhr=r(Q_t,"TFConvBertForMultipleChoice"),Q_t.forEach(t),epr=r(g9e," (ConvBERT model)"),g9e.forEach(t),opr=i(le),YF=n(le,"LI",{});var h9e=s(YF);Cue=n(h9e,"STRONG",{});var H_t=s(Cue);rpr=r(H_t,"distilbert"),H_t.forEach(t),tpr=r(h9e," \u2014 "),rX=n(h9e,"A",{href:!0});var U_t=s(rX);apr=r(U_t,"TFDistilBertForMultipleChoice"),U_t.forEach(t),npr=r(h9e," (DistilBERT model)"),h9e.forEach(t),spr=i(le),KF=n(le,"LI",{});var p9e=s(KF);Mue=n(p9e,"STRONG",{});var J_t=s(Mue);lpr=r(J_t,"electra"),J_t.forEach(t),ipr=r(p9e," \u2014 "),tX=n(p9e,"A",{href:!0});var Y_t=s(tX);dpr=r(Y_t,"TFElectraForMultipleChoice"),Y_t.forEach(t),cpr=r(p9e," (ELECTRA model)"),p9e.forEach(t),fpr=i(le),ZF=n(le,"LI",{});var _9e=s(ZF);Eue=n(_9e,"STRONG",{});var K_t=s(Eue);mpr=r(K_t,"flaubert"),K_t.forEach(t),gpr=r(_9e," \u2014 "),aX=n(_9e,"A",{href:!0});var Z_t=s(aX);hpr=r(Z_t,"TFFlaubertForMultipleChoice"),Z_t.forEach(t),ppr=r(_9e," (FlauBERT model)"),_9e.forEach(t),_pr=i(le),eC=n(le,"LI",{});var u9e=s(eC);yue=n(u9e,"STRONG",{});var eut=s(yue);upr=r(eut,"funnel"),eut.forEach(t),bpr=r(u9e," \u2014 "),nX=n(u9e,"A",{href:!0});var out=s(nX);vpr=r(out,"TFFunnelForMultipleChoice"),out.forEach(t),Tpr=r(u9e," (Funnel Transformer model)"),u9e.forEach(t),Fpr=i(le),oC=n(le,"LI",{});var b9e=s(oC);wue=n(b9e,"STRONG",{});var rut=s(wue);Cpr=r(rut,"longformer"),rut.forEach(t),Mpr=r(b9e," \u2014 "),sX=n(b9e,"A",{href:!0});var tut=s(sX);Epr=r(tut,"TFLongformerForMultipleChoice"),tut.forEach(t),ypr=r(b9e," (Longformer model)"),b9e.forEach(t),wpr=i(le),rC=n(le,"LI",{});var v9e=s(rC);Aue=n(v9e,"STRONG",{});var aut=s(Aue);Apr=r(aut,"mobilebert"),aut.forEach(t),Lpr=r(v9e," \u2014 "),lX=n(v9e,"A",{href:!0});var nut=s(lX);Bpr=r(nut,"TFMobileBertForMultipleChoice"),nut.forEach(t),xpr=r(v9e," (MobileBERT model)"),v9e.forEach(t),kpr=i(le),tC=n(le,"LI",{});var T9e=s(tC);Lue=n(T9e,"STRONG",{});var sut=s(Lue);Rpr=r(sut,"mpnet"),sut.forEach(t),Spr=r(T9e," \u2014 "),iX=n(T9e,"A",{href:!0});var lut=s(iX);Ppr=r(lut,"TFMPNetForMultipleChoice"),lut.forEach(t),$pr=r(T9e," (MPNet model)"),T9e.forEach(t),Ipr=i(le),aC=n(le,"LI",{});var F9e=s(aC);Bue=n(F9e,"STRONG",{});var iut=s(Bue);Npr=r(iut,"rembert"),iut.forEach(t),Dpr=r(F9e," \u2014 "),dX=n(F9e,"A",{href:!0});var dut=s(dX);jpr=r(dut,"TFRemBertForMultipleChoice"),dut.forEach(t),qpr=r(F9e," (RemBERT model)"),F9e.forEach(t),Gpr=i(le),nC=n(le,"LI",{});var C9e=s(nC);xue=n(C9e,"STRONG",{});var cut=s(xue);Opr=r(cut,"roberta"),cut.forEach(t),Xpr=r(C9e," \u2014 "),cX=n(C9e,"A",{href:!0});var fut=s(cX);Vpr=r(fut,"TFRobertaForMultipleChoice"),fut.forEach(t),zpr=r(C9e," (RoBERTa model)"),C9e.forEach(t),Wpr=i(le),sC=n(le,"LI",{});var M9e=s(sC);kue=n(M9e,"STRONG",{});var mut=s(kue);Qpr=r(mut,"roformer"),mut.forEach(t),Hpr=r(M9e," \u2014 "),fX=n(M9e,"A",{href:!0});var gut=s(fX);Upr=r(gut,"TFRoFormerForMultipleChoice"),gut.forEach(t),Jpr=r(M9e," (RoFormer model)"),M9e.forEach(t),Ypr=i(le),lC=n(le,"LI",{});var E9e=s(lC);Rue=n(E9e,"STRONG",{});var hut=s(Rue);Kpr=r(hut,"xlm"),hut.forEach(t),Zpr=r(E9e," \u2014 "),mX=n(E9e,"A",{href:!0});var put=s(mX);e_r=r(put,"TFXLMForMultipleChoice"),put.forEach(t),o_r=r(E9e," (XLM model)"),E9e.forEach(t),r_r=i(le),iC=n(le,"LI",{});var y9e=s(iC);Sue=n(y9e,"STRONG",{});var _ut=s(Sue);t_r=r(_ut,"xlm-roberta"),_ut.forEach(t),a_r=r(y9e," \u2014 "),gX=n(y9e,"A",{href:!0});var uut=s(gX);n_r=r(uut,"TFXLMRobertaForMultipleChoice"),uut.forEach(t),s_r=r(y9e," (XLM-RoBERTa model)"),y9e.forEach(t),l_r=i(le),dC=n(le,"LI",{});var w9e=s(dC);Pue=n(w9e,"STRONG",{});var but=s(Pue);i_r=r(but,"xlnet"),but.forEach(t),d_r=r(w9e," \u2014 "),hX=n(w9e,"A",{href:!0});var vut=s(hX);c_r=r(vut,"TFXLNetForMultipleChoice"),vut.forEach(t),f_r=r(w9e," (XLNet model)"),w9e.forEach(t),le.forEach(t),m_r=i(Ca),$ue=n(Ca,"P",{});var Tut=s($ue);g_r=r(Tut,"Examples:"),Tut.forEach(t),h_r=i(Ca),m(V0.$$.fragment,Ca),Ca.forEach(t),Zl.forEach(t),BRe=i(c),Ic=n(c,"H2",{class:!0});var GPe=s(Ic);cC=n(GPe,"A",{id:!0,class:!0,href:!0});var Fut=s(cC);Iue=n(Fut,"SPAN",{});var Cut=s(Iue);m(z0.$$.fragment,Cut),Cut.forEach(t),Fut.forEach(t),p_r=i(GPe),Nue=n(GPe,"SPAN",{});var Mut=s(Nue);__r=r(Mut,"TFAutoModelForTableQuestionAnswering"),Mut.forEach(t),GPe.forEach(t),xRe=i(c),Ar=n(c,"DIV",{class:!0});var oi=s(Ar);m(W0.$$.fragment,oi),u_r=i(oi),Nc=n(oi,"P",{});var iQ=s(Nc);b_r=r(iQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Due=n(iQ,"CODE",{});var Eut=s(Due);v_r=r(Eut,"from_pretrained()"),Eut.forEach(t),T_r=r(iQ,"class method or the "),jue=n(iQ,"CODE",{});var yut=s(jue);F_r=r(yut,"from_config()"),yut.forEach(t),C_r=r(iQ,`class
method.`),iQ.forEach(t),M_r=i(oi),Q0=n(oi,"P",{});var OPe=s(Q0);E_r=r(OPe,"This class cannot be instantiated directly using "),que=n(OPe,"CODE",{});var wut=s(que);y_r=r(wut,"__init__()"),wut.forEach(t),w_r=r(OPe," (throws an error)."),OPe.forEach(t),A_r=i(oi),Ft=n(oi,"DIV",{class:!0});var ri=s(Ft);m(H0.$$.fragment,ri),L_r=i(ri),Gue=n(ri,"P",{});var Aut=s(Gue);B_r=r(Aut,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Aut.forEach(t),x_r=i(ri),Dc=n(ri,"P",{});var dQ=s(Dc);k_r=r(dQ,`Note:
Loading a model from its configuration file does `),Oue=n(dQ,"STRONG",{});var Lut=s(Oue);R_r=r(Lut,"not"),Lut.forEach(t),S_r=r(dQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xue=n(dQ,"CODE",{});var But=s(Xue);P_r=r(But,"from_pretrained()"),But.forEach(t),$_r=r(dQ,"to load the model weights."),dQ.forEach(t),I_r=i(ri),Vue=n(ri,"P",{});var xut=s(Vue);N_r=r(xut,"Examples:"),xut.forEach(t),D_r=i(ri),m(U0.$$.fragment,ri),ri.forEach(t),j_r=i(oi),Co=n(oi,"DIV",{class:!0});var Ma=s(Co);m(J0.$$.fragment,Ma),q_r=i(Ma),zue=n(Ma,"P",{});var kut=s(zue);G_r=r(kut,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),kut.forEach(t),O_r=i(Ma),En=n(Ma,"P",{});var VE=s(En);X_r=r(VE,"The model class to instantiate is selected based on the "),Wue=n(VE,"CODE",{});var Rut=s(Wue);V_r=r(Rut,"model_type"),Rut.forEach(t),z_r=r(VE,` property of the config object (either
passed as an argument or loaded from `),Que=n(VE,"CODE",{});var Sut=s(Que);W_r=r(Sut,"pretrained_model_name_or_path"),Sut.forEach(t),Q_r=r(VE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hue=n(VE,"CODE",{});var Put=s(Hue);H_r=r(Put,"pretrained_model_name_or_path"),Put.forEach(t),U_r=r(VE,":"),VE.forEach(t),J_r=i(Ma),Uue=n(Ma,"UL",{});var $ut=s(Uue);fC=n($ut,"LI",{});var A9e=s(fC);Jue=n(A9e,"STRONG",{});var Iut=s(Jue);Y_r=r(Iut,"tapas"),Iut.forEach(t),K_r=r(A9e," \u2014 "),pX=n(A9e,"A",{href:!0});var Nut=s(pX);Z_r=r(Nut,"TFTapasForQuestionAnswering"),Nut.forEach(t),eur=r(A9e," (TAPAS model)"),A9e.forEach(t),$ut.forEach(t),our=i(Ma),Yue=n(Ma,"P",{});var Dut=s(Yue);rur=r(Dut,"Examples:"),Dut.forEach(t),tur=i(Ma),m(Y0.$$.fragment,Ma),Ma.forEach(t),oi.forEach(t),kRe=i(c),jc=n(c,"H2",{class:!0});var XPe=s(jc);mC=n(XPe,"A",{id:!0,class:!0,href:!0});var jut=s(mC);Kue=n(jut,"SPAN",{});var qut=s(Kue);m(K0.$$.fragment,qut),qut.forEach(t),jut.forEach(t),aur=i(XPe),Zue=n(XPe,"SPAN",{});var Gut=s(Zue);nur=r(Gut,"TFAutoModelForTokenClassification"),Gut.forEach(t),XPe.forEach(t),RRe=i(c),Lr=n(c,"DIV",{class:!0});var ti=s(Lr);m(Z0.$$.fragment,ti),sur=i(ti),qc=n(ti,"P",{});var cQ=s(qc);lur=r(cQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),e5e=n(cQ,"CODE",{});var Out=s(e5e);iur=r(Out,"from_pretrained()"),Out.forEach(t),dur=r(cQ,"class method or the "),o5e=n(cQ,"CODE",{});var Xut=s(o5e);cur=r(Xut,"from_config()"),Xut.forEach(t),fur=r(cQ,`class
method.`),cQ.forEach(t),mur=i(ti),eL=n(ti,"P",{});var VPe=s(eL);gur=r(VPe,"This class cannot be instantiated directly using "),r5e=n(VPe,"CODE",{});var Vut=s(r5e);hur=r(Vut,"__init__()"),Vut.forEach(t),pur=r(VPe," (throws an error)."),VPe.forEach(t),_ur=i(ti),Ct=n(ti,"DIV",{class:!0});var ai=s(Ct);m(oL.$$.fragment,ai),uur=i(ai),t5e=n(ai,"P",{});var zut=s(t5e);bur=r(zut,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),zut.forEach(t),vur=i(ai),Gc=n(ai,"P",{});var fQ=s(Gc);Tur=r(fQ,`Note:
Loading a model from its configuration file does `),a5e=n(fQ,"STRONG",{});var Wut=s(a5e);Fur=r(Wut,"not"),Wut.forEach(t),Cur=r(fQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),n5e=n(fQ,"CODE",{});var Qut=s(n5e);Mur=r(Qut,"from_pretrained()"),Qut.forEach(t),Eur=r(fQ,"to load the model weights."),fQ.forEach(t),yur=i(ai),s5e=n(ai,"P",{});var Hut=s(s5e);wur=r(Hut,"Examples:"),Hut.forEach(t),Aur=i(ai),m(rL.$$.fragment,ai),ai.forEach(t),Lur=i(ti),Mo=n(ti,"DIV",{class:!0});var Ea=s(Mo);m(tL.$$.fragment,Ea),Bur=i(Ea),l5e=n(Ea,"P",{});var Uut=s(l5e);xur=r(Uut,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Uut.forEach(t),kur=i(Ea),yn=n(Ea,"P",{});var zE=s(yn);Rur=r(zE,"The model class to instantiate is selected based on the "),i5e=n(zE,"CODE",{});var Jut=s(i5e);Sur=r(Jut,"model_type"),Jut.forEach(t),Pur=r(zE,` property of the config object (either
passed as an argument or loaded from `),d5e=n(zE,"CODE",{});var Yut=s(d5e);$ur=r(Yut,"pretrained_model_name_or_path"),Yut.forEach(t),Iur=r(zE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c5e=n(zE,"CODE",{});var Kut=s(c5e);Nur=r(Kut,"pretrained_model_name_or_path"),Kut.forEach(t),Dur=r(zE,":"),zE.forEach(t),jur=i(Ea),Y=n(Ea,"UL",{});var oe=s(Y);gC=n(oe,"LI",{});var L9e=s(gC);f5e=n(L9e,"STRONG",{});var Zut=s(f5e);qur=r(Zut,"albert"),Zut.forEach(t),Gur=r(L9e," \u2014 "),_X=n(L9e,"A",{href:!0});var e5t=s(_X);Our=r(e5t,"TFAlbertForTokenClassification"),e5t.forEach(t),Xur=r(L9e," (ALBERT model)"),L9e.forEach(t),Vur=i(oe),hC=n(oe,"LI",{});var B9e=s(hC);m5e=n(B9e,"STRONG",{});var o5t=s(m5e);zur=r(o5t,"bert"),o5t.forEach(t),Wur=r(B9e," \u2014 "),uX=n(B9e,"A",{href:!0});var r5t=s(uX);Qur=r(r5t,"TFBertForTokenClassification"),r5t.forEach(t),Hur=r(B9e," (BERT model)"),B9e.forEach(t),Uur=i(oe),pC=n(oe,"LI",{});var x9e=s(pC);g5e=n(x9e,"STRONG",{});var t5t=s(g5e);Jur=r(t5t,"camembert"),t5t.forEach(t),Yur=r(x9e," \u2014 "),bX=n(x9e,"A",{href:!0});var a5t=s(bX);Kur=r(a5t,"TFCamembertForTokenClassification"),a5t.forEach(t),Zur=r(x9e," (CamemBERT model)"),x9e.forEach(t),e5r=i(oe),_C=n(oe,"LI",{});var k9e=s(_C);h5e=n(k9e,"STRONG",{});var n5t=s(h5e);o5r=r(n5t,"convbert"),n5t.forEach(t),r5r=r(k9e," \u2014 "),vX=n(k9e,"A",{href:!0});var s5t=s(vX);t5r=r(s5t,"TFConvBertForTokenClassification"),s5t.forEach(t),a5r=r(k9e," (ConvBERT model)"),k9e.forEach(t),n5r=i(oe),uC=n(oe,"LI",{});var R9e=s(uC);p5e=n(R9e,"STRONG",{});var l5t=s(p5e);s5r=r(l5t,"deberta"),l5t.forEach(t),l5r=r(R9e," \u2014 "),TX=n(R9e,"A",{href:!0});var i5t=s(TX);i5r=r(i5t,"TFDebertaForTokenClassification"),i5t.forEach(t),d5r=r(R9e," (DeBERTa model)"),R9e.forEach(t),c5r=i(oe),bC=n(oe,"LI",{});var S9e=s(bC);_5e=n(S9e,"STRONG",{});var d5t=s(_5e);f5r=r(d5t,"deberta-v2"),d5t.forEach(t),m5r=r(S9e," \u2014 "),FX=n(S9e,"A",{href:!0});var c5t=s(FX);g5r=r(c5t,"TFDebertaV2ForTokenClassification"),c5t.forEach(t),h5r=r(S9e," (DeBERTa-v2 model)"),S9e.forEach(t),p5r=i(oe),vC=n(oe,"LI",{});var P9e=s(vC);u5e=n(P9e,"STRONG",{});var f5t=s(u5e);_5r=r(f5t,"distilbert"),f5t.forEach(t),u5r=r(P9e," \u2014 "),CX=n(P9e,"A",{href:!0});var m5t=s(CX);b5r=r(m5t,"TFDistilBertForTokenClassification"),m5t.forEach(t),v5r=r(P9e," (DistilBERT model)"),P9e.forEach(t),T5r=i(oe),TC=n(oe,"LI",{});var $9e=s(TC);b5e=n($9e,"STRONG",{});var g5t=s(b5e);F5r=r(g5t,"electra"),g5t.forEach(t),C5r=r($9e," \u2014 "),MX=n($9e,"A",{href:!0});var h5t=s(MX);M5r=r(h5t,"TFElectraForTokenClassification"),h5t.forEach(t),E5r=r($9e," (ELECTRA model)"),$9e.forEach(t),y5r=i(oe),FC=n(oe,"LI",{});var I9e=s(FC);v5e=n(I9e,"STRONG",{});var p5t=s(v5e);w5r=r(p5t,"flaubert"),p5t.forEach(t),A5r=r(I9e," \u2014 "),EX=n(I9e,"A",{href:!0});var _5t=s(EX);L5r=r(_5t,"TFFlaubertForTokenClassification"),_5t.forEach(t),B5r=r(I9e," (FlauBERT model)"),I9e.forEach(t),x5r=i(oe),CC=n(oe,"LI",{});var N9e=s(CC);T5e=n(N9e,"STRONG",{});var u5t=s(T5e);k5r=r(u5t,"funnel"),u5t.forEach(t),R5r=r(N9e," \u2014 "),yX=n(N9e,"A",{href:!0});var b5t=s(yX);S5r=r(b5t,"TFFunnelForTokenClassification"),b5t.forEach(t),P5r=r(N9e," (Funnel Transformer model)"),N9e.forEach(t),$5r=i(oe),MC=n(oe,"LI",{});var D9e=s(MC);F5e=n(D9e,"STRONG",{});var v5t=s(F5e);I5r=r(v5t,"layoutlm"),v5t.forEach(t),N5r=r(D9e," \u2014 "),wX=n(D9e,"A",{href:!0});var T5t=s(wX);D5r=r(T5t,"TFLayoutLMForTokenClassification"),T5t.forEach(t),j5r=r(D9e," (LayoutLM model)"),D9e.forEach(t),q5r=i(oe),EC=n(oe,"LI",{});var j9e=s(EC);C5e=n(j9e,"STRONG",{});var F5t=s(C5e);G5r=r(F5t,"longformer"),F5t.forEach(t),O5r=r(j9e," \u2014 "),AX=n(j9e,"A",{href:!0});var C5t=s(AX);X5r=r(C5t,"TFLongformerForTokenClassification"),C5t.forEach(t),V5r=r(j9e," (Longformer model)"),j9e.forEach(t),z5r=i(oe),yC=n(oe,"LI",{});var q9e=s(yC);M5e=n(q9e,"STRONG",{});var M5t=s(M5e);W5r=r(M5t,"mobilebert"),M5t.forEach(t),Q5r=r(q9e," \u2014 "),LX=n(q9e,"A",{href:!0});var E5t=s(LX);H5r=r(E5t,"TFMobileBertForTokenClassification"),E5t.forEach(t),U5r=r(q9e," (MobileBERT model)"),q9e.forEach(t),J5r=i(oe),wC=n(oe,"LI",{});var G9e=s(wC);E5e=n(G9e,"STRONG",{});var y5t=s(E5e);Y5r=r(y5t,"mpnet"),y5t.forEach(t),K5r=r(G9e," \u2014 "),BX=n(G9e,"A",{href:!0});var w5t=s(BX);Z5r=r(w5t,"TFMPNetForTokenClassification"),w5t.forEach(t),e2r=r(G9e," (MPNet model)"),G9e.forEach(t),o2r=i(oe),AC=n(oe,"LI",{});var O9e=s(AC);y5e=n(O9e,"STRONG",{});var A5t=s(y5e);r2r=r(A5t,"rembert"),A5t.forEach(t),t2r=r(O9e," \u2014 "),xX=n(O9e,"A",{href:!0});var L5t=s(xX);a2r=r(L5t,"TFRemBertForTokenClassification"),L5t.forEach(t),n2r=r(O9e," (RemBERT model)"),O9e.forEach(t),s2r=i(oe),LC=n(oe,"LI",{});var X9e=s(LC);w5e=n(X9e,"STRONG",{});var B5t=s(w5e);l2r=r(B5t,"roberta"),B5t.forEach(t),i2r=r(X9e," \u2014 "),kX=n(X9e,"A",{href:!0});var x5t=s(kX);d2r=r(x5t,"TFRobertaForTokenClassification"),x5t.forEach(t),c2r=r(X9e," (RoBERTa model)"),X9e.forEach(t),f2r=i(oe),BC=n(oe,"LI",{});var V9e=s(BC);A5e=n(V9e,"STRONG",{});var k5t=s(A5e);m2r=r(k5t,"roformer"),k5t.forEach(t),g2r=r(V9e," \u2014 "),RX=n(V9e,"A",{href:!0});var R5t=s(RX);h2r=r(R5t,"TFRoFormerForTokenClassification"),R5t.forEach(t),p2r=r(V9e," (RoFormer model)"),V9e.forEach(t),_2r=i(oe),xC=n(oe,"LI",{});var z9e=s(xC);L5e=n(z9e,"STRONG",{});var S5t=s(L5e);u2r=r(S5t,"xlm"),S5t.forEach(t),b2r=r(z9e," \u2014 "),SX=n(z9e,"A",{href:!0});var P5t=s(SX);v2r=r(P5t,"TFXLMForTokenClassification"),P5t.forEach(t),T2r=r(z9e," (XLM model)"),z9e.forEach(t),F2r=i(oe),kC=n(oe,"LI",{});var W9e=s(kC);B5e=n(W9e,"STRONG",{});var $5t=s(B5e);C2r=r($5t,"xlm-roberta"),$5t.forEach(t),M2r=r(W9e," \u2014 "),PX=n(W9e,"A",{href:!0});var I5t=s(PX);E2r=r(I5t,"TFXLMRobertaForTokenClassification"),I5t.forEach(t),y2r=r(W9e," (XLM-RoBERTa model)"),W9e.forEach(t),w2r=i(oe),RC=n(oe,"LI",{});var Q9e=s(RC);x5e=n(Q9e,"STRONG",{});var N5t=s(x5e);A2r=r(N5t,"xlnet"),N5t.forEach(t),L2r=r(Q9e," \u2014 "),$X=n(Q9e,"A",{href:!0});var D5t=s($X);B2r=r(D5t,"TFXLNetForTokenClassification"),D5t.forEach(t),x2r=r(Q9e," (XLNet model)"),Q9e.forEach(t),oe.forEach(t),k2r=i(Ea),k5e=n(Ea,"P",{});var j5t=s(k5e);R2r=r(j5t,"Examples:"),j5t.forEach(t),S2r=i(Ea),m(aL.$$.fragment,Ea),Ea.forEach(t),ti.forEach(t),SRe=i(c),Oc=n(c,"H2",{class:!0});var zPe=s(Oc);SC=n(zPe,"A",{id:!0,class:!0,href:!0});var q5t=s(SC);R5e=n(q5t,"SPAN",{});var G5t=s(R5e);m(nL.$$.fragment,G5t),G5t.forEach(t),q5t.forEach(t),P2r=i(zPe),S5e=n(zPe,"SPAN",{});var O5t=s(S5e);$2r=r(O5t,"TFAutoModelForQuestionAnswering"),O5t.forEach(t),zPe.forEach(t),PRe=i(c),Br=n(c,"DIV",{class:!0});var ni=s(Br);m(sL.$$.fragment,ni),I2r=i(ni),Xc=n(ni,"P",{});var mQ=s(Xc);N2r=r(mQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),P5e=n(mQ,"CODE",{});var X5t=s(P5e);D2r=r(X5t,"from_pretrained()"),X5t.forEach(t),j2r=r(mQ,"class method or the "),$5e=n(mQ,"CODE",{});var V5t=s($5e);q2r=r(V5t,"from_config()"),V5t.forEach(t),G2r=r(mQ,`class
method.`),mQ.forEach(t),O2r=i(ni),lL=n(ni,"P",{});var WPe=s(lL);X2r=r(WPe,"This class cannot be instantiated directly using "),I5e=n(WPe,"CODE",{});var z5t=s(I5e);V2r=r(z5t,"__init__()"),z5t.forEach(t),z2r=r(WPe," (throws an error)."),WPe.forEach(t),W2r=i(ni),Mt=n(ni,"DIV",{class:!0});var si=s(Mt);m(iL.$$.fragment,si),Q2r=i(si),N5e=n(si,"P",{});var W5t=s(N5e);H2r=r(W5t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),W5t.forEach(t),U2r=i(si),Vc=n(si,"P",{});var gQ=s(Vc);J2r=r(gQ,`Note:
Loading a model from its configuration file does `),D5e=n(gQ,"STRONG",{});var Q5t=s(D5e);Y2r=r(Q5t,"not"),Q5t.forEach(t),K2r=r(gQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),j5e=n(gQ,"CODE",{});var H5t=s(j5e);Z2r=r(H5t,"from_pretrained()"),H5t.forEach(t),e1r=r(gQ,"to load the model weights."),gQ.forEach(t),o1r=i(si),q5e=n(si,"P",{});var U5t=s(q5e);r1r=r(U5t,"Examples:"),U5t.forEach(t),t1r=i(si),m(dL.$$.fragment,si),si.forEach(t),a1r=i(ni),Eo=n(ni,"DIV",{class:!0});var ya=s(Eo);m(cL.$$.fragment,ya),n1r=i(ya),G5e=n(ya,"P",{});var J5t=s(G5e);s1r=r(J5t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),J5t.forEach(t),l1r=i(ya),wn=n(ya,"P",{});var WE=s(wn);i1r=r(WE,"The model class to instantiate is selected based on the "),O5e=n(WE,"CODE",{});var Y5t=s(O5e);d1r=r(Y5t,"model_type"),Y5t.forEach(t),c1r=r(WE,` property of the config object (either
passed as an argument or loaded from `),X5e=n(WE,"CODE",{});var K5t=s(X5e);f1r=r(K5t,"pretrained_model_name_or_path"),K5t.forEach(t),m1r=r(WE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=n(WE,"CODE",{});var Z5t=s(V5e);g1r=r(Z5t,"pretrained_model_name_or_path"),Z5t.forEach(t),h1r=r(WE,":"),WE.forEach(t),p1r=i(ya),Z=n(ya,"UL",{});var te=s(Z);PC=n(te,"LI",{});var H9e=s(PC);z5e=n(H9e,"STRONG",{});var e2t=s(z5e);_1r=r(e2t,"albert"),e2t.forEach(t),u1r=r(H9e," \u2014 "),IX=n(H9e,"A",{href:!0});var o2t=s(IX);b1r=r(o2t,"TFAlbertForQuestionAnswering"),o2t.forEach(t),v1r=r(H9e," (ALBERT model)"),H9e.forEach(t),T1r=i(te),$C=n(te,"LI",{});var U9e=s($C);W5e=n(U9e,"STRONG",{});var r2t=s(W5e);F1r=r(r2t,"bert"),r2t.forEach(t),C1r=r(U9e," \u2014 "),NX=n(U9e,"A",{href:!0});var t2t=s(NX);M1r=r(t2t,"TFBertForQuestionAnswering"),t2t.forEach(t),E1r=r(U9e," (BERT model)"),U9e.forEach(t),y1r=i(te),IC=n(te,"LI",{});var J9e=s(IC);Q5e=n(J9e,"STRONG",{});var a2t=s(Q5e);w1r=r(a2t,"camembert"),a2t.forEach(t),A1r=r(J9e," \u2014 "),DX=n(J9e,"A",{href:!0});var n2t=s(DX);L1r=r(n2t,"TFCamembertForQuestionAnswering"),n2t.forEach(t),B1r=r(J9e," (CamemBERT model)"),J9e.forEach(t),x1r=i(te),NC=n(te,"LI",{});var Y9e=s(NC);H5e=n(Y9e,"STRONG",{});var s2t=s(H5e);k1r=r(s2t,"convbert"),s2t.forEach(t),R1r=r(Y9e," \u2014 "),jX=n(Y9e,"A",{href:!0});var l2t=s(jX);S1r=r(l2t,"TFConvBertForQuestionAnswering"),l2t.forEach(t),P1r=r(Y9e," (ConvBERT model)"),Y9e.forEach(t),$1r=i(te),DC=n(te,"LI",{});var K9e=s(DC);U5e=n(K9e,"STRONG",{});var i2t=s(U5e);I1r=r(i2t,"deberta"),i2t.forEach(t),N1r=r(K9e," \u2014 "),qX=n(K9e,"A",{href:!0});var d2t=s(qX);D1r=r(d2t,"TFDebertaForQuestionAnswering"),d2t.forEach(t),j1r=r(K9e," (DeBERTa model)"),K9e.forEach(t),q1r=i(te),jC=n(te,"LI",{});var Z9e=s(jC);J5e=n(Z9e,"STRONG",{});var c2t=s(J5e);G1r=r(c2t,"deberta-v2"),c2t.forEach(t),O1r=r(Z9e," \u2014 "),GX=n(Z9e,"A",{href:!0});var f2t=s(GX);X1r=r(f2t,"TFDebertaV2ForQuestionAnswering"),f2t.forEach(t),V1r=r(Z9e," (DeBERTa-v2 model)"),Z9e.forEach(t),z1r=i(te),qC=n(te,"LI",{});var eBe=s(qC);Y5e=n(eBe,"STRONG",{});var m2t=s(Y5e);W1r=r(m2t,"distilbert"),m2t.forEach(t),Q1r=r(eBe," \u2014 "),OX=n(eBe,"A",{href:!0});var g2t=s(OX);H1r=r(g2t,"TFDistilBertForQuestionAnswering"),g2t.forEach(t),U1r=r(eBe," (DistilBERT model)"),eBe.forEach(t),J1r=i(te),GC=n(te,"LI",{});var oBe=s(GC);K5e=n(oBe,"STRONG",{});var h2t=s(K5e);Y1r=r(h2t,"electra"),h2t.forEach(t),K1r=r(oBe," \u2014 "),XX=n(oBe,"A",{href:!0});var p2t=s(XX);Z1r=r(p2t,"TFElectraForQuestionAnswering"),p2t.forEach(t),ebr=r(oBe," (ELECTRA model)"),oBe.forEach(t),obr=i(te),OC=n(te,"LI",{});var rBe=s(OC);Z5e=n(rBe,"STRONG",{});var _2t=s(Z5e);rbr=r(_2t,"flaubert"),_2t.forEach(t),tbr=r(rBe," \u2014 "),VX=n(rBe,"A",{href:!0});var u2t=s(VX);abr=r(u2t,"TFFlaubertForQuestionAnsweringSimple"),u2t.forEach(t),nbr=r(rBe," (FlauBERT model)"),rBe.forEach(t),sbr=i(te),XC=n(te,"LI",{});var tBe=s(XC);e2e=n(tBe,"STRONG",{});var b2t=s(e2e);lbr=r(b2t,"funnel"),b2t.forEach(t),ibr=r(tBe," \u2014 "),zX=n(tBe,"A",{href:!0});var v2t=s(zX);dbr=r(v2t,"TFFunnelForQuestionAnswering"),v2t.forEach(t),cbr=r(tBe," (Funnel Transformer model)"),tBe.forEach(t),fbr=i(te),VC=n(te,"LI",{});var aBe=s(VC);o2e=n(aBe,"STRONG",{});var T2t=s(o2e);mbr=r(T2t,"longformer"),T2t.forEach(t),gbr=r(aBe," \u2014 "),WX=n(aBe,"A",{href:!0});var F2t=s(WX);hbr=r(F2t,"TFLongformerForQuestionAnswering"),F2t.forEach(t),pbr=r(aBe," (Longformer model)"),aBe.forEach(t),_br=i(te),zC=n(te,"LI",{});var nBe=s(zC);r2e=n(nBe,"STRONG",{});var C2t=s(r2e);ubr=r(C2t,"mobilebert"),C2t.forEach(t),bbr=r(nBe," \u2014 "),QX=n(nBe,"A",{href:!0});var M2t=s(QX);vbr=r(M2t,"TFMobileBertForQuestionAnswering"),M2t.forEach(t),Tbr=r(nBe," (MobileBERT model)"),nBe.forEach(t),Fbr=i(te),WC=n(te,"LI",{});var sBe=s(WC);t2e=n(sBe,"STRONG",{});var E2t=s(t2e);Cbr=r(E2t,"mpnet"),E2t.forEach(t),Mbr=r(sBe," \u2014 "),HX=n(sBe,"A",{href:!0});var y2t=s(HX);Ebr=r(y2t,"TFMPNetForQuestionAnswering"),y2t.forEach(t),ybr=r(sBe," (MPNet model)"),sBe.forEach(t),wbr=i(te),QC=n(te,"LI",{});var lBe=s(QC);a2e=n(lBe,"STRONG",{});var w2t=s(a2e);Abr=r(w2t,"rembert"),w2t.forEach(t),Lbr=r(lBe," \u2014 "),UX=n(lBe,"A",{href:!0});var A2t=s(UX);Bbr=r(A2t,"TFRemBertForQuestionAnswering"),A2t.forEach(t),xbr=r(lBe," (RemBERT model)"),lBe.forEach(t),kbr=i(te),HC=n(te,"LI",{});var iBe=s(HC);n2e=n(iBe,"STRONG",{});var L2t=s(n2e);Rbr=r(L2t,"roberta"),L2t.forEach(t),Sbr=r(iBe," \u2014 "),JX=n(iBe,"A",{href:!0});var B2t=s(JX);Pbr=r(B2t,"TFRobertaForQuestionAnswering"),B2t.forEach(t),$br=r(iBe," (RoBERTa model)"),iBe.forEach(t),Ibr=i(te),UC=n(te,"LI",{});var dBe=s(UC);s2e=n(dBe,"STRONG",{});var x2t=s(s2e);Nbr=r(x2t,"roformer"),x2t.forEach(t),Dbr=r(dBe," \u2014 "),YX=n(dBe,"A",{href:!0});var k2t=s(YX);jbr=r(k2t,"TFRoFormerForQuestionAnswering"),k2t.forEach(t),qbr=r(dBe," (RoFormer model)"),dBe.forEach(t),Gbr=i(te),JC=n(te,"LI",{});var cBe=s(JC);l2e=n(cBe,"STRONG",{});var R2t=s(l2e);Obr=r(R2t,"xlm"),R2t.forEach(t),Xbr=r(cBe," \u2014 "),KX=n(cBe,"A",{href:!0});var S2t=s(KX);Vbr=r(S2t,"TFXLMForQuestionAnsweringSimple"),S2t.forEach(t),zbr=r(cBe," (XLM model)"),cBe.forEach(t),Wbr=i(te),YC=n(te,"LI",{});var fBe=s(YC);i2e=n(fBe,"STRONG",{});var P2t=s(i2e);Qbr=r(P2t,"xlm-roberta"),P2t.forEach(t),Hbr=r(fBe," \u2014 "),ZX=n(fBe,"A",{href:!0});var $2t=s(ZX);Ubr=r($2t,"TFXLMRobertaForQuestionAnswering"),$2t.forEach(t),Jbr=r(fBe," (XLM-RoBERTa model)"),fBe.forEach(t),Ybr=i(te),KC=n(te,"LI",{});var mBe=s(KC);d2e=n(mBe,"STRONG",{});var I2t=s(d2e);Kbr=r(I2t,"xlnet"),I2t.forEach(t),Zbr=r(mBe," \u2014 "),eV=n(mBe,"A",{href:!0});var N2t=s(eV);evr=r(N2t,"TFXLNetForQuestionAnsweringSimple"),N2t.forEach(t),ovr=r(mBe," (XLNet model)"),mBe.forEach(t),te.forEach(t),rvr=i(ya),c2e=n(ya,"P",{});var D2t=s(c2e);tvr=r(D2t,"Examples:"),D2t.forEach(t),avr=i(ya),m(fL.$$.fragment,ya),ya.forEach(t),ni.forEach(t),$Re=i(c),zc=n(c,"H2",{class:!0});var QPe=s(zc);ZC=n(QPe,"A",{id:!0,class:!0,href:!0});var j2t=s(ZC);f2e=n(j2t,"SPAN",{});var q2t=s(f2e);m(mL.$$.fragment,q2t),q2t.forEach(t),j2t.forEach(t),nvr=i(QPe),m2e=n(QPe,"SPAN",{});var G2t=s(m2e);svr=r(G2t,"TFAutoModelForVision2Seq"),G2t.forEach(t),QPe.forEach(t),IRe=i(c),xr=n(c,"DIV",{class:!0});var li=s(xr);m(gL.$$.fragment,li),lvr=i(li),Wc=n(li,"P",{});var hQ=s(Wc);ivr=r(hQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),g2e=n(hQ,"CODE",{});var O2t=s(g2e);dvr=r(O2t,"from_pretrained()"),O2t.forEach(t),cvr=r(hQ,"class method or the "),h2e=n(hQ,"CODE",{});var X2t=s(h2e);fvr=r(X2t,"from_config()"),X2t.forEach(t),mvr=r(hQ,`class
method.`),hQ.forEach(t),gvr=i(li),hL=n(li,"P",{});var HPe=s(hL);hvr=r(HPe,"This class cannot be instantiated directly using "),p2e=n(HPe,"CODE",{});var V2t=s(p2e);pvr=r(V2t,"__init__()"),V2t.forEach(t),_vr=r(HPe," (throws an error)."),HPe.forEach(t),uvr=i(li),Et=n(li,"DIV",{class:!0});var ii=s(Et);m(pL.$$.fragment,ii),bvr=i(ii),_2e=n(ii,"P",{});var z2t=s(_2e);vvr=r(z2t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),z2t.forEach(t),Tvr=i(ii),Qc=n(ii,"P",{});var pQ=s(Qc);Fvr=r(pQ,`Note:
Loading a model from its configuration file does `),u2e=n(pQ,"STRONG",{});var W2t=s(u2e);Cvr=r(W2t,"not"),W2t.forEach(t),Mvr=r(pQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),b2e=n(pQ,"CODE",{});var Q2t=s(b2e);Evr=r(Q2t,"from_pretrained()"),Q2t.forEach(t),yvr=r(pQ,"to load the model weights."),pQ.forEach(t),wvr=i(ii),v2e=n(ii,"P",{});var H2t=s(v2e);Avr=r(H2t,"Examples:"),H2t.forEach(t),Lvr=i(ii),m(_L.$$.fragment,ii),ii.forEach(t),Bvr=i(li),yo=n(li,"DIV",{class:!0});var wa=s(yo);m(uL.$$.fragment,wa),xvr=i(wa),T2e=n(wa,"P",{});var U2t=s(T2e);kvr=r(U2t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),U2t.forEach(t),Rvr=i(wa),An=n(wa,"P",{});var QE=s(An);Svr=r(QE,"The model class to instantiate is selected based on the "),F2e=n(QE,"CODE",{});var J2t=s(F2e);Pvr=r(J2t,"model_type"),J2t.forEach(t),$vr=r(QE,` property of the config object (either
passed as an argument or loaded from `),C2e=n(QE,"CODE",{});var Y2t=s(C2e);Ivr=r(Y2t,"pretrained_model_name_or_path"),Y2t.forEach(t),Nvr=r(QE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M2e=n(QE,"CODE",{});var K2t=s(M2e);Dvr=r(K2t,"pretrained_model_name_or_path"),K2t.forEach(t),jvr=r(QE,":"),QE.forEach(t),qvr=i(wa),E2e=n(wa,"UL",{});var Z2t=s(E2e);eM=n(Z2t,"LI",{});var gBe=s(eM);y2e=n(gBe,"STRONG",{});var e1t=s(y2e);Gvr=r(e1t,"vision-encoder-decoder"),e1t.forEach(t),Ovr=r(gBe," \u2014 "),oV=n(gBe,"A",{href:!0});var o1t=s(oV);Xvr=r(o1t,"TFVisionEncoderDecoderModel"),o1t.forEach(t),Vvr=r(gBe," (Vision Encoder decoder model)"),gBe.forEach(t),Z2t.forEach(t),zvr=i(wa),w2e=n(wa,"P",{});var r1t=s(w2e);Wvr=r(r1t,"Examples:"),r1t.forEach(t),Qvr=i(wa),m(bL.$$.fragment,wa),wa.forEach(t),li.forEach(t),NRe=i(c),Hc=n(c,"H2",{class:!0});var UPe=s(Hc);oM=n(UPe,"A",{id:!0,class:!0,href:!0});var t1t=s(oM);A2e=n(t1t,"SPAN",{});var a1t=s(A2e);m(vL.$$.fragment,a1t),a1t.forEach(t),t1t.forEach(t),Hvr=i(UPe),L2e=n(UPe,"SPAN",{});var n1t=s(L2e);Uvr=r(n1t,"TFAutoModelForSpeechSeq2Seq"),n1t.forEach(t),UPe.forEach(t),DRe=i(c),kr=n(c,"DIV",{class:!0});var di=s(kr);m(TL.$$.fragment,di),Jvr=i(di),Uc=n(di,"P",{});var _Q=s(Uc);Yvr=r(_Q,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),B2e=n(_Q,"CODE",{});var s1t=s(B2e);Kvr=r(s1t,"from_pretrained()"),s1t.forEach(t),Zvr=r(_Q,"class method or the "),x2e=n(_Q,"CODE",{});var l1t=s(x2e);e6r=r(l1t,"from_config()"),l1t.forEach(t),o6r=r(_Q,`class
method.`),_Q.forEach(t),r6r=i(di),FL=n(di,"P",{});var JPe=s(FL);t6r=r(JPe,"This class cannot be instantiated directly using "),k2e=n(JPe,"CODE",{});var i1t=s(k2e);a6r=r(i1t,"__init__()"),i1t.forEach(t),n6r=r(JPe," (throws an error)."),JPe.forEach(t),s6r=i(di),yt=n(di,"DIV",{class:!0});var ci=s(yt);m(CL.$$.fragment,ci),l6r=i(ci),R2e=n(ci,"P",{});var d1t=s(R2e);i6r=r(d1t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),d1t.forEach(t),d6r=i(ci),Jc=n(ci,"P",{});var uQ=s(Jc);c6r=r(uQ,`Note:
Loading a model from its configuration file does `),S2e=n(uQ,"STRONG",{});var c1t=s(S2e);f6r=r(c1t,"not"),c1t.forEach(t),m6r=r(uQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),P2e=n(uQ,"CODE",{});var f1t=s(P2e);g6r=r(f1t,"from_pretrained()"),f1t.forEach(t),h6r=r(uQ,"to load the model weights."),uQ.forEach(t),p6r=i(ci),$2e=n(ci,"P",{});var m1t=s($2e);_6r=r(m1t,"Examples:"),m1t.forEach(t),u6r=i(ci),m(ML.$$.fragment,ci),ci.forEach(t),b6r=i(di),wo=n(di,"DIV",{class:!0});var Aa=s(wo);m(EL.$$.fragment,Aa),v6r=i(Aa),I2e=n(Aa,"P",{});var g1t=s(I2e);T6r=r(g1t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),g1t.forEach(t),F6r=i(Aa),Ln=n(Aa,"P",{});var HE=s(Ln);C6r=r(HE,"The model class to instantiate is selected based on the "),N2e=n(HE,"CODE",{});var h1t=s(N2e);M6r=r(h1t,"model_type"),h1t.forEach(t),E6r=r(HE,` property of the config object (either
passed as an argument or loaded from `),D2e=n(HE,"CODE",{});var p1t=s(D2e);y6r=r(p1t,"pretrained_model_name_or_path"),p1t.forEach(t),w6r=r(HE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j2e=n(HE,"CODE",{});var _1t=s(j2e);A6r=r(_1t,"pretrained_model_name_or_path"),_1t.forEach(t),L6r=r(HE,":"),HE.forEach(t),B6r=i(Aa),q2e=n(Aa,"UL",{});var u1t=s(q2e);rM=n(u1t,"LI",{});var hBe=s(rM);G2e=n(hBe,"STRONG",{});var b1t=s(G2e);x6r=r(b1t,"speech_to_text"),b1t.forEach(t),k6r=r(hBe," \u2014 "),rV=n(hBe,"A",{href:!0});var v1t=s(rV);R6r=r(v1t,"TFSpeech2TextForConditionalGeneration"),v1t.forEach(t),S6r=r(hBe," (Speech2Text model)"),hBe.forEach(t),u1t.forEach(t),P6r=i(Aa),O2e=n(Aa,"P",{});var T1t=s(O2e);$6r=r(T1t,"Examples:"),T1t.forEach(t),I6r=i(Aa),m(yL.$$.fragment,Aa),Aa.forEach(t),di.forEach(t),jRe=i(c),Yc=n(c,"H2",{class:!0});var YPe=s(Yc);tM=n(YPe,"A",{id:!0,class:!0,href:!0});var F1t=s(tM);X2e=n(F1t,"SPAN",{});var C1t=s(X2e);m(wL.$$.fragment,C1t),C1t.forEach(t),F1t.forEach(t),N6r=i(YPe),V2e=n(YPe,"SPAN",{});var M1t=s(V2e);D6r=r(M1t,"FlaxAutoModel"),M1t.forEach(t),YPe.forEach(t),qRe=i(c),Rr=n(c,"DIV",{class:!0});var fi=s(Rr);m(AL.$$.fragment,fi),j6r=i(fi),Kc=n(fi,"P",{});var bQ=s(Kc);q6r=r(bQ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),z2e=n(bQ,"CODE",{});var E1t=s(z2e);G6r=r(E1t,"from_pretrained()"),E1t.forEach(t),O6r=r(bQ,"class method or the "),W2e=n(bQ,"CODE",{});var y1t=s(W2e);X6r=r(y1t,"from_config()"),y1t.forEach(t),V6r=r(bQ,`class
method.`),bQ.forEach(t),z6r=i(fi),LL=n(fi,"P",{});var KPe=s(LL);W6r=r(KPe,"This class cannot be instantiated directly using "),Q2e=n(KPe,"CODE",{});var w1t=s(Q2e);Q6r=r(w1t,"__init__()"),w1t.forEach(t),H6r=r(KPe," (throws an error)."),KPe.forEach(t),U6r=i(fi),wt=n(fi,"DIV",{class:!0});var mi=s(wt);m(BL.$$.fragment,mi),J6r=i(mi),H2e=n(mi,"P",{});var A1t=s(H2e);Y6r=r(A1t,"Instantiates one of the base model classes of the library from a configuration."),A1t.forEach(t),K6r=i(mi),Zc=n(mi,"P",{});var vQ=s(Zc);Z6r=r(vQ,`Note:
Loading a model from its configuration file does `),U2e=n(vQ,"STRONG",{});var L1t=s(U2e);eTr=r(L1t,"not"),L1t.forEach(t),oTr=r(vQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),J2e=n(vQ,"CODE",{});var B1t=s(J2e);rTr=r(B1t,"from_pretrained()"),B1t.forEach(t),tTr=r(vQ,"to load the model weights."),vQ.forEach(t),aTr=i(mi),Y2e=n(mi,"P",{});var x1t=s(Y2e);nTr=r(x1t,"Examples:"),x1t.forEach(t),sTr=i(mi),m(xL.$$.fragment,mi),mi.forEach(t),lTr=i(fi),Ao=n(fi,"DIV",{class:!0});var La=s(Ao);m(kL.$$.fragment,La),iTr=i(La),K2e=n(La,"P",{});var k1t=s(K2e);dTr=r(k1t,"Instantiate one of the base model classes of the library from a pretrained model."),k1t.forEach(t),cTr=i(La),Bn=n(La,"P",{});var UE=s(Bn);fTr=r(UE,"The model class to instantiate is selected based on the "),Z2e=n(UE,"CODE",{});var R1t=s(Z2e);mTr=r(R1t,"model_type"),R1t.forEach(t),gTr=r(UE,` property of the config object (either
passed as an argument or loaded from `),e1e=n(UE,"CODE",{});var S1t=s(e1e);hTr=r(S1t,"pretrained_model_name_or_path"),S1t.forEach(t),pTr=r(UE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=n(UE,"CODE",{});var P1t=s(o1e);_Tr=r(P1t,"pretrained_model_name_or_path"),P1t.forEach(t),uTr=r(UE,":"),UE.forEach(t),bTr=i(La),z=n(La,"UL",{});var Q=s(z);aM=n(Q,"LI",{});var pBe=s(aM);r1e=n(pBe,"STRONG",{});var $1t=s(r1e);vTr=r($1t,"albert"),$1t.forEach(t),TTr=r(pBe," \u2014 "),tV=n(pBe,"A",{href:!0});var I1t=s(tV);FTr=r(I1t,"FlaxAlbertModel"),I1t.forEach(t),CTr=r(pBe," (ALBERT model)"),pBe.forEach(t),MTr=i(Q),nM=n(Q,"LI",{});var _Be=s(nM);t1e=n(_Be,"STRONG",{});var N1t=s(t1e);ETr=r(N1t,"bart"),N1t.forEach(t),yTr=r(_Be," \u2014 "),aV=n(_Be,"A",{href:!0});var D1t=s(aV);wTr=r(D1t,"FlaxBartModel"),D1t.forEach(t),ATr=r(_Be," (BART model)"),_Be.forEach(t),LTr=i(Q),sM=n(Q,"LI",{});var uBe=s(sM);a1e=n(uBe,"STRONG",{});var j1t=s(a1e);BTr=r(j1t,"beit"),j1t.forEach(t),xTr=r(uBe," \u2014 "),nV=n(uBe,"A",{href:!0});var q1t=s(nV);kTr=r(q1t,"FlaxBeitModel"),q1t.forEach(t),RTr=r(uBe," (BEiT model)"),uBe.forEach(t),STr=i(Q),lM=n(Q,"LI",{});var bBe=s(lM);n1e=n(bBe,"STRONG",{});var G1t=s(n1e);PTr=r(G1t,"bert"),G1t.forEach(t),$Tr=r(bBe," \u2014 "),sV=n(bBe,"A",{href:!0});var O1t=s(sV);ITr=r(O1t,"FlaxBertModel"),O1t.forEach(t),NTr=r(bBe," (BERT model)"),bBe.forEach(t),DTr=i(Q),iM=n(Q,"LI",{});var vBe=s(iM);s1e=n(vBe,"STRONG",{});var X1t=s(s1e);jTr=r(X1t,"big_bird"),X1t.forEach(t),qTr=r(vBe," \u2014 "),lV=n(vBe,"A",{href:!0});var V1t=s(lV);GTr=r(V1t,"FlaxBigBirdModel"),V1t.forEach(t),OTr=r(vBe," (BigBird model)"),vBe.forEach(t),XTr=i(Q),dM=n(Q,"LI",{});var TBe=s(dM);l1e=n(TBe,"STRONG",{});var z1t=s(l1e);VTr=r(z1t,"blenderbot"),z1t.forEach(t),zTr=r(TBe," \u2014 "),iV=n(TBe,"A",{href:!0});var W1t=s(iV);WTr=r(W1t,"FlaxBlenderbotModel"),W1t.forEach(t),QTr=r(TBe," (Blenderbot model)"),TBe.forEach(t),HTr=i(Q),cM=n(Q,"LI",{});var FBe=s(cM);i1e=n(FBe,"STRONG",{});var Q1t=s(i1e);UTr=r(Q1t,"blenderbot-small"),Q1t.forEach(t),JTr=r(FBe," \u2014 "),dV=n(FBe,"A",{href:!0});var H1t=s(dV);YTr=r(H1t,"FlaxBlenderbotSmallModel"),H1t.forEach(t),KTr=r(FBe," (BlenderbotSmall model)"),FBe.forEach(t),ZTr=i(Q),fM=n(Q,"LI",{});var CBe=s(fM);d1e=n(CBe,"STRONG",{});var U1t=s(d1e);eFr=r(U1t,"clip"),U1t.forEach(t),oFr=r(CBe," \u2014 "),cV=n(CBe,"A",{href:!0});var J1t=s(cV);rFr=r(J1t,"FlaxCLIPModel"),J1t.forEach(t),tFr=r(CBe," (CLIP model)"),CBe.forEach(t),aFr=i(Q),mM=n(Q,"LI",{});var MBe=s(mM);c1e=n(MBe,"STRONG",{});var Y1t=s(c1e);nFr=r(Y1t,"distilbert"),Y1t.forEach(t),sFr=r(MBe," \u2014 "),fV=n(MBe,"A",{href:!0});var K1t=s(fV);lFr=r(K1t,"FlaxDistilBertModel"),K1t.forEach(t),iFr=r(MBe," (DistilBERT model)"),MBe.forEach(t),dFr=i(Q),gM=n(Q,"LI",{});var EBe=s(gM);f1e=n(EBe,"STRONG",{});var Z1t=s(f1e);cFr=r(Z1t,"electra"),Z1t.forEach(t),fFr=r(EBe," \u2014 "),mV=n(EBe,"A",{href:!0});var ebt=s(mV);mFr=r(ebt,"FlaxElectraModel"),ebt.forEach(t),gFr=r(EBe," (ELECTRA model)"),EBe.forEach(t),hFr=i(Q),hM=n(Q,"LI",{});var yBe=s(hM);m1e=n(yBe,"STRONG",{});var obt=s(m1e);pFr=r(obt,"gpt2"),obt.forEach(t),_Fr=r(yBe," \u2014 "),gV=n(yBe,"A",{href:!0});var rbt=s(gV);uFr=r(rbt,"FlaxGPT2Model"),rbt.forEach(t),bFr=r(yBe," (OpenAI GPT-2 model)"),yBe.forEach(t),vFr=i(Q),pM=n(Q,"LI",{});var wBe=s(pM);g1e=n(wBe,"STRONG",{});var tbt=s(g1e);TFr=r(tbt,"gpt_neo"),tbt.forEach(t),FFr=r(wBe," \u2014 "),hV=n(wBe,"A",{href:!0});var abt=s(hV);CFr=r(abt,"FlaxGPTNeoModel"),abt.forEach(t),MFr=r(wBe," (GPT Neo model)"),wBe.forEach(t),EFr=i(Q),_M=n(Q,"LI",{});var ABe=s(_M);h1e=n(ABe,"STRONG",{});var nbt=s(h1e);yFr=r(nbt,"gptj"),nbt.forEach(t),wFr=r(ABe," \u2014 "),pV=n(ABe,"A",{href:!0});var sbt=s(pV);AFr=r(sbt,"FlaxGPTJModel"),sbt.forEach(t),LFr=r(ABe," (GPT-J model)"),ABe.forEach(t),BFr=i(Q),uM=n(Q,"LI",{});var LBe=s(uM);p1e=n(LBe,"STRONG",{});var lbt=s(p1e);xFr=r(lbt,"marian"),lbt.forEach(t),kFr=r(LBe," \u2014 "),_V=n(LBe,"A",{href:!0});var ibt=s(_V);RFr=r(ibt,"FlaxMarianModel"),ibt.forEach(t),SFr=r(LBe," (Marian model)"),LBe.forEach(t),PFr=i(Q),bM=n(Q,"LI",{});var BBe=s(bM);_1e=n(BBe,"STRONG",{});var dbt=s(_1e);$Fr=r(dbt,"mbart"),dbt.forEach(t),IFr=r(BBe," \u2014 "),uV=n(BBe,"A",{href:!0});var cbt=s(uV);NFr=r(cbt,"FlaxMBartModel"),cbt.forEach(t),DFr=r(BBe," (mBART model)"),BBe.forEach(t),jFr=i(Q),vM=n(Q,"LI",{});var xBe=s(vM);u1e=n(xBe,"STRONG",{});var fbt=s(u1e);qFr=r(fbt,"mt5"),fbt.forEach(t),GFr=r(xBe," \u2014 "),bV=n(xBe,"A",{href:!0});var mbt=s(bV);OFr=r(mbt,"FlaxMT5Model"),mbt.forEach(t),XFr=r(xBe," (mT5 model)"),xBe.forEach(t),VFr=i(Q),TM=n(Q,"LI",{});var kBe=s(TM);b1e=n(kBe,"STRONG",{});var gbt=s(b1e);zFr=r(gbt,"pegasus"),gbt.forEach(t),WFr=r(kBe," \u2014 "),vV=n(kBe,"A",{href:!0});var hbt=s(vV);QFr=r(hbt,"FlaxPegasusModel"),hbt.forEach(t),HFr=r(kBe," (Pegasus model)"),kBe.forEach(t),UFr=i(Q),FM=n(Q,"LI",{});var RBe=s(FM);v1e=n(RBe,"STRONG",{});var pbt=s(v1e);JFr=r(pbt,"roberta"),pbt.forEach(t),YFr=r(RBe," \u2014 "),TV=n(RBe,"A",{href:!0});var _bt=s(TV);KFr=r(_bt,"FlaxRobertaModel"),_bt.forEach(t),ZFr=r(RBe," (RoBERTa model)"),RBe.forEach(t),eCr=i(Q),CM=n(Q,"LI",{});var SBe=s(CM);T1e=n(SBe,"STRONG",{});var ubt=s(T1e);oCr=r(ubt,"roformer"),ubt.forEach(t),rCr=r(SBe," \u2014 "),FV=n(SBe,"A",{href:!0});var bbt=s(FV);tCr=r(bbt,"FlaxRoFormerModel"),bbt.forEach(t),aCr=r(SBe," (RoFormer model)"),SBe.forEach(t),nCr=i(Q),MM=n(Q,"LI",{});var PBe=s(MM);F1e=n(PBe,"STRONG",{});var vbt=s(F1e);sCr=r(vbt,"t5"),vbt.forEach(t),lCr=r(PBe," \u2014 "),CV=n(PBe,"A",{href:!0});var Tbt=s(CV);iCr=r(Tbt,"FlaxT5Model"),Tbt.forEach(t),dCr=r(PBe," (T5 model)"),PBe.forEach(t),cCr=i(Q),EM=n(Q,"LI",{});var $Be=s(EM);C1e=n($Be,"STRONG",{});var Fbt=s(C1e);fCr=r(Fbt,"vision-text-dual-encoder"),Fbt.forEach(t),mCr=r($Be," \u2014 "),MV=n($Be,"A",{href:!0});var Cbt=s(MV);gCr=r(Cbt,"FlaxVisionTextDualEncoderModel"),Cbt.forEach(t),hCr=r($Be," (VisionTextDualEncoder model)"),$Be.forEach(t),pCr=i(Q),yM=n(Q,"LI",{});var IBe=s(yM);M1e=n(IBe,"STRONG",{});var Mbt=s(M1e);_Cr=r(Mbt,"vit"),Mbt.forEach(t),uCr=r(IBe," \u2014 "),EV=n(IBe,"A",{href:!0});var Ebt=s(EV);bCr=r(Ebt,"FlaxViTModel"),Ebt.forEach(t),vCr=r(IBe," (ViT model)"),IBe.forEach(t),TCr=i(Q),wM=n(Q,"LI",{});var NBe=s(wM);E1e=n(NBe,"STRONG",{});var ybt=s(E1e);FCr=r(ybt,"wav2vec2"),ybt.forEach(t),CCr=r(NBe," \u2014 "),yV=n(NBe,"A",{href:!0});var wbt=s(yV);MCr=r(wbt,"FlaxWav2Vec2Model"),wbt.forEach(t),ECr=r(NBe," (Wav2Vec2 model)"),NBe.forEach(t),yCr=i(Q),AM=n(Q,"LI",{});var DBe=s(AM);y1e=n(DBe,"STRONG",{});var Abt=s(y1e);wCr=r(Abt,"xglm"),Abt.forEach(t),ACr=r(DBe," \u2014 "),wV=n(DBe,"A",{href:!0});var Lbt=s(wV);LCr=r(Lbt,"FlaxXGLMModel"),Lbt.forEach(t),BCr=r(DBe," (XGLM model)"),DBe.forEach(t),xCr=i(Q),LM=n(Q,"LI",{});var jBe=s(LM);w1e=n(jBe,"STRONG",{});var Bbt=s(w1e);kCr=r(Bbt,"xlm-roberta"),Bbt.forEach(t),RCr=r(jBe," \u2014 "),AV=n(jBe,"A",{href:!0});var xbt=s(AV);SCr=r(xbt,"FlaxXLMRobertaModel"),xbt.forEach(t),PCr=r(jBe," (XLM-RoBERTa model)"),jBe.forEach(t),Q.forEach(t),$Cr=i(La),A1e=n(La,"P",{});var kbt=s(A1e);ICr=r(kbt,"Examples:"),kbt.forEach(t),NCr=i(La),m(RL.$$.fragment,La),La.forEach(t),fi.forEach(t),GRe=i(c),ef=n(c,"H2",{class:!0});var ZPe=s(ef);BM=n(ZPe,"A",{id:!0,class:!0,href:!0});var Rbt=s(BM);L1e=n(Rbt,"SPAN",{});var Sbt=s(L1e);m(SL.$$.fragment,Sbt),Sbt.forEach(t),Rbt.forEach(t),DCr=i(ZPe),B1e=n(ZPe,"SPAN",{});var Pbt=s(B1e);jCr=r(Pbt,"FlaxAutoModelForCausalLM"),Pbt.forEach(t),ZPe.forEach(t),ORe=i(c),Sr=n(c,"DIV",{class:!0});var gi=s(Sr);m(PL.$$.fragment,gi),qCr=i(gi),of=n(gi,"P",{});var TQ=s(of);GCr=r(TQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),x1e=n(TQ,"CODE",{});var $bt=s(x1e);OCr=r($bt,"from_pretrained()"),$bt.forEach(t),XCr=r(TQ,"class method or the "),k1e=n(TQ,"CODE",{});var Ibt=s(k1e);VCr=r(Ibt,"from_config()"),Ibt.forEach(t),zCr=r(TQ,`class
method.`),TQ.forEach(t),WCr=i(gi),$L=n(gi,"P",{});var e$e=s($L);QCr=r(e$e,"This class cannot be instantiated directly using "),R1e=n(e$e,"CODE",{});var Nbt=s(R1e);HCr=r(Nbt,"__init__()"),Nbt.forEach(t),UCr=r(e$e," (throws an error)."),e$e.forEach(t),JCr=i(gi),At=n(gi,"DIV",{class:!0});var hi=s(At);m(IL.$$.fragment,hi),YCr=i(hi),S1e=n(hi,"P",{});var Dbt=s(S1e);KCr=r(Dbt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Dbt.forEach(t),ZCr=i(hi),rf=n(hi,"P",{});var FQ=s(rf);eMr=r(FQ,`Note:
Loading a model from its configuration file does `),P1e=n(FQ,"STRONG",{});var jbt=s(P1e);oMr=r(jbt,"not"),jbt.forEach(t),rMr=r(FQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),$1e=n(FQ,"CODE",{});var qbt=s($1e);tMr=r(qbt,"from_pretrained()"),qbt.forEach(t),aMr=r(FQ,"to load the model weights."),FQ.forEach(t),nMr=i(hi),I1e=n(hi,"P",{});var Gbt=s(I1e);sMr=r(Gbt,"Examples:"),Gbt.forEach(t),lMr=i(hi),m(NL.$$.fragment,hi),hi.forEach(t),iMr=i(gi),Lo=n(gi,"DIV",{class:!0});var Ba=s(Lo);m(DL.$$.fragment,Ba),dMr=i(Ba),N1e=n(Ba,"P",{});var Obt=s(N1e);cMr=r(Obt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Obt.forEach(t),fMr=i(Ba),xn=n(Ba,"P",{});var JE=s(xn);mMr=r(JE,"The model class to instantiate is selected based on the "),D1e=n(JE,"CODE",{});var Xbt=s(D1e);gMr=r(Xbt,"model_type"),Xbt.forEach(t),hMr=r(JE,` property of the config object (either
passed as an argument or loaded from `),j1e=n(JE,"CODE",{});var Vbt=s(j1e);pMr=r(Vbt,"pretrained_model_name_or_path"),Vbt.forEach(t),_Mr=r(JE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q1e=n(JE,"CODE",{});var zbt=s(q1e);uMr=r(zbt,"pretrained_model_name_or_path"),zbt.forEach(t),bMr=r(JE,":"),JE.forEach(t),vMr=i(Ba),ca=n(Ba,"UL",{});var pi=s(ca);xM=n(pi,"LI",{});var qBe=s(xM);G1e=n(qBe,"STRONG",{});var Wbt=s(G1e);TMr=r(Wbt,"bart"),Wbt.forEach(t),FMr=r(qBe," \u2014 "),LV=n(qBe,"A",{href:!0});var Qbt=s(LV);CMr=r(Qbt,"FlaxBartForCausalLM"),Qbt.forEach(t),MMr=r(qBe," (BART model)"),qBe.forEach(t),EMr=i(pi),kM=n(pi,"LI",{});var GBe=s(kM);O1e=n(GBe,"STRONG",{});var Hbt=s(O1e);yMr=r(Hbt,"gpt2"),Hbt.forEach(t),wMr=r(GBe," \u2014 "),BV=n(GBe,"A",{href:!0});var Ubt=s(BV);AMr=r(Ubt,"FlaxGPT2LMHeadModel"),Ubt.forEach(t),LMr=r(GBe," (OpenAI GPT-2 model)"),GBe.forEach(t),BMr=i(pi),RM=n(pi,"LI",{});var OBe=s(RM);X1e=n(OBe,"STRONG",{});var Jbt=s(X1e);xMr=r(Jbt,"gpt_neo"),Jbt.forEach(t),kMr=r(OBe," \u2014 "),xV=n(OBe,"A",{href:!0});var Ybt=s(xV);RMr=r(Ybt,"FlaxGPTNeoForCausalLM"),Ybt.forEach(t),SMr=r(OBe," (GPT Neo model)"),OBe.forEach(t),PMr=i(pi),SM=n(pi,"LI",{});var XBe=s(SM);V1e=n(XBe,"STRONG",{});var Kbt=s(V1e);$Mr=r(Kbt,"gptj"),Kbt.forEach(t),IMr=r(XBe," \u2014 "),kV=n(XBe,"A",{href:!0});var Zbt=s(kV);NMr=r(Zbt,"FlaxGPTJForCausalLM"),Zbt.forEach(t),DMr=r(XBe," (GPT-J model)"),XBe.forEach(t),jMr=i(pi),PM=n(pi,"LI",{});var VBe=s(PM);z1e=n(VBe,"STRONG",{});var evt=s(z1e);qMr=r(evt,"xglm"),evt.forEach(t),GMr=r(VBe," \u2014 "),RV=n(VBe,"A",{href:!0});var ovt=s(RV);OMr=r(ovt,"FlaxXGLMForCausalLM"),ovt.forEach(t),XMr=r(VBe," (XGLM model)"),VBe.forEach(t),pi.forEach(t),VMr=i(Ba),W1e=n(Ba,"P",{});var rvt=s(W1e);zMr=r(rvt,"Examples:"),rvt.forEach(t),WMr=i(Ba),m(jL.$$.fragment,Ba),Ba.forEach(t),gi.forEach(t),XRe=i(c),tf=n(c,"H2",{class:!0});var o$e=s(tf);$M=n(o$e,"A",{id:!0,class:!0,href:!0});var tvt=s($M);Q1e=n(tvt,"SPAN",{});var avt=s(Q1e);m(qL.$$.fragment,avt),avt.forEach(t),tvt.forEach(t),QMr=i(o$e),H1e=n(o$e,"SPAN",{});var nvt=s(H1e);HMr=r(nvt,"FlaxAutoModelForPreTraining"),nvt.forEach(t),o$e.forEach(t),VRe=i(c),Pr=n(c,"DIV",{class:!0});var _i=s(Pr);m(GL.$$.fragment,_i),UMr=i(_i),af=n(_i,"P",{});var CQ=s(af);JMr=r(CQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),U1e=n(CQ,"CODE",{});var svt=s(U1e);YMr=r(svt,"from_pretrained()"),svt.forEach(t),KMr=r(CQ,"class method or the "),J1e=n(CQ,"CODE",{});var lvt=s(J1e);ZMr=r(lvt,"from_config()"),lvt.forEach(t),e4r=r(CQ,`class
method.`),CQ.forEach(t),o4r=i(_i),OL=n(_i,"P",{});var r$e=s(OL);r4r=r(r$e,"This class cannot be instantiated directly using "),Y1e=n(r$e,"CODE",{});var ivt=s(Y1e);t4r=r(ivt,"__init__()"),ivt.forEach(t),a4r=r(r$e," (throws an error)."),r$e.forEach(t),n4r=i(_i),Lt=n(_i,"DIV",{class:!0});var ui=s(Lt);m(XL.$$.fragment,ui),s4r=i(ui),K1e=n(ui,"P",{});var dvt=s(K1e);l4r=r(dvt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),dvt.forEach(t),i4r=i(ui),nf=n(ui,"P",{});var MQ=s(nf);d4r=r(MQ,`Note:
Loading a model from its configuration file does `),Z1e=n(MQ,"STRONG",{});var cvt=s(Z1e);c4r=r(cvt,"not"),cvt.forEach(t),f4r=r(MQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),ebe=n(MQ,"CODE",{});var fvt=s(ebe);m4r=r(fvt,"from_pretrained()"),fvt.forEach(t),g4r=r(MQ,"to load the model weights."),MQ.forEach(t),h4r=i(ui),obe=n(ui,"P",{});var mvt=s(obe);p4r=r(mvt,"Examples:"),mvt.forEach(t),_4r=i(ui),m(VL.$$.fragment,ui),ui.forEach(t),u4r=i(_i),Bo=n(_i,"DIV",{class:!0});var xa=s(Bo);m(zL.$$.fragment,xa),b4r=i(xa),rbe=n(xa,"P",{});var gvt=s(rbe);v4r=r(gvt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),gvt.forEach(t),T4r=i(xa),kn=n(xa,"P",{});var YE=s(kn);F4r=r(YE,"The model class to instantiate is selected based on the "),tbe=n(YE,"CODE",{});var hvt=s(tbe);C4r=r(hvt,"model_type"),hvt.forEach(t),M4r=r(YE,` property of the config object (either
passed as an argument or loaded from `),abe=n(YE,"CODE",{});var pvt=s(abe);E4r=r(pvt,"pretrained_model_name_or_path"),pvt.forEach(t),y4r=r(YE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=n(YE,"CODE",{});var _vt=s(nbe);w4r=r(_vt,"pretrained_model_name_or_path"),_vt.forEach(t),A4r=r(YE,":"),YE.forEach(t),L4r=i(xa),ce=n(xa,"UL",{});var he=s(ce);IM=n(he,"LI",{});var zBe=s(IM);sbe=n(zBe,"STRONG",{});var uvt=s(sbe);B4r=r(uvt,"albert"),uvt.forEach(t),x4r=r(zBe," \u2014 "),SV=n(zBe,"A",{href:!0});var bvt=s(SV);k4r=r(bvt,"FlaxAlbertForPreTraining"),bvt.forEach(t),R4r=r(zBe," (ALBERT model)"),zBe.forEach(t),S4r=i(he),NM=n(he,"LI",{});var WBe=s(NM);lbe=n(WBe,"STRONG",{});var vvt=s(lbe);P4r=r(vvt,"bart"),vvt.forEach(t),$4r=r(WBe," \u2014 "),PV=n(WBe,"A",{href:!0});var Tvt=s(PV);I4r=r(Tvt,"FlaxBartForConditionalGeneration"),Tvt.forEach(t),N4r=r(WBe," (BART model)"),WBe.forEach(t),D4r=i(he),DM=n(he,"LI",{});var QBe=s(DM);ibe=n(QBe,"STRONG",{});var Fvt=s(ibe);j4r=r(Fvt,"bert"),Fvt.forEach(t),q4r=r(QBe," \u2014 "),$V=n(QBe,"A",{href:!0});var Cvt=s($V);G4r=r(Cvt,"FlaxBertForPreTraining"),Cvt.forEach(t),O4r=r(QBe," (BERT model)"),QBe.forEach(t),X4r=i(he),jM=n(he,"LI",{});var HBe=s(jM);dbe=n(HBe,"STRONG",{});var Mvt=s(dbe);V4r=r(Mvt,"big_bird"),Mvt.forEach(t),z4r=r(HBe," \u2014 "),IV=n(HBe,"A",{href:!0});var Evt=s(IV);W4r=r(Evt,"FlaxBigBirdForPreTraining"),Evt.forEach(t),Q4r=r(HBe," (BigBird model)"),HBe.forEach(t),H4r=i(he),qM=n(he,"LI",{});var UBe=s(qM);cbe=n(UBe,"STRONG",{});var yvt=s(cbe);U4r=r(yvt,"electra"),yvt.forEach(t),J4r=r(UBe," \u2014 "),NV=n(UBe,"A",{href:!0});var wvt=s(NV);Y4r=r(wvt,"FlaxElectraForPreTraining"),wvt.forEach(t),K4r=r(UBe," (ELECTRA model)"),UBe.forEach(t),Z4r=i(he),GM=n(he,"LI",{});var JBe=s(GM);fbe=n(JBe,"STRONG",{});var Avt=s(fbe);eEr=r(Avt,"mbart"),Avt.forEach(t),oEr=r(JBe," \u2014 "),DV=n(JBe,"A",{href:!0});var Lvt=s(DV);rEr=r(Lvt,"FlaxMBartForConditionalGeneration"),Lvt.forEach(t),tEr=r(JBe," (mBART model)"),JBe.forEach(t),aEr=i(he),OM=n(he,"LI",{});var YBe=s(OM);mbe=n(YBe,"STRONG",{});var Bvt=s(mbe);nEr=r(Bvt,"mt5"),Bvt.forEach(t),sEr=r(YBe," \u2014 "),jV=n(YBe,"A",{href:!0});var xvt=s(jV);lEr=r(xvt,"FlaxMT5ForConditionalGeneration"),xvt.forEach(t),iEr=r(YBe," (mT5 model)"),YBe.forEach(t),dEr=i(he),XM=n(he,"LI",{});var KBe=s(XM);gbe=n(KBe,"STRONG",{});var kvt=s(gbe);cEr=r(kvt,"roberta"),kvt.forEach(t),fEr=r(KBe," \u2014 "),qV=n(KBe,"A",{href:!0});var Rvt=s(qV);mEr=r(Rvt,"FlaxRobertaForMaskedLM"),Rvt.forEach(t),gEr=r(KBe," (RoBERTa model)"),KBe.forEach(t),hEr=i(he),VM=n(he,"LI",{});var ZBe=s(VM);hbe=n(ZBe,"STRONG",{});var Svt=s(hbe);pEr=r(Svt,"roformer"),Svt.forEach(t),_Er=r(ZBe," \u2014 "),GV=n(ZBe,"A",{href:!0});var Pvt=s(GV);uEr=r(Pvt,"FlaxRoFormerForMaskedLM"),Pvt.forEach(t),bEr=r(ZBe," (RoFormer model)"),ZBe.forEach(t),vEr=i(he),zM=n(he,"LI",{});var exe=s(zM);pbe=n(exe,"STRONG",{});var $vt=s(pbe);TEr=r($vt,"t5"),$vt.forEach(t),FEr=r(exe," \u2014 "),OV=n(exe,"A",{href:!0});var Ivt=s(OV);CEr=r(Ivt,"FlaxT5ForConditionalGeneration"),Ivt.forEach(t),MEr=r(exe," (T5 model)"),exe.forEach(t),EEr=i(he),WM=n(he,"LI",{});var oxe=s(WM);_be=n(oxe,"STRONG",{});var Nvt=s(_be);yEr=r(Nvt,"wav2vec2"),Nvt.forEach(t),wEr=r(oxe," \u2014 "),XV=n(oxe,"A",{href:!0});var Dvt=s(XV);AEr=r(Dvt,"FlaxWav2Vec2ForPreTraining"),Dvt.forEach(t),LEr=r(oxe," (Wav2Vec2 model)"),oxe.forEach(t),BEr=i(he),QM=n(he,"LI",{});var rxe=s(QM);ube=n(rxe,"STRONG",{});var jvt=s(ube);xEr=r(jvt,"xlm-roberta"),jvt.forEach(t),kEr=r(rxe," \u2014 "),VV=n(rxe,"A",{href:!0});var qvt=s(VV);REr=r(qvt,"FlaxXLMRobertaForMaskedLM"),qvt.forEach(t),SEr=r(rxe," (XLM-RoBERTa model)"),rxe.forEach(t),he.forEach(t),PEr=i(xa),bbe=n(xa,"P",{});var Gvt=s(bbe);$Er=r(Gvt,"Examples:"),Gvt.forEach(t),IEr=i(xa),m(WL.$$.fragment,xa),xa.forEach(t),_i.forEach(t),zRe=i(c),sf=n(c,"H2",{class:!0});var t$e=s(sf);HM=n(t$e,"A",{id:!0,class:!0,href:!0});var Ovt=s(HM);vbe=n(Ovt,"SPAN",{});var Xvt=s(vbe);m(QL.$$.fragment,Xvt),Xvt.forEach(t),Ovt.forEach(t),NEr=i(t$e),Tbe=n(t$e,"SPAN",{});var Vvt=s(Tbe);DEr=r(Vvt,"FlaxAutoModelForMaskedLM"),Vvt.forEach(t),t$e.forEach(t),WRe=i(c),$r=n(c,"DIV",{class:!0});var bi=s($r);m(HL.$$.fragment,bi),jEr=i(bi),lf=n(bi,"P",{});var EQ=s(lf);qEr=r(EQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fbe=n(EQ,"CODE",{});var zvt=s(Fbe);GEr=r(zvt,"from_pretrained()"),zvt.forEach(t),OEr=r(EQ,"class method or the "),Cbe=n(EQ,"CODE",{});var Wvt=s(Cbe);XEr=r(Wvt,"from_config()"),Wvt.forEach(t),VEr=r(EQ,`class
method.`),EQ.forEach(t),zEr=i(bi),UL=n(bi,"P",{});var a$e=s(UL);WEr=r(a$e,"This class cannot be instantiated directly using "),Mbe=n(a$e,"CODE",{});var Qvt=s(Mbe);QEr=r(Qvt,"__init__()"),Qvt.forEach(t),HEr=r(a$e," (throws an error)."),a$e.forEach(t),UEr=i(bi),Bt=n(bi,"DIV",{class:!0});var vi=s(Bt);m(JL.$$.fragment,vi),JEr=i(vi),Ebe=n(vi,"P",{});var Hvt=s(Ebe);YEr=r(Hvt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Hvt.forEach(t),KEr=i(vi),df=n(vi,"P",{});var yQ=s(df);ZEr=r(yQ,`Note:
Loading a model from its configuration file does `),ybe=n(yQ,"STRONG",{});var Uvt=s(ybe);e3r=r(Uvt,"not"),Uvt.forEach(t),o3r=r(yQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),wbe=n(yQ,"CODE",{});var Jvt=s(wbe);r3r=r(Jvt,"from_pretrained()"),Jvt.forEach(t),t3r=r(yQ,"to load the model weights."),yQ.forEach(t),a3r=i(vi),Abe=n(vi,"P",{});var Yvt=s(Abe);n3r=r(Yvt,"Examples:"),Yvt.forEach(t),s3r=i(vi),m(YL.$$.fragment,vi),vi.forEach(t),l3r=i(bi),xo=n(bi,"DIV",{class:!0});var ka=s(xo);m(KL.$$.fragment,ka),i3r=i(ka),Lbe=n(ka,"P",{});var Kvt=s(Lbe);d3r=r(Kvt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Kvt.forEach(t),c3r=i(ka),Rn=n(ka,"P",{});var KE=s(Rn);f3r=r(KE,"The model class to instantiate is selected based on the "),Bbe=n(KE,"CODE",{});var Zvt=s(Bbe);m3r=r(Zvt,"model_type"),Zvt.forEach(t),g3r=r(KE,` property of the config object (either
passed as an argument or loaded from `),xbe=n(KE,"CODE",{});var e6t=s(xbe);h3r=r(e6t,"pretrained_model_name_or_path"),e6t.forEach(t),p3r=r(KE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kbe=n(KE,"CODE",{});var o6t=s(kbe);_3r=r(o6t,"pretrained_model_name_or_path"),o6t.forEach(t),u3r=r(KE,":"),KE.forEach(t),b3r=i(ka),ue=n(ka,"UL",{});var we=s(ue);UM=n(we,"LI",{});var txe=s(UM);Rbe=n(txe,"STRONG",{});var r6t=s(Rbe);v3r=r(r6t,"albert"),r6t.forEach(t),T3r=r(txe," \u2014 "),zV=n(txe,"A",{href:!0});var t6t=s(zV);F3r=r(t6t,"FlaxAlbertForMaskedLM"),t6t.forEach(t),C3r=r(txe," (ALBERT model)"),txe.forEach(t),M3r=i(we),JM=n(we,"LI",{});var axe=s(JM);Sbe=n(axe,"STRONG",{});var a6t=s(Sbe);E3r=r(a6t,"bart"),a6t.forEach(t),y3r=r(axe," \u2014 "),WV=n(axe,"A",{href:!0});var n6t=s(WV);w3r=r(n6t,"FlaxBartForConditionalGeneration"),n6t.forEach(t),A3r=r(axe," (BART model)"),axe.forEach(t),L3r=i(we),YM=n(we,"LI",{});var nxe=s(YM);Pbe=n(nxe,"STRONG",{});var s6t=s(Pbe);B3r=r(s6t,"bert"),s6t.forEach(t),x3r=r(nxe," \u2014 "),QV=n(nxe,"A",{href:!0});var l6t=s(QV);k3r=r(l6t,"FlaxBertForMaskedLM"),l6t.forEach(t),R3r=r(nxe," (BERT model)"),nxe.forEach(t),S3r=i(we),KM=n(we,"LI",{});var sxe=s(KM);$be=n(sxe,"STRONG",{});var i6t=s($be);P3r=r(i6t,"big_bird"),i6t.forEach(t),$3r=r(sxe," \u2014 "),HV=n(sxe,"A",{href:!0});var d6t=s(HV);I3r=r(d6t,"FlaxBigBirdForMaskedLM"),d6t.forEach(t),N3r=r(sxe," (BigBird model)"),sxe.forEach(t),D3r=i(we),ZM=n(we,"LI",{});var lxe=s(ZM);Ibe=n(lxe,"STRONG",{});var c6t=s(Ibe);j3r=r(c6t,"distilbert"),c6t.forEach(t),q3r=r(lxe," \u2014 "),UV=n(lxe,"A",{href:!0});var f6t=s(UV);G3r=r(f6t,"FlaxDistilBertForMaskedLM"),f6t.forEach(t),O3r=r(lxe," (DistilBERT model)"),lxe.forEach(t),X3r=i(we),e4=n(we,"LI",{});var ixe=s(e4);Nbe=n(ixe,"STRONG",{});var m6t=s(Nbe);V3r=r(m6t,"electra"),m6t.forEach(t),z3r=r(ixe," \u2014 "),JV=n(ixe,"A",{href:!0});var g6t=s(JV);W3r=r(g6t,"FlaxElectraForMaskedLM"),g6t.forEach(t),Q3r=r(ixe," (ELECTRA model)"),ixe.forEach(t),H3r=i(we),o4=n(we,"LI",{});var dxe=s(o4);Dbe=n(dxe,"STRONG",{});var h6t=s(Dbe);U3r=r(h6t,"mbart"),h6t.forEach(t),J3r=r(dxe," \u2014 "),YV=n(dxe,"A",{href:!0});var p6t=s(YV);Y3r=r(p6t,"FlaxMBartForConditionalGeneration"),p6t.forEach(t),K3r=r(dxe," (mBART model)"),dxe.forEach(t),Z3r=i(we),r4=n(we,"LI",{});var cxe=s(r4);jbe=n(cxe,"STRONG",{});var _6t=s(jbe);eyr=r(_6t,"roberta"),_6t.forEach(t),oyr=r(cxe," \u2014 "),KV=n(cxe,"A",{href:!0});var u6t=s(KV);ryr=r(u6t,"FlaxRobertaForMaskedLM"),u6t.forEach(t),tyr=r(cxe," (RoBERTa model)"),cxe.forEach(t),ayr=i(we),t4=n(we,"LI",{});var fxe=s(t4);qbe=n(fxe,"STRONG",{});var b6t=s(qbe);nyr=r(b6t,"roformer"),b6t.forEach(t),syr=r(fxe," \u2014 "),ZV=n(fxe,"A",{href:!0});var v6t=s(ZV);lyr=r(v6t,"FlaxRoFormerForMaskedLM"),v6t.forEach(t),iyr=r(fxe," (RoFormer model)"),fxe.forEach(t),dyr=i(we),a4=n(we,"LI",{});var mxe=s(a4);Gbe=n(mxe,"STRONG",{});var T6t=s(Gbe);cyr=r(T6t,"xlm-roberta"),T6t.forEach(t),fyr=r(mxe," \u2014 "),ez=n(mxe,"A",{href:!0});var F6t=s(ez);myr=r(F6t,"FlaxXLMRobertaForMaskedLM"),F6t.forEach(t),gyr=r(mxe," (XLM-RoBERTa model)"),mxe.forEach(t),we.forEach(t),hyr=i(ka),Obe=n(ka,"P",{});var C6t=s(Obe);pyr=r(C6t,"Examples:"),C6t.forEach(t),_yr=i(ka),m(ZL.$$.fragment,ka),ka.forEach(t),bi.forEach(t),QRe=i(c),cf=n(c,"H2",{class:!0});var n$e=s(cf);n4=n(n$e,"A",{id:!0,class:!0,href:!0});var M6t=s(n4);Xbe=n(M6t,"SPAN",{});var E6t=s(Xbe);m(e7.$$.fragment,E6t),E6t.forEach(t),M6t.forEach(t),uyr=i(n$e),Vbe=n(n$e,"SPAN",{});var y6t=s(Vbe);byr=r(y6t,"FlaxAutoModelForSeq2SeqLM"),y6t.forEach(t),n$e.forEach(t),HRe=i(c),Ir=n(c,"DIV",{class:!0});var Ti=s(Ir);m(o7.$$.fragment,Ti),vyr=i(Ti),ff=n(Ti,"P",{});var wQ=s(ff);Tyr=r(wQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zbe=n(wQ,"CODE",{});var w6t=s(zbe);Fyr=r(w6t,"from_pretrained()"),w6t.forEach(t),Cyr=r(wQ,"class method or the "),Wbe=n(wQ,"CODE",{});var A6t=s(Wbe);Myr=r(A6t,"from_config()"),A6t.forEach(t),Eyr=r(wQ,`class
method.`),wQ.forEach(t),yyr=i(Ti),r7=n(Ti,"P",{});var s$e=s(r7);wyr=r(s$e,"This class cannot be instantiated directly using "),Qbe=n(s$e,"CODE",{});var L6t=s(Qbe);Ayr=r(L6t,"__init__()"),L6t.forEach(t),Lyr=r(s$e," (throws an error)."),s$e.forEach(t),Byr=i(Ti),xt=n(Ti,"DIV",{class:!0});var Fi=s(xt);m(t7.$$.fragment,Fi),xyr=i(Fi),Hbe=n(Fi,"P",{});var B6t=s(Hbe);kyr=r(B6t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),B6t.forEach(t),Ryr=i(Fi),mf=n(Fi,"P",{});var AQ=s(mf);Syr=r(AQ,`Note:
Loading a model from its configuration file does `),Ube=n(AQ,"STRONG",{});var x6t=s(Ube);Pyr=r(x6t,"not"),x6t.forEach(t),$yr=r(AQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jbe=n(AQ,"CODE",{});var k6t=s(Jbe);Iyr=r(k6t,"from_pretrained()"),k6t.forEach(t),Nyr=r(AQ,"to load the model weights."),AQ.forEach(t),Dyr=i(Fi),Ybe=n(Fi,"P",{});var R6t=s(Ybe);jyr=r(R6t,"Examples:"),R6t.forEach(t),qyr=i(Fi),m(a7.$$.fragment,Fi),Fi.forEach(t),Gyr=i(Ti),ko=n(Ti,"DIV",{class:!0});var Ra=s(ko);m(n7.$$.fragment,Ra),Oyr=i(Ra),Kbe=n(Ra,"P",{});var S6t=s(Kbe);Xyr=r(S6t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),S6t.forEach(t),Vyr=i(Ra),Sn=n(Ra,"P",{});var ZE=s(Sn);zyr=r(ZE,"The model class to instantiate is selected based on the "),Zbe=n(ZE,"CODE",{});var P6t=s(Zbe);Wyr=r(P6t,"model_type"),P6t.forEach(t),Qyr=r(ZE,` property of the config object (either
passed as an argument or loaded from `),eve=n(ZE,"CODE",{});var $6t=s(eve);Hyr=r($6t,"pretrained_model_name_or_path"),$6t.forEach(t),Uyr=r(ZE,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ove=n(ZE,"CODE",{});var I6t=s(ove);Jyr=r(I6t,"pretrained_model_name_or_path"),I6t.forEach(t),Yyr=r(ZE,":"),ZE.forEach(t),Kyr=i(Ra),Me=n(Ra,"UL",{});var so=s(Me);s4=n(so,"LI",{});var gxe=s(s4);rve=n(gxe,"STRONG",{});var N6t=s(rve);Zyr=r(N6t,"bart"),N6t.forEach(t),ewr=r(gxe," \u2014 "),oz=n(gxe,"A",{href:!0});var D6t=s(oz);owr=r(D6t,"FlaxBartForConditionalGeneration"),D6t.forEach(t),rwr=r(gxe," (BART model)"),gxe.forEach(t),twr=i(so),l4=n(so,"LI",{});var hxe=s(l4);tve=n(hxe,"STRONG",{});var j6t=s(tve);awr=r(j6t,"blenderbot"),j6t.forEach(t),nwr=r(hxe," \u2014 "),rz=n(hxe,"A",{href:!0});var q6t=s(rz);swr=r(q6t,"FlaxBlenderbotForConditionalGeneration"),q6t.forEach(t),lwr=r(hxe," (Blenderbot model)"),hxe.forEach(t),iwr=i(so),i4=n(so,"LI",{});var pxe=s(i4);ave=n(pxe,"STRONG",{});var G6t=s(ave);dwr=r(G6t,"blenderbot-small"),G6t.forEach(t),cwr=r(pxe," \u2014 "),tz=n(pxe,"A",{href:!0});var O6t=s(tz);fwr=r(O6t,"FlaxBlenderbotSmallForConditionalGeneration"),O6t.forEach(t),mwr=r(pxe," (BlenderbotSmall model)"),pxe.forEach(t),gwr=i(so),d4=n(so,"LI",{});var _xe=s(d4);nve=n(_xe,"STRONG",{});var X6t=s(nve);hwr=r(X6t,"encoder-decoder"),X6t.forEach(t),pwr=r(_xe," \u2014 "),az=n(_xe,"A",{href:!0});var V6t=s(az);_wr=r(V6t,"FlaxEncoderDecoderModel"),V6t.forEach(t),uwr=r(_xe," (Encoder decoder model)"),_xe.forEach(t),bwr=i(so),c4=n(so,"LI",{});var uxe=s(c4);sve=n(uxe,"STRONG",{});var z6t=s(sve);vwr=r(z6t,"marian"),z6t.forEach(t),Twr=r(uxe," \u2014 "),nz=n(uxe,"A",{href:!0});var W6t=s(nz);Fwr=r(W6t,"FlaxMarianMTModel"),W6t.forEach(t),Cwr=r(uxe," (Marian model)"),uxe.forEach(t),Mwr=i(so),f4=n(so,"LI",{});var bxe=s(f4);lve=n(bxe,"STRONG",{});var Q6t=s(lve);Ewr=r(Q6t,"mbart"),Q6t.forEach(t),ywr=r(bxe," \u2014 "),sz=n(bxe,"A",{href:!0});var H6t=s(sz);wwr=r(H6t,"FlaxMBartForConditionalGeneration"),H6t.forEach(t),Awr=r(bxe," (mBART model)"),bxe.forEach(t),Lwr=i(so),m4=n(so,"LI",{});var vxe=s(m4);ive=n(vxe,"STRONG",{});var U6t=s(ive);Bwr=r(U6t,"mt5"),U6t.forEach(t),xwr=r(vxe," \u2014 "),lz=n(vxe,"A",{href:!0});var J6t=s(lz);kwr=r(J6t,"FlaxMT5ForConditionalGeneration"),J6t.forEach(t),Rwr=r(vxe," (mT5 model)"),vxe.forEach(t),Swr=i(so),g4=n(so,"LI",{});var Txe=s(g4);dve=n(Txe,"STRONG",{});var Y6t=s(dve);Pwr=r(Y6t,"pegasus"),Y6t.forEach(t),$wr=r(Txe," \u2014 "),iz=n(Txe,"A",{href:!0});var K6t=s(iz);Iwr=r(K6t,"FlaxPegasusForConditionalGeneration"),K6t.forEach(t),Nwr=r(Txe," (Pegasus model)"),Txe.forEach(t),Dwr=i(so),h4=n(so,"LI",{});var Fxe=s(h4);cve=n(Fxe,"STRONG",{});var Z6t=s(cve);jwr=r(Z6t,"t5"),Z6t.forEach(t),qwr=r(Fxe," \u2014 "),dz=n(Fxe,"A",{href:!0});var eTt=s(dz);Gwr=r(eTt,"FlaxT5ForConditionalGeneration"),eTt.forEach(t),Owr=r(Fxe," (T5 model)"),Fxe.forEach(t),so.forEach(t),Xwr=i(Ra),fve=n(Ra,"P",{});var oTt=s(fve);Vwr=r(oTt,"Examples:"),oTt.forEach(t),zwr=i(Ra),m(s7.$$.fragment,Ra),Ra.forEach(t),Ti.forEach(t),URe=i(c),gf=n(c,"H2",{class:!0});var l$e=s(gf);p4=n(l$e,"A",{id:!0,class:!0,href:!0});var rTt=s(p4);mve=n(rTt,"SPAN",{});var tTt=s(mve);m(l7.$$.fragment,tTt),tTt.forEach(t),rTt.forEach(t),Wwr=i(l$e),gve=n(l$e,"SPAN",{});var aTt=s(gve);Qwr=r(aTt,"FlaxAutoModelForSequenceClassification"),aTt.forEach(t),l$e.forEach(t),JRe=i(c),Nr=n(c,"DIV",{class:!0});var Ci=s(Nr);m(i7.$$.fragment,Ci),Hwr=i(Ci),hf=n(Ci,"P",{});var LQ=s(hf);Uwr=r(LQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hve=n(LQ,"CODE",{});var nTt=s(hve);Jwr=r(nTt,"from_pretrained()"),nTt.forEach(t),Ywr=r(LQ,"class method or the "),pve=n(LQ,"CODE",{});var sTt=s(pve);Kwr=r(sTt,"from_config()"),sTt.forEach(t),Zwr=r(LQ,`class
method.`),LQ.forEach(t),eAr=i(Ci),d7=n(Ci,"P",{});var i$e=s(d7);oAr=r(i$e,"This class cannot be instantiated directly using "),_ve=n(i$e,"CODE",{});var lTt=s(_ve);rAr=r(lTt,"__init__()"),lTt.forEach(t),tAr=r(i$e," (throws an error)."),i$e.forEach(t),aAr=i(Ci),kt=n(Ci,"DIV",{class:!0});var Mi=s(kt);m(c7.$$.fragment,Mi),nAr=i(Mi),uve=n(Mi,"P",{});var iTt=s(uve);sAr=r(iTt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),iTt.forEach(t),lAr=i(Mi),pf=n(Mi,"P",{});var BQ=s(pf);iAr=r(BQ,`Note:
Loading a model from its configuration file does `),bve=n(BQ,"STRONG",{});var dTt=s(bve);dAr=r(dTt,"not"),dTt.forEach(t),cAr=r(BQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),vve=n(BQ,"CODE",{});var cTt=s(vve);fAr=r(cTt,"from_pretrained()"),cTt.forEach(t),mAr=r(BQ,"to load the model weights."),BQ.forEach(t),gAr=i(Mi),Tve=n(Mi,"P",{});var fTt=s(Tve);hAr=r(fTt,"Examples:"),fTt.forEach(t),pAr=i(Mi),m(f7.$$.fragment,Mi),Mi.forEach(t),_Ar=i(Ci),Ro=n(Ci,"DIV",{class:!0});var Sa=s(Ro);m(m7.$$.fragment,Sa),uAr=i(Sa),Fve=n(Sa,"P",{});var mTt=s(Fve);bAr=r(mTt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),mTt.forEach(t),vAr=i(Sa),Pn=n(Sa,"P",{});var e3=s(Pn);TAr=r(e3,"The model class to instantiate is selected based on the "),Cve=n(e3,"CODE",{});var gTt=s(Cve);FAr=r(gTt,"model_type"),gTt.forEach(t),CAr=r(e3,` property of the config object (either
passed as an argument or loaded from `),Mve=n(e3,"CODE",{});var hTt=s(Mve);MAr=r(hTt,"pretrained_model_name_or_path"),hTt.forEach(t),EAr=r(e3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Eve=n(e3,"CODE",{});var pTt=s(Eve);yAr=r(pTt,"pretrained_model_name_or_path"),pTt.forEach(t),wAr=r(e3,":"),e3.forEach(t),AAr=i(Sa),be=n(Sa,"UL",{});var Ae=s(be);_4=n(Ae,"LI",{});var Cxe=s(_4);yve=n(Cxe,"STRONG",{});var _Tt=s(yve);LAr=r(_Tt,"albert"),_Tt.forEach(t),BAr=r(Cxe," \u2014 "),cz=n(Cxe,"A",{href:!0});var uTt=s(cz);xAr=r(uTt,"FlaxAlbertForSequenceClassification"),uTt.forEach(t),kAr=r(Cxe," (ALBERT model)"),Cxe.forEach(t),RAr=i(Ae),u4=n(Ae,"LI",{});var Mxe=s(u4);wve=n(Mxe,"STRONG",{});var bTt=s(wve);SAr=r(bTt,"bart"),bTt.forEach(t),PAr=r(Mxe," \u2014 "),fz=n(Mxe,"A",{href:!0});var vTt=s(fz);$Ar=r(vTt,"FlaxBartForSequenceClassification"),vTt.forEach(t),IAr=r(Mxe," (BART model)"),Mxe.forEach(t),NAr=i(Ae),b4=n(Ae,"LI",{});var Exe=s(b4);Ave=n(Exe,"STRONG",{});var TTt=s(Ave);DAr=r(TTt,"bert"),TTt.forEach(t),jAr=r(Exe," \u2014 "),mz=n(Exe,"A",{href:!0});var FTt=s(mz);qAr=r(FTt,"FlaxBertForSequenceClassification"),FTt.forEach(t),GAr=r(Exe," (BERT model)"),Exe.forEach(t),OAr=i(Ae),v4=n(Ae,"LI",{});var yxe=s(v4);Lve=n(yxe,"STRONG",{});var CTt=s(Lve);XAr=r(CTt,"big_bird"),CTt.forEach(t),VAr=r(yxe," \u2014 "),gz=n(yxe,"A",{href:!0});var MTt=s(gz);zAr=r(MTt,"FlaxBigBirdForSequenceClassification"),MTt.forEach(t),WAr=r(yxe," (BigBird model)"),yxe.forEach(t),QAr=i(Ae),T4=n(Ae,"LI",{});var wxe=s(T4);Bve=n(wxe,"STRONG",{});var ETt=s(Bve);HAr=r(ETt,"distilbert"),ETt.forEach(t),UAr=r(wxe," \u2014 "),hz=n(wxe,"A",{href:!0});var yTt=s(hz);JAr=r(yTt,"FlaxDistilBertForSequenceClassification"),yTt.forEach(t),YAr=r(wxe," (DistilBERT model)"),wxe.forEach(t),KAr=i(Ae),F4=n(Ae,"LI",{});var Axe=s(F4);xve=n(Axe,"STRONG",{});var wTt=s(xve);ZAr=r(wTt,"electra"),wTt.forEach(t),e0r=r(Axe," \u2014 "),pz=n(Axe,"A",{href:!0});var ATt=s(pz);o0r=r(ATt,"FlaxElectraForSequenceClassification"),ATt.forEach(t),r0r=r(Axe," (ELECTRA model)"),Axe.forEach(t),t0r=i(Ae),C4=n(Ae,"LI",{});var Lxe=s(C4);kve=n(Lxe,"STRONG",{});var LTt=s(kve);a0r=r(LTt,"mbart"),LTt.forEach(t),n0r=r(Lxe," \u2014 "),_z=n(Lxe,"A",{href:!0});var BTt=s(_z);s0r=r(BTt,"FlaxMBartForSequenceClassification"),BTt.forEach(t),l0r=r(Lxe," (mBART model)"),Lxe.forEach(t),i0r=i(Ae),M4=n(Ae,"LI",{});var Bxe=s(M4);Rve=n(Bxe,"STRONG",{});var xTt=s(Rve);d0r=r(xTt,"roberta"),xTt.forEach(t),c0r=r(Bxe," \u2014 "),uz=n(Bxe,"A",{href:!0});var kTt=s(uz);f0r=r(kTt,"FlaxRobertaForSequenceClassification"),kTt.forEach(t),m0r=r(Bxe," (RoBERTa model)"),Bxe.forEach(t),g0r=i(Ae),E4=n(Ae,"LI",{});var xxe=s(E4);Sve=n(xxe,"STRONG",{});var RTt=s(Sve);h0r=r(RTt,"roformer"),RTt.forEach(t),p0r=r(xxe," \u2014 "),bz=n(xxe,"A",{href:!0});var STt=s(bz);_0r=r(STt,"FlaxRoFormerForSequenceClassification"),STt.forEach(t),u0r=r(xxe," (RoFormer model)"),xxe.forEach(t),b0r=i(Ae),y4=n(Ae,"LI",{});var kxe=s(y4);Pve=n(kxe,"STRONG",{});var PTt=s(Pve);v0r=r(PTt,"xlm-roberta"),PTt.forEach(t),T0r=r(kxe," \u2014 "),vz=n(kxe,"A",{href:!0});var $Tt=s(vz);F0r=r($Tt,"FlaxXLMRobertaForSequenceClassification"),$Tt.forEach(t),C0r=r(kxe," (XLM-RoBERTa model)"),kxe.forEach(t),Ae.forEach(t),M0r=i(Sa),$ve=n(Sa,"P",{});var ITt=s($ve);E0r=r(ITt,"Examples:"),ITt.forEach(t),y0r=i(Sa),m(g7.$$.fragment,Sa),Sa.forEach(t),Ci.forEach(t),YRe=i(c),_f=n(c,"H2",{class:!0});var d$e=s(_f);w4=n(d$e,"A",{id:!0,class:!0,href:!0});var NTt=s(w4);Ive=n(NTt,"SPAN",{});var DTt=s(Ive);m(h7.$$.fragment,DTt),DTt.forEach(t),NTt.forEach(t),w0r=i(d$e),Nve=n(d$e,"SPAN",{});var jTt=s(Nve);A0r=r(jTt,"FlaxAutoModelForQuestionAnswering"),jTt.forEach(t),d$e.forEach(t),KRe=i(c),Dr=n(c,"DIV",{class:!0});var Ei=s(Dr);m(p7.$$.fragment,Ei),L0r=i(Ei),uf=n(Ei,"P",{});var xQ=s(uf);B0r=r(xQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dve=n(xQ,"CODE",{});var qTt=s(Dve);x0r=r(qTt,"from_pretrained()"),qTt.forEach(t),k0r=r(xQ,"class method or the "),jve=n(xQ,"CODE",{});var GTt=s(jve);R0r=r(GTt,"from_config()"),GTt.forEach(t),S0r=r(xQ,`class
method.`),xQ.forEach(t),P0r=i(Ei),_7=n(Ei,"P",{});var c$e=s(_7);$0r=r(c$e,"This class cannot be instantiated directly using "),qve=n(c$e,"CODE",{});var OTt=s(qve);I0r=r(OTt,"__init__()"),OTt.forEach(t),N0r=r(c$e," (throws an error)."),c$e.forEach(t),D0r=i(Ei),Rt=n(Ei,"DIV",{class:!0});var yi=s(Rt);m(u7.$$.fragment,yi),j0r=i(yi),Gve=n(yi,"P",{});var XTt=s(Gve);q0r=r(XTt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),XTt.forEach(t),G0r=i(yi),bf=n(yi,"P",{});var kQ=s(bf);O0r=r(kQ,`Note:
Loading a model from its configuration file does `),Ove=n(kQ,"STRONG",{});var VTt=s(Ove);X0r=r(VTt,"not"),VTt.forEach(t),V0r=r(kQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xve=n(kQ,"CODE",{});var zTt=s(Xve);z0r=r(zTt,"from_pretrained()"),zTt.forEach(t),W0r=r(kQ,"to load the model weights."),kQ.forEach(t),Q0r=i(yi),Vve=n(yi,"P",{});var WTt=s(Vve);H0r=r(WTt,"Examples:"),WTt.forEach(t),U0r=i(yi),m(b7.$$.fragment,yi),yi.forEach(t),J0r=i(Ei),So=n(Ei,"DIV",{class:!0});var Pa=s(So);m(v7.$$.fragment,Pa),Y0r=i(Pa),zve=n(Pa,"P",{});var QTt=s(zve);K0r=r(QTt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),QTt.forEach(t),Z0r=i(Pa),$n=n(Pa,"P",{});var o3=s($n);eLr=r(o3,"The model class to instantiate is selected based on the "),Wve=n(o3,"CODE",{});var HTt=s(Wve);oLr=r(HTt,"model_type"),HTt.forEach(t),rLr=r(o3,` property of the config object (either
passed as an argument or loaded from `),Qve=n(o3,"CODE",{});var UTt=s(Qve);tLr=r(UTt,"pretrained_model_name_or_path"),UTt.forEach(t),aLr=r(o3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hve=n(o3,"CODE",{});var JTt=s(Hve);nLr=r(JTt,"pretrained_model_name_or_path"),JTt.forEach(t),sLr=r(o3,":"),o3.forEach(t),lLr=i(Pa),ve=n(Pa,"UL",{});var Le=s(ve);A4=n(Le,"LI",{});var Rxe=s(A4);Uve=n(Rxe,"STRONG",{});var YTt=s(Uve);iLr=r(YTt,"albert"),YTt.forEach(t),dLr=r(Rxe," \u2014 "),Tz=n(Rxe,"A",{href:!0});var KTt=s(Tz);cLr=r(KTt,"FlaxAlbertForQuestionAnswering"),KTt.forEach(t),fLr=r(Rxe," (ALBERT model)"),Rxe.forEach(t),mLr=i(Le),L4=n(Le,"LI",{});var Sxe=s(L4);Jve=n(Sxe,"STRONG",{});var ZTt=s(Jve);gLr=r(ZTt,"bart"),ZTt.forEach(t),hLr=r(Sxe," \u2014 "),Fz=n(Sxe,"A",{href:!0});var eFt=s(Fz);pLr=r(eFt,"FlaxBartForQuestionAnswering"),eFt.forEach(t),_Lr=r(Sxe," (BART model)"),Sxe.forEach(t),uLr=i(Le),B4=n(Le,"LI",{});var Pxe=s(B4);Yve=n(Pxe,"STRONG",{});var oFt=s(Yve);bLr=r(oFt,"bert"),oFt.forEach(t),vLr=r(Pxe," \u2014 "),Cz=n(Pxe,"A",{href:!0});var rFt=s(Cz);TLr=r(rFt,"FlaxBertForQuestionAnswering"),rFt.forEach(t),FLr=r(Pxe," (BERT model)"),Pxe.forEach(t),CLr=i(Le),x4=n(Le,"LI",{});var $xe=s(x4);Kve=n($xe,"STRONG",{});var tFt=s(Kve);MLr=r(tFt,"big_bird"),tFt.forEach(t),ELr=r($xe," \u2014 "),Mz=n($xe,"A",{href:!0});var aFt=s(Mz);yLr=r(aFt,"FlaxBigBirdForQuestionAnswering"),aFt.forEach(t),wLr=r($xe," (BigBird model)"),$xe.forEach(t),ALr=i(Le),k4=n(Le,"LI",{});var Ixe=s(k4);Zve=n(Ixe,"STRONG",{});var nFt=s(Zve);LLr=r(nFt,"distilbert"),nFt.forEach(t),BLr=r(Ixe," \u2014 "),Ez=n(Ixe,"A",{href:!0});var sFt=s(Ez);xLr=r(sFt,"FlaxDistilBertForQuestionAnswering"),sFt.forEach(t),kLr=r(Ixe," (DistilBERT model)"),Ixe.forEach(t),RLr=i(Le),R4=n(Le,"LI",{});var Nxe=s(R4);e6e=n(Nxe,"STRONG",{});var lFt=s(e6e);SLr=r(lFt,"electra"),lFt.forEach(t),PLr=r(Nxe," \u2014 "),yz=n(Nxe,"A",{href:!0});var iFt=s(yz);$Lr=r(iFt,"FlaxElectraForQuestionAnswering"),iFt.forEach(t),ILr=r(Nxe," (ELECTRA model)"),Nxe.forEach(t),NLr=i(Le),S4=n(Le,"LI",{});var Dxe=s(S4);o6e=n(Dxe,"STRONG",{});var dFt=s(o6e);DLr=r(dFt,"mbart"),dFt.forEach(t),jLr=r(Dxe," \u2014 "),wz=n(Dxe,"A",{href:!0});var cFt=s(wz);qLr=r(cFt,"FlaxMBartForQuestionAnswering"),cFt.forEach(t),GLr=r(Dxe," (mBART model)"),Dxe.forEach(t),OLr=i(Le),P4=n(Le,"LI",{});var jxe=s(P4);r6e=n(jxe,"STRONG",{});var fFt=s(r6e);XLr=r(fFt,"roberta"),fFt.forEach(t),VLr=r(jxe," \u2014 "),Az=n(jxe,"A",{href:!0});var mFt=s(Az);zLr=r(mFt,"FlaxRobertaForQuestionAnswering"),mFt.forEach(t),WLr=r(jxe," (RoBERTa model)"),jxe.forEach(t),QLr=i(Le),$4=n(Le,"LI",{});var qxe=s($4);t6e=n(qxe,"STRONG",{});var gFt=s(t6e);HLr=r(gFt,"roformer"),gFt.forEach(t),ULr=r(qxe," \u2014 "),Lz=n(qxe,"A",{href:!0});var hFt=s(Lz);JLr=r(hFt,"FlaxRoFormerForQuestionAnswering"),hFt.forEach(t),YLr=r(qxe," (RoFormer model)"),qxe.forEach(t),KLr=i(Le),I4=n(Le,"LI",{});var Gxe=s(I4);a6e=n(Gxe,"STRONG",{});var pFt=s(a6e);ZLr=r(pFt,"xlm-roberta"),pFt.forEach(t),e7r=r(Gxe," \u2014 "),Bz=n(Gxe,"A",{href:!0});var _Ft=s(Bz);o7r=r(_Ft,"FlaxXLMRobertaForQuestionAnswering"),_Ft.forEach(t),r7r=r(Gxe," (XLM-RoBERTa model)"),Gxe.forEach(t),Le.forEach(t),t7r=i(Pa),n6e=n(Pa,"P",{});var uFt=s(n6e);a7r=r(uFt,"Examples:"),uFt.forEach(t),n7r=i(Pa),m(T7.$$.fragment,Pa),Pa.forEach(t),Ei.forEach(t),ZRe=i(c),vf=n(c,"H2",{class:!0});var f$e=s(vf);N4=n(f$e,"A",{id:!0,class:!0,href:!0});var bFt=s(N4);s6e=n(bFt,"SPAN",{});var vFt=s(s6e);m(F7.$$.fragment,vFt),vFt.forEach(t),bFt.forEach(t),s7r=i(f$e),l6e=n(f$e,"SPAN",{});var TFt=s(l6e);l7r=r(TFt,"FlaxAutoModelForTokenClassification"),TFt.forEach(t),f$e.forEach(t),eSe=i(c),jr=n(c,"DIV",{class:!0});var wi=s(jr);m(C7.$$.fragment,wi),i7r=i(wi),Tf=n(wi,"P",{});var RQ=s(Tf);d7r=r(RQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),i6e=n(RQ,"CODE",{});var FFt=s(i6e);c7r=r(FFt,"from_pretrained()"),FFt.forEach(t),f7r=r(RQ,"class method or the "),d6e=n(RQ,"CODE",{});var CFt=s(d6e);m7r=r(CFt,"from_config()"),CFt.forEach(t),g7r=r(RQ,`class
method.`),RQ.forEach(t),h7r=i(wi),M7=n(wi,"P",{});var m$e=s(M7);p7r=r(m$e,"This class cannot be instantiated directly using "),c6e=n(m$e,"CODE",{});var MFt=s(c6e);_7r=r(MFt,"__init__()"),MFt.forEach(t),u7r=r(m$e," (throws an error)."),m$e.forEach(t),b7r=i(wi),St=n(wi,"DIV",{class:!0});var Ai=s(St);m(E7.$$.fragment,Ai),v7r=i(Ai),f6e=n(Ai,"P",{});var EFt=s(f6e);T7r=r(EFt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),EFt.forEach(t),F7r=i(Ai),Ff=n(Ai,"P",{});var SQ=s(Ff);C7r=r(SQ,`Note:
Loading a model from its configuration file does `),m6e=n(SQ,"STRONG",{});var yFt=s(m6e);M7r=r(yFt,"not"),yFt.forEach(t),E7r=r(SQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),g6e=n(SQ,"CODE",{});var wFt=s(g6e);y7r=r(wFt,"from_pretrained()"),wFt.forEach(t),w7r=r(SQ,"to load the model weights."),SQ.forEach(t),A7r=i(Ai),h6e=n(Ai,"P",{});var AFt=s(h6e);L7r=r(AFt,"Examples:"),AFt.forEach(t),B7r=i(Ai),m(y7.$$.fragment,Ai),Ai.forEach(t),x7r=i(wi),Po=n(wi,"DIV",{class:!0});var $a=s(Po);m(w7.$$.fragment,$a),k7r=i($a),p6e=n($a,"P",{});var LFt=s(p6e);R7r=r(LFt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),LFt.forEach(t),S7r=i($a),In=n($a,"P",{});var r3=s(In);P7r=r(r3,"The model class to instantiate is selected based on the "),_6e=n(r3,"CODE",{});var BFt=s(_6e);$7r=r(BFt,"model_type"),BFt.forEach(t),I7r=r(r3,` property of the config object (either
passed as an argument or loaded from `),u6e=n(r3,"CODE",{});var xFt=s(u6e);N7r=r(xFt,"pretrained_model_name_or_path"),xFt.forEach(t),D7r=r(r3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b6e=n(r3,"CODE",{});var kFt=s(b6e);j7r=r(kFt,"pretrained_model_name_or_path"),kFt.forEach(t),q7r=r(r3,":"),r3.forEach(t),G7r=i($a),Se=n($a,"UL",{});var Oo=s(Se);D4=n(Oo,"LI",{});var Oxe=s(D4);v6e=n(Oxe,"STRONG",{});var RFt=s(v6e);O7r=r(RFt,"albert"),RFt.forEach(t),X7r=r(Oxe," \u2014 "),xz=n(Oxe,"A",{href:!0});var SFt=s(xz);V7r=r(SFt,"FlaxAlbertForTokenClassification"),SFt.forEach(t),z7r=r(Oxe," (ALBERT model)"),Oxe.forEach(t),W7r=i(Oo),j4=n(Oo,"LI",{});var Xxe=s(j4);T6e=n(Xxe,"STRONG",{});var PFt=s(T6e);Q7r=r(PFt,"bert"),PFt.forEach(t),H7r=r(Xxe," \u2014 "),kz=n(Xxe,"A",{href:!0});var $Ft=s(kz);U7r=r($Ft,"FlaxBertForTokenClassification"),$Ft.forEach(t),J7r=r(Xxe," (BERT model)"),Xxe.forEach(t),Y7r=i(Oo),q4=n(Oo,"LI",{});var Vxe=s(q4);F6e=n(Vxe,"STRONG",{});var IFt=s(F6e);K7r=r(IFt,"big_bird"),IFt.forEach(t),Z7r=r(Vxe," \u2014 "),Rz=n(Vxe,"A",{href:!0});var NFt=s(Rz);e8r=r(NFt,"FlaxBigBirdForTokenClassification"),NFt.forEach(t),o8r=r(Vxe," (BigBird model)"),Vxe.forEach(t),r8r=i(Oo),G4=n(Oo,"LI",{});var zxe=s(G4);C6e=n(zxe,"STRONG",{});var DFt=s(C6e);t8r=r(DFt,"distilbert"),DFt.forEach(t),a8r=r(zxe," \u2014 "),Sz=n(zxe,"A",{href:!0});var jFt=s(Sz);n8r=r(jFt,"FlaxDistilBertForTokenClassification"),jFt.forEach(t),s8r=r(zxe," (DistilBERT model)"),zxe.forEach(t),l8r=i(Oo),O4=n(Oo,"LI",{});var Wxe=s(O4);M6e=n(Wxe,"STRONG",{});var qFt=s(M6e);i8r=r(qFt,"electra"),qFt.forEach(t),d8r=r(Wxe," \u2014 "),Pz=n(Wxe,"A",{href:!0});var GFt=s(Pz);c8r=r(GFt,"FlaxElectraForTokenClassification"),GFt.forEach(t),f8r=r(Wxe," (ELECTRA model)"),Wxe.forEach(t),m8r=i(Oo),X4=n(Oo,"LI",{});var Qxe=s(X4);E6e=n(Qxe,"STRONG",{});var OFt=s(E6e);g8r=r(OFt,"roberta"),OFt.forEach(t),h8r=r(Qxe," \u2014 "),$z=n(Qxe,"A",{href:!0});var XFt=s($z);p8r=r(XFt,"FlaxRobertaForTokenClassification"),XFt.forEach(t),_8r=r(Qxe," (RoBERTa model)"),Qxe.forEach(t),u8r=i(Oo),V4=n(Oo,"LI",{});var Hxe=s(V4);y6e=n(Hxe,"STRONG",{});var VFt=s(y6e);b8r=r(VFt,"roformer"),VFt.forEach(t),v8r=r(Hxe," \u2014 "),Iz=n(Hxe,"A",{href:!0});var zFt=s(Iz);T8r=r(zFt,"FlaxRoFormerForTokenClassification"),zFt.forEach(t),F8r=r(Hxe," (RoFormer model)"),Hxe.forEach(t),C8r=i(Oo),z4=n(Oo,"LI",{});var Uxe=s(z4);w6e=n(Uxe,"STRONG",{});var WFt=s(w6e);M8r=r(WFt,"xlm-roberta"),WFt.forEach(t),E8r=r(Uxe," \u2014 "),Nz=n(Uxe,"A",{href:!0});var QFt=s(Nz);y8r=r(QFt,"FlaxXLMRobertaForTokenClassification"),QFt.forEach(t),w8r=r(Uxe," (XLM-RoBERTa model)"),Uxe.forEach(t),Oo.forEach(t),A8r=i($a),A6e=n($a,"P",{});var HFt=s(A6e);L8r=r(HFt,"Examples:"),HFt.forEach(t),B8r=i($a),m(A7.$$.fragment,$a),$a.forEach(t),wi.forEach(t),oSe=i(c),Cf=n(c,"H2",{class:!0});var g$e=s(Cf);W4=n(g$e,"A",{id:!0,class:!0,href:!0});var UFt=s(W4);L6e=n(UFt,"SPAN",{});var JFt=s(L6e);m(L7.$$.fragment,JFt),JFt.forEach(t),UFt.forEach(t),x8r=i(g$e),B6e=n(g$e,"SPAN",{});var YFt=s(B6e);k8r=r(YFt,"FlaxAutoModelForMultipleChoice"),YFt.forEach(t),g$e.forEach(t),rSe=i(c),qr=n(c,"DIV",{class:!0});var Li=s(qr);m(B7.$$.fragment,Li),R8r=i(Li),Mf=n(Li,"P",{});var PQ=s(Mf);S8r=r(PQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),x6e=n(PQ,"CODE",{});var KFt=s(x6e);P8r=r(KFt,"from_pretrained()"),KFt.forEach(t),$8r=r(PQ,"class method or the "),k6e=n(PQ,"CODE",{});var ZFt=s(k6e);I8r=r(ZFt,"from_config()"),ZFt.forEach(t),N8r=r(PQ,`class
method.`),PQ.forEach(t),D8r=i(Li),x7=n(Li,"P",{});var h$e=s(x7);j8r=r(h$e,"This class cannot be instantiated directly using "),R6e=n(h$e,"CODE",{});var eCt=s(R6e);q8r=r(eCt,"__init__()"),eCt.forEach(t),G8r=r(h$e," (throws an error)."),h$e.forEach(t),O8r=i(Li),Pt=n(Li,"DIV",{class:!0});var Bi=s(Pt);m(k7.$$.fragment,Bi),X8r=i(Bi),S6e=n(Bi,"P",{});var oCt=s(S6e);V8r=r(oCt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),oCt.forEach(t),z8r=i(Bi),Ef=n(Bi,"P",{});var $Q=s(Ef);W8r=r($Q,`Note:
Loading a model from its configuration file does `),P6e=n($Q,"STRONG",{});var rCt=s(P6e);Q8r=r(rCt,"not"),rCt.forEach(t),H8r=r($Q,` load the model weights. It only affects the
model\u2019s configuration. Use `),$6e=n($Q,"CODE",{});var tCt=s($6e);U8r=r(tCt,"from_pretrained()"),tCt.forEach(t),J8r=r($Q,"to load the model weights."),$Q.forEach(t),Y8r=i(Bi),I6e=n(Bi,"P",{});var aCt=s(I6e);K8r=r(aCt,"Examples:"),aCt.forEach(t),Z8r=i(Bi),m(R7.$$.fragment,Bi),Bi.forEach(t),e9r=i(Li),$o=n(Li,"DIV",{class:!0});var Ia=s($o);m(S7.$$.fragment,Ia),o9r=i(Ia),N6e=n(Ia,"P",{});var nCt=s(N6e);r9r=r(nCt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),nCt.forEach(t),t9r=i(Ia),Nn=n(Ia,"P",{});var t3=s(Nn);a9r=r(t3,"The model class to instantiate is selected based on the "),D6e=n(t3,"CODE",{});var sCt=s(D6e);n9r=r(sCt,"model_type"),sCt.forEach(t),s9r=r(t3,` property of the config object (either
passed as an argument or loaded from `),j6e=n(t3,"CODE",{});var lCt=s(j6e);l9r=r(lCt,"pretrained_model_name_or_path"),lCt.forEach(t),i9r=r(t3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q6e=n(t3,"CODE",{});var iCt=s(q6e);d9r=r(iCt,"pretrained_model_name_or_path"),iCt.forEach(t),c9r=r(t3,":"),t3.forEach(t),f9r=i(Ia),Pe=n(Ia,"UL",{});var Xo=s(Pe);Q4=n(Xo,"LI",{});var Jxe=s(Q4);G6e=n(Jxe,"STRONG",{});var dCt=s(G6e);m9r=r(dCt,"albert"),dCt.forEach(t),g9r=r(Jxe," \u2014 "),Dz=n(Jxe,"A",{href:!0});var cCt=s(Dz);h9r=r(cCt,"FlaxAlbertForMultipleChoice"),cCt.forEach(t),p9r=r(Jxe," (ALBERT model)"),Jxe.forEach(t),_9r=i(Xo),H4=n(Xo,"LI",{});var Yxe=s(H4);O6e=n(Yxe,"STRONG",{});var fCt=s(O6e);u9r=r(fCt,"bert"),fCt.forEach(t),b9r=r(Yxe," \u2014 "),jz=n(Yxe,"A",{href:!0});var mCt=s(jz);v9r=r(mCt,"FlaxBertForMultipleChoice"),mCt.forEach(t),T9r=r(Yxe," (BERT model)"),Yxe.forEach(t),F9r=i(Xo),U4=n(Xo,"LI",{});var Kxe=s(U4);X6e=n(Kxe,"STRONG",{});var gCt=s(X6e);C9r=r(gCt,"big_bird"),gCt.forEach(t),M9r=r(Kxe," \u2014 "),qz=n(Kxe,"A",{href:!0});var hCt=s(qz);E9r=r(hCt,"FlaxBigBirdForMultipleChoice"),hCt.forEach(t),y9r=r(Kxe," (BigBird model)"),Kxe.forEach(t),w9r=i(Xo),J4=n(Xo,"LI",{});var Zxe=s(J4);V6e=n(Zxe,"STRONG",{});var pCt=s(V6e);A9r=r(pCt,"distilbert"),pCt.forEach(t),L9r=r(Zxe," \u2014 "),Gz=n(Zxe,"A",{href:!0});var _Ct=s(Gz);B9r=r(_Ct,"FlaxDistilBertForMultipleChoice"),_Ct.forEach(t),x9r=r(Zxe," (DistilBERT model)"),Zxe.forEach(t),k9r=i(Xo),Y4=n(Xo,"LI",{});var eke=s(Y4);z6e=n(eke,"STRONG",{});var uCt=s(z6e);R9r=r(uCt,"electra"),uCt.forEach(t),S9r=r(eke," \u2014 "),Oz=n(eke,"A",{href:!0});var bCt=s(Oz);P9r=r(bCt,"FlaxElectraForMultipleChoice"),bCt.forEach(t),$9r=r(eke," (ELECTRA model)"),eke.forEach(t),I9r=i(Xo),K4=n(Xo,"LI",{});var oke=s(K4);W6e=n(oke,"STRONG",{});var vCt=s(W6e);N9r=r(vCt,"roberta"),vCt.forEach(t),D9r=r(oke," \u2014 "),Xz=n(oke,"A",{href:!0});var TCt=s(Xz);j9r=r(TCt,"FlaxRobertaForMultipleChoice"),TCt.forEach(t),q9r=r(oke," (RoBERTa model)"),oke.forEach(t),G9r=i(Xo),Z4=n(Xo,"LI",{});var rke=s(Z4);Q6e=n(rke,"STRONG",{});var FCt=s(Q6e);O9r=r(FCt,"roformer"),FCt.forEach(t),X9r=r(rke," \u2014 "),Vz=n(rke,"A",{href:!0});var CCt=s(Vz);V9r=r(CCt,"FlaxRoFormerForMultipleChoice"),CCt.forEach(t),z9r=r(rke," (RoFormer model)"),rke.forEach(t),W9r=i(Xo),eE=n(Xo,"LI",{});var tke=s(eE);H6e=n(tke,"STRONG",{});var MCt=s(H6e);Q9r=r(MCt,"xlm-roberta"),MCt.forEach(t),H9r=r(tke," \u2014 "),zz=n(tke,"A",{href:!0});var ECt=s(zz);U9r=r(ECt,"FlaxXLMRobertaForMultipleChoice"),ECt.forEach(t),J9r=r(tke," (XLM-RoBERTa model)"),tke.forEach(t),Xo.forEach(t),Y9r=i(Ia),U6e=n(Ia,"P",{});var yCt=s(U6e);K9r=r(yCt,"Examples:"),yCt.forEach(t),Z9r=i(Ia),m(P7.$$.fragment,Ia),Ia.forEach(t),Li.forEach(t),tSe=i(c),yf=n(c,"H2",{class:!0});var p$e=s(yf);oE=n(p$e,"A",{id:!0,class:!0,href:!0});var wCt=s(oE);J6e=n(wCt,"SPAN",{});var ACt=s(J6e);m($7.$$.fragment,ACt),ACt.forEach(t),wCt.forEach(t),eBr=i(p$e),Y6e=n(p$e,"SPAN",{});var LCt=s(Y6e);oBr=r(LCt,"FlaxAutoModelForNextSentencePrediction"),LCt.forEach(t),p$e.forEach(t),aSe=i(c),Gr=n(c,"DIV",{class:!0});var xi=s(Gr);m(I7.$$.fragment,xi),rBr=i(xi),wf=n(xi,"P",{});var IQ=s(wf);tBr=r(IQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),K6e=n(IQ,"CODE",{});var BCt=s(K6e);aBr=r(BCt,"from_pretrained()"),BCt.forEach(t),nBr=r(IQ,"class method or the "),Z6e=n(IQ,"CODE",{});var xCt=s(Z6e);sBr=r(xCt,"from_config()"),xCt.forEach(t),lBr=r(IQ,`class
method.`),IQ.forEach(t),iBr=i(xi),N7=n(xi,"P",{});var _$e=s(N7);dBr=r(_$e,"This class cannot be instantiated directly using "),eTe=n(_$e,"CODE",{});var kCt=s(eTe);cBr=r(kCt,"__init__()"),kCt.forEach(t),fBr=r(_$e," (throws an error)."),_$e.forEach(t),mBr=i(xi),$t=n(xi,"DIV",{class:!0});var ki=s($t);m(D7.$$.fragment,ki),gBr=i(ki),oTe=n(ki,"P",{});var RCt=s(oTe);hBr=r(RCt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),RCt.forEach(t),pBr=i(ki),Af=n(ki,"P",{});var NQ=s(Af);_Br=r(NQ,`Note:
Loading a model from its configuration file does `),rTe=n(NQ,"STRONG",{});var SCt=s(rTe);uBr=r(SCt,"not"),SCt.forEach(t),bBr=r(NQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),tTe=n(NQ,"CODE",{});var PCt=s(tTe);vBr=r(PCt,"from_pretrained()"),PCt.forEach(t),TBr=r(NQ,"to load the model weights."),NQ.forEach(t),FBr=i(ki),aTe=n(ki,"P",{});var $Ct=s(aTe);CBr=r($Ct,"Examples:"),$Ct.forEach(t),MBr=i(ki),m(j7.$$.fragment,ki),ki.forEach(t),EBr=i(xi),Io=n(xi,"DIV",{class:!0});var Na=s(Io);m(q7.$$.fragment,Na),yBr=i(Na),nTe=n(Na,"P",{});var ICt=s(nTe);wBr=r(ICt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),ICt.forEach(t),ABr=i(Na),Dn=n(Na,"P",{});var a3=s(Dn);LBr=r(a3,"The model class to instantiate is selected based on the "),sTe=n(a3,"CODE",{});var NCt=s(sTe);BBr=r(NCt,"model_type"),NCt.forEach(t),xBr=r(a3,` property of the config object (either
passed as an argument or loaded from `),lTe=n(a3,"CODE",{});var DCt=s(lTe);kBr=r(DCt,"pretrained_model_name_or_path"),DCt.forEach(t),RBr=r(a3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=n(a3,"CODE",{});var jCt=s(iTe);SBr=r(jCt,"pretrained_model_name_or_path"),jCt.forEach(t),PBr=r(a3,":"),a3.forEach(t),$Br=i(Na),dTe=n(Na,"UL",{});var qCt=s(dTe);rE=n(qCt,"LI",{});var ake=s(rE);cTe=n(ake,"STRONG",{});var GCt=s(cTe);IBr=r(GCt,"bert"),GCt.forEach(t),NBr=r(ake," \u2014 "),Wz=n(ake,"A",{href:!0});var OCt=s(Wz);DBr=r(OCt,"FlaxBertForNextSentencePrediction"),OCt.forEach(t),jBr=r(ake," (BERT model)"),ake.forEach(t),qCt.forEach(t),qBr=i(Na),fTe=n(Na,"P",{});var XCt=s(fTe);GBr=r(XCt,"Examples:"),XCt.forEach(t),OBr=i(Na),m(G7.$$.fragment,Na),Na.forEach(t),xi.forEach(t),nSe=i(c),Lf=n(c,"H2",{class:!0});var u$e=s(Lf);tE=n(u$e,"A",{id:!0,class:!0,href:!0});var VCt=s(tE);mTe=n(VCt,"SPAN",{});var zCt=s(mTe);m(O7.$$.fragment,zCt),zCt.forEach(t),VCt.forEach(t),XBr=i(u$e),gTe=n(u$e,"SPAN",{});var WCt=s(gTe);VBr=r(WCt,"FlaxAutoModelForImageClassification"),WCt.forEach(t),u$e.forEach(t),sSe=i(c),Or=n(c,"DIV",{class:!0});var Ri=s(Or);m(X7.$$.fragment,Ri),zBr=i(Ri),Bf=n(Ri,"P",{});var DQ=s(Bf);WBr=r(DQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hTe=n(DQ,"CODE",{});var QCt=s(hTe);QBr=r(QCt,"from_pretrained()"),QCt.forEach(t),HBr=r(DQ,"class method or the "),pTe=n(DQ,"CODE",{});var HCt=s(pTe);UBr=r(HCt,"from_config()"),HCt.forEach(t),JBr=r(DQ,`class
method.`),DQ.forEach(t),YBr=i(Ri),V7=n(Ri,"P",{});var b$e=s(V7);KBr=r(b$e,"This class cannot be instantiated directly using "),_Te=n(b$e,"CODE",{});var UCt=s(_Te);ZBr=r(UCt,"__init__()"),UCt.forEach(t),exr=r(b$e," (throws an error)."),b$e.forEach(t),oxr=i(Ri),It=n(Ri,"DIV",{class:!0});var Si=s(It);m(z7.$$.fragment,Si),rxr=i(Si),uTe=n(Si,"P",{});var JCt=s(uTe);txr=r(JCt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),JCt.forEach(t),axr=i(Si),xf=n(Si,"P",{});var jQ=s(xf);nxr=r(jQ,`Note:
Loading a model from its configuration file does `),bTe=n(jQ,"STRONG",{});var YCt=s(bTe);sxr=r(YCt,"not"),YCt.forEach(t),lxr=r(jQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),vTe=n(jQ,"CODE",{});var KCt=s(vTe);ixr=r(KCt,"from_pretrained()"),KCt.forEach(t),dxr=r(jQ,"to load the model weights."),jQ.forEach(t),cxr=i(Si),TTe=n(Si,"P",{});var ZCt=s(TTe);fxr=r(ZCt,"Examples:"),ZCt.forEach(t),mxr=i(Si),m(W7.$$.fragment,Si),Si.forEach(t),gxr=i(Ri),No=n(Ri,"DIV",{class:!0});var Da=s(No);m(Q7.$$.fragment,Da),hxr=i(Da),FTe=n(Da,"P",{});var eMt=s(FTe);pxr=r(eMt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),eMt.forEach(t),_xr=i(Da),jn=n(Da,"P",{});var n3=s(jn);uxr=r(n3,"The model class to instantiate is selected based on the "),CTe=n(n3,"CODE",{});var oMt=s(CTe);bxr=r(oMt,"model_type"),oMt.forEach(t),vxr=r(n3,` property of the config object (either
passed as an argument or loaded from `),MTe=n(n3,"CODE",{});var rMt=s(MTe);Txr=r(rMt,"pretrained_model_name_or_path"),rMt.forEach(t),Fxr=r(n3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ETe=n(n3,"CODE",{});var tMt=s(ETe);Cxr=r(tMt,"pretrained_model_name_or_path"),tMt.forEach(t),Mxr=r(n3,":"),n3.forEach(t),Exr=i(Da),H7=n(Da,"UL",{});var v$e=s(H7);aE=n(v$e,"LI",{});var nke=s(aE);yTe=n(nke,"STRONG",{});var aMt=s(yTe);yxr=r(aMt,"beit"),aMt.forEach(t),wxr=r(nke," \u2014 "),Qz=n(nke,"A",{href:!0});var nMt=s(Qz);Axr=r(nMt,"FlaxBeitForImageClassification"),nMt.forEach(t),Lxr=r(nke," (BEiT model)"),nke.forEach(t),Bxr=i(v$e),nE=n(v$e,"LI",{});var ske=s(nE);wTe=n(ske,"STRONG",{});var sMt=s(wTe);xxr=r(sMt,"vit"),sMt.forEach(t),kxr=r(ske," \u2014 "),Hz=n(ske,"A",{href:!0});var lMt=s(Hz);Rxr=r(lMt,"FlaxViTForImageClassification"),lMt.forEach(t),Sxr=r(ske," (ViT model)"),ske.forEach(t),v$e.forEach(t),Pxr=i(Da),ATe=n(Da,"P",{});var iMt=s(ATe);$xr=r(iMt,"Examples:"),iMt.forEach(t),Ixr=i(Da),m(U7.$$.fragment,Da),Da.forEach(t),Ri.forEach(t),lSe=i(c),kf=n(c,"H2",{class:!0});var T$e=s(kf);sE=n(T$e,"A",{id:!0,class:!0,href:!0});var dMt=s(sE);LTe=n(dMt,"SPAN",{});var cMt=s(LTe);m(J7.$$.fragment,cMt),cMt.forEach(t),dMt.forEach(t),Nxr=i(T$e),BTe=n(T$e,"SPAN",{});var fMt=s(BTe);Dxr=r(fMt,"FlaxAutoModelForVision2Seq"),fMt.forEach(t),T$e.forEach(t),iSe=i(c),Xr=n(c,"DIV",{class:!0});var Pi=s(Xr);m(Y7.$$.fragment,Pi),jxr=i(Pi),Rf=n(Pi,"P",{});var qQ=s(Rf);qxr=r(qQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xTe=n(qQ,"CODE",{});var mMt=s(xTe);Gxr=r(mMt,"from_pretrained()"),mMt.forEach(t),Oxr=r(qQ,"class method or the "),kTe=n(qQ,"CODE",{});var gMt=s(kTe);Xxr=r(gMt,"from_config()"),gMt.forEach(t),Vxr=r(qQ,`class
method.`),qQ.forEach(t),zxr=i(Pi),K7=n(Pi,"P",{});var F$e=s(K7);Wxr=r(F$e,"This class cannot be instantiated directly using "),RTe=n(F$e,"CODE",{});var hMt=s(RTe);Qxr=r(hMt,"__init__()"),hMt.forEach(t),Hxr=r(F$e," (throws an error)."),F$e.forEach(t),Uxr=i(Pi),Nt=n(Pi,"DIV",{class:!0});var $i=s(Nt);m(Z7.$$.fragment,$i),Jxr=i($i),STe=n($i,"P",{});var pMt=s(STe);Yxr=r(pMt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pMt.forEach(t),Kxr=i($i),Sf=n($i,"P",{});var GQ=s(Sf);Zxr=r(GQ,`Note:
Loading a model from its configuration file does `),PTe=n(GQ,"STRONG",{});var _Mt=s(PTe);ekr=r(_Mt,"not"),_Mt.forEach(t),okr=r(GQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),$Te=n(GQ,"CODE",{});var uMt=s($Te);rkr=r(uMt,"from_pretrained()"),uMt.forEach(t),tkr=r(GQ,"to load the model weights."),GQ.forEach(t),akr=i($i),ITe=n($i,"P",{});var bMt=s(ITe);nkr=r(bMt,"Examples:"),bMt.forEach(t),skr=i($i),m(e8.$$.fragment,$i),$i.forEach(t),lkr=i(Pi),Do=n(Pi,"DIV",{class:!0});var ja=s(Do);m(o8.$$.fragment,ja),ikr=i(ja),NTe=n(ja,"P",{});var vMt=s(NTe);dkr=r(vMt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),vMt.forEach(t),ckr=i(ja),qn=n(ja,"P",{});var s3=s(qn);fkr=r(s3,"The model class to instantiate is selected based on the "),DTe=n(s3,"CODE",{});var TMt=s(DTe);mkr=r(TMt,"model_type"),TMt.forEach(t),gkr=r(s3,` property of the config object (either
passed as an argument or loaded from `),jTe=n(s3,"CODE",{});var FMt=s(jTe);hkr=r(FMt,"pretrained_model_name_or_path"),FMt.forEach(t),pkr=r(s3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qTe=n(s3,"CODE",{});var CMt=s(qTe);_kr=r(CMt,"pretrained_model_name_or_path"),CMt.forEach(t),ukr=r(s3,":"),s3.forEach(t),bkr=i(ja),GTe=n(ja,"UL",{});var MMt=s(GTe);lE=n(MMt,"LI",{});var lke=s(lE);OTe=n(lke,"STRONG",{});var EMt=s(OTe);vkr=r(EMt,"vision-encoder-decoder"),EMt.forEach(t),Tkr=r(lke," \u2014 "),Uz=n(lke,"A",{href:!0});var yMt=s(Uz);Fkr=r(yMt,"FlaxVisionEncoderDecoderModel"),yMt.forEach(t),Ckr=r(lke," (Vision Encoder decoder model)"),lke.forEach(t),MMt.forEach(t),Mkr=i(ja),XTe=n(ja,"P",{});var wMt=s(XTe);Ekr=r(wMt,"Examples:"),wMt.forEach(t),ykr=i(ja),m(r8.$$.fragment,ja),ja.forEach(t),Pi.forEach(t),this.h()},h(){d(K,"name","hf:doc:metadata"),d(K,"content",JSON.stringify(IMt)),d(Ee,"id","auto-classes"),d(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ee,"href","#auto-classes"),d(de,"class","relative group"),d(Gn,"href","/docs/transformers/pr_16255/en/model_doc/auto#transformers.AutoConfig"),d(Xn,"href","/docs/transformers/pr_16255/en/model_doc/auto#transformers.AutoModel"),d(Vn,"href","/docs/transformers/pr_16255/en/model_doc/auto#transformers.AutoTokenizer"),d(Oi,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertModel"),d(qf,"id","extending-the-auto-classes"),d(qf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qf,"href","#extending-the-auto-classes"),d(Xi,"class","relative group"),d(Of,"id","transformers.AutoConfig"),d(Of,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Of,"href","#transformers.AutoConfig"),d(Vi,"class","relative group"),d(s9,"href","/docs/transformers/pr_16255/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(l9,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertConfig"),d(i9,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartConfig"),d(d9,"href","/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitConfig"),d(c9,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertConfig"),d(f9,"href","/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(m9,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdConfig"),d(g9,"href","/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(h9,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(p9,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(_9,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertConfig"),d(u9,"href","/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineConfig"),d(b9,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPConfig"),d(v9,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertConfig"),d(T9,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextConfig"),d(F9,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLConfig"),d(C9,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(M9,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(E9,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaConfig"),d(y9,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(w9,"href","/docs/transformers/pr_16255/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(A9,"href","/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTConfig"),d(L9,"href","/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrConfig"),d(B9,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertConfig"),d(x9,"href","/docs/transformers/pr_16255/en/model_doc/dpr#transformers.DPRConfig"),d(k9,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraConfig"),d(R9,"href","/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(S9,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertConfig"),d(P9,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetConfig"),d($9,"href","/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTConfig"),d(I9,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelConfig"),d(N9,"href","/docs/transformers/pr_16255/en/model_doc/glpn#transformers.GLPNConfig"),d(D9,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Config"),d(j9,"href","/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(q9,"href","/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJConfig"),d(G9,"href","/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertConfig"),d(O9,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertConfig"),d(X9,"href","/docs/transformers/pr_16255/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(V9,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(z9,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(W9,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDConfig"),d(Q9,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerConfig"),d(H9,"href","/docs/transformers/pr_16255/en/model_doc/luke#transformers.LukeConfig"),d(U9,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertConfig"),d(J9,"href","/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100Config"),d(Y9,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianConfig"),d(K9,"href","/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(Z9,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartConfig"),d(eB,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(oB,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(rB,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetConfig"),d(tB,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Config"),d(aB,"href","/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(nB,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(sB,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusConfig"),d(lB,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverConfig"),d(iB,"href","/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartConfig"),d(dB,"href","/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(cB,"href","/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(fB,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(mB,"href","/docs/transformers/pr_16255/en/model_doc/rag#transformers.RagConfig"),d(gB,"href","/docs/transformers/pr_16255/en/model_doc/realm#transformers.RealmConfig"),d(hB,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerConfig"),d(pB,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertConfig"),d(_B,"href","/docs/transformers/pr_16255/en/model_doc/resnet#transformers.ResNetConfig"),d(uB,"href","/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertConfig"),d(bB,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaConfig"),d(vB,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerConfig"),d(TB,"href","/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerConfig"),d(FB,"href","/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWConfig"),d(CB,"href","/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDConfig"),d(MB,"href","/docs/transformers/pr_16255/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(EB,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(yB,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(wB,"href","/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterConfig"),d(AB,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(LB,"href","/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinConfig"),d(BB,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Config"),d(xB,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasConfig"),d(kB,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(RB,"href","/docs/transformers/pr_16255/en/model_doc/trocr#transformers.TrOCRConfig"),d(SB,"href","/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(PB,"href","/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d($B,"href","/docs/transformers/pr_16255/en/model_doc/van#transformers.VanConfig"),d(IB,"href","/docs/transformers/pr_16255/en/model_doc/vilt#transformers.ViltConfig"),d(NB,"href","/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(DB,"href","/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(jB,"href","/docs/transformers/pr_16255/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(qB,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTConfig"),d(GB,"href","/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(OB,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(XB,"href","/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMConfig"),d(VB,"href","/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMConfig"),d(zB,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMConfig"),d(WB,"href","/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(QB,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(HB,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(UB,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetConfig"),d(JB,"href","/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoConfig"),d(mo,"class","docstring"),d(Sg,"class","docstring"),d(Wo,"class","docstring"),d(Pg,"id","transformers.AutoTokenizer"),d(Pg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Pg,"href","#transformers.AutoTokenizer"),d(Wi,"class","relative group"),d(YB,"href","/docs/transformers/pr_16255/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(KB,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertTokenizer"),d(ZB,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(ex,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartTokenizer"),d(ox,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartTokenizerFast"),d(rx,"href","/docs/transformers/pr_16255/en/model_doc/barthez#transformers.BarthezTokenizer"),d(tx,"href","/docs/transformers/pr_16255/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(ax,"href","/docs/transformers/pr_16255/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(nx,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertTokenizer"),d(sx,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertTokenizerFast"),d(lx,"href","/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(ix,"href","/docs/transformers/pr_16255/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(dx,"href","/docs/transformers/pr_16255/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(cx,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(fx,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(mx,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(gx,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(hx,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(px,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(_x,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(ux,"href","/docs/transformers/pr_16255/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(bx,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertTokenizer"),d(vx,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(Tx,"href","/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineTokenizer"),d(Fx,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPTokenizer"),d(Cx,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(Mx,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(Ex,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(yx,"href","/docs/transformers/pr_16255/en/model_doc/cpm#transformers.CpmTokenizer"),d(wx,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(Ax,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaTokenizer"),d(Lx,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(Bx,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(xx,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(kx,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(Rx,"href","/docs/transformers/pr_16255/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(Sx,"href","/docs/transformers/pr_16255/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(Px,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraTokenizer"),d($x,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(Ix,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(Nx,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetTokenizer"),d(Dx,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(jx,"href","/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(qx,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelTokenizer"),d(Gx,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(Ox,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(Xx,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(Vx,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(zx,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(Wx,"href","/docs/transformers/pr_16255/en/model_doc/herbert#transformers.HerbertTokenizer"),d(Qx,"href","/docs/transformers/pr_16255/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(Hx,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(Ux,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaTokenizer"),d(Jx,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(Yx,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(Kx,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(Zx,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(ek,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(ok,"href","/docs/transformers/pr_16255/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(rk,"href","/docs/transformers/pr_16255/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(tk,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDTokenizer"),d(ak,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDTokenizerFast"),d(nk,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerTokenizer"),d(sk,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(lk,"href","/docs/transformers/pr_16255/en/model_doc/luke#transformers.LukeTokenizer"),d(ik,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(dk,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(ck,"href","/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(fk,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianTokenizer"),d(mk,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartTokenizer"),d(gk,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(hk,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(pk,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(_k,"href","/docs/transformers/pr_16255/en/model_doc/mluke#transformers.MLukeTokenizer"),d(uk,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(bk,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(vk,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(Tk,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(Fk,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.T5Tokenizer"),d(Ck,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.T5TokenizerFast"),d(Mk,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(Ek,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(yk,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(wk,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(Ak,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(Lk,"href","/docs/transformers/pr_16255/en/model_doc/phobert#transformers.PhobertTokenizer"),d(Bk,"href","/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartTokenizer"),d(xk,"href","/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(kk,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertTokenizer"),d(Rk,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertTokenizerFast"),d(Sk,"href","/docs/transformers/pr_16255/en/model_doc/rag#transformers.RagTokenizer"),d(Pk,"href","/docs/transformers/pr_16255/en/model_doc/realm#transformers.RealmTokenizer"),d($k,"href","/docs/transformers/pr_16255/en/model_doc/realm#transformers.RealmTokenizerFast"),d(Ik,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerTokenizer"),d(Nk,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(Dk,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertTokenizer"),d(jk,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(qk,"href","/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(Gk,"href","/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(Ok,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaTokenizer"),d(Xk,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(Vk,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(zk,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(Wk,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(Qk,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(Hk,"href","/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterTokenizer"),d(Uk,"href","/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(Jk,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(Yk,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(Kk,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.T5Tokenizer"),d(Zk,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.T5TokenizerFast"),d(eR,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasTokenizer"),d(oR,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(rR,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(tR,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(aR,"href","/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMTokenizer"),d(nR,"href","/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(sR,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMTokenizer"),d(lR,"href","/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(iR,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(dR,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(cR,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(fR,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(go,"class","docstring"),d(ch,"class","docstring"),d(Qo,"class","docstring"),d(fh,"id","transformers.AutoFeatureExtractor"),d(fh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(fh,"href","#transformers.AutoFeatureExtractor"),d(Qi,"class","relative group"),d(mR,"href","/docs/transformers/pr_16255/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(gR,"href","/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(hR,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(pR,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(_R,"href","/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTFeatureExtractor"),d(uR,"href","/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(bR,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(vR,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),d(TR,"href","/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(FR,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),d(CR,"href","/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),d(MR,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(ER,"href","/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),d(yR,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(wR,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(AR,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(LR,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(BR,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(xR,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d($e,"class","docstring"),d(kh,"class","docstring"),d(Ho,"class","docstring"),d(Rh,"id","transformers.AutoProcessor"),d(Rh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Rh,"href","#transformers.AutoProcessor"),d(Hi,"class","relative group"),d(kR,"href","/docs/transformers/pr_16255/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(RR,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPProcessor"),d(SR,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(PR,"href","/docs/transformers/pr_16255/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d($R,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(IR,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(NR,"href","/docs/transformers/pr_16255/en/model_doc/trocr#transformers.TrOCRProcessor"),d(DR,"href","/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(jR,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(Ie,"class","docstring"),d(Oh,"class","docstring"),d(Uo,"class","docstring"),d(Xh,"id","transformers.AutoModel"),d(Xh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Xh,"href","#transformers.AutoModel"),d(Ji,"class","relative group"),d(Vr,"class","docstring"),d(qR,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertModel"),d(GR,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartModel"),d(OR,"href","/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitModel"),d(XR,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertModel"),d(VR,"href","/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(zR,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdModel"),d(WR,"href","/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(QR,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(HR,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(UR,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertModel"),d(JR,"href","/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineModel"),d(YR,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.CLIPModel"),d(KR,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertModel"),d(ZR,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextModel"),d(eS,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLModel"),d(oS,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(rS,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(tS,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaModel"),d(aS,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(nS,"href","/docs/transformers/pr_16255/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(sS,"href","/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTModel"),d(lS,"href","/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrModel"),d(iS,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertModel"),d(dS,"href","/docs/transformers/pr_16255/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(cS,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraModel"),d(fS,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertModel"),d(mS,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetModel"),d(gS,"href","/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTModel"),d(hS,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelModel"),d(pS,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelBaseModel"),d(_S,"href","/docs/transformers/pr_16255/en/model_doc/glpn#transformers.GLPNModel"),d(uS,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2Model"),d(bS,"href","/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(vS,"href","/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJModel"),d(TS,"href","/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertModel"),d(FS,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertModel"),d(CS,"href","/docs/transformers/pr_16255/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(MS,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(ES,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(yS,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDModel"),d(wS,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerModel"),d(AS,"href","/docs/transformers/pr_16255/en/model_doc/luke#transformers.LukeModel"),d(LS,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertModel"),d(BS,"href","/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100Model"),d(xS,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianModel"),d(kS,"href","/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerModel"),d(RS,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartModel"),d(SS,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(PS,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertModel"),d($S,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetModel"),d(IS,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5Model"),d(NS,"href","/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerModel"),d(DS,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(jS,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusModel"),d(qS,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverModel"),d(GS,"href","/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartModel"),d(OS,"href","/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerModel"),d(XS,"href","/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(VS,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertModel"),d(zS,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerModel"),d(WS,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertModel"),d(QS,"href","/docs/transformers/pr_16255/en/model_doc/resnet#transformers.ResNetModel"),d(HS,"href","/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertModel"),d(US,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaModel"),d(JS,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerModel"),d(YS,"href","/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerModel"),d(KS,"href","/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWModel"),d(ZS,"href","/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDModel"),d(eP,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(oP,"href","/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterModel"),d(rP,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(tP,"href","/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinModel"),d(aP,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5Model"),d(nP,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasModel"),d(sP,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(lP,"href","/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechModel"),d(iP,"href","/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(dP,"href","/docs/transformers/pr_16255/en/model_doc/van#transformers.VanModel"),d(cP,"href","/docs/transformers/pr_16255/en/model_doc/vilt#transformers.ViltModel"),d(fP,"href","/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(mP,"href","/docs/transformers/pr_16255/en/model_doc/visual_bert#transformers.VisualBertModel"),d(gP,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTModel"),d(hP,"href","/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(pP,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(_P,"href","/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMModel"),d(uP,"href","/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMModel"),d(bP,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMModel"),d(vP,"href","/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(TP,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(FP,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(CP,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetModel"),d(MP,"href","/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoModel"),d(Ne,"class","docstring"),d(Jo,"class","docstring"),d(A_,"id","transformers.AutoModelForPreTraining"),d(A_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A_,"href","#transformers.AutoModelForPreTraining"),d(Zi,"class","relative group"),d(zr,"class","docstring"),d(EP,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForPreTraining"),d(yP,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(wP,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForPreTraining"),d(AP,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(LP,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(BP,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(xP,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(kP,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(RP,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(SP,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(PP,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForPreTraining"),d($P,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(IP,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForPreTraining"),d(NP,"href","/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(DP,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(jP,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(qP,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(GP,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(OP,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(XP,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(VP,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(zP,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(WP,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(QP,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(HP,"href","/docs/transformers/pr_16255/en/model_doc/retribert#transformers.RetriBertModel"),d(UP,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(JP,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(YP,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(KP,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(ZP,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(e$,"href","/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(o$,"href","/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(r$,"href","/docs/transformers/pr_16255/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(t$,"href","/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(a$,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(n$,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(s$,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(l$,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(i$,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(De,"class","docstring"),d(Yo,"class","docstring"),d(hu,"id","transformers.AutoModelForCausalLM"),d(hu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(hu,"href","#transformers.AutoModelForCausalLM"),d(rd,"class","relative group"),d(Wr,"class","docstring"),d(d$,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForCausalLM"),d(c$,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertLMHeadModel"),d(f$,"href","/docs/transformers/pr_16255/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(m$,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(g$,"href","/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(h$,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(p$,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(_$,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(u$,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(b$,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(v$,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForCausalLM"),d(T$,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(F$,"href","/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(C$,"href","/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(M$,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianForCausalLM"),d(E$,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForCausalLM"),d(y$,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(w$,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(A$,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(L$,"href","/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(B$,"href","/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(x$,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(k$,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(R$,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(S$,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(P$,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d($$,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(I$,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(N$,"href","/docs/transformers/pr_16255/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(D$,"href","/docs/transformers/pr_16255/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(j$,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(q$,"href","/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(G$,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(O$,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(X$,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(je,"class","docstring"),d(Ko,"class","docstring"),d(Yu,"id","transformers.AutoModelForMaskedLM"),d(Yu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Yu,"href","#transformers.AutoModelForMaskedLM"),d(nd,"class","relative group"),d(Qr,"class","docstring"),d(V$,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(z$,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(W$,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForMaskedLM"),d(Q$,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(H$,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(U$,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(J$,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(Y$,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(K$,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(Z$,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(eI,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(oI,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(rI,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(tI,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(aI,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(nI,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(sI,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(lI,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(iI,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(dI,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(cI,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(fI,"href","/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(mI,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(gI,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(hI,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(pI,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(_I,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(uI,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(bI,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(vI,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(TI,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(FI,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(CI,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(MI,"href","/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(qe,"class","docstring"),d(Zo,"class","docstring"),d(P5,"id","transformers.AutoModelForSeq2SeqLM"),d(P5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(P5,"href","#transformers.AutoModelForSeq2SeqLM"),d(id,"class","relative group"),d(Hr,"class","docstring"),d(EI,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(yI,"href","/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(wI,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(AI,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(LI,"href","/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(BI,"href","/docs/transformers/pr_16255/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(xI,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(kI,"href","/docs/transformers/pr_16255/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(RI,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.MarianMTModel"),d(SI,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(PI,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d($I,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(II,"href","/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(NI,"href","/docs/transformers/pr_16255/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(DI,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(jI,"href","/docs/transformers/pr_16255/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(Ge,"class","docstring"),d(er,"class","docstring"),d(K5,"id","transformers.AutoModelForSequenceClassification"),d(K5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K5,"href","#transformers.AutoModelForSequenceClassification"),d(fd,"class","relative group"),d(Ur,"class","docstring"),d(qI,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(GI,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForSequenceClassification"),d(OI,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForSequenceClassification"),d(XI,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(VI,"href","/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(zI,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(WI,"href","/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(QI,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(HI,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(UI,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(JI,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(YI,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(KI,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(ZI,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(eN,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(oN,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(rN,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(tN,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(aN,"href","/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(nN,"href","/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(sN,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(lN,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(iN,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(dN,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDForSequenceClassification"),d(cN,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(fN,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(mN,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(gN,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(hN,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(pN,"href","/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(_N,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(uN,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(bN,"href","/docs/transformers/pr_16255/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(vN,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(TN,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(FN,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(CN,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(MN,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(EN,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(yN,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(wN,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(AN,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(LN,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(BN,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(xN,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(kN,"href","/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(Oe,"class","docstring"),d(or,"class","docstring"),d(W2,"id","transformers.AutoModelForMultipleChoice"),d(W2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W2,"href","#transformers.AutoModelForMultipleChoice"),d(hd,"class","relative group"),d(Jr,"class","docstring"),d(RN,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(SN,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForMultipleChoice"),d(PN,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d($N,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(IN,"href","/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(NN,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(DN,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(jN,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(qN,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(GN,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(ON,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(XN,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(VN,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(zN,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(WN,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(QN,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(HN,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(UN,"href","/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(JN,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(YN,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(KN,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(ZN,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(eD,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(oD,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(rD,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(tD,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(aD,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(nD,"href","/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(Xe,"class","docstring"),d(rr,"class","docstring"),d(C1,"id","transformers.AutoModelForNextSentencePrediction"),d(C1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(C1,"href","#transformers.AutoModelForNextSentencePrediction"),d(ud,"class","relative group"),d(Yr,"class","docstring"),d(sD,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(lD,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(iD,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(dD,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(cD,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(Ve,"class","docstring"),d(tr,"class","docstring"),d(B1,"id","transformers.AutoModelForTokenClassification"),d(B1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(B1,"href","#transformers.AutoModelForTokenClassification"),d(Td,"class","relative group"),d(Kr,"class","docstring"),d(fD,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(mD,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForTokenClassification"),d(gD,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(hD,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(pD,"href","/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForTokenClassification"),d(_D,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(uD,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(bD,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(vD,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(TD,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(FD,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(CD,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(MD,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(ED,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(yD,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(wD,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(AD,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(LD,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(BD,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(xD,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(kD,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(RD,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(SD,"href","/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(PD,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d($D,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(ID,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(ND,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(DD,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(jD,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(qD,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(GD,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(OD,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(XD,"href","/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(ze,"class","docstring"),d(ar,"class","docstring"),d(cb,"id","transformers.AutoModelForQuestionAnswering"),d(cb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(cb,"href","#transformers.AutoModelForQuestionAnswering"),d(Md,"class","relative group"),d(Zr,"class","docstring"),d(VD,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(zD,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(WD,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(QD,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(HD,"href","/docs/transformers/pr_16255/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(UD,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(JD,"href","/docs/transformers/pr_16255/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(YD,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(KD,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(ZD,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(ej,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(oj,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(rj,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(tj,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(aj,"href","/docs/transformers/pr_16255/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(nj,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(sj,"href","/docs/transformers/pr_16255/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(lj,"href","/docs/transformers/pr_16255/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(ij,"href","/docs/transformers/pr_16255/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(dj,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(cj,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(fj,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(mj,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(gj,"href","/docs/transformers/pr_16255/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(hj,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(pj,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(_j,"href","/docs/transformers/pr_16255/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(uj,"href","/docs/transformers/pr_16255/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(bj,"href","/docs/transformers/pr_16255/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(vj,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(Tj,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(Fj,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(Cj,"href","/docs/transformers/pr_16255/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(Mj,"href","/docs/transformers/pr_16255/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(Ej,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(yj,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(wj,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(Aj,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(Lj,"href","/docs/transformers/pr_16255/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(We,"class","docstring"),d(nr,"class","docstring"),d(Yb,"id","transformers.AutoModelForTableQuestionAnswering"),d(Yb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Yb,"href","#transformers.AutoModelForTableQuestionAnswering"),d(wd,"class","relative group"),d(et,"class","docstring"),d(Bj,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(Qe,"class","docstring"),d(sr,"class","docstring"),d(ev,"id","transformers.AutoModelForImageClassification"),d(ev,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ev,"href","#transformers.AutoModelForImageClassification"),d(Bd,"class","relative group"),d(ot,"class","docstring"),d(xj,"href","/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitForImageClassification"),d(kj,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(Rj,"href","/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTForImageClassification"),d(Sj,"href","/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(Pj,"href","/docs/transformers/pr_16255/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d($j,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(Ij,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(Nj,"href","/docs/transformers/pr_16255/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(Dj,"href","/docs/transformers/pr_16255/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(jj,"href","/docs/transformers/pr_16255/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(qj,"href","/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(Gj,"href","/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinForImageClassification"),d(Oj,"href","/docs/transformers/pr_16255/en/model_doc/van#transformers.VanForImageClassification"),d(Xj,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTForImageClassification"),d(He,"class","docstring"),d(lr,"class","docstring"),d(fv,"id","transformers.AutoModelForVision2Seq"),d(fv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(fv,"href","#transformers.AutoModelForVision2Seq"),d(Rd,"class","relative group"),d(rt,"class","docstring"),d(Vj,"href","/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(Ue,"class","docstring"),d(ir,"class","docstring"),d(hv,"id","transformers.AutoModelForAudioClassification"),d(hv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(hv,"href","#transformers.AutoModelForAudioClassification"),d($d,"class","relative group"),d(tt,"class","docstring"),d(zj,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(Wj,"href","/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(Qj,"href","/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(Hj,"href","/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(Uj,"href","/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(Jj,"href","/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(Yj,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(Kj,"href","/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(Je,"class","docstring"),d(dr,"class","docstring"),d(Ev,"id","transformers.AutoModelForAudioFrameClassification"),d(Ev,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ev,"href","#transformers.AutoModelForAudioFrameClassification"),d(Dd,"class","relative group"),d(at,"class","docstring"),d(Zj,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(eq,"href","/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(oq,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(rq,"href","/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(Ye,"class","docstring"),d(cr,"class","docstring"),d(xv,"id","transformers.AutoModelForCTC"),d(xv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xv,"href","#transformers.AutoModelForCTC"),d(Gd,"class","relative group"),d(nt,"class","docstring"),d(tq,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(aq,"href","/docs/transformers/pr_16255/en/model_doc/hubert#transformers.HubertForCTC"),d(nq,"href","/docs/transformers/pr_16255/en/model_doc/sew#transformers.SEWForCTC"),d(sq,"href","/docs/transformers/pr_16255/en/model_doc/sew-d#transformers.SEWDForCTC"),d(lq,"href","/docs/transformers/pr_16255/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(iq,"href","/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(dq,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(cq,"href","/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForCTC"),d(Ke,"class","docstring"),d(fr,"class","docstring"),d(qv,"id","transformers.AutoModelForSpeechSeq2Seq"),d(qv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qv,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Vd,"class","relative group"),d(st,"class","docstring"),d(fq,"href","/docs/transformers/pr_16255/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(mq,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(Ze,"class","docstring"),d(mr,"class","docstring"),d(Vv,"id","transformers.AutoModelForAudioXVector"),d(Vv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Vv,"href","#transformers.AutoModelForAudioXVector"),d(Qd,"class","relative group"),d(lt,"class","docstring"),d(gq,"href","/docs/transformers/pr_16255/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(hq,"href","/docs/transformers/pr_16255/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(pq,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(_q,"href","/docs/transformers/pr_16255/en/model_doc/wavlm#transformers.WavLMForXVector"),d(eo,"class","docstring"),d(gr,"class","docstring"),d(Jv,"id","transformers.AutoModelForMaskedImageModeling"),d(Jv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Jv,"href","#transformers.AutoModelForMaskedImageModeling"),d(Jd,"class","relative group"),d(it,"class","docstring"),d(uq,"href","/docs/transformers/pr_16255/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(bq,"href","/docs/transformers/pr_16255/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(vq,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(oo,"class","docstring"),d(hr,"class","docstring"),d(o6,"id","transformers.AutoModelForObjectDetection"),d(o6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(o6,"href","#transformers.AutoModelForObjectDetection"),d(ec,"class","relative group"),d(dt,"class","docstring"),d(Tq,"href","/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrForObjectDetection"),d(ro,"class","docstring"),d(pr,"class","docstring"),d(a6,"id","transformers.AutoModelForImageSegmentation"),d(a6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(a6,"href","#transformers.AutoModelForImageSegmentation"),d(tc,"class","relative group"),d(ct,"class","docstring"),d(Fq,"href","/docs/transformers/pr_16255/en/model_doc/detr#transformers.DetrForSegmentation"),d(to,"class","docstring"),d(_r,"class","docstring"),d(l6,"id","transformers.AutoModelForSemanticSegmentation"),d(l6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(l6,"href","#transformers.AutoModelForSemanticSegmentation"),d(sc,"class","relative group"),d(ft,"class","docstring"),d(Cq,"href","/docs/transformers/pr_16255/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(Mq,"href","/docs/transformers/pr_16255/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(ao,"class","docstring"),d(ur,"class","docstring"),d(f6,"id","transformers.AutoModelForInstanceSegmentation"),d(f6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f6,"href","#transformers.AutoModelForInstanceSegmentation"),d(dc,"class","relative group"),d(mt,"class","docstring"),d(Eq,"href","/docs/transformers/pr_16255/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d(no,"class","docstring"),d(br,"class","docstring"),d(h6,"id","transformers.TFAutoModel"),d(h6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(h6,"href","#transformers.TFAutoModel"),d(mc,"class","relative group"),d(gt,"class","docstring"),d(yq,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertModel"),d(wq,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.TFBartModel"),d(Aq,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertModel"),d(Lq,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(Bq,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(xq,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertModel"),d(kq,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.TFCLIPModel"),d(Rq,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertModel"),d(Sq,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.TFConvNextModel"),d(Pq,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLModel"),d($q,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaModel"),d(Iq,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(Nq,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(Dq,"href","/docs/transformers/pr_16255/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(jq,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraModel"),d(qq,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(Gq,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelModel"),d(Oq,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(Xq,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2Model"),d(Vq,"href","/docs/transformers/pr_16255/en/model_doc/hubert#transformers.TFHubertModel"),d(zq,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(Wq,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.TFLEDModel"),d(Qq,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerModel"),d(Hq,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.TFLxmertModel"),d(Uq,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.TFMarianModel"),d(Jq,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.TFMBartModel"),d(Yq,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(Kq,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetModel"),d(Zq,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.TFMT5Model"),d(eG,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(oG,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.TFPegasusModel"),d(rG,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertModel"),d(tG,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaModel"),d(aG,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerModel"),d(nG,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(sG,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.TFT5Model"),d(lG,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasModel"),d(iG,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(dG,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.TFViTModel"),d(cG,"href","/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(fG,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(mG,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMModel"),d(gG,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(hG,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetModel"),d(ho,"class","docstring"),d(vr,"class","docstring"),d(tT,"id","transformers.TFAutoModelForPreTraining"),d(tT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(tT,"href","#transformers.TFAutoModelForPreTraining"),d(pc,"class","relative group"),d(ht,"class","docstring"),d(pG,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(_G,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(uG,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForPreTraining"),d(bG,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(vG,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(TG,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(FG,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(CG,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(MG,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(EG,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(yG,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(wG,"href","/docs/transformers/pr_16255/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(AG,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(LG,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(BG,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(xG,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(kG,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(RG,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(SG,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(PG,"href","/docs/transformers/pr_16255/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d($G,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(IG,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(NG,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(po,"class","docstring"),d(Tr,"class","docstring"),d(AT,"id","transformers.TFAutoModelForCausalLM"),d(AT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(AT,"href","#transformers.TFAutoModelForCausalLM"),d(bc,"class","relative group"),d(pt,"class","docstring"),d(DG,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(jG,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(qG,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(GG,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(OG,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(XG,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(VG,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(zG,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(WG,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(QG,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(HG,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(_o,"class","docstring"),d(Fr,"class","docstring"),d(jT,"id","transformers.TFAutoModelForImageClassification"),d(jT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(jT,"href","#transformers.TFAutoModelForImageClassification"),d(Fc,"class","relative group"),d(_t,"class","docstring"),d(UG,"href","/docs/transformers/pr_16255/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(JG,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.TFViTForImageClassification"),d(uo,"class","docstring"),d(Cr,"class","docstring"),d(OT,"id","transformers.TFAutoModelForMaskedLM"),d(OT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(OT,"href","#transformers.TFAutoModelForMaskedLM"),d(Ec,"class","relative group"),d(ut,"class","docstring"),d(YG,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(KG,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(ZG,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(eO,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(oO,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(rO,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(tO,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(aO,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(nO,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(sO,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(lO,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(iO,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(dO,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(cO,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(fO,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(mO,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(gO,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(hO,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(pO,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(_O,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(bo,"class","docstring"),d(Mr,"class","docstring"),d(dF,"id","transformers.TFAutoModelForSeq2SeqLM"),d(dF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dF,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(Ac,"class","relative group"),d(bt,"class","docstring"),d(uO,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(bO,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(vO,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(TO,"href","/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(FO,"href","/docs/transformers/pr_16255/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(CO,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.TFMarianMTModel"),d(MO,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(EO,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(yO,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(wO,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(vo,"class","docstring"),d(Er,"class","docstring"),d(TF,"id","transformers.TFAutoModelForSequenceClassification"),d(TF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(TF,"href","#transformers.TFAutoModelForSequenceClassification"),d(xc,"class","relative group"),d(vt,"class","docstring"),d(AO,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(LO,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(BO,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(xO,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(kO,"href","/docs/transformers/pr_16255/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(RO,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(SO,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(PO,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d($O,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(IO,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(NO,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(DO,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(jO,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(qO,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(GO,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(OO,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(XO,"href","/docs/transformers/pr_16255/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(VO,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(zO,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(WO,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(QO,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(HO,"href","/docs/transformers/pr_16255/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(UO,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(JO,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(YO,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(To,"class","docstring"),d(yr,"class","docstring"),d(WF,"id","transformers.TFAutoModelForMultipleChoice"),d(WF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(WF,"href","#transformers.TFAutoModelForMultipleChoice"),d(Sc,"class","relative group"),d(Tt,"class","docstring"),d(KO,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(ZO,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(eX,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(oX,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(rX,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(tX,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(aX,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(nX,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(sX,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(lX,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(iX,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(dX,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(cX,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(fX,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(mX,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(gX,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(hX,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Fo,"class","docstring"),d(wr,"class","docstring"),d(cC,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(cC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(cC,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Ic,"class","relative group"),d(Ft,"class","docstring"),d(pX,"href","/docs/transformers/pr_16255/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(Co,"class","docstring"),d(Ar,"class","docstring"),d(mC,"id","transformers.TFAutoModelForTokenClassification"),d(mC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(mC,"href","#transformers.TFAutoModelForTokenClassification"),d(jc,"class","relative group"),d(Ct,"class","docstring"),d(_X,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(uX,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(bX,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(vX,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(TX,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(FX,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(CX,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(MX,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(EX,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(yX,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(wX,"href","/docs/transformers/pr_16255/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(AX,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(LX,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(BX,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(xX,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(kX,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(RX,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(SX,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(PX,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d($X,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(Mo,"class","docstring"),d(Lr,"class","docstring"),d(SC,"id","transformers.TFAutoModelForQuestionAnswering"),d(SC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(SC,"href","#transformers.TFAutoModelForQuestionAnswering"),d(Oc,"class","relative group"),d(Mt,"class","docstring"),d(IX,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(NX,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(DX,"href","/docs/transformers/pr_16255/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(jX,"href","/docs/transformers/pr_16255/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(qX,"href","/docs/transformers/pr_16255/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(GX,"href","/docs/transformers/pr_16255/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(OX,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(XX,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(VX,"href","/docs/transformers/pr_16255/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(zX,"href","/docs/transformers/pr_16255/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(WX,"href","/docs/transformers/pr_16255/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(QX,"href","/docs/transformers/pr_16255/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(HX,"href","/docs/transformers/pr_16255/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(UX,"href","/docs/transformers/pr_16255/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(JX,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(YX,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(KX,"href","/docs/transformers/pr_16255/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(ZX,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(eV,"href","/docs/transformers/pr_16255/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(Eo,"class","docstring"),d(Br,"class","docstring"),d(ZC,"id","transformers.TFAutoModelForVision2Seq"),d(ZC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ZC,"href","#transformers.TFAutoModelForVision2Seq"),d(zc,"class","relative group"),d(Et,"class","docstring"),d(oV,"href","/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(yo,"class","docstring"),d(xr,"class","docstring"),d(oM,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(oM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(oM,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(Hc,"class","relative group"),d(yt,"class","docstring"),d(rV,"href","/docs/transformers/pr_16255/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(wo,"class","docstring"),d(kr,"class","docstring"),d(tM,"id","transformers.FlaxAutoModel"),d(tM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(tM,"href","#transformers.FlaxAutoModel"),d(Yc,"class","relative group"),d(wt,"class","docstring"),d(tV,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertModel"),d(aV,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartModel"),d(nV,"href","/docs/transformers/pr_16255/en/model_doc/beit#transformers.FlaxBeitModel"),d(sV,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertModel"),d(lV,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(iV,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(dV,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(cV,"href","/docs/transformers/pr_16255/en/model_doc/clip#transformers.FlaxCLIPModel"),d(fV,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(mV,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraModel"),d(gV,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(hV,"href","/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(pV,"href","/docs/transformers/pr_16255/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(_V,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.FlaxMarianModel"),d(uV,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartModel"),d(bV,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.FlaxMT5Model"),d(vV,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(TV,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(FV,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(CV,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.FlaxT5Model"),d(MV,"href","/docs/transformers/pr_16255/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(EV,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.FlaxViTModel"),d(yV,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(wV,"href","/docs/transformers/pr_16255/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(AV,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(Ao,"class","docstring"),d(Rr,"class","docstring"),d(BM,"id","transformers.FlaxAutoModelForCausalLM"),d(BM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(BM,"href","#transformers.FlaxAutoModelForCausalLM"),d(ef,"class","relative group"),d(At,"class","docstring"),d(LV,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(BV,"href","/docs/transformers/pr_16255/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(xV,"href","/docs/transformers/pr_16255/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(kV,"href","/docs/transformers/pr_16255/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(RV,"href","/docs/transformers/pr_16255/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(Lo,"class","docstring"),d(Sr,"class","docstring"),d($M,"id","transformers.FlaxAutoModelForPreTraining"),d($M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($M,"href","#transformers.FlaxAutoModelForPreTraining"),d(tf,"class","relative group"),d(Lt,"class","docstring"),d(SV,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(PV,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d($V,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(IV,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(NV,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(DV,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(jV,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(qV,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(GV,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(OV,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(XV,"href","/docs/transformers/pr_16255/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(VV,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(Bo,"class","docstring"),d(Pr,"class","docstring"),d(HM,"id","transformers.FlaxAutoModelForMaskedLM"),d(HM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(HM,"href","#transformers.FlaxAutoModelForMaskedLM"),d(sf,"class","relative group"),d(Bt,"class","docstring"),d(zV,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(WV,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(QV,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(HV,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(UV,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(JV,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(YV,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(KV,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(ZV,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(ez,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(xo,"class","docstring"),d($r,"class","docstring"),d(n4,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(n4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n4,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(cf,"class","relative group"),d(xt,"class","docstring"),d(oz,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(rz,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(tz,"href","/docs/transformers/pr_16255/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(az,"href","/docs/transformers/pr_16255/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(nz,"href","/docs/transformers/pr_16255/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(sz,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(lz,"href","/docs/transformers/pr_16255/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(iz,"href","/docs/transformers/pr_16255/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(dz,"href","/docs/transformers/pr_16255/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(ko,"class","docstring"),d(Ir,"class","docstring"),d(p4,"id","transformers.FlaxAutoModelForSequenceClassification"),d(p4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p4,"href","#transformers.FlaxAutoModelForSequenceClassification"),d(gf,"class","relative group"),d(kt,"class","docstring"),d(cz,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(fz,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(mz,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(gz,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(hz,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(pz,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(_z,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(uz,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(bz,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(vz,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(Ro,"class","docstring"),d(Nr,"class","docstring"),d(w4,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(w4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w4,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(_f,"class","relative group"),d(Rt,"class","docstring"),d(Tz,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(Fz,"href","/docs/transformers/pr_16255/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(Cz,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(Mz,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(Ez,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(yz,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(wz,"href","/docs/transformers/pr_16255/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(Az,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(Lz,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(Bz,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(So,"class","docstring"),d(Dr,"class","docstring"),d(N4,"id","transformers.FlaxAutoModelForTokenClassification"),d(N4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N4,"href","#transformers.FlaxAutoModelForTokenClassification"),d(vf,"class","relative group"),d(St,"class","docstring"),d(xz,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(kz,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(Rz,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(Sz,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(Pz,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d($z,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(Iz,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(Nz,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(Po,"class","docstring"),d(jr,"class","docstring"),d(W4,"id","transformers.FlaxAutoModelForMultipleChoice"),d(W4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W4,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(Cf,"class","relative group"),d(Pt,"class","docstring"),d(Dz,"href","/docs/transformers/pr_16255/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(jz,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(qz,"href","/docs/transformers/pr_16255/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(Gz,"href","/docs/transformers/pr_16255/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(Oz,"href","/docs/transformers/pr_16255/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(Xz,"href","/docs/transformers/pr_16255/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(Vz,"href","/docs/transformers/pr_16255/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(zz,"href","/docs/transformers/pr_16255/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d($o,"class","docstring"),d(qr,"class","docstring"),d(oE,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(oE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(oE,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(yf,"class","relative group"),d($t,"class","docstring"),d(Wz,"href","/docs/transformers/pr_16255/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(Io,"class","docstring"),d(Gr,"class","docstring"),d(tE,"id","transformers.FlaxAutoModelForImageClassification"),d(tE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(tE,"href","#transformers.FlaxAutoModelForImageClassification"),d(Lf,"class","relative group"),d(It,"class","docstring"),d(Qz,"href","/docs/transformers/pr_16255/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(Hz,"href","/docs/transformers/pr_16255/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(No,"class","docstring"),d(Or,"class","docstring"),d(sE,"id","transformers.FlaxAutoModelForVision2Seq"),d(sE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sE,"href","#transformers.FlaxAutoModelForVision2Seq"),d(kf,"class","relative group"),d(Nt,"class","docstring"),d(Uz,"href","/docs/transformers/pr_16255/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(Do,"class","docstring"),d(Xr,"class","docstring")},m(c,u){e(document.head,K),b(c,io,u),b(c,de,u),e(de,Ee),e(Ee,lo),g(fe,lo,null),e(de,Ce),e(de,Vo),e(Vo,Ii),b(c,If,u),b(c,fa,u),e(fa,Ni),e(fa,Di),e(Di,l3),e(fa,Nf),b(c,Be,u),b(c,co,u),e(co,ji),e(co,Gn),e(Gn,i3),e(co,On),e(co,Xn),e(Xn,d3),e(co,qi),e(co,Vn),e(Vn,c3),e(co,Gi),b(c,Df,u),g(qa,c,u),b(c,fo,u),b(c,pe,u),e(pe,e9),e(pe,Oi),e(Oi,o9),e(pe,r9),b(c,zo,u),b(c,Ga,u),e(Ga,t9),e(Ga,jf),e(jf,a9),e(Ga,C$e),b(c,ike,u),b(c,Xi,u),e(Xi,qf),e(qf,OQ),g(f3,OQ,null),e(Xi,M$e),e(Xi,XQ),e(XQ,E$e),b(c,dke,u),b(c,zn,u),e(zn,y$e),e(zn,VQ),e(VQ,w$e),e(zn,A$e),e(zn,zQ),e(zQ,L$e),e(zn,B$e),b(c,cke,u),g(m3,c,u),b(c,fke,u),b(c,n9,u),e(n9,x$e),b(c,mke,u),g(Gf,c,u),b(c,gke,u),b(c,Vi,u),e(Vi,Of),e(Of,WQ),g(g3,WQ,null),e(Vi,k$e),e(Vi,QQ),e(QQ,R$e),b(c,hke,u),b(c,Wo,u),g(h3,Wo,null),e(Wo,S$e),e(Wo,p3),e(p3,P$e),e(p3,s9),e(s9,$$e),e(p3,I$e),e(Wo,N$e),e(Wo,_3),e(_3,D$e),e(_3,HQ),e(HQ,j$e),e(_3,q$e),e(Wo,G$e),e(Wo,mo),g(u3,mo,null),e(mo,O$e),e(mo,UQ),e(UQ,X$e),e(mo,V$e),e(mo,zi),e(zi,z$e),e(zi,JQ),e(JQ,W$e),e(zi,Q$e),e(zi,YQ),e(YQ,H$e),e(zi,U$e),e(mo,J$e),e(mo,v),e(v,Xf),e(Xf,KQ),e(KQ,Y$e),e(Xf,K$e),e(Xf,l9),e(l9,Z$e),e(Xf,eIe),e(v,oIe),e(v,Vf),e(Vf,ZQ),e(ZQ,rIe),e(Vf,tIe),e(Vf,i9),e(i9,aIe),e(Vf,nIe),e(v,sIe),e(v,zf),e(zf,eH),e(eH,lIe),e(zf,iIe),e(zf,d9),e(d9,dIe),e(zf,cIe),e(v,fIe),e(v,Wf),e(Wf,oH),e(oH,mIe),e(Wf,gIe),e(Wf,c9),e(c9,hIe),e(Wf,pIe),e(v,_Ie),e(v,Qf),e(Qf,rH),e(rH,uIe),e(Qf,bIe),e(Qf,f9),e(f9,vIe),e(Qf,TIe),e(v,FIe),e(v,Hf),e(Hf,tH),e(tH,CIe),e(Hf,MIe),e(Hf,m9),e(m9,EIe),e(Hf,yIe),e(v,wIe),e(v,Uf),e(Uf,aH),e(aH,AIe),e(Uf,LIe),e(Uf,g9),e(g9,BIe),e(Uf,xIe),e(v,kIe),e(v,Jf),e(Jf,nH),e(nH,RIe),e(Jf,SIe),e(Jf,h9),e(h9,PIe),e(Jf,$Ie),e(v,IIe),e(v,Yf),e(Yf,sH),e(sH,NIe),e(Yf,DIe),e(Yf,p9),e(p9,jIe),e(Yf,qIe),e(v,GIe),e(v,Kf),e(Kf,lH),e(lH,OIe),e(Kf,XIe),e(Kf,_9),e(_9,VIe),e(Kf,zIe),e(v,WIe),e(v,Zf),e(Zf,iH),e(iH,QIe),e(Zf,HIe),e(Zf,u9),e(u9,UIe),e(Zf,JIe),e(v,YIe),e(v,em),e(em,dH),e(dH,KIe),e(em,ZIe),e(em,b9),e(b9,eNe),e(em,oNe),e(v,rNe),e(v,om),e(om,cH),e(cH,tNe),e(om,aNe),e(om,v9),e(v9,nNe),e(om,sNe),e(v,lNe),e(v,rm),e(rm,fH),e(fH,iNe),e(rm,dNe),e(rm,T9),e(T9,cNe),e(rm,fNe),e(v,mNe),e(v,tm),e(tm,mH),e(mH,gNe),e(tm,hNe),e(tm,F9),e(F9,pNe),e(tm,_Ne),e(v,uNe),e(v,am),e(am,gH),e(gH,bNe),e(am,vNe),e(am,C9),e(C9,TNe),e(am,FNe),e(v,CNe),e(v,nm),e(nm,hH),e(hH,MNe),e(nm,ENe),e(nm,M9),e(M9,yNe),e(nm,wNe),e(v,ANe),e(v,sm),e(sm,pH),e(pH,LNe),e(sm,BNe),e(sm,E9),e(E9,xNe),e(sm,kNe),e(v,RNe),e(v,lm),e(lm,_H),e(_H,SNe),e(lm,PNe),e(lm,y9),e(y9,$Ne),e(lm,INe),e(v,NNe),e(v,im),e(im,uH),e(uH,DNe),e(im,jNe),e(im,w9),e(w9,qNe),e(im,GNe),e(v,ONe),e(v,dm),e(dm,bH),e(bH,XNe),e(dm,VNe),e(dm,A9),e(A9,zNe),e(dm,WNe),e(v,QNe),e(v,cm),e(cm,vH),e(vH,HNe),e(cm,UNe),e(cm,L9),e(L9,JNe),e(cm,YNe),e(v,KNe),e(v,fm),e(fm,TH),e(TH,ZNe),e(fm,eDe),e(fm,B9),e(B9,oDe),e(fm,rDe),e(v,tDe),e(v,mm),e(mm,FH),e(FH,aDe),e(mm,nDe),e(mm,x9),e(x9,sDe),e(mm,lDe),e(v,iDe),e(v,gm),e(gm,CH),e(CH,dDe),e(gm,cDe),e(gm,k9),e(k9,fDe),e(gm,mDe),e(v,gDe),e(v,hm),e(hm,MH),e(MH,hDe),e(hm,pDe),e(hm,R9),e(R9,_De),e(hm,uDe),e(v,bDe),e(v,pm),e(pm,EH),e(EH,vDe),e(pm,TDe),e(pm,S9),e(S9,FDe),e(pm,CDe),e(v,MDe),e(v,_m),e(_m,yH),e(yH,EDe),e(_m,yDe),e(_m,P9),e(P9,wDe),e(_m,ADe),e(v,LDe),e(v,um),e(um,wH),e(wH,BDe),e(um,xDe),e(um,$9),e($9,kDe),e(um,RDe),e(v,SDe),e(v,bm),e(bm,AH),e(AH,PDe),e(bm,$De),e(bm,I9),e(I9,IDe),e(bm,NDe),e(v,DDe),e(v,vm),e(vm,LH),e(LH,jDe),e(vm,qDe),e(vm,N9),e(N9,GDe),e(vm,ODe),e(v,XDe),e(v,Tm),e(Tm,BH),e(BH,VDe),e(Tm,zDe),e(Tm,D9),e(D9,WDe),e(Tm,QDe),e(v,HDe),e(v,Fm),e(Fm,xH),e(xH,UDe),e(Fm,JDe),e(Fm,j9),e(j9,YDe),e(Fm,KDe),e(v,ZDe),e(v,Cm),e(Cm,kH),e(kH,eje),e(Cm,oje),e(Cm,q9),e(q9,rje),e(Cm,tje),e(v,aje),e(v,Mm),e(Mm,RH),e(RH,nje),e(Mm,sje),e(Mm,G9),e(G9,lje),e(Mm,ije),e(v,dje),e(v,Em),e(Em,SH),e(SH,cje),e(Em,fje),e(Em,O9),e(O9,mje),e(Em,gje),e(v,hje),e(v,ym),e(ym,PH),e(PH,pje),e(ym,_je),e(ym,X9),e(X9,uje),e(ym,bje),e(v,vje),e(v,wm),e(wm,$H),e($H,Tje),e(wm,Fje),e(wm,V9),e(V9,Cje),e(wm,Mje),e(v,Eje),e(v,Am),e(Am,IH),e(IH,yje),e(Am,wje),e(Am,z9),e(z9,Aje),e(Am,Lje),e(v,Bje),e(v,Lm),e(Lm,NH),e(NH,xje),e(Lm,kje),e(Lm,W9),e(W9,Rje),e(Lm,Sje),e(v,Pje),e(v,Bm),e(Bm,DH),e(DH,$je),e(Bm,Ije),e(Bm,Q9),e(Q9,Nje),e(Bm,Dje),e(v,jje),e(v,xm),e(xm,jH),e(jH,qje),e(xm,Gje),e(xm,H9),e(H9,Oje),e(xm,Xje),e(v,Vje),e(v,km),e(km,qH),e(qH,zje),e(km,Wje),e(km,U9),e(U9,Qje),e(km,Hje),e(v,Uje),e(v,Rm),e(Rm,GH),e(GH,Jje),e(Rm,Yje),e(Rm,J9),e(J9,Kje),e(Rm,Zje),e(v,eqe),e(v,Sm),e(Sm,OH),e(OH,oqe),e(Sm,rqe),e(Sm,Y9),e(Y9,tqe),e(Sm,aqe),e(v,nqe),e(v,Pm),e(Pm,XH),e(XH,sqe),e(Pm,lqe),e(Pm,K9),e(K9,iqe),e(Pm,dqe),e(v,cqe),e(v,$m),e($m,VH),e(VH,fqe),e($m,mqe),e($m,Z9),e(Z9,gqe),e($m,hqe),e(v,pqe),e(v,Im),e(Im,zH),e(zH,_qe),e(Im,uqe),e(Im,eB),e(eB,bqe),e(Im,vqe),e(v,Tqe),e(v,Nm),e(Nm,WH),e(WH,Fqe),e(Nm,Cqe),e(Nm,oB),e(oB,Mqe),e(Nm,Eqe),e(v,yqe),e(v,Dm),e(Dm,QH),e(QH,wqe),e(Dm,Aqe),e(Dm,rB),e(rB,Lqe),e(Dm,Bqe),e(v,xqe),e(v,jm),e(jm,HH),e(HH,kqe),e(jm,Rqe),e(jm,tB),e(tB,Sqe),e(jm,Pqe),e(v,$qe),e(v,qm),e(qm,UH),e(UH,Iqe),e(qm,Nqe),e(qm,aB),e(aB,Dqe),e(qm,jqe),e(v,qqe),e(v,Gm),e(Gm,JH),e(JH,Gqe),e(Gm,Oqe),e(Gm,nB),e(nB,Xqe),e(Gm,Vqe),e(v,zqe),e(v,Om),e(Om,YH),e(YH,Wqe),e(Om,Qqe),e(Om,sB),e(sB,Hqe),e(Om,Uqe),e(v,Jqe),e(v,Xm),e(Xm,KH),e(KH,Yqe),e(Xm,Kqe),e(Xm,lB),e(lB,Zqe),e(Xm,eGe),e(v,oGe),e(v,Vm),e(Vm,ZH),e(ZH,rGe),e(Vm,tGe),e(Vm,iB),e(iB,aGe),e(Vm,nGe),e(v,sGe),e(v,zm),e(zm,eU),e(eU,lGe),e(zm,iGe),e(zm,dB),e(dB,dGe),e(zm,cGe),e(v,fGe),e(v,Wm),e(Wm,oU),e(oU,mGe),e(Wm,gGe),e(Wm,cB),e(cB,hGe),e(Wm,pGe),e(v,_Ge),e(v,Qm),e(Qm,rU),e(rU,uGe),e(Qm,bGe),e(Qm,fB),e(fB,vGe),e(Qm,TGe),e(v,FGe),e(v,Hm),e(Hm,tU),e(tU,CGe),e(Hm,MGe),e(Hm,mB),e(mB,EGe),e(Hm,yGe),e(v,wGe),e(v,Um),e(Um,aU),e(aU,AGe),e(Um,LGe),e(Um,gB),e(gB,BGe),e(Um,xGe),e(v,kGe),e(v,Jm),e(Jm,nU),e(nU,RGe),e(Jm,SGe),e(Jm,hB),e(hB,PGe),e(Jm,$Ge),e(v,IGe),e(v,Ym),e(Ym,sU),e(sU,NGe),e(Ym,DGe),e(Ym,pB),e(pB,jGe),e(Ym,qGe),e(v,GGe),e(v,Km),e(Km,lU),e(lU,OGe),e(Km,XGe),e(Km,_B),e(_B,VGe),e(Km,zGe),e(v,WGe),e(v,Zm),e(Zm,iU),e(iU,QGe),e(Zm,HGe),e(Zm,uB),e(uB,UGe),e(Zm,JGe),e(v,YGe),e(v,eg),e(eg,dU),e(dU,KGe),e(eg,ZGe),e(eg,bB),e(bB,eOe),e(eg,oOe),e(v,rOe),e(v,og),e(og,cU),e(cU,tOe),e(og,aOe),e(og,vB),e(vB,nOe),e(og,sOe),e(v,lOe),e(v,rg),e(rg,fU),e(fU,iOe),e(rg,dOe),e(rg,TB),e(TB,cOe),e(rg,fOe),e(v,mOe),e(v,tg),e(tg,mU),e(mU,gOe),e(tg,hOe),e(tg,FB),e(FB,pOe),e(tg,_Oe),e(v,uOe),e(v,ag),e(ag,gU),e(gU,bOe),e(ag,vOe),e(ag,CB),e(CB,TOe),e(ag,FOe),e(v,COe),e(v,ng),e(ng,hU),e(hU,MOe),e(ng,EOe),e(ng,MB),e(MB,yOe),e(ng,wOe),e(v,AOe),e(v,sg),e(sg,pU),e(pU,LOe),e(sg,BOe),e(sg,EB),e(EB,xOe),e(sg,kOe),e(v,ROe),e(v,lg),e(lg,_U),e(_U,SOe),e(lg,POe),e(lg,yB),e(yB,$Oe),e(lg,IOe),e(v,NOe),e(v,ig),e(ig,uU),e(uU,DOe),e(ig,jOe),e(ig,wB),e(wB,qOe),e(ig,GOe),e(v,OOe),e(v,dg),e(dg,bU),e(bU,XOe),e(dg,VOe),e(dg,AB),e(AB,zOe),e(dg,WOe),e(v,QOe),e(v,cg),e(cg,vU),e(vU,HOe),e(cg,UOe),e(cg,LB),e(LB,JOe),e(cg,YOe),e(v,KOe),e(v,fg),e(fg,TU),e(TU,ZOe),e(fg,eXe),e(fg,BB),e(BB,oXe),e(fg,rXe),e(v,tXe),e(v,mg),e(mg,FU),e(FU,aXe),e(mg,nXe),e(mg,xB),e(xB,sXe),e(mg,lXe),e(v,iXe),e(v,gg),e(gg,CU),e(CU,dXe),e(gg,cXe),e(gg,kB),e(kB,fXe),e(gg,mXe),e(v,gXe),e(v,hg),e(hg,MU),e(MU,hXe),e(hg,pXe),e(hg,RB),e(RB,_Xe),e(hg,uXe),e(v,bXe),e(v,pg),e(pg,EU),e(EU,vXe),e(pg,TXe),e(pg,SB),e(SB,FXe),e(pg,CXe),e(v,MXe),e(v,_g),e(_g,yU),e(yU,EXe),e(_g,yXe),e(_g,PB),e(PB,wXe),e(_g,AXe),e(v,LXe),e(v,ug),e(ug,wU),e(wU,BXe),e(ug,xXe),e(ug,$B),e($B,kXe),e(ug,RXe),e(v,SXe),e(v,bg),e(bg,AU),e(AU,PXe),e(bg,$Xe),e(bg,IB),e(IB,IXe),e(bg,NXe),e(v,DXe),e(v,vg),e(vg,LU),e(LU,jXe),e(vg,qXe),e(vg,NB),e(NB,GXe),e(vg,OXe),e(v,XXe),e(v,Tg),e(Tg,BU),e(BU,VXe),e(Tg,zXe),e(Tg,DB),e(DB,WXe),e(Tg,QXe),e(v,HXe),e(v,Fg),e(Fg,xU),e(xU,UXe),e(Fg,JXe),e(Fg,jB),e(jB,YXe),e(Fg,KXe),e(v,ZXe),e(v,Cg),e(Cg,kU),e(kU,eVe),e(Cg,oVe),e(Cg,qB),e(qB,rVe),e(Cg,tVe),e(v,aVe),e(v,Mg),e(Mg,RU),e(RU,nVe),e(Mg,sVe),e(Mg,GB),e(GB,lVe),e(Mg,iVe),e(v,dVe),e(v,Eg),e(Eg,SU),e(SU,cVe),e(Eg,fVe),e(Eg,OB),e(OB,mVe),e(Eg,gVe),e(v,hVe),e(v,yg),e(yg,PU),e(PU,pVe),e(yg,_Ve),e(yg,XB),e(XB,uVe),e(yg,bVe),e(v,vVe),e(v,wg),e(wg,$U),e($U,TVe),e(wg,FVe),e(wg,VB),e(VB,CVe),e(wg,MVe),e(v,EVe),e(v,Ag),e(Ag,IU),e(IU,yVe),e(Ag,wVe),e(Ag,zB),e(zB,AVe),e(Ag,LVe),e(v,BVe),e(v,Lg),e(Lg,NU),e(NU,xVe),e(Lg,kVe),e(Lg,WB),e(WB,RVe),e(Lg,SVe),e(v,PVe),e(v,Bg),e(Bg,DU),e(DU,$Ve),e(Bg,IVe),e(Bg,QB),e(QB,NVe),e(Bg,DVe),e(v,jVe),e(v,xg),e(xg,jU),e(jU,qVe),e(xg,GVe),e(xg,HB),e(HB,OVe),e(xg,XVe),e(v,VVe),e(v,kg),e(kg,qU),e(qU,zVe),e(kg,WVe),e(kg,UB),e(UB,QVe),e(kg,HVe),e(v,UVe),e(v,Rg),e(Rg,GU),e(GU,JVe),e(Rg,YVe),e(Rg,JB),e(JB,KVe),e(Rg,ZVe),e(mo,eze),e(mo,OU),e(OU,oze),e(mo,rze),g(b3,mo,null),e(Wo,tze),e(Wo,Sg),g(v3,Sg,null),e(Sg,aze),e(Sg,XU),e(XU,nze),b(c,pke,u),b(c,Wi,u),e(Wi,Pg),e(Pg,VU),g(T3,VU,null),e(Wi,sze),e(Wi,zU),e(zU,lze),b(c,_ke,u),b(c,Qo,u),g(F3,Qo,null),e(Qo,ize),e(Qo,C3),e(C3,dze),e(C3,YB),e(YB,cze),e(C3,fze),e(Qo,mze),e(Qo,M3),e(M3,gze),e(M3,WU),e(WU,hze),e(M3,pze),e(Qo,_ze),e(Qo,go),g(E3,go,null),e(go,uze),e(go,QU),e(QU,bze),e(go,vze),e(go,Oa),e(Oa,Tze),e(Oa,HU),e(HU,Fze),e(Oa,Cze),e(Oa,UU),e(UU,Mze),e(Oa,Eze),e(Oa,JU),e(JU,yze),e(Oa,wze),e(go,Aze),e(go,E),e(E,Wn),e(Wn,YU),e(YU,Lze),e(Wn,Bze),e(Wn,KB),e(KB,xze),e(Wn,kze),e(Wn,ZB),e(ZB,Rze),e(Wn,Sze),e(E,Pze),e(E,Qn),e(Qn,KU),e(KU,$ze),e(Qn,Ize),e(Qn,ex),e(ex,Nze),e(Qn,Dze),e(Qn,ox),e(ox,jze),e(Qn,qze),e(E,Gze),e(E,Hn),e(Hn,ZU),e(ZU,Oze),e(Hn,Xze),e(Hn,rx),e(rx,Vze),e(Hn,zze),e(Hn,tx),e(tx,Wze),e(Hn,Qze),e(E,Hze),e(E,$g),e($g,eJ),e(eJ,Uze),e($g,Jze),e($g,ax),e(ax,Yze),e($g,Kze),e(E,Zze),e(E,Un),e(Un,oJ),e(oJ,eWe),e(Un,oWe),e(Un,nx),e(nx,rWe),e(Un,tWe),e(Un,sx),e(sx,aWe),e(Un,nWe),e(E,sWe),e(E,Ig),e(Ig,rJ),e(rJ,lWe),e(Ig,iWe),e(Ig,lx),e(lx,dWe),e(Ig,cWe),e(E,fWe),e(E,Ng),e(Ng,tJ),e(tJ,mWe),e(Ng,gWe),e(Ng,ix),e(ix,hWe),e(Ng,pWe),e(E,_We),e(E,Dg),e(Dg,aJ),e(aJ,uWe),e(Dg,bWe),e(Dg,dx),e(dx,vWe),e(Dg,TWe),e(E,FWe),e(E,Jn),e(Jn,nJ),e(nJ,CWe),e(Jn,MWe),e(Jn,cx),e(cx,EWe),e(Jn,yWe),e(Jn,fx),e(fx,wWe),e(Jn,AWe),e(E,LWe),e(E,Yn),e(Yn,sJ),e(sJ,BWe),e(Yn,xWe),e(Yn,mx),e(mx,kWe),e(Yn,RWe),e(Yn,gx),e(gx,SWe),e(Yn,PWe),e(E,$We),e(E,Kn),e(Kn,lJ),e(lJ,IWe),e(Kn,NWe),e(Kn,hx),e(hx,DWe),e(Kn,jWe),e(Kn,px),e(px,qWe),e(Kn,GWe),e(E,OWe),e(E,jg),e(jg,iJ),e(iJ,XWe),e(jg,VWe),e(jg,_x),e(_x,zWe),e(jg,WWe),e(E,QWe),e(E,qg),e(qg,dJ),e(dJ,HWe),e(qg,UWe),e(qg,ux),e(ux,JWe),e(qg,YWe),e(E,KWe),e(E,Zn),e(Zn,cJ),e(cJ,ZWe),e(Zn,eQe),e(Zn,bx),e(bx,oQe),e(Zn,rQe),e(Zn,vx),e(vx,tQe),e(Zn,aQe),e(E,nQe),e(E,Gg),e(Gg,fJ),e(fJ,sQe),e(Gg,lQe),e(Gg,Tx),e(Tx,iQe),e(Gg,dQe),e(E,cQe),e(E,es),e(es,mJ),e(mJ,fQe),e(es,mQe),e(es,Fx),e(Fx,gQe),e(es,hQe),e(es,Cx),e(Cx,pQe),e(es,_Qe),e(E,uQe),e(E,os),e(os,gJ),e(gJ,bQe),e(os,vQe),e(os,Mx),e(Mx,TQe),e(os,FQe),e(os,Ex),e(Ex,CQe),e(os,MQe),e(E,EQe),e(E,rs),e(rs,hJ),e(hJ,yQe),e(rs,wQe),e(rs,yx),e(yx,AQe),e(rs,LQe),e(rs,pJ),e(pJ,BQe),e(rs,xQe),e(E,kQe),e(E,Og),e(Og,_J),e(_J,RQe),e(Og,SQe),e(Og,wx),e(wx,PQe),e(Og,$Qe),e(E,IQe),e(E,ts),e(ts,uJ),e(uJ,NQe),e(ts,DQe),e(ts,Ax),e(Ax,jQe),e(ts,qQe),e(ts,Lx),e(Lx,GQe),e(ts,OQe),e(E,XQe),e(E,Xg),e(Xg,bJ),e(bJ,VQe),e(Xg,zQe),e(Xg,Bx),e(Bx,WQe),e(Xg,QQe),e(E,HQe),e(E,as),e(as,vJ),e(vJ,UQe),e(as,JQe),e(as,xx),e(xx,YQe),e(as,KQe),e(as,kx),e(kx,ZQe),e(as,eHe),e(E,oHe),e(E,ns),e(ns,TJ),e(TJ,rHe),e(ns,tHe),e(ns,Rx),e(Rx,aHe),e(ns,nHe),e(ns,Sx),e(Sx,sHe),e(ns,lHe),e(E,iHe),e(E,ss),e(ss,FJ),e(FJ,dHe),e(ss,cHe),e(ss,Px),e(Px,fHe),e(ss,mHe),e(ss,$x),e($x,gHe),e(ss,hHe),e(E,pHe),e(E,Vg),e(Vg,CJ),e(CJ,_He),e(Vg,uHe),e(Vg,Ix),e(Ix,bHe),e(Vg,vHe),e(E,THe),e(E,ls),e(ls,MJ),e(MJ,FHe),e(ls,CHe),e(ls,Nx),e(Nx,MHe),e(ls,EHe),e(ls,Dx),e(Dx,yHe),e(ls,wHe),e(E,AHe),e(E,zg),e(zg,EJ),e(EJ,LHe),e(zg,BHe),e(zg,jx),e(jx,xHe),e(zg,kHe),e(E,RHe),e(E,is),e(is,yJ),e(yJ,SHe),e(is,PHe),e(is,qx),e(qx,$He),e(is,IHe),e(is,Gx),e(Gx,NHe),e(is,DHe),e(E,jHe),e(E,ds),e(ds,wJ),e(wJ,qHe),e(ds,GHe),e(ds,Ox),e(Ox,OHe),e(ds,XHe),e(ds,Xx),e(Xx,VHe),e(ds,zHe),e(E,WHe),e(E,cs),e(cs,AJ),e(AJ,QHe),e(cs,HHe),e(cs,Vx),e(Vx,UHe),e(cs,JHe),e(cs,zx),e(zx,YHe),e(cs,KHe),e(E,ZHe),e(E,fs),e(fs,LJ),e(LJ,eUe),e(fs,oUe),e(fs,Wx),e(Wx,rUe),e(fs,tUe),e(fs,Qx),e(Qx,aUe),e(fs,nUe),e(E,sUe),e(E,Wg),e(Wg,BJ),e(BJ,lUe),e(Wg,iUe),e(Wg,Hx),e(Hx,dUe),e(Wg,cUe),e(E,fUe),e(E,ms),e(ms,xJ),e(xJ,mUe),e(ms,gUe),e(ms,Ux),e(Ux,hUe),e(ms,pUe),e(ms,Jx),e(Jx,_Ue),e(ms,uUe),e(E,bUe),e(E,gs),e(gs,kJ),e(kJ,vUe),e(gs,TUe),e(gs,Yx),e(Yx,FUe),e(gs,CUe),e(gs,Kx),e(Kx,MUe),e(gs,EUe),e(E,yUe),e(E,hs),e(hs,RJ),e(RJ,wUe),e(hs,AUe),e(hs,Zx),e(Zx,LUe),e(hs,BUe),e(hs,ek),e(ek,xUe),e(hs,kUe),e(E,RUe),e(E,ps),e(ps,SJ),e(SJ,SUe),e(ps,PUe),e(ps,ok),e(ok,$Ue),e(ps,IUe),e(ps,rk),e(rk,NUe),e(ps,DUe),e(E,jUe),e(E,_s),e(_s,PJ),e(PJ,qUe),e(_s,GUe),e(_s,tk),e(tk,OUe),e(_s,XUe),e(_s,ak),e(ak,VUe),e(_s,zUe),e(E,WUe),e(E,us),e(us,$J),e($J,QUe),e(us,HUe),e(us,nk),e(nk,UUe),e(us,JUe),e(us,sk),e(sk,YUe),e(us,KUe),e(E,ZUe),e(E,Qg),e(Qg,IJ),e(IJ,eJe),e(Qg,oJe),e(Qg,lk),e(lk,rJe),e(Qg,tJe),e(E,aJe),e(E,bs),e(bs,NJ),e(NJ,nJe),e(bs,sJe),e(bs,ik),e(ik,lJe),e(bs,iJe),e(bs,dk),e(dk,dJe),e(bs,cJe),e(E,fJe),e(E,Hg),e(Hg,DJ),e(DJ,mJe),e(Hg,gJe),e(Hg,ck),e(ck,hJe),e(Hg,pJe),e(E,_Je),e(E,Ug),e(Ug,jJ),e(jJ,uJe),e(Ug,bJe),e(Ug,fk),e(fk,vJe),e(Ug,TJe),e(E,FJe),e(E,vs),e(vs,qJ),e(qJ,CJe),e(vs,MJe),e(vs,mk),e(mk,EJe),e(vs,yJe),e(vs,gk),e(gk,wJe),e(vs,AJe),e(E,LJe),e(E,Ts),e(Ts,GJ),e(GJ,BJe),e(Ts,xJe),e(Ts,hk),e(hk,kJe),e(Ts,RJe),e(Ts,pk),e(pk,SJe),e(Ts,PJe),e(E,$Je),e(E,Jg),e(Jg,OJ),e(OJ,IJe),e(Jg,NJe),e(Jg,_k),e(_k,DJe),e(Jg,jJe),e(E,qJe),e(E,Fs),e(Fs,XJ),e(XJ,GJe),e(Fs,OJe),e(Fs,uk),e(uk,XJe),e(Fs,VJe),e(Fs,bk),e(bk,zJe),e(Fs,WJe),e(E,QJe),e(E,Cs),e(Cs,VJ),e(VJ,HJe),e(Cs,UJe),e(Cs,vk),e(vk,JJe),e(Cs,YJe),e(Cs,Tk),e(Tk,KJe),e(Cs,ZJe),e(E,eYe),e(E,Ms),e(Ms,zJ),e(zJ,oYe),e(Ms,rYe),e(Ms,Fk),e(Fk,tYe),e(Ms,aYe),e(Ms,Ck),e(Ck,nYe),e(Ms,sYe),e(E,lYe),e(E,Es),e(Es,WJ),e(WJ,iYe),e(Es,dYe),e(Es,Mk),e(Mk,cYe),e(Es,fYe),e(Es,Ek),e(Ek,mYe),e(Es,gYe),e(E,hYe),e(E,ys),e(ys,QJ),e(QJ,pYe),e(ys,_Ye),e(ys,yk),e(yk,uYe),e(ys,bYe),e(ys,wk),e(wk,vYe),e(ys,TYe),e(E,FYe),e(E,Yg),e(Yg,HJ),e(HJ,CYe),e(Yg,MYe),e(Yg,Ak),e(Ak,EYe),e(Yg,yYe),e(E,wYe),e(E,Kg),e(Kg,UJ),e(UJ,AYe),e(Kg,LYe),e(Kg,Lk),e(Lk,BYe),e(Kg,xYe),e(E,kYe),e(E,Zg),e(Zg,JJ),e(JJ,RYe),e(Zg,SYe),e(Zg,Bk),e(Bk,PYe),e(Zg,$Ye),e(E,IYe),e(E,eh),e(eh,YJ),e(YJ,NYe),e(eh,DYe),e(eh,xk),e(xk,jYe),e(eh,qYe),e(E,GYe),e(E,ws),e(ws,KJ),e(KJ,OYe),e(ws,XYe),e(ws,kk),e(kk,VYe),e(ws,zYe),e(ws,Rk),e(Rk,WYe),e(ws,QYe),e(E,HYe),e(E,oh),e(oh,ZJ),e(ZJ,UYe),e(oh,JYe),e(oh,Sk),e(Sk,YYe),e(oh,KYe),e(E,ZYe),e(E,As),e(As,eY),e(eY,eKe),e(As,oKe),e(As,Pk),e(Pk,rKe),e(As,tKe),e(As,$k),e($k,aKe),e(As,nKe),e(E,sKe),e(E,Ls),e(Ls,oY),e(oY,lKe),e(Ls,iKe),e(Ls,Ik),e(Ik,dKe),e(Ls,cKe),e(Ls,Nk),e(Nk,fKe),e(Ls,mKe),e(E,gKe),e(E,Bs),e(Bs,rY),e(rY,hKe),e(Bs,pKe),e(Bs,Dk),e(Dk,_Ke),e(Bs,uKe),e(Bs,jk),e(jk,bKe),e(Bs,vKe),e(E,TKe),e(E,xs),e(xs,tY),e(tY,FKe),e(xs,CKe),e(xs,qk),e(qk,MKe),e(xs,EKe),e(xs,Gk),e(Gk,yKe),e(xs,wKe),e(E,AKe),e(E,ks),e(ks,aY),e(aY,LKe),e(ks,BKe),e(ks,Ok),e(Ok,xKe),e(ks,kKe),e(ks,Xk),e(Xk,RKe),e(ks,SKe),e(E,PKe),e(E,Rs),e(Rs,nY),e(nY,$Ke),e(Rs,IKe),e(Rs,Vk),e(Vk,NKe),e(Rs,DKe),e(Rs,zk),e(zk,jKe),e(Rs,qKe),e(E,GKe),e(E,rh),e(rh,sY),e(sY,OKe),e(rh,XKe),e(rh,Wk),e(Wk,VKe),e(rh,zKe),e(E,WKe),e(E,th),e(th,lY),e(lY,QKe),e(th,HKe),e(th,Qk),e(Qk,UKe),e(th,JKe),e(E,YKe),e(E,Ss),e(Ss,iY),e(iY,KKe),e(Ss,ZKe),e(Ss,Hk),e(Hk,eZe),e(Ss,oZe),e(Ss,Uk),e(Uk,rZe),e(Ss,tZe),e(E,aZe),e(E,Ps),e(Ps,dY),e(dY,nZe),e(Ps,sZe),e(Ps,Jk),e(Jk,lZe),e(Ps,iZe),e(Ps,Yk),e(Yk,dZe),e(Ps,cZe),e(E,fZe),e(E,$s),e($s,cY),e(cY,mZe),e($s,gZe),e($s,Kk),e(Kk,hZe),e($s,pZe),e($s,Zk),e(Zk,_Ze),e($s,uZe),e(E,bZe),e(E,ah),e(ah,fY),e(fY,vZe),e(ah,TZe),e(ah,eR),e(eR,FZe),e(ah,CZe),e(E,MZe),e(E,nh),e(nh,mY),e(mY,EZe),e(nh,yZe),e(nh,oR),e(oR,wZe),e(nh,AZe),e(E,LZe),e(E,sh),e(sh,gY),e(gY,BZe),e(sh,xZe),e(sh,rR),e(rR,kZe),e(sh,RZe),e(E,SZe),e(E,lh),e(lh,hY),e(hY,PZe),e(lh,$Ze),e(lh,tR),e(tR,IZe),e(lh,NZe),e(E,DZe),e(E,Is),e(Is,pY),e(pY,jZe),e(Is,qZe),e(Is,aR),e(aR,GZe),e(Is,OZe),e(Is,nR),e(nR,XZe),e(Is,VZe),e(E,zZe),e(E,ih),e(ih,_Y),e(_Y,WZe),e(ih,QZe),e(ih,sR),e(sR,HZe),e(ih,UZe),e(E,JZe),e(E,dh),e(dh,uY),e(uY,YZe),e(dh,KZe),e(dh,lR),e(lR,ZZe),e(dh,eeo),e(E,oeo),e(E,Ns),e(Ns,bY),e(bY,reo),e(Ns,teo),e(Ns,iR),e(iR,aeo),e(Ns,neo),e(Ns,dR),e(dR,seo),e(Ns,leo),e(E,ieo),e(E,Ds),e(Ds,vY),e(vY,deo),e(Ds,ceo),e(Ds,cR),e(cR,feo),e(Ds,meo),e(Ds,fR),e(fR,geo),e(Ds,heo),e(go,peo),e(go,TY),e(TY,_eo),e(go,ueo),g(y3,go,null),e(Qo,beo),e(Qo,ch),g(w3,ch,null),e(ch,veo),e(ch,FY),e(FY,Teo),b(c,uke,u),b(c,Qi,u),e(Qi,fh),e(fh,CY),g(A3,CY,null),e(Qi,Feo),e(Qi,MY),e(MY,Ceo),b(c,bke,u),b(c,Ho,u),g(L3,Ho,null),e(Ho,Meo),e(Ho,B3),e(B3,Eeo),e(B3,mR),e(mR,yeo),e(B3,weo),e(Ho,Aeo),e(Ho,x3),e(x3,Leo),e(x3,EY),e(EY,Beo),e(x3,xeo),e(Ho,keo),e(Ho,$e),g(k3,$e,null),e($e,Reo),e($e,yY),e(yY,Seo),e($e,Peo),e($e,Xa),e(Xa,$eo),e(Xa,wY),e(wY,Ieo),e(Xa,Neo),e(Xa,AY),e(AY,Deo),e(Xa,jeo),e(Xa,LY),e(LY,qeo),e(Xa,Geo),e($e,Oeo),e($e,re),e(re,mh),e(mh,BY),e(BY,Xeo),e(mh,Veo),e(mh,gR),e(gR,zeo),e(mh,Weo),e(re,Qeo),e(re,gh),e(gh,xY),e(xY,Heo),e(gh,Ueo),e(gh,hR),e(hR,Jeo),e(gh,Yeo),e(re,Keo),e(re,hh),e(hh,kY),e(kY,Zeo),e(hh,eoo),e(hh,pR),e(pR,ooo),e(hh,roo),e(re,too),e(re,ph),e(ph,RY),e(RY,aoo),e(ph,noo),e(ph,_R),e(_R,soo),e(ph,loo),e(re,ioo),e(re,_h),e(_h,SY),e(SY,doo),e(_h,coo),e(_h,uR),e(uR,foo),e(_h,moo),e(re,goo),e(re,uh),e(uh,PY),e(PY,hoo),e(uh,poo),e(uh,bR),e(bR,_oo),e(uh,uoo),e(re,boo),e(re,bh),e(bh,$Y),e($Y,voo),e(bh,Too),e(bh,vR),e(vR,Foo),e(bh,Coo),e(re,Moo),e(re,vh),e(vh,IY),e(IY,Eoo),e(vh,yoo),e(vh,TR),e(TR,woo),e(vh,Aoo),e(re,Loo),e(re,Th),e(Th,NY),e(NY,Boo),e(Th,xoo),e(Th,FR),e(FR,koo),e(Th,Roo),e(re,Soo),e(re,Fh),e(Fh,DY),e(DY,Poo),e(Fh,$oo),e(Fh,CR),e(CR,Ioo),e(Fh,Noo),e(re,Doo),e(re,Ch),e(Ch,jY),e(jY,joo),e(Ch,qoo),e(Ch,MR),e(MR,Goo),e(Ch,Ooo),e(re,Xoo),e(re,Mh),e(Mh,qY),e(qY,Voo),e(Mh,zoo),e(Mh,ER),e(ER,Woo),e(Mh,Qoo),e(re,Hoo),e(re,Eh),e(Eh,GY),e(GY,Uoo),e(Eh,Joo),e(Eh,yR),e(yR,Yoo),e(Eh,Koo),e(re,Zoo),e(re,yh),e(yh,OY),e(OY,ero),e(yh,oro),e(yh,wR),e(wR,rro),e(yh,tro),e(re,aro),e(re,wh),e(wh,XY),e(XY,nro),e(wh,sro),e(wh,AR),e(AR,lro),e(wh,iro),e(re,dro),e(re,Ah),e(Ah,VY),e(VY,cro),e(Ah,fro),e(Ah,LR),e(LR,mro),e(Ah,gro),e(re,hro),e(re,Lh),e(Lh,zY),e(zY,pro),e(Lh,_ro),e(Lh,BR),e(BR,uro),e(Lh,bro),e(re,vro),e(re,Bh),e(Bh,WY),e(WY,Tro),e(Bh,Fro),e(Bh,xR),e(xR,Cro),e(Bh,Mro),e($e,Ero),g(xh,$e,null),e($e,yro),e($e,QY),e(QY,wro),e($e,Aro),g(R3,$e,null),e(Ho,Lro),e(Ho,kh),g(S3,kh,null),e(kh,Bro),e(kh,HY),e(HY,xro),b(c,vke,u),b(c,Hi,u),e(Hi,Rh),e(Rh,UY),g(P3,UY,null),e(Hi,kro),e(Hi,JY),e(JY,Rro),b(c,Tke,u),b(c,Uo,u),g($3,Uo,null),e(Uo,Sro),e(Uo,I3),e(I3,Pro),e(I3,kR),e(kR,$ro),e(I3,Iro),e(Uo,Nro),e(Uo,N3),e(N3,Dro),e(N3,YY),e(YY,jro),e(N3,qro),e(Uo,Gro),e(Uo,Ie),g(D3,Ie,null),e(Ie,Oro),e(Ie,KY),e(KY,Xro),e(Ie,Vro),e(Ie,Ui),e(Ui,zro),e(Ui,ZY),e(ZY,Wro),e(Ui,Qro),e(Ui,eK),e(eK,Hro),e(Ui,Uro),e(Ie,Jro),e(Ie,xe),e(xe,Sh),e(Sh,oK),e(oK,Yro),e(Sh,Kro),e(Sh,RR),e(RR,Zro),e(Sh,eto),e(xe,oto),e(xe,Ph),e(Ph,rK),e(rK,rto),e(Ph,tto),e(Ph,SR),e(SR,ato),e(Ph,nto),e(xe,sto),e(xe,$h),e($h,tK),e(tK,lto),e($h,ito),e($h,PR),e(PR,dto),e($h,cto),e(xe,fto),e(xe,Ih),e(Ih,aK),e(aK,mto),e(Ih,gto),e(Ih,$R),e($R,hto),e(Ih,pto),e(xe,_to),e(xe,Nh),e(Nh,nK),e(nK,uto),e(Nh,bto),e(Nh,IR),e(IR,vto),e(Nh,Tto),e(xe,Fto),e(xe,Dh),e(Dh,sK),e(sK,Cto),e(Dh,Mto),e(Dh,NR),e(NR,Eto),e(Dh,yto),e(xe,wto),e(xe,jh),e(jh,lK),e(lK,Ato),e(jh,Lto),e(jh,DR),e(DR,Bto),e(jh,xto),e(xe,kto),e(xe,qh),e(qh,iK),e(iK,Rto),e(qh,Sto),e(qh,jR),e(jR,Pto),e(qh,$to),e(Ie,Ito),g(Gh,Ie,null),e(Ie,Nto),e(Ie,dK),e(dK,Dto),e(Ie,jto),g(j3,Ie,null),e(Uo,qto),e(Uo,Oh),g(q3,Oh,null),e(Oh,Gto),e(Oh,cK),e(cK,Oto),b(c,Fke,u),b(c,Ji,u),e(Ji,Xh),e(Xh,fK),g(G3,fK,null),e(Ji,Xto),e(Ji,mK),e(mK,Vto),b(c,Cke,u),b(c,Jo,u),g(O3,Jo,null),e(Jo,zto),e(Jo,Yi),e(Yi,Wto),e(Yi,gK),e(gK,Qto),e(Yi,Hto),e(Yi,hK),e(hK,Uto),e(Yi,Jto),e(Jo,Yto),e(Jo,X3),e(X3,Kto),e(X3,pK),e(pK,Zto),e(X3,eao),e(Jo,oao),e(Jo,Vr),g(V3,Vr,null),e(Vr,rao),e(Vr,_K),e(_K,tao),e(Vr,aao),e(Vr,Ki),e(Ki,nao),e(Ki,uK),e(uK,sao),e(Ki,lao),e(Ki,bK),e(bK,iao),e(Ki,dao),e(Vr,cao),e(Vr,vK),e(vK,fao),e(Vr,mao),g(z3,Vr,null),e(Jo,gao),e(Jo,Ne),g(W3,Ne,null),e(Ne,hao),e(Ne,TK),e(TK,pao),e(Ne,_ao),e(Ne,Va),e(Va,uao),e(Va,FK),e(FK,bao),e(Va,vao),e(Va,CK),e(CK,Tao),e(Va,Fao),e(Va,MK),e(MK,Cao),e(Va,Mao),e(Ne,Eao),e(Ne,F),e(F,Vh),e(Vh,EK),e(EK,yao),e(Vh,wao),e(Vh,qR),e(qR,Aao),e(Vh,Lao),e(F,Bao),e(F,zh),e(zh,yK),e(yK,xao),e(zh,kao),e(zh,GR),e(GR,Rao),e(zh,Sao),e(F,Pao),e(F,Wh),e(Wh,wK),e(wK,$ao),e(Wh,Iao),e(Wh,OR),e(OR,Nao),e(Wh,Dao),e(F,jao),e(F,Qh),e(Qh,AK),e(AK,qao),e(Qh,Gao),e(Qh,XR),e(XR,Oao),e(Qh,Xao),e(F,Vao),e(F,Hh),e(Hh,LK),e(LK,zao),e(Hh,Wao),e(Hh,VR),e(VR,Qao),e(Hh,Hao),e(F,Uao),e(F,Uh),e(Uh,BK),e(BK,Jao),e(Uh,Yao),e(Uh,zR),e(zR,Kao),e(Uh,Zao),e(F,eno),e(F,Jh),e(Jh,xK),e(xK,ono),e(Jh,rno),e(Jh,WR),e(WR,tno),e(Jh,ano),e(F,nno),e(F,Yh),e(Yh,kK),e(kK,sno),e(Yh,lno),e(Yh,QR),e(QR,ino),e(Yh,dno),e(F,cno),e(F,Kh),e(Kh,RK),e(RK,fno),e(Kh,mno),e(Kh,HR),e(HR,gno),e(Kh,hno),e(F,pno),e(F,Zh),e(Zh,SK),e(SK,_no),e(Zh,uno),e(Zh,UR),e(UR,bno),e(Zh,vno),e(F,Tno),e(F,ep),e(ep,PK),e(PK,Fno),e(ep,Cno),e(ep,JR),e(JR,Mno),e(ep,Eno),e(F,yno),e(F,op),e(op,$K),e($K,wno),e(op,Ano),e(op,YR),e(YR,Lno),e(op,Bno),e(F,xno),e(F,rp),e(rp,IK),e(IK,kno),e(rp,Rno),e(rp,KR),e(KR,Sno),e(rp,Pno),e(F,$no),e(F,tp),e(tp,NK),e(NK,Ino),e(tp,Nno),e(tp,ZR),e(ZR,Dno),e(tp,jno),e(F,qno),e(F,ap),e(ap,DK),e(DK,Gno),e(ap,Ono),e(ap,eS),e(eS,Xno),e(ap,Vno),e(F,zno),e(F,np),e(np,jK),e(jK,Wno),e(np,Qno),e(np,oS),e(oS,Hno),e(np,Uno),e(F,Jno),e(F,sp),e(sp,qK),e(qK,Yno),e(sp,Kno),e(sp,rS),e(rS,Zno),e(sp,eso),e(F,oso),e(F,lp),e(lp,GK),e(GK,rso),e(lp,tso),e(lp,tS),e(tS,aso),e(lp,nso),e(F,sso),e(F,ip),e(ip,OK),e(OK,lso),e(ip,iso),e(ip,aS),e(aS,dso),e(ip,cso),e(F,fso),e(F,dp),e(dp,XK),e(XK,mso),e(dp,gso),e(dp,nS),e(nS,hso),e(dp,pso),e(F,_so),e(F,cp),e(cp,VK),e(VK,uso),e(cp,bso),e(cp,sS),e(sS,vso),e(cp,Tso),e(F,Fso),e(F,fp),e(fp,zK),e(zK,Cso),e(fp,Mso),e(fp,lS),e(lS,Eso),e(fp,yso),e(F,wso),e(F,mp),e(mp,WK),e(WK,Aso),e(mp,Lso),e(mp,iS),e(iS,Bso),e(mp,xso),e(F,kso),e(F,gp),e(gp,QK),e(QK,Rso),e(gp,Sso),e(gp,dS),e(dS,Pso),e(gp,$so),e(F,Iso),e(F,hp),e(hp,HK),e(HK,Nso),e(hp,Dso),e(hp,cS),e(cS,jso),e(hp,qso),e(F,Gso),e(F,pp),e(pp,UK),e(UK,Oso),e(pp,Xso),e(pp,fS),e(fS,Vso),e(pp,zso),e(F,Wso),e(F,_p),e(_p,JK),e(JK,Qso),e(_p,Hso),e(_p,mS),e(mS,Uso),e(_p,Jso),e(F,Yso),e(F,up),e(up,YK),e(YK,Kso),e(up,Zso),e(up,gS),e(gS,elo),e(up,olo),e(F,rlo),e(F,js),e(js,KK),e(KK,tlo),e(js,alo),e(js,hS),e(hS,nlo),e(js,slo),e(js,pS),e(pS,llo),e(js,ilo),e(F,dlo),e(F,bp),e(bp,ZK),e(ZK,clo),e(bp,flo),e(bp,_S),e(_S,mlo),e(bp,glo),e(F,hlo),e(F,vp),e(vp,eZ),e(eZ,plo),e(vp,_lo),e(vp,uS),e(uS,ulo),e(vp,blo),e(F,vlo),e(F,Tp),e(Tp,oZ),e(oZ,Tlo),e(Tp,Flo),e(Tp,bS),e(bS,Clo),e(Tp,Mlo),e(F,Elo),e(F,Fp),e(Fp,rZ),e(rZ,ylo),e(Fp,wlo),e(Fp,vS),e(vS,Alo),e(Fp,Llo),e(F,Blo),e(F,Cp),e(Cp,tZ),e(tZ,xlo),e(Cp,klo),e(Cp,TS),e(TS,Rlo),e(Cp,Slo),e(F,Plo),e(F,Mp),e(Mp,aZ),e(aZ,$lo),e(Mp,Ilo),e(Mp,FS),e(FS,Nlo),e(Mp,Dlo),e(F,jlo),e(F,Ep),e(Ep,nZ),e(nZ,qlo),e(Ep,Glo),e(Ep,CS),e(CS,Olo),e(Ep,Xlo),e(F,Vlo),e(F,yp),e(yp,sZ),e(sZ,zlo),e(yp,Wlo),e(yp,MS),e(MS,Qlo),e(yp,Hlo),e(F,Ulo),e(F,wp),e(wp,lZ),e(lZ,Jlo),e(wp,Ylo),e(wp,ES),e(ES,Klo),e(wp,Zlo),e(F,eio),e(F,Ap),e(Ap,iZ),e(iZ,oio),e(Ap,rio),e(Ap,yS),e(yS,tio),e(Ap,aio),e(F,nio),e(F,Lp),e(Lp,dZ),e(dZ,sio),e(Lp,lio),e(Lp,wS),e(wS,iio),e(Lp,dio),e(F,cio),e(F,Bp),e(Bp,cZ),e(cZ,fio),e(Bp,mio),e(Bp,AS),e(AS,gio),e(Bp,hio),e(F,pio),e(F,xp),e(xp,fZ),e(fZ,_io),e(xp,uio),e(xp,LS),e(LS,bio),e(xp,vio),e(F,Tio),e(F,kp),e(kp,mZ),e(mZ,Fio),e(kp,Cio),e(kp,BS),e(BS,Mio),e(kp,Eio),e(F,yio),e(F,Rp),e(Rp,gZ),e(gZ,wio),e(Rp,Aio),e(Rp,xS),e(xS,Lio),e(Rp,Bio),e(F,xio),e(F,Sp),e(Sp,hZ),e(hZ,kio),e(Sp,Rio),e(Sp,kS),e(kS,Sio),e(Sp,Pio),e(F,$io),e(F,Pp),e(Pp,pZ),e(pZ,Iio),e(Pp,Nio),e(Pp,RS),e(RS,Dio),e(Pp,jio),e(F,qio),e(F,$p),e($p,_Z),e(_Z,Gio),e($p,Oio),e($p,SS),e(SS,Xio),e($p,Vio),e(F,zio),e(F,Ip),e(Ip,uZ),e(uZ,Wio),e(Ip,Qio),e(Ip,PS),e(PS,Hio),e(Ip,Uio),e(F,Jio),e(F,Np),e(Np,bZ),e(bZ,Yio),e(Np,Kio),e(Np,$S),e($S,Zio),e(Np,edo),e(F,odo),e(F,Dp),e(Dp,vZ),e(vZ,rdo),e(Dp,tdo),e(Dp,IS),e(IS,ado),e(Dp,ndo),e(F,sdo),e(F,jp),e(jp,TZ),e(TZ,ldo),e(jp,ido),e(jp,NS),e(NS,ddo),e(jp,cdo),e(F,fdo),e(F,qp),e(qp,FZ),e(FZ,mdo),e(qp,gdo),e(qp,DS),e(DS,hdo),e(qp,pdo),e(F,_do),e(F,Gp),e(Gp,CZ),e(CZ,udo),e(Gp,bdo),e(Gp,jS),e(jS,vdo),e(Gp,Tdo),e(F,Fdo),e(F,Op),e(Op,MZ),e(MZ,Cdo),e(Op,Mdo),e(Op,qS),e(qS,Edo),e(Op,ydo),e(F,wdo),e(F,Xp),e(Xp,EZ),e(EZ,Ado),e(Xp,Ldo),e(Xp,GS),e(GS,Bdo),e(Xp,xdo),e(F,kdo),e(F,Vp),e(Vp,yZ),e(yZ,Rdo),e(Vp,Sdo),e(Vp,OS),e(OS,Pdo),e(Vp,$do),e(F,Ido),e(F,zp),e(zp,wZ),e(wZ,Ndo),e(zp,Ddo),e(zp,XS),e(XS,jdo),e(zp,qdo),e(F,Gdo),e(F,Wp),e(Wp,AZ),e(AZ,Odo),e(Wp,Xdo),e(Wp,VS),e(VS,Vdo),e(Wp,zdo),e(F,Wdo),e(F,Qp),e(Qp,LZ),e(LZ,Qdo),e(Qp,Hdo),e(Qp,zS),e(zS,Udo),e(Qp,Jdo),e(F,Ydo),e(F,Hp),e(Hp,BZ),e(BZ,Kdo),e(Hp,Zdo),e(Hp,WS),e(WS,eco),e(Hp,oco),e(F,rco),e(F,Up),e(Up,xZ),e(xZ,tco),e(Up,aco),e(Up,QS),e(QS,nco),e(Up,sco),e(F,lco),e(F,Jp),e(Jp,kZ),e(kZ,ico),e(Jp,dco),e(Jp,HS),e(HS,cco),e(Jp,fco),e(F,mco),e(F,Yp),e(Yp,RZ),e(RZ,gco),e(Yp,hco),e(Yp,US),e(US,pco),e(Yp,_co),e(F,uco),e(F,Kp),e(Kp,SZ),e(SZ,bco),e(Kp,vco),e(Kp,JS),e(JS,Tco),e(Kp,Fco),e(F,Cco),e(F,Zp),e(Zp,PZ),e(PZ,Mco),e(Zp,Eco),e(Zp,YS),e(YS,yco),e(Zp,wco),e(F,Aco),e(F,e_),e(e_,$Z),e($Z,Lco),e(e_,Bco),e(e_,KS),e(KS,xco),e(e_,kco),e(F,Rco),e(F,o_),e(o_,IZ),e(IZ,Sco),e(o_,Pco),e(o_,ZS),e(ZS,$co),e(o_,Ico),e(F,Nco),e(F,r_),e(r_,NZ),e(NZ,Dco),e(r_,jco),e(r_,eP),e(eP,qco),e(r_,Gco),e(F,Oco),e(F,t_),e(t_,DZ),e(DZ,Xco),e(t_,Vco),e(t_,oP),e(oP,zco),e(t_,Wco),e(F,Qco),e(F,a_),e(a_,jZ),e(jZ,Hco),e(a_,Uco),e(a_,rP),e(rP,Jco),e(a_,Yco),e(F,Kco),e(F,n_),e(n_,qZ),e(qZ,Zco),e(n_,efo),e(n_,tP),e(tP,ofo),e(n_,rfo),e(F,tfo),e(F,s_),e(s_,GZ),e(GZ,afo),e(s_,nfo),e(s_,aP),e(aP,sfo),e(s_,lfo),e(F,ifo),e(F,l_),e(l_,OZ),e(OZ,dfo),e(l_,cfo),e(l_,nP),e(nP,ffo),e(l_,mfo),e(F,gfo),e(F,i_),e(i_,XZ),e(XZ,hfo),e(i_,pfo),e(i_,sP),e(sP,_fo),e(i_,ufo),e(F,bfo),e(F,d_),e(d_,VZ),e(VZ,vfo),e(d_,Tfo),e(d_,lP),e(lP,Ffo),e(d_,Cfo),e(F,Mfo),e(F,c_),e(c_,zZ),e(zZ,Efo),e(c_,yfo),e(c_,iP),e(iP,wfo),e(c_,Afo),e(F,Lfo),e(F,f_),e(f_,WZ),e(WZ,Bfo),e(f_,xfo),e(f_,dP),e(dP,kfo),e(f_,Rfo),e(F,Sfo),e(F,m_),e(m_,QZ),e(QZ,Pfo),e(m_,$fo),e(m_,cP),e(cP,Ifo),e(m_,Nfo),e(F,Dfo),e(F,g_),e(g_,HZ),e(HZ,jfo),e(g_,qfo),e(g_,fP),e(fP,Gfo),e(g_,Ofo),e(F,Xfo),e(F,h_),e(h_,UZ),e(UZ,Vfo),e(h_,zfo),e(h_,mP),e(mP,Wfo),e(h_,Qfo),e(F,Hfo),e(F,p_),e(p_,JZ),e(JZ,Ufo),e(p_,Jfo),e(p_,gP),e(gP,Yfo),e(p_,Kfo),e(F,Zfo),e(F,__),e(__,YZ),e(YZ,emo),e(__,omo),e(__,hP),e(hP,rmo),e(__,tmo),e(F,amo),e(F,u_),e(u_,KZ),e(KZ,nmo),e(u_,smo),e(u_,pP),e(pP,lmo),e(u_,imo),e(F,dmo),e(F,b_),e(b_,ZZ),e(ZZ,cmo),e(b_,fmo),e(b_,_P),e(_P,mmo),e(b_,gmo),e(F,hmo),e(F,v_),e(v_,eee),e(eee,pmo),e(v_,_mo),e(v_,uP),e(uP,umo),e(v_,bmo),e(F,vmo),e(F,T_),e(T_,oee),e(oee,Tmo),e(T_,Fmo),e(T_,bP),e(bP,Cmo),e(T_,Mmo),e(F,Emo),e(F,F_),e(F_,ree),e(ree,ymo),e(F_,wmo),e(F_,vP),e(vP,Amo),e(F_,Lmo),e(F,Bmo),e(F,C_),e(C_,tee),e(tee,xmo),e(C_,kmo),e(C_,TP),e(TP,Rmo),e(C_,Smo),e(F,Pmo),e(F,M_),e(M_,aee),e(aee,$mo),e(M_,Imo),e(M_,FP),e(FP,Nmo),e(M_,Dmo),e(F,jmo),e(F,E_),e(E_,nee),e(nee,qmo),e(E_,Gmo),e(E_,CP),e(CP,Omo),e(E_,Xmo),e(F,Vmo),e(F,y_),e(y_,see),e(see,zmo),e(y_,Wmo),e(y_,MP),e(MP,Qmo),e(y_,Hmo),e(Ne,Umo),e(Ne,w_),e(w_,Jmo),e(w_,lee),e(lee,Ymo),e(w_,Kmo),e(w_,iee),e(iee,Zmo),e(Ne,ego),e(Ne,dee),e(dee,ogo),e(Ne,rgo),g(Q3,Ne,null),b(c,Mke,u),b(c,Zi,u),e(Zi,A_),e(A_,cee),g(H3,cee,null),e(Zi,tgo),e(Zi,fee),e(fee,ago),b(c,Eke,u),b(c,Yo,u),g(U3,Yo,null),e(Yo,ngo),e(Yo,ed),e(ed,sgo),e(ed,mee),e(mee,lgo),e(ed,igo),e(ed,gee),e(gee,dgo),e(ed,cgo),e(Yo,fgo),e(Yo,J3),e(J3,mgo),e(J3,hee),e(hee,ggo),e(J3,hgo),e(Yo,pgo),e(Yo,zr),g(Y3,zr,null),e(zr,_go),e(zr,pee),e(pee,ugo),e(zr,bgo),e(zr,od),e(od,vgo),e(od,_ee),e(_ee,Tgo),e(od,Fgo),e(od,uee),e(uee,Cgo),e(od,Mgo),e(zr,Ego),e(zr,bee),e(bee,ygo),e(zr,wgo),g(K3,zr,null),e(Yo,Ago),e(Yo,De),g(Z3,De,null),e(De,Lgo),e(De,vee),e(vee,Bgo),e(De,xgo),e(De,za),e(za,kgo),e(za,Tee),e(Tee,Rgo),e(za,Sgo),e(za,Fee),e(Fee,Pgo),e(za,$go),e(za,Cee),e(Cee,Igo),e(za,Ngo),e(De,Dgo),e(De,k),e(k,L_),e(L_,Mee),e(Mee,jgo),e(L_,qgo),e(L_,EP),e(EP,Ggo),e(L_,Ogo),e(k,Xgo),e(k,B_),e(B_,Eee),e(Eee,Vgo),e(B_,zgo),e(B_,yP),e(yP,Wgo),e(B_,Qgo),e(k,Hgo),e(k,x_),e(x_,yee),e(yee,Ugo),e(x_,Jgo),e(x_,wP),e(wP,Ygo),e(x_,Kgo),e(k,Zgo),e(k,k_),e(k_,wee),e(wee,eho),e(k_,oho),e(k_,AP),e(AP,rho),e(k_,tho),e(k,aho),e(k,R_),e(R_,Aee),e(Aee,nho),e(R_,sho),e(R_,LP),e(LP,lho),e(R_,iho),e(k,dho),e(k,S_),e(S_,Lee),e(Lee,cho),e(S_,fho),e(S_,BP),e(BP,mho),e(S_,gho),e(k,hho),e(k,P_),e(P_,Bee),e(Bee,pho),e(P_,_ho),e(P_,xP),e(xP,uho),e(P_,bho),e(k,vho),e(k,$_),e($_,xee),e(xee,Tho),e($_,Fho),e($_,kP),e(kP,Cho),e($_,Mho),e(k,Eho),e(k,I_),e(I_,kee),e(kee,yho),e(I_,who),e(I_,RP),e(RP,Aho),e(I_,Lho),e(k,Bho),e(k,N_),e(N_,Ree),e(Ree,xho),e(N_,kho),e(N_,SP),e(SP,Rho),e(N_,Sho),e(k,Pho),e(k,D_),e(D_,See),e(See,$ho),e(D_,Iho),e(D_,PP),e(PP,Nho),e(D_,Dho),e(k,jho),e(k,j_),e(j_,Pee),e(Pee,qho),e(j_,Gho),e(j_,$P),e($P,Oho),e(j_,Xho),e(k,Vho),e(k,q_),e(q_,$ee),e($ee,zho),e(q_,Who),e(q_,IP),e(IP,Qho),e(q_,Hho),e(k,Uho),e(k,G_),e(G_,Iee),e(Iee,Jho),e(G_,Yho),e(G_,NP),e(NP,Kho),e(G_,Zho),e(k,epo),e(k,O_),e(O_,Nee),e(Nee,opo),e(O_,rpo),e(O_,DP),e(DP,tpo),e(O_,apo),e(k,npo),e(k,X_),e(X_,Dee),e(Dee,spo),e(X_,lpo),e(X_,jP),e(jP,ipo),e(X_,dpo),e(k,cpo),e(k,V_),e(V_,jee),e(jee,fpo),e(V_,mpo),e(V_,qP),e(qP,gpo),e(V_,hpo),e(k,ppo),e(k,z_),e(z_,qee),e(qee,_po),e(z_,upo),e(z_,GP),e(GP,bpo),e(z_,vpo),e(k,Tpo),e(k,W_),e(W_,Gee),e(Gee,Fpo),e(W_,Cpo),e(W_,OP),e(OP,Mpo),e(W_,Epo),e(k,ypo),e(k,Q_),e(Q_,Oee),e(Oee,wpo),e(Q_,Apo),e(Q_,XP),e(XP,Lpo),e(Q_,Bpo),e(k,xpo),e(k,H_),e(H_,Xee),e(Xee,kpo),e(H_,Rpo),e(H_,VP),e(VP,Spo),e(H_,Ppo),e(k,$po),e(k,U_),e(U_,Vee),e(Vee,Ipo),e(U_,Npo),e(U_,zP),e(zP,Dpo),e(U_,jpo),e(k,qpo),e(k,J_),e(J_,zee),e(zee,Gpo),e(J_,Opo),e(J_,WP),e(WP,Xpo),e(J_,Vpo),e(k,zpo),e(k,Y_),e(Y_,Wee),e(Wee,Wpo),e(Y_,Qpo),e(Y_,QP),e(QP,Hpo),e(Y_,Upo),e(k,Jpo),e(k,K_),e(K_,Qee),e(Qee,Ypo),e(K_,Kpo),e(K_,HP),e(HP,Zpo),e(K_,e_o),e(k,o_o),e(k,Z_),e(Z_,Hee),e(Hee,r_o),e(Z_,t_o),e(Z_,UP),e(UP,a_o),e(Z_,n_o),e(k,s_o),e(k,eu),e(eu,Uee),e(Uee,l_o),e(eu,i_o),e(eu,JP),e(JP,d_o),e(eu,c_o),e(k,f_o),e(k,ou),e(ou,Jee),e(Jee,m_o),e(ou,g_o),e(ou,YP),e(YP,h_o),e(ou,p_o),e(k,__o),e(k,ru),e(ru,Yee),e(Yee,u_o),e(ru,b_o),e(ru,KP),e(KP,v_o),e(ru,T_o),e(k,F_o),e(k,tu),e(tu,Kee),e(Kee,C_o),e(tu,M_o),e(tu,ZP),e(ZP,E_o),e(tu,y_o),e(k,w_o),e(k,au),e(au,Zee),e(Zee,A_o),e(au,L_o),e(au,e$),e(e$,B_o),e(au,x_o),e(k,k_o),e(k,nu),e(nu,eoe),e(eoe,R_o),e(nu,S_o),e(nu,o$),e(o$,P_o),e(nu,$_o),e(k,I_o),e(k,su),e(su,ooe),e(ooe,N_o),e(su,D_o),e(su,r$),e(r$,j_o),e(su,q_o),e(k,G_o),e(k,lu),e(lu,roe),e(roe,O_o),e(lu,X_o),e(lu,t$),e(t$,V_o),e(lu,z_o),e(k,W_o),e(k,iu),e(iu,toe),e(toe,Q_o),e(iu,H_o),e(iu,a$),e(a$,U_o),e(iu,J_o),e(k,Y_o),e(k,du),e(du,aoe),e(aoe,K_o),e(du,Z_o),e(du,n$),e(n$,euo),e(du,ouo),e(k,ruo),e(k,cu),e(cu,noe),e(noe,tuo),e(cu,auo),e(cu,s$),e(s$,nuo),e(cu,suo),e(k,luo),e(k,fu),e(fu,soe),e(soe,iuo),e(fu,duo),e(fu,l$),e(l$,cuo),e(fu,fuo),e(k,muo),e(k,mu),e(mu,loe),e(loe,guo),e(mu,huo),e(mu,i$),e(i$,puo),e(mu,_uo),e(De,uuo),e(De,gu),e(gu,buo),e(gu,ioe),e(ioe,vuo),e(gu,Tuo),e(gu,doe),e(doe,Fuo),e(De,Cuo),e(De,coe),e(coe,Muo),e(De,Euo),g(ey,De,null),b(c,yke,u),b(c,rd,u),e(rd,hu),e(hu,foe),g(oy,foe,null),e(rd,yuo),e(rd,moe),e(moe,wuo),b(c,wke,u),b(c,Ko,u),g(ry,Ko,null),e(Ko,Auo),e(Ko,td),e(td,Luo),e(td,goe),e(goe,Buo),e(td,xuo),e(td,hoe),e(hoe,kuo),e(td,Ruo),e(Ko,Suo),e(Ko,ty),e(ty,Puo),e(ty,poe),e(poe,$uo),e(ty,Iuo),e(Ko,Nuo),e(Ko,Wr),g(ay,Wr,null),e(Wr,Duo),e(Wr,_oe),e(_oe,juo),e(Wr,quo),e(Wr,ad),e(ad,Guo),e(ad,uoe),e(uoe,Ouo),e(ad,Xuo),e(ad,boe),e(boe,Vuo),e(ad,zuo),e(Wr,Wuo),e(Wr,voe),e(voe,Quo),e(Wr,Huo),g(ny,Wr,null),e(Ko,Uuo),e(Ko,je),g(sy,je,null),e(je,Juo),e(je,Toe),e(Toe,Yuo),e(je,Kuo),e(je,Wa),e(Wa,Zuo),e(Wa,Foe),e(Foe,e5o),e(Wa,o5o),e(Wa,Coe),e(Coe,r5o),e(Wa,t5o),e(Wa,Moe),e(Moe,a5o),e(Wa,n5o),e(je,s5o),e(je,$),e($,pu),e(pu,Eoe),e(Eoe,l5o),e(pu,i5o),e(pu,d$),e(d$,d5o),e(pu,c5o),e($,f5o),e($,_u),e(_u,yoe),e(yoe,m5o),e(_u,g5o),e(_u,c$),e(c$,h5o),e(_u,p5o),e($,_5o),e($,uu),e(uu,woe),e(woe,u5o),e(uu,b5o),e(uu,f$),e(f$,v5o),e(uu,T5o),e($,F5o),e($,bu),e(bu,Aoe),e(Aoe,C5o),e(bu,M5o),e(bu,m$),e(m$,E5o),e(bu,y5o),e($,w5o),e($,vu),e(vu,Loe),e(Loe,A5o),e(vu,L5o),e(vu,g$),e(g$,B5o),e(vu,x5o),e($,k5o),e($,Tu),e(Tu,Boe),e(Boe,R5o),e(Tu,S5o),e(Tu,h$),e(h$,P5o),e(Tu,$5o),e($,I5o),e($,Fu),e(Fu,xoe),e(xoe,N5o),e(Fu,D5o),e(Fu,p$),e(p$,j5o),e(Fu,q5o),e($,G5o),e($,Cu),e(Cu,koe),e(koe,O5o),e(Cu,X5o),e(Cu,_$),e(_$,V5o),e(Cu,z5o),e($,W5o),e($,Mu),e(Mu,Roe),e(Roe,Q5o),e(Mu,H5o),e(Mu,u$),e(u$,U5o),e(Mu,J5o),e($,Y5o),e($,Eu),e(Eu,Soe),e(Soe,K5o),e(Eu,Z5o),e(Eu,b$),e(b$,e2o),e(Eu,o2o),e($,r2o),e($,yu),e(yu,Poe),e(Poe,t2o),e(yu,a2o),e(yu,v$),e(v$,n2o),e(yu,s2o),e($,l2o),e($,wu),e(wu,$oe),e($oe,i2o),e(wu,d2o),e(wu,T$),e(T$,c2o),e(wu,f2o),e($,m2o),e($,Au),e(Au,Ioe),e(Ioe,g2o),e(Au,h2o),e(Au,F$),e(F$,p2o),e(Au,_2o),e($,u2o),e($,Lu),e(Lu,Noe),e(Noe,b2o),e(Lu,v2o),e(Lu,C$),e(C$,T2o),e(Lu,F2o),e($,C2o),e($,Bu),e(Bu,Doe),e(Doe,M2o),e(Bu,E2o),e(Bu,M$),e(M$,y2o),e(Bu,w2o),e($,A2o),e($,xu),e(xu,joe),e(joe,L2o),e(xu,B2o),e(xu,E$),e(E$,x2o),e(xu,k2o),e($,R2o),e($,ku),e(ku,qoe),e(qoe,S2o),e(ku,P2o),e(ku,y$),e(y$,$2o),e(ku,I2o),e($,N2o),e($,Ru),e(Ru,Goe),e(Goe,D2o),e(Ru,j2o),e(Ru,w$),e(w$,q2o),e(Ru,G2o),e($,O2o),e($,Su),e(Su,Ooe),e(Ooe,X2o),e(Su,V2o),e(Su,A$),e(A$,z2o),e(Su,W2o),e($,Q2o),e($,Pu),e(Pu,Xoe),e(Xoe,H2o),e(Pu,U2o),e(Pu,L$),e(L$,J2o),e(Pu,Y2o),e($,K2o),e($,$u),e($u,Voe),e(Voe,Z2o),e($u,e1o),e($u,B$),e(B$,o1o),e($u,r1o),e($,t1o),e($,Iu),e(Iu,zoe),e(zoe,a1o),e(Iu,n1o),e(Iu,x$),e(x$,s1o),e(Iu,l1o),e($,i1o),e($,Nu),e(Nu,Woe),e(Woe,d1o),e(Nu,c1o),e(Nu,k$),e(k$,f1o),e(Nu,m1o),e($,g1o),e($,Du),e(Du,Qoe),e(Qoe,h1o),e(Du,p1o),e(Du,R$),e(R$,_1o),e(Du,u1o),e($,b1o),e($,ju),e(ju,Hoe),e(Hoe,v1o),e(ju,T1o),e(ju,S$),e(S$,F1o),e(ju,C1o),e($,M1o),e($,qu),e(qu,Uoe),e(Uoe,E1o),e(qu,y1o),e(qu,P$),e(P$,w1o),e(qu,A1o),e($,L1o),e($,Gu),e(Gu,Joe),e(Joe,B1o),e(Gu,x1o),e(Gu,$$),e($$,k1o),e(Gu,R1o),e($,S1o),e($,Ou),e(Ou,Yoe),e(Yoe,P1o),e(Ou,$1o),e(Ou,I$),e(I$,I1o),e(Ou,N1o),e($,D1o),e($,Xu),e(Xu,Koe),e(Koe,j1o),e(Xu,q1o),e(Xu,N$),e(N$,G1o),e(Xu,O1o),e($,X1o),e($,Vu),e(Vu,Zoe),e(Zoe,V1o),e(Vu,z1o),e(Vu,D$),e(D$,W1o),e(Vu,Q1o),e($,H1o),e($,zu),e(zu,ere),e(ere,U1o),e(zu,J1o),e(zu,j$),e(j$,Y1o),e(zu,K1o),e($,Z1o),e($,Wu),e(Wu,ore),e(ore,ebo),e(Wu,obo),e(Wu,q$),e(q$,rbo),e(Wu,tbo),e($,abo),e($,Qu),e(Qu,rre),e(rre,nbo),e(Qu,sbo),e(Qu,G$),e(G$,lbo),e(Qu,ibo),e($,dbo),e($,Hu),e(Hu,tre),e(tre,cbo),e(Hu,fbo),e(Hu,O$),e(O$,mbo),e(Hu,gbo),e($,hbo),e($,Uu),e(Uu,are),e(are,pbo),e(Uu,_bo),e(Uu,X$),e(X$,ubo),e(Uu,bbo),e(je,vbo),e(je,Ju),e(Ju,Tbo),e(Ju,nre),e(nre,Fbo),e(Ju,Cbo),e(Ju,sre),e(sre,Mbo),e(je,Ebo),e(je,lre),e(lre,ybo),e(je,wbo),g(ly,je,null),b(c,Ake,u),b(c,nd,u),e(nd,Yu),e(Yu,ire),g(iy,ire,null),e(nd,Abo),e(nd,dre),e(dre,Lbo),b(c,Lke,u),b(c,Zo,u),g(dy,Zo,null),e(Zo,Bbo),e(Zo,sd),e(sd,xbo),e(sd,cre),e(cre,kbo),e(sd,Rbo),e(sd,fre),e(fre,Sbo),e(sd,Pbo),e(Zo,$bo),e(Zo,cy),e(cy,Ibo),e(cy,mre),e(mre,Nbo),e(cy,Dbo),e(Zo,jbo),e(Zo,Qr),g(fy,Qr,null),e(Qr,qbo),e(Qr,gre),e(gre,Gbo),e(Qr,Obo),e(Qr,ld),e(ld,Xbo),e(ld,hre),e(hre,Vbo),e(ld,zbo),e(ld,pre),e(pre,Wbo),e(ld,Qbo),e(Qr,Hbo),e(Qr,_re),e(_re,Ubo),e(Qr,Jbo),g(my,Qr,null),e(Zo,Ybo),e(Zo,qe),g(gy,qe,null),e(qe,Kbo),e(qe,ure),e(ure,Zbo),e(qe,evo),e(qe,Qa),e(Qa,ovo),e(Qa,bre),e(bre,rvo),e(Qa,tvo),e(Qa,vre),e(vre,avo),e(Qa,nvo),e(Qa,Tre),e(Tre,svo),e(Qa,lvo),e(qe,ivo),e(qe,I),e(I,Ku),e(Ku,Fre),e(Fre,dvo),e(Ku,cvo),e(Ku,V$),e(V$,fvo),e(Ku,mvo),e(I,gvo),e(I,Zu),e(Zu,Cre),e(Cre,hvo),e(Zu,pvo),e(Zu,z$),e(z$,_vo),e(Zu,uvo),e(I,bvo),e(I,e5),e(e5,Mre),e(Mre,vvo),e(e5,Tvo),e(e5,W$),e(W$,Fvo),e(e5,Cvo),e(I,Mvo),e(I,o5),e(o5,Ere),e(Ere,Evo),e(o5,yvo),e(o5,Q$),e(Q$,wvo),e(o5,Avo),e(I,Lvo),e(I,r5),e(r5,yre),e(yre,Bvo),e(r5,xvo),e(r5,H$),e(H$,kvo),e(r5,Rvo),e(I,Svo),e(I,t5),e(t5,wre),e(wre,Pvo),e(t5,$vo),e(t5,U$),e(U$,Ivo),e(t5,Nvo),e(I,Dvo),e(I,a5),e(a5,Are),e(Are,jvo),e(a5,qvo),e(a5,J$),e(J$,Gvo),e(a5,Ovo),e(I,Xvo),e(I,n5),e(n5,Lre),e(Lre,Vvo),e(n5,zvo),e(n5,Y$),e(Y$,Wvo),e(n5,Qvo),e(I,Hvo),e(I,s5),e(s5,Bre),e(Bre,Uvo),e(s5,Jvo),e(s5,K$),e(K$,Yvo),e(s5,Kvo),e(I,Zvo),e(I,l5),e(l5,xre),e(xre,e6o),e(l5,o6o),e(l5,Z$),e(Z$,r6o),e(l5,t6o),e(I,a6o),e(I,i5),e(i5,kre),e(kre,n6o),e(i5,s6o),e(i5,eI),e(eI,l6o),e(i5,i6o),e(I,d6o),e(I,d5),e(d5,Rre),e(Rre,c6o),e(d5,f6o),e(d5,oI),e(oI,m6o),e(d5,g6o),e(I,h6o),e(I,c5),e(c5,Sre),e(Sre,p6o),e(c5,_6o),e(c5,rI),e(rI,u6o),e(c5,b6o),e(I,v6o),e(I,f5),e(f5,Pre),e(Pre,T6o),e(f5,F6o),e(f5,tI),e(tI,C6o),e(f5,M6o),e(I,E6o),e(I,m5),e(m5,$re),e($re,y6o),e(m5,w6o),e(m5,aI),e(aI,A6o),e(m5,L6o),e(I,B6o),e(I,g5),e(g5,Ire),e(Ire,x6o),e(g5,k6o),e(g5,nI),e(nI,R6o),e(g5,S6o),e(I,P6o),e(I,h5),e(h5,Nre),e(Nre,$6o),e(h5,I6o),e(h5,sI),e(sI,N6o),e(h5,D6o),e(I,j6o),e(I,p5),e(p5,Dre),e(Dre,q6o),e(p5,G6o),e(p5,lI),e(lI,O6o),e(p5,X6o),e(I,V6o),e(I,_5),e(_5,jre),e(jre,z6o),e(_5,W6o),e(_5,iI),e(iI,Q6o),e(_5,H6o),e(I,U6o),e(I,u5),e(u5,qre),e(qre,J6o),e(u5,Y6o),e(u5,dI),e(dI,K6o),e(u5,Z6o),e(I,eTo),e(I,b5),e(b5,Gre),e(Gre,oTo),e(b5,rTo),e(b5,cI),e(cI,tTo),e(b5,aTo),e(I,nTo),e(I,v5),e(v5,Ore),e(Ore,sTo),e(v5,lTo),e(v5,fI),e(fI,iTo),e(v5,dTo),e(I,cTo),e(I,T5),e(T5,Xre),e(Xre,fTo),e(T5,mTo),e(T5,mI),e(mI,gTo),e(T5,hTo),e(I,pTo),e(I,F5),e(F5,Vre),e(Vre,_To),e(F5,uTo),e(F5,gI),e(gI,bTo),e(F5,vTo),e(I,TTo),e(I,C5),e(C5,zre),e(zre,FTo),e(C5,CTo),e(C5,hI),e(hI,MTo),e(C5,ETo),e(I,yTo),e(I,M5),e(M5,Wre),e(Wre,wTo),e(M5,ATo),e(M5,pI),e(pI,LTo),e(M5,BTo),e(I,xTo),e(I,E5),e(E5,Qre),e(Qre,kTo),e(E5,RTo),e(E5,_I),e(_I,STo),e(E5,PTo),e(I,$To),e(I,y5),e(y5,Hre),e(Hre,ITo),e(y5,NTo),e(y5,uI),e(uI,DTo),e(y5,jTo),e(I,qTo),e(I,w5),e(w5,Ure),e(Ure,GTo),e(w5,OTo),e(w5,bI),e(bI,XTo),e(w5,VTo),e(I,zTo),e(I,A5),e(A5,Jre),e(Jre,WTo),e(A5,QTo),e(A5,vI),e(vI,HTo),e(A5,UTo),e(I,JTo),e(I,L5),e(L5,Yre),e(Yre,YTo),e(L5,KTo),e(L5,Kre),e(Kre,ZTo),e(L5,eFo),e(I,oFo),e(I,B5),e(B5,Zre),e(Zre,rFo),e(B5,tFo),e(B5,TI),e(TI,aFo),e(B5,nFo),e(I,sFo),e(I,x5),e(x5,ete),e(ete,lFo),e(x5,iFo),e(x5,FI),e(FI,dFo),e(x5,cFo),e(I,fFo),e(I,k5),e(k5,ote),e(ote,mFo),e(k5,gFo),e(k5,CI),e(CI,hFo),e(k5,pFo),e(I,_Fo),e(I,R5),e(R5,rte),e(rte,uFo),e(R5,bFo),e(R5,MI),e(MI,vFo),e(R5,TFo),e(qe,FFo),e(qe,S5),e(S5,CFo),e(S5,tte),e(tte,MFo),e(S5,EFo),e(S5,ate),e(ate,yFo),e(qe,wFo),e(qe,nte),e(nte,AFo),e(qe,LFo),g(hy,qe,null),b(c,Bke,u),b(c,id,u),e(id,P5),e(P5,ste),g(py,ste,null),e(id,BFo),e(id,lte),e(lte,xFo),b(c,xke,u),b(c,er,u),g(_y,er,null),e(er,kFo),e(er,dd),e(dd,RFo),e(dd,ite),e(ite,SFo),e(dd,PFo),e(dd,dte),e(dte,$Fo),e(dd,IFo),e(er,NFo),e(er,uy),e(uy,DFo),e(uy,cte),e(cte,jFo),e(uy,qFo),e(er,GFo),e(er,Hr),g(by,Hr,null),e(Hr,OFo),e(Hr,fte),e(fte,XFo),e(Hr,VFo),e(Hr,cd),e(cd,zFo),e(cd,mte),e(mte,WFo),e(cd,QFo),e(cd,gte),e(gte,HFo),e(cd,UFo),e(Hr,JFo),e(Hr,hte),e(hte,YFo),e(Hr,KFo),g(vy,Hr,null),e(er,ZFo),e(er,Ge),g(Ty,Ge,null),e(Ge,eCo),e(Ge,pte),e(pte,oCo),e(Ge,rCo),e(Ge,Ha),e(Ha,tCo),e(Ha,_te),e(_te,aCo),e(Ha,nCo),e(Ha,ute),e(ute,sCo),e(Ha,lCo),e(Ha,bte),e(bte,iCo),e(Ha,dCo),e(Ge,cCo),e(Ge,se),e(se,$5),e($5,vte),e(vte,fCo),e($5,mCo),e($5,EI),e(EI,gCo),e($5,hCo),e(se,pCo),e(se,I5),e(I5,Tte),e(Tte,_Co),e(I5,uCo),e(I5,yI),e(yI,bCo),e(I5,vCo),e(se,TCo),e(se,N5),e(N5,Fte),e(Fte,FCo),e(N5,CCo),e(N5,wI),e(wI,MCo),e(N5,ECo),e(se,yCo),e(se,D5),e(D5,Cte),e(Cte,wCo),e(D5,ACo),e(D5,AI),e(AI,LCo),e(D5,BCo),e(se,xCo),e(se,j5),e(j5,Mte),e(Mte,kCo),e(j5,RCo),e(j5,LI),e(LI,SCo),e(j5,PCo),e(se,$Co),e(se,q5),e(q5,Ete),e(Ete,ICo),e(q5,NCo),e(q5,BI),e(BI,DCo),e(q5,jCo),e(se,qCo),e(se,G5),e(G5,yte),e(yte,GCo),e(G5,OCo),e(G5,xI),e(xI,XCo),e(G5,VCo),e(se,zCo),e(se,O5),e(O5,wte),e(wte,WCo),e(O5,QCo),e(O5,kI),e(kI,HCo),e(O5,UCo),e(se,JCo),e(se,X5),e(X5,Ate),e(Ate,YCo),e(X5,KCo),e(X5,RI),e(RI,ZCo),e(X5,eMo),e(se,oMo),e(se,V5),e(V5,Lte),e(Lte,rMo),e(V5,tMo),e(V5,SI),e(SI,aMo),e(V5,nMo),e(se,sMo),e(se,z5),e(z5,Bte),e(Bte,lMo),e(z5,iMo),e(z5,PI),e(PI,dMo),e(z5,cMo),e(se,fMo),e(se,W5),e(W5,xte),e(xte,mMo),e(W5,gMo),e(W5,$I),e($I,hMo),e(W5,pMo),e(se,_Mo),e(se,Q5),e(Q5,kte),e(kte,uMo),e(Q5,bMo),e(Q5,II),e(II,vMo),e(Q5,TMo),e(se,FMo),e(se,H5),e(H5,Rte),e(Rte,CMo),e(H5,MMo),e(H5,NI),e(NI,EMo),e(H5,yMo),e(se,wMo),e(se,U5),e(U5,Ste),e(Ste,AMo),e(U5,LMo),e(U5,DI),e(DI,BMo),e(U5,xMo),e(se,kMo),e(se,J5),e(J5,Pte),e(Pte,RMo),e(J5,SMo),e(J5,jI),e(jI,PMo),e(J5,$Mo),e(Ge,IMo),e(Ge,Y5),e(Y5,NMo),e(Y5,$te),e($te,DMo),e(Y5,jMo),e(Y5,Ite),e(Ite,qMo),e(Ge,GMo),e(Ge,Nte),e(Nte,OMo),e(Ge,XMo),g(Fy,Ge,null),b(c,kke,u),b(c,fd,u),e(fd,K5),e(K5,Dte),g(Cy,Dte,null),e(fd,VMo),e(fd,jte),e(jte,zMo),b(c,Rke,u),b(c,or,u),g(My,or,null),e(or,WMo),e(or,md),e(md,QMo),e(md,qte),e(qte,HMo),e(md,UMo),e(md,Gte),e(Gte,JMo),e(md,YMo),e(or,KMo),e(or,Ey),e(Ey,ZMo),e(Ey,Ote),e(Ote,e4o),e(Ey,o4o),e(or,r4o),e(or,Ur),g(yy,Ur,null),e(Ur,t4o),e(Ur,Xte),e(Xte,a4o),e(Ur,n4o),e(Ur,gd),e(gd,s4o),e(gd,Vte),e(Vte,l4o),e(gd,i4o),e(gd,zte),e(zte,d4o),e(gd,c4o),e(Ur,f4o),e(Ur,Wte),e(Wte,m4o),e(Ur,g4o),g(wy,Ur,null),e(or,h4o),e(or,Oe),g(Ay,Oe,null),e(Oe,p4o),e(Oe,Qte),e(Qte,_4o),e(Oe,u4o),e(Oe,Ua),e(Ua,b4o),e(Ua,Hte),e(Hte,v4o),e(Ua,T4o),e(Ua,Ute),e(Ute,F4o),e(Ua,C4o),e(Ua,Jte),e(Jte,M4o),e(Ua,E4o),e(Oe,y4o),e(Oe,A),e(A,Z5),e(Z5,Yte),e(Yte,w4o),e(Z5,A4o),e(Z5,qI),e(qI,L4o),e(Z5,B4o),e(A,x4o),e(A,e2),e(e2,Kte),e(Kte,k4o),e(e2,R4o),e(e2,GI),e(GI,S4o),e(e2,P4o),e(A,$4o),e(A,o2),e(o2,Zte),e(Zte,I4o),e(o2,N4o),e(o2,OI),e(OI,D4o),e(o2,j4o),e(A,q4o),e(A,r2),e(r2,eae),e(eae,G4o),e(r2,O4o),e(r2,XI),e(XI,X4o),e(r2,V4o),e(A,z4o),e(A,t2),e(t2,oae),e(oae,W4o),e(t2,Q4o),e(t2,VI),e(VI,H4o),e(t2,U4o),e(A,J4o),e(A,a2),e(a2,rae),e(rae,Y4o),e(a2,K4o),e(a2,zI),e(zI,Z4o),e(a2,eEo),e(A,oEo),e(A,n2),e(n2,tae),e(tae,rEo),e(n2,tEo),e(n2,WI),e(WI,aEo),e(n2,nEo),e(A,sEo),e(A,s2),e(s2,aae),e(aae,lEo),e(s2,iEo),e(s2,QI),e(QI,dEo),e(s2,cEo),e(A,fEo),e(A,l2),e(l2,nae),e(nae,mEo),e(l2,gEo),e(l2,HI),e(HI,hEo),e(l2,pEo),e(A,_Eo),e(A,i2),e(i2,sae),e(sae,uEo),e(i2,bEo),e(i2,UI),e(UI,vEo),e(i2,TEo),e(A,FEo),e(A,d2),e(d2,lae),e(lae,CEo),e(d2,MEo),e(d2,JI),e(JI,EEo),e(d2,yEo),e(A,wEo),e(A,c2),e(c2,iae),e(iae,AEo),e(c2,LEo),e(c2,YI),e(YI,BEo),e(c2,xEo),e(A,kEo),e(A,f2),e(f2,dae),e(dae,REo),e(f2,SEo),e(f2,KI),e(KI,PEo),e(f2,$Eo),e(A,IEo),e(A,m2),e(m2,cae),e(cae,NEo),e(m2,DEo),e(m2,ZI),e(ZI,jEo),e(m2,qEo),e(A,GEo),e(A,g2),e(g2,fae),e(fae,OEo),e(g2,XEo),e(g2,eN),e(eN,VEo),e(g2,zEo),e(A,WEo),e(A,h2),e(h2,mae),e(mae,QEo),e(h2,HEo),e(h2,oN),e(oN,UEo),e(h2,JEo),e(A,YEo),e(A,p2),e(p2,gae),e(gae,KEo),e(p2,ZEo),e(p2,rN),e(rN,e3o),e(p2,o3o),e(A,r3o),e(A,_2),e(_2,hae),e(hae,t3o),e(_2,a3o),e(_2,tN),e(tN,n3o),e(_2,s3o),e(A,l3o),e(A,u2),e(u2,pae),e(pae,i3o),e(u2,d3o),e(u2,aN),e(aN,c3o),e(u2,f3o),e(A,m3o),e(A,b2),e(b2,_ae),e(_ae,g3o),e(b2,h3o),e(b2,nN),e(nN,p3o),e(b2,_3o),e(A,u3o),e(A,v2),e(v2,uae),e(uae,b3o),e(v2,v3o),e(v2,sN),e(sN,T3o),e(v2,F3o),e(A,C3o),e(A,T2),e(T2,bae),e(bae,M3o),e(T2,E3o),e(T2,lN),e(lN,y3o),e(T2,w3o),e(A,A3o),e(A,F2),e(F2,vae),e(vae,L3o),e(F2,B3o),e(F2,iN),e(iN,x3o),e(F2,k3o),e(A,R3o),e(A,C2),e(C2,Tae),e(Tae,S3o),e(C2,P3o),e(C2,dN),e(dN,$3o),e(C2,I3o),e(A,N3o),e(A,M2),e(M2,Fae),e(Fae,D3o),e(M2,j3o),e(M2,cN),e(cN,q3o),e(M2,G3o),e(A,O3o),e(A,E2),e(E2,Cae),e(Cae,X3o),e(E2,V3o),e(E2,fN),e(fN,z3o),e(E2,W3o),e(A,Q3o),e(A,y2),e(y2,Mae),e(Mae,H3o),e(y2,U3o),e(y2,mN),e(mN,J3o),e(y2,Y3o),e(A,K3o),e(A,w2),e(w2,Eae),e(Eae,Z3o),e(w2,eyo),e(w2,gN),e(gN,oyo),e(w2,ryo),e(A,tyo),e(A,A2),e(A2,yae),e(yae,ayo),e(A2,nyo),e(A2,hN),e(hN,syo),e(A2,lyo),e(A,iyo),e(A,L2),e(L2,wae),e(wae,dyo),e(L2,cyo),e(L2,pN),e(pN,fyo),e(L2,myo),e(A,gyo),e(A,B2),e(B2,Aae),e(Aae,hyo),e(B2,pyo),e(B2,_N),e(_N,_yo),e(B2,uyo),e(A,byo),e(A,x2),e(x2,Lae),e(Lae,vyo),e(x2,Tyo),e(x2,uN),e(uN,Fyo),e(x2,Cyo),e(A,Myo),e(A,k2),e(k2,Bae),e(Bae,Eyo),e(k2,yyo),e(k2,bN),e(bN,wyo),e(k2,Ayo),e(A,Lyo),e(A,R2),e(R2,xae),e(xae,Byo),e(R2,xyo),e(R2,vN),e(vN,kyo),e(R2,Ryo),e(A,Syo),e(A,S2),e(S2,kae),e(kae,Pyo),e(S2,$yo),e(S2,TN),e(TN,Iyo),e(S2,Nyo),e(A,Dyo),e(A,P2),e(P2,Rae),e(Rae,jyo),e(P2,qyo),e(P2,FN),e(FN,Gyo),e(P2,Oyo),e(A,Xyo),e(A,$2),e($2,Sae),e(Sae,Vyo),e($2,zyo),e($2,CN),e(CN,Wyo),e($2,Qyo),e(A,Hyo),e(A,I2),e(I2,Pae),e(Pae,Uyo),e(I2,Jyo),e(I2,MN),e(MN,Yyo),e(I2,Kyo),e(A,Zyo),e(A,N2),e(N2,$ae),e($ae,ewo),e(N2,owo),e(N2,EN),e(EN,rwo),e(N2,two),e(A,awo),e(A,D2),e(D2,Iae),e(Iae,nwo),e(D2,swo),e(D2,yN),e(yN,lwo),e(D2,iwo),e(A,dwo),e(A,j2),e(j2,Nae),e(Nae,cwo),e(j2,fwo),e(j2,wN),e(wN,mwo),e(j2,gwo),e(A,hwo),e(A,q2),e(q2,Dae),e(Dae,pwo),e(q2,_wo),e(q2,AN),e(AN,uwo),e(q2,bwo),e(A,vwo),e(A,G2),e(G2,jae),e(jae,Two),e(G2,Fwo),e(G2,LN),e(LN,Cwo),e(G2,Mwo),e(A,Ewo),e(A,O2),e(O2,qae),e(qae,ywo),e(O2,wwo),e(O2,BN),e(BN,Awo),e(O2,Lwo),e(A,Bwo),e(A,X2),e(X2,Gae),e(Gae,xwo),e(X2,kwo),e(X2,xN),e(xN,Rwo),e(X2,Swo),e(A,Pwo),e(A,V2),e(V2,Oae),e(Oae,$wo),e(V2,Iwo),e(V2,kN),e(kN,Nwo),e(V2,Dwo),e(Oe,jwo),e(Oe,z2),e(z2,qwo),e(z2,Xae),e(Xae,Gwo),e(z2,Owo),e(z2,Vae),e(Vae,Xwo),e(Oe,Vwo),e(Oe,zae),e(zae,zwo),e(Oe,Wwo),g(Ly,Oe,null),b(c,Ske,u),b(c,hd,u),e(hd,W2),e(W2,Wae),g(By,Wae,null),e(hd,Qwo),e(hd,Qae),e(Qae,Hwo),b(c,Pke,u),b(c,rr,u),g(xy,rr,null),e(rr,Uwo),e(rr,pd),e(pd,Jwo),e(pd,Hae),e(Hae,Ywo),e(pd,Kwo),e(pd,Uae),e(Uae,Zwo),e(pd,eAo),e(rr,oAo),e(rr,ky),e(ky,rAo),e(ky,Jae),e(Jae,tAo),e(ky,aAo),e(rr,nAo),e(rr,Jr),g(Ry,Jr,null),e(Jr,sAo),e(Jr,Yae),e(Yae,lAo),e(Jr,iAo),e(Jr,_d),e(_d,dAo),e(_d,Kae),e(Kae,cAo),e(_d,fAo),e(_d,Zae),e(Zae,mAo),e(_d,gAo),e(Jr,hAo),e(Jr,ene),e(ene,pAo),e(Jr,_Ao),g(Sy,Jr,null),e(rr,uAo),e(rr,Xe),g(Py,Xe,null),e(Xe,bAo),e(Xe,one),e(one,vAo),e(Xe,TAo),e(Xe,Ja),e(Ja,FAo),e(Ja,rne),e(rne,CAo),e(Ja,MAo),e(Ja,tne),e(tne,EAo),e(Ja,yAo),e(Ja,ane),e(ane,wAo),e(Ja,AAo),e(Xe,LAo),e(Xe,G),e(G,Q2),e(Q2,nne),e(nne,BAo),e(Q2,xAo),e(Q2,RN),e(RN,kAo),e(Q2,RAo),e(G,SAo),e(G,H2),e(H2,sne),e(sne,PAo),e(H2,$Ao),e(H2,SN),e(SN,IAo),e(H2,NAo),e(G,DAo),e(G,U2),e(U2,lne),e(lne,jAo),e(U2,qAo),e(U2,PN),e(PN,GAo),e(U2,OAo),e(G,XAo),e(G,J2),e(J2,ine),e(ine,VAo),e(J2,zAo),e(J2,$N),e($N,WAo),e(J2,QAo),e(G,HAo),e(G,Y2),e(Y2,dne),e(dne,UAo),e(Y2,JAo),e(Y2,IN),e(IN,YAo),e(Y2,KAo),e(G,ZAo),e(G,K2),e(K2,cne),e(cne,e0o),e(K2,o0o),e(K2,NN),e(NN,r0o),e(K2,t0o),e(G,a0o),e(G,Z2),e(Z2,fne),e(fne,n0o),e(Z2,s0o),e(Z2,DN),e(DN,l0o),e(Z2,i0o),e(G,d0o),e(G,e1),e(e1,mne),e(mne,c0o),e(e1,f0o),e(e1,jN),e(jN,m0o),e(e1,g0o),e(G,h0o),e(G,o1),e(o1,gne),e(gne,p0o),e(o1,_0o),e(o1,qN),e(qN,u0o),e(o1,b0o),e(G,v0o),e(G,r1),e(r1,hne),e(hne,T0o),e(r1,F0o),e(r1,GN),e(GN,C0o),e(r1,M0o),e(G,E0o),e(G,t1),e(t1,pne),e(pne,y0o),e(t1,w0o),e(t1,ON),e(ON,A0o),e(t1,L0o),e(G,B0o),e(G,a1),e(a1,_ne),e(_ne,x0o),e(a1,k0o),e(a1,XN),e(XN,R0o),e(a1,S0o),e(G,P0o),e(G,n1),e(n1,une),e(une,$0o),e(n1,I0o),e(n1,VN),e(VN,N0o),e(n1,D0o),e(G,j0o),e(G,s1),e(s1,bne),e(bne,q0o),e(s1,G0o),e(s1,zN),e(zN,O0o),e(s1,X0o),e(G,V0o),e(G,l1),e(l1,vne),e(vne,z0o),e(l1,W0o),e(l1,WN),e(WN,Q0o),e(l1,H0o),e(G,U0o),e(G,i1),e(i1,Tne),e(Tne,J0o),e(i1,Y0o),e(i1,QN),e(QN,K0o),e(i1,Z0o),e(G,eLo),e(G,d1),e(d1,Fne),e(Fne,oLo),e(d1,rLo),e(d1,HN),e(HN,tLo),e(d1,aLo),e(G,nLo),e(G,c1),e(c1,Cne),e(Cne,sLo),e(c1,lLo),e(c1,UN),e(UN,iLo),e(c1,dLo),e(G,cLo),e(G,f1),e(f1,Mne),e(Mne,fLo),e(f1,mLo),e(f1,JN),e(JN,gLo),e(f1,hLo),e(G,pLo),e(G,m1),e(m1,Ene),e(Ene,_Lo),e(m1,uLo),e(m1,YN),e(YN,bLo),e(m1,vLo),e(G,TLo),e(G,g1),e(g1,yne),e(yne,FLo),e(g1,CLo),e(g1,KN),e(KN,MLo),e(g1,ELo),e(G,yLo),e(G,h1),e(h1,wne),e(wne,wLo),e(h1,ALo),e(h1,ZN),e(ZN,LLo),e(h1,BLo),e(G,xLo),e(G,p1),e(p1,Ane),e(Ane,kLo),e(p1,RLo),e(p1,eD),e(eD,SLo),e(p1,PLo),e(G,$Lo),e(G,_1),e(_1,Lne),e(Lne,ILo),e(_1,NLo),e(_1,oD),e(oD,DLo),e(_1,jLo),e(G,qLo),e(G,u1),e(u1,Bne),e(Bne,GLo),e(u1,OLo),e(u1,rD),e(rD,XLo),e(u1,VLo),e(G,zLo),e(G,b1),e(b1,xne),e(xne,WLo),e(b1,QLo),e(b1,tD),e(tD,HLo),e(b1,ULo),e(G,JLo),e(G,v1),e(v1,kne),e(kne,YLo),e(v1,KLo),e(v1,aD),e(aD,ZLo),e(v1,e7o),e(G,o7o),e(G,T1),e(T1,Rne),e(Rne,r7o),e(T1,t7o),e(T1,nD),e(nD,a7o),e(T1,n7o),e(Xe,s7o),e(Xe,F1),e(F1,l7o),e(F1,Sne),e(Sne,i7o),e(F1,d7o),e(F1,Pne),e(Pne,c7o),e(Xe,f7o),e(Xe,$ne),e($ne,m7o),e(Xe,g7o),g($y,Xe,null),b(c,$ke,u),b(c,ud,u),e(ud,C1),e(C1,Ine),g(Iy,Ine,null),e(ud,h7o),e(ud,Nne),e(Nne,p7o),b(c,Ike,u),b(c,tr,u),g(Ny,tr,null),e(tr,_7o),e(tr,bd),e(bd,u7o),e(bd,Dne),e(Dne,b7o),e(bd,v7o),e(bd,jne),e(jne,T7o),e(bd,F7o),e(tr,C7o),e(tr,Dy),e(Dy,M7o),e(Dy,qne),e(qne,E7o),e(Dy,y7o),e(tr,w7o),e(tr,Yr),g(jy,Yr,null),e(Yr,A7o),e(Yr,Gne),e(Gne,L7o),e(Yr,B7o),e(Yr,vd),e(vd,x7o),e(vd,One),e(One,k7o),e(vd,R7o),e(vd,Xne),e(Xne,S7o),e(vd,P7o),e(Yr,$7o),e(Yr,Vne),e(Vne,I7o),e(Yr,N7o),g(qy,Yr,null),e(tr,D7o),e(tr,Ve),g(Gy,Ve,null),e(Ve,j7o),e(Ve,zne),e(zne,q7o),e(Ve,G7o),e(Ve,Ya),e(Ya,O7o),e(Ya,Wne),e(Wne,X7o),e(Ya,V7o),e(Ya,Qne),e(Qne,z7o),e(Ya,W7o),e(Ya,Hne),e(Hne,Q7o),e(Ya,H7o),e(Ve,U7o),e(Ve,da),e(da,M1),e(M1,Une),e(Une,J7o),e(M1,Y7o),e(M1,sD),e(sD,K7o),e(M1,Z7o),e(da,e8o),e(da,E1),e(E1,Jne),e(Jne,o8o),e(E1,r8o),e(E1,lD),e(lD,t8o),e(E1,a8o),e(da,n8o),e(da,y1),e(y1,Yne),e(Yne,s8o),e(y1,l8o),e(y1,iD),e(iD,i8o),e(y1,d8o),e(da,c8o),e(da,w1),e(w1,Kne),e(Kne,f8o),e(w1,m8o),e(w1,dD),e(dD,g8o),e(w1,h8o),e(da,p8o),e(da,A1),e(A1,Zne),e(Zne,_8o),e(A1,u8o),e(A1,cD),e(cD,b8o),e(A1,v8o),e(Ve,T8o),e(Ve,L1),e(L1,F8o),e(L1,ese),e(ese,C8o),e(L1,M8o),e(L1,ose),e(ose,E8o),e(Ve,y8o),e(Ve,rse),e(rse,w8o),e(Ve,A8o),g(Oy,Ve,null),b(c,Nke,u),b(c,Td,u),e(Td,B1),e(B1,tse),g(Xy,tse,null),e(Td,L8o),e(Td,ase),e(ase,B8o),b(c,Dke,u),b(c,ar,u),g(Vy,ar,null),e(ar,x8o),e(ar,Fd),e(Fd,k8o),e(Fd,nse),e(nse,R8o),e(Fd,S8o),e(Fd,sse),e(sse,P8o),e(Fd,$8o),e(ar,I8o),e(ar,zy),e(zy,N8o),e(zy,lse),e(lse,D8o),e(zy,j8o),e(ar,q8o),e(ar,Kr),g(Wy,Kr,null),e(Kr,G8o),e(Kr,ise),e(ise,O8o),e(Kr,X8o),e(Kr,Cd),e(Cd,V8o),e(Cd,dse),e(dse,z8o),e(Cd,W8o),e(Cd,cse),e(cse,Q8o),e(Cd,H8o),e(Kr,U8o),e(Kr,fse),e(fse,J8o),e(Kr,Y8o),g(Qy,Kr,null),e(ar,K8o),e(ar,ze),g(Hy,ze,null),e(ze,Z8o),e(ze,mse),e(mse,e9o),e(ze,o9o),e(ze,Ka),e(Ka,r9o),e(Ka,gse),e(gse,t9o),e(Ka,a9o),e(Ka,hse),e(hse,n9o),e(Ka,s9o),e(Ka,pse),e(pse,l9o),e(Ka,i9o),e(ze,d9o),e(ze,j),e(j,x1),e(x1,_se),e(_se,c9o),e(x1,f9o),e(x1,fD),e(fD,m9o),e(x1,g9o),e(j,h9o),e(j,k1),e(k1,use),e(use,p9o),e(k1,_9o),e(k1,mD),e(mD,u9o),e(k1,b9o),e(j,v9o),e(j,R1),e(R1,bse),e(bse,T9o),e(R1,F9o),e(R1,gD),e(gD,C9o),e(R1,M9o),e(j,E9o),e(j,S1),e(S1,vse),e(vse,y9o),e(S1,w9o),e(S1,hD),e(hD,A9o),e(S1,L9o),e(j,B9o),e(j,P1),e(P1,Tse),e(Tse,x9o),e(P1,k9o),e(P1,pD),e(pD,R9o),e(P1,S9o),e(j,P9o),e(j,$1),e($1,Fse),e(Fse,$9o),e($1,I9o),e($1,_D),e(_D,N9o),e($1,D9o),e(j,j9o),e(j,I1),e(I1,Cse),e(Cse,q9o),e(I1,G9o),e(I1,uD),e(uD,O9o),e(I1,X9o),e(j,V9o),e(j,N1),e(N1,Mse),e(Mse,z9o),e(N1,W9o),e(N1,bD),e(bD,Q9o),e(N1,H9o),e(j,U9o),e(j,D1),e(D1,Ese),e(Ese,J9o),e(D1,Y9o),e(D1,vD),e(vD,K9o),e(D1,Z9o),e(j,eBo),e(j,j1),e(j1,yse),e(yse,oBo),e(j1,rBo),e(j1,TD),e(TD,tBo),e(j1,aBo),e(j,nBo),e(j,q1),e(q1,wse),e(wse,sBo),e(q1,lBo),e(q1,FD),e(FD,iBo),e(q1,dBo),e(j,cBo),e(j,G1),e(G1,Ase),e(Ase,fBo),e(G1,mBo),e(G1,CD),e(CD,gBo),e(G1,hBo),e(j,pBo),e(j,O1),e(O1,Lse),e(Lse,_Bo),e(O1,uBo),e(O1,MD),e(MD,bBo),e(O1,vBo),e(j,TBo),e(j,X1),e(X1,Bse),e(Bse,FBo),e(X1,CBo),e(X1,ED),e(ED,MBo),e(X1,EBo),e(j,yBo),e(j,V1),e(V1,xse),e(xse,wBo),e(V1,ABo),e(V1,yD),e(yD,LBo),e(V1,BBo),e(j,xBo),e(j,z1),e(z1,kse),e(kse,kBo),e(z1,RBo),e(z1,wD),e(wD,SBo),e(z1,PBo),e(j,$Bo),e(j,W1),e(W1,Rse),e(Rse,IBo),e(W1,NBo),e(W1,AD),e(AD,DBo),e(W1,jBo),e(j,qBo),e(j,Q1),e(Q1,Sse),e(Sse,GBo),e(Q1,OBo),e(Q1,LD),e(LD,XBo),e(Q1,VBo),e(j,zBo),e(j,H1),e(H1,Pse),e(Pse,WBo),e(H1,QBo),e(H1,BD),e(BD,HBo),e(H1,UBo),e(j,JBo),e(j,U1),e(U1,$se),e($se,YBo),e(U1,KBo),e(U1,xD),e(xD,ZBo),e(U1,exo),e(j,oxo),e(j,J1),e(J1,Ise),e(Ise,rxo),e(J1,txo),e(J1,kD),e(kD,axo),e(J1,nxo),e(j,sxo),e(j,Y1),e(Y1,Nse),e(Nse,lxo),e(Y1,ixo),e(Y1,RD),e(RD,dxo),e(Y1,cxo),e(j,fxo),e(j,K1),e(K1,Dse),e(Dse,mxo),e(K1,gxo),e(K1,SD),e(SD,hxo),e(K1,pxo),e(j,_xo),e(j,Z1),e(Z1,jse),e(jse,uxo),e(Z1,bxo),e(Z1,PD),e(PD,vxo),e(Z1,Txo),e(j,Fxo),e(j,eb),e(eb,qse),e(qse,Cxo),e(eb,Mxo),e(eb,$D),e($D,Exo),e(eb,yxo),e(j,wxo),e(j,ob),e(ob,Gse),e(Gse,Axo),e(ob,Lxo),e(ob,ID),e(ID,Bxo),e(ob,xxo),e(j,kxo),e(j,rb),e(rb,Ose),e(Ose,Rxo),e(rb,Sxo),e(rb,ND),e(ND,Pxo),e(rb,$xo),e(j,Ixo),e(j,tb),e(tb,Xse),e(Xse,Nxo),e(tb,Dxo),e(tb,DD),e(DD,jxo),e(tb,qxo),e(j,Gxo),e(j,ab),e(ab,Vse),e(Vse,Oxo),e(ab,Xxo),e(ab,jD),e(jD,Vxo),e(ab,zxo),e(j,Wxo),e(j,nb),e(nb,zse),e(zse,Qxo),e(nb,Hxo),e(nb,qD),e(qD,Uxo),e(nb,Jxo),e(j,Yxo),e(j,sb),e(sb,Wse),e(Wse,Kxo),e(sb,Zxo),e(sb,GD),e(GD,eko),e(sb,oko),e(j,rko),e(j,lb),e(lb,Qse),e(Qse,tko),e(lb,ako),e(lb,OD),e(OD,nko),e(lb,sko),e(j,lko),e(j,ib),e(ib,Hse),e(Hse,iko),e(ib,dko),e(ib,XD),e(XD,cko),e(ib,fko),e(ze,mko),e(ze,db),e(db,gko),e(db,Use),e(Use,hko),e(db,pko),e(db,Jse),e(Jse,_ko),e(ze,uko),e(ze,Yse),e(Yse,bko),e(ze,vko),g(Uy,ze,null),b(c,jke,u),b(c,Md,u),e(Md,cb),e(cb,Kse),g(Jy,Kse,null),e(Md,Tko),e(Md,Zse),e(Zse,Fko),b(c,qke,u),b(c,nr,u),g(Yy,nr,null),e(nr,Cko),e(nr,Ed),e(Ed,Mko),e(Ed,ele),e(ele,Eko),e(Ed,yko),e(Ed,ole),e(ole,wko),e(Ed,Ako),e(nr,Lko),e(nr,Ky),e(Ky,Bko),e(Ky,rle),e(rle,xko),e(Ky,kko),e(nr,Rko),e(nr,Zr),g(Zy,Zr,null),e(Zr,Sko),e(Zr,tle),e(tle,Pko),e(Zr,$ko),e(Zr,yd),e(yd,Iko),e(yd,ale),e(ale,Nko),e(yd,Dko),e(yd,nle),e(nle,jko),e(yd,qko),e(Zr,Gko),e(Zr,sle),e(sle,Oko),e(Zr,Xko),g(ew,Zr,null),e(nr,Vko),e(nr,We),g(ow,We,null),e(We,zko),e(We,lle),e(lle,Wko),e(We,Qko),e(We,Za),e(Za,Hko),e(Za,ile),e(ile,Uko),e(Za,Jko),e(Za,dle),e(dle,Yko),e(Za,Kko),e(Za,cle),e(cle,Zko),e(Za,eRo),e(We,oRo),e(We,R),e(R,fb),e(fb,fle),e(fle,rRo),e(fb,tRo),e(fb,VD),e(VD,aRo),e(fb,nRo),e(R,sRo),e(R,mb),e(mb,mle),e(mle,lRo),e(mb,iRo),e(mb,zD),e(zD,dRo),e(mb,cRo),e(R,fRo),e(R,gb),e(gb,gle),e(gle,mRo),e(gb,gRo),e(gb,WD),e(WD,hRo),e(gb,pRo),e(R,_Ro),e(R,hb),e(hb,hle),e(hle,uRo),e(hb,bRo),e(hb,QD),e(QD,vRo),e(hb,TRo),e(R,FRo),e(R,pb),e(pb,ple),e(ple,CRo),e(pb,MRo),e(pb,HD),e(HD,ERo),e(pb,yRo),e(R,wRo),e(R,_b),e(_b,_le),e(_le,ARo),e(_b,LRo),e(_b,UD),e(UD,BRo),e(_b,xRo),e(R,kRo),e(R,ub),e(ub,ule),e(ule,RRo),e(ub,SRo),e(ub,JD),e(JD,PRo),e(ub,$Ro),e(R,IRo),e(R,bb),e(bb,ble),e(ble,NRo),e(bb,DRo),e(bb,YD),e(YD,jRo),e(bb,qRo),e(R,GRo),e(R,vb),e(vb,vle),e(vle,ORo),e(vb,XRo),e(vb,KD),e(KD,VRo),e(vb,zRo),e(R,WRo),e(R,Tb),e(Tb,Tle),e(Tle,QRo),e(Tb,HRo),e(Tb,ZD),e(ZD,URo),e(Tb,JRo),e(R,YRo),e(R,Fb),e(Fb,Fle),e(Fle,KRo),e(Fb,ZRo),e(Fb,ej),e(ej,eSo),e(Fb,oSo),e(R,rSo),e(R,Cb),e(Cb,Cle),e(Cle,tSo),e(Cb,aSo),e(Cb,oj),e(oj,nSo),e(Cb,sSo),e(R,lSo),e(R,Mb),e(Mb,Mle),e(Mle,iSo),e(Mb,dSo),e(Mb,rj),e(rj,cSo),e(Mb,fSo),e(R,mSo),e(R,Eb),e(Eb,Ele),e(Ele,gSo),e(Eb,hSo),e(Eb,tj),e(tj,pSo),e(Eb,_So),e(R,uSo),e(R,yb),e(yb,yle),e(yle,bSo),e(yb,vSo),e(yb,aj),e(aj,TSo),e(yb,FSo),e(R,CSo),e(R,wb),e(wb,wle),e(wle,MSo),e(wb,ESo),e(wb,nj),e(nj,ySo),e(wb,wSo),e(R,ASo),e(R,Ab),e(Ab,Ale),e(Ale,LSo),e(Ab,BSo),e(Ab,sj),e(sj,xSo),e(Ab,kSo),e(R,RSo),e(R,Lb),e(Lb,Lle),e(Lle,SSo),e(Lb,PSo),e(Lb,lj),e(lj,$So),e(Lb,ISo),e(R,NSo),e(R,Bb),e(Bb,Ble),e(Ble,DSo),e(Bb,jSo),e(Bb,ij),e(ij,qSo),e(Bb,GSo),e(R,OSo),e(R,xb),e(xb,xle),e(xle,XSo),e(xb,VSo),e(xb,dj),e(dj,zSo),e(xb,WSo),e(R,QSo),e(R,kb),e(kb,kle),e(kle,HSo),e(kb,USo),e(kb,cj),e(cj,JSo),e(kb,YSo),e(R,KSo),e(R,Rb),e(Rb,Rle),e(Rle,ZSo),e(Rb,ePo),e(Rb,fj),e(fj,oPo),e(Rb,rPo),e(R,tPo),e(R,Sb),e(Sb,Sle),e(Sle,aPo),e(Sb,nPo),e(Sb,mj),e(mj,sPo),e(Sb,lPo),e(R,iPo),e(R,Pb),e(Pb,Ple),e(Ple,dPo),e(Pb,cPo),e(Pb,gj),e(gj,fPo),e(Pb,mPo),e(R,gPo),e(R,$b),e($b,$le),e($le,hPo),e($b,pPo),e($b,hj),e(hj,_Po),e($b,uPo),e(R,bPo),e(R,Ib),e(Ib,Ile),e(Ile,vPo),e(Ib,TPo),e(Ib,pj),e(pj,FPo),e(Ib,CPo),e(R,MPo),e(R,Nb),e(Nb,Nle),e(Nle,EPo),e(Nb,yPo),e(Nb,_j),e(_j,wPo),e(Nb,APo),e(R,LPo),e(R,Db),e(Db,Dle),e(Dle,BPo),e(Db,xPo),e(Db,uj),e(uj,kPo),e(Db,RPo),e(R,SPo),e(R,jb),e(jb,jle),e(jle,PPo),e(jb,$Po),e(jb,bj),e(bj,IPo),e(jb,NPo),e(R,DPo),e(R,qb),e(qb,qle),e(qle,jPo),e(qb,qPo),e(qb,vj),e(vj,GPo),e(qb,OPo),e(R,XPo),e(R,Gb),e(Gb,Gle),e(Gle,VPo),e(Gb,zPo),e(Gb,Tj),e(Tj,WPo),e(Gb,QPo),e(R,HPo),e(R,Ob),e(Ob,Ole),e(Ole,UPo),e(Ob,JPo),e(Ob,Fj),e(Fj,YPo),e(Ob,KPo),e(R,ZPo),e(R,Xb),e(Xb,Xle),e(Xle,e$o),e(Xb,o$o),e(Xb,Cj),e(Cj,r$o),e(Xb,t$o),e(R,a$o),e(R,Vb),e(Vb,Vle),e(Vle,n$o),e(Vb,s$o),e(Vb,Mj),e(Mj,l$o),e(Vb,i$o),e(R,d$o),e(R,zb),e(zb,zle),e(zle,c$o),e(zb,f$o),e(zb,Ej),e(Ej,m$o),e(zb,g$o),e(R,h$o),e(R,Wb),e(Wb,Wle),e(Wle,p$o),e(Wb,_$o),e(Wb,yj),e(yj,u$o),e(Wb,b$o),e(R,v$o),e(R,Qb),e(Qb,Qle),e(Qle,T$o),e(Qb,F$o),e(Qb,wj),e(wj,C$o),e(Qb,M$o),e(R,E$o),e(R,Hb),e(Hb,Hle),e(Hle,y$o),e(Hb,w$o),e(Hb,Aj),e(Aj,A$o),e(Hb,L$o),e(R,B$o),e(R,Ub),e(Ub,Ule),e(Ule,x$o),e(Ub,k$o),e(Ub,Lj),e(Lj,R$o),e(Ub,S$o),e(We,P$o),e(We,Jb),e(Jb,$$o),e(Jb,Jle),e(Jle,I$o),e(Jb,N$o),e(Jb,Yle),e(Yle,D$o),e(We,j$o),e(We,Kle),e(Kle,q$o),e(We,G$o),g(rw,We,null),b(c,Gke,u),b(c,wd,u),e(wd,Yb),e(Yb,Zle),g(tw,Zle,null),e(wd,O$o),e(wd,eie),e(eie,X$o),b(c,Oke,u),b(c,sr,u),g(aw,sr,null),e(sr,V$o),e(sr,Ad),e(Ad,z$o),e(Ad,oie),e(oie,W$o),e(Ad,Q$o),e(Ad,rie),e(rie,H$o),e(Ad,U$o),e(sr,J$o),e(sr,nw),e(nw,Y$o),e(nw,tie),e(tie,K$o),e(nw,Z$o),e(sr,eIo),e(sr,et),g(sw,et,null),e(et,oIo),e(et,aie),e(aie,rIo),e(et,tIo),e(et,Ld),e(Ld,aIo),e(Ld,nie),e(nie,nIo),e(Ld,sIo),e(Ld,sie),e(sie,lIo),e(Ld,iIo),e(et,dIo),e(et,lie),e(lie,cIo),e(et,fIo),g(lw,et,null),e(sr,mIo),e(sr,Qe),g(iw,Qe,null),e(Qe,gIo),e(Qe,iie),e(iie,hIo),e(Qe,pIo),e(Qe,en),e(en,_Io),e(en,die),e(die,uIo),e(en,bIo),e(en,cie),e(cie,vIo),e(en,TIo),e(en,fie),e(fie,FIo),e(en,CIo),e(Qe,MIo),e(Qe,mie),e(mie,Kb),e(Kb,gie),e(gie,EIo),e(Kb,yIo),e(Kb,Bj),e(Bj,wIo),e(Kb,AIo),e(Qe,LIo),e(Qe,Zb),e(Zb,BIo),e(Zb,hie),e(hie,xIo),e(Zb,kIo),e(Zb,pie),e(pie,RIo),e(Qe,SIo),e(Qe,_ie),e(_ie,PIo),e(Qe,$Io),g(dw,Qe,null),b(c,Xke,u),b(c,Bd,u),e(Bd,ev),e(ev,uie),g(cw,uie,null),e(Bd,IIo),e(Bd,bie),e(bie,NIo),b(c,Vke,u),b(c,lr,u),g(fw,lr,null),e(lr,DIo),e(lr,xd),e(xd,jIo),e(xd,vie),e(vie,qIo),e(xd,GIo),e(xd,Tie),e(Tie,OIo),e(xd,XIo),e(lr,VIo),e(lr,mw),e(mw,zIo),e(mw,Fie),e(Fie,WIo),e(mw,QIo),e(lr,HIo),e(lr,ot),g(gw,ot,null),e(ot,UIo),e(ot,Cie),e(Cie,JIo),e(ot,YIo),e(ot,kd),e(kd,KIo),e(kd,Mie),e(Mie,ZIo),e(kd,eNo),e(kd,Eie),e(Eie,oNo),e(kd,rNo),e(ot,tNo),e(ot,yie),e(yie,aNo),e(ot,nNo),g(hw,ot,null),e(lr,sNo),e(lr,He),g(pw,He,null),e(He,lNo),e(He,wie),e(wie,iNo),e(He,dNo),e(He,on),e(on,cNo),e(on,Aie),e(Aie,fNo),e(on,mNo),e(on,Lie),e(Lie,gNo),e(on,hNo),e(on,Bie),e(Bie,pNo),e(on,_No),e(He,uNo),e(He,me),e(me,ov),e(ov,xie),e(xie,bNo),e(ov,vNo),e(ov,xj),e(xj,TNo),e(ov,FNo),e(me,CNo),e(me,rv),e(rv,kie),e(kie,MNo),e(rv,ENo),e(rv,kj),e(kj,yNo),e(rv,wNo),e(me,ANo),e(me,qs),e(qs,Rie),e(Rie,LNo),e(qs,BNo),e(qs,Rj),e(Rj,xNo),e(qs,kNo),e(qs,Sj),e(Sj,RNo),e(qs,SNo),e(me,PNo),e(me,tv),e(tv,Sie),e(Sie,$No),e(tv,INo),e(tv,Pj),e(Pj,NNo),e(tv,DNo),e(me,jNo),e(me,ma),e(ma,Pie),e(Pie,qNo),e(ma,GNo),e(ma,$j),e($j,ONo),e(ma,XNo),e(ma,Ij),e(Ij,VNo),e(ma,zNo),e(ma,Nj),e(Nj,WNo),e(ma,QNo),e(me,HNo),e(me,av),e(av,$ie),e($ie,UNo),e(av,JNo),e(av,Dj),e(Dj,YNo),e(av,KNo),e(me,ZNo),e(me,nv),e(nv,Iie),e(Iie,eDo),e(nv,oDo),e(nv,jj),e(jj,rDo),e(nv,tDo),e(me,aDo),e(me,sv),e(sv,Nie),e(Nie,nDo),e(sv,sDo),e(sv,qj),e(qj,lDo),e(sv,iDo),e(me,dDo),e(me,lv),e(lv,Die),e(Die,cDo),e(lv,fDo),e(lv,Gj),e(Gj,mDo),e(lv,gDo),e(me,hDo),e(me,iv),e(iv,jie),e(jie,pDo),e(iv,_Do),e(iv,Oj),e(Oj,uDo),e(iv,bDo),e(me,vDo),e(me,dv),e(dv,qie),e(qie,TDo),e(dv,FDo),e(dv,Xj),e(Xj,CDo),e(dv,MDo),e(He,EDo),e(He,cv),e(cv,yDo),e(cv,Gie),e(Gie,wDo),e(cv,ADo),e(cv,Oie),e(Oie,LDo),e(He,BDo),e(He,Xie),e(Xie,xDo),e(He,kDo),g(_w,He,null),b(c,zke,u),b(c,Rd,u),e(Rd,fv),e(fv,Vie),g(uw,Vie,null),e(Rd,RDo),e(Rd,zie),e(zie,SDo),b(c,Wke,u),b(c,ir,u),g(bw,ir,null),e(ir,PDo),e(ir,Sd),e(Sd,$Do),e(Sd,Wie),e(Wie,IDo),e(Sd,NDo),e(Sd,Qie),e(Qie,DDo),e(Sd,jDo),e(ir,qDo),e(ir,vw),e(vw,GDo),e(vw,Hie),e(Hie,ODo),e(vw,XDo),e(ir,VDo),e(ir,rt),g(Tw,rt,null),e(rt,zDo),e(rt,Uie),e(Uie,WDo),e(rt,QDo),e(rt,Pd),e(Pd,HDo),e(Pd,Jie),e(Jie,UDo),e(Pd,JDo),e(Pd,Yie),e(Yie,YDo),e(Pd,KDo),e(rt,ZDo),e(rt,Kie),e(Kie,ejo),e(rt,ojo),g(Fw,rt,null),e(ir,rjo),e(ir,Ue),g(Cw,Ue,null),e(Ue,tjo),e(Ue,Zie),e(Zie,ajo),e(Ue,njo),e(Ue,rn),e(rn,sjo),e(rn,ede),e(ede,ljo),e(rn,ijo),e(rn,ode),e(ode,djo),e(rn,cjo),e(rn,rde),e(rde,fjo),e(rn,mjo),e(Ue,gjo),e(Ue,tde),e(tde,mv),e(mv,ade),e(ade,hjo),e(mv,pjo),e(mv,Vj),e(Vj,_jo),e(mv,ujo),e(Ue,bjo),e(Ue,gv),e(gv,vjo),e(gv,nde),e(nde,Tjo),e(gv,Fjo),e(gv,sde),e(sde,Cjo),e(Ue,Mjo),e(Ue,lde),e(lde,Ejo),e(Ue,yjo),g(Mw,Ue,null),b(c,Qke,u),b(c,$d,u),e($d,hv),e(hv,ide),g(Ew,ide,null),e($d,wjo),e($d,dde),e(dde,Ajo),b(c,Hke,u),b(c,dr,u),g(yw,dr,null),e(dr,Ljo),e(dr,Id),e(Id,Bjo),e(Id,cde),e(cde,xjo),e(Id,kjo),e(Id,fde),e(fde,Rjo),e(Id,Sjo),e(dr,Pjo),e(dr,ww),e(ww,$jo),e(ww,mde),e(mde,Ijo),e(ww,Njo),e(dr,Djo),e(dr,tt),g(Aw,tt,null),e(tt,jjo),e(tt,gde),e(gde,qjo),e(tt,Gjo),e(tt,Nd),e(Nd,Ojo),e(Nd,hde),e(hde,Xjo),e(Nd,Vjo),e(Nd,pde),e(pde,zjo),e(Nd,Wjo),e(tt,Qjo),e(tt,_de),e(_de,Hjo),e(tt,Ujo),g(Lw,tt,null),e(dr,Jjo),e(dr,Je),g(Bw,Je,null),e(Je,Yjo),e(Je,ude),e(ude,Kjo),e(Je,Zjo),e(Je,tn),e(tn,eqo),e(tn,bde),e(bde,oqo),e(tn,rqo),e(tn,vde),e(vde,tqo),e(tn,aqo),e(tn,Tde),e(Tde,nqo),e(tn,sqo),e(Je,lqo),e(Je,ke),e(ke,pv),e(pv,Fde),e(Fde,iqo),e(pv,dqo),e(pv,zj),e(zj,cqo),e(pv,fqo),e(ke,mqo),e(ke,_v),e(_v,Cde),e(Cde,gqo),e(_v,hqo),e(_v,Wj),e(Wj,pqo),e(_v,_qo),e(ke,uqo),e(ke,uv),e(uv,Mde),e(Mde,bqo),e(uv,vqo),e(uv,Qj),e(Qj,Tqo),e(uv,Fqo),e(ke,Cqo),e(ke,bv),e(bv,Ede),e(Ede,Mqo),e(bv,Eqo),e(bv,Hj),e(Hj,yqo),e(bv,wqo),e(ke,Aqo),e(ke,vv),e(vv,yde),e(yde,Lqo),e(vv,Bqo),e(vv,Uj),e(Uj,xqo),e(vv,kqo),e(ke,Rqo),e(ke,Tv),e(Tv,wde),e(wde,Sqo),e(Tv,Pqo),e(Tv,Jj),e(Jj,$qo),e(Tv,Iqo),e(ke,Nqo),e(ke,Fv),e(Fv,Ade),e(Ade,Dqo),e(Fv,jqo),e(Fv,Yj),e(Yj,qqo),e(Fv,Gqo),e(ke,Oqo),e(ke,Cv),e(Cv,Lde),e(Lde,Xqo),e(Cv,Vqo),e(Cv,Kj),e(Kj,zqo),e(Cv,Wqo),e(Je,Qqo),e(Je,Mv),e(Mv,Hqo),e(Mv,Bde),e(Bde,Uqo),e(Mv,Jqo),e(Mv,xde),e(xde,Yqo),e(Je,Kqo),e(Je,kde),e(kde,Zqo),e(Je,eGo),g(xw,Je,null),b(c,Uke,u),b(c,Dd,u),e(Dd,Ev),e(Ev,Rde),g(kw,Rde,null),e(Dd,oGo),e(Dd,Sde),e(Sde,rGo),b(c,Jke,u),b(c,cr,u),g(Rw,cr,null),e(cr,tGo),e(cr,jd),e(jd,aGo),e(jd,Pde),e(Pde,nGo),e(jd,sGo),e(jd,$de),e($de,lGo),e(jd,iGo),e(cr,dGo),e(cr,Sw),e(Sw,cGo),e(Sw,Ide),e(Ide,fGo),e(Sw,mGo),e(cr,gGo),e(cr,at),g(Pw,at,null),e(at,hGo),e(at,Nde),e(Nde,pGo),e(at,_Go),e(at,qd),e(qd,uGo),e(qd,Dde),e(Dde,bGo),e(qd,vGo),e(qd,jde),e(jde,TGo),e(qd,FGo),e(at,CGo),e(at,qde),e(qde,MGo),e(at,EGo),g($w,at,null),e(cr,yGo),e(cr,Ye),g(Iw,Ye,null),e(Ye,wGo),e(Ye,Gde),e(Gde,AGo),e(Ye,LGo),e(Ye,an),e(an,BGo),e(an,Ode),e(Ode,xGo),e(an,kGo),e(an,Xde),e(Xde,RGo),e(an,SGo),e(an,Vde),e(Vde,PGo),e(an,$Go),e(Ye,IGo),e(Ye,nn),e(nn,yv),e(yv,zde),e(zde,NGo),e(yv,DGo),e(yv,Zj),e(Zj,jGo),e(yv,qGo),e(nn,GGo),e(nn,wv),e(wv,Wde),e(Wde,OGo),e(wv,XGo),e(wv,eq),e(eq,VGo),e(wv,zGo),e(nn,WGo),e(nn,Av),e(Av,Qde),e(Qde,QGo),e(Av,HGo),e(Av,oq),e(oq,UGo),e(Av,JGo),e(nn,YGo),e(nn,Lv),e(Lv,Hde),e(Hde,KGo),e(Lv,ZGo),e(Lv,rq),e(rq,eOo),e(Lv,oOo),e(Ye,rOo),e(Ye,Bv),e(Bv,tOo),e(Bv,Ude),e(Ude,aOo),e(Bv,nOo),e(Bv,Jde),e(Jde,sOo),e(Ye,lOo),e(Ye,Yde),e(Yde,iOo),e(Ye,dOo),g(Nw,Ye,null),b(c,Yke,u),b(c,Gd,u),e(Gd,xv),e(xv,Kde),g(Dw,Kde,null),e(Gd,cOo),e(Gd,Zde),e(Zde,fOo),b(c,Kke,u),b(c,fr,u),g(jw,fr,null),e(fr,mOo),e(fr,Od),e(Od,gOo),e(Od,ece),e(ece,hOo),e(Od,pOo),e(Od,oce),e(oce,_Oo),e(Od,uOo),e(fr,bOo),e(fr,qw),e(qw,vOo),e(qw,rce),e(rce,TOo),e(qw,FOo),e(fr,COo),e(fr,nt),g(Gw,nt,null),e(nt,MOo),e(nt,tce),e(tce,EOo),e(nt,yOo),e(nt,Xd),e(Xd,wOo),e(Xd,ace),e(ace,AOo),e(Xd,LOo),e(Xd,nce),e(nce,BOo),e(Xd,xOo),e(nt,kOo),e(nt,sce),e(sce,ROo),e(nt,SOo),g(Ow,nt,null),e(fr,POo),e(fr,Ke),g(Xw,Ke,null),e(Ke,$Oo),e(Ke,lce),e(lce,IOo),e(Ke,NOo),e(Ke,sn),e(sn,DOo),e(sn,ice),e(ice,jOo),e(sn,qOo),e(sn,dce),e(dce,GOo),e(sn,OOo),e(sn,cce),e(cce,XOo),e(sn,VOo),e(Ke,zOo),e(Ke,Re),e(Re,kv),e(kv,fce),e(fce,WOo),e(kv,QOo),e(kv,tq),e(tq,HOo),e(kv,UOo),e(Re,JOo),e(Re,Rv),e(Rv,mce),e(mce,YOo),e(Rv,KOo),e(Rv,aq),e(aq,ZOo),e(Rv,eXo),e(Re,oXo),e(Re,Sv),e(Sv,gce),e(gce,rXo),e(Sv,tXo),e(Sv,nq),e(nq,aXo),e(Sv,nXo),e(Re,sXo),e(Re,Pv),e(Pv,hce),e(hce,lXo),e(Pv,iXo),e(Pv,sq),e(sq,dXo),e(Pv,cXo),e(Re,fXo),e(Re,$v),e($v,pce),e(pce,mXo),e($v,gXo),e($v,lq),e(lq,hXo),e($v,pXo),e(Re,_Xo),e(Re,Iv),e(Iv,_ce),e(_ce,uXo),e(Iv,bXo),e(Iv,iq),e(iq,vXo),e(Iv,TXo),e(Re,FXo),e(Re,Nv),e(Nv,uce),e(uce,CXo),e(Nv,MXo),e(Nv,dq),e(dq,EXo),e(Nv,yXo),e(Re,wXo),e(Re,Dv),e(Dv,bce),e(bce,AXo),e(Dv,LXo),e(Dv,cq),e(cq,BXo),e(Dv,xXo),e(Ke,kXo),e(Ke,jv),e(jv,RXo),e(jv,vce),e(vce,SXo),e(jv,PXo),e(jv,Tce),e(Tce,$Xo),e(Ke,IXo),e(Ke,Fce),e(Fce,NXo),e(Ke,DXo),g(Vw,Ke,null),b(c,Zke,u),b(c,Vd,u),e(Vd,qv),e(qv,Cce),g(zw,Cce,null),e(Vd,jXo),e(Vd,Mce),e(Mce,qXo),b(c,eRe,u),b(c,mr,u),g(Ww,mr,null),e(mr,GXo),e(mr,zd),e(zd,OXo),e(zd,Ece),e(Ece,XXo),e(zd,VXo),e(zd,yce),e(yce,zXo),e(zd,WXo),e(mr,QXo),e(mr,Qw),e(Qw,HXo),e(Qw,wce),e(wce,UXo),e(Qw,JXo),e(mr,YXo),e(mr,st),g(Hw,st,null),e(st,KXo),e(st,Ace),e(Ace,ZXo),e(st,eVo),e(st,Wd),e(Wd,oVo),e(Wd,Lce),e(Lce,rVo),e(Wd,tVo),e(Wd,Bce),e(Bce,aVo),e(Wd,nVo),e(st,sVo),e(st,xce),e(xce,lVo),e(st,iVo),g(Uw,st,null),e(mr,dVo),e(mr,Ze),g(Jw,Ze,null),e(Ze,cVo),e(Ze,kce),e(kce,fVo),e(Ze,mVo),e(Ze,ln),e(ln,gVo),e(ln,Rce),e(Rce,hVo),e(ln,pVo),e(ln,Sce),e(Sce,_Vo),e(ln,uVo),e(ln,Pce),e(Pce,bVo),e(ln,vVo),e(Ze,TVo),e(Ze,Yw),e(Yw,Gv),e(Gv,$ce),e($ce,FVo),e(Gv,CVo),e(Gv,fq),e(fq,MVo),e(Gv,EVo),e(Yw,yVo),e(Yw,Ov),e(Ov,Ice),e(Ice,wVo),e(Ov,AVo),e(Ov,mq),e(mq,LVo),e(Ov,BVo),e(Ze,xVo),e(Ze,Xv),e(Xv,kVo),e(Xv,Nce),e(Nce,RVo),e(Xv,SVo),e(Xv,Dce),e(Dce,PVo),e(Ze,$Vo),e(Ze,jce),e(jce,IVo),e(Ze,NVo),g(Kw,Ze,null),b(c,oRe,u),b(c,Qd,u),e(Qd,Vv),e(Vv,qce),g(Zw,qce,null),e(Qd,DVo),e(Qd,Gce),e(Gce,jVo),b(c,rRe,u),b(c,gr,u),g(eA,gr,null),e(gr,qVo),e(gr,Hd),e(Hd,GVo),e(Hd,Oce),e(Oce,OVo),e(Hd,XVo),e(Hd,Xce),e(Xce,VVo),e(Hd,zVo),e(gr,WVo),e(gr,oA),e(oA,QVo),e(oA,Vce),e(Vce,HVo),e(oA,UVo),e(gr,JVo),e(gr,lt),g(rA,lt,null),e(lt,YVo),e(lt,zce),e(zce,KVo),e(lt,ZVo),e(lt,Ud),e(Ud,ezo),e(Ud,Wce),e(Wce,ozo),e(Ud,rzo),e(Ud,Qce),e(Qce,tzo),e(Ud,azo),e(lt,nzo),e(lt,Hce),e(Hce,szo),e(lt,lzo),g(tA,lt,null),e(gr,izo),e(gr,eo),g(aA,eo,null),e(eo,dzo),e(eo,Uce),e(Uce,czo),e(eo,fzo),e(eo,dn),e(dn,mzo),e(dn,Jce),e(Jce,gzo),e(dn,hzo),e(dn,Yce),e(Yce,pzo),e(dn,_zo),e(dn,Kce),e(Kce,uzo),e(dn,bzo),e(eo,vzo),e(eo,cn),e(cn,zv),e(zv,Zce),e(Zce,Tzo),e(zv,Fzo),e(zv,gq),e(gq,Czo),e(zv,Mzo),e(cn,Ezo),e(cn,Wv),e(Wv,efe),e(efe,yzo),e(Wv,wzo),e(Wv,hq),e(hq,Azo),e(Wv,Lzo),e(cn,Bzo),e(cn,Qv),e(Qv,ofe),e(ofe,xzo),e(Qv,kzo),e(Qv,pq),e(pq,Rzo),e(Qv,Szo),e(cn,Pzo),e(cn,Hv),e(Hv,rfe),e(rfe,$zo),e(Hv,Izo),e(Hv,_q),e(_q,Nzo),e(Hv,Dzo),e(eo,jzo),e(eo,Uv),e(Uv,qzo),e(Uv,tfe),e(tfe,Gzo),e(Uv,Ozo),e(Uv,afe),e(afe,Xzo),e(eo,Vzo),e(eo,nfe),e(nfe,zzo),e(eo,Wzo),g(nA,eo,null),b(c,tRe,u),b(c,Jd,u),e(Jd,Jv),e(Jv,sfe),g(sA,sfe,null),e(Jd,Qzo),e(Jd,lfe),e(lfe,Hzo),b(c,aRe,u),b(c,hr,u),g(lA,hr,null),e(hr,Uzo),e(hr,Yd),e(Yd,Jzo),e(Yd,ife),e(ife,Yzo),e(Yd,Kzo),e(Yd,dfe),e(dfe,Zzo),e(Yd,eWo),e(hr,oWo),e(hr,iA),e(iA,rWo),e(iA,cfe),e(cfe,tWo),e(iA,aWo),e(hr,nWo),e(hr,it),g(dA,it,null),e(it,sWo),e(it,ffe),e(ffe,lWo),e(it,iWo),e(it,Kd),e(Kd,dWo),e(Kd,mfe),e(mfe,cWo),e(Kd,fWo),e(Kd,gfe),e(gfe,mWo),e(Kd,gWo),e(it,hWo),e(it,hfe),e(hfe,pWo),e(it,_Wo),g(cA,it,null),e(hr,uWo),e(hr,oo),g(fA,oo,null),e(oo,bWo),e(oo,pfe),e(pfe,vWo),e(oo,TWo),e(oo,fn),e(fn,FWo),e(fn,_fe),e(_fe,CWo),e(fn,MWo),e(fn,ufe),e(ufe,EWo),e(fn,yWo),e(fn,bfe),e(bfe,wWo),e(fn,AWo),e(oo,LWo),e(oo,Zd),e(Zd,Yv),e(Yv,vfe),e(vfe,BWo),e(Yv,xWo),e(Yv,uq),e(uq,kWo),e(Yv,RWo),e(Zd,SWo),e(Zd,Kv),e(Kv,Tfe),e(Tfe,PWo),e(Kv,$Wo),e(Kv,bq),e(bq,IWo),e(Kv,NWo),e(Zd,DWo),e(Zd,Zv),e(Zv,Ffe),e(Ffe,jWo),e(Zv,qWo),e(Zv,vq),e(vq,GWo),e(Zv,OWo),e(oo,XWo),e(oo,e6),e(e6,VWo),e(e6,Cfe),e(Cfe,zWo),e(e6,WWo),e(e6,Mfe),e(Mfe,QWo),e(oo,HWo),e(oo,Efe),e(Efe,UWo),e(oo,JWo),g(mA,oo,null),b(c,nRe,u),b(c,ec,u),e(ec,o6),e(o6,yfe),g(gA,yfe,null),e(ec,YWo),e(ec,wfe),e(wfe,KWo),b(c,sRe,u),b(c,pr,u),g(hA,pr,null),e(pr,ZWo),e(pr,oc),e(oc,eQo),e(oc,Afe),e(Afe,oQo),e(oc,rQo),e(oc,Lfe),e(Lfe,tQo),e(oc,aQo),e(pr,nQo),e(pr,pA),e(pA,sQo),e(pA,Bfe),e(Bfe,lQo),e(pA,iQo),e(pr,dQo),e(pr,dt),g(_A,dt,null),e(dt,cQo),e(dt,xfe),e(xfe,fQo),e(dt,mQo),e(dt,rc),e(rc,gQo),e(rc,kfe),e(kfe,hQo),e(rc,pQo),e(rc,Rfe),e(Rfe,_Qo),e(rc,uQo),e(dt,bQo),e(dt,Sfe),e(Sfe,vQo),e(dt,TQo),g(uA,dt,null),e(pr,FQo),e(pr,ro),g(bA,ro,null),e(ro,CQo),e(ro,Pfe),e(Pfe,MQo),e(ro,EQo),e(ro,mn),e(mn,yQo),e(mn,$fe),e($fe,wQo),e(mn,AQo),e(mn,Ife),e(Ife,LQo),e(mn,BQo),e(mn,Nfe),e(Nfe,xQo),e(mn,kQo),e(ro,RQo),e(ro,Dfe),e(Dfe,r6),e(r6,jfe),e(jfe,SQo),e(r6,PQo),e(r6,Tq),e(Tq,$Qo),e(r6,IQo),e(ro,NQo),e(ro,t6),e(t6,DQo),e(t6,qfe),e(qfe,jQo),e(t6,qQo),e(t6,Gfe),e(Gfe,GQo),e(ro,OQo),e(ro,Ofe),e(Ofe,XQo),e(ro,VQo),g(vA,ro,null),b(c,lRe,u),b(c,tc,u),e(tc,a6),e(a6,Xfe),g(TA,Xfe,null),e(tc,zQo),e(tc,Vfe),e(Vfe,WQo),b(c,iRe,u),b(c,_r,u),g(FA,_r,null),e(_r,QQo),e(_r,ac),e(ac,HQo),e(ac,zfe),e(zfe,UQo),e(ac,JQo),e(ac,Wfe),e(Wfe,YQo),e(ac,KQo),e(_r,ZQo),e(_r,CA),e(CA,eHo),e(CA,Qfe),e(Qfe,oHo),e(CA,rHo),e(_r,tHo),e(_r,ct),g(MA,ct,null),e(ct,aHo),e(ct,Hfe),e(Hfe,nHo),e(ct,sHo),e(ct,nc),e(nc,lHo),e(nc,Ufe),e(Ufe,iHo),e(nc,dHo),e(nc,Jfe),e(Jfe,cHo),e(nc,fHo),e(ct,mHo),e(ct,Yfe),e(Yfe,gHo),e(ct,hHo),g(EA,ct,null),e(_r,pHo),e(_r,to),g(yA,to,null),e(to,_Ho),e(to,Kfe),e(Kfe,uHo),e(to,bHo),e(to,gn),e(gn,vHo),e(gn,Zfe),e(Zfe,THo),e(gn,FHo),e(gn,eme),e(eme,CHo),e(gn,MHo),e(gn,ome),e(ome,EHo),e(gn,yHo),e(to,wHo),e(to,rme),e(rme,n6),e(n6,tme),e(tme,AHo),e(n6,LHo),e(n6,Fq),e(Fq,BHo),e(n6,xHo),e(to,kHo),e(to,s6),e(s6,RHo),e(s6,ame),e(ame,SHo),e(s6,PHo),e(s6,nme),e(nme,$Ho),e(to,IHo),e(to,sme),e(sme,NHo),e(to,DHo),g(wA,to,null),b(c,dRe,u),b(c,sc,u),e(sc,l6),e(l6,lme),g(AA,lme,null),e(sc,jHo),e(sc,ime),e(ime,qHo),b(c,cRe,u),b(c,ur,u),g(LA,ur,null),e(ur,GHo),e(ur,lc),e(lc,OHo),e(lc,dme),e(dme,XHo),e(lc,VHo),e(lc,cme),e(cme,zHo),e(lc,WHo),e(ur,QHo),e(ur,BA),e(BA,HHo),e(BA,fme),e(fme,UHo),e(BA,JHo),e(ur,YHo),e(ur,ft),g(xA,ft,null),e(ft,KHo),e(ft,mme),e(mme,ZHo),e(ft,eUo),e(ft,ic),e(ic,oUo),e(ic,gme),e(gme,rUo),e(ic,tUo),e(ic,hme),e(hme,aUo),e(ic,nUo),e(ft,sUo),e(ft,pme),e(pme,lUo),e(ft,iUo),g(kA,ft,null),e(ur,dUo),e(ur,ao),g(RA,ao,null),e(ao,cUo),e(ao,_me),e(_me,fUo),e(ao,mUo),e(ao,hn),e(hn,gUo),e(hn,ume),e(ume,hUo),e(hn,pUo),e(hn,bme),e(bme,_Uo),e(hn,uUo),e(hn,vme),e(vme,bUo),e(hn,vUo),e(ao,TUo),e(ao,SA),e(SA,i6),e(i6,Tme),e(Tme,FUo),e(i6,CUo),e(i6,Cq),e(Cq,MUo),e(i6,EUo),e(SA,yUo),e(SA,d6),e(d6,Fme),e(Fme,wUo),e(d6,AUo),e(d6,Mq),e(Mq,LUo),e(d6,BUo),e(ao,xUo),e(ao,c6),e(c6,kUo),e(c6,Cme),e(Cme,RUo),e(c6,SUo),e(c6,Mme),e(Mme,PUo),e(ao,$Uo),e(ao,Eme),e(Eme,IUo),e(ao,NUo),g(PA,ao,null),b(c,fRe,u),b(c,dc,u),e(dc,f6),e(f6,yme),g($A,yme,null),e(dc,DUo),e(dc,wme),e(wme,jUo),b(c,mRe,u),b(c,br,u),g(IA,br,null),e(br,qUo),e(br,cc),e(cc,GUo),e(cc,Ame),e(Ame,OUo),e(cc,XUo),e(cc,Lme),e(Lme,VUo),e(cc,zUo),e(br,WUo),e(br,NA),e(NA,QUo),e(NA,Bme),e(Bme,HUo),e(NA,UUo),e(br,JUo),e(br,mt),g(DA,mt,null),e(mt,YUo),e(mt,xme),e(xme,KUo),e(mt,ZUo),e(mt,fc),e(fc,eJo),e(fc,kme),e(kme,oJo),e(fc,rJo),e(fc,Rme),e(Rme,tJo),e(fc,aJo),e(mt,nJo),e(mt,Sme),e(Sme,sJo),e(mt,lJo),g(jA,mt,null),e(br,iJo),e(br,no),g(qA,no,null),e(no,dJo),e(no,Pme),e(Pme,cJo),e(no,fJo),e(no,pn),e(pn,mJo),e(pn,$me),e($me,gJo),e(pn,hJo),e(pn,Ime),e(Ime,pJo),e(pn,_Jo),e(pn,Nme),e(Nme,uJo),e(pn,bJo),e(no,vJo),e(no,Dme),e(Dme,m6),e(m6,jme),e(jme,TJo),e(m6,FJo),e(m6,Eq),e(Eq,CJo),e(m6,MJo),e(no,EJo),e(no,g6),e(g6,yJo),e(g6,qme),e(qme,wJo),e(g6,AJo),e(g6,Gme),e(Gme,LJo),e(no,BJo),e(no,Ome),e(Ome,xJo),e(no,kJo),g(GA,no,null),b(c,gRe,u),b(c,mc,u),e(mc,h6),e(h6,Xme),g(OA,Xme,null),e(mc,RJo),e(mc,Vme),e(Vme,SJo),b(c,hRe,u),b(c,vr,u),g(XA,vr,null),e(vr,PJo),e(vr,gc),e(gc,$Jo),e(gc,zme),e(zme,IJo),e(gc,NJo),e(gc,Wme),e(Wme,DJo),e(gc,jJo),e(vr,qJo),e(vr,VA),e(VA,GJo),e(VA,Qme),e(Qme,OJo),e(VA,XJo),e(vr,VJo),e(vr,gt),g(zA,gt,null),e(gt,zJo),e(gt,Hme),e(Hme,WJo),e(gt,QJo),e(gt,hc),e(hc,HJo),e(hc,Ume),e(Ume,UJo),e(hc,JJo),e(hc,Jme),e(Jme,YJo),e(hc,KJo),e(gt,ZJo),e(gt,Yme),e(Yme,eYo),e(gt,oYo),g(WA,gt,null),e(vr,rYo),e(vr,ho),g(QA,ho,null),e(ho,tYo),e(ho,Kme),e(Kme,aYo),e(ho,nYo),e(ho,_n),e(_n,sYo),e(_n,Zme),e(Zme,lYo),e(_n,iYo),e(_n,ege),e(ege,dYo),e(_n,cYo),e(_n,oge),e(oge,fYo),e(_n,mYo),e(ho,gYo),e(ho,B),e(B,p6),e(p6,rge),e(rge,hYo),e(p6,pYo),e(p6,yq),e(yq,_Yo),e(p6,uYo),e(B,bYo),e(B,_6),e(_6,tge),e(tge,vYo),e(_6,TYo),e(_6,wq),e(wq,FYo),e(_6,CYo),e(B,MYo),e(B,u6),e(u6,age),e(age,EYo),e(u6,yYo),e(u6,Aq),e(Aq,wYo),e(u6,AYo),e(B,LYo),e(B,b6),e(b6,nge),e(nge,BYo),e(b6,xYo),e(b6,Lq),e(Lq,kYo),e(b6,RYo),e(B,SYo),e(B,v6),e(v6,sge),e(sge,PYo),e(v6,$Yo),e(v6,Bq),e(Bq,IYo),e(v6,NYo),e(B,DYo),e(B,T6),e(T6,lge),e(lge,jYo),e(T6,qYo),e(T6,xq),e(xq,GYo),e(T6,OYo),e(B,XYo),e(B,F6),e(F6,ige),e(ige,VYo),e(F6,zYo),e(F6,kq),e(kq,WYo),e(F6,QYo),e(B,HYo),e(B,C6),e(C6,dge),e(dge,UYo),e(C6,JYo),e(C6,Rq),e(Rq,YYo),e(C6,KYo),e(B,ZYo),e(B,M6),e(M6,cge),e(cge,eKo),e(M6,oKo),e(M6,Sq),e(Sq,rKo),e(M6,tKo),e(B,aKo),e(B,E6),e(E6,fge),e(fge,nKo),e(E6,sKo),e(E6,Pq),e(Pq,lKo),e(E6,iKo),e(B,dKo),e(B,y6),e(y6,mge),e(mge,cKo),e(y6,fKo),e(y6,$q),e($q,mKo),e(y6,gKo),e(B,hKo),e(B,w6),e(w6,gge),e(gge,pKo),e(w6,_Ko),e(w6,Iq),e(Iq,uKo),e(w6,bKo),e(B,vKo),e(B,A6),e(A6,hge),e(hge,TKo),e(A6,FKo),e(A6,Nq),e(Nq,CKo),e(A6,MKo),e(B,EKo),e(B,L6),e(L6,pge),e(pge,yKo),e(L6,wKo),e(L6,Dq),e(Dq,AKo),e(L6,LKo),e(B,BKo),e(B,B6),e(B6,_ge),e(_ge,xKo),e(B6,kKo),e(B6,jq),e(jq,RKo),e(B6,SKo),e(B,PKo),e(B,x6),e(x6,uge),e(uge,$Ko),e(x6,IKo),e(x6,qq),e(qq,NKo),e(x6,DKo),e(B,jKo),e(B,Gs),e(Gs,bge),e(bge,qKo),e(Gs,GKo),e(Gs,Gq),e(Gq,OKo),e(Gs,XKo),e(Gs,Oq),e(Oq,VKo),e(Gs,zKo),e(B,WKo),e(B,k6),e(k6,vge),e(vge,QKo),e(k6,HKo),e(k6,Xq),e(Xq,UKo),e(k6,JKo),e(B,YKo),e(B,R6),e(R6,Tge),e(Tge,KKo),e(R6,ZKo),e(R6,Vq),e(Vq,eZo),e(R6,oZo),e(B,rZo),e(B,S6),e(S6,Fge),e(Fge,tZo),e(S6,aZo),e(S6,zq),e(zq,nZo),e(S6,sZo),e(B,lZo),e(B,P6),e(P6,Cge),e(Cge,iZo),e(P6,dZo),e(P6,Wq),e(Wq,cZo),e(P6,fZo),e(B,mZo),e(B,$6),e($6,Mge),e(Mge,gZo),e($6,hZo),e($6,Qq),e(Qq,pZo),e($6,_Zo),e(B,uZo),e(B,I6),e(I6,Ege),e(Ege,bZo),e(I6,vZo),e(I6,Hq),e(Hq,TZo),e(I6,FZo),e(B,CZo),e(B,N6),e(N6,yge),e(yge,MZo),e(N6,EZo),e(N6,Uq),e(Uq,yZo),e(N6,wZo),e(B,AZo),e(B,D6),e(D6,wge),e(wge,LZo),e(D6,BZo),e(D6,Jq),e(Jq,xZo),e(D6,kZo),e(B,RZo),e(B,j6),e(j6,Age),e(Age,SZo),e(j6,PZo),e(j6,Yq),e(Yq,$Zo),e(j6,IZo),e(B,NZo),e(B,q6),e(q6,Lge),e(Lge,DZo),e(q6,jZo),e(q6,Kq),e(Kq,qZo),e(q6,GZo),e(B,OZo),e(B,G6),e(G6,Bge),e(Bge,XZo),e(G6,VZo),e(G6,Zq),e(Zq,zZo),e(G6,WZo),e(B,QZo),e(B,O6),e(O6,xge),e(xge,HZo),e(O6,UZo),e(O6,eG),e(eG,JZo),e(O6,YZo),e(B,KZo),e(B,X6),e(X6,kge),e(kge,ZZo),e(X6,eer),e(X6,oG),e(oG,oer),e(X6,rer),e(B,ter),e(B,V6),e(V6,Rge),e(Rge,aer),e(V6,ner),e(V6,rG),e(rG,ser),e(V6,ler),e(B,ier),e(B,z6),e(z6,Sge),e(Sge,der),e(z6,cer),e(z6,tG),e(tG,fer),e(z6,mer),e(B,ger),e(B,W6),e(W6,Pge),e(Pge,her),e(W6,per),e(W6,aG),e(aG,_er),e(W6,uer),e(B,ber),e(B,Q6),e(Q6,$ge),e($ge,ver),e(Q6,Ter),e(Q6,nG),e(nG,Fer),e(Q6,Cer),e(B,Mer),e(B,H6),e(H6,Ige),e(Ige,Eer),e(H6,yer),e(H6,sG),e(sG,wer),e(H6,Aer),e(B,Ler),e(B,U6),e(U6,Nge),e(Nge,Ber),e(U6,xer),e(U6,lG),e(lG,ker),e(U6,Rer),e(B,Ser),e(B,J6),e(J6,Dge),e(Dge,Per),e(J6,$er),e(J6,iG),e(iG,Ier),e(J6,Ner),e(B,Der),e(B,Y6),e(Y6,jge),e(jge,jer),e(Y6,qer),e(Y6,dG),e(dG,Ger),e(Y6,Oer),e(B,Xer),e(B,K6),e(K6,qge),e(qge,Ver),e(K6,zer),e(K6,cG),e(cG,Wer),e(K6,Qer),e(B,Her),e(B,Z6),e(Z6,Gge),e(Gge,Uer),e(Z6,Jer),e(Z6,fG),e(fG,Yer),e(Z6,Ker),e(B,Zer),e(B,eT),e(eT,Oge),e(Oge,eor),e(eT,oor),e(eT,mG),e(mG,ror),e(eT,tor),e(B,aor),e(B,oT),e(oT,Xge),e(Xge,nor),e(oT,sor),e(oT,gG),e(gG,lor),e(oT,ior),e(B,dor),e(B,rT),e(rT,Vge),e(Vge,cor),e(rT,mor),e(rT,hG),e(hG,gor),e(rT,hor),e(ho,por),e(ho,zge),e(zge,_or),e(ho,uor),g(HA,ho,null),b(c,pRe,u),b(c,pc,u),e(pc,tT),e(tT,Wge),g(UA,Wge,null),e(pc,bor),e(pc,Qge),e(Qge,vor),b(c,_Re,u),b(c,Tr,u),g(JA,Tr,null),e(Tr,Tor),e(Tr,_c),e(_c,For),e(_c,Hge),e(Hge,Cor),e(_c,Mor),e(_c,Uge),e(Uge,Eor),e(_c,yor),e(Tr,wor),e(Tr,YA),e(YA,Aor),e(YA,Jge),e(Jge,Lor),e(YA,Bor),e(Tr,xor),e(Tr,ht),g(KA,ht,null),e(ht,kor),e(ht,Yge),e(Yge,Ror),e(ht,Sor),e(ht,uc),e(uc,Por),e(uc,Kge),e(Kge,$or),e(uc,Ior),e(uc,Zge),e(Zge,Nor),e(uc,Dor),e(ht,jor),e(ht,ehe),e(ehe,qor),e(ht,Gor),g(ZA,ht,null),e(Tr,Oor),e(Tr,po),g(e0,po,null),e(po,Xor),e(po,ohe),e(ohe,Vor),e(po,zor),e(po,un),e(un,Wor),e(un,rhe),e(rhe,Qor),e(un,Hor),e(un,the),e(the,Uor),e(un,Jor),e(un,ahe),e(ahe,Yor),e(un,Kor),e(po,Zor),e(po,H),e(H,aT),e(aT,nhe),e(nhe,err),e(aT,orr),e(aT,pG),e(pG,rrr),e(aT,trr),e(H,arr),e(H,nT),e(nT,she),e(she,nrr),e(nT,srr),e(nT,_G),e(_G,lrr),e(nT,irr),e(H,drr),e(H,sT),e(sT,lhe),e(lhe,crr),e(sT,frr),e(sT,uG),e(uG,mrr),e(sT,grr),e(H,hrr),e(H,lT),e(lT,ihe),e(ihe,prr),e(lT,_rr),e(lT,bG),e(bG,urr),e(lT,brr),e(H,vrr),e(H,iT),e(iT,dhe),e(dhe,Trr),e(iT,Frr),e(iT,vG),e(vG,Crr),e(iT,Mrr),e(H,Err),e(H,dT),e(dT,che),e(che,yrr),e(dT,wrr),e(dT,TG),e(TG,Arr),e(dT,Lrr),e(H,Brr),e(H,cT),e(cT,fhe),e(fhe,xrr),e(cT,krr),e(cT,FG),e(FG,Rrr),e(cT,Srr),e(H,Prr),e(H,fT),e(fT,mhe),e(mhe,$rr),e(fT,Irr),e(fT,CG),e(CG,Nrr),e(fT,Drr),e(H,jrr),e(H,mT),e(mT,ghe),e(ghe,qrr),e(mT,Grr),e(mT,MG),e(MG,Orr),e(mT,Xrr),e(H,Vrr),e(H,gT),e(gT,hhe),e(hhe,zrr),e(gT,Wrr),e(gT,EG),e(EG,Qrr),e(gT,Hrr),e(H,Urr),e(H,hT),e(hT,phe),e(phe,Jrr),e(hT,Yrr),e(hT,yG),e(yG,Krr),e(hT,Zrr),e(H,etr),e(H,pT),e(pT,_he),e(_he,otr),e(pT,rtr),e(pT,wG),e(wG,ttr),e(pT,atr),e(H,ntr),e(H,_T),e(_T,uhe),e(uhe,str),e(_T,ltr),e(_T,AG),e(AG,itr),e(_T,dtr),e(H,ctr),e(H,uT),e(uT,bhe),e(bhe,ftr),e(uT,mtr),e(uT,LG),e(LG,gtr),e(uT,htr),e(H,ptr),e(H,bT),e(bT,vhe),e(vhe,_tr),e(bT,utr),e(bT,BG),e(BG,btr),e(bT,vtr),e(H,Ttr),e(H,vT),e(vT,The),e(The,Ftr),e(vT,Ctr),e(vT,xG),e(xG,Mtr),e(vT,Etr),e(H,ytr),e(H,TT),e(TT,Fhe),e(Fhe,wtr),e(TT,Atr),e(TT,kG),e(kG,Ltr),e(TT,Btr),e(H,xtr),e(H,FT),e(FT,Che),e(Che,ktr),e(FT,Rtr),e(FT,RG),e(RG,Str),e(FT,Ptr),e(H,$tr),e(H,CT),e(CT,Mhe),e(Mhe,Itr),e(CT,Ntr),e(CT,SG),e(SG,Dtr),e(CT,jtr),e(H,qtr),e(H,MT),e(MT,Ehe),e(Ehe,Gtr),e(MT,Otr),e(MT,PG),e(PG,Xtr),e(MT,Vtr),e(H,ztr),e(H,ET),e(ET,yhe),e(yhe,Wtr),e(ET,Qtr),e(ET,$G),e($G,Htr),e(ET,Utr),e(H,Jtr),e(H,yT),e(yT,whe),e(whe,Ytr),e(yT,Ktr),e(yT,IG),e(IG,Ztr),e(yT,ear),e(H,oar),e(H,wT),e(wT,Ahe),e(Ahe,rar),e(wT,tar),e(wT,NG),e(NG,aar),e(wT,nar),e(po,sar),e(po,Lhe),e(Lhe,lar),e(po,iar),g(o0,po,null),b(c,uRe,u),b(c,bc,u),e(bc,AT),e(AT,Bhe),g(r0,Bhe,null),e(bc,dar),e(bc,xhe),e(xhe,car),b(c,bRe,u),b(c,Fr,u),g(t0,Fr,null),e(Fr,far),e(Fr,vc),e(vc,mar),e(vc,khe),e(khe,gar),e(vc,har),e(vc,Rhe),e(Rhe,par),e(vc,_ar),e(Fr,uar),e(Fr,a0),e(a0,bar),e(a0,She),e(She,Tar),e(a0,Far),e(Fr,Car),e(Fr,pt),g(n0,pt,null),e(pt,Mar),e(pt,Phe),e(Phe,Ear),e(pt,yar),e(pt,Tc),e(Tc,war),e(Tc,$he),e($he,Aar),e(Tc,Lar),e(Tc,Ihe),e(Ihe,Bar),e(Tc,xar),e(pt,kar),e(pt,Nhe),e(Nhe,Rar),e(pt,Sar),g(s0,pt,null),e(Fr,Par),e(Fr,_o),g(l0,_o,null),e(_o,$ar),e(_o,Dhe),e(Dhe,Iar),e(_o,Nar),e(_o,bn),e(bn,Dar),e(bn,jhe),e(jhe,jar),e(bn,qar),e(bn,qhe),e(qhe,Gar),e(bn,Oar),e(bn,Ghe),e(Ghe,Xar),e(bn,Var),e(_o,zar),e(_o,ge),e(ge,LT),e(LT,Ohe),e(Ohe,War),e(LT,Qar),e(LT,DG),e(DG,Har),e(LT,Uar),e(ge,Jar),e(ge,BT),e(BT,Xhe),e(Xhe,Yar),e(BT,Kar),e(BT,jG),e(jG,Zar),e(BT,enr),e(ge,onr),e(ge,xT),e(xT,Vhe),e(Vhe,rnr),e(xT,tnr),e(xT,qG),e(qG,anr),e(xT,nnr),e(ge,snr),e(ge,kT),e(kT,zhe),e(zhe,lnr),e(kT,inr),e(kT,GG),e(GG,dnr),e(kT,cnr),e(ge,fnr),e(ge,RT),e(RT,Whe),e(Whe,mnr),e(RT,gnr),e(RT,OG),e(OG,hnr),e(RT,pnr),e(ge,_nr),e(ge,ST),e(ST,Qhe),e(Qhe,unr),e(ST,bnr),e(ST,XG),e(XG,vnr),e(ST,Tnr),e(ge,Fnr),e(ge,PT),e(PT,Hhe),e(Hhe,Cnr),e(PT,Mnr),e(PT,VG),e(VG,Enr),e(PT,ynr),e(ge,wnr),e(ge,$T),e($T,Uhe),e(Uhe,Anr),e($T,Lnr),e($T,zG),e(zG,Bnr),e($T,xnr),e(ge,knr),e(ge,IT),e(IT,Jhe),e(Jhe,Rnr),e(IT,Snr),e(IT,WG),e(WG,Pnr),e(IT,$nr),e(ge,Inr),e(ge,NT),e(NT,Yhe),e(Yhe,Nnr),e(NT,Dnr),e(NT,QG),e(QG,jnr),e(NT,qnr),e(ge,Gnr),e(ge,DT),e(DT,Khe),e(Khe,Onr),e(DT,Xnr),e(DT,HG),e(HG,Vnr),e(DT,znr),e(_o,Wnr),e(_o,Zhe),e(Zhe,Qnr),e(_o,Hnr),g(i0,_o,null),b(c,vRe,u),b(c,Fc,u),e(Fc,jT),e(jT,epe),g(d0,epe,null),e(Fc,Unr),e(Fc,ope),e(ope,Jnr),b(c,TRe,u),b(c,Cr,u),g(c0,Cr,null),e(Cr,Ynr),e(Cr,Cc),e(Cc,Knr),e(Cc,rpe),e(rpe,Znr),e(Cc,esr),e(Cc,tpe),e(tpe,osr),e(Cc,rsr),e(Cr,tsr),e(Cr,f0),e(f0,asr),e(f0,ape),e(ape,nsr),e(f0,ssr),e(Cr,lsr),e(Cr,_t),g(m0,_t,null),e(_t,isr),e(_t,npe),e(npe,dsr),e(_t,csr),e(_t,Mc),e(Mc,fsr),e(Mc,spe),e(spe,msr),e(Mc,gsr),e(Mc,lpe),e(lpe,hsr),e(Mc,psr),e(_t,_sr),e(_t,ipe),e(ipe,usr),e(_t,bsr),g(g0,_t,null),e(Cr,vsr),e(Cr,uo),g(h0,uo,null),e(uo,Tsr),e(uo,dpe),e(dpe,Fsr),e(uo,Csr),e(uo,vn),e(vn,Msr),e(vn,cpe),e(cpe,Esr),e(vn,ysr),e(vn,fpe),e(fpe,wsr),e(vn,Asr),e(vn,mpe),e(mpe,Lsr),e(vn,Bsr),e(uo,xsr),e(uo,p0),e(p0,qT),e(qT,gpe),e(gpe,ksr),e(qT,Rsr),e(qT,UG),e(UG,Ssr),e(qT,Psr),e(p0,$sr),e(p0,GT),e(GT,hpe),e(hpe,Isr),e(GT,Nsr),e(GT,JG),e(JG,Dsr),e(GT,jsr),e(uo,qsr),e(uo,ppe),e(ppe,Gsr),e(uo,Osr),g(_0,uo,null),b(c,FRe,u),b(c,Ec,u),e(Ec,OT),e(OT,_pe),g(u0,_pe,null),e(Ec,Xsr),e(Ec,upe),e(upe,Vsr),b(c,CRe,u),b(c,Mr,u),g(b0,Mr,null),e(Mr,zsr),e(Mr,yc),e(yc,Wsr),e(yc,bpe),e(bpe,Qsr),e(yc,Hsr),e(yc,vpe),e(vpe,Usr),e(yc,Jsr),e(Mr,Ysr),e(Mr,v0),e(v0,Ksr),e(v0,Tpe),e(Tpe,Zsr),e(v0,elr),e(Mr,olr),e(Mr,ut),g(T0,ut,null),e(ut,rlr),e(ut,Fpe),e(Fpe,tlr),e(ut,alr),e(ut,wc),e(wc,nlr),e(wc,Cpe),e(Cpe,slr),e(wc,llr),e(wc,Mpe),e(Mpe,ilr),e(wc,dlr),e(ut,clr),e(ut,Epe),e(Epe,flr),e(ut,mlr),g(F0,ut,null),e(Mr,glr),e(Mr,bo),g(C0,bo,null),e(bo,hlr),e(bo,ype),e(ype,plr),e(bo,_lr),e(bo,Tn),e(Tn,ulr),e(Tn,wpe),e(wpe,blr),e(Tn,vlr),e(Tn,Ape),e(Ape,Tlr),e(Tn,Flr),e(Tn,Lpe),e(Lpe,Clr),e(Tn,Mlr),e(bo,Elr),e(bo,J),e(J,XT),e(XT,Bpe),e(Bpe,ylr),e(XT,wlr),e(XT,YG),e(YG,Alr),e(XT,Llr),e(J,Blr),e(J,VT),e(VT,xpe),e(xpe,xlr),e(VT,klr),e(VT,KG),e(KG,Rlr),e(VT,Slr),e(J,Plr),e(J,zT),e(zT,kpe),e(kpe,$lr),e(zT,Ilr),e(zT,ZG),e(ZG,Nlr),e(zT,Dlr),e(J,jlr),e(J,WT),e(WT,Rpe),e(Rpe,qlr),e(WT,Glr),e(WT,eO),e(eO,Olr),e(WT,Xlr),e(J,Vlr),e(J,QT),e(QT,Spe),e(Spe,zlr),e(QT,Wlr),e(QT,oO),e(oO,Qlr),e(QT,Hlr),e(J,Ulr),e(J,HT),e(HT,Ppe),e(Ppe,Jlr),e(HT,Ylr),e(HT,rO),e(rO,Klr),e(HT,Zlr),e(J,eir),e(J,UT),e(UT,$pe),e($pe,oir),e(UT,rir),e(UT,tO),e(tO,tir),e(UT,air),e(J,nir),e(J,JT),e(JT,Ipe),e(Ipe,sir),e(JT,lir),e(JT,aO),e(aO,iir),e(JT,dir),e(J,cir),e(J,YT),e(YT,Npe),e(Npe,fir),e(YT,mir),e(YT,nO),e(nO,gir),e(YT,hir),e(J,pir),e(J,KT),e(KT,Dpe),e(Dpe,_ir),e(KT,uir),e(KT,sO),e(sO,bir),e(KT,vir),e(J,Tir),e(J,ZT),e(ZT,jpe),e(jpe,Fir),e(ZT,Cir),e(ZT,lO),e(lO,Mir),e(ZT,Eir),e(J,yir),e(J,eF),e(eF,qpe),e(qpe,wir),e(eF,Air),e(eF,iO),e(iO,Lir),e(eF,Bir),e(J,xir),e(J,oF),e(oF,Gpe),e(Gpe,kir),e(oF,Rir),e(oF,dO),e(dO,Sir),e(oF,Pir),e(J,$ir),e(J,rF),e(rF,Ope),e(Ope,Iir),e(rF,Nir),e(rF,cO),e(cO,Dir),e(rF,jir),e(J,qir),e(J,tF),e(tF,Xpe),e(Xpe,Gir),e(tF,Oir),e(tF,fO),e(fO,Xir),e(tF,Vir),e(J,zir),e(J,aF),e(aF,Vpe),e(Vpe,Wir),e(aF,Qir),e(aF,mO),e(mO,Hir),e(aF,Uir),e(J,Jir),e(J,nF),e(nF,zpe),e(zpe,Yir),e(nF,Kir),e(nF,gO),e(gO,Zir),e(nF,edr),e(J,odr),e(J,sF),e(sF,Wpe),e(Wpe,rdr),e(sF,tdr),e(sF,hO),e(hO,adr),e(sF,ndr),e(J,sdr),e(J,lF),e(lF,Qpe),e(Qpe,ldr),e(lF,idr),e(lF,pO),e(pO,ddr),e(lF,cdr),e(J,fdr),e(J,iF),e(iF,Hpe),e(Hpe,mdr),e(iF,gdr),e(iF,_O),e(_O,hdr),e(iF,pdr),e(bo,_dr),e(bo,Upe),e(Upe,udr),e(bo,bdr),g(M0,bo,null),b(c,MRe,u),b(c,Ac,u),e(Ac,dF),e(dF,Jpe),g(E0,Jpe,null),e(Ac,vdr),e(Ac,Ype),e(Ype,Tdr),b(c,ERe,u),b(c,Er,u),g(y0,Er,null),e(Er,Fdr),e(Er,Lc),e(Lc,Cdr),e(Lc,Kpe),e(Kpe,Mdr),e(Lc,Edr),e(Lc,Zpe),e(Zpe,ydr),e(Lc,wdr),e(Er,Adr),e(Er,w0),e(w0,Ldr),e(w0,e_e),e(e_e,Bdr),e(w0,xdr),e(Er,kdr),e(Er,bt),g(A0,bt,null),e(bt,Rdr),e(bt,o_e),e(o_e,Sdr),e(bt,Pdr),e(bt,Bc),e(Bc,$dr),e(Bc,r_e),e(r_e,Idr),e(Bc,Ndr),e(Bc,t_e),e(t_e,Ddr),e(Bc,jdr),e(bt,qdr),e(bt,a_e),e(a_e,Gdr),e(bt,Odr),g(L0,bt,null),e(Er,Xdr),e(Er,vo),g(B0,vo,null),e(vo,Vdr),e(vo,n_e),e(n_e,zdr),e(vo,Wdr),e(vo,Fn),e(Fn,Qdr),e(Fn,s_e),e(s_e,Hdr),e(Fn,Udr),e(Fn,l_e),e(l_e,Jdr),e(Fn,Ydr),e(Fn,i_e),e(i_e,Kdr),e(Fn,Zdr),e(vo,ecr),e(vo,_e),e(_e,cF),e(cF,d_e),e(d_e,ocr),e(cF,rcr),e(cF,uO),e(uO,tcr),e(cF,acr),e(_e,ncr),e(_e,fF),e(fF,c_e),e(c_e,scr),e(fF,lcr),e(fF,bO),e(bO,icr),e(fF,dcr),e(_e,ccr),e(_e,mF),e(mF,f_e),e(f_e,fcr),e(mF,mcr),e(mF,vO),e(vO,gcr),e(mF,hcr),e(_e,pcr),e(_e,gF),e(gF,m_e),e(m_e,_cr),e(gF,ucr),e(gF,TO),e(TO,bcr),e(gF,vcr),e(_e,Tcr),e(_e,hF),e(hF,g_e),e(g_e,Fcr),e(hF,Ccr),e(hF,FO),e(FO,Mcr),e(hF,Ecr),e(_e,ycr),e(_e,pF),e(pF,h_e),e(h_e,wcr),e(pF,Acr),e(pF,CO),e(CO,Lcr),e(pF,Bcr),e(_e,xcr),e(_e,_F),e(_F,p_e),e(p_e,kcr),e(_F,Rcr),e(_F,MO),e(MO,Scr),e(_F,Pcr),e(_e,$cr),e(_e,uF),e(uF,__e),e(__e,Icr),e(uF,Ncr),e(uF,EO),e(EO,Dcr),e(uF,jcr),e(_e,qcr),e(_e,bF),e(bF,u_e),e(u_e,Gcr),e(bF,Ocr),e(bF,yO),e(yO,Xcr),e(bF,Vcr),e(_e,zcr),e(_e,vF),e(vF,b_e),e(b_e,Wcr),e(vF,Qcr),e(vF,wO),e(wO,Hcr),e(vF,Ucr),e(vo,Jcr),e(vo,v_e),e(v_e,Ycr),e(vo,Kcr),g(x0,vo,null),b(c,yRe,u),b(c,xc,u),e(xc,TF),e(TF,T_e),g(k0,T_e,null),e(xc,Zcr),e(xc,F_e),e(F_e,efr),b(c,wRe,u),b(c,yr,u),g(R0,yr,null),e(yr,ofr),e(yr,kc),e(kc,rfr),e(kc,C_e),e(C_e,tfr),e(kc,afr),e(kc,M_e),e(M_e,nfr),e(kc,sfr),e(yr,lfr),e(yr,S0),e(S0,ifr),e(S0,E_e),e(E_e,dfr),e(S0,cfr),e(yr,ffr),e(yr,vt),g(P0,vt,null),e(vt,mfr),e(vt,y_e),e(y_e,gfr),e(vt,hfr),e(vt,Rc),e(Rc,pfr),e(Rc,w_e),e(w_e,_fr),e(Rc,ufr),e(Rc,A_e),e(A_e,bfr),e(Rc,vfr),e(vt,Tfr),e(vt,L_e),e(L_e,Ffr),e(vt,Cfr),g($0,vt,null),e(yr,Mfr),e(yr,To),g(I0,To,null),e(To,Efr),e(To,B_e),e(B_e,yfr),e(To,wfr),e(To,Cn),e(Cn,Afr),e(Cn,x_e),e(x_e,Lfr),e(Cn,Bfr),e(Cn,k_e),e(k_e,xfr),e(Cn,kfr),e(Cn,R_e),e(R_e,Rfr),e(Cn,Sfr),e(To,Pfr),e(To,V),e(V,FF),e(FF,S_e),e(S_e,$fr),e(FF,Ifr),e(FF,AO),e(AO,Nfr),e(FF,Dfr),e(V,jfr),e(V,CF),e(CF,P_e),e(P_e,qfr),e(CF,Gfr),e(CF,LO),e(LO,Ofr),e(CF,Xfr),e(V,Vfr),e(V,MF),e(MF,$_e),e($_e,zfr),e(MF,Wfr),e(MF,BO),e(BO,Qfr),e(MF,Hfr),e(V,Ufr),e(V,EF),e(EF,I_e),e(I_e,Jfr),e(EF,Yfr),e(EF,xO),e(xO,Kfr),e(EF,Zfr),e(V,emr),e(V,yF),e(yF,N_e),e(N_e,omr),e(yF,rmr),e(yF,kO),e(kO,tmr),e(yF,amr),e(V,nmr),e(V,wF),e(wF,D_e),e(D_e,smr),e(wF,lmr),e(wF,RO),e(RO,imr),e(wF,dmr),e(V,cmr),e(V,AF),e(AF,j_e),e(j_e,fmr),e(AF,mmr),e(AF,SO),e(SO,gmr),e(AF,hmr),e(V,pmr),e(V,LF),e(LF,q_e),e(q_e,_mr),e(LF,umr),e(LF,PO),e(PO,bmr),e(LF,vmr),e(V,Tmr),e(V,BF),e(BF,G_e),e(G_e,Fmr),e(BF,Cmr),e(BF,$O),e($O,Mmr),e(BF,Emr),e(V,ymr),e(V,xF),e(xF,O_e),e(O_e,wmr),e(xF,Amr),e(xF,IO),e(IO,Lmr),e(xF,Bmr),e(V,xmr),e(V,kF),e(kF,X_e),e(X_e,kmr),e(kF,Rmr),e(kF,NO),e(NO,Smr),e(kF,Pmr),e(V,$mr),e(V,RF),e(RF,V_e),e(V_e,Imr),e(RF,Nmr),e(RF,DO),e(DO,Dmr),e(RF,jmr),e(V,qmr),e(V,SF),e(SF,z_e),e(z_e,Gmr),e(SF,Omr),e(SF,jO),e(jO,Xmr),e(SF,Vmr),e(V,zmr),e(V,PF),e(PF,W_e),e(W_e,Wmr),e(PF,Qmr),e(PF,qO),e(qO,Hmr),e(PF,Umr),e(V,Jmr),e(V,$F),e($F,Q_e),e(Q_e,Ymr),e($F,Kmr),e($F,GO),e(GO,Zmr),e($F,egr),e(V,ogr),e(V,IF),e(IF,H_e),e(H_e,rgr),e(IF,tgr),e(IF,OO),e(OO,agr),e(IF,ngr),e(V,sgr),e(V,NF),e(NF,U_e),e(U_e,lgr),e(NF,igr),e(NF,XO),e(XO,dgr),e(NF,cgr),e(V,fgr),e(V,DF),e(DF,J_e),e(J_e,mgr),e(DF,ggr),e(DF,VO),e(VO,hgr),e(DF,pgr),e(V,_gr),e(V,jF),e(jF,Y_e),e(Y_e,ugr),e(jF,bgr),e(jF,zO),e(zO,vgr),e(jF,Tgr),e(V,Fgr),e(V,qF),e(qF,K_e),e(K_e,Cgr),e(qF,Mgr),e(qF,WO),e(WO,Egr),e(qF,ygr),e(V,wgr),e(V,GF),e(GF,Z_e),e(Z_e,Agr),e(GF,Lgr),e(GF,QO),e(QO,Bgr),e(GF,xgr),e(V,kgr),e(V,OF),e(OF,eue),e(eue,Rgr),e(OF,Sgr),e(OF,HO),e(HO,Pgr),e(OF,$gr),e(V,Igr),e(V,XF),e(XF,oue),e(oue,Ngr),e(XF,Dgr),e(XF,UO),e(UO,jgr),e(XF,qgr),e(V,Ggr),e(V,VF),e(VF,rue),e(rue,Ogr),e(VF,Xgr),e(VF,JO),e(JO,Vgr),e(VF,zgr),e(V,Wgr),e(V,zF),e(zF,tue),e(tue,Qgr),e(zF,Hgr),e(zF,YO),e(YO,Ugr),e(zF,Jgr),e(To,Ygr),e(To,aue),e(aue,Kgr),e(To,Zgr),g(N0,To,null),b(c,ARe,u),b(c,Sc,u),e(Sc,WF),e(WF,nue),g(D0,nue,null),e(Sc,ehr),e(Sc,sue),e(sue,ohr),b(c,LRe,u),b(c,wr,u),g(j0,wr,null),e(wr,rhr),e(wr,Pc),e(Pc,thr),e(Pc,lue),e(lue,ahr),e(Pc,nhr),e(Pc,iue),e(iue,shr),e(Pc,lhr),e(wr,ihr),e(wr,q0),e(q0,dhr),e(q0,due),e(due,chr),e(q0,fhr),e(wr,mhr),e(wr,Tt),g(G0,Tt,null),e(Tt,ghr),e(Tt,cue),e(cue,hhr),e(Tt,phr),e(Tt,$c),e($c,_hr),e($c,fue),e(fue,uhr),e($c,bhr),e($c,mue),e(mue,vhr),e($c,Thr),e(Tt,Fhr),e(Tt,gue),e(gue,Chr),e(Tt,Mhr),g(O0,Tt,null),e(wr,Ehr),e(wr,Fo),g(X0,Fo,null),e(Fo,yhr),e(Fo,hue),e(hue,whr),e(Fo,Ahr),e(Fo,Mn),e(Mn,Lhr),e(Mn,pue),e(pue,Bhr),e(Mn,xhr),e(Mn,_ue),e(_ue,khr),e(Mn,Rhr),e(Mn,uue),e(uue,Shr),e(Mn,Phr),e(Fo,$hr),e(Fo,ae),e(ae,QF),e(QF,bue),e(bue,Ihr),e(QF,Nhr),e(QF,KO),e(KO,Dhr),e(QF,jhr),e(ae,qhr),e(ae,HF),e(HF,vue),e(vue,Ghr),e(HF,Ohr),e(HF,ZO),e(ZO,Xhr),e(HF,Vhr),e(ae,zhr),e(ae,UF),e(UF,Tue),e(Tue,Whr),e(UF,Qhr),e(UF,eX),e(eX,Hhr),e(UF,Uhr),e(ae,Jhr),e(ae,JF),e(JF,Fue),e(Fue,Yhr),e(JF,Khr),e(JF,oX),e(oX,Zhr),e(JF,epr),e(ae,opr),e(ae,YF),e(YF,Cue),e(Cue,rpr),e(YF,tpr),e(YF,rX),e(rX,apr),e(YF,npr),e(ae,spr),e(ae,KF),e(KF,Mue),e(Mue,lpr),e(KF,ipr),e(KF,tX),e(tX,dpr),e(KF,cpr),e(ae,fpr),e(ae,ZF),e(ZF,Eue),e(Eue,mpr),e(ZF,gpr),e(ZF,aX),e(aX,hpr),e(ZF,ppr),e(ae,_pr),e(ae,eC),e(eC,yue),e(yue,upr),e(eC,bpr),e(eC,nX),e(nX,vpr),e(eC,Tpr),e(ae,Fpr),e(ae,oC),e(oC,wue),e(wue,Cpr),e(oC,Mpr),e(oC,sX),e(sX,Epr),e(oC,ypr),e(ae,wpr),e(ae,rC),e(rC,Aue),e(Aue,Apr),e(rC,Lpr),e(rC,lX),e(lX,Bpr),e(rC,xpr),e(ae,kpr),e(ae,tC),e(tC,Lue),e(Lue,Rpr),e(tC,Spr),e(tC,iX),e(iX,Ppr),e(tC,$pr),e(ae,Ipr),e(ae,aC),e(aC,Bue),e(Bue,Npr),e(aC,Dpr),e(aC,dX),e(dX,jpr),e(aC,qpr),e(ae,Gpr),e(ae,nC),e(nC,xue),e(xue,Opr),e(nC,Xpr),e(nC,cX),e(cX,Vpr),e(nC,zpr),e(ae,Wpr),e(ae,sC),e(sC,kue),e(kue,Qpr),e(sC,Hpr),e(sC,fX),e(fX,Upr),e(sC,Jpr),e(ae,Ypr),e(ae,lC),e(lC,Rue),e(Rue,Kpr),e(lC,Zpr),e(lC,mX),e(mX,e_r),e(lC,o_r),e(ae,r_r),e(ae,iC),e(iC,Sue),e(Sue,t_r),e(iC,a_r),e(iC,gX),e(gX,n_r),e(iC,s_r),e(ae,l_r),e(ae,dC),e(dC,Pue),e(Pue,i_r),e(dC,d_r),e(dC,hX),e(hX,c_r),e(dC,f_r),e(Fo,m_r),e(Fo,$ue),e($ue,g_r),e(Fo,h_r),g(V0,Fo,null),b(c,BRe,u),b(c,Ic,u),e(Ic,cC),e(cC,Iue),g(z0,Iue,null),e(Ic,p_r),e(Ic,Nue),e(Nue,__r),b(c,xRe,u),b(c,Ar,u),g(W0,Ar,null),e(Ar,u_r),e(Ar,Nc),e(Nc,b_r),e(Nc,Due),e(Due,v_r),e(Nc,T_r),e(Nc,jue),e(jue,F_r),e(Nc,C_r),e(Ar,M_r),e(Ar,Q0),e(Q0,E_r),e(Q0,que),e(que,y_r),e(Q0,w_r),e(Ar,A_r),e(Ar,Ft),g(H0,Ft,null),e(Ft,L_r),e(Ft,Gue),e(Gue,B_r),e(Ft,x_r),e(Ft,Dc),e(Dc,k_r),e(Dc,Oue),e(Oue,R_r),e(Dc,S_r),e(Dc,Xue),e(Xue,P_r),e(Dc,$_r),e(Ft,I_r),e(Ft,Vue),e(Vue,N_r),e(Ft,D_r),g(U0,Ft,null),e(Ar,j_r),e(Ar,Co),g(J0,Co,null),e(Co,q_r),e(Co,zue),e(zue,G_r),e(Co,O_r),e(Co,En),e(En,X_r),e(En,Wue),e(Wue,V_r),e(En,z_r),e(En,Que),e(Que,W_r),e(En,Q_r),e(En,Hue),e(Hue,H_r),e(En,U_r),e(Co,J_r),e(Co,Uue),e(Uue,fC),e(fC,Jue),e(Jue,Y_r),e(fC,K_r),e(fC,pX),e(pX,Z_r),e(fC,eur),e(Co,our),e(Co,Yue),e(Yue,rur),e(Co,tur),g(Y0,Co,null),b(c,kRe,u),b(c,jc,u),e(jc,mC),e(mC,Kue),g(K0,Kue,null),e(jc,aur),e(jc,Zue),e(Zue,nur),b(c,RRe,u),b(c,Lr,u),g(Z0,Lr,null),e(Lr,sur),e(Lr,qc),e(qc,lur),e(qc,e5e),e(e5e,iur),e(qc,dur),e(qc,o5e),e(o5e,cur),e(qc,fur),e(Lr,mur),e(Lr,eL),e(eL,gur),e(eL,r5e),e(r5e,hur),e(eL,pur),e(Lr,_ur),e(Lr,Ct),g(oL,Ct,null),e(Ct,uur),e(Ct,t5e),e(t5e,bur),e(Ct,vur),e(Ct,Gc),e(Gc,Tur),e(Gc,a5e),e(a5e,Fur),e(Gc,Cur),e(Gc,n5e),e(n5e,Mur),e(Gc,Eur),e(Ct,yur),e(Ct,s5e),e(s5e,wur),e(Ct,Aur),g(rL,Ct,null),e(Lr,Lur),e(Lr,Mo),g(tL,Mo,null),e(Mo,Bur),e(Mo,l5e),e(l5e,xur),e(Mo,kur),e(Mo,yn),e(yn,Rur),e(yn,i5e),e(i5e,Sur),e(yn,Pur),e(yn,d5e),e(d5e,$ur),e(yn,Iur),e(yn,c5e),e(c5e,Nur),e(yn,Dur),e(Mo,jur),e(Mo,Y),e(Y,gC),e(gC,f5e),e(f5e,qur),e(gC,Gur),e(gC,_X),e(_X,Our),e(gC,Xur),e(Y,Vur),e(Y,hC),e(hC,m5e),e(m5e,zur),e(hC,Wur),e(hC,uX),e(uX,Qur),e(hC,Hur),e(Y,Uur),e(Y,pC),e(pC,g5e),e(g5e,Jur),e(pC,Yur),e(pC,bX),e(bX,Kur),e(pC,Zur),e(Y,e5r),e(Y,_C),e(_C,h5e),e(h5e,o5r),e(_C,r5r),e(_C,vX),e(vX,t5r),e(_C,a5r),e(Y,n5r),e(Y,uC),e(uC,p5e),e(p5e,s5r),e(uC,l5r),e(uC,TX),e(TX,i5r),e(uC,d5r),e(Y,c5r),e(Y,bC),e(bC,_5e),e(_5e,f5r),e(bC,m5r),e(bC,FX),e(FX,g5r),e(bC,h5r),e(Y,p5r),e(Y,vC),e(vC,u5e),e(u5e,_5r),e(vC,u5r),e(vC,CX),e(CX,b5r),e(vC,v5r),e(Y,T5r),e(Y,TC),e(TC,b5e),e(b5e,F5r),e(TC,C5r),e(TC,MX),e(MX,M5r),e(TC,E5r),e(Y,y5r),e(Y,FC),e(FC,v5e),e(v5e,w5r),e(FC,A5r),e(FC,EX),e(EX,L5r),e(FC,B5r),e(Y,x5r),e(Y,CC),e(CC,T5e),e(T5e,k5r),e(CC,R5r),e(CC,yX),e(yX,S5r),e(CC,P5r),e(Y,$5r),e(Y,MC),e(MC,F5e),e(F5e,I5r),e(MC,N5r),e(MC,wX),e(wX,D5r),e(MC,j5r),e(Y,q5r),e(Y,EC),e(EC,C5e),e(C5e,G5r),e(EC,O5r),e(EC,AX),e(AX,X5r),e(EC,V5r),e(Y,z5r),e(Y,yC),e(yC,M5e),e(M5e,W5r),e(yC,Q5r),e(yC,LX),e(LX,H5r),e(yC,U5r),e(Y,J5r),e(Y,wC),e(wC,E5e),e(E5e,Y5r),e(wC,K5r),e(wC,BX),e(BX,Z5r),e(wC,e2r),e(Y,o2r),e(Y,AC),e(AC,y5e),e(y5e,r2r),e(AC,t2r),e(AC,xX),e(xX,a2r),e(AC,n2r),e(Y,s2r),e(Y,LC),e(LC,w5e),e(w5e,l2r),e(LC,i2r),e(LC,kX),e(kX,d2r),e(LC,c2r),e(Y,f2r),e(Y,BC),e(BC,A5e),e(A5e,m2r),e(BC,g2r),e(BC,RX),e(RX,h2r),e(BC,p2r),e(Y,_2r),e(Y,xC),e(xC,L5e),e(L5e,u2r),e(xC,b2r),e(xC,SX),e(SX,v2r),e(xC,T2r),e(Y,F2r),e(Y,kC),e(kC,B5e),e(B5e,C2r),e(kC,M2r),e(kC,PX),e(PX,E2r),e(kC,y2r),e(Y,w2r),e(Y,RC),e(RC,x5e),e(x5e,A2r),e(RC,L2r),e(RC,$X),e($X,B2r),e(RC,x2r),e(Mo,k2r),e(Mo,k5e),e(k5e,R2r),e(Mo,S2r),g(aL,Mo,null),b(c,SRe,u),b(c,Oc,u),e(Oc,SC),e(SC,R5e),g(nL,R5e,null),e(Oc,P2r),e(Oc,S5e),e(S5e,$2r),b(c,PRe,u),b(c,Br,u),g(sL,Br,null),e(Br,I2r),e(Br,Xc),e(Xc,N2r),e(Xc,P5e),e(P5e,D2r),e(Xc,j2r),e(Xc,$5e),e($5e,q2r),e(Xc,G2r),e(Br,O2r),e(Br,lL),e(lL,X2r),e(lL,I5e),e(I5e,V2r),e(lL,z2r),e(Br,W2r),e(Br,Mt),g(iL,Mt,null),e(Mt,Q2r),e(Mt,N5e),e(N5e,H2r),e(Mt,U2r),e(Mt,Vc),e(Vc,J2r),e(Vc,D5e),e(D5e,Y2r),e(Vc,K2r),e(Vc,j5e),e(j5e,Z2r),e(Vc,e1r),e(Mt,o1r),e(Mt,q5e),e(q5e,r1r),e(Mt,t1r),g(dL,Mt,null),e(Br,a1r),e(Br,Eo),g(cL,Eo,null),e(Eo,n1r),e(Eo,G5e),e(G5e,s1r),e(Eo,l1r),e(Eo,wn),e(wn,i1r),e(wn,O5e),e(O5e,d1r),e(wn,c1r),e(wn,X5e),e(X5e,f1r),e(wn,m1r),e(wn,V5e),e(V5e,g1r),e(wn,h1r),e(Eo,p1r),e(Eo,Z),e(Z,PC),e(PC,z5e),e(z5e,_1r),e(PC,u1r),e(PC,IX),e(IX,b1r),e(PC,v1r),e(Z,T1r),e(Z,$C),e($C,W5e),e(W5e,F1r),e($C,C1r),e($C,NX),e(NX,M1r),e($C,E1r),e(Z,y1r),e(Z,IC),e(IC,Q5e),e(Q5e,w1r),e(IC,A1r),e(IC,DX),e(DX,L1r),e(IC,B1r),e(Z,x1r),e(Z,NC),e(NC,H5e),e(H5e,k1r),e(NC,R1r),e(NC,jX),e(jX,S1r),e(NC,P1r),e(Z,$1r),e(Z,DC),e(DC,U5e),e(U5e,I1r),e(DC,N1r),e(DC,qX),e(qX,D1r),e(DC,j1r),e(Z,q1r),e(Z,jC),e(jC,J5e),e(J5e,G1r),e(jC,O1r),e(jC,GX),e(GX,X1r),e(jC,V1r),e(Z,z1r),e(Z,qC),e(qC,Y5e),e(Y5e,W1r),e(qC,Q1r),e(qC,OX),e(OX,H1r),e(qC,U1r),e(Z,J1r),e(Z,GC),e(GC,K5e),e(K5e,Y1r),e(GC,K1r),e(GC,XX),e(XX,Z1r),e(GC,ebr),e(Z,obr),e(Z,OC),e(OC,Z5e),e(Z5e,rbr),e(OC,tbr),e(OC,VX),e(VX,abr),e(OC,nbr),e(Z,sbr),e(Z,XC),e(XC,e2e),e(e2e,lbr),e(XC,ibr),e(XC,zX),e(zX,dbr),e(XC,cbr),e(Z,fbr),e(Z,VC),e(VC,o2e),e(o2e,mbr),e(VC,gbr),e(VC,WX),e(WX,hbr),e(VC,pbr),e(Z,_br),e(Z,zC),e(zC,r2e),e(r2e,ubr),e(zC,bbr),e(zC,QX),e(QX,vbr),e(zC,Tbr),e(Z,Fbr),e(Z,WC),e(WC,t2e),e(t2e,Cbr),e(WC,Mbr),e(WC,HX),e(HX,Ebr),e(WC,ybr),e(Z,wbr),e(Z,QC),e(QC,a2e),e(a2e,Abr),e(QC,Lbr),e(QC,UX),e(UX,Bbr),e(QC,xbr),e(Z,kbr),e(Z,HC),e(HC,n2e),e(n2e,Rbr),e(HC,Sbr),e(HC,JX),e(JX,Pbr),e(HC,$br),e(Z,Ibr),e(Z,UC),e(UC,s2e),e(s2e,Nbr),e(UC,Dbr),e(UC,YX),e(YX,jbr),e(UC,qbr),e(Z,Gbr),e(Z,JC),e(JC,l2e),e(l2e,Obr),e(JC,Xbr),e(JC,KX),e(KX,Vbr),e(JC,zbr),e(Z,Wbr),e(Z,YC),e(YC,i2e),e(i2e,Qbr),e(YC,Hbr),e(YC,ZX),e(ZX,Ubr),e(YC,Jbr),e(Z,Ybr),e(Z,KC),e(KC,d2e),e(d2e,Kbr),e(KC,Zbr),e(KC,eV),e(eV,evr),e(KC,ovr),e(Eo,rvr),e(Eo,c2e),e(c2e,tvr),e(Eo,avr),g(fL,Eo,null),b(c,$Re,u),b(c,zc,u),e(zc,ZC),e(ZC,f2e),g(mL,f2e,null),e(zc,nvr),e(zc,m2e),e(m2e,svr),b(c,IRe,u),b(c,xr,u),g(gL,xr,null),e(xr,lvr),e(xr,Wc),e(Wc,ivr),e(Wc,g2e),e(g2e,dvr),e(Wc,cvr),e(Wc,h2e),e(h2e,fvr),e(Wc,mvr),e(xr,gvr),e(xr,hL),e(hL,hvr),e(hL,p2e),e(p2e,pvr),e(hL,_vr),e(xr,uvr),e(xr,Et),g(pL,Et,null),e(Et,bvr),e(Et,_2e),e(_2e,vvr),e(Et,Tvr),e(Et,Qc),e(Qc,Fvr),e(Qc,u2e),e(u2e,Cvr),e(Qc,Mvr),e(Qc,b2e),e(b2e,Evr),e(Qc,yvr),e(Et,wvr),e(Et,v2e),e(v2e,Avr),e(Et,Lvr),g(_L,Et,null),e(xr,Bvr),e(xr,yo),g(uL,yo,null),e(yo,xvr),e(yo,T2e),e(T2e,kvr),e(yo,Rvr),e(yo,An),e(An,Svr),e(An,F2e),e(F2e,Pvr),e(An,$vr),e(An,C2e),e(C2e,Ivr),e(An,Nvr),e(An,M2e),e(M2e,Dvr),e(An,jvr),e(yo,qvr),e(yo,E2e),e(E2e,eM),e(eM,y2e),e(y2e,Gvr),e(eM,Ovr),e(eM,oV),e(oV,Xvr),e(eM,Vvr),e(yo,zvr),e(yo,w2e),e(w2e,Wvr),e(yo,Qvr),g(bL,yo,null),b(c,NRe,u),b(c,Hc,u),e(Hc,oM),e(oM,A2e),g(vL,A2e,null),e(Hc,Hvr),e(Hc,L2e),e(L2e,Uvr),b(c,DRe,u),b(c,kr,u),g(TL,kr,null),e(kr,Jvr),e(kr,Uc),e(Uc,Yvr),e(Uc,B2e),e(B2e,Kvr),e(Uc,Zvr),e(Uc,x2e),e(x2e,e6r),e(Uc,o6r),e(kr,r6r),e(kr,FL),e(FL,t6r),e(FL,k2e),e(k2e,a6r),e(FL,n6r),e(kr,s6r),e(kr,yt),g(CL,yt,null),e(yt,l6r),e(yt,R2e),e(R2e,i6r),e(yt,d6r),e(yt,Jc),e(Jc,c6r),e(Jc,S2e),e(S2e,f6r),e(Jc,m6r),e(Jc,P2e),e(P2e,g6r),e(Jc,h6r),e(yt,p6r),e(yt,$2e),e($2e,_6r),e(yt,u6r),g(ML,yt,null),e(kr,b6r),e(kr,wo),g(EL,wo,null),e(wo,v6r),e(wo,I2e),e(I2e,T6r),e(wo,F6r),e(wo,Ln),e(Ln,C6r),e(Ln,N2e),e(N2e,M6r),e(Ln,E6r),e(Ln,D2e),e(D2e,y6r),e(Ln,w6r),e(Ln,j2e),e(j2e,A6r),e(Ln,L6r),e(wo,B6r),e(wo,q2e),e(q2e,rM),e(rM,G2e),e(G2e,x6r),e(rM,k6r),e(rM,rV),e(rV,R6r),e(rM,S6r),e(wo,P6r),e(wo,O2e),e(O2e,$6r),e(wo,I6r),g(yL,wo,null),b(c,jRe,u),b(c,Yc,u),e(Yc,tM),e(tM,X2e),g(wL,X2e,null),e(Yc,N6r),e(Yc,V2e),e(V2e,D6r),b(c,qRe,u),b(c,Rr,u),g(AL,Rr,null),e(Rr,j6r),e(Rr,Kc),e(Kc,q6r),e(Kc,z2e),e(z2e,G6r),e(Kc,O6r),e(Kc,W2e),e(W2e,X6r),e(Kc,V6r),e(Rr,z6r),e(Rr,LL),e(LL,W6r),e(LL,Q2e),e(Q2e,Q6r),e(LL,H6r),e(Rr,U6r),e(Rr,wt),g(BL,wt,null),e(wt,J6r),e(wt,H2e),e(H2e,Y6r),e(wt,K6r),e(wt,Zc),e(Zc,Z6r),e(Zc,U2e),e(U2e,eTr),e(Zc,oTr),e(Zc,J2e),e(J2e,rTr),e(Zc,tTr),e(wt,aTr),e(wt,Y2e),e(Y2e,nTr),e(wt,sTr),g(xL,wt,null),e(Rr,lTr),e(Rr,Ao),g(kL,Ao,null),e(Ao,iTr),e(Ao,K2e),e(K2e,dTr),e(Ao,cTr),e(Ao,Bn),e(Bn,fTr),e(Bn,Z2e),e(Z2e,mTr),e(Bn,gTr),e(Bn,e1e),e(e1e,hTr),e(Bn,pTr),e(Bn,o1e),e(o1e,_Tr),e(Bn,uTr),e(Ao,bTr),e(Ao,z),e(z,aM),e(aM,r1e),e(r1e,vTr),e(aM,TTr),e(aM,tV),e(tV,FTr),e(aM,CTr),e(z,MTr),e(z,nM),e(nM,t1e),e(t1e,ETr),e(nM,yTr),e(nM,aV),e(aV,wTr),e(nM,ATr),e(z,LTr),e(z,sM),e(sM,a1e),e(a1e,BTr),e(sM,xTr),e(sM,nV),e(nV,kTr),e(sM,RTr),e(z,STr),e(z,lM),e(lM,n1e),e(n1e,PTr),e(lM,$Tr),e(lM,sV),e(sV,ITr),e(lM,NTr),e(z,DTr),e(z,iM),e(iM,s1e),e(s1e,jTr),e(iM,qTr),e(iM,lV),e(lV,GTr),e(iM,OTr),e(z,XTr),e(z,dM),e(dM,l1e),e(l1e,VTr),e(dM,zTr),e(dM,iV),e(iV,WTr),e(dM,QTr),e(z,HTr),e(z,cM),e(cM,i1e),e(i1e,UTr),e(cM,JTr),e(cM,dV),e(dV,YTr),e(cM,KTr),e(z,ZTr),e(z,fM),e(fM,d1e),e(d1e,eFr),e(fM,oFr),e(fM,cV),e(cV,rFr),e(fM,tFr),e(z,aFr),e(z,mM),e(mM,c1e),e(c1e,nFr),e(mM,sFr),e(mM,fV),e(fV,lFr),e(mM,iFr),e(z,dFr),e(z,gM),e(gM,f1e),e(f1e,cFr),e(gM,fFr),e(gM,mV),e(mV,mFr),e(gM,gFr),e(z,hFr),e(z,hM),e(hM,m1e),e(m1e,pFr),e(hM,_Fr),e(hM,gV),e(gV,uFr),e(hM,bFr),e(z,vFr),e(z,pM),e(pM,g1e),e(g1e,TFr),e(pM,FFr),e(pM,hV),e(hV,CFr),e(pM,MFr),e(z,EFr),e(z,_M),e(_M,h1e),e(h1e,yFr),e(_M,wFr),e(_M,pV),e(pV,AFr),e(_M,LFr),e(z,BFr),e(z,uM),e(uM,p1e),e(p1e,xFr),e(uM,kFr),e(uM,_V),e(_V,RFr),e(uM,SFr),e(z,PFr),e(z,bM),e(bM,_1e),e(_1e,$Fr),e(bM,IFr),e(bM,uV),e(uV,NFr),e(bM,DFr),e(z,jFr),e(z,vM),e(vM,u1e),e(u1e,qFr),e(vM,GFr),e(vM,bV),e(bV,OFr),e(vM,XFr),e(z,VFr),e(z,TM),e(TM,b1e),e(b1e,zFr),e(TM,WFr),e(TM,vV),e(vV,QFr),e(TM,HFr),e(z,UFr),e(z,FM),e(FM,v1e),e(v1e,JFr),e(FM,YFr),e(FM,TV),e(TV,KFr),e(FM,ZFr),e(z,eCr),e(z,CM),e(CM,T1e),e(T1e,oCr),e(CM,rCr),e(CM,FV),e(FV,tCr),e(CM,aCr),e(z,nCr),e(z,MM),e(MM,F1e),e(F1e,sCr),e(MM,lCr),e(MM,CV),e(CV,iCr),e(MM,dCr),e(z,cCr),e(z,EM),e(EM,C1e),e(C1e,fCr),e(EM,mCr),e(EM,MV),e(MV,gCr),e(EM,hCr),e(z,pCr),e(z,yM),e(yM,M1e),e(M1e,_Cr),e(yM,uCr),e(yM,EV),e(EV,bCr),e(yM,vCr),e(z,TCr),e(z,wM),e(wM,E1e),e(E1e,FCr),e(wM,CCr),e(wM,yV),e(yV,MCr),e(wM,ECr),e(z,yCr),e(z,AM),e(AM,y1e),e(y1e,wCr),e(AM,ACr),e(AM,wV),e(wV,LCr),e(AM,BCr),e(z,xCr),e(z,LM),e(LM,w1e),e(w1e,kCr),e(LM,RCr),e(LM,AV),e(AV,SCr),e(LM,PCr),e(Ao,$Cr),e(Ao,A1e),e(A1e,ICr),e(Ao,NCr),g(RL,Ao,null),b(c,GRe,u),b(c,ef,u),e(ef,BM),e(BM,L1e),g(SL,L1e,null),e(ef,DCr),e(ef,B1e),e(B1e,jCr),b(c,ORe,u),b(c,Sr,u),g(PL,Sr,null),e(Sr,qCr),e(Sr,of),e(of,GCr),e(of,x1e),e(x1e,OCr),e(of,XCr),e(of,k1e),e(k1e,VCr),e(of,zCr),e(Sr,WCr),e(Sr,$L),e($L,QCr),e($L,R1e),e(R1e,HCr),e($L,UCr),e(Sr,JCr),e(Sr,At),g(IL,At,null),e(At,YCr),e(At,S1e),e(S1e,KCr),e(At,ZCr),e(At,rf),e(rf,eMr),e(rf,P1e),e(P1e,oMr),e(rf,rMr),e(rf,$1e),e($1e,tMr),e(rf,aMr),e(At,nMr),e(At,I1e),e(I1e,sMr),e(At,lMr),g(NL,At,null),e(Sr,iMr),e(Sr,Lo),g(DL,Lo,null),e(Lo,dMr),e(Lo,N1e),e(N1e,cMr),e(Lo,fMr),e(Lo,xn),e(xn,mMr),e(xn,D1e),e(D1e,gMr),e(xn,hMr),e(xn,j1e),e(j1e,pMr),e(xn,_Mr),e(xn,q1e),e(q1e,uMr),e(xn,bMr),e(Lo,vMr),e(Lo,ca),e(ca,xM),e(xM,G1e),e(G1e,TMr),e(xM,FMr),e(xM,LV),e(LV,CMr),e(xM,MMr),e(ca,EMr),e(ca,kM),e(kM,O1e),e(O1e,yMr),e(kM,wMr),e(kM,BV),e(BV,AMr),e(kM,LMr),e(ca,BMr),e(ca,RM),e(RM,X1e),e(X1e,xMr),e(RM,kMr),e(RM,xV),e(xV,RMr),e(RM,SMr),e(ca,PMr),e(ca,SM),e(SM,V1e),e(V1e,$Mr),e(SM,IMr),e(SM,kV),e(kV,NMr),e(SM,DMr),e(ca,jMr),e(ca,PM),e(PM,z1e),e(z1e,qMr),e(PM,GMr),e(PM,RV),e(RV,OMr),e(PM,XMr),e(Lo,VMr),e(Lo,W1e),e(W1e,zMr),e(Lo,WMr),g(jL,Lo,null),b(c,XRe,u),b(c,tf,u),e(tf,$M),e($M,Q1e),g(qL,Q1e,null),e(tf,QMr),e(tf,H1e),e(H1e,HMr),b(c,VRe,u),b(c,Pr,u),g(GL,Pr,null),e(Pr,UMr),e(Pr,af),e(af,JMr),e(af,U1e),e(U1e,YMr),e(af,KMr),e(af,J1e),e(J1e,ZMr),e(af,e4r),e(Pr,o4r),e(Pr,OL),e(OL,r4r),e(OL,Y1e),e(Y1e,t4r),e(OL,a4r),e(Pr,n4r),e(Pr,Lt),g(XL,Lt,null),e(Lt,s4r),e(Lt,K1e),e(K1e,l4r),e(Lt,i4r),e(Lt,nf),e(nf,d4r),e(nf,Z1e),e(Z1e,c4r),e(nf,f4r),e(nf,ebe),e(ebe,m4r),e(nf,g4r),e(Lt,h4r),e(Lt,obe),e(obe,p4r),e(Lt,_4r),g(VL,Lt,null),e(Pr,u4r),e(Pr,Bo),g(zL,Bo,null),e(Bo,b4r),e(Bo,rbe),e(rbe,v4r),e(Bo,T4r),e(Bo,kn),e(kn,F4r),e(kn,tbe),e(tbe,C4r),e(kn,M4r),e(kn,abe),e(abe,E4r),e(kn,y4r),e(kn,nbe),e(nbe,w4r),e(kn,A4r),e(Bo,L4r),e(Bo,ce),e(ce,IM),e(IM,sbe),e(sbe,B4r),e(IM,x4r),e(IM,SV),e(SV,k4r),e(IM,R4r),e(ce,S4r),e(ce,NM),e(NM,lbe),e(lbe,P4r),e(NM,$4r),e(NM,PV),e(PV,I4r),e(NM,N4r),e(ce,D4r),e(ce,DM),e(DM,ibe),e(ibe,j4r),e(DM,q4r),e(DM,$V),e($V,G4r),e(DM,O4r),e(ce,X4r),e(ce,jM),e(jM,dbe),e(dbe,V4r),e(jM,z4r),e(jM,IV),e(IV,W4r),e(jM,Q4r),e(ce,H4r),e(ce,qM),e(qM,cbe),e(cbe,U4r),e(qM,J4r),e(qM,NV),e(NV,Y4r),e(qM,K4r),e(ce,Z4r),e(ce,GM),e(GM,fbe),e(fbe,eEr),e(GM,oEr),e(GM,DV),e(DV,rEr),e(GM,tEr),e(ce,aEr),e(ce,OM),e(OM,mbe),e(mbe,nEr),e(OM,sEr),e(OM,jV),e(jV,lEr),e(OM,iEr),e(ce,dEr),e(ce,XM),e(XM,gbe),e(gbe,cEr),e(XM,fEr),e(XM,qV),e(qV,mEr),e(XM,gEr),e(ce,hEr),e(ce,VM),e(VM,hbe),e(hbe,pEr),e(VM,_Er),e(VM,GV),e(GV,uEr),e(VM,bEr),e(ce,vEr),e(ce,zM),e(zM,pbe),e(pbe,TEr),e(zM,FEr),e(zM,OV),e(OV,CEr),e(zM,MEr),e(ce,EEr),e(ce,WM),e(WM,_be),e(_be,yEr),e(WM,wEr),e(WM,XV),e(XV,AEr),e(WM,LEr),e(ce,BEr),e(ce,QM),e(QM,ube),e(ube,xEr),e(QM,kEr),e(QM,VV),e(VV,REr),e(QM,SEr),e(Bo,PEr),e(Bo,bbe),e(bbe,$Er),e(Bo,IEr),g(WL,Bo,null),b(c,zRe,u),b(c,sf,u),e(sf,HM),e(HM,vbe),g(QL,vbe,null),e(sf,NEr),e(sf,Tbe),e(Tbe,DEr),b(c,WRe,u),b(c,$r,u),g(HL,$r,null),e($r,jEr),e($r,lf),e(lf,qEr),e(lf,Fbe),e(Fbe,GEr),e(lf,OEr),e(lf,Cbe),e(Cbe,XEr),e(lf,VEr),e($r,zEr),e($r,UL),e(UL,WEr),e(UL,Mbe),e(Mbe,QEr),e(UL,HEr),e($r,UEr),e($r,Bt),g(JL,Bt,null),e(Bt,JEr),e(Bt,Ebe),e(Ebe,YEr),e(Bt,KEr),e(Bt,df),e(df,ZEr),e(df,ybe),e(ybe,e3r),e(df,o3r),e(df,wbe),e(wbe,r3r),e(df,t3r),e(Bt,a3r),e(Bt,Abe),e(Abe,n3r),e(Bt,s3r),g(YL,Bt,null),e($r,l3r),e($r,xo),g(KL,xo,null),e(xo,i3r),e(xo,Lbe),e(Lbe,d3r),e(xo,c3r),e(xo,Rn),e(Rn,f3r),e(Rn,Bbe),e(Bbe,m3r),e(Rn,g3r),e(Rn,xbe),e(xbe,h3r),e(Rn,p3r),e(Rn,kbe),e(kbe,_3r),e(Rn,u3r),e(xo,b3r),e(xo,ue),e(ue,UM),e(UM,Rbe),e(Rbe,v3r),e(UM,T3r),e(UM,zV),e(zV,F3r),e(UM,C3r),e(ue,M3r),e(ue,JM),e(JM,Sbe),e(Sbe,E3r),e(JM,y3r),e(JM,WV),e(WV,w3r),e(JM,A3r),e(ue,L3r),e(ue,YM),e(YM,Pbe),e(Pbe,B3r),e(YM,x3r),e(YM,QV),e(QV,k3r),e(YM,R3r),e(ue,S3r),e(ue,KM),e(KM,$be),e($be,P3r),e(KM,$3r),e(KM,HV),e(HV,I3r),e(KM,N3r),e(ue,D3r),e(ue,ZM),e(ZM,Ibe),e(Ibe,j3r),e(ZM,q3r),e(ZM,UV),e(UV,G3r),e(ZM,O3r),e(ue,X3r),e(ue,e4),e(e4,Nbe),e(Nbe,V3r),e(e4,z3r),e(e4,JV),e(JV,W3r),e(e4,Q3r),e(ue,H3r),e(ue,o4),e(o4,Dbe),e(Dbe,U3r),e(o4,J3r),e(o4,YV),e(YV,Y3r),e(o4,K3r),e(ue,Z3r),e(ue,r4),e(r4,jbe),e(jbe,eyr),e(r4,oyr),e(r4,KV),e(KV,ryr),e(r4,tyr),e(ue,ayr),e(ue,t4),e(t4,qbe),e(qbe,nyr),e(t4,syr),e(t4,ZV),e(ZV,lyr),e(t4,iyr),e(ue,dyr),e(ue,a4),e(a4,Gbe),e(Gbe,cyr),e(a4,fyr),e(a4,ez),e(ez,myr),e(a4,gyr),e(xo,hyr),e(xo,Obe),e(Obe,pyr),e(xo,_yr),g(ZL,xo,null),b(c,QRe,u),b(c,cf,u),e(cf,n4),e(n4,Xbe),g(e7,Xbe,null),e(cf,uyr),e(cf,Vbe),e(Vbe,byr),b(c,HRe,u),b(c,Ir,u),g(o7,Ir,null),e(Ir,vyr),e(Ir,ff),e(ff,Tyr),e(ff,zbe),e(zbe,Fyr),e(ff,Cyr),e(ff,Wbe),e(Wbe,Myr),e(ff,Eyr),e(Ir,yyr),e(Ir,r7),e(r7,wyr),e(r7,Qbe),e(Qbe,Ayr),e(r7,Lyr),e(Ir,Byr),e(Ir,xt),g(t7,xt,null),e(xt,xyr),e(xt,Hbe),e(Hbe,kyr),e(xt,Ryr),e(xt,mf),e(mf,Syr),e(mf,Ube),e(Ube,Pyr),e(mf,$yr),e(mf,Jbe),e(Jbe,Iyr),e(mf,Nyr),e(xt,Dyr),e(xt,Ybe),e(Ybe,jyr),e(xt,qyr),g(a7,xt,null),e(Ir,Gyr),e(Ir,ko),g(n7,ko,null),e(ko,Oyr),e(ko,Kbe),e(Kbe,Xyr),e(ko,Vyr),e(ko,Sn),e(Sn,zyr),e(Sn,Zbe),e(Zbe,Wyr),e(Sn,Qyr),e(Sn,eve),e(eve,Hyr),e(Sn,Uyr),e(Sn,ove),e(ove,Jyr),e(Sn,Yyr),e(ko,Kyr),e(ko,Me),e(Me,s4),e(s4,rve),e(rve,Zyr),e(s4,ewr),e(s4,oz),e(oz,owr),e(s4,rwr),e(Me,twr),e(Me,l4),e(l4,tve),e(tve,awr),e(l4,nwr),e(l4,rz),e(rz,swr),e(l4,lwr),e(Me,iwr),e(Me,i4),e(i4,ave),e(ave,dwr),e(i4,cwr),e(i4,tz),e(tz,fwr),e(i4,mwr),e(Me,gwr),e(Me,d4),e(d4,nve),e(nve,hwr),e(d4,pwr),e(d4,az),e(az,_wr),e(d4,uwr),e(Me,bwr),e(Me,c4),e(c4,sve),e(sve,vwr),e(c4,Twr),e(c4,nz),e(nz,Fwr),e(c4,Cwr),e(Me,Mwr),e(Me,f4),e(f4,lve),e(lve,Ewr),e(f4,ywr),e(f4,sz),e(sz,wwr),e(f4,Awr),e(Me,Lwr),e(Me,m4),e(m4,ive),e(ive,Bwr),e(m4,xwr),e(m4,lz),e(lz,kwr),e(m4,Rwr),e(Me,Swr),e(Me,g4),e(g4,dve),e(dve,Pwr),e(g4,$wr),e(g4,iz),e(iz,Iwr),e(g4,Nwr),e(Me,Dwr),e(Me,h4),e(h4,cve),e(cve,jwr),e(h4,qwr),e(h4,dz),e(dz,Gwr),e(h4,Owr),e(ko,Xwr),e(ko,fve),e(fve,Vwr),e(ko,zwr),g(s7,ko,null),b(c,URe,u),b(c,gf,u),e(gf,p4),e(p4,mve),g(l7,mve,null),e(gf,Wwr),e(gf,gve),e(gve,Qwr),b(c,JRe,u),b(c,Nr,u),g(i7,Nr,null),e(Nr,Hwr),e(Nr,hf),e(hf,Uwr),e(hf,hve),e(hve,Jwr),e(hf,Ywr),e(hf,pve),e(pve,Kwr),e(hf,Zwr),e(Nr,eAr),e(Nr,d7),e(d7,oAr),e(d7,_ve),e(_ve,rAr),e(d7,tAr),e(Nr,aAr),e(Nr,kt),g(c7,kt,null),e(kt,nAr),e(kt,uve),e(uve,sAr),e(kt,lAr),e(kt,pf),e(pf,iAr),e(pf,bve),e(bve,dAr),e(pf,cAr),e(pf,vve),e(vve,fAr),e(pf,mAr),e(kt,gAr),e(kt,Tve),e(Tve,hAr),e(kt,pAr),g(f7,kt,null),e(Nr,_Ar),e(Nr,Ro),g(m7,Ro,null),e(Ro,uAr),e(Ro,Fve),e(Fve,bAr),e(Ro,vAr),e(Ro,Pn),e(Pn,TAr),e(Pn,Cve),e(Cve,FAr),e(Pn,CAr),e(Pn,Mve),e(Mve,MAr),e(Pn,EAr),e(Pn,Eve),e(Eve,yAr),e(Pn,wAr),e(Ro,AAr),e(Ro,be),e(be,_4),e(_4,yve),e(yve,LAr),e(_4,BAr),e(_4,cz),e(cz,xAr),e(_4,kAr),e(be,RAr),e(be,u4),e(u4,wve),e(wve,SAr),e(u4,PAr),e(u4,fz),e(fz,$Ar),e(u4,IAr),e(be,NAr),e(be,b4),e(b4,Ave),e(Ave,DAr),e(b4,jAr),e(b4,mz),e(mz,qAr),e(b4,GAr),e(be,OAr),e(be,v4),e(v4,Lve),e(Lve,XAr),e(v4,VAr),e(v4,gz),e(gz,zAr),e(v4,WAr),e(be,QAr),e(be,T4),e(T4,Bve),e(Bve,HAr),e(T4,UAr),e(T4,hz),e(hz,JAr),e(T4,YAr),e(be,KAr),e(be,F4),e(F4,xve),e(xve,ZAr),e(F4,e0r),e(F4,pz),e(pz,o0r),e(F4,r0r),e(be,t0r),e(be,C4),e(C4,kve),e(kve,a0r),e(C4,n0r),e(C4,_z),e(_z,s0r),e(C4,l0r),e(be,i0r),e(be,M4),e(M4,Rve),e(Rve,d0r),e(M4,c0r),e(M4,uz),e(uz,f0r),e(M4,m0r),e(be,g0r),e(be,E4),e(E4,Sve),e(Sve,h0r),e(E4,p0r),e(E4,bz),e(bz,_0r),e(E4,u0r),e(be,b0r),e(be,y4),e(y4,Pve),e(Pve,v0r),e(y4,T0r),e(y4,vz),e(vz,F0r),e(y4,C0r),e(Ro,M0r),e(Ro,$ve),e($ve,E0r),e(Ro,y0r),g(g7,Ro,null),b(c,YRe,u),b(c,_f,u),e(_f,w4),e(w4,Ive),g(h7,Ive,null),e(_f,w0r),e(_f,Nve),e(Nve,A0r),b(c,KRe,u),b(c,Dr,u),g(p7,Dr,null),e(Dr,L0r),e(Dr,uf),e(uf,B0r),e(uf,Dve),e(Dve,x0r),e(uf,k0r),e(uf,jve),e(jve,R0r),e(uf,S0r),e(Dr,P0r),e(Dr,_7),e(_7,$0r),e(_7,qve),e(qve,I0r),e(_7,N0r),e(Dr,D0r),e(Dr,Rt),g(u7,Rt,null),e(Rt,j0r),e(Rt,Gve),e(Gve,q0r),e(Rt,G0r),e(Rt,bf),e(bf,O0r),e(bf,Ove),e(Ove,X0r),e(bf,V0r),e(bf,Xve),e(Xve,z0r),e(bf,W0r),e(Rt,Q0r),e(Rt,Vve),e(Vve,H0r),e(Rt,U0r),g(b7,Rt,null),e(Dr,J0r),e(Dr,So),g(v7,So,null),e(So,Y0r),e(So,zve),e(zve,K0r),e(So,Z0r),e(So,$n),e($n,eLr),e($n,Wve),e(Wve,oLr),e($n,rLr),e($n,Qve),e(Qve,tLr),e($n,aLr),e($n,Hve),e(Hve,nLr),e($n,sLr),e(So,lLr),e(So,ve),e(ve,A4),e(A4,Uve),e(Uve,iLr),e(A4,dLr),e(A4,Tz),e(Tz,cLr),e(A4,fLr),e(ve,mLr),e(ve,L4),e(L4,Jve),e(Jve,gLr),e(L4,hLr),e(L4,Fz),e(Fz,pLr),e(L4,_Lr),e(ve,uLr),e(ve,B4),e(B4,Yve),e(Yve,bLr),e(B4,vLr),e(B4,Cz),e(Cz,TLr),e(B4,FLr),e(ve,CLr),e(ve,x4),e(x4,Kve),e(Kve,MLr),e(x4,ELr),e(x4,Mz),e(Mz,yLr),e(x4,wLr),e(ve,ALr),e(ve,k4),e(k4,Zve),e(Zve,LLr),e(k4,BLr),e(k4,Ez),e(Ez,xLr),e(k4,kLr),e(ve,RLr),e(ve,R4),e(R4,e6e),e(e6e,SLr),e(R4,PLr),e(R4,yz),e(yz,$Lr),e(R4,ILr),e(ve,NLr),e(ve,S4),e(S4,o6e),e(o6e,DLr),e(S4,jLr),e(S4,wz),e(wz,qLr),e(S4,GLr),e(ve,OLr),e(ve,P4),e(P4,r6e),e(r6e,XLr),e(P4,VLr),e(P4,Az),e(Az,zLr),e(P4,WLr),e(ve,QLr),e(ve,$4),e($4,t6e),e(t6e,HLr),e($4,ULr),e($4,Lz),e(Lz,JLr),e($4,YLr),e(ve,KLr),e(ve,I4),e(I4,a6e),e(a6e,ZLr),e(I4,e7r),e(I4,Bz),e(Bz,o7r),e(I4,r7r),e(So,t7r),e(So,n6e),e(n6e,a7r),e(So,n7r),g(T7,So,null),b(c,ZRe,u),b(c,vf,u),e(vf,N4),e(N4,s6e),g(F7,s6e,null),e(vf,s7r),e(vf,l6e),e(l6e,l7r),b(c,eSe,u),b(c,jr,u),g(C7,jr,null),e(jr,i7r),e(jr,Tf),e(Tf,d7r),e(Tf,i6e),e(i6e,c7r),e(Tf,f7r),e(Tf,d6e),e(d6e,m7r),e(Tf,g7r),e(jr,h7r),e(jr,M7),e(M7,p7r),e(M7,c6e),e(c6e,_7r),e(M7,u7r),e(jr,b7r),e(jr,St),g(E7,St,null),e(St,v7r),e(St,f6e),e(f6e,T7r),e(St,F7r),e(St,Ff),e(Ff,C7r),e(Ff,m6e),e(m6e,M7r),e(Ff,E7r),e(Ff,g6e),e(g6e,y7r),e(Ff,w7r),e(St,A7r),e(St,h6e),e(h6e,L7r),e(St,B7r),g(y7,St,null),e(jr,x7r),e(jr,Po),g(w7,Po,null),e(Po,k7r),e(Po,p6e),e(p6e,R7r),e(Po,S7r),e(Po,In),e(In,P7r),e(In,_6e),e(_6e,$7r),e(In,I7r),e(In,u6e),e(u6e,N7r),e(In,D7r),e(In,b6e),e(b6e,j7r),e(In,q7r),e(Po,G7r),e(Po,Se),e(Se,D4),e(D4,v6e),e(v6e,O7r),e(D4,X7r),e(D4,xz),e(xz,V7r),e(D4,z7r),e(Se,W7r),e(Se,j4),e(j4,T6e),e(T6e,Q7r),e(j4,H7r),e(j4,kz),e(kz,U7r),e(j4,J7r),e(Se,Y7r),e(Se,q4),e(q4,F6e),e(F6e,K7r),e(q4,Z7r),e(q4,Rz),e(Rz,e8r),e(q4,o8r),e(Se,r8r),e(Se,G4),e(G4,C6e),e(C6e,t8r),e(G4,a8r),e(G4,Sz),e(Sz,n8r),e(G4,s8r),e(Se,l8r),e(Se,O4),e(O4,M6e),e(M6e,i8r),e(O4,d8r),e(O4,Pz),e(Pz,c8r),e(O4,f8r),e(Se,m8r),e(Se,X4),e(X4,E6e),e(E6e,g8r),e(X4,h8r),e(X4,$z),e($z,p8r),e(X4,_8r),e(Se,u8r),e(Se,V4),e(V4,y6e),e(y6e,b8r),e(V4,v8r),e(V4,Iz),e(Iz,T8r),e(V4,F8r),e(Se,C8r),e(Se,z4),e(z4,w6e),e(w6e,M8r),e(z4,E8r),e(z4,Nz),e(Nz,y8r),e(z4,w8r),e(Po,A8r),e(Po,A6e),e(A6e,L8r),e(Po,B8r),g(A7,Po,null),b(c,oSe,u),b(c,Cf,u),e(Cf,W4),e(W4,L6e),g(L7,L6e,null),e(Cf,x8r),e(Cf,B6e),e(B6e,k8r),b(c,rSe,u),b(c,qr,u),g(B7,qr,null),e(qr,R8r),e(qr,Mf),e(Mf,S8r),e(Mf,x6e),e(x6e,P8r),e(Mf,$8r),e(Mf,k6e),e(k6e,I8r),e(Mf,N8r),e(qr,D8r),e(qr,x7),e(x7,j8r),e(x7,R6e),e(R6e,q8r),e(x7,G8r),e(qr,O8r),e(qr,Pt),g(k7,Pt,null),e(Pt,X8r),e(Pt,S6e),e(S6e,V8r),e(Pt,z8r),e(Pt,Ef),e(Ef,W8r),e(Ef,P6e),e(P6e,Q8r),e(Ef,H8r),e(Ef,$6e),e($6e,U8r),e(Ef,J8r),e(Pt,Y8r),e(Pt,I6e),e(I6e,K8r),e(Pt,Z8r),g(R7,Pt,null),e(qr,e9r),e(qr,$o),g(S7,$o,null),e($o,o9r),e($o,N6e),e(N6e,r9r),e($o,t9r),e($o,Nn),e(Nn,a9r),e(Nn,D6e),e(D6e,n9r),e(Nn,s9r),e(Nn,j6e),e(j6e,l9r),e(Nn,i9r),e(Nn,q6e),e(q6e,d9r),e(Nn,c9r),e($o,f9r),e($o,Pe),e(Pe,Q4),e(Q4,G6e),e(G6e,m9r),e(Q4,g9r),e(Q4,Dz),e(Dz,h9r),e(Q4,p9r),e(Pe,_9r),e(Pe,H4),e(H4,O6e),e(O6e,u9r),e(H4,b9r),e(H4,jz),e(jz,v9r),e(H4,T9r),e(Pe,F9r),e(Pe,U4),e(U4,X6e),e(X6e,C9r),e(U4,M9r),e(U4,qz),e(qz,E9r),e(U4,y9r),e(Pe,w9r),e(Pe,J4),e(J4,V6e),e(V6e,A9r),e(J4,L9r),e(J4,Gz),e(Gz,B9r),e(J4,x9r),e(Pe,k9r),e(Pe,Y4),e(Y4,z6e),e(z6e,R9r),e(Y4,S9r),e(Y4,Oz),e(Oz,P9r),e(Y4,$9r),e(Pe,I9r),e(Pe,K4),e(K4,W6e),e(W6e,N9r),e(K4,D9r),e(K4,Xz),e(Xz,j9r),e(K4,q9r),e(Pe,G9r),e(Pe,Z4),e(Z4,Q6e),e(Q6e,O9r),e(Z4,X9r),e(Z4,Vz),e(Vz,V9r),e(Z4,z9r),e(Pe,W9r),e(Pe,eE),e(eE,H6e),e(H6e,Q9r),e(eE,H9r),e(eE,zz),e(zz,U9r),e(eE,J9r),e($o,Y9r),e($o,U6e),e(U6e,K9r),e($o,Z9r),g(P7,$o,null),b(c,tSe,u),b(c,yf,u),e(yf,oE),e(oE,J6e),g($7,J6e,null),e(yf,eBr),e(yf,Y6e),e(Y6e,oBr),b(c,aSe,u),b(c,Gr,u),g(I7,Gr,null),e(Gr,rBr),e(Gr,wf),e(wf,tBr),e(wf,K6e),e(K6e,aBr),e(wf,nBr),e(wf,Z6e),e(Z6e,sBr),e(wf,lBr),e(Gr,iBr),e(Gr,N7),e(N7,dBr),e(N7,eTe),e(eTe,cBr),e(N7,fBr),e(Gr,mBr),e(Gr,$t),g(D7,$t,null),e($t,gBr),e($t,oTe),e(oTe,hBr),e($t,pBr),e($t,Af),e(Af,_Br),e(Af,rTe),e(rTe,uBr),e(Af,bBr),e(Af,tTe),e(tTe,vBr),e(Af,TBr),e($t,FBr),e($t,aTe),e(aTe,CBr),e($t,MBr),g(j7,$t,null),e(Gr,EBr),e(Gr,Io),g(q7,Io,null),e(Io,yBr),e(Io,nTe),e(nTe,wBr),e(Io,ABr),e(Io,Dn),e(Dn,LBr),e(Dn,sTe),e(sTe,BBr),e(Dn,xBr),e(Dn,lTe),e(lTe,kBr),e(Dn,RBr),e(Dn,iTe),e(iTe,SBr),e(Dn,PBr),e(Io,$Br),e(Io,dTe),e(dTe,rE),e(rE,cTe),e(cTe,IBr),e(rE,NBr),e(rE,Wz),e(Wz,DBr),e(rE,jBr),e(Io,qBr),e(Io,fTe),e(fTe,GBr),e(Io,OBr),g(G7,Io,null),b(c,nSe,u),b(c,Lf,u),e(Lf,tE),e(tE,mTe),g(O7,mTe,null),e(Lf,XBr),e(Lf,gTe),e(gTe,VBr),b(c,sSe,u),b(c,Or,u),g(X7,Or,null),e(Or,zBr),e(Or,Bf),e(Bf,WBr),e(Bf,hTe),e(hTe,QBr),e(Bf,HBr),e(Bf,pTe),e(pTe,UBr),e(Bf,JBr),e(Or,YBr),e(Or,V7),e(V7,KBr),e(V7,_Te),e(_Te,ZBr),e(V7,exr),e(Or,oxr),e(Or,It),g(z7,It,null),e(It,rxr),e(It,uTe),e(uTe,txr),e(It,axr),e(It,xf),e(xf,nxr),e(xf,bTe),e(bTe,sxr),e(xf,lxr),e(xf,vTe),e(vTe,ixr),e(xf,dxr),e(It,cxr),e(It,TTe),e(TTe,fxr),e(It,mxr),g(W7,It,null),e(Or,gxr),e(Or,No),g(Q7,No,null),e(No,hxr),e(No,FTe),e(FTe,pxr),e(No,_xr),e(No,jn),e(jn,uxr),e(jn,CTe),e(CTe,bxr),e(jn,vxr),e(jn,MTe),e(MTe,Txr),e(jn,Fxr),e(jn,ETe),e(ETe,Cxr),e(jn,Mxr),e(No,Exr),e(No,H7),e(H7,aE),e(aE,yTe),e(yTe,yxr),e(aE,wxr),e(aE,Qz),e(Qz,Axr),e(aE,Lxr),e(H7,Bxr),e(H7,nE),e(nE,wTe),e(wTe,xxr),e(nE,kxr),e(nE,Hz),e(Hz,Rxr),e(nE,Sxr),e(No,Pxr),e(No,ATe),e(ATe,$xr),e(No,Ixr),g(U7,No,null),b(c,lSe,u),b(c,kf,u),e(kf,sE),e(sE,LTe),g(J7,LTe,null),e(kf,Nxr),e(kf,BTe),e(BTe,Dxr),b(c,iSe,u),b(c,Xr,u),g(Y7,Xr,null),e(Xr,jxr),e(Xr,Rf),e(Rf,qxr),e(Rf,xTe),e(xTe,Gxr),e(Rf,Oxr),e(Rf,kTe),e(kTe,Xxr),e(Rf,Vxr),e(Xr,zxr),e(Xr,K7),e(K7,Wxr),e(K7,RTe),e(RTe,Qxr),e(K7,Hxr),e(Xr,Uxr),e(Xr,Nt),g(Z7,Nt,null),e(Nt,Jxr),e(Nt,STe),e(STe,Yxr),e(Nt,Kxr),e(Nt,Sf),e(Sf,Zxr),e(Sf,PTe),e(PTe,ekr),e(Sf,okr),e(Sf,$Te),e($Te,rkr),e(Sf,tkr),e(Nt,akr),e(Nt,ITe),e(ITe,nkr),e(Nt,skr),g(e8,Nt,null),e(Xr,lkr),e(Xr,Do),g(o8,Do,null),e(Do,ikr),e(Do,NTe),e(NTe,dkr),e(Do,ckr),e(Do,qn),e(qn,fkr),e(qn,DTe),e(DTe,mkr),e(qn,gkr),e(qn,jTe),e(jTe,hkr),e(qn,pkr),e(qn,qTe),e(qTe,_kr),e(qn,ukr),e(Do,bkr),e(Do,GTe),e(GTe,lE),e(lE,OTe),e(OTe,vkr),e(lE,Tkr),e(lE,Uz),e(Uz,Fkr),e(lE,Ckr),e(Do,Mkr),e(Do,XTe),e(XTe,Ekr),e(Do,ykr),g(r8,Do,null),dSe=!0},p(c,[u]){const t8={};u&2&&(t8.$$scope={dirty:u,ctx:c}),Gf.$set(t8);const VTe={};u&2&&(VTe.$$scope={dirty:u,ctx:c}),xh.$set(VTe);const zTe={};u&2&&(zTe.$$scope={dirty:u,ctx:c}),Gh.$set(zTe)},i(c){dSe||(h(fe.$$.fragment,c),h(qa.$$.fragment,c),h(f3.$$.fragment,c),h(m3.$$.fragment,c),h(Gf.$$.fragment,c),h(g3.$$.fragment,c),h(h3.$$.fragment,c),h(u3.$$.fragment,c),h(b3.$$.fragment,c),h(v3.$$.fragment,c),h(T3.$$.fragment,c),h(F3.$$.fragment,c),h(E3.$$.fragment,c),h(y3.$$.fragment,c),h(w3.$$.fragment,c),h(A3.$$.fragment,c),h(L3.$$.fragment,c),h(k3.$$.fragment,c),h(xh.$$.fragment,c),h(R3.$$.fragment,c),h(S3.$$.fragment,c),h(P3.$$.fragment,c),h($3.$$.fragment,c),h(D3.$$.fragment,c),h(Gh.$$.fragment,c),h(j3.$$.fragment,c),h(q3.$$.fragment,c),h(G3.$$.fragment,c),h(O3.$$.fragment,c),h(V3.$$.fragment,c),h(z3.$$.fragment,c),h(W3.$$.fragment,c),h(Q3.$$.fragment,c),h(H3.$$.fragment,c),h(U3.$$.fragment,c),h(Y3.$$.fragment,c),h(K3.$$.fragment,c),h(Z3.$$.fragment,c),h(ey.$$.fragment,c),h(oy.$$.fragment,c),h(ry.$$.fragment,c),h(ay.$$.fragment,c),h(ny.$$.fragment,c),h(sy.$$.fragment,c),h(ly.$$.fragment,c),h(iy.$$.fragment,c),h(dy.$$.fragment,c),h(fy.$$.fragment,c),h(my.$$.fragment,c),h(gy.$$.fragment,c),h(hy.$$.fragment,c),h(py.$$.fragment,c),h(_y.$$.fragment,c),h(by.$$.fragment,c),h(vy.$$.fragment,c),h(Ty.$$.fragment,c),h(Fy.$$.fragment,c),h(Cy.$$.fragment,c),h(My.$$.fragment,c),h(yy.$$.fragment,c),h(wy.$$.fragment,c),h(Ay.$$.fragment,c),h(Ly.$$.fragment,c),h(By.$$.fragment,c),h(xy.$$.fragment,c),h(Ry.$$.fragment,c),h(Sy.$$.fragment,c),h(Py.$$.fragment,c),h($y.$$.fragment,c),h(Iy.$$.fragment,c),h(Ny.$$.fragment,c),h(jy.$$.fragment,c),h(qy.$$.fragment,c),h(Gy.$$.fragment,c),h(Oy.$$.fragment,c),h(Xy.$$.fragment,c),h(Vy.$$.fragment,c),h(Wy.$$.fragment,c),h(Qy.$$.fragment,c),h(Hy.$$.fragment,c),h(Uy.$$.fragment,c),h(Jy.$$.fragment,c),h(Yy.$$.fragment,c),h(Zy.$$.fragment,c),h(ew.$$.fragment,c),h(ow.$$.fragment,c),h(rw.$$.fragment,c),h(tw.$$.fragment,c),h(aw.$$.fragment,c),h(sw.$$.fragment,c),h(lw.$$.fragment,c),h(iw.$$.fragment,c),h(dw.$$.fragment,c),h(cw.$$.fragment,c),h(fw.$$.fragment,c),h(gw.$$.fragment,c),h(hw.$$.fragment,c),h(pw.$$.fragment,c),h(_w.$$.fragment,c),h(uw.$$.fragment,c),h(bw.$$.fragment,c),h(Tw.$$.fragment,c),h(Fw.$$.fragment,c),h(Cw.$$.fragment,c),h(Mw.$$.fragment,c),h(Ew.$$.fragment,c),h(yw.$$.fragment,c),h(Aw.$$.fragment,c),h(Lw.$$.fragment,c),h(Bw.$$.fragment,c),h(xw.$$.fragment,c),h(kw.$$.fragment,c),h(Rw.$$.fragment,c),h(Pw.$$.fragment,c),h($w.$$.fragment,c),h(Iw.$$.fragment,c),h(Nw.$$.fragment,c),h(Dw.$$.fragment,c),h(jw.$$.fragment,c),h(Gw.$$.fragment,c),h(Ow.$$.fragment,c),h(Xw.$$.fragment,c),h(Vw.$$.fragment,c),h(zw.$$.fragment,c),h(Ww.$$.fragment,c),h(Hw.$$.fragment,c),h(Uw.$$.fragment,c),h(Jw.$$.fragment,c),h(Kw.$$.fragment,c),h(Zw.$$.fragment,c),h(eA.$$.fragment,c),h(rA.$$.fragment,c),h(tA.$$.fragment,c),h(aA.$$.fragment,c),h(nA.$$.fragment,c),h(sA.$$.fragment,c),h(lA.$$.fragment,c),h(dA.$$.fragment,c),h(cA.$$.fragment,c),h(fA.$$.fragment,c),h(mA.$$.fragment,c),h(gA.$$.fragment,c),h(hA.$$.fragment,c),h(_A.$$.fragment,c),h(uA.$$.fragment,c),h(bA.$$.fragment,c),h(vA.$$.fragment,c),h(TA.$$.fragment,c),h(FA.$$.fragment,c),h(MA.$$.fragment,c),h(EA.$$.fragment,c),h(yA.$$.fragment,c),h(wA.$$.fragment,c),h(AA.$$.fragment,c),h(LA.$$.fragment,c),h(xA.$$.fragment,c),h(kA.$$.fragment,c),h(RA.$$.fragment,c),h(PA.$$.fragment,c),h($A.$$.fragment,c),h(IA.$$.fragment,c),h(DA.$$.fragment,c),h(jA.$$.fragment,c),h(qA.$$.fragment,c),h(GA.$$.fragment,c),h(OA.$$.fragment,c),h(XA.$$.fragment,c),h(zA.$$.fragment,c),h(WA.$$.fragment,c),h(QA.$$.fragment,c),h(HA.$$.fragment,c),h(UA.$$.fragment,c),h(JA.$$.fragment,c),h(KA.$$.fragment,c),h(ZA.$$.fragment,c),h(e0.$$.fragment,c),h(o0.$$.fragment,c),h(r0.$$.fragment,c),h(t0.$$.fragment,c),h(n0.$$.fragment,c),h(s0.$$.fragment,c),h(l0.$$.fragment,c),h(i0.$$.fragment,c),h(d0.$$.fragment,c),h(c0.$$.fragment,c),h(m0.$$.fragment,c),h(g0.$$.fragment,c),h(h0.$$.fragment,c),h(_0.$$.fragment,c),h(u0.$$.fragment,c),h(b0.$$.fragment,c),h(T0.$$.fragment,c),h(F0.$$.fragment,c),h(C0.$$.fragment,c),h(M0.$$.fragment,c),h(E0.$$.fragment,c),h(y0.$$.fragment,c),h(A0.$$.fragment,c),h(L0.$$.fragment,c),h(B0.$$.fragment,c),h(x0.$$.fragment,c),h(k0.$$.fragment,c),h(R0.$$.fragment,c),h(P0.$$.fragment,c),h($0.$$.fragment,c),h(I0.$$.fragment,c),h(N0.$$.fragment,c),h(D0.$$.fragment,c),h(j0.$$.fragment,c),h(G0.$$.fragment,c),h(O0.$$.fragment,c),h(X0.$$.fragment,c),h(V0.$$.fragment,c),h(z0.$$.fragment,c),h(W0.$$.fragment,c),h(H0.$$.fragment,c),h(U0.$$.fragment,c),h(J0.$$.fragment,c),h(Y0.$$.fragment,c),h(K0.$$.fragment,c),h(Z0.$$.fragment,c),h(oL.$$.fragment,c),h(rL.$$.fragment,c),h(tL.$$.fragment,c),h(aL.$$.fragment,c),h(nL.$$.fragment,c),h(sL.$$.fragment,c),h(iL.$$.fragment,c),h(dL.$$.fragment,c),h(cL.$$.fragment,c),h(fL.$$.fragment,c),h(mL.$$.fragment,c),h(gL.$$.fragment,c),h(pL.$$.fragment,c),h(_L.$$.fragment,c),h(uL.$$.fragment,c),h(bL.$$.fragment,c),h(vL.$$.fragment,c),h(TL.$$.fragment,c),h(CL.$$.fragment,c),h(ML.$$.fragment,c),h(EL.$$.fragment,c),h(yL.$$.fragment,c),h(wL.$$.fragment,c),h(AL.$$.fragment,c),h(BL.$$.fragment,c),h(xL.$$.fragment,c),h(kL.$$.fragment,c),h(RL.$$.fragment,c),h(SL.$$.fragment,c),h(PL.$$.fragment,c),h(IL.$$.fragment,c),h(NL.$$.fragment,c),h(DL.$$.fragment,c),h(jL.$$.fragment,c),h(qL.$$.fragment,c),h(GL.$$.fragment,c),h(XL.$$.fragment,c),h(VL.$$.fragment,c),h(zL.$$.fragment,c),h(WL.$$.fragment,c),h(QL.$$.fragment,c),h(HL.$$.fragment,c),h(JL.$$.fragment,c),h(YL.$$.fragment,c),h(KL.$$.fragment,c),h(ZL.$$.fragment,c),h(e7.$$.fragment,c),h(o7.$$.fragment,c),h(t7.$$.fragment,c),h(a7.$$.fragment,c),h(n7.$$.fragment,c),h(s7.$$.fragment,c),h(l7.$$.fragment,c),h(i7.$$.fragment,c),h(c7.$$.fragment,c),h(f7.$$.fragment,c),h(m7.$$.fragment,c),h(g7.$$.fragment,c),h(h7.$$.fragment,c),h(p7.$$.fragment,c),h(u7.$$.fragment,c),h(b7.$$.fragment,c),h(v7.$$.fragment,c),h(T7.$$.fragment,c),h(F7.$$.fragment,c),h(C7.$$.fragment,c),h(E7.$$.fragment,c),h(y7.$$.fragment,c),h(w7.$$.fragment,c),h(A7.$$.fragment,c),h(L7.$$.fragment,c),h(B7.$$.fragment,c),h(k7.$$.fragment,c),h(R7.$$.fragment,c),h(S7.$$.fragment,c),h(P7.$$.fragment,c),h($7.$$.fragment,c),h(I7.$$.fragment,c),h(D7.$$.fragment,c),h(j7.$$.fragment,c),h(q7.$$.fragment,c),h(G7.$$.fragment,c),h(O7.$$.fragment,c),h(X7.$$.fragment,c),h(z7.$$.fragment,c),h(W7.$$.fragment,c),h(Q7.$$.fragment,c),h(U7.$$.fragment,c),h(J7.$$.fragment,c),h(Y7.$$.fragment,c),h(Z7.$$.fragment,c),h(e8.$$.fragment,c),h(o8.$$.fragment,c),h(r8.$$.fragment,c),dSe=!0)},o(c){p(fe.$$.fragment,c),p(qa.$$.fragment,c),p(f3.$$.fragment,c),p(m3.$$.fragment,c),p(Gf.$$.fragment,c),p(g3.$$.fragment,c),p(h3.$$.fragment,c),p(u3.$$.fragment,c),p(b3.$$.fragment,c),p(v3.$$.fragment,c),p(T3.$$.fragment,c),p(F3.$$.fragment,c),p(E3.$$.fragment,c),p(y3.$$.fragment,c),p(w3.$$.fragment,c),p(A3.$$.fragment,c),p(L3.$$.fragment,c),p(k3.$$.fragment,c),p(xh.$$.fragment,c),p(R3.$$.fragment,c),p(S3.$$.fragment,c),p(P3.$$.fragment,c),p($3.$$.fragment,c),p(D3.$$.fragment,c),p(Gh.$$.fragment,c),p(j3.$$.fragment,c),p(q3.$$.fragment,c),p(G3.$$.fragment,c),p(O3.$$.fragment,c),p(V3.$$.fragment,c),p(z3.$$.fragment,c),p(W3.$$.fragment,c),p(Q3.$$.fragment,c),p(H3.$$.fragment,c),p(U3.$$.fragment,c),p(Y3.$$.fragment,c),p(K3.$$.fragment,c),p(Z3.$$.fragment,c),p(ey.$$.fragment,c),p(oy.$$.fragment,c),p(ry.$$.fragment,c),p(ay.$$.fragment,c),p(ny.$$.fragment,c),p(sy.$$.fragment,c),p(ly.$$.fragment,c),p(iy.$$.fragment,c),p(dy.$$.fragment,c),p(fy.$$.fragment,c),p(my.$$.fragment,c),p(gy.$$.fragment,c),p(hy.$$.fragment,c),p(py.$$.fragment,c),p(_y.$$.fragment,c),p(by.$$.fragment,c),p(vy.$$.fragment,c),p(Ty.$$.fragment,c),p(Fy.$$.fragment,c),p(Cy.$$.fragment,c),p(My.$$.fragment,c),p(yy.$$.fragment,c),p(wy.$$.fragment,c),p(Ay.$$.fragment,c),p(Ly.$$.fragment,c),p(By.$$.fragment,c),p(xy.$$.fragment,c),p(Ry.$$.fragment,c),p(Sy.$$.fragment,c),p(Py.$$.fragment,c),p($y.$$.fragment,c),p(Iy.$$.fragment,c),p(Ny.$$.fragment,c),p(jy.$$.fragment,c),p(qy.$$.fragment,c),p(Gy.$$.fragment,c),p(Oy.$$.fragment,c),p(Xy.$$.fragment,c),p(Vy.$$.fragment,c),p(Wy.$$.fragment,c),p(Qy.$$.fragment,c),p(Hy.$$.fragment,c),p(Uy.$$.fragment,c),p(Jy.$$.fragment,c),p(Yy.$$.fragment,c),p(Zy.$$.fragment,c),p(ew.$$.fragment,c),p(ow.$$.fragment,c),p(rw.$$.fragment,c),p(tw.$$.fragment,c),p(aw.$$.fragment,c),p(sw.$$.fragment,c),p(lw.$$.fragment,c),p(iw.$$.fragment,c),p(dw.$$.fragment,c),p(cw.$$.fragment,c),p(fw.$$.fragment,c),p(gw.$$.fragment,c),p(hw.$$.fragment,c),p(pw.$$.fragment,c),p(_w.$$.fragment,c),p(uw.$$.fragment,c),p(bw.$$.fragment,c),p(Tw.$$.fragment,c),p(Fw.$$.fragment,c),p(Cw.$$.fragment,c),p(Mw.$$.fragment,c),p(Ew.$$.fragment,c),p(yw.$$.fragment,c),p(Aw.$$.fragment,c),p(Lw.$$.fragment,c),p(Bw.$$.fragment,c),p(xw.$$.fragment,c),p(kw.$$.fragment,c),p(Rw.$$.fragment,c),p(Pw.$$.fragment,c),p($w.$$.fragment,c),p(Iw.$$.fragment,c),p(Nw.$$.fragment,c),p(Dw.$$.fragment,c),p(jw.$$.fragment,c),p(Gw.$$.fragment,c),p(Ow.$$.fragment,c),p(Xw.$$.fragment,c),p(Vw.$$.fragment,c),p(zw.$$.fragment,c),p(Ww.$$.fragment,c),p(Hw.$$.fragment,c),p(Uw.$$.fragment,c),p(Jw.$$.fragment,c),p(Kw.$$.fragment,c),p(Zw.$$.fragment,c),p(eA.$$.fragment,c),p(rA.$$.fragment,c),p(tA.$$.fragment,c),p(aA.$$.fragment,c),p(nA.$$.fragment,c),p(sA.$$.fragment,c),p(lA.$$.fragment,c),p(dA.$$.fragment,c),p(cA.$$.fragment,c),p(fA.$$.fragment,c),p(mA.$$.fragment,c),p(gA.$$.fragment,c),p(hA.$$.fragment,c),p(_A.$$.fragment,c),p(uA.$$.fragment,c),p(bA.$$.fragment,c),p(vA.$$.fragment,c),p(TA.$$.fragment,c),p(FA.$$.fragment,c),p(MA.$$.fragment,c),p(EA.$$.fragment,c),p(yA.$$.fragment,c),p(wA.$$.fragment,c),p(AA.$$.fragment,c),p(LA.$$.fragment,c),p(xA.$$.fragment,c),p(kA.$$.fragment,c),p(RA.$$.fragment,c),p(PA.$$.fragment,c),p($A.$$.fragment,c),p(IA.$$.fragment,c),p(DA.$$.fragment,c),p(jA.$$.fragment,c),p(qA.$$.fragment,c),p(GA.$$.fragment,c),p(OA.$$.fragment,c),p(XA.$$.fragment,c),p(zA.$$.fragment,c),p(WA.$$.fragment,c),p(QA.$$.fragment,c),p(HA.$$.fragment,c),p(UA.$$.fragment,c),p(JA.$$.fragment,c),p(KA.$$.fragment,c),p(ZA.$$.fragment,c),p(e0.$$.fragment,c),p(o0.$$.fragment,c),p(r0.$$.fragment,c),p(t0.$$.fragment,c),p(n0.$$.fragment,c),p(s0.$$.fragment,c),p(l0.$$.fragment,c),p(i0.$$.fragment,c),p(d0.$$.fragment,c),p(c0.$$.fragment,c),p(m0.$$.fragment,c),p(g0.$$.fragment,c),p(h0.$$.fragment,c),p(_0.$$.fragment,c),p(u0.$$.fragment,c),p(b0.$$.fragment,c),p(T0.$$.fragment,c),p(F0.$$.fragment,c),p(C0.$$.fragment,c),p(M0.$$.fragment,c),p(E0.$$.fragment,c),p(y0.$$.fragment,c),p(A0.$$.fragment,c),p(L0.$$.fragment,c),p(B0.$$.fragment,c),p(x0.$$.fragment,c),p(k0.$$.fragment,c),p(R0.$$.fragment,c),p(P0.$$.fragment,c),p($0.$$.fragment,c),p(I0.$$.fragment,c),p(N0.$$.fragment,c),p(D0.$$.fragment,c),p(j0.$$.fragment,c),p(G0.$$.fragment,c),p(O0.$$.fragment,c),p(X0.$$.fragment,c),p(V0.$$.fragment,c),p(z0.$$.fragment,c),p(W0.$$.fragment,c),p(H0.$$.fragment,c),p(U0.$$.fragment,c),p(J0.$$.fragment,c),p(Y0.$$.fragment,c),p(K0.$$.fragment,c),p(Z0.$$.fragment,c),p(oL.$$.fragment,c),p(rL.$$.fragment,c),p(tL.$$.fragment,c),p(aL.$$.fragment,c),p(nL.$$.fragment,c),p(sL.$$.fragment,c),p(iL.$$.fragment,c),p(dL.$$.fragment,c),p(cL.$$.fragment,c),p(fL.$$.fragment,c),p(mL.$$.fragment,c),p(gL.$$.fragment,c),p(pL.$$.fragment,c),p(_L.$$.fragment,c),p(uL.$$.fragment,c),p(bL.$$.fragment,c),p(vL.$$.fragment,c),p(TL.$$.fragment,c),p(CL.$$.fragment,c),p(ML.$$.fragment,c),p(EL.$$.fragment,c),p(yL.$$.fragment,c),p(wL.$$.fragment,c),p(AL.$$.fragment,c),p(BL.$$.fragment,c),p(xL.$$.fragment,c),p(kL.$$.fragment,c),p(RL.$$.fragment,c),p(SL.$$.fragment,c),p(PL.$$.fragment,c),p(IL.$$.fragment,c),p(NL.$$.fragment,c),p(DL.$$.fragment,c),p(jL.$$.fragment,c),p(qL.$$.fragment,c),p(GL.$$.fragment,c),p(XL.$$.fragment,c),p(VL.$$.fragment,c),p(zL.$$.fragment,c),p(WL.$$.fragment,c),p(QL.$$.fragment,c),p(HL.$$.fragment,c),p(JL.$$.fragment,c),p(YL.$$.fragment,c),p(KL.$$.fragment,c),p(ZL.$$.fragment,c),p(e7.$$.fragment,c),p(o7.$$.fragment,c),p(t7.$$.fragment,c),p(a7.$$.fragment,c),p(n7.$$.fragment,c),p(s7.$$.fragment,c),p(l7.$$.fragment,c),p(i7.$$.fragment,c),p(c7.$$.fragment,c),p(f7.$$.fragment,c),p(m7.$$.fragment,c),p(g7.$$.fragment,c),p(h7.$$.fragment,c),p(p7.$$.fragment,c),p(u7.$$.fragment,c),p(b7.$$.fragment,c),p(v7.$$.fragment,c),p(T7.$$.fragment,c),p(F7.$$.fragment,c),p(C7.$$.fragment,c),p(E7.$$.fragment,c),p(y7.$$.fragment,c),p(w7.$$.fragment,c),p(A7.$$.fragment,c),p(L7.$$.fragment,c),p(B7.$$.fragment,c),p(k7.$$.fragment,c),p(R7.$$.fragment,c),p(S7.$$.fragment,c),p(P7.$$.fragment,c),p($7.$$.fragment,c),p(I7.$$.fragment,c),p(D7.$$.fragment,c),p(j7.$$.fragment,c),p(q7.$$.fragment,c),p(G7.$$.fragment,c),p(O7.$$.fragment,c),p(X7.$$.fragment,c),p(z7.$$.fragment,c),p(W7.$$.fragment,c),p(Q7.$$.fragment,c),p(U7.$$.fragment,c),p(J7.$$.fragment,c),p(Y7.$$.fragment,c),p(Z7.$$.fragment,c),p(e8.$$.fragment,c),p(o8.$$.fragment,c),p(r8.$$.fragment,c),dSe=!1},d(c){t(K),c&&t(io),c&&t(de),_(fe),c&&t(If),c&&t(fa),c&&t(Be),c&&t(co),c&&t(Df),_(qa,c),c&&t(fo),c&&t(pe),c&&t(zo),c&&t(Ga),c&&t(ike),c&&t(Xi),_(f3),c&&t(dke),c&&t(zn),c&&t(cke),_(m3,c),c&&t(fke),c&&t(n9),c&&t(mke),_(Gf,c),c&&t(gke),c&&t(Vi),_(g3),c&&t(hke),c&&t(Wo),_(h3),_(u3),_(b3),_(v3),c&&t(pke),c&&t(Wi),_(T3),c&&t(_ke),c&&t(Qo),_(F3),_(E3),_(y3),_(w3),c&&t(uke),c&&t(Qi),_(A3),c&&t(bke),c&&t(Ho),_(L3),_(k3),_(xh),_(R3),_(S3),c&&t(vke),c&&t(Hi),_(P3),c&&t(Tke),c&&t(Uo),_($3),_(D3),_(Gh),_(j3),_(q3),c&&t(Fke),c&&t(Ji),_(G3),c&&t(Cke),c&&t(Jo),_(O3),_(V3),_(z3),_(W3),_(Q3),c&&t(Mke),c&&t(Zi),_(H3),c&&t(Eke),c&&t(Yo),_(U3),_(Y3),_(K3),_(Z3),_(ey),c&&t(yke),c&&t(rd),_(oy),c&&t(wke),c&&t(Ko),_(ry),_(ay),_(ny),_(sy),_(ly),c&&t(Ake),c&&t(nd),_(iy),c&&t(Lke),c&&t(Zo),_(dy),_(fy),_(my),_(gy),_(hy),c&&t(Bke),c&&t(id),_(py),c&&t(xke),c&&t(er),_(_y),_(by),_(vy),_(Ty),_(Fy),c&&t(kke),c&&t(fd),_(Cy),c&&t(Rke),c&&t(or),_(My),_(yy),_(wy),_(Ay),_(Ly),c&&t(Ske),c&&t(hd),_(By),c&&t(Pke),c&&t(rr),_(xy),_(Ry),_(Sy),_(Py),_($y),c&&t($ke),c&&t(ud),_(Iy),c&&t(Ike),c&&t(tr),_(Ny),_(jy),_(qy),_(Gy),_(Oy),c&&t(Nke),c&&t(Td),_(Xy),c&&t(Dke),c&&t(ar),_(Vy),_(Wy),_(Qy),_(Hy),_(Uy),c&&t(jke),c&&t(Md),_(Jy),c&&t(qke),c&&t(nr),_(Yy),_(Zy),_(ew),_(ow),_(rw),c&&t(Gke),c&&t(wd),_(tw),c&&t(Oke),c&&t(sr),_(aw),_(sw),_(lw),_(iw),_(dw),c&&t(Xke),c&&t(Bd),_(cw),c&&t(Vke),c&&t(lr),_(fw),_(gw),_(hw),_(pw),_(_w),c&&t(zke),c&&t(Rd),_(uw),c&&t(Wke),c&&t(ir),_(bw),_(Tw),_(Fw),_(Cw),_(Mw),c&&t(Qke),c&&t($d),_(Ew),c&&t(Hke),c&&t(dr),_(yw),_(Aw),_(Lw),_(Bw),_(xw),c&&t(Uke),c&&t(Dd),_(kw),c&&t(Jke),c&&t(cr),_(Rw),_(Pw),_($w),_(Iw),_(Nw),c&&t(Yke),c&&t(Gd),_(Dw),c&&t(Kke),c&&t(fr),_(jw),_(Gw),_(Ow),_(Xw),_(Vw),c&&t(Zke),c&&t(Vd),_(zw),c&&t(eRe),c&&t(mr),_(Ww),_(Hw),_(Uw),_(Jw),_(Kw),c&&t(oRe),c&&t(Qd),_(Zw),c&&t(rRe),c&&t(gr),_(eA),_(rA),_(tA),_(aA),_(nA),c&&t(tRe),c&&t(Jd),_(sA),c&&t(aRe),c&&t(hr),_(lA),_(dA),_(cA),_(fA),_(mA),c&&t(nRe),c&&t(ec),_(gA),c&&t(sRe),c&&t(pr),_(hA),_(_A),_(uA),_(bA),_(vA),c&&t(lRe),c&&t(tc),_(TA),c&&t(iRe),c&&t(_r),_(FA),_(MA),_(EA),_(yA),_(wA),c&&t(dRe),c&&t(sc),_(AA),c&&t(cRe),c&&t(ur),_(LA),_(xA),_(kA),_(RA),_(PA),c&&t(fRe),c&&t(dc),_($A),c&&t(mRe),c&&t(br),_(IA),_(DA),_(jA),_(qA),_(GA),c&&t(gRe),c&&t(mc),_(OA),c&&t(hRe),c&&t(vr),_(XA),_(zA),_(WA),_(QA),_(HA),c&&t(pRe),c&&t(pc),_(UA),c&&t(_Re),c&&t(Tr),_(JA),_(KA),_(ZA),_(e0),_(o0),c&&t(uRe),c&&t(bc),_(r0),c&&t(bRe),c&&t(Fr),_(t0),_(n0),_(s0),_(l0),_(i0),c&&t(vRe),c&&t(Fc),_(d0),c&&t(TRe),c&&t(Cr),_(c0),_(m0),_(g0),_(h0),_(_0),c&&t(FRe),c&&t(Ec),_(u0),c&&t(CRe),c&&t(Mr),_(b0),_(T0),_(F0),_(C0),_(M0),c&&t(MRe),c&&t(Ac),_(E0),c&&t(ERe),c&&t(Er),_(y0),_(A0),_(L0),_(B0),_(x0),c&&t(yRe),c&&t(xc),_(k0),c&&t(wRe),c&&t(yr),_(R0),_(P0),_($0),_(I0),_(N0),c&&t(ARe),c&&t(Sc),_(D0),c&&t(LRe),c&&t(wr),_(j0),_(G0),_(O0),_(X0),_(V0),c&&t(BRe),c&&t(Ic),_(z0),c&&t(xRe),c&&t(Ar),_(W0),_(H0),_(U0),_(J0),_(Y0),c&&t(kRe),c&&t(jc),_(K0),c&&t(RRe),c&&t(Lr),_(Z0),_(oL),_(rL),_(tL),_(aL),c&&t(SRe),c&&t(Oc),_(nL),c&&t(PRe),c&&t(Br),_(sL),_(iL),_(dL),_(cL),_(fL),c&&t($Re),c&&t(zc),_(mL),c&&t(IRe),c&&t(xr),_(gL),_(pL),_(_L),_(uL),_(bL),c&&t(NRe),c&&t(Hc),_(vL),c&&t(DRe),c&&t(kr),_(TL),_(CL),_(ML),_(EL),_(yL),c&&t(jRe),c&&t(Yc),_(wL),c&&t(qRe),c&&t(Rr),_(AL),_(BL),_(xL),_(kL),_(RL),c&&t(GRe),c&&t(ef),_(SL),c&&t(ORe),c&&t(Sr),_(PL),_(IL),_(NL),_(DL),_(jL),c&&t(XRe),c&&t(tf),_(qL),c&&t(VRe),c&&t(Pr),_(GL),_(XL),_(VL),_(zL),_(WL),c&&t(zRe),c&&t(sf),_(QL),c&&t(WRe),c&&t($r),_(HL),_(JL),_(YL),_(KL),_(ZL),c&&t(QRe),c&&t(cf),_(e7),c&&t(HRe),c&&t(Ir),_(o7),_(t7),_(a7),_(n7),_(s7),c&&t(URe),c&&t(gf),_(l7),c&&t(JRe),c&&t(Nr),_(i7),_(c7),_(f7),_(m7),_(g7),c&&t(YRe),c&&t(_f),_(h7),c&&t(KRe),c&&t(Dr),_(p7),_(u7),_(b7),_(v7),_(T7),c&&t(ZRe),c&&t(vf),_(F7),c&&t(eSe),c&&t(jr),_(C7),_(E7),_(y7),_(w7),_(A7),c&&t(oSe),c&&t(Cf),_(L7),c&&t(rSe),c&&t(qr),_(B7),_(k7),_(R7),_(S7),_(P7),c&&t(tSe),c&&t(yf),_($7),c&&t(aSe),c&&t(Gr),_(I7),_(D7),_(j7),_(q7),_(G7),c&&t(nSe),c&&t(Lf),_(O7),c&&t(sSe),c&&t(Or),_(X7),_(z7),_(W7),_(Q7),_(U7),c&&t(lSe),c&&t(kf),_(J7),c&&t(iSe),c&&t(Xr),_(Y7),_(Z7),_(e8),_(o8),_(r8)}}}const IMt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function NMt($f){return kMt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class XMt extends AMt{constructor(K){super();LMt(this,K,NMt,$Mt,BMt,{})}}export{XMt as default,IMt as metadata};
