import{S as tTt,i as aTt,s as nTt,e as a,k as l,w as f,t as o,M as sTt,c as n,d as t,m as i,a as s,x as m,h as r,b as d,F as e,g as b,y as g,q as h,o as p,B as _}from"../../chunks/vendor-4833417e.js";import{T as wBr}from"../../chunks/Tip-fffd6df1.js";import{D as M}from"../../chunks/Docstring-7b52c3d4.js";import{C as w}from"../../chunks/CodeBlock-6a3d1b46.js";import{I as X}from"../../chunks/IconCopyLink-4b81c553.js";import"../../chunks/CopyButton-dacfbfaf.js";function lTt($i){let J,$e,de,ge,io,fe,Fe,Vo,Ii,$f,ca,ji,Di,U4,If,Be,co,Ni,On,J4,Gn,Xn,Y4,qi,Vn,K4,Oi,jf,Na;return{c(){J=a("p"),$e=o("If your "),de=a("code"),ge=o("NewModelConfig"),io=o(" is a subclass of "),fe=a("code"),Fe=o("PretrainedConfig"),Vo=o(`, make sure its
`),Ii=a("code"),$f=o("model_type"),ca=o(" attribute is set to the same key you use when registering the config (here "),ji=a("code"),Di=o('"new-model"'),U4=o(")."),If=l(),Be=a("p"),co=o("Likewise, if your "),Ni=a("code"),On=o("NewModel"),J4=o(" is a subclass of "),Gn=a("a"),Xn=o("PreTrainedModel"),Y4=o(`, make sure its
`),qi=a("code"),Vn=o("config_class"),K4=o(` attribute is set to the same class you use when registering the model (here
`),Oi=a("code"),jf=o("NewModelConfig"),Na=o(")."),this.h()},l(fo){J=n(fo,"P",{});var he=s(J);$e=r(he,"If your "),de=n(he,"CODE",{});var G8=s(de);ge=r(G8,"NewModelConfig"),G8.forEach(t),io=r(he," is a subclass of "),fe=n(he,"CODE",{});var Gi=s(fe);Fe=r(Gi,"PretrainedConfig"),Gi.forEach(t),Vo=r(he,`, make sure its
`),Ii=n(he,"CODE",{});var X8=s(Ii);$f=r(X8,"model_type"),X8.forEach(t),ca=r(he," attribute is set to the same key you use when registering the config (here "),ji=n(he,"CODE",{});var V8=s(ji);Di=r(V8,'"new-model"'),V8.forEach(t),U4=r(he,")."),he.forEach(t),If=i(fo),Be=n(fo,"P",{});var zo=s(Be);co=r(zo,"Likewise, if your "),Ni=n(zo,"CODE",{});var qa=s(Ni);On=r(qa,"NewModel"),qa.forEach(t),J4=r(zo," is a subclass of "),Gn=n(zo,"A",{href:!0});var z8=s(Gn);Xn=r(z8,"PreTrainedModel"),z8.forEach(t),Y4=r(zo,`, make sure its
`),qi=n(zo,"CODE",{});var Df=s(qi);Vn=r(Df,"config_class"),Df.forEach(t),K4=r(zo,` attribute is set to the same class you use when registering the model (here
`),Oi=n(zo,"CODE",{});var W8=s(Oi);jf=r(W8,"NewModelConfig"),W8.forEach(t),Na=r(zo,")."),zo.forEach(t),this.h()},h(){d(Gn,"href","/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel")},m(fo,he){b(fo,J,he),e(J,$e),e(J,de),e(de,ge),e(J,io),e(J,fe),e(fe,Fe),e(J,Vo),e(J,Ii),e(Ii,$f),e(J,ca),e(J,ji),e(ji,Di),e(J,U4),b(fo,If,he),b(fo,Be,he),e(Be,co),e(Be,Ni),e(Ni,On),e(Be,J4),e(Be,Gn),e(Gn,Xn),e(Be,Y4),e(Be,qi),e(qi,Vn),e(Be,K4),e(Be,Oi),e(Oi,jf),e(Be,Na)},d(fo){fo&&t(J),fo&&t(If),fo&&t(Be)}}}function iTt($i){let J,$e,de,ge,io;return{c(){J=a("p"),$e=o("Passing "),de=a("code"),ge=o("use_auth_token=True"),io=o(" is required when you want to use a private model.")},l(fe){J=n(fe,"P",{});var Fe=s(J);$e=r(Fe,"Passing "),de=n(Fe,"CODE",{});var Vo=s(de);ge=r(Vo,"use_auth_token=True"),Vo.forEach(t),io=r(Fe," is required when you want to use a private model."),Fe.forEach(t)},m(fe,Fe){b(fe,J,Fe),e(J,$e),e(J,de),e(de,ge),e(J,io)},d(fe){fe&&t(J)}}}function dTt($i){let J,$e,de,ge,io;return{c(){J=a("p"),$e=o("Passing "),de=a("code"),ge=o("use_auth_token=True"),io=o(" is required when you want to use a private model.")},l(fe){J=n(fe,"P",{});var Fe=s(J);$e=r(Fe,"Passing "),de=n(Fe,"CODE",{});var Vo=s(de);ge=r(Vo,"use_auth_token=True"),Vo.forEach(t),io=r(Fe," is required when you want to use a private model."),Fe.forEach(t)},m(fe,Fe){b(fe,J,Fe),e(J,$e),e(J,de),e(de,ge),e(J,io)},d(fe){fe&&t(J)}}}function cTt($i){let J,$e,de,ge,io,fe,Fe,Vo,Ii,$f,ca,ji,Di,U4,If,Be,co,Ni,On,J4,Gn,Xn,Y4,qi,Vn,K4,Oi,jf,Na,fo,he,G8,Gi,X8,V8,zo,qa,z8,Df,W8,LPe,hxe,Xi,Nf,bQ,Z4,BPe,vQ,xPe,pxe,zn,kPe,TQ,RPe,SPe,FQ,PPe,$Pe,_xe,eE,uxe,Q8,IPe,bxe,qf,vxe,Vi,Of,CQ,oE,jPe,MQ,DPe,Txe,Wo,rE,NPe,tE,qPe,H8,OPe,GPe,XPe,aE,VPe,EQ,zPe,WPe,QPe,mo,nE,HPe,yQ,UPe,JPe,zi,YPe,wQ,KPe,ZPe,AQ,e$e,o$e,r$e,v,Gf,LQ,t$e,a$e,U8,n$e,s$e,l$e,Xf,BQ,i$e,d$e,J8,c$e,f$e,m$e,Vf,xQ,g$e,h$e,Y8,p$e,_$e,u$e,zf,kQ,b$e,v$e,K8,T$e,F$e,C$e,Wf,RQ,M$e,E$e,Z8,y$e,w$e,A$e,Qf,SQ,L$e,B$e,e9,x$e,k$e,R$e,Hf,PQ,S$e,P$e,o9,$$e,I$e,j$e,Uf,$Q,D$e,N$e,r9,q$e,O$e,G$e,Jf,IQ,X$e,V$e,t9,z$e,W$e,Q$e,Yf,jQ,H$e,U$e,a9,J$e,Y$e,K$e,Kf,DQ,Z$e,eIe,n9,oIe,rIe,tIe,Zf,NQ,aIe,nIe,s9,sIe,lIe,iIe,em,qQ,dIe,cIe,l9,fIe,mIe,gIe,om,OQ,hIe,pIe,i9,_Ie,uIe,bIe,rm,GQ,vIe,TIe,d9,FIe,CIe,MIe,tm,XQ,EIe,yIe,c9,wIe,AIe,LIe,am,VQ,BIe,xIe,f9,kIe,RIe,SIe,nm,zQ,PIe,$Ie,m9,IIe,jIe,DIe,sm,WQ,NIe,qIe,g9,OIe,GIe,XIe,lm,QQ,VIe,zIe,h9,WIe,QIe,HIe,im,HQ,UIe,JIe,p9,YIe,KIe,ZIe,dm,UQ,eje,oje,_9,rje,tje,aje,cm,JQ,nje,sje,u9,lje,ije,dje,fm,YQ,cje,fje,b9,mje,gje,hje,mm,KQ,pje,_je,v9,uje,bje,vje,gm,ZQ,Tje,Fje,T9,Cje,Mje,Eje,hm,eH,yje,wje,F9,Aje,Lje,Bje,pm,oH,xje,kje,C9,Rje,Sje,Pje,_m,rH,$je,Ije,M9,jje,Dje,Nje,um,tH,qje,Oje,E9,Gje,Xje,Vje,bm,aH,zje,Wje,y9,Qje,Hje,Uje,vm,nH,Jje,Yje,w9,Kje,Zje,eDe,Tm,sH,oDe,rDe,A9,tDe,aDe,nDe,Fm,lH,sDe,lDe,L9,iDe,dDe,cDe,Cm,iH,fDe,mDe,B9,gDe,hDe,pDe,Mm,dH,_De,uDe,x9,bDe,vDe,TDe,Em,cH,FDe,CDe,k9,MDe,EDe,yDe,ym,fH,wDe,ADe,R9,LDe,BDe,xDe,wm,mH,kDe,RDe,S9,SDe,PDe,$De,Am,gH,IDe,jDe,P9,DDe,NDe,qDe,Lm,hH,ODe,GDe,$9,XDe,VDe,zDe,Bm,pH,WDe,QDe,I9,HDe,UDe,JDe,xm,_H,YDe,KDe,j9,ZDe,eNe,oNe,km,uH,rNe,tNe,D9,aNe,nNe,sNe,Rm,bH,lNe,iNe,N9,dNe,cNe,fNe,Sm,vH,mNe,gNe,q9,hNe,pNe,_Ne,Pm,TH,uNe,bNe,O9,vNe,TNe,FNe,$m,FH,CNe,MNe,G9,ENe,yNe,wNe,Im,CH,ANe,LNe,X9,BNe,xNe,kNe,jm,MH,RNe,SNe,V9,PNe,$Ne,INe,Dm,EH,jNe,DNe,z9,NNe,qNe,ONe,Nm,yH,GNe,XNe,W9,VNe,zNe,WNe,qm,wH,QNe,HNe,Q9,UNe,JNe,YNe,Om,AH,KNe,ZNe,H9,eqe,oqe,rqe,Gm,LH,tqe,aqe,U9,nqe,sqe,lqe,Xm,BH,iqe,dqe,J9,cqe,fqe,mqe,Vm,xH,gqe,hqe,Y9,pqe,_qe,uqe,zm,kH,bqe,vqe,K9,Tqe,Fqe,Cqe,Wm,RH,Mqe,Eqe,Z9,yqe,wqe,Aqe,Qm,SH,Lqe,Bqe,eB,xqe,kqe,Rqe,Hm,PH,Sqe,Pqe,oB,$qe,Iqe,jqe,Um,$H,Dqe,Nqe,rB,qqe,Oqe,Gqe,Jm,IH,Xqe,Vqe,tB,zqe,Wqe,Qqe,Ym,jH,Hqe,Uqe,aB,Jqe,Yqe,Kqe,Km,DH,Zqe,eOe,nB,oOe,rOe,tOe,Zm,NH,aOe,nOe,sB,sOe,lOe,iOe,eg,qH,dOe,cOe,lB,fOe,mOe,gOe,og,OH,hOe,pOe,iB,_Oe,uOe,bOe,rg,GH,vOe,TOe,dB,FOe,COe,MOe,tg,XH,EOe,yOe,cB,wOe,AOe,LOe,ag,VH,BOe,xOe,fB,kOe,ROe,SOe,ng,zH,POe,$Oe,mB,IOe,jOe,DOe,sg,WH,NOe,qOe,gB,OOe,GOe,XOe,lg,QH,VOe,zOe,hB,WOe,QOe,HOe,ig,HH,UOe,JOe,pB,YOe,KOe,ZOe,dg,UH,eGe,oGe,_B,rGe,tGe,aGe,cg,JH,nGe,sGe,uB,lGe,iGe,dGe,fg,YH,cGe,fGe,bB,mGe,gGe,hGe,mg,KH,pGe,_Ge,vB,uGe,bGe,vGe,gg,ZH,TGe,FGe,TB,CGe,MGe,EGe,hg,eU,yGe,wGe,FB,AGe,LGe,BGe,pg,oU,xGe,kGe,CB,RGe,SGe,PGe,_g,rU,$Ge,IGe,MB,jGe,DGe,NGe,ug,tU,qGe,OGe,EB,GGe,XGe,VGe,bg,aU,zGe,WGe,yB,QGe,HGe,UGe,vg,nU,JGe,YGe,wB,KGe,ZGe,eXe,Tg,sU,oXe,rXe,AB,tXe,aXe,nXe,Fg,lU,sXe,lXe,LB,iXe,dXe,cXe,Cg,iU,fXe,mXe,BB,gXe,hXe,pXe,Mg,dU,_Xe,uXe,xB,bXe,vXe,TXe,Eg,cU,FXe,CXe,kB,MXe,EXe,yXe,yg,fU,wXe,AXe,RB,LXe,BXe,xXe,wg,mU,kXe,RXe,SB,SXe,PXe,$Xe,Ag,gU,IXe,jXe,PB,DXe,NXe,qXe,Lg,hU,OXe,GXe,$B,XXe,VXe,zXe,pU,WXe,QXe,sE,HXe,Bg,lE,UXe,_U,JXe,Fxe,Wi,xg,uU,iE,YXe,bU,KXe,Cxe,Qo,dE,ZXe,cE,eVe,IB,oVe,rVe,tVe,fE,aVe,vU,nVe,sVe,lVe,go,mE,iVe,TU,dVe,cVe,Oa,fVe,FU,mVe,gVe,CU,hVe,pVe,MU,_Ve,uVe,bVe,E,Wn,EU,vVe,TVe,jB,FVe,CVe,DB,MVe,EVe,yVe,Qn,yU,wVe,AVe,NB,LVe,BVe,qB,xVe,kVe,RVe,Hn,wU,SVe,PVe,OB,$Ve,IVe,GB,jVe,DVe,NVe,kg,AU,qVe,OVe,XB,GVe,XVe,VVe,Un,LU,zVe,WVe,VB,QVe,HVe,zB,UVe,JVe,YVe,Rg,BU,KVe,ZVe,WB,eze,oze,rze,Sg,xU,tze,aze,QB,nze,sze,lze,Pg,kU,ize,dze,HB,cze,fze,mze,Jn,RU,gze,hze,UB,pze,_ze,JB,uze,bze,vze,Yn,SU,Tze,Fze,YB,Cze,Mze,KB,Eze,yze,wze,Kn,PU,Aze,Lze,ZB,Bze,xze,ex,kze,Rze,Sze,$g,$U,Pze,$ze,ox,Ize,jze,Dze,Ig,IU,Nze,qze,rx,Oze,Gze,Xze,Zn,jU,Vze,zze,tx,Wze,Qze,ax,Hze,Uze,Jze,jg,DU,Yze,Kze,nx,Zze,eWe,oWe,es,NU,rWe,tWe,sx,aWe,nWe,lx,sWe,lWe,iWe,os,qU,dWe,cWe,ix,fWe,mWe,dx,gWe,hWe,pWe,rs,OU,_We,uWe,cx,bWe,vWe,GU,TWe,FWe,CWe,Dg,XU,MWe,EWe,fx,yWe,wWe,AWe,ts,VU,LWe,BWe,mx,xWe,kWe,gx,RWe,SWe,PWe,Ng,zU,$We,IWe,hx,jWe,DWe,NWe,as,WU,qWe,OWe,px,GWe,XWe,_x,VWe,zWe,WWe,ns,QU,QWe,HWe,ux,UWe,JWe,bx,YWe,KWe,ZWe,ss,HU,eQe,oQe,vx,rQe,tQe,Tx,aQe,nQe,sQe,qg,UU,lQe,iQe,Fx,dQe,cQe,fQe,ls,JU,mQe,gQe,Cx,hQe,pQe,Mx,_Qe,uQe,bQe,Og,YU,vQe,TQe,Ex,FQe,CQe,MQe,is,KU,EQe,yQe,yx,wQe,AQe,wx,LQe,BQe,xQe,ds,ZU,kQe,RQe,Ax,SQe,PQe,Lx,$Qe,IQe,jQe,cs,eJ,DQe,NQe,Bx,qQe,OQe,xx,GQe,XQe,VQe,fs,oJ,zQe,WQe,kx,QQe,HQe,Rx,UQe,JQe,YQe,Gg,rJ,KQe,ZQe,Sx,eHe,oHe,rHe,ms,tJ,tHe,aHe,Px,nHe,sHe,$x,lHe,iHe,dHe,gs,aJ,cHe,fHe,Ix,mHe,gHe,jx,hHe,pHe,_He,hs,nJ,uHe,bHe,Dx,vHe,THe,Nx,FHe,CHe,MHe,ps,sJ,EHe,yHe,qx,wHe,AHe,Ox,LHe,BHe,xHe,_s,lJ,kHe,RHe,Gx,SHe,PHe,Xx,$He,IHe,jHe,us,iJ,DHe,NHe,Vx,qHe,OHe,zx,GHe,XHe,VHe,Xg,dJ,zHe,WHe,Wx,QHe,HHe,UHe,bs,cJ,JHe,YHe,Qx,KHe,ZHe,Hx,eUe,oUe,rUe,Vg,fJ,tUe,aUe,Ux,nUe,sUe,lUe,zg,mJ,iUe,dUe,Jx,cUe,fUe,mUe,vs,gJ,gUe,hUe,Yx,pUe,_Ue,Kx,uUe,bUe,vUe,Ts,hJ,TUe,FUe,Zx,CUe,MUe,ek,EUe,yUe,wUe,Wg,pJ,AUe,LUe,ok,BUe,xUe,kUe,Fs,_J,RUe,SUe,rk,PUe,$Ue,tk,IUe,jUe,DUe,Cs,uJ,NUe,qUe,ak,OUe,GUe,nk,XUe,VUe,zUe,Ms,bJ,WUe,QUe,sk,HUe,UUe,lk,JUe,YUe,KUe,Es,vJ,ZUe,eJe,ik,oJe,rJe,dk,tJe,aJe,nJe,ys,TJ,sJe,lJe,ck,iJe,dJe,fk,cJe,fJe,mJe,Qg,FJ,gJe,hJe,mk,pJe,_Je,uJe,Hg,CJ,bJe,vJe,gk,TJe,FJe,CJe,Ug,MJ,MJe,EJe,hk,yJe,wJe,AJe,Jg,EJ,LJe,BJe,pk,xJe,kJe,RJe,ws,yJ,SJe,PJe,_k,$Je,IJe,uk,jJe,DJe,NJe,Yg,wJ,qJe,OJe,bk,GJe,XJe,VJe,As,AJ,zJe,WJe,vk,QJe,HJe,Tk,UJe,JJe,YJe,Ls,LJ,KJe,ZJe,Fk,eYe,oYe,Ck,rYe,tYe,aYe,Bs,BJ,nYe,sYe,Mk,lYe,iYe,Ek,dYe,cYe,fYe,xs,xJ,mYe,gYe,yk,hYe,pYe,wk,_Ye,uYe,bYe,ks,kJ,vYe,TYe,Ak,FYe,CYe,Lk,MYe,EYe,yYe,Rs,RJ,wYe,AYe,Bk,LYe,BYe,xk,xYe,kYe,RYe,Kg,SJ,SYe,PYe,kk,$Ye,IYe,jYe,Zg,PJ,DYe,NYe,Rk,qYe,OYe,GYe,Ss,$J,XYe,VYe,Sk,zYe,WYe,Pk,QYe,HYe,UYe,Ps,IJ,JYe,YYe,$k,KYe,ZYe,Ik,eKe,oKe,rKe,$s,jJ,tKe,aKe,jk,nKe,sKe,Dk,lKe,iKe,dKe,eh,DJ,cKe,fKe,Nk,mKe,gKe,hKe,oh,NJ,pKe,_Ke,qk,uKe,bKe,vKe,rh,qJ,TKe,FKe,Ok,CKe,MKe,EKe,th,OJ,yKe,wKe,Gk,AKe,LKe,BKe,Is,GJ,xKe,kKe,Xk,RKe,SKe,Vk,PKe,$Ke,IKe,ah,XJ,jKe,DKe,zk,NKe,qKe,OKe,nh,VJ,GKe,XKe,Wk,VKe,zKe,WKe,js,zJ,QKe,HKe,Qk,UKe,JKe,Hk,YKe,KKe,ZKe,Ds,WJ,eZe,oZe,Uk,rZe,tZe,Jk,aZe,nZe,sZe,QJ,lZe,iZe,gE,dZe,sh,hE,cZe,HJ,fZe,Mxe,Qi,lh,UJ,pE,mZe,JJ,gZe,Exe,Ho,_E,hZe,uE,pZe,Yk,_Ze,uZe,bZe,bE,vZe,YJ,TZe,FZe,CZe,Ie,vE,MZe,KJ,EZe,yZe,Ga,wZe,ZJ,AZe,LZe,eY,BZe,xZe,oY,kZe,RZe,SZe,te,ih,rY,PZe,$Ze,Kk,IZe,jZe,DZe,dh,tY,NZe,qZe,Zk,OZe,GZe,XZe,ch,aY,VZe,zZe,eR,WZe,QZe,HZe,fh,nY,UZe,JZe,oR,YZe,KZe,ZZe,mh,sY,eeo,oeo,rR,reo,teo,aeo,gh,lY,neo,seo,tR,leo,ieo,deo,hh,iY,ceo,feo,aR,meo,geo,heo,ph,dY,peo,_eo,nR,ueo,beo,veo,_h,cY,Teo,Feo,sR,Ceo,Meo,Eeo,uh,fY,yeo,weo,lR,Aeo,Leo,Beo,bh,mY,xeo,keo,iR,Reo,Seo,Peo,vh,gY,$eo,Ieo,dR,jeo,Deo,Neo,Th,hY,qeo,Oeo,cR,Geo,Xeo,Veo,Fh,pY,zeo,Weo,fR,Qeo,Heo,Ueo,Ch,_Y,Jeo,Yeo,mR,Keo,Zeo,eoo,Mh,uY,ooo,roo,gR,too,aoo,noo,Eh,bY,soo,loo,hR,ioo,doo,coo,yh,foo,vY,moo,goo,TE,hoo,wh,FE,poo,TY,_oo,yxe,Hi,Ah,FY,CE,uoo,CY,boo,wxe,Uo,ME,voo,EE,Too,pR,Foo,Coo,Moo,yE,Eoo,MY,yoo,woo,Aoo,je,wE,Loo,EY,Boo,xoo,Ui,koo,yY,Roo,Soo,wY,Poo,$oo,Ioo,xe,Lh,AY,joo,Doo,_R,Noo,qoo,Ooo,Bh,LY,Goo,Xoo,uR,Voo,zoo,Woo,xh,BY,Qoo,Hoo,bR,Uoo,Joo,Yoo,kh,xY,Koo,Zoo,vR,ero,oro,rro,Rh,kY,tro,aro,TR,nro,sro,lro,Sh,RY,iro,dro,FR,cro,fro,mro,Ph,SY,gro,hro,CR,pro,_ro,uro,$h,PY,bro,vro,MR,Tro,Fro,Cro,Ih,Mro,$Y,Ero,yro,AE,wro,jh,LE,Aro,IY,Lro,Axe,Ji,Dh,jY,BE,Bro,DY,xro,Lxe,Jo,xE,kro,Yi,Rro,NY,Sro,Pro,qY,$ro,Iro,jro,kE,Dro,OY,Nro,qro,Oro,Vr,RE,Gro,GY,Xro,Vro,Ki,zro,XY,Wro,Qro,VY,Hro,Uro,Jro,zY,Yro,Kro,SE,Zro,De,PE,eto,WY,oto,rto,Xa,tto,QY,ato,nto,HY,sto,lto,UY,ito,dto,cto,F,Nh,JY,fto,mto,ER,gto,hto,pto,qh,YY,_to,uto,yR,bto,vto,Tto,Oh,KY,Fto,Cto,wR,Mto,Eto,yto,Gh,ZY,wto,Ato,AR,Lto,Bto,xto,Xh,eK,kto,Rto,LR,Sto,Pto,$to,Vh,oK,Ito,jto,BR,Dto,Nto,qto,zh,rK,Oto,Gto,xR,Xto,Vto,zto,Wh,tK,Wto,Qto,kR,Hto,Uto,Jto,Qh,aK,Yto,Kto,RR,Zto,eao,oao,Hh,nK,rao,tao,SR,aao,nao,sao,Uh,sK,lao,iao,PR,dao,cao,fao,Jh,lK,mao,gao,$R,hao,pao,_ao,Yh,iK,uao,bao,IR,vao,Tao,Fao,Kh,dK,Cao,Mao,jR,Eao,yao,wao,Zh,cK,Aao,Lao,DR,Bao,xao,kao,ep,fK,Rao,Sao,NR,Pao,$ao,Iao,op,mK,jao,Dao,qR,Nao,qao,Oao,rp,gK,Gao,Xao,OR,Vao,zao,Wao,tp,hK,Qao,Hao,GR,Uao,Jao,Yao,ap,pK,Kao,Zao,XR,eno,ono,rno,np,_K,tno,ano,VR,nno,sno,lno,sp,uK,ino,dno,zR,cno,fno,mno,lp,bK,gno,hno,WR,pno,_no,uno,ip,vK,bno,vno,QR,Tno,Fno,Cno,dp,TK,Mno,Eno,HR,yno,wno,Ano,cp,FK,Lno,Bno,UR,xno,kno,Rno,fp,CK,Sno,Pno,JR,$no,Ino,jno,Ns,MK,Dno,Nno,YR,qno,Ono,KR,Gno,Xno,Vno,mp,EK,zno,Wno,ZR,Qno,Hno,Uno,gp,yK,Jno,Yno,eS,Kno,Zno,eso,hp,wK,oso,rso,oS,tso,aso,nso,pp,AK,sso,lso,rS,iso,dso,cso,_p,LK,fso,mso,tS,gso,hso,pso,up,BK,_so,uso,aS,bso,vso,Tso,bp,xK,Fso,Cso,nS,Mso,Eso,yso,vp,kK,wso,Aso,sS,Lso,Bso,xso,Tp,RK,kso,Rso,lS,Sso,Pso,$so,Fp,SK,Iso,jso,iS,Dso,Nso,qso,Cp,PK,Oso,Gso,dS,Xso,Vso,zso,Mp,$K,Wso,Qso,cS,Hso,Uso,Jso,Ep,IK,Yso,Kso,fS,Zso,elo,olo,yp,jK,rlo,tlo,mS,alo,nlo,slo,wp,DK,llo,ilo,gS,dlo,clo,flo,Ap,NK,mlo,glo,hS,hlo,plo,_lo,Lp,qK,ulo,blo,pS,vlo,Tlo,Flo,Bp,OK,Clo,Mlo,_S,Elo,ylo,wlo,xp,GK,Alo,Llo,uS,Blo,xlo,klo,kp,XK,Rlo,Slo,bS,Plo,$lo,Ilo,Rp,VK,jlo,Dlo,vS,Nlo,qlo,Olo,Sp,zK,Glo,Xlo,TS,Vlo,zlo,Wlo,Pp,WK,Qlo,Hlo,FS,Ulo,Jlo,Ylo,$p,QK,Klo,Zlo,CS,eio,oio,rio,Ip,HK,tio,aio,MS,nio,sio,lio,jp,UK,iio,dio,ES,cio,fio,mio,Dp,JK,gio,hio,yS,pio,_io,uio,Np,YK,bio,vio,wS,Tio,Fio,Cio,qp,KK,Mio,Eio,AS,yio,wio,Aio,Op,ZK,Lio,Bio,LS,xio,kio,Rio,Gp,eZ,Sio,Pio,BS,$io,Iio,jio,Xp,oZ,Dio,Nio,xS,qio,Oio,Gio,Vp,rZ,Xio,Vio,kS,zio,Wio,Qio,zp,tZ,Hio,Uio,RS,Jio,Yio,Kio,Wp,aZ,Zio,edo,SS,odo,rdo,tdo,Qp,nZ,ado,ndo,PS,sdo,ldo,ido,Hp,sZ,ddo,cdo,$S,fdo,mdo,gdo,Up,lZ,hdo,pdo,IS,_do,udo,bdo,Jp,iZ,vdo,Tdo,jS,Fdo,Cdo,Mdo,Yp,dZ,Edo,ydo,DS,wdo,Ado,Ldo,Kp,cZ,Bdo,xdo,NS,kdo,Rdo,Sdo,Zp,fZ,Pdo,$do,qS,Ido,jdo,Ddo,e_,mZ,Ndo,qdo,OS,Odo,Gdo,Xdo,o_,gZ,Vdo,zdo,GS,Wdo,Qdo,Hdo,r_,hZ,Udo,Jdo,XS,Ydo,Kdo,Zdo,t_,pZ,eco,oco,VS,rco,tco,aco,a_,_Z,nco,sco,zS,lco,ico,dco,n_,uZ,cco,fco,WS,mco,gco,hco,s_,bZ,pco,_co,QS,uco,bco,vco,l_,vZ,Tco,Fco,HS,Cco,Mco,Eco,i_,TZ,yco,wco,US,Aco,Lco,Bco,d_,FZ,xco,kco,JS,Rco,Sco,Pco,c_,CZ,$co,Ico,YS,jco,Dco,Nco,f_,MZ,qco,Oco,KS,Gco,Xco,Vco,m_,EZ,zco,Wco,ZS,Qco,Hco,Uco,g_,yZ,Jco,Yco,eP,Kco,Zco,efo,h_,wZ,ofo,rfo,oP,tfo,afo,nfo,p_,AZ,sfo,lfo,rP,ifo,dfo,cfo,__,LZ,ffo,mfo,tP,gfo,hfo,pfo,u_,BZ,_fo,ufo,aP,bfo,vfo,Tfo,b_,Ffo,xZ,Cfo,Mfo,kZ,Efo,yfo,RZ,wfo,Afo,$E,Bxe,Zi,v_,SZ,IE,Lfo,PZ,Bfo,xxe,Yo,jE,xfo,ed,kfo,$Z,Rfo,Sfo,IZ,Pfo,$fo,Ifo,DE,jfo,jZ,Dfo,Nfo,qfo,zr,NE,Ofo,DZ,Gfo,Xfo,od,Vfo,NZ,zfo,Wfo,qZ,Qfo,Hfo,Ufo,OZ,Jfo,Yfo,qE,Kfo,Ne,OE,Zfo,GZ,emo,omo,Va,rmo,XZ,tmo,amo,VZ,nmo,smo,zZ,lmo,imo,dmo,k,T_,WZ,cmo,fmo,nP,mmo,gmo,hmo,F_,QZ,pmo,_mo,sP,umo,bmo,vmo,C_,HZ,Tmo,Fmo,lP,Cmo,Mmo,Emo,M_,UZ,ymo,wmo,iP,Amo,Lmo,Bmo,E_,JZ,xmo,kmo,dP,Rmo,Smo,Pmo,y_,YZ,$mo,Imo,cP,jmo,Dmo,Nmo,w_,KZ,qmo,Omo,fP,Gmo,Xmo,Vmo,A_,ZZ,zmo,Wmo,mP,Qmo,Hmo,Umo,L_,eee,Jmo,Ymo,gP,Kmo,Zmo,ego,B_,oee,ogo,rgo,hP,tgo,ago,ngo,x_,ree,sgo,lgo,pP,igo,dgo,cgo,k_,tee,fgo,mgo,_P,ggo,hgo,pgo,R_,aee,_go,ugo,uP,bgo,vgo,Tgo,S_,nee,Fgo,Cgo,bP,Mgo,Ego,ygo,P_,see,wgo,Ago,vP,Lgo,Bgo,xgo,$_,lee,kgo,Rgo,TP,Sgo,Pgo,$go,I_,iee,Igo,jgo,FP,Dgo,Ngo,qgo,j_,dee,Ogo,Ggo,CP,Xgo,Vgo,zgo,D_,cee,Wgo,Qgo,MP,Hgo,Ugo,Jgo,N_,fee,Ygo,Kgo,EP,Zgo,eho,oho,q_,mee,rho,tho,yP,aho,nho,sho,O_,gee,lho,iho,wP,dho,cho,fho,G_,hee,mho,gho,AP,hho,pho,_ho,X_,pee,uho,bho,LP,vho,Tho,Fho,V_,_ee,Cho,Mho,BP,Eho,yho,who,z_,uee,Aho,Lho,xP,Bho,xho,kho,W_,bee,Rho,Sho,kP,Pho,$ho,Iho,Q_,vee,jho,Dho,RP,Nho,qho,Oho,H_,Tee,Gho,Xho,SP,Vho,zho,Who,U_,Fee,Qho,Hho,PP,Uho,Jho,Yho,J_,Cee,Kho,Zho,$P,epo,opo,rpo,Y_,Mee,tpo,apo,IP,npo,spo,lpo,K_,Eee,ipo,dpo,jP,cpo,fpo,mpo,Z_,yee,gpo,hpo,DP,ppo,_po,upo,eu,wee,bpo,vpo,NP,Tpo,Fpo,Cpo,ou,Aee,Mpo,Epo,qP,ypo,wpo,Apo,ru,Lee,Lpo,Bpo,OP,xpo,kpo,Rpo,tu,Bee,Spo,Ppo,GP,$po,Ipo,jpo,au,xee,Dpo,Npo,XP,qpo,Opo,Gpo,nu,Xpo,kee,Vpo,zpo,Ree,Wpo,Qpo,See,Hpo,Upo,GE,kxe,rd,su,Pee,XE,Jpo,$ee,Ypo,Rxe,Ko,VE,Kpo,td,Zpo,Iee,e_o,o_o,jee,r_o,t_o,a_o,zE,n_o,Dee,s_o,l_o,i_o,Wr,WE,d_o,Nee,c_o,f_o,ad,m_o,qee,g_o,h_o,Oee,p_o,__o,u_o,Gee,b_o,v_o,QE,T_o,qe,HE,F_o,Xee,C_o,M_o,za,E_o,Vee,y_o,w_o,zee,A_o,L_o,Wee,B_o,x_o,k_o,$,lu,Qee,R_o,S_o,VP,P_o,$_o,I_o,iu,Hee,j_o,D_o,zP,N_o,q_o,O_o,du,Uee,G_o,X_o,WP,V_o,z_o,W_o,cu,Jee,Q_o,H_o,QP,U_o,J_o,Y_o,fu,Yee,K_o,Z_o,HP,euo,ouo,ruo,mu,Kee,tuo,auo,UP,nuo,suo,luo,gu,Zee,iuo,duo,JP,cuo,fuo,muo,hu,eoe,guo,huo,YP,puo,_uo,uuo,pu,ooe,buo,vuo,KP,Tuo,Fuo,Cuo,_u,roe,Muo,Euo,ZP,yuo,wuo,Auo,uu,toe,Luo,Buo,e$,xuo,kuo,Ruo,bu,aoe,Suo,Puo,o$,$uo,Iuo,juo,vu,noe,Duo,Nuo,r$,quo,Ouo,Guo,Tu,soe,Xuo,Vuo,t$,zuo,Wuo,Quo,Fu,loe,Huo,Uuo,a$,Juo,Yuo,Kuo,Cu,ioe,Zuo,e1o,n$,o1o,r1o,t1o,Mu,doe,a1o,n1o,s$,s1o,l1o,i1o,Eu,coe,d1o,c1o,l$,f1o,m1o,g1o,yu,foe,h1o,p1o,i$,_1o,u1o,b1o,wu,moe,v1o,T1o,d$,F1o,C1o,M1o,Au,goe,E1o,y1o,c$,w1o,A1o,L1o,Lu,hoe,B1o,x1o,f$,k1o,R1o,S1o,Bu,poe,P1o,$1o,m$,I1o,j1o,D1o,xu,_oe,N1o,q1o,g$,O1o,G1o,X1o,ku,uoe,V1o,z1o,h$,W1o,Q1o,H1o,Ru,boe,U1o,J1o,p$,Y1o,K1o,Z1o,Su,voe,e7o,o7o,_$,r7o,t7o,a7o,Pu,Toe,n7o,s7o,u$,l7o,i7o,d7o,$u,Foe,c7o,f7o,b$,m7o,g7o,h7o,Iu,Coe,p7o,_7o,v$,u7o,b7o,v7o,ju,Moe,T7o,F7o,T$,C7o,M7o,E7o,Du,Eoe,y7o,w7o,F$,A7o,L7o,B7o,Nu,yoe,x7o,k7o,C$,R7o,S7o,P7o,qu,woe,$7o,I7o,M$,j7o,D7o,N7o,Ou,Aoe,q7o,O7o,E$,G7o,X7o,V7o,Gu,z7o,Loe,W7o,Q7o,Boe,H7o,U7o,xoe,J7o,Y7o,UE,Sxe,nd,Xu,koe,JE,K7o,Roe,Z7o,Pxe,Zo,YE,ebo,sd,obo,Soe,rbo,tbo,Poe,abo,nbo,sbo,KE,lbo,$oe,ibo,dbo,cbo,Qr,ZE,fbo,Ioe,mbo,gbo,ld,hbo,joe,pbo,_bo,Doe,ubo,bbo,vbo,Noe,Tbo,Fbo,e3,Cbo,Oe,o3,Mbo,qoe,Ebo,ybo,Wa,wbo,Ooe,Abo,Lbo,Goe,Bbo,xbo,Xoe,kbo,Rbo,Sbo,I,Vu,Voe,Pbo,$bo,y$,Ibo,jbo,Dbo,zu,zoe,Nbo,qbo,w$,Obo,Gbo,Xbo,Wu,Woe,Vbo,zbo,A$,Wbo,Qbo,Hbo,Qu,Qoe,Ubo,Jbo,L$,Ybo,Kbo,Zbo,Hu,Hoe,e5o,o5o,B$,r5o,t5o,a5o,Uu,Uoe,n5o,s5o,x$,l5o,i5o,d5o,Ju,Joe,c5o,f5o,k$,m5o,g5o,h5o,Yu,Yoe,p5o,_5o,R$,u5o,b5o,v5o,Ku,Koe,T5o,F5o,S$,C5o,M5o,E5o,Zu,Zoe,y5o,w5o,P$,A5o,L5o,B5o,e1,ere,x5o,k5o,$$,R5o,S5o,P5o,o1,ore,$5o,I5o,I$,j5o,D5o,N5o,r1,rre,q5o,O5o,j$,G5o,X5o,V5o,t1,tre,z5o,W5o,D$,Q5o,H5o,U5o,a1,are,J5o,Y5o,N$,K5o,Z5o,e2o,n1,nre,o2o,r2o,q$,t2o,a2o,n2o,s1,sre,s2o,l2o,O$,i2o,d2o,c2o,l1,lre,f2o,m2o,G$,g2o,h2o,p2o,i1,ire,_2o,u2o,X$,b2o,v2o,T2o,d1,dre,F2o,C2o,V$,M2o,E2o,y2o,c1,cre,w2o,A2o,z$,L2o,B2o,x2o,f1,fre,k2o,R2o,W$,S2o,P2o,$2o,m1,mre,I2o,j2o,Q$,D2o,N2o,q2o,g1,gre,O2o,G2o,H$,X2o,V2o,z2o,h1,hre,W2o,Q2o,U$,H2o,U2o,J2o,p1,pre,Y2o,K2o,J$,Z2o,evo,ovo,_1,_re,rvo,tvo,Y$,avo,nvo,svo,u1,ure,lvo,ivo,K$,dvo,cvo,fvo,b1,bre,mvo,gvo,Z$,hvo,pvo,_vo,v1,vre,uvo,bvo,eI,vvo,Tvo,Fvo,T1,Tre,Cvo,Mvo,Fre,Evo,yvo,wvo,F1,Cre,Avo,Lvo,oI,Bvo,xvo,kvo,C1,Mre,Rvo,Svo,rI,Pvo,$vo,Ivo,M1,Ere,jvo,Dvo,tI,Nvo,qvo,Ovo,E1,yre,Gvo,Xvo,aI,Vvo,zvo,Wvo,y1,Qvo,wre,Hvo,Uvo,Are,Jvo,Yvo,Lre,Kvo,Zvo,r3,$xe,id,w1,Bre,t3,e0o,xre,o0o,Ixe,er,a3,r0o,dd,t0o,kre,a0o,n0o,Rre,s0o,l0o,i0o,n3,d0o,Sre,c0o,f0o,m0o,Hr,s3,g0o,Pre,h0o,p0o,cd,_0o,$re,u0o,b0o,Ire,v0o,T0o,F0o,jre,C0o,M0o,l3,E0o,Ge,i3,y0o,Dre,w0o,A0o,Qa,L0o,Nre,B0o,x0o,qre,k0o,R0o,Ore,S0o,P0o,$0o,ne,A1,Gre,I0o,j0o,nI,D0o,N0o,q0o,L1,Xre,O0o,G0o,sI,X0o,V0o,z0o,B1,Vre,W0o,Q0o,lI,H0o,U0o,J0o,x1,zre,Y0o,K0o,iI,Z0o,eTo,oTo,k1,Wre,rTo,tTo,dI,aTo,nTo,sTo,R1,Qre,lTo,iTo,cI,dTo,cTo,fTo,S1,Hre,mTo,gTo,fI,hTo,pTo,_To,P1,Ure,uTo,bTo,mI,vTo,TTo,FTo,$1,Jre,CTo,MTo,gI,ETo,yTo,wTo,I1,Yre,ATo,LTo,hI,BTo,xTo,kTo,j1,Kre,RTo,STo,pI,PTo,$To,ITo,D1,Zre,jTo,DTo,_I,NTo,qTo,OTo,N1,ete,GTo,XTo,uI,VTo,zTo,WTo,q1,ote,QTo,HTo,bI,UTo,JTo,YTo,O1,rte,KTo,ZTo,vI,eFo,oFo,rFo,G1,tte,tFo,aFo,TI,nFo,sFo,lFo,X1,iFo,ate,dFo,cFo,nte,fFo,mFo,ste,gFo,hFo,d3,jxe,fd,V1,lte,c3,pFo,ite,_Fo,Dxe,or,f3,uFo,md,bFo,dte,vFo,TFo,cte,FFo,CFo,MFo,m3,EFo,fte,yFo,wFo,AFo,Ur,g3,LFo,mte,BFo,xFo,gd,kFo,gte,RFo,SFo,hte,PFo,$Fo,IFo,pte,jFo,DFo,h3,NFo,Xe,p3,qFo,_te,OFo,GFo,Ha,XFo,ute,VFo,zFo,bte,WFo,QFo,vte,HFo,UFo,JFo,A,z1,Tte,YFo,KFo,FI,ZFo,eCo,oCo,W1,Fte,rCo,tCo,CI,aCo,nCo,sCo,Q1,Cte,lCo,iCo,MI,dCo,cCo,fCo,H1,Mte,mCo,gCo,EI,hCo,pCo,_Co,U1,Ete,uCo,bCo,yI,vCo,TCo,FCo,J1,yte,CCo,MCo,wI,ECo,yCo,wCo,Y1,wte,ACo,LCo,AI,BCo,xCo,kCo,K1,Ate,RCo,SCo,LI,PCo,$Co,ICo,Z1,Lte,jCo,DCo,BI,NCo,qCo,OCo,e7,Bte,GCo,XCo,xI,VCo,zCo,WCo,o7,xte,QCo,HCo,kI,UCo,JCo,YCo,r7,kte,KCo,ZCo,RI,eMo,oMo,rMo,t7,Rte,tMo,aMo,SI,nMo,sMo,lMo,a7,Ste,iMo,dMo,PI,cMo,fMo,mMo,n7,Pte,gMo,hMo,$I,pMo,_Mo,uMo,s7,$te,bMo,vMo,II,TMo,FMo,CMo,l7,Ite,MMo,EMo,jI,yMo,wMo,AMo,i7,jte,LMo,BMo,DI,xMo,kMo,RMo,d7,Dte,SMo,PMo,NI,$Mo,IMo,jMo,c7,Nte,DMo,NMo,qI,qMo,OMo,GMo,f7,qte,XMo,VMo,OI,zMo,WMo,QMo,m7,Ote,HMo,UMo,GI,JMo,YMo,KMo,g7,Gte,ZMo,e4o,XI,o4o,r4o,t4o,h7,Xte,a4o,n4o,VI,s4o,l4o,i4o,p7,Vte,d4o,c4o,zI,f4o,m4o,g4o,_7,zte,h4o,p4o,WI,_4o,u4o,b4o,u7,Wte,v4o,T4o,QI,F4o,C4o,M4o,b7,Qte,E4o,y4o,HI,w4o,A4o,L4o,v7,Hte,B4o,x4o,UI,k4o,R4o,S4o,T7,Ute,P4o,$4o,JI,I4o,j4o,D4o,F7,Jte,N4o,q4o,YI,O4o,G4o,X4o,C7,Yte,V4o,z4o,KI,W4o,Q4o,H4o,M7,Kte,U4o,J4o,ZI,Y4o,K4o,Z4o,E7,Zte,eEo,oEo,ej,rEo,tEo,aEo,y7,eae,nEo,sEo,oj,lEo,iEo,dEo,w7,oae,cEo,fEo,rj,mEo,gEo,hEo,A7,rae,pEo,_Eo,tj,uEo,bEo,vEo,L7,tae,TEo,FEo,aj,CEo,MEo,EEo,B7,aae,yEo,wEo,nj,AEo,LEo,BEo,x7,nae,xEo,kEo,sj,REo,SEo,PEo,k7,sae,$Eo,IEo,lj,jEo,DEo,NEo,R7,lae,qEo,OEo,ij,GEo,XEo,VEo,S7,iae,zEo,WEo,dj,QEo,HEo,UEo,P7,dae,JEo,YEo,cj,KEo,ZEo,e3o,$7,cae,o3o,r3o,fj,t3o,a3o,n3o,I7,fae,s3o,l3o,mj,i3o,d3o,c3o,j7,f3o,mae,m3o,g3o,gae,h3o,p3o,hae,_3o,u3o,_3,Nxe,hd,D7,pae,u3,b3o,_ae,v3o,qxe,rr,b3,T3o,pd,F3o,uae,C3o,M3o,bae,E3o,y3o,w3o,v3,A3o,vae,L3o,B3o,x3o,Jr,T3,k3o,Tae,R3o,S3o,_d,P3o,Fae,$3o,I3o,Cae,j3o,D3o,N3o,Mae,q3o,O3o,F3,G3o,Ve,C3,X3o,Eae,V3o,z3o,Ua,W3o,yae,Q3o,H3o,wae,U3o,J3o,Aae,Y3o,K3o,Z3o,O,N7,Lae,eyo,oyo,gj,ryo,tyo,ayo,q7,Bae,nyo,syo,hj,lyo,iyo,dyo,O7,xae,cyo,fyo,pj,myo,gyo,hyo,G7,kae,pyo,_yo,_j,uyo,byo,vyo,X7,Rae,Tyo,Fyo,uj,Cyo,Myo,Eyo,V7,Sae,yyo,wyo,bj,Ayo,Lyo,Byo,z7,Pae,xyo,kyo,vj,Ryo,Syo,Pyo,W7,$ae,$yo,Iyo,Tj,jyo,Dyo,Nyo,Q7,Iae,qyo,Oyo,Fj,Gyo,Xyo,Vyo,H7,jae,zyo,Wyo,Cj,Qyo,Hyo,Uyo,U7,Dae,Jyo,Yyo,Mj,Kyo,Zyo,ewo,J7,Nae,owo,rwo,Ej,two,awo,nwo,Y7,qae,swo,lwo,yj,iwo,dwo,cwo,K7,Oae,fwo,mwo,wj,gwo,hwo,pwo,Z7,Gae,_wo,uwo,Aj,bwo,vwo,Two,eb,Xae,Fwo,Cwo,Lj,Mwo,Ewo,ywo,ob,Vae,wwo,Awo,Bj,Lwo,Bwo,xwo,rb,zae,kwo,Rwo,xj,Swo,Pwo,$wo,tb,Wae,Iwo,jwo,kj,Dwo,Nwo,qwo,ab,Qae,Owo,Gwo,Rj,Xwo,Vwo,zwo,nb,Hae,Wwo,Qwo,Sj,Hwo,Uwo,Jwo,sb,Uae,Ywo,Kwo,Pj,Zwo,e6o,o6o,lb,Jae,r6o,t6o,$j,a6o,n6o,s6o,ib,Yae,l6o,i6o,Ij,d6o,c6o,f6o,db,Kae,m6o,g6o,jj,h6o,p6o,_6o,cb,Zae,u6o,b6o,Dj,v6o,T6o,F6o,fb,ene,C6o,M6o,Nj,E6o,y6o,w6o,mb,one,A6o,L6o,qj,B6o,x6o,k6o,gb,R6o,rne,S6o,P6o,tne,$6o,I6o,ane,j6o,D6o,M3,Oxe,ud,hb,nne,E3,N6o,sne,q6o,Gxe,tr,y3,O6o,bd,G6o,lne,X6o,V6o,ine,z6o,W6o,Q6o,w3,H6o,dne,U6o,J6o,Y6o,Yr,A3,K6o,cne,Z6o,eAo,vd,oAo,fne,rAo,tAo,mne,aAo,nAo,sAo,gne,lAo,iAo,L3,dAo,ze,B3,cAo,hne,fAo,mAo,Ja,gAo,pne,hAo,pAo,_ne,_Ao,uAo,une,bAo,vAo,TAo,da,pb,bne,FAo,CAo,Oj,MAo,EAo,yAo,_b,vne,wAo,AAo,Gj,LAo,BAo,xAo,ub,Tne,kAo,RAo,Xj,SAo,PAo,$Ao,bb,Fne,IAo,jAo,Vj,DAo,NAo,qAo,vb,Cne,OAo,GAo,zj,XAo,VAo,zAo,Tb,WAo,Mne,QAo,HAo,Ene,UAo,JAo,yne,YAo,KAo,x3,Xxe,Td,Fb,wne,k3,ZAo,Ane,eLo,Vxe,ar,R3,oLo,Fd,rLo,Lne,tLo,aLo,Bne,nLo,sLo,lLo,S3,iLo,xne,dLo,cLo,fLo,Kr,P3,mLo,kne,gLo,hLo,Cd,pLo,Rne,_Lo,uLo,Sne,bLo,vLo,TLo,Pne,FLo,CLo,$3,MLo,We,I3,ELo,$ne,yLo,wLo,Ya,ALo,Ine,LLo,BLo,jne,xLo,kLo,Dne,RLo,SLo,PLo,N,Cb,Nne,$Lo,ILo,Wj,jLo,DLo,NLo,Mb,qne,qLo,OLo,Qj,GLo,XLo,VLo,Eb,One,zLo,WLo,Hj,QLo,HLo,ULo,yb,Gne,JLo,YLo,Uj,KLo,ZLo,e8o,wb,Xne,o8o,r8o,Jj,t8o,a8o,n8o,Ab,Vne,s8o,l8o,Yj,i8o,d8o,c8o,Lb,zne,f8o,m8o,Kj,g8o,h8o,p8o,Bb,Wne,_8o,u8o,Zj,b8o,v8o,T8o,xb,Qne,F8o,C8o,eD,M8o,E8o,y8o,kb,Hne,w8o,A8o,oD,L8o,B8o,x8o,Rb,Une,k8o,R8o,rD,S8o,P8o,$8o,Sb,Jne,I8o,j8o,tD,D8o,N8o,q8o,Pb,Yne,O8o,G8o,aD,X8o,V8o,z8o,$b,Kne,W8o,Q8o,nD,H8o,U8o,J8o,Ib,Zne,Y8o,K8o,sD,Z8o,e9o,o9o,jb,ese,r9o,t9o,lD,a9o,n9o,s9o,Db,ose,l9o,i9o,iD,d9o,c9o,f9o,Nb,rse,m9o,g9o,dD,h9o,p9o,_9o,qb,tse,u9o,b9o,cD,v9o,T9o,F9o,Ob,ase,C9o,M9o,fD,E9o,y9o,w9o,Gb,nse,A9o,L9o,mD,B9o,x9o,k9o,Xb,sse,R9o,S9o,gD,P9o,$9o,I9o,Vb,lse,j9o,D9o,hD,N9o,q9o,O9o,zb,ise,G9o,X9o,pD,V9o,z9o,W9o,Wb,dse,Q9o,H9o,_D,U9o,J9o,Y9o,Qb,cse,K9o,Z9o,uD,eBo,oBo,rBo,Hb,fse,tBo,aBo,bD,nBo,sBo,lBo,Ub,mse,iBo,dBo,vD,cBo,fBo,mBo,Jb,gse,gBo,hBo,TD,pBo,_Bo,uBo,Yb,hse,bBo,vBo,FD,TBo,FBo,CBo,Kb,pse,MBo,EBo,CD,yBo,wBo,ABo,Zb,_se,LBo,BBo,MD,xBo,kBo,RBo,e5,use,SBo,PBo,ED,$Bo,IBo,jBo,o5,DBo,bse,NBo,qBo,vse,OBo,GBo,Tse,XBo,VBo,j3,zxe,Md,r5,Fse,D3,zBo,Cse,WBo,Wxe,nr,N3,QBo,Ed,HBo,Mse,UBo,JBo,Ese,YBo,KBo,ZBo,q3,exo,yse,oxo,rxo,txo,Zr,O3,axo,wse,nxo,sxo,yd,lxo,Ase,ixo,dxo,Lse,cxo,fxo,mxo,Bse,gxo,hxo,G3,pxo,Qe,X3,_xo,xse,uxo,bxo,Ka,vxo,kse,Txo,Fxo,Rse,Cxo,Mxo,Sse,Exo,yxo,wxo,R,t5,Pse,Axo,Lxo,yD,Bxo,xxo,kxo,a5,$se,Rxo,Sxo,wD,Pxo,$xo,Ixo,n5,Ise,jxo,Dxo,AD,Nxo,qxo,Oxo,s5,jse,Gxo,Xxo,LD,Vxo,zxo,Wxo,l5,Dse,Qxo,Hxo,BD,Uxo,Jxo,Yxo,i5,Nse,Kxo,Zxo,xD,eko,oko,rko,d5,qse,tko,ako,kD,nko,sko,lko,c5,Ose,iko,dko,RD,cko,fko,mko,f5,Gse,gko,hko,SD,pko,_ko,uko,m5,Xse,bko,vko,PD,Tko,Fko,Cko,g5,Vse,Mko,Eko,$D,yko,wko,Ako,h5,zse,Lko,Bko,ID,xko,kko,Rko,p5,Wse,Sko,Pko,jD,$ko,Iko,jko,_5,Qse,Dko,Nko,DD,qko,Oko,Gko,u5,Hse,Xko,Vko,ND,zko,Wko,Qko,b5,Use,Hko,Uko,qD,Jko,Yko,Kko,v5,Jse,Zko,eRo,OD,oRo,rRo,tRo,T5,Yse,aRo,nRo,GD,sRo,lRo,iRo,F5,Kse,dRo,cRo,XD,fRo,mRo,gRo,C5,Zse,hRo,pRo,VD,_Ro,uRo,bRo,M5,ele,vRo,TRo,zD,FRo,CRo,MRo,E5,ole,ERo,yRo,WD,wRo,ARo,LRo,y5,rle,BRo,xRo,QD,kRo,RRo,SRo,w5,tle,PRo,$Ro,HD,IRo,jRo,DRo,A5,ale,NRo,qRo,UD,ORo,GRo,XRo,L5,nle,VRo,zRo,JD,WRo,QRo,HRo,B5,sle,URo,JRo,YD,YRo,KRo,ZRo,x5,lle,eSo,oSo,KD,rSo,tSo,aSo,k5,ile,nSo,sSo,ZD,lSo,iSo,dSo,R5,dle,cSo,fSo,eN,mSo,gSo,hSo,S5,cle,pSo,_So,oN,uSo,bSo,vSo,P5,fle,TSo,FSo,rN,CSo,MSo,ESo,$5,mle,ySo,wSo,tN,ASo,LSo,BSo,I5,gle,xSo,kSo,aN,RSo,SSo,PSo,j5,hle,$So,ISo,nN,jSo,DSo,NSo,D5,ple,qSo,OSo,sN,GSo,XSo,VSo,N5,_le,zSo,WSo,lN,QSo,HSo,USo,q5,ule,JSo,YSo,iN,KSo,ZSo,ePo,O5,ble,oPo,rPo,dN,tPo,aPo,nPo,G5,sPo,vle,lPo,iPo,Tle,dPo,cPo,Fle,fPo,mPo,V3,Qxe,wd,X5,Cle,z3,gPo,Mle,hPo,Hxe,sr,W3,pPo,Ad,_Po,Ele,uPo,bPo,yle,vPo,TPo,FPo,Q3,CPo,wle,MPo,EPo,yPo,et,H3,wPo,Ale,APo,LPo,Ld,BPo,Lle,xPo,kPo,Ble,RPo,SPo,PPo,xle,$Po,IPo,U3,jPo,He,J3,DPo,kle,NPo,qPo,Za,OPo,Rle,GPo,XPo,Sle,VPo,zPo,Ple,WPo,QPo,HPo,$le,V5,Ile,UPo,JPo,cN,YPo,KPo,ZPo,z5,e$o,jle,o$o,r$o,Dle,t$o,a$o,Nle,n$o,s$o,Y3,Uxe,Bd,W5,qle,K3,l$o,Ole,i$o,Jxe,lr,Z3,d$o,xd,c$o,Gle,f$o,m$o,Xle,g$o,h$o,p$o,ey,_$o,Vle,u$o,b$o,v$o,ot,oy,T$o,zle,F$o,C$o,kd,M$o,Wle,E$o,y$o,Qle,w$o,A$o,L$o,Hle,B$o,x$o,ry,k$o,Ue,ty,R$o,Ule,S$o,P$o,en,$$o,Jle,I$o,j$o,Yle,D$o,N$o,Kle,q$o,O$o,G$o,pe,Q5,Zle,X$o,V$o,fN,z$o,W$o,Q$o,H5,eie,H$o,U$o,mN,J$o,Y$o,K$o,qs,oie,Z$o,eIo,gN,oIo,rIo,hN,tIo,aIo,nIo,U5,rie,sIo,lIo,pN,iIo,dIo,cIo,fa,tie,fIo,mIo,_N,gIo,hIo,uN,pIo,_Io,bN,uIo,bIo,vIo,J5,aie,TIo,FIo,vN,CIo,MIo,EIo,Y5,nie,yIo,wIo,TN,AIo,LIo,BIo,K5,sie,xIo,kIo,FN,RIo,SIo,PIo,Z5,lie,$Io,IIo,CN,jIo,DIo,NIo,e2,iie,qIo,OIo,MN,GIo,XIo,VIo,o2,zIo,die,WIo,QIo,cie,HIo,UIo,fie,JIo,YIo,ay,Yxe,Rd,r2,mie,ny,KIo,gie,ZIo,Kxe,ir,sy,ejo,Sd,ojo,hie,rjo,tjo,pie,ajo,njo,sjo,ly,ljo,_ie,ijo,djo,cjo,rt,iy,fjo,uie,mjo,gjo,Pd,hjo,bie,pjo,_jo,vie,ujo,bjo,vjo,Tie,Tjo,Fjo,dy,Cjo,Je,cy,Mjo,Fie,Ejo,yjo,on,wjo,Cie,Ajo,Ljo,Mie,Bjo,xjo,Eie,kjo,Rjo,Sjo,yie,t2,wie,Pjo,$jo,EN,Ijo,jjo,Djo,a2,Njo,Aie,qjo,Ojo,Lie,Gjo,Xjo,Bie,Vjo,zjo,fy,Zxe,$d,n2,xie,my,Wjo,kie,Qjo,eke,dr,gy,Hjo,Id,Ujo,Rie,Jjo,Yjo,Sie,Kjo,Zjo,eDo,hy,oDo,Pie,rDo,tDo,aDo,tt,py,nDo,$ie,sDo,lDo,jd,iDo,Iie,dDo,cDo,jie,fDo,mDo,gDo,Die,hDo,pDo,_y,_Do,Ye,uy,uDo,Nie,bDo,vDo,rn,TDo,qie,FDo,CDo,Oie,MDo,EDo,Gie,yDo,wDo,ADo,ke,s2,Xie,LDo,BDo,yN,xDo,kDo,RDo,l2,Vie,SDo,PDo,wN,$Do,IDo,jDo,i2,zie,DDo,NDo,AN,qDo,ODo,GDo,d2,Wie,XDo,VDo,LN,zDo,WDo,QDo,c2,Qie,HDo,UDo,BN,JDo,YDo,KDo,f2,Hie,ZDo,eNo,xN,oNo,rNo,tNo,m2,Uie,aNo,nNo,kN,sNo,lNo,iNo,g2,Jie,dNo,cNo,RN,fNo,mNo,gNo,h2,hNo,Yie,pNo,_No,Kie,uNo,bNo,Zie,vNo,TNo,by,oke,Dd,p2,ede,vy,FNo,ode,CNo,rke,cr,Ty,MNo,Nd,ENo,rde,yNo,wNo,tde,ANo,LNo,BNo,Fy,xNo,ade,kNo,RNo,SNo,at,Cy,PNo,nde,$No,INo,qd,jNo,sde,DNo,NNo,lde,qNo,ONo,GNo,ide,XNo,VNo,My,zNo,Ke,Ey,WNo,dde,QNo,HNo,tn,UNo,cde,JNo,YNo,fde,KNo,ZNo,mde,eqo,oqo,rqo,an,_2,gde,tqo,aqo,SN,nqo,sqo,lqo,u2,hde,iqo,dqo,PN,cqo,fqo,mqo,b2,pde,gqo,hqo,$N,pqo,_qo,uqo,v2,_de,bqo,vqo,IN,Tqo,Fqo,Cqo,T2,Mqo,ude,Eqo,yqo,bde,wqo,Aqo,vde,Lqo,Bqo,yy,tke,Od,F2,Tde,wy,xqo,Fde,kqo,ake,fr,Ay,Rqo,Gd,Sqo,Cde,Pqo,$qo,Mde,Iqo,jqo,Dqo,Ly,Nqo,Ede,qqo,Oqo,Gqo,nt,By,Xqo,yde,Vqo,zqo,Xd,Wqo,wde,Qqo,Hqo,Ade,Uqo,Jqo,Yqo,Lde,Kqo,Zqo,xy,eOo,Ze,ky,oOo,Bde,rOo,tOo,nn,aOo,xde,nOo,sOo,kde,lOo,iOo,Rde,dOo,cOo,fOo,Re,C2,Sde,mOo,gOo,jN,hOo,pOo,_Oo,M2,Pde,uOo,bOo,DN,vOo,TOo,FOo,E2,$de,COo,MOo,NN,EOo,yOo,wOo,y2,Ide,AOo,LOo,qN,BOo,xOo,kOo,w2,jde,ROo,SOo,ON,POo,$Oo,IOo,A2,Dde,jOo,DOo,GN,NOo,qOo,OOo,L2,Nde,GOo,XOo,XN,VOo,zOo,WOo,B2,qde,QOo,HOo,VN,UOo,JOo,YOo,x2,KOo,Ode,ZOo,eGo,Gde,oGo,rGo,Xde,tGo,aGo,Ry,nke,Vd,k2,Vde,Sy,nGo,zde,sGo,ske,mr,Py,lGo,zd,iGo,Wde,dGo,cGo,Qde,fGo,mGo,gGo,$y,hGo,Hde,pGo,_Go,uGo,st,Iy,bGo,Ude,vGo,TGo,Wd,FGo,Jde,CGo,MGo,Yde,EGo,yGo,wGo,Kde,AGo,LGo,jy,BGo,eo,Dy,xGo,Zde,kGo,RGo,sn,SGo,ece,PGo,$Go,oce,IGo,jGo,rce,DGo,NGo,qGo,Ny,R2,tce,OGo,GGo,zN,XGo,VGo,zGo,S2,ace,WGo,QGo,WN,HGo,UGo,JGo,P2,YGo,nce,KGo,ZGo,sce,eXo,oXo,lce,rXo,tXo,qy,lke,Qd,$2,ice,Oy,aXo,dce,nXo,ike,gr,Gy,sXo,Hd,lXo,cce,iXo,dXo,fce,cXo,fXo,mXo,Xy,gXo,mce,hXo,pXo,_Xo,lt,Vy,uXo,gce,bXo,vXo,Ud,TXo,hce,FXo,CXo,pce,MXo,EXo,yXo,_ce,wXo,AXo,zy,LXo,oo,Wy,BXo,uce,xXo,kXo,ln,RXo,bce,SXo,PXo,vce,$Xo,IXo,Tce,jXo,DXo,NXo,dn,I2,Fce,qXo,OXo,QN,GXo,XXo,VXo,j2,Cce,zXo,WXo,HN,QXo,HXo,UXo,D2,Mce,JXo,YXo,UN,KXo,ZXo,eVo,N2,Ece,oVo,rVo,JN,tVo,aVo,nVo,q2,sVo,yce,lVo,iVo,wce,dVo,cVo,Ace,fVo,mVo,Qy,dke,Jd,O2,Lce,Hy,gVo,Bce,hVo,cke,hr,Uy,pVo,Yd,_Vo,xce,uVo,bVo,kce,vVo,TVo,FVo,Jy,CVo,Rce,MVo,EVo,yVo,it,Yy,wVo,Sce,AVo,LVo,Kd,BVo,Pce,xVo,kVo,$ce,RVo,SVo,PVo,Ice,$Vo,IVo,Ky,jVo,ro,Zy,DVo,jce,NVo,qVo,cn,OVo,Dce,GVo,XVo,Nce,VVo,zVo,qce,WVo,QVo,HVo,Zd,G2,Oce,UVo,JVo,YN,YVo,KVo,ZVo,X2,Gce,ezo,ozo,KN,rzo,tzo,azo,V2,Xce,nzo,szo,ZN,lzo,izo,dzo,z2,czo,Vce,fzo,mzo,zce,gzo,hzo,Wce,pzo,_zo,ew,fke,ec,W2,Qce,ow,uzo,Hce,bzo,mke,pr,rw,vzo,oc,Tzo,Uce,Fzo,Czo,Jce,Mzo,Ezo,yzo,tw,wzo,Yce,Azo,Lzo,Bzo,dt,aw,xzo,Kce,kzo,Rzo,rc,Szo,Zce,Pzo,$zo,efe,Izo,jzo,Dzo,ofe,Nzo,qzo,nw,Ozo,to,sw,Gzo,rfe,Xzo,Vzo,fn,zzo,tfe,Wzo,Qzo,afe,Hzo,Uzo,nfe,Jzo,Yzo,Kzo,sfe,Q2,lfe,Zzo,eWo,eq,oWo,rWo,tWo,H2,aWo,ife,nWo,sWo,dfe,lWo,iWo,cfe,dWo,cWo,lw,gke,tc,U2,ffe,iw,fWo,mfe,mWo,hke,_r,dw,gWo,ac,hWo,gfe,pWo,_Wo,hfe,uWo,bWo,vWo,cw,TWo,pfe,FWo,CWo,MWo,ct,fw,EWo,_fe,yWo,wWo,nc,AWo,ufe,LWo,BWo,bfe,xWo,kWo,RWo,vfe,SWo,PWo,mw,$Wo,ao,gw,IWo,Tfe,jWo,DWo,mn,NWo,Ffe,qWo,OWo,Cfe,GWo,XWo,Mfe,VWo,zWo,WWo,Efe,J2,yfe,QWo,HWo,oq,UWo,JWo,YWo,Y2,KWo,wfe,ZWo,eQo,Afe,oQo,rQo,Lfe,tQo,aQo,hw,pke,sc,K2,Bfe,pw,nQo,xfe,sQo,_ke,ur,_w,lQo,lc,iQo,kfe,dQo,cQo,Rfe,fQo,mQo,gQo,uw,hQo,Sfe,pQo,_Qo,uQo,ft,bw,bQo,Pfe,vQo,TQo,ic,FQo,$fe,CQo,MQo,Ife,EQo,yQo,wQo,jfe,AQo,LQo,vw,BQo,no,Tw,xQo,Dfe,kQo,RQo,gn,SQo,Nfe,PQo,$Qo,qfe,IQo,jQo,Ofe,DQo,NQo,qQo,Fw,Z2,Gfe,OQo,GQo,rq,XQo,VQo,zQo,ev,Xfe,WQo,QQo,tq,HQo,UQo,JQo,ov,YQo,Vfe,KQo,ZQo,zfe,eHo,oHo,Wfe,rHo,tHo,Cw,uke,dc,rv,Qfe,Mw,aHo,Hfe,nHo,bke,br,Ew,sHo,cc,lHo,Ufe,iHo,dHo,Jfe,cHo,fHo,mHo,yw,gHo,Yfe,hHo,pHo,_Ho,mt,ww,uHo,Kfe,bHo,vHo,fc,THo,Zfe,FHo,CHo,eme,MHo,EHo,yHo,ome,wHo,AHo,Aw,LHo,so,Lw,BHo,rme,xHo,kHo,hn,RHo,tme,SHo,PHo,ame,$Ho,IHo,nme,jHo,DHo,NHo,sme,tv,lme,qHo,OHo,aq,GHo,XHo,VHo,av,zHo,ime,WHo,QHo,dme,HHo,UHo,cme,JHo,YHo,Bw,vke,mc,nv,fme,xw,KHo,mme,ZHo,Tke,vr,kw,eUo,gc,oUo,gme,rUo,tUo,hme,aUo,nUo,sUo,Rw,lUo,pme,iUo,dUo,cUo,gt,Sw,fUo,_me,mUo,gUo,hc,hUo,ume,pUo,_Uo,bme,uUo,bUo,vUo,vme,TUo,FUo,Pw,CUo,ho,$w,MUo,Tme,EUo,yUo,pn,wUo,Fme,AUo,LUo,Cme,BUo,xUo,Mme,kUo,RUo,SUo,B,sv,Eme,PUo,$Uo,nq,IUo,jUo,DUo,lv,yme,NUo,qUo,sq,OUo,GUo,XUo,iv,wme,VUo,zUo,lq,WUo,QUo,HUo,dv,Ame,UUo,JUo,iq,YUo,KUo,ZUo,cv,Lme,eJo,oJo,dq,rJo,tJo,aJo,fv,Bme,nJo,sJo,cq,lJo,iJo,dJo,mv,xme,cJo,fJo,fq,mJo,gJo,hJo,gv,kme,pJo,_Jo,mq,uJo,bJo,vJo,hv,Rme,TJo,FJo,gq,CJo,MJo,EJo,pv,Sme,yJo,wJo,hq,AJo,LJo,BJo,_v,Pme,xJo,kJo,pq,RJo,SJo,PJo,uv,$me,$Jo,IJo,_q,jJo,DJo,NJo,bv,Ime,qJo,OJo,uq,GJo,XJo,VJo,vv,jme,zJo,WJo,bq,QJo,HJo,UJo,Tv,Dme,JJo,YJo,vq,KJo,ZJo,eYo,Fv,Nme,oYo,rYo,Tq,tYo,aYo,nYo,Os,qme,sYo,lYo,Fq,iYo,dYo,Cq,cYo,fYo,mYo,Cv,Ome,gYo,hYo,Mq,pYo,_Yo,uYo,Mv,Gme,bYo,vYo,Eq,TYo,FYo,CYo,Ev,Xme,MYo,EYo,yq,yYo,wYo,AYo,yv,Vme,LYo,BYo,wq,xYo,kYo,RYo,wv,zme,SYo,PYo,Aq,$Yo,IYo,jYo,Av,Wme,DYo,NYo,Lq,qYo,OYo,GYo,Lv,Qme,XYo,VYo,Bq,zYo,WYo,QYo,Bv,Hme,HYo,UYo,xq,JYo,YYo,KYo,xv,Ume,ZYo,eKo,kq,oKo,rKo,tKo,kv,Jme,aKo,nKo,Rq,sKo,lKo,iKo,Rv,Yme,dKo,cKo,Sq,fKo,mKo,gKo,Sv,Kme,hKo,pKo,Pq,_Ko,uKo,bKo,Pv,Zme,vKo,TKo,$q,FKo,CKo,MKo,$v,ege,EKo,yKo,Iq,wKo,AKo,LKo,Iv,oge,BKo,xKo,jq,kKo,RKo,SKo,jv,rge,PKo,$Ko,Dq,IKo,jKo,DKo,Dv,tge,NKo,qKo,Nq,OKo,GKo,XKo,Nv,age,VKo,zKo,qq,WKo,QKo,HKo,qv,nge,UKo,JKo,Oq,YKo,KKo,ZKo,Ov,sge,eZo,oZo,Gq,rZo,tZo,aZo,Gv,lge,nZo,sZo,Xq,lZo,iZo,dZo,Xv,ige,cZo,fZo,Vq,mZo,gZo,hZo,Vv,dge,pZo,_Zo,zq,uZo,bZo,vZo,zv,cge,TZo,FZo,Wq,CZo,MZo,EZo,Wv,fge,yZo,wZo,Qq,AZo,LZo,BZo,mge,xZo,kZo,Iw,Fke,pc,Qv,gge,jw,RZo,hge,SZo,Cke,Tr,Dw,PZo,_c,$Zo,pge,IZo,jZo,_ge,DZo,NZo,qZo,Nw,OZo,uge,GZo,XZo,VZo,ht,qw,zZo,bge,WZo,QZo,uc,HZo,vge,UZo,JZo,Tge,YZo,KZo,ZZo,Fge,eer,oer,Ow,rer,po,Gw,ter,Cge,aer,ner,_n,ser,Mge,ler,ier,Ege,der,cer,yge,fer,mer,ger,H,Hv,wge,her,per,Hq,_er,uer,ber,Uv,Age,ver,Ter,Uq,Fer,Cer,Mer,Jv,Lge,Eer,yer,Jq,wer,Aer,Ler,Yv,Bge,Ber,xer,Yq,ker,Rer,Ser,Kv,xge,Per,$er,Kq,Ier,jer,Der,Zv,kge,Ner,qer,Zq,Oer,Ger,Xer,e0,Rge,Ver,zer,eO,Wer,Qer,Her,o0,Sge,Uer,Jer,oO,Yer,Ker,Zer,r0,Pge,eor,oor,rO,ror,tor,aor,t0,$ge,nor,sor,tO,lor,ior,dor,a0,Ige,cor,mor,aO,gor,hor,por,n0,jge,_or,uor,nO,bor,vor,Tor,s0,Dge,For,Cor,sO,Mor,Eor,yor,l0,Nge,wor,Aor,lO,Lor,Bor,xor,i0,qge,kor,Ror,iO,Sor,Por,$or,d0,Oge,Ior,jor,dO,Dor,Nor,qor,c0,Gge,Oor,Gor,cO,Xor,Vor,zor,f0,Xge,Wor,Qor,fO,Hor,Uor,Jor,m0,Vge,Yor,Kor,mO,Zor,err,orr,g0,zge,rrr,trr,gO,arr,nrr,srr,h0,Wge,lrr,irr,hO,drr,crr,frr,p0,Qge,mrr,grr,pO,hrr,prr,_rr,Hge,urr,brr,Xw,Mke,bc,_0,Uge,Vw,vrr,Jge,Trr,Eke,Fr,zw,Frr,vc,Crr,Yge,Mrr,Err,Kge,yrr,wrr,Arr,Ww,Lrr,Zge,Brr,xrr,krr,pt,Qw,Rrr,ehe,Srr,Prr,Tc,$rr,ohe,Irr,jrr,rhe,Drr,Nrr,qrr,the,Orr,Grr,Hw,Xrr,_o,Uw,Vrr,ahe,zrr,Wrr,un,Qrr,nhe,Hrr,Urr,she,Jrr,Yrr,lhe,Krr,Zrr,etr,_e,u0,ihe,otr,rtr,_O,ttr,atr,ntr,b0,dhe,str,ltr,uO,itr,dtr,ctr,v0,che,ftr,mtr,bO,gtr,htr,ptr,T0,fhe,_tr,utr,vO,btr,vtr,Ttr,F0,mhe,Ftr,Ctr,TO,Mtr,Etr,ytr,C0,ghe,wtr,Atr,FO,Ltr,Btr,xtr,M0,hhe,ktr,Rtr,CO,Str,Ptr,$tr,E0,phe,Itr,jtr,MO,Dtr,Ntr,qtr,y0,_he,Otr,Gtr,EO,Xtr,Vtr,ztr,w0,uhe,Wtr,Qtr,yO,Htr,Utr,Jtr,bhe,Ytr,Ktr,Jw,yke,Fc,A0,vhe,Yw,Ztr,The,ear,wke,Cr,Kw,oar,Cc,rar,Fhe,tar,aar,Che,nar,sar,lar,Zw,iar,Mhe,dar,car,far,_t,e6,mar,Ehe,gar,har,Mc,par,yhe,_ar,uar,whe,bar,Tar,Far,Ahe,Car,Mar,o6,Ear,uo,r6,yar,Lhe,war,Aar,bn,Lar,Bhe,Bar,xar,xhe,kar,Rar,khe,Sar,Par,$ar,t6,L0,Rhe,Iar,jar,wO,Dar,Nar,qar,B0,She,Oar,Gar,AO,Xar,Var,zar,Phe,War,Qar,a6,Ake,Ec,x0,$he,n6,Har,Ihe,Uar,Lke,Mr,s6,Jar,yc,Yar,jhe,Kar,Zar,Dhe,enr,onr,rnr,l6,tnr,Nhe,anr,nnr,snr,ut,i6,lnr,qhe,inr,dnr,wc,cnr,Ohe,fnr,mnr,Ghe,gnr,hnr,pnr,Xhe,_nr,unr,d6,bnr,bo,c6,vnr,Vhe,Tnr,Fnr,vn,Cnr,zhe,Mnr,Enr,Whe,ynr,wnr,Qhe,Anr,Lnr,Bnr,Y,k0,Hhe,xnr,knr,LO,Rnr,Snr,Pnr,R0,Uhe,$nr,Inr,BO,jnr,Dnr,Nnr,S0,Jhe,qnr,Onr,xO,Gnr,Xnr,Vnr,P0,Yhe,znr,Wnr,kO,Qnr,Hnr,Unr,$0,Khe,Jnr,Ynr,RO,Knr,Znr,esr,I0,Zhe,osr,rsr,SO,tsr,asr,nsr,j0,epe,ssr,lsr,PO,isr,dsr,csr,D0,ope,fsr,msr,$O,gsr,hsr,psr,N0,rpe,_sr,usr,IO,bsr,vsr,Tsr,q0,tpe,Fsr,Csr,jO,Msr,Esr,ysr,O0,ape,wsr,Asr,DO,Lsr,Bsr,xsr,G0,npe,ksr,Rsr,NO,Ssr,Psr,$sr,X0,spe,Isr,jsr,qO,Dsr,Nsr,qsr,V0,lpe,Osr,Gsr,OO,Xsr,Vsr,zsr,z0,ipe,Wsr,Qsr,GO,Hsr,Usr,Jsr,W0,dpe,Ysr,Ksr,XO,Zsr,elr,olr,Q0,cpe,rlr,tlr,VO,alr,nlr,slr,H0,fpe,llr,ilr,zO,dlr,clr,flr,U0,mpe,mlr,glr,WO,hlr,plr,_lr,J0,gpe,ulr,blr,QO,vlr,Tlr,Flr,hpe,Clr,Mlr,f6,Bke,Ac,Y0,ppe,m6,Elr,_pe,ylr,xke,Er,g6,wlr,Lc,Alr,upe,Llr,Blr,bpe,xlr,klr,Rlr,h6,Slr,vpe,Plr,$lr,Ilr,bt,p6,jlr,Tpe,Dlr,Nlr,Bc,qlr,Fpe,Olr,Glr,Cpe,Xlr,Vlr,zlr,Mpe,Wlr,Qlr,_6,Hlr,vo,u6,Ulr,Epe,Jlr,Ylr,Tn,Klr,ype,Zlr,eir,wpe,oir,rir,Ape,tir,air,nir,ue,K0,Lpe,sir,lir,HO,iir,dir,cir,Z0,Bpe,fir,mir,UO,gir,hir,pir,eT,xpe,_ir,uir,JO,bir,vir,Tir,oT,kpe,Fir,Cir,YO,Mir,Eir,yir,rT,Rpe,wir,Air,KO,Lir,Bir,xir,tT,Spe,kir,Rir,ZO,Sir,Pir,$ir,aT,Ppe,Iir,jir,eG,Dir,Nir,qir,nT,$pe,Oir,Gir,oG,Xir,Vir,zir,sT,Ipe,Wir,Qir,rG,Hir,Uir,Jir,lT,jpe,Yir,Kir,tG,Zir,edr,odr,Dpe,rdr,tdr,b6,kke,xc,iT,Npe,v6,adr,qpe,ndr,Rke,yr,T6,sdr,kc,ldr,Ope,idr,ddr,Gpe,cdr,fdr,mdr,F6,gdr,Xpe,hdr,pdr,_dr,vt,C6,udr,Vpe,bdr,vdr,Rc,Tdr,zpe,Fdr,Cdr,Wpe,Mdr,Edr,ydr,Qpe,wdr,Adr,M6,Ldr,To,E6,Bdr,Hpe,xdr,kdr,Fn,Rdr,Upe,Sdr,Pdr,Jpe,$dr,Idr,Ype,jdr,Ddr,Ndr,V,dT,Kpe,qdr,Odr,aG,Gdr,Xdr,Vdr,cT,Zpe,zdr,Wdr,nG,Qdr,Hdr,Udr,fT,e_e,Jdr,Ydr,sG,Kdr,Zdr,ecr,mT,o_e,ocr,rcr,lG,tcr,acr,ncr,gT,r_e,scr,lcr,iG,icr,dcr,ccr,hT,t_e,fcr,mcr,dG,gcr,hcr,pcr,pT,a_e,_cr,ucr,cG,bcr,vcr,Tcr,_T,n_e,Fcr,Ccr,fG,Mcr,Ecr,ycr,uT,s_e,wcr,Acr,mG,Lcr,Bcr,xcr,bT,l_e,kcr,Rcr,gG,Scr,Pcr,$cr,vT,i_e,Icr,jcr,hG,Dcr,Ncr,qcr,TT,d_e,Ocr,Gcr,pG,Xcr,Vcr,zcr,FT,c_e,Wcr,Qcr,_G,Hcr,Ucr,Jcr,CT,f_e,Ycr,Kcr,uG,Zcr,efr,ofr,MT,m_e,rfr,tfr,bG,afr,nfr,sfr,ET,g_e,lfr,ifr,vG,dfr,cfr,ffr,yT,h_e,mfr,gfr,TG,hfr,pfr,_fr,wT,p_e,ufr,bfr,FG,vfr,Tfr,Ffr,AT,__e,Cfr,Mfr,CG,Efr,yfr,wfr,LT,u_e,Afr,Lfr,MG,Bfr,xfr,kfr,BT,b_e,Rfr,Sfr,EG,Pfr,$fr,Ifr,xT,v_e,jfr,Dfr,yG,Nfr,qfr,Ofr,kT,T_e,Gfr,Xfr,wG,Vfr,zfr,Wfr,RT,F_e,Qfr,Hfr,AG,Ufr,Jfr,Yfr,ST,C_e,Kfr,Zfr,LG,emr,omr,rmr,M_e,tmr,amr,y6,Ske,Sc,PT,E_e,w6,nmr,y_e,smr,Pke,wr,A6,lmr,Pc,imr,w_e,dmr,cmr,A_e,fmr,mmr,gmr,L6,hmr,L_e,pmr,_mr,umr,Tt,B6,bmr,B_e,vmr,Tmr,$c,Fmr,x_e,Cmr,Mmr,k_e,Emr,ymr,wmr,R_e,Amr,Lmr,x6,Bmr,Fo,k6,xmr,S_e,kmr,Rmr,Cn,Smr,P_e,Pmr,$mr,$_e,Imr,jmr,I_e,Dmr,Nmr,qmr,ae,$T,j_e,Omr,Gmr,BG,Xmr,Vmr,zmr,IT,D_e,Wmr,Qmr,xG,Hmr,Umr,Jmr,jT,N_e,Ymr,Kmr,kG,Zmr,egr,ogr,DT,q_e,rgr,tgr,RG,agr,ngr,sgr,NT,O_e,lgr,igr,SG,dgr,cgr,fgr,qT,G_e,mgr,ggr,PG,hgr,pgr,_gr,OT,X_e,ugr,bgr,$G,vgr,Tgr,Fgr,GT,V_e,Cgr,Mgr,IG,Egr,ygr,wgr,XT,z_e,Agr,Lgr,jG,Bgr,xgr,kgr,VT,W_e,Rgr,Sgr,DG,Pgr,$gr,Igr,zT,Q_e,jgr,Dgr,NG,Ngr,qgr,Ogr,WT,H_e,Ggr,Xgr,qG,Vgr,zgr,Wgr,QT,U_e,Qgr,Hgr,OG,Ugr,Jgr,Ygr,HT,J_e,Kgr,Zgr,GG,ehr,ohr,rhr,UT,Y_e,thr,ahr,XG,nhr,shr,lhr,JT,K_e,ihr,dhr,VG,chr,fhr,mhr,YT,Z_e,ghr,hhr,zG,phr,_hr,uhr,eue,bhr,vhr,R6,$ke,Ic,KT,oue,S6,Thr,rue,Fhr,Ike,Ar,P6,Chr,jc,Mhr,tue,Ehr,yhr,aue,whr,Ahr,Lhr,$6,Bhr,nue,xhr,khr,Rhr,Ft,I6,Shr,sue,Phr,$hr,Dc,Ihr,lue,jhr,Dhr,iue,Nhr,qhr,Ohr,due,Ghr,Xhr,j6,Vhr,Co,D6,zhr,cue,Whr,Qhr,Mn,Hhr,fue,Uhr,Jhr,mue,Yhr,Khr,gue,Zhr,epr,opr,hue,ZT,pue,rpr,tpr,WG,apr,npr,spr,_ue,lpr,ipr,N6,jke,Nc,eF,uue,q6,dpr,bue,cpr,Dke,Lr,O6,fpr,qc,mpr,vue,gpr,hpr,Tue,ppr,_pr,upr,G6,bpr,Fue,vpr,Tpr,Fpr,Ct,X6,Cpr,Cue,Mpr,Epr,Oc,ypr,Mue,wpr,Apr,Eue,Lpr,Bpr,xpr,yue,kpr,Rpr,V6,Spr,Mo,z6,Ppr,wue,$pr,Ipr,En,jpr,Aue,Dpr,Npr,Lue,qpr,Opr,Bue,Gpr,Xpr,Vpr,K,oF,xue,zpr,Wpr,QG,Qpr,Hpr,Upr,rF,kue,Jpr,Ypr,HG,Kpr,Zpr,e_r,tF,Rue,o_r,r_r,UG,t_r,a_r,n_r,aF,Sue,s_r,l_r,JG,i_r,d_r,c_r,nF,Pue,f_r,m_r,YG,g_r,h_r,p_r,sF,$ue,__r,u_r,KG,b_r,v_r,T_r,lF,Iue,F_r,C_r,ZG,M_r,E_r,y_r,iF,jue,w_r,A_r,eX,L_r,B_r,x_r,dF,Due,k_r,R_r,oX,S_r,P_r,$_r,cF,Nue,I_r,j_r,rX,D_r,N_r,q_r,fF,que,O_r,G_r,tX,X_r,V_r,z_r,mF,Oue,W_r,Q_r,aX,H_r,U_r,J_r,gF,Gue,Y_r,K_r,nX,Z_r,eur,our,hF,Xue,rur,tur,sX,aur,nur,sur,pF,Vue,lur,iur,lX,dur,cur,fur,_F,zue,mur,gur,iX,hur,pur,_ur,uF,Wue,uur,bur,dX,vur,Tur,Fur,bF,Que,Cur,Mur,cX,Eur,yur,wur,vF,Hue,Aur,Lur,fX,Bur,xur,kur,TF,Uue,Rur,Sur,mX,Pur,$ur,Iur,Jue,jur,Dur,W6,Nke,Gc,FF,Yue,Q6,Nur,Kue,qur,qke,Br,H6,Our,Xc,Gur,Zue,Xur,Vur,e1e,zur,Wur,Qur,U6,Hur,o1e,Uur,Jur,Yur,Mt,J6,Kur,r1e,Zur,e1r,Vc,o1r,t1e,r1r,t1r,a1e,a1r,n1r,s1r,n1e,l1r,i1r,Y6,d1r,Eo,K6,c1r,s1e,f1r,m1r,yn,g1r,l1e,h1r,p1r,i1e,_1r,u1r,d1e,b1r,v1r,T1r,Z,CF,c1e,F1r,C1r,gX,M1r,E1r,y1r,MF,f1e,w1r,A1r,hX,L1r,B1r,x1r,EF,m1e,k1r,R1r,pX,S1r,P1r,$1r,yF,g1e,I1r,j1r,_X,D1r,N1r,q1r,wF,h1e,O1r,G1r,uX,X1r,V1r,z1r,AF,p1e,W1r,Q1r,bX,H1r,U1r,J1r,LF,_1e,Y1r,K1r,vX,Z1r,e7r,o7r,BF,u1e,r7r,t7r,TX,a7r,n7r,s7r,xF,b1e,l7r,i7r,FX,d7r,c7r,f7r,kF,v1e,m7r,g7r,CX,h7r,p7r,_7r,RF,T1e,u7r,b7r,MX,v7r,T7r,F7r,SF,F1e,C7r,M7r,EX,E7r,y7r,w7r,PF,C1e,A7r,L7r,yX,B7r,x7r,k7r,$F,M1e,R7r,S7r,wX,P7r,$7r,I7r,IF,E1e,j7r,D7r,AX,N7r,q7r,O7r,jF,y1e,G7r,X7r,LX,V7r,z7r,W7r,DF,w1e,Q7r,H7r,BX,U7r,J7r,Y7r,NF,A1e,K7r,Z7r,xX,ebr,obr,rbr,qF,L1e,tbr,abr,kX,nbr,sbr,lbr,B1e,ibr,dbr,Z6,Oke,zc,OF,x1e,eA,cbr,k1e,fbr,Gke,xr,oA,mbr,Wc,gbr,R1e,hbr,pbr,S1e,_br,ubr,bbr,rA,vbr,P1e,Tbr,Fbr,Cbr,Et,tA,Mbr,$1e,Ebr,ybr,Qc,wbr,I1e,Abr,Lbr,j1e,Bbr,xbr,kbr,D1e,Rbr,Sbr,aA,Pbr,yo,nA,$br,N1e,Ibr,jbr,wn,Dbr,q1e,Nbr,qbr,O1e,Obr,Gbr,G1e,Xbr,Vbr,zbr,X1e,GF,V1e,Wbr,Qbr,RX,Hbr,Ubr,Jbr,z1e,Ybr,Kbr,sA,Xke,Hc,XF,W1e,lA,Zbr,Q1e,e5r,Vke,kr,iA,o5r,Uc,r5r,H1e,t5r,a5r,U1e,n5r,s5r,l5r,dA,i5r,J1e,d5r,c5r,f5r,yt,cA,m5r,Y1e,g5r,h5r,Jc,p5r,K1e,_5r,u5r,Z1e,b5r,v5r,T5r,e7e,F5r,C5r,fA,M5r,wo,mA,E5r,o7e,y5r,w5r,An,A5r,r7e,L5r,B5r,t7e,x5r,k5r,a7e,R5r,S5r,P5r,n7e,VF,s7e,$5r,I5r,SX,j5r,D5r,N5r,l7e,q5r,O5r,gA,zke,Yc,zF,i7e,hA,G5r,d7e,X5r,Wke,Rr,pA,V5r,Kc,z5r,c7e,W5r,Q5r,f7e,H5r,U5r,J5r,_A,Y5r,m7e,K5r,Z5r,e2r,wt,uA,o2r,g7e,r2r,t2r,Zc,a2r,h7e,n2r,s2r,p7e,l2r,i2r,d2r,_7e,c2r,f2r,bA,m2r,Ao,vA,g2r,u7e,h2r,p2r,Ln,_2r,b7e,u2r,b2r,v7e,v2r,T2r,T7e,F2r,C2r,M2r,z,WF,F7e,E2r,y2r,PX,w2r,A2r,L2r,QF,C7e,B2r,x2r,$X,k2r,R2r,S2r,HF,M7e,P2r,$2r,IX,I2r,j2r,D2r,UF,E7e,N2r,q2r,jX,O2r,G2r,X2r,JF,y7e,V2r,z2r,DX,W2r,Q2r,H2r,YF,w7e,U2r,J2r,NX,Y2r,K2r,Z2r,KF,A7e,evr,ovr,qX,rvr,tvr,avr,ZF,L7e,nvr,svr,OX,lvr,ivr,dvr,eC,B7e,cvr,fvr,GX,mvr,gvr,hvr,oC,x7e,pvr,_vr,XX,uvr,bvr,vvr,rC,k7e,Tvr,Fvr,VX,Cvr,Mvr,Evr,tC,R7e,yvr,wvr,zX,Avr,Lvr,Bvr,aC,S7e,xvr,kvr,WX,Rvr,Svr,Pvr,nC,P7e,$vr,Ivr,QX,jvr,Dvr,Nvr,sC,$7e,qvr,Ovr,HX,Gvr,Xvr,Vvr,lC,I7e,zvr,Wvr,UX,Qvr,Hvr,Uvr,iC,j7e,Jvr,Yvr,JX,Kvr,Zvr,e0r,dC,D7e,o0r,r0r,YX,t0r,a0r,n0r,cC,N7e,s0r,l0r,KX,i0r,d0r,c0r,fC,q7e,f0r,m0r,ZX,g0r,h0r,p0r,mC,O7e,_0r,u0r,eV,b0r,v0r,T0r,gC,G7e,F0r,C0r,oV,M0r,E0r,y0r,hC,X7e,w0r,A0r,rV,L0r,B0r,x0r,pC,V7e,k0r,R0r,tV,S0r,P0r,$0r,_C,z7e,I0r,j0r,aV,D0r,N0r,q0r,W7e,O0r,G0r,TA,Qke,ef,uC,Q7e,FA,X0r,H7e,V0r,Hke,Sr,CA,z0r,of,W0r,U7e,Q0r,H0r,J7e,U0r,J0r,Y0r,MA,K0r,Y7e,Z0r,eTr,oTr,At,EA,rTr,K7e,tTr,aTr,rf,nTr,Z7e,sTr,lTr,ebe,iTr,dTr,cTr,obe,fTr,mTr,yA,gTr,Lo,wA,hTr,rbe,pTr,_Tr,Bn,uTr,tbe,bTr,vTr,abe,TTr,FTr,nbe,CTr,MTr,ETr,xn,bC,sbe,yTr,wTr,nV,ATr,LTr,BTr,vC,lbe,xTr,kTr,sV,RTr,STr,PTr,TC,ibe,$Tr,ITr,lV,jTr,DTr,NTr,FC,dbe,qTr,OTr,iV,GTr,XTr,VTr,cbe,zTr,WTr,AA,Uke,tf,CC,fbe,LA,QTr,mbe,HTr,Jke,Pr,BA,UTr,af,JTr,gbe,YTr,KTr,hbe,ZTr,eFr,oFr,xA,rFr,pbe,tFr,aFr,nFr,Lt,kA,sFr,_be,lFr,iFr,nf,dFr,ube,cFr,fFr,bbe,mFr,gFr,hFr,vbe,pFr,_Fr,RA,uFr,Bo,SA,bFr,Tbe,vFr,TFr,kn,FFr,Fbe,CFr,MFr,Cbe,EFr,yFr,Mbe,wFr,AFr,LFr,ce,MC,Ebe,BFr,xFr,dV,kFr,RFr,SFr,EC,ybe,PFr,$Fr,cV,IFr,jFr,DFr,yC,wbe,NFr,qFr,fV,OFr,GFr,XFr,wC,Abe,VFr,zFr,mV,WFr,QFr,HFr,AC,Lbe,UFr,JFr,gV,YFr,KFr,ZFr,LC,Bbe,eCr,oCr,hV,rCr,tCr,aCr,BC,xbe,nCr,sCr,pV,lCr,iCr,dCr,xC,kbe,cCr,fCr,_V,mCr,gCr,hCr,kC,Rbe,pCr,_Cr,uV,uCr,bCr,vCr,RC,Sbe,TCr,FCr,bV,CCr,MCr,ECr,SC,Pbe,yCr,wCr,vV,ACr,LCr,BCr,PC,$be,xCr,kCr,TV,RCr,SCr,PCr,Ibe,$Cr,ICr,PA,Yke,sf,$C,jbe,$A,jCr,Dbe,DCr,Kke,$r,IA,NCr,lf,qCr,Nbe,OCr,GCr,qbe,XCr,VCr,zCr,jA,WCr,Obe,QCr,HCr,UCr,Bt,DA,JCr,Gbe,YCr,KCr,df,ZCr,Xbe,eMr,oMr,Vbe,rMr,tMr,aMr,zbe,nMr,sMr,NA,lMr,xo,qA,iMr,Wbe,dMr,cMr,Rn,fMr,Qbe,mMr,gMr,Hbe,hMr,pMr,Ube,_Mr,uMr,bMr,be,IC,Jbe,vMr,TMr,FV,FMr,CMr,MMr,jC,Ybe,EMr,yMr,CV,wMr,AMr,LMr,DC,Kbe,BMr,xMr,MV,kMr,RMr,SMr,NC,Zbe,PMr,$Mr,EV,IMr,jMr,DMr,qC,e5e,NMr,qMr,yV,OMr,GMr,XMr,OC,o5e,VMr,zMr,wV,WMr,QMr,HMr,GC,r5e,UMr,JMr,AV,YMr,KMr,ZMr,XC,t5e,e4r,o4r,LV,r4r,t4r,a4r,VC,a5e,n4r,s4r,BV,l4r,i4r,d4r,zC,n5e,c4r,f4r,xV,m4r,g4r,h4r,s5e,p4r,_4r,OA,Zke,cf,WC,l5e,GA,u4r,i5e,b4r,eRe,Ir,XA,v4r,ff,T4r,d5e,F4r,C4r,c5e,M4r,E4r,y4r,VA,w4r,f5e,A4r,L4r,B4r,xt,zA,x4r,m5e,k4r,R4r,mf,S4r,g5e,P4r,$4r,h5e,I4r,j4r,D4r,p5e,N4r,q4r,WA,O4r,ko,QA,G4r,_5e,X4r,V4r,Sn,z4r,u5e,W4r,Q4r,b5e,H4r,U4r,v5e,J4r,Y4r,K4r,Ce,QC,T5e,Z4r,eEr,kV,oEr,rEr,tEr,HC,F5e,aEr,nEr,RV,sEr,lEr,iEr,UC,C5e,dEr,cEr,SV,fEr,mEr,gEr,JC,M5e,hEr,pEr,PV,_Er,uEr,bEr,YC,E5e,vEr,TEr,$V,FEr,CEr,MEr,KC,y5e,EEr,yEr,IV,wEr,AEr,LEr,ZC,w5e,BEr,xEr,jV,kEr,REr,SEr,eM,A5e,PEr,$Er,DV,IEr,jEr,DEr,oM,L5e,NEr,qEr,NV,OEr,GEr,XEr,B5e,VEr,zEr,HA,oRe,gf,rM,x5e,UA,WEr,k5e,QEr,rRe,jr,JA,HEr,hf,UEr,R5e,JEr,YEr,S5e,KEr,ZEr,e3r,YA,o3r,P5e,r3r,t3r,a3r,kt,KA,n3r,$5e,s3r,l3r,pf,i3r,I5e,d3r,c3r,j5e,f3r,m3r,g3r,D5e,h3r,p3r,ZA,_3r,Ro,eL,u3r,N5e,b3r,v3r,Pn,T3r,q5e,F3r,C3r,O5e,M3r,E3r,G5e,y3r,w3r,A3r,ve,tM,X5e,L3r,B3r,qV,x3r,k3r,R3r,aM,V5e,S3r,P3r,OV,$3r,I3r,j3r,nM,z5e,D3r,N3r,GV,q3r,O3r,G3r,sM,W5e,X3r,V3r,XV,z3r,W3r,Q3r,lM,Q5e,H3r,U3r,VV,J3r,Y3r,K3r,iM,H5e,Z3r,eyr,zV,oyr,ryr,tyr,dM,U5e,ayr,nyr,WV,syr,lyr,iyr,cM,J5e,dyr,cyr,QV,fyr,myr,gyr,fM,Y5e,hyr,pyr,HV,_yr,uyr,byr,mM,K5e,vyr,Tyr,UV,Fyr,Cyr,Myr,Z5e,Eyr,yyr,oL,tRe,_f,gM,e2e,rL,wyr,o2e,Ayr,aRe,Dr,tL,Lyr,uf,Byr,r2e,xyr,kyr,t2e,Ryr,Syr,Pyr,aL,$yr,a2e,Iyr,jyr,Dyr,Rt,nL,Nyr,n2e,qyr,Oyr,bf,Gyr,s2e,Xyr,Vyr,l2e,zyr,Wyr,Qyr,i2e,Hyr,Uyr,sL,Jyr,So,lL,Yyr,d2e,Kyr,Zyr,$n,ewr,c2e,owr,rwr,f2e,twr,awr,m2e,nwr,swr,lwr,Te,hM,g2e,iwr,dwr,JV,cwr,fwr,mwr,pM,h2e,gwr,hwr,YV,pwr,_wr,uwr,_M,p2e,bwr,vwr,KV,Twr,Fwr,Cwr,uM,_2e,Mwr,Ewr,ZV,ywr,wwr,Awr,bM,u2e,Lwr,Bwr,ez,xwr,kwr,Rwr,vM,b2e,Swr,Pwr,oz,$wr,Iwr,jwr,TM,v2e,Dwr,Nwr,rz,qwr,Owr,Gwr,FM,T2e,Xwr,Vwr,tz,zwr,Wwr,Qwr,CM,F2e,Hwr,Uwr,az,Jwr,Ywr,Kwr,MM,C2e,Zwr,e6r,nz,o6r,r6r,t6r,M2e,a6r,n6r,iL,nRe,vf,EM,E2e,dL,s6r,y2e,l6r,sRe,Nr,cL,i6r,Tf,d6r,w2e,c6r,f6r,A2e,m6r,g6r,h6r,fL,p6r,L2e,_6r,u6r,b6r,St,mL,v6r,B2e,T6r,F6r,Ff,C6r,x2e,M6r,E6r,k2e,y6r,w6r,A6r,R2e,L6r,B6r,gL,x6r,Po,hL,k6r,S2e,R6r,S6r,In,P6r,P2e,$6r,I6r,$2e,j6r,D6r,I2e,N6r,q6r,O6r,Se,yM,j2e,G6r,X6r,sz,V6r,z6r,W6r,wM,D2e,Q6r,H6r,lz,U6r,J6r,Y6r,AM,N2e,K6r,Z6r,iz,eAr,oAr,rAr,LM,q2e,tAr,aAr,dz,nAr,sAr,lAr,BM,O2e,iAr,dAr,cz,cAr,fAr,mAr,xM,G2e,gAr,hAr,fz,pAr,_Ar,uAr,kM,X2e,bAr,vAr,mz,TAr,FAr,CAr,RM,V2e,MAr,EAr,gz,yAr,wAr,AAr,z2e,LAr,BAr,pL,lRe,Cf,SM,W2e,_L,xAr,Q2e,kAr,iRe,qr,uL,RAr,Mf,SAr,H2e,PAr,$Ar,U2e,IAr,jAr,DAr,bL,NAr,J2e,qAr,OAr,GAr,Pt,vL,XAr,Y2e,VAr,zAr,Ef,WAr,K2e,QAr,HAr,Z2e,UAr,JAr,YAr,eve,KAr,ZAr,TL,eLr,$o,FL,oLr,ove,rLr,tLr,jn,aLr,rve,nLr,sLr,tve,lLr,iLr,ave,dLr,cLr,fLr,Pe,PM,nve,mLr,gLr,hz,hLr,pLr,_Lr,$M,sve,uLr,bLr,pz,vLr,TLr,FLr,IM,lve,CLr,MLr,_z,ELr,yLr,wLr,jM,ive,ALr,LLr,uz,BLr,xLr,kLr,DM,dve,RLr,SLr,bz,PLr,$Lr,ILr,NM,cve,jLr,DLr,vz,NLr,qLr,OLr,qM,fve,GLr,XLr,Tz,VLr,zLr,WLr,OM,mve,QLr,HLr,Fz,ULr,JLr,YLr,gve,KLr,ZLr,CL,dRe,yf,GM,hve,ML,e8r,pve,o8r,cRe,Or,EL,r8r,wf,t8r,_ve,a8r,n8r,uve,s8r,l8r,i8r,yL,d8r,bve,c8r,f8r,m8r,$t,wL,g8r,vve,h8r,p8r,Af,_8r,Tve,u8r,b8r,Fve,v8r,T8r,F8r,Cve,C8r,M8r,AL,E8r,Io,LL,y8r,Mve,w8r,A8r,Dn,L8r,Eve,B8r,x8r,yve,k8r,R8r,wve,S8r,P8r,$8r,Ave,XM,Lve,I8r,j8r,Cz,D8r,N8r,q8r,Bve,O8r,G8r,BL,fRe,Lf,VM,xve,xL,X8r,kve,V8r,mRe,Gr,kL,z8r,Bf,W8r,Rve,Q8r,H8r,Sve,U8r,J8r,Y8r,RL,K8r,Pve,Z8r,e9r,o9r,It,SL,r9r,$ve,t9r,a9r,xf,n9r,Ive,s9r,l9r,jve,i9r,d9r,c9r,Dve,f9r,m9r,PL,g9r,jo,$L,h9r,Nve,p9r,_9r,Nn,u9r,qve,b9r,v9r,Ove,T9r,F9r,Gve,C9r,M9r,E9r,IL,zM,Xve,y9r,w9r,Mz,A9r,L9r,B9r,WM,Vve,x9r,k9r,Ez,R9r,S9r,P9r,zve,$9r,I9r,jL,gRe,kf,QM,Wve,DL,j9r,Qve,D9r,hRe,Xr,NL,N9r,Rf,q9r,Hve,O9r,G9r,Uve,X9r,V9r,z9r,qL,W9r,Jve,Q9r,H9r,U9r,jt,OL,J9r,Yve,Y9r,K9r,Sf,Z9r,Kve,eBr,oBr,Zve,rBr,tBr,aBr,e0e,nBr,sBr,GL,lBr,Do,XL,iBr,o0e,dBr,cBr,qn,fBr,r0e,mBr,gBr,t0e,hBr,pBr,a0e,_Br,uBr,bBr,n0e,HM,s0e,vBr,TBr,yz,FBr,CBr,MBr,l0e,EBr,yBr,VL,pRe;return fe=new X({}),Na=new w({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),Z4=new X({}),eE=new w({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),qf=new wBr({props:{warning:"&lcub;true}",$$slots:{default:[lTt]},$$scope:{ctx:$i}}}),oE=new X({}),rE=new M({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/configuration_auto.py#L529"}}),nE=new M({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/configuration_auto.py#L552",parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}]}}),sE=new w({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),lE=new M({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/configuration_auto.py#L674",parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}]}}),iE=new X({}),dE=new M({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/tokenization_auto.py#L352"}}),mE=new M({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/tokenization_auto.py#L366",parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_15770/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}]}}),gE=new w({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),hE=new M({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/tokenization_auto.py#L562",parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}]}}),pE=new X({}),_E=new M({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/feature_extraction_auto.py#L171"}}),vE=new M({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/feature_extraction_auto.py#L185",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_15770/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),yh=new wBr({props:{$$slots:{default:[iTt]},$$scope:{ctx:$i}}}),TE=new w({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),FE=new M({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/feature_extraction_auto.py#L312",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}]}}),CE=new X({}),ME=new M({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/processing_auto.py#L71"}}),wE=new M({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/processing_auto.py#L85",parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),Ih=new wBr({props:{$$slots:{default:[dTt]},$$scope:{ctx:$i}}}),AE=new w({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),LE=new M({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/processing_auto.py#L238",parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}]}}),BE=new X({}),xE=new M({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L699"}}),RE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),SE=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),PE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),$E=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),IE=new X({}),jE=new M({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L706"}}),NE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),qE=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),OE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),GE=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),XE=new X({}),VE=new M({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L721"}}),WE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),QE=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),HE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),UE=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),JE=new X({}),YE=new M({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L728"}}),ZE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code>(Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),e3=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),o3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),r3=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),t3=new X({}),a3=new M({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L735"}}),s3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}]}}),l3=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),i3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),d3=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),c3=new X({}),f3=new M({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L744"}}),g3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),h3=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),p3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),_3=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),u3=new X({}),b3=new M({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L778"}}),T3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),F3=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),C3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),M3=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),E3=new X({}),y3=new M({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L785"}}),A3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}]}}),L3=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),B3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),x3=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),k3=new X({}),R3=new M({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L771"}}),P3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),$3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),I3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),j3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),D3=new X({}),N3=new M({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L753"}}),O3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),G3=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),X3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),V3=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),z3=new X({}),W3=new M({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L760"}}),H3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),U3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),J3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Y3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),K3=new X({}),Z3=new M({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L794"}}),oy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),ry=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),ty=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ay=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),ny=new X({}),sy=new M({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L833"}}),iy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),dy=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),cy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),fy=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),my=new X({}),gy=new M({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L840"}}),py=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),_y=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),uy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),by=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),vy=new X({}),Ty=new M({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L863"}}),Cy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),My=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),Ey=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),yy=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),wy=new X({}),Ay=new M({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L847"}}),By=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),xy=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),ky=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Ry=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Sy=new X({}),Py=new M({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L854"}}),Iy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}]}}),jy=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),Dy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),qy=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Oy=new X({}),Gy=new M({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L872"}}),Vy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),zy=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),Wy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Qy=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Hy=new X({}),Uy=new M({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L879"}}),Yy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}]}}),Ky=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),Zy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ew=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),ow=new X({}),rw=new M({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L826"}}),aw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
</ul>`,name:"config"}]}}),nw=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),sw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),lw=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),iw=new X({}),dw=new M({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L801"}}),fw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}]}}),mw=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),gw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),hw=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),pw=new X({}),_w=new M({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L808"}}),bw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}]}}),vw=new w({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),Tw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Cw=new w({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Mw=new X({}),Ew=new M({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_auto.py#L817"}}),ww=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}]}}),Aw=new w({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),Lw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Bw=new w({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),xw=new X({}),kw=new M({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L373"}}),Sw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Pw=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),$w=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Iw=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),jw=new X({}),Dw=new M({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L380"}}),qw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Ow=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),Gw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Xw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Vw=new X({}),zw=new M({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L395"}}),Qw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Hw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),Uw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Jw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Yw=new X({}),Kw=new M({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L402"}}),e6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),o6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),r6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),a6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),n6=new X({}),s6=new M({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),i6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),d6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),c6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),f6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),m6=new X({}),g6=new M({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L423"}}),p6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),_6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),u6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),b6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),v6=new X({}),T6=new M({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),C6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),M6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),E6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),y6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),w6=new X({}),A6=new M({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L468"}}),B6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),x6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),k6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),R6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),S6=new X({}),P6=new M({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L448"}}),I6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),j6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),D6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),N6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),q6=new X({}),O6=new M({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L459"}}),X6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),V6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),z6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),W6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Q6=new X({}),H6=new M({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),J6=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Y6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),K6=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Z6=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),eA=new X({}),oA=new M({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L409"}}),tA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),aA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),nA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),sA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),lA=new X({}),iA=new M({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_tf_auto.py#L484"}}),cA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}]}}),fA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),mA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),gA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),hA=new X({}),pA=new M({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L236"}}),uA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),bA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),vA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),TA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),FA=new X({}),CA=new M({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L250"}}),EA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}]}}),yA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),wA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),AA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),LA=new X({}),BA=new M({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L243"}}),kA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),RA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),SA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),PA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),$A=new X({}),IA=new M({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L257"}}),DA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),NA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),qA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),OA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),GA=new X({}),XA=new M({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),zA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),WA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),QA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),HA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),UA=new X({}),JA=new M({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L273"}}),KA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),ZA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),eL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),oL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),rL=new X({}),tL=new M({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L282"}}),nL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),sL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),lL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),iL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),dL=new X({}),cL=new M({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L289"}}),mL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),gL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),hL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),pL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),_L=new X({}),uL=new M({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L298"}}),vL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),TL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),FL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),CL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),ML=new X({}),EL=new M({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L305"}}),wL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}]}}),AL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),LL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),BL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),xL=new X({}),kL=new M({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L314"}}),SL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),PL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),$L=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),jL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),DL=new X({}),NL=new M({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/modeling_flax_auto.py#L323"}}),OL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),GL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),XL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15770/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_15770/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_15770/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),VL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){J=a("meta"),$e=l(),de=a("h1"),ge=a("a"),io=a("span"),f(fe.$$.fragment),Fe=l(),Vo=a("span"),Ii=o("Auto Classes"),$f=l(),ca=a("p"),ji=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Di=a("code"),U4=o("from_pretrained()"),If=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Be=l(),co=a("p"),Ni=o("Instantiating one of "),On=a("a"),J4=o("AutoConfig"),Gn=o(", "),Xn=a("a"),Y4=o("AutoModel"),qi=o(`, and
`),Vn=a("a"),K4=o("AutoTokenizer"),Oi=o(" will directly create a class of the relevant architecture. For instance"),jf=l(),f(Na.$$.fragment),fo=l(),he=a("p"),G8=o("will create a model that is an instance of "),Gi=a("a"),X8=o("BertModel"),V8=o("."),zo=l(),qa=a("p"),z8=o("There is one class of "),Df=a("code"),W8=o("AutoModel"),LPe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),hxe=l(),Xi=a("h2"),Nf=a("a"),bQ=a("span"),f(Z4.$$.fragment),BPe=l(),vQ=a("span"),xPe=o("Extending the Auto Classes"),pxe=l(),zn=a("p"),kPe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),TQ=a("code"),RPe=o("NewModel"),SPe=o(", make sure you have a "),FQ=a("code"),PPe=o("NewModelConfig"),$Pe=o(` then you can add those to the auto
classes like this:`),_xe=l(),f(eE.$$.fragment),uxe=l(),Q8=a("p"),IPe=o("You will then be able to use the auto classes like you would usually do!"),bxe=l(),f(qf.$$.fragment),vxe=l(),Vi=a("h2"),Of=a("a"),CQ=a("span"),f(oE.$$.fragment),jPe=l(),MQ=a("span"),DPe=o("AutoConfig"),Txe=l(),Wo=a("div"),f(rE.$$.fragment),NPe=l(),tE=a("p"),qPe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),H8=a("a"),OPe=o("from_pretrained()"),GPe=o(" class method."),XPe=l(),aE=a("p"),VPe=o("This class cannot be instantiated directly using "),EQ=a("code"),zPe=o("__init__()"),WPe=o(" (throws an error)."),QPe=l(),mo=a("div"),f(nE.$$.fragment),HPe=l(),yQ=a("p"),UPe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),JPe=l(),zi=a("p"),YPe=o("The configuration class to instantiate is selected based on the "),wQ=a("code"),KPe=o("model_type"),ZPe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),AQ=a("code"),e$e=o("pretrained_model_name_or_path"),o$e=o(":"),r$e=l(),v=a("ul"),Gf=a("li"),LQ=a("strong"),t$e=o("albert"),a$e=o(" \u2014 "),U8=a("a"),n$e=o("AlbertConfig"),s$e=o(" (ALBERT model)"),l$e=l(),Xf=a("li"),BQ=a("strong"),i$e=o("bart"),d$e=o(" \u2014 "),J8=a("a"),c$e=o("BartConfig"),f$e=o(" (BART model)"),m$e=l(),Vf=a("li"),xQ=a("strong"),g$e=o("beit"),h$e=o(" \u2014 "),Y8=a("a"),p$e=o("BeitConfig"),_$e=o(" (BEiT model)"),u$e=l(),zf=a("li"),kQ=a("strong"),b$e=o("bert"),v$e=o(" \u2014 "),K8=a("a"),T$e=o("BertConfig"),F$e=o(" (BERT model)"),C$e=l(),Wf=a("li"),RQ=a("strong"),M$e=o("bert-generation"),E$e=o(" \u2014 "),Z8=a("a"),y$e=o("BertGenerationConfig"),w$e=o(" (Bert Generation model)"),A$e=l(),Qf=a("li"),SQ=a("strong"),L$e=o("big_bird"),B$e=o(" \u2014 "),e9=a("a"),x$e=o("BigBirdConfig"),k$e=o(" (BigBird model)"),R$e=l(),Hf=a("li"),PQ=a("strong"),S$e=o("bigbird_pegasus"),P$e=o(" \u2014 "),o9=a("a"),$$e=o("BigBirdPegasusConfig"),I$e=o(" (BigBirdPegasus model)"),j$e=l(),Uf=a("li"),$Q=a("strong"),D$e=o("blenderbot"),N$e=o(" \u2014 "),r9=a("a"),q$e=o("BlenderbotConfig"),O$e=o(" (Blenderbot model)"),G$e=l(),Jf=a("li"),IQ=a("strong"),X$e=o("blenderbot-small"),V$e=o(" \u2014 "),t9=a("a"),z$e=o("BlenderbotSmallConfig"),W$e=o(" (BlenderbotSmall model)"),Q$e=l(),Yf=a("li"),jQ=a("strong"),H$e=o("camembert"),U$e=o(" \u2014 "),a9=a("a"),J$e=o("CamembertConfig"),Y$e=o(" (CamemBERT model)"),K$e=l(),Kf=a("li"),DQ=a("strong"),Z$e=o("canine"),eIe=o(" \u2014 "),n9=a("a"),oIe=o("CanineConfig"),rIe=o(" (Canine model)"),tIe=l(),Zf=a("li"),NQ=a("strong"),aIe=o("clip"),nIe=o(" \u2014 "),s9=a("a"),sIe=o("CLIPConfig"),lIe=o(" (CLIP model)"),iIe=l(),em=a("li"),qQ=a("strong"),dIe=o("convbert"),cIe=o(" \u2014 "),l9=a("a"),fIe=o("ConvBertConfig"),mIe=o(" (ConvBERT model)"),gIe=l(),om=a("li"),OQ=a("strong"),hIe=o("convnext"),pIe=o(" \u2014 "),i9=a("a"),_Ie=o("ConvNextConfig"),uIe=o(" (ConvNext model)"),bIe=l(),rm=a("li"),GQ=a("strong"),vIe=o("ctrl"),TIe=o(" \u2014 "),d9=a("a"),FIe=o("CTRLConfig"),CIe=o(" (CTRL model)"),MIe=l(),tm=a("li"),XQ=a("strong"),EIe=o("data2vec-audio"),yIe=o(" \u2014 "),c9=a("a"),wIe=o("Data2VecAudioConfig"),AIe=o(" (Data2VecAudio model)"),LIe=l(),am=a("li"),VQ=a("strong"),BIe=o("data2vec-text"),xIe=o(" \u2014 "),f9=a("a"),kIe=o("Data2VecTextConfig"),RIe=o(" (Data2VecText model)"),SIe=l(),nm=a("li"),zQ=a("strong"),PIe=o("deberta"),$Ie=o(" \u2014 "),m9=a("a"),IIe=o("DebertaConfig"),jIe=o(" (DeBERTa model)"),DIe=l(),sm=a("li"),WQ=a("strong"),NIe=o("deberta-v2"),qIe=o(" \u2014 "),g9=a("a"),OIe=o("DebertaV2Config"),GIe=o(" (DeBERTa-v2 model)"),XIe=l(),lm=a("li"),QQ=a("strong"),VIe=o("deit"),zIe=o(" \u2014 "),h9=a("a"),WIe=o("DeiTConfig"),QIe=o(" (DeiT model)"),HIe=l(),im=a("li"),HQ=a("strong"),UIe=o("detr"),JIe=o(" \u2014 "),p9=a("a"),YIe=o("DetrConfig"),KIe=o(" (DETR model)"),ZIe=l(),dm=a("li"),UQ=a("strong"),eje=o("distilbert"),oje=o(" \u2014 "),_9=a("a"),rje=o("DistilBertConfig"),tje=o(" (DistilBERT model)"),aje=l(),cm=a("li"),JQ=a("strong"),nje=o("dpr"),sje=o(" \u2014 "),u9=a("a"),lje=o("DPRConfig"),ije=o(" (DPR model)"),dje=l(),fm=a("li"),YQ=a("strong"),cje=o("electra"),fje=o(" \u2014 "),b9=a("a"),mje=o("ElectraConfig"),gje=o(" (ELECTRA model)"),hje=l(),mm=a("li"),KQ=a("strong"),pje=o("encoder-decoder"),_je=o(" \u2014 "),v9=a("a"),uje=o("EncoderDecoderConfig"),bje=o(" (Encoder decoder model)"),vje=l(),gm=a("li"),ZQ=a("strong"),Tje=o("flaubert"),Fje=o(" \u2014 "),T9=a("a"),Cje=o("FlaubertConfig"),Mje=o(" (FlauBERT model)"),Eje=l(),hm=a("li"),eH=a("strong"),yje=o("fnet"),wje=o(" \u2014 "),F9=a("a"),Aje=o("FNetConfig"),Lje=o(" (FNet model)"),Bje=l(),pm=a("li"),oH=a("strong"),xje=o("fsmt"),kje=o(" \u2014 "),C9=a("a"),Rje=o("FSMTConfig"),Sje=o(" (FairSeq Machine-Translation model)"),Pje=l(),_m=a("li"),rH=a("strong"),$je=o("funnel"),Ije=o(" \u2014 "),M9=a("a"),jje=o("FunnelConfig"),Dje=o(" (Funnel Transformer model)"),Nje=l(),um=a("li"),tH=a("strong"),qje=o("gpt2"),Oje=o(" \u2014 "),E9=a("a"),Gje=o("GPT2Config"),Xje=o(" (OpenAI GPT-2 model)"),Vje=l(),bm=a("li"),aH=a("strong"),zje=o("gpt_neo"),Wje=o(" \u2014 "),y9=a("a"),Qje=o("GPTNeoConfig"),Hje=o(" (GPT Neo model)"),Uje=l(),vm=a("li"),nH=a("strong"),Jje=o("gptj"),Yje=o(" \u2014 "),w9=a("a"),Kje=o("GPTJConfig"),Zje=o(" (GPT-J model)"),eDe=l(),Tm=a("li"),sH=a("strong"),oDe=o("hubert"),rDe=o(" \u2014 "),A9=a("a"),tDe=o("HubertConfig"),aDe=o(" (Hubert model)"),nDe=l(),Fm=a("li"),lH=a("strong"),sDe=o("ibert"),lDe=o(" \u2014 "),L9=a("a"),iDe=o("IBertConfig"),dDe=o(" (I-BERT model)"),cDe=l(),Cm=a("li"),iH=a("strong"),fDe=o("imagegpt"),mDe=o(" \u2014 "),B9=a("a"),gDe=o("ImageGPTConfig"),hDe=o(" (ImageGPT model)"),pDe=l(),Mm=a("li"),dH=a("strong"),_De=o("layoutlm"),uDe=o(" \u2014 "),x9=a("a"),bDe=o("LayoutLMConfig"),vDe=o(" (LayoutLM model)"),TDe=l(),Em=a("li"),cH=a("strong"),FDe=o("layoutlmv2"),CDe=o(" \u2014 "),k9=a("a"),MDe=o("LayoutLMv2Config"),EDe=o(" (LayoutLMv2 model)"),yDe=l(),ym=a("li"),fH=a("strong"),wDe=o("led"),ADe=o(" \u2014 "),R9=a("a"),LDe=o("LEDConfig"),BDe=o(" (LED model)"),xDe=l(),wm=a("li"),mH=a("strong"),kDe=o("longformer"),RDe=o(" \u2014 "),S9=a("a"),SDe=o("LongformerConfig"),PDe=o(" (Longformer model)"),$De=l(),Am=a("li"),gH=a("strong"),IDe=o("luke"),jDe=o(" \u2014 "),P9=a("a"),DDe=o("LukeConfig"),NDe=o(" (LUKE model)"),qDe=l(),Lm=a("li"),hH=a("strong"),ODe=o("lxmert"),GDe=o(" \u2014 "),$9=a("a"),XDe=o("LxmertConfig"),VDe=o(" (LXMERT model)"),zDe=l(),Bm=a("li"),pH=a("strong"),WDe=o("m2m_100"),QDe=o(" \u2014 "),I9=a("a"),HDe=o("M2M100Config"),UDe=o(" (M2M100 model)"),JDe=l(),xm=a("li"),_H=a("strong"),YDe=o("marian"),KDe=o(" \u2014 "),j9=a("a"),ZDe=o("MarianConfig"),eNe=o(" (Marian model)"),oNe=l(),km=a("li"),uH=a("strong"),rNe=o("maskformer"),tNe=o(" \u2014 "),D9=a("a"),aNe=o("MaskFormerConfig"),nNe=o(" (MaskFormer model)"),sNe=l(),Rm=a("li"),bH=a("strong"),lNe=o("mbart"),iNe=o(" \u2014 "),N9=a("a"),dNe=o("MBartConfig"),cNe=o(" (mBART model)"),fNe=l(),Sm=a("li"),vH=a("strong"),mNe=o("megatron-bert"),gNe=o(" \u2014 "),q9=a("a"),hNe=o("MegatronBertConfig"),pNe=o(" (MegatronBert model)"),_Ne=l(),Pm=a("li"),TH=a("strong"),uNe=o("mobilebert"),bNe=o(" \u2014 "),O9=a("a"),vNe=o("MobileBertConfig"),TNe=o(" (MobileBERT model)"),FNe=l(),$m=a("li"),FH=a("strong"),CNe=o("mpnet"),MNe=o(" \u2014 "),G9=a("a"),ENe=o("MPNetConfig"),yNe=o(" (MPNet model)"),wNe=l(),Im=a("li"),CH=a("strong"),ANe=o("mt5"),LNe=o(" \u2014 "),X9=a("a"),BNe=o("MT5Config"),xNe=o(" (mT5 model)"),kNe=l(),jm=a("li"),MH=a("strong"),RNe=o("nystromformer"),SNe=o(" \u2014 "),V9=a("a"),PNe=o("NystromformerConfig"),$Ne=o(" (Nystromformer model)"),INe=l(),Dm=a("li"),EH=a("strong"),jNe=o("openai-gpt"),DNe=o(" \u2014 "),z9=a("a"),NNe=o("OpenAIGPTConfig"),qNe=o(" (OpenAI GPT model)"),ONe=l(),Nm=a("li"),yH=a("strong"),GNe=o("pegasus"),XNe=o(" \u2014 "),W9=a("a"),VNe=o("PegasusConfig"),zNe=o(" (Pegasus model)"),WNe=l(),qm=a("li"),wH=a("strong"),QNe=o("perceiver"),HNe=o(" \u2014 "),Q9=a("a"),UNe=o("PerceiverConfig"),JNe=o(" (Perceiver model)"),YNe=l(),Om=a("li"),AH=a("strong"),KNe=o("plbart"),ZNe=o(" \u2014 "),H9=a("a"),eqe=o("PLBartConfig"),oqe=o(" (PLBart model)"),rqe=l(),Gm=a("li"),LH=a("strong"),tqe=o("poolformer"),aqe=o(" \u2014 "),U9=a("a"),nqe=o("PoolFormerConfig"),sqe=o(" (PoolFormer model)"),lqe=l(),Xm=a("li"),BH=a("strong"),iqe=o("prophetnet"),dqe=o(" \u2014 "),J9=a("a"),cqe=o("ProphetNetConfig"),fqe=o(" (ProphetNet model)"),mqe=l(),Vm=a("li"),xH=a("strong"),gqe=o("qdqbert"),hqe=o(" \u2014 "),Y9=a("a"),pqe=o("QDQBertConfig"),_qe=o(" (QDQBert model)"),uqe=l(),zm=a("li"),kH=a("strong"),bqe=o("rag"),vqe=o(" \u2014 "),K9=a("a"),Tqe=o("RagConfig"),Fqe=o(" (RAG model)"),Cqe=l(),Wm=a("li"),RH=a("strong"),Mqe=o("realm"),Eqe=o(" \u2014 "),Z9=a("a"),yqe=o("RealmConfig"),wqe=o(" (Realm model)"),Aqe=l(),Qm=a("li"),SH=a("strong"),Lqe=o("reformer"),Bqe=o(" \u2014 "),eB=a("a"),xqe=o("ReformerConfig"),kqe=o(" (Reformer model)"),Rqe=l(),Hm=a("li"),PH=a("strong"),Sqe=o("rembert"),Pqe=o(" \u2014 "),oB=a("a"),$qe=o("RemBertConfig"),Iqe=o(" (RemBERT model)"),jqe=l(),Um=a("li"),$H=a("strong"),Dqe=o("resnet"),Nqe=o(" \u2014 "),rB=a("a"),qqe=o("ResNetConfig"),Oqe=o(" (ResNet model)"),Gqe=l(),Jm=a("li"),IH=a("strong"),Xqe=o("retribert"),Vqe=o(" \u2014 "),tB=a("a"),zqe=o("RetriBertConfig"),Wqe=o(" (RetriBERT model)"),Qqe=l(),Ym=a("li"),jH=a("strong"),Hqe=o("roberta"),Uqe=o(" \u2014 "),aB=a("a"),Jqe=o("RobertaConfig"),Yqe=o(" (RoBERTa model)"),Kqe=l(),Km=a("li"),DH=a("strong"),Zqe=o("roformer"),eOe=o(" \u2014 "),nB=a("a"),oOe=o("RoFormerConfig"),rOe=o(" (RoFormer model)"),tOe=l(),Zm=a("li"),NH=a("strong"),aOe=o("segformer"),nOe=o(" \u2014 "),sB=a("a"),sOe=o("SegformerConfig"),lOe=o(" (SegFormer model)"),iOe=l(),eg=a("li"),qH=a("strong"),dOe=o("sew"),cOe=o(" \u2014 "),lB=a("a"),fOe=o("SEWConfig"),mOe=o(" (SEW model)"),gOe=l(),og=a("li"),OH=a("strong"),hOe=o("sew-d"),pOe=o(" \u2014 "),iB=a("a"),_Oe=o("SEWDConfig"),uOe=o(" (SEW-D model)"),bOe=l(),rg=a("li"),GH=a("strong"),vOe=o("speech-encoder-decoder"),TOe=o(" \u2014 "),dB=a("a"),FOe=o("SpeechEncoderDecoderConfig"),COe=o(" (Speech Encoder decoder model)"),MOe=l(),tg=a("li"),XH=a("strong"),EOe=o("speech_to_text"),yOe=o(" \u2014 "),cB=a("a"),wOe=o("Speech2TextConfig"),AOe=o(" (Speech2Text model)"),LOe=l(),ag=a("li"),VH=a("strong"),BOe=o("speech_to_text_2"),xOe=o(" \u2014 "),fB=a("a"),kOe=o("Speech2Text2Config"),ROe=o(" (Speech2Text2 model)"),SOe=l(),ng=a("li"),zH=a("strong"),POe=o("splinter"),$Oe=o(" \u2014 "),mB=a("a"),IOe=o("SplinterConfig"),jOe=o(" (Splinter model)"),DOe=l(),sg=a("li"),WH=a("strong"),NOe=o("squeezebert"),qOe=o(" \u2014 "),gB=a("a"),OOe=o("SqueezeBertConfig"),GOe=o(" (SqueezeBERT model)"),XOe=l(),lg=a("li"),QH=a("strong"),VOe=o("swin"),zOe=o(" \u2014 "),hB=a("a"),WOe=o("SwinConfig"),QOe=o(" (Swin model)"),HOe=l(),ig=a("li"),HH=a("strong"),UOe=o("t5"),JOe=o(" \u2014 "),pB=a("a"),YOe=o("T5Config"),KOe=o(" (T5 model)"),ZOe=l(),dg=a("li"),UH=a("strong"),eGe=o("tapas"),oGe=o(" \u2014 "),_B=a("a"),rGe=o("TapasConfig"),tGe=o(" (TAPAS model)"),aGe=l(),cg=a("li"),JH=a("strong"),nGe=o("transfo-xl"),sGe=o(" \u2014 "),uB=a("a"),lGe=o("TransfoXLConfig"),iGe=o(" (Transformer-XL model)"),dGe=l(),fg=a("li"),YH=a("strong"),cGe=o("trocr"),fGe=o(" \u2014 "),bB=a("a"),mGe=o("TrOCRConfig"),gGe=o(" (TrOCR model)"),hGe=l(),mg=a("li"),KH=a("strong"),pGe=o("unispeech"),_Ge=o(" \u2014 "),vB=a("a"),uGe=o("UniSpeechConfig"),bGe=o(" (UniSpeech model)"),vGe=l(),gg=a("li"),ZH=a("strong"),TGe=o("unispeech-sat"),FGe=o(" \u2014 "),TB=a("a"),CGe=o("UniSpeechSatConfig"),MGe=o(" (UniSpeechSat model)"),EGe=l(),hg=a("li"),eU=a("strong"),yGe=o("vilt"),wGe=o(" \u2014 "),FB=a("a"),AGe=o("ViltConfig"),LGe=o(" (ViLT model)"),BGe=l(),pg=a("li"),oU=a("strong"),xGe=o("vision-encoder-decoder"),kGe=o(" \u2014 "),CB=a("a"),RGe=o("VisionEncoderDecoderConfig"),SGe=o(" (Vision Encoder decoder model)"),PGe=l(),_g=a("li"),rU=a("strong"),$Ge=o("vision-text-dual-encoder"),IGe=o(" \u2014 "),MB=a("a"),jGe=o("VisionTextDualEncoderConfig"),DGe=o(" (VisionTextDualEncoder model)"),NGe=l(),ug=a("li"),tU=a("strong"),qGe=o("visual_bert"),OGe=o(" \u2014 "),EB=a("a"),GGe=o("VisualBertConfig"),XGe=o(" (VisualBert model)"),VGe=l(),bg=a("li"),aU=a("strong"),zGe=o("vit"),WGe=o(" \u2014 "),yB=a("a"),QGe=o("ViTConfig"),HGe=o(" (ViT model)"),UGe=l(),vg=a("li"),nU=a("strong"),JGe=o("vit_mae"),YGe=o(" \u2014 "),wB=a("a"),KGe=o("ViTMAEConfig"),ZGe=o(" (ViTMAE model)"),eXe=l(),Tg=a("li"),sU=a("strong"),oXe=o("wav2vec2"),rXe=o(" \u2014 "),AB=a("a"),tXe=o("Wav2Vec2Config"),aXe=o(" (Wav2Vec2 model)"),nXe=l(),Fg=a("li"),lU=a("strong"),sXe=o("wavlm"),lXe=o(" \u2014 "),LB=a("a"),iXe=o("WavLMConfig"),dXe=o(" (WavLM model)"),cXe=l(),Cg=a("li"),iU=a("strong"),fXe=o("xglm"),mXe=o(" \u2014 "),BB=a("a"),gXe=o("XGLMConfig"),hXe=o(" (XGLM model)"),pXe=l(),Mg=a("li"),dU=a("strong"),_Xe=o("xlm"),uXe=o(" \u2014 "),xB=a("a"),bXe=o("XLMConfig"),vXe=o(" (XLM model)"),TXe=l(),Eg=a("li"),cU=a("strong"),FXe=o("xlm-prophetnet"),CXe=o(" \u2014 "),kB=a("a"),MXe=o("XLMProphetNetConfig"),EXe=o(" (XLMProphetNet model)"),yXe=l(),yg=a("li"),fU=a("strong"),wXe=o("xlm-roberta"),AXe=o(" \u2014 "),RB=a("a"),LXe=o("XLMRobertaConfig"),BXe=o(" (XLM-RoBERTa model)"),xXe=l(),wg=a("li"),mU=a("strong"),kXe=o("xlm-roberta-xl"),RXe=o(" \u2014 "),SB=a("a"),SXe=o("XLMRobertaXLConfig"),PXe=o(" (XLM-RoBERTa-XL model)"),$Xe=l(),Ag=a("li"),gU=a("strong"),IXe=o("xlnet"),jXe=o(" \u2014 "),PB=a("a"),DXe=o("XLNetConfig"),NXe=o(" (XLNet model)"),qXe=l(),Lg=a("li"),hU=a("strong"),OXe=o("yoso"),GXe=o(" \u2014 "),$B=a("a"),XXe=o("YosoConfig"),VXe=o(" (YOSO model)"),zXe=l(),pU=a("p"),WXe=o("Examples:"),QXe=l(),f(sE.$$.fragment),HXe=l(),Bg=a("div"),f(lE.$$.fragment),UXe=l(),_U=a("p"),JXe=o("Register a new configuration for this class."),Fxe=l(),Wi=a("h2"),xg=a("a"),uU=a("span"),f(iE.$$.fragment),YXe=l(),bU=a("span"),KXe=o("AutoTokenizer"),Cxe=l(),Qo=a("div"),f(dE.$$.fragment),ZXe=l(),cE=a("p"),eVe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),IB=a("a"),oVe=o("AutoTokenizer.from_pretrained()"),rVe=o(" class method."),tVe=l(),fE=a("p"),aVe=o("This class cannot be instantiated directly using "),vU=a("code"),nVe=o("__init__()"),sVe=o(" (throws an error)."),lVe=l(),go=a("div"),f(mE.$$.fragment),iVe=l(),TU=a("p"),dVe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),cVe=l(),Oa=a("p"),fVe=o("The tokenizer class to instantiate is selected based on the "),FU=a("code"),mVe=o("model_type"),gVe=o(` property of the config object (either
passed as an argument or loaded from `),CU=a("code"),hVe=o("pretrained_model_name_or_path"),pVe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MU=a("code"),_Ve=o("pretrained_model_name_or_path"),uVe=o(":"),bVe=l(),E=a("ul"),Wn=a("li"),EU=a("strong"),vVe=o("albert"),TVe=o(" \u2014 "),jB=a("a"),FVe=o("AlbertTokenizer"),CVe=o(" or "),DB=a("a"),MVe=o("AlbertTokenizerFast"),EVe=o(" (ALBERT model)"),yVe=l(),Qn=a("li"),yU=a("strong"),wVe=o("bart"),AVe=o(" \u2014 "),NB=a("a"),LVe=o("BartTokenizer"),BVe=o(" or "),qB=a("a"),xVe=o("BartTokenizerFast"),kVe=o(" (BART model)"),RVe=l(),Hn=a("li"),wU=a("strong"),SVe=o("barthez"),PVe=o(" \u2014 "),OB=a("a"),$Ve=o("BarthezTokenizer"),IVe=o(" or "),GB=a("a"),jVe=o("BarthezTokenizerFast"),DVe=o(" (BARThez model)"),NVe=l(),kg=a("li"),AU=a("strong"),qVe=o("bartpho"),OVe=o(" \u2014 "),XB=a("a"),GVe=o("BartphoTokenizer"),XVe=o(" (BARTpho model)"),VVe=l(),Un=a("li"),LU=a("strong"),zVe=o("bert"),WVe=o(" \u2014 "),VB=a("a"),QVe=o("BertTokenizer"),HVe=o(" or "),zB=a("a"),UVe=o("BertTokenizerFast"),JVe=o(" (BERT model)"),YVe=l(),Rg=a("li"),BU=a("strong"),KVe=o("bert-generation"),ZVe=o(" \u2014 "),WB=a("a"),eze=o("BertGenerationTokenizer"),oze=o(" (Bert Generation model)"),rze=l(),Sg=a("li"),xU=a("strong"),tze=o("bert-japanese"),aze=o(" \u2014 "),QB=a("a"),nze=o("BertJapaneseTokenizer"),sze=o(" (BertJapanese model)"),lze=l(),Pg=a("li"),kU=a("strong"),ize=o("bertweet"),dze=o(" \u2014 "),HB=a("a"),cze=o("BertweetTokenizer"),fze=o(" (Bertweet model)"),mze=l(),Jn=a("li"),RU=a("strong"),gze=o("big_bird"),hze=o(" \u2014 "),UB=a("a"),pze=o("BigBirdTokenizer"),_ze=o(" or "),JB=a("a"),uze=o("BigBirdTokenizerFast"),bze=o(" (BigBird model)"),vze=l(),Yn=a("li"),SU=a("strong"),Tze=o("bigbird_pegasus"),Fze=o(" \u2014 "),YB=a("a"),Cze=o("PegasusTokenizer"),Mze=o(" or "),KB=a("a"),Eze=o("PegasusTokenizerFast"),yze=o(" (BigBirdPegasus model)"),wze=l(),Kn=a("li"),PU=a("strong"),Aze=o("blenderbot"),Lze=o(" \u2014 "),ZB=a("a"),Bze=o("BlenderbotTokenizer"),xze=o(" or "),ex=a("a"),kze=o("BlenderbotTokenizerFast"),Rze=o(" (Blenderbot model)"),Sze=l(),$g=a("li"),$U=a("strong"),Pze=o("blenderbot-small"),$ze=o(" \u2014 "),ox=a("a"),Ize=o("BlenderbotSmallTokenizer"),jze=o(" (BlenderbotSmall model)"),Dze=l(),Ig=a("li"),IU=a("strong"),Nze=o("byt5"),qze=o(" \u2014 "),rx=a("a"),Oze=o("ByT5Tokenizer"),Gze=o(" (ByT5 model)"),Xze=l(),Zn=a("li"),jU=a("strong"),Vze=o("camembert"),zze=o(" \u2014 "),tx=a("a"),Wze=o("CamembertTokenizer"),Qze=o(" or "),ax=a("a"),Hze=o("CamembertTokenizerFast"),Uze=o(" (CamemBERT model)"),Jze=l(),jg=a("li"),DU=a("strong"),Yze=o("canine"),Kze=o(" \u2014 "),nx=a("a"),Zze=o("CanineTokenizer"),eWe=o(" (Canine model)"),oWe=l(),es=a("li"),NU=a("strong"),rWe=o("clip"),tWe=o(" \u2014 "),sx=a("a"),aWe=o("CLIPTokenizer"),nWe=o(" or "),lx=a("a"),sWe=o("CLIPTokenizerFast"),lWe=o(" (CLIP model)"),iWe=l(),os=a("li"),qU=a("strong"),dWe=o("convbert"),cWe=o(" \u2014 "),ix=a("a"),fWe=o("ConvBertTokenizer"),mWe=o(" or "),dx=a("a"),gWe=o("ConvBertTokenizerFast"),hWe=o(" (ConvBERT model)"),pWe=l(),rs=a("li"),OU=a("strong"),_We=o("cpm"),uWe=o(" \u2014 "),cx=a("a"),bWe=o("CpmTokenizer"),vWe=o(" or "),GU=a("code"),TWe=o("CpmTokenizerFast"),FWe=o(" (CPM model)"),CWe=l(),Dg=a("li"),XU=a("strong"),MWe=o("ctrl"),EWe=o(" \u2014 "),fx=a("a"),yWe=o("CTRLTokenizer"),wWe=o(" (CTRL model)"),AWe=l(),ts=a("li"),VU=a("strong"),LWe=o("deberta"),BWe=o(" \u2014 "),mx=a("a"),xWe=o("DebertaTokenizer"),kWe=o(" or "),gx=a("a"),RWe=o("DebertaTokenizerFast"),SWe=o(" (DeBERTa model)"),PWe=l(),Ng=a("li"),zU=a("strong"),$We=o("deberta-v2"),IWe=o(" \u2014 "),hx=a("a"),jWe=o("DebertaV2Tokenizer"),DWe=o(" (DeBERTa-v2 model)"),NWe=l(),as=a("li"),WU=a("strong"),qWe=o("distilbert"),OWe=o(" \u2014 "),px=a("a"),GWe=o("DistilBertTokenizer"),XWe=o(" or "),_x=a("a"),VWe=o("DistilBertTokenizerFast"),zWe=o(" (DistilBERT model)"),WWe=l(),ns=a("li"),QU=a("strong"),QWe=o("dpr"),HWe=o(" \u2014 "),ux=a("a"),UWe=o("DPRQuestionEncoderTokenizer"),JWe=o(" or "),bx=a("a"),YWe=o("DPRQuestionEncoderTokenizerFast"),KWe=o(" (DPR model)"),ZWe=l(),ss=a("li"),HU=a("strong"),eQe=o("electra"),oQe=o(" \u2014 "),vx=a("a"),rQe=o("ElectraTokenizer"),tQe=o(" or "),Tx=a("a"),aQe=o("ElectraTokenizerFast"),nQe=o(" (ELECTRA model)"),sQe=l(),qg=a("li"),UU=a("strong"),lQe=o("flaubert"),iQe=o(" \u2014 "),Fx=a("a"),dQe=o("FlaubertTokenizer"),cQe=o(" (FlauBERT model)"),fQe=l(),ls=a("li"),JU=a("strong"),mQe=o("fnet"),gQe=o(" \u2014 "),Cx=a("a"),hQe=o("FNetTokenizer"),pQe=o(" or "),Mx=a("a"),_Qe=o("FNetTokenizerFast"),uQe=o(" (FNet model)"),bQe=l(),Og=a("li"),YU=a("strong"),vQe=o("fsmt"),TQe=o(" \u2014 "),Ex=a("a"),FQe=o("FSMTTokenizer"),CQe=o(" (FairSeq Machine-Translation model)"),MQe=l(),is=a("li"),KU=a("strong"),EQe=o("funnel"),yQe=o(" \u2014 "),yx=a("a"),wQe=o("FunnelTokenizer"),AQe=o(" or "),wx=a("a"),LQe=o("FunnelTokenizerFast"),BQe=o(" (Funnel Transformer model)"),xQe=l(),ds=a("li"),ZU=a("strong"),kQe=o("gpt2"),RQe=o(" \u2014 "),Ax=a("a"),SQe=o("GPT2Tokenizer"),PQe=o(" or "),Lx=a("a"),$Qe=o("GPT2TokenizerFast"),IQe=o(" (OpenAI GPT-2 model)"),jQe=l(),cs=a("li"),eJ=a("strong"),DQe=o("gpt_neo"),NQe=o(" \u2014 "),Bx=a("a"),qQe=o("GPT2Tokenizer"),OQe=o(" or "),xx=a("a"),GQe=o("GPT2TokenizerFast"),XQe=o(" (GPT Neo model)"),VQe=l(),fs=a("li"),oJ=a("strong"),zQe=o("herbert"),WQe=o(" \u2014 "),kx=a("a"),QQe=o("HerbertTokenizer"),HQe=o(" or "),Rx=a("a"),UQe=o("HerbertTokenizerFast"),JQe=o(" (HerBERT model)"),YQe=l(),Gg=a("li"),rJ=a("strong"),KQe=o("hubert"),ZQe=o(" \u2014 "),Sx=a("a"),eHe=o("Wav2Vec2CTCTokenizer"),oHe=o(" (Hubert model)"),rHe=l(),ms=a("li"),tJ=a("strong"),tHe=o("ibert"),aHe=o(" \u2014 "),Px=a("a"),nHe=o("RobertaTokenizer"),sHe=o(" or "),$x=a("a"),lHe=o("RobertaTokenizerFast"),iHe=o(" (I-BERT model)"),dHe=l(),gs=a("li"),aJ=a("strong"),cHe=o("layoutlm"),fHe=o(" \u2014 "),Ix=a("a"),mHe=o("LayoutLMTokenizer"),gHe=o(" or "),jx=a("a"),hHe=o("LayoutLMTokenizerFast"),pHe=o(" (LayoutLM model)"),_He=l(),hs=a("li"),nJ=a("strong"),uHe=o("layoutlmv2"),bHe=o(" \u2014 "),Dx=a("a"),vHe=o("LayoutLMv2Tokenizer"),THe=o(" or "),Nx=a("a"),FHe=o("LayoutLMv2TokenizerFast"),CHe=o(" (LayoutLMv2 model)"),MHe=l(),ps=a("li"),sJ=a("strong"),EHe=o("layoutxlm"),yHe=o(" \u2014 "),qx=a("a"),wHe=o("LayoutXLMTokenizer"),AHe=o(" or "),Ox=a("a"),LHe=o("LayoutXLMTokenizerFast"),BHe=o(" (LayoutXLM model)"),xHe=l(),_s=a("li"),lJ=a("strong"),kHe=o("led"),RHe=o(" \u2014 "),Gx=a("a"),SHe=o("LEDTokenizer"),PHe=o(" or "),Xx=a("a"),$He=o("LEDTokenizerFast"),IHe=o(" (LED model)"),jHe=l(),us=a("li"),iJ=a("strong"),DHe=o("longformer"),NHe=o(" \u2014 "),Vx=a("a"),qHe=o("LongformerTokenizer"),OHe=o(" or "),zx=a("a"),GHe=o("LongformerTokenizerFast"),XHe=o(" (Longformer model)"),VHe=l(),Xg=a("li"),dJ=a("strong"),zHe=o("luke"),WHe=o(" \u2014 "),Wx=a("a"),QHe=o("LukeTokenizer"),HHe=o(" (LUKE model)"),UHe=l(),bs=a("li"),cJ=a("strong"),JHe=o("lxmert"),YHe=o(" \u2014 "),Qx=a("a"),KHe=o("LxmertTokenizer"),ZHe=o(" or "),Hx=a("a"),eUe=o("LxmertTokenizerFast"),oUe=o(" (LXMERT model)"),rUe=l(),Vg=a("li"),fJ=a("strong"),tUe=o("m2m_100"),aUe=o(" \u2014 "),Ux=a("a"),nUe=o("M2M100Tokenizer"),sUe=o(" (M2M100 model)"),lUe=l(),zg=a("li"),mJ=a("strong"),iUe=o("marian"),dUe=o(" \u2014 "),Jx=a("a"),cUe=o("MarianTokenizer"),fUe=o(" (Marian model)"),mUe=l(),vs=a("li"),gJ=a("strong"),gUe=o("mbart"),hUe=o(" \u2014 "),Yx=a("a"),pUe=o("MBartTokenizer"),_Ue=o(" or "),Kx=a("a"),uUe=o("MBartTokenizerFast"),bUe=o(" (mBART model)"),vUe=l(),Ts=a("li"),hJ=a("strong"),TUe=o("mbart50"),FUe=o(" \u2014 "),Zx=a("a"),CUe=o("MBart50Tokenizer"),MUe=o(" or "),ek=a("a"),EUe=o("MBart50TokenizerFast"),yUe=o(" (mBART-50 model)"),wUe=l(),Wg=a("li"),pJ=a("strong"),AUe=o("mluke"),LUe=o(" \u2014 "),ok=a("a"),BUe=o("MLukeTokenizer"),xUe=o(" (mLUKE model)"),kUe=l(),Fs=a("li"),_J=a("strong"),RUe=o("mobilebert"),SUe=o(" \u2014 "),rk=a("a"),PUe=o("MobileBertTokenizer"),$Ue=o(" or "),tk=a("a"),IUe=o("MobileBertTokenizerFast"),jUe=o(" (MobileBERT model)"),DUe=l(),Cs=a("li"),uJ=a("strong"),NUe=o("mpnet"),qUe=o(" \u2014 "),ak=a("a"),OUe=o("MPNetTokenizer"),GUe=o(" or "),nk=a("a"),XUe=o("MPNetTokenizerFast"),VUe=o(" (MPNet model)"),zUe=l(),Ms=a("li"),bJ=a("strong"),WUe=o("mt5"),QUe=o(" \u2014 "),sk=a("a"),HUe=o("MT5Tokenizer"),UUe=o(" or "),lk=a("a"),JUe=o("MT5TokenizerFast"),YUe=o(" (mT5 model)"),KUe=l(),Es=a("li"),vJ=a("strong"),ZUe=o("openai-gpt"),eJe=o(" \u2014 "),ik=a("a"),oJe=o("OpenAIGPTTokenizer"),rJe=o(" or "),dk=a("a"),tJe=o("OpenAIGPTTokenizerFast"),aJe=o(" (OpenAI GPT model)"),nJe=l(),ys=a("li"),TJ=a("strong"),sJe=o("pegasus"),lJe=o(" \u2014 "),ck=a("a"),iJe=o("PegasusTokenizer"),dJe=o(" or "),fk=a("a"),cJe=o("PegasusTokenizerFast"),fJe=o(" (Pegasus model)"),mJe=l(),Qg=a("li"),FJ=a("strong"),gJe=o("perceiver"),hJe=o(" \u2014 "),mk=a("a"),pJe=o("PerceiverTokenizer"),_Je=o(" (Perceiver model)"),uJe=l(),Hg=a("li"),CJ=a("strong"),bJe=o("phobert"),vJe=o(" \u2014 "),gk=a("a"),TJe=o("PhobertTokenizer"),FJe=o(" (PhoBERT model)"),CJe=l(),Ug=a("li"),MJ=a("strong"),MJe=o("plbart"),EJe=o(" \u2014 "),hk=a("a"),yJe=o("PLBartTokenizer"),wJe=o(" (PLBart model)"),AJe=l(),Jg=a("li"),EJ=a("strong"),LJe=o("prophetnet"),BJe=o(" \u2014 "),pk=a("a"),xJe=o("ProphetNetTokenizer"),kJe=o(" (ProphetNet model)"),RJe=l(),ws=a("li"),yJ=a("strong"),SJe=o("qdqbert"),PJe=o(" \u2014 "),_k=a("a"),$Je=o("BertTokenizer"),IJe=o(" or "),uk=a("a"),jJe=o("BertTokenizerFast"),DJe=o(" (QDQBert model)"),NJe=l(),Yg=a("li"),wJ=a("strong"),qJe=o("rag"),OJe=o(" \u2014 "),bk=a("a"),GJe=o("RagTokenizer"),XJe=o(" (RAG model)"),VJe=l(),As=a("li"),AJ=a("strong"),zJe=o("realm"),WJe=o(" \u2014 "),vk=a("a"),QJe=o("RealmTokenizer"),HJe=o(" or "),Tk=a("a"),UJe=o("RealmTokenizerFast"),JJe=o(" (Realm model)"),YJe=l(),Ls=a("li"),LJ=a("strong"),KJe=o("reformer"),ZJe=o(" \u2014 "),Fk=a("a"),eYe=o("ReformerTokenizer"),oYe=o(" or "),Ck=a("a"),rYe=o("ReformerTokenizerFast"),tYe=o(" (Reformer model)"),aYe=l(),Bs=a("li"),BJ=a("strong"),nYe=o("rembert"),sYe=o(" \u2014 "),Mk=a("a"),lYe=o("RemBertTokenizer"),iYe=o(" or "),Ek=a("a"),dYe=o("RemBertTokenizerFast"),cYe=o(" (RemBERT model)"),fYe=l(),xs=a("li"),xJ=a("strong"),mYe=o("retribert"),gYe=o(" \u2014 "),yk=a("a"),hYe=o("RetriBertTokenizer"),pYe=o(" or "),wk=a("a"),_Ye=o("RetriBertTokenizerFast"),uYe=o(" (RetriBERT model)"),bYe=l(),ks=a("li"),kJ=a("strong"),vYe=o("roberta"),TYe=o(" \u2014 "),Ak=a("a"),FYe=o("RobertaTokenizer"),CYe=o(" or "),Lk=a("a"),MYe=o("RobertaTokenizerFast"),EYe=o(" (RoBERTa model)"),yYe=l(),Rs=a("li"),RJ=a("strong"),wYe=o("roformer"),AYe=o(" \u2014 "),Bk=a("a"),LYe=o("RoFormerTokenizer"),BYe=o(" or "),xk=a("a"),xYe=o("RoFormerTokenizerFast"),kYe=o(" (RoFormer model)"),RYe=l(),Kg=a("li"),SJ=a("strong"),SYe=o("speech_to_text"),PYe=o(" \u2014 "),kk=a("a"),$Ye=o("Speech2TextTokenizer"),IYe=o(" (Speech2Text model)"),jYe=l(),Zg=a("li"),PJ=a("strong"),DYe=o("speech_to_text_2"),NYe=o(" \u2014 "),Rk=a("a"),qYe=o("Speech2Text2Tokenizer"),OYe=o(" (Speech2Text2 model)"),GYe=l(),Ss=a("li"),$J=a("strong"),XYe=o("splinter"),VYe=o(" \u2014 "),Sk=a("a"),zYe=o("SplinterTokenizer"),WYe=o(" or "),Pk=a("a"),QYe=o("SplinterTokenizerFast"),HYe=o(" (Splinter model)"),UYe=l(),Ps=a("li"),IJ=a("strong"),JYe=o("squeezebert"),YYe=o(" \u2014 "),$k=a("a"),KYe=o("SqueezeBertTokenizer"),ZYe=o(" or "),Ik=a("a"),eKe=o("SqueezeBertTokenizerFast"),oKe=o(" (SqueezeBERT model)"),rKe=l(),$s=a("li"),jJ=a("strong"),tKe=o("t5"),aKe=o(" \u2014 "),jk=a("a"),nKe=o("T5Tokenizer"),sKe=o(" or "),Dk=a("a"),lKe=o("T5TokenizerFast"),iKe=o(" (T5 model)"),dKe=l(),eh=a("li"),DJ=a("strong"),cKe=o("tapas"),fKe=o(" \u2014 "),Nk=a("a"),mKe=o("TapasTokenizer"),gKe=o(" (TAPAS model)"),hKe=l(),oh=a("li"),NJ=a("strong"),pKe=o("transfo-xl"),_Ke=o(" \u2014 "),qk=a("a"),uKe=o("TransfoXLTokenizer"),bKe=o(" (Transformer-XL model)"),vKe=l(),rh=a("li"),qJ=a("strong"),TKe=o("wav2vec2"),FKe=o(" \u2014 "),Ok=a("a"),CKe=o("Wav2Vec2CTCTokenizer"),MKe=o(" (Wav2Vec2 model)"),EKe=l(),th=a("li"),OJ=a("strong"),yKe=o("wav2vec2_phoneme"),wKe=o(" \u2014 "),Gk=a("a"),AKe=o("Wav2Vec2PhonemeCTCTokenizer"),LKe=o(" (Wav2Vec2Phoneme model)"),BKe=l(),Is=a("li"),GJ=a("strong"),xKe=o("xglm"),kKe=o(" \u2014 "),Xk=a("a"),RKe=o("XGLMTokenizer"),SKe=o(" or "),Vk=a("a"),PKe=o("XGLMTokenizerFast"),$Ke=o(" (XGLM model)"),IKe=l(),ah=a("li"),XJ=a("strong"),jKe=o("xlm"),DKe=o(" \u2014 "),zk=a("a"),NKe=o("XLMTokenizer"),qKe=o(" (XLM model)"),OKe=l(),nh=a("li"),VJ=a("strong"),GKe=o("xlm-prophetnet"),XKe=o(" \u2014 "),Wk=a("a"),VKe=o("XLMProphetNetTokenizer"),zKe=o(" (XLMProphetNet model)"),WKe=l(),js=a("li"),zJ=a("strong"),QKe=o("xlm-roberta"),HKe=o(" \u2014 "),Qk=a("a"),UKe=o("XLMRobertaTokenizer"),JKe=o(" or "),Hk=a("a"),YKe=o("XLMRobertaTokenizerFast"),KKe=o(" (XLM-RoBERTa model)"),ZKe=l(),Ds=a("li"),WJ=a("strong"),eZe=o("xlnet"),oZe=o(" \u2014 "),Uk=a("a"),rZe=o("XLNetTokenizer"),tZe=o(" or "),Jk=a("a"),aZe=o("XLNetTokenizerFast"),nZe=o(" (XLNet model)"),sZe=l(),QJ=a("p"),lZe=o("Examples:"),iZe=l(),f(gE.$$.fragment),dZe=l(),sh=a("div"),f(hE.$$.fragment),cZe=l(),HJ=a("p"),fZe=o("Register a new tokenizer in this mapping."),Mxe=l(),Qi=a("h2"),lh=a("a"),UJ=a("span"),f(pE.$$.fragment),mZe=l(),JJ=a("span"),gZe=o("AutoFeatureExtractor"),Exe=l(),Ho=a("div"),f(_E.$$.fragment),hZe=l(),uE=a("p"),pZe=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Yk=a("a"),_Ze=o("AutoFeatureExtractor.from_pretrained()"),uZe=o(" class method."),bZe=l(),bE=a("p"),vZe=o("This class cannot be instantiated directly using "),YJ=a("code"),TZe=o("__init__()"),FZe=o(" (throws an error)."),CZe=l(),Ie=a("div"),f(vE.$$.fragment),MZe=l(),KJ=a("p"),EZe=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),yZe=l(),Ga=a("p"),wZe=o("The feature extractor class to instantiate is selected based on the "),ZJ=a("code"),AZe=o("model_type"),LZe=o(` property of the config object
(either passed as an argument or loaded from `),eY=a("code"),BZe=o("pretrained_model_name_or_path"),xZe=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),oY=a("code"),kZe=o("pretrained_model_name_or_path"),RZe=o(":"),SZe=l(),te=a("ul"),ih=a("li"),rY=a("strong"),PZe=o("beit"),$Ze=o(" \u2014 "),Kk=a("a"),IZe=o("BeitFeatureExtractor"),jZe=o(" (BEiT model)"),DZe=l(),dh=a("li"),tY=a("strong"),NZe=o("clip"),qZe=o(" \u2014 "),Zk=a("a"),OZe=o("CLIPFeatureExtractor"),GZe=o(" (CLIP model)"),XZe=l(),ch=a("li"),aY=a("strong"),VZe=o("convnext"),zZe=o(" \u2014 "),eR=a("a"),WZe=o("ConvNextFeatureExtractor"),QZe=o(" (ConvNext model)"),HZe=l(),fh=a("li"),nY=a("strong"),UZe=o("deit"),JZe=o(" \u2014 "),oR=a("a"),YZe=o("DeiTFeatureExtractor"),KZe=o(" (DeiT model)"),ZZe=l(),mh=a("li"),sY=a("strong"),eeo=o("detr"),oeo=o(" \u2014 "),rR=a("a"),reo=o("DetrFeatureExtractor"),teo=o(" (DETR model)"),aeo=l(),gh=a("li"),lY=a("strong"),neo=o("hubert"),seo=o(" \u2014 "),tR=a("a"),leo=o("Wav2Vec2FeatureExtractor"),ieo=o(" (Hubert model)"),deo=l(),hh=a("li"),iY=a("strong"),ceo=o("layoutlmv2"),feo=o(" \u2014 "),aR=a("a"),meo=o("LayoutLMv2FeatureExtractor"),geo=o(" (LayoutLMv2 model)"),heo=l(),ph=a("li"),dY=a("strong"),peo=o("maskformer"),_eo=o(" \u2014 "),nR=a("a"),ueo=o("MaskFormerFeatureExtractor"),beo=o(" (MaskFormer model)"),veo=l(),_h=a("li"),cY=a("strong"),Teo=o("perceiver"),Feo=o(" \u2014 "),sR=a("a"),Ceo=o("PerceiverFeatureExtractor"),Meo=o(" (Perceiver model)"),Eeo=l(),uh=a("li"),fY=a("strong"),yeo=o("poolformer"),weo=o(" \u2014 "),lR=a("a"),Aeo=o("PoolFormerFeatureExtractor"),Leo=o(" (PoolFormer model)"),Beo=l(),bh=a("li"),mY=a("strong"),xeo=o("resnet"),keo=o(" \u2014 "),iR=a("a"),Reo=o("ConvNextFeatureExtractor"),Seo=o(" (ResNet model)"),Peo=l(),vh=a("li"),gY=a("strong"),$eo=o("segformer"),Ieo=o(" \u2014 "),dR=a("a"),jeo=o("SegformerFeatureExtractor"),Deo=o(" (SegFormer model)"),Neo=l(),Th=a("li"),hY=a("strong"),qeo=o("speech_to_text"),Oeo=o(" \u2014 "),cR=a("a"),Geo=o("Speech2TextFeatureExtractor"),Xeo=o(" (Speech2Text model)"),Veo=l(),Fh=a("li"),pY=a("strong"),zeo=o("swin"),Weo=o(" \u2014 "),fR=a("a"),Qeo=o("ViTFeatureExtractor"),Heo=o(" (Swin model)"),Ueo=l(),Ch=a("li"),_Y=a("strong"),Jeo=o("vit"),Yeo=o(" \u2014 "),mR=a("a"),Keo=o("ViTFeatureExtractor"),Zeo=o(" (ViT model)"),eoo=l(),Mh=a("li"),uY=a("strong"),ooo=o("vit_mae"),roo=o(" \u2014 "),gR=a("a"),too=o("ViTFeatureExtractor"),aoo=o(" (ViTMAE model)"),noo=l(),Eh=a("li"),bY=a("strong"),soo=o("wav2vec2"),loo=o(" \u2014 "),hR=a("a"),ioo=o("Wav2Vec2FeatureExtractor"),doo=o(" (Wav2Vec2 model)"),coo=l(),f(yh.$$.fragment),foo=l(),vY=a("p"),moo=o("Examples:"),goo=l(),f(TE.$$.fragment),hoo=l(),wh=a("div"),f(FE.$$.fragment),poo=l(),TY=a("p"),_oo=o("Register a new feature extractor for this class."),yxe=l(),Hi=a("h2"),Ah=a("a"),FY=a("span"),f(CE.$$.fragment),uoo=l(),CY=a("span"),boo=o("AutoProcessor"),wxe=l(),Uo=a("div"),f(ME.$$.fragment),voo=l(),EE=a("p"),Too=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),pR=a("a"),Foo=o("AutoProcessor.from_pretrained()"),Coo=o(" class method."),Moo=l(),yE=a("p"),Eoo=o("This class cannot be instantiated directly using "),MY=a("code"),yoo=o("__init__()"),woo=o(" (throws an error)."),Aoo=l(),je=a("div"),f(wE.$$.fragment),Loo=l(),EY=a("p"),Boo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),xoo=l(),Ui=a("p"),koo=o("The processor class to instantiate is selected based on the "),yY=a("code"),Roo=o("model_type"),Soo=o(` property of the config object (either
passed as an argument or loaded from `),wY=a("code"),Poo=o("pretrained_model_name_or_path"),$oo=o(" if possible):"),Ioo=l(),xe=a("ul"),Lh=a("li"),AY=a("strong"),joo=o("clip"),Doo=o(" \u2014 "),_R=a("a"),Noo=o("CLIPProcessor"),qoo=o(" (CLIP model)"),Ooo=l(),Bh=a("li"),LY=a("strong"),Goo=o("layoutlmv2"),Xoo=o(" \u2014 "),uR=a("a"),Voo=o("LayoutLMv2Processor"),zoo=o(" (LayoutLMv2 model)"),Woo=l(),xh=a("li"),BY=a("strong"),Qoo=o("layoutxlm"),Hoo=o(" \u2014 "),bR=a("a"),Uoo=o("LayoutXLMProcessor"),Joo=o(" (LayoutXLM model)"),Yoo=l(),kh=a("li"),xY=a("strong"),Koo=o("speech_to_text"),Zoo=o(" \u2014 "),vR=a("a"),ero=o("Speech2TextProcessor"),oro=o(" (Speech2Text model)"),rro=l(),Rh=a("li"),kY=a("strong"),tro=o("speech_to_text_2"),aro=o(" \u2014 "),TR=a("a"),nro=o("Speech2Text2Processor"),sro=o(" (Speech2Text2 model)"),lro=l(),Sh=a("li"),RY=a("strong"),iro=o("trocr"),dro=o(" \u2014 "),FR=a("a"),cro=o("TrOCRProcessor"),fro=o(" (TrOCR model)"),mro=l(),Ph=a("li"),SY=a("strong"),gro=o("vision-text-dual-encoder"),hro=o(" \u2014 "),CR=a("a"),pro=o("VisionTextDualEncoderProcessor"),_ro=o(" (VisionTextDualEncoder model)"),uro=l(),$h=a("li"),PY=a("strong"),bro=o("wav2vec2"),vro=o(" \u2014 "),MR=a("a"),Tro=o("Wav2Vec2Processor"),Fro=o(" (Wav2Vec2 model)"),Cro=l(),f(Ih.$$.fragment),Mro=l(),$Y=a("p"),Ero=o("Examples:"),yro=l(),f(AE.$$.fragment),wro=l(),jh=a("div"),f(LE.$$.fragment),Aro=l(),IY=a("p"),Lro=o("Register a new processor for this class."),Axe=l(),Ji=a("h2"),Dh=a("a"),jY=a("span"),f(BE.$$.fragment),Bro=l(),DY=a("span"),xro=o("AutoModel"),Lxe=l(),Jo=a("div"),f(xE.$$.fragment),kro=l(),Yi=a("p"),Rro=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),NY=a("code"),Sro=o("from_pretrained()"),Pro=o("class method or the "),qY=a("code"),$ro=o("from_config()"),Iro=o(`class
method.`),jro=l(),kE=a("p"),Dro=o("This class cannot be instantiated directly using "),OY=a("code"),Nro=o("__init__()"),qro=o(" (throws an error)."),Oro=l(),Vr=a("div"),f(RE.$$.fragment),Gro=l(),GY=a("p"),Xro=o("Instantiates one of the base model classes of the library from a configuration."),Vro=l(),Ki=a("p"),zro=o(`Note:
Loading a model from its configuration file does `),XY=a("strong"),Wro=o("not"),Qro=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VY=a("code"),Hro=o("from_pretrained()"),Uro=o("to load the model weights."),Jro=l(),zY=a("p"),Yro=o("Examples:"),Kro=l(),f(SE.$$.fragment),Zro=l(),De=a("div"),f(PE.$$.fragment),eto=l(),WY=a("p"),oto=o("Instantiate one of the base model classes of the library from a pretrained model."),rto=l(),Xa=a("p"),tto=o("The model class to instantiate is selected based on the "),QY=a("code"),ato=o("model_type"),nto=o(` property of the config object (either
passed as an argument or loaded from `),HY=a("code"),sto=o("pretrained_model_name_or_path"),lto=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UY=a("code"),ito=o("pretrained_model_name_or_path"),dto=o(":"),cto=l(),F=a("ul"),Nh=a("li"),JY=a("strong"),fto=o("albert"),mto=o(" \u2014 "),ER=a("a"),gto=o("AlbertModel"),hto=o(" (ALBERT model)"),pto=l(),qh=a("li"),YY=a("strong"),_to=o("bart"),uto=o(" \u2014 "),yR=a("a"),bto=o("BartModel"),vto=o(" (BART model)"),Tto=l(),Oh=a("li"),KY=a("strong"),Fto=o("beit"),Cto=o(" \u2014 "),wR=a("a"),Mto=o("BeitModel"),Eto=o(" (BEiT model)"),yto=l(),Gh=a("li"),ZY=a("strong"),wto=o("bert"),Ato=o(" \u2014 "),AR=a("a"),Lto=o("BertModel"),Bto=o(" (BERT model)"),xto=l(),Xh=a("li"),eK=a("strong"),kto=o("bert-generation"),Rto=o(" \u2014 "),LR=a("a"),Sto=o("BertGenerationEncoder"),Pto=o(" (Bert Generation model)"),$to=l(),Vh=a("li"),oK=a("strong"),Ito=o("big_bird"),jto=o(" \u2014 "),BR=a("a"),Dto=o("BigBirdModel"),Nto=o(" (BigBird model)"),qto=l(),zh=a("li"),rK=a("strong"),Oto=o("bigbird_pegasus"),Gto=o(" \u2014 "),xR=a("a"),Xto=o("BigBirdPegasusModel"),Vto=o(" (BigBirdPegasus model)"),zto=l(),Wh=a("li"),tK=a("strong"),Wto=o("blenderbot"),Qto=o(" \u2014 "),kR=a("a"),Hto=o("BlenderbotModel"),Uto=o(" (Blenderbot model)"),Jto=l(),Qh=a("li"),aK=a("strong"),Yto=o("blenderbot-small"),Kto=o(" \u2014 "),RR=a("a"),Zto=o("BlenderbotSmallModel"),eao=o(" (BlenderbotSmall model)"),oao=l(),Hh=a("li"),nK=a("strong"),rao=o("camembert"),tao=o(" \u2014 "),SR=a("a"),aao=o("CamembertModel"),nao=o(" (CamemBERT model)"),sao=l(),Uh=a("li"),sK=a("strong"),lao=o("canine"),iao=o(" \u2014 "),PR=a("a"),dao=o("CanineModel"),cao=o(" (Canine model)"),fao=l(),Jh=a("li"),lK=a("strong"),mao=o("clip"),gao=o(" \u2014 "),$R=a("a"),hao=o("CLIPModel"),pao=o(" (CLIP model)"),_ao=l(),Yh=a("li"),iK=a("strong"),uao=o("convbert"),bao=o(" \u2014 "),IR=a("a"),vao=o("ConvBertModel"),Tao=o(" (ConvBERT model)"),Fao=l(),Kh=a("li"),dK=a("strong"),Cao=o("convnext"),Mao=o(" \u2014 "),jR=a("a"),Eao=o("ConvNextModel"),yao=o(" (ConvNext model)"),wao=l(),Zh=a("li"),cK=a("strong"),Aao=o("ctrl"),Lao=o(" \u2014 "),DR=a("a"),Bao=o("CTRLModel"),xao=o(" (CTRL model)"),kao=l(),ep=a("li"),fK=a("strong"),Rao=o("data2vec-audio"),Sao=o(" \u2014 "),NR=a("a"),Pao=o("Data2VecAudioModel"),$ao=o(" (Data2VecAudio model)"),Iao=l(),op=a("li"),mK=a("strong"),jao=o("data2vec-text"),Dao=o(" \u2014 "),qR=a("a"),Nao=o("Data2VecTextModel"),qao=o(" (Data2VecText model)"),Oao=l(),rp=a("li"),gK=a("strong"),Gao=o("deberta"),Xao=o(" \u2014 "),OR=a("a"),Vao=o("DebertaModel"),zao=o(" (DeBERTa model)"),Wao=l(),tp=a("li"),hK=a("strong"),Qao=o("deberta-v2"),Hao=o(" \u2014 "),GR=a("a"),Uao=o("DebertaV2Model"),Jao=o(" (DeBERTa-v2 model)"),Yao=l(),ap=a("li"),pK=a("strong"),Kao=o("deit"),Zao=o(" \u2014 "),XR=a("a"),eno=o("DeiTModel"),ono=o(" (DeiT model)"),rno=l(),np=a("li"),_K=a("strong"),tno=o("detr"),ano=o(" \u2014 "),VR=a("a"),nno=o("DetrModel"),sno=o(" (DETR model)"),lno=l(),sp=a("li"),uK=a("strong"),ino=o("distilbert"),dno=o(" \u2014 "),zR=a("a"),cno=o("DistilBertModel"),fno=o(" (DistilBERT model)"),mno=l(),lp=a("li"),bK=a("strong"),gno=o("dpr"),hno=o(" \u2014 "),WR=a("a"),pno=o("DPRQuestionEncoder"),_no=o(" (DPR model)"),uno=l(),ip=a("li"),vK=a("strong"),bno=o("electra"),vno=o(" \u2014 "),QR=a("a"),Tno=o("ElectraModel"),Fno=o(" (ELECTRA model)"),Cno=l(),dp=a("li"),TK=a("strong"),Mno=o("flaubert"),Eno=o(" \u2014 "),HR=a("a"),yno=o("FlaubertModel"),wno=o(" (FlauBERT model)"),Ano=l(),cp=a("li"),FK=a("strong"),Lno=o("fnet"),Bno=o(" \u2014 "),UR=a("a"),xno=o("FNetModel"),kno=o(" (FNet model)"),Rno=l(),fp=a("li"),CK=a("strong"),Sno=o("fsmt"),Pno=o(" \u2014 "),JR=a("a"),$no=o("FSMTModel"),Ino=o(" (FairSeq Machine-Translation model)"),jno=l(),Ns=a("li"),MK=a("strong"),Dno=o("funnel"),Nno=o(" \u2014 "),YR=a("a"),qno=o("FunnelModel"),Ono=o(" or "),KR=a("a"),Gno=o("FunnelBaseModel"),Xno=o(" (Funnel Transformer model)"),Vno=l(),mp=a("li"),EK=a("strong"),zno=o("gpt2"),Wno=o(" \u2014 "),ZR=a("a"),Qno=o("GPT2Model"),Hno=o(" (OpenAI GPT-2 model)"),Uno=l(),gp=a("li"),yK=a("strong"),Jno=o("gpt_neo"),Yno=o(" \u2014 "),eS=a("a"),Kno=o("GPTNeoModel"),Zno=o(" (GPT Neo model)"),eso=l(),hp=a("li"),wK=a("strong"),oso=o("gptj"),rso=o(" \u2014 "),oS=a("a"),tso=o("GPTJModel"),aso=o(" (GPT-J model)"),nso=l(),pp=a("li"),AK=a("strong"),sso=o("hubert"),lso=o(" \u2014 "),rS=a("a"),iso=o("HubertModel"),dso=o(" (Hubert model)"),cso=l(),_p=a("li"),LK=a("strong"),fso=o("ibert"),mso=o(" \u2014 "),tS=a("a"),gso=o("IBertModel"),hso=o(" (I-BERT model)"),pso=l(),up=a("li"),BK=a("strong"),_so=o("imagegpt"),uso=o(" \u2014 "),aS=a("a"),bso=o("ImageGPTModel"),vso=o(" (ImageGPT model)"),Tso=l(),bp=a("li"),xK=a("strong"),Fso=o("layoutlm"),Cso=o(" \u2014 "),nS=a("a"),Mso=o("LayoutLMModel"),Eso=o(" (LayoutLM model)"),yso=l(),vp=a("li"),kK=a("strong"),wso=o("layoutlmv2"),Aso=o(" \u2014 "),sS=a("a"),Lso=o("LayoutLMv2Model"),Bso=o(" (LayoutLMv2 model)"),xso=l(),Tp=a("li"),RK=a("strong"),kso=o("led"),Rso=o(" \u2014 "),lS=a("a"),Sso=o("LEDModel"),Pso=o(" (LED model)"),$so=l(),Fp=a("li"),SK=a("strong"),Iso=o("longformer"),jso=o(" \u2014 "),iS=a("a"),Dso=o("LongformerModel"),Nso=o(" (Longformer model)"),qso=l(),Cp=a("li"),PK=a("strong"),Oso=o("luke"),Gso=o(" \u2014 "),dS=a("a"),Xso=o("LukeModel"),Vso=o(" (LUKE model)"),zso=l(),Mp=a("li"),$K=a("strong"),Wso=o("lxmert"),Qso=o(" \u2014 "),cS=a("a"),Hso=o("LxmertModel"),Uso=o(" (LXMERT model)"),Jso=l(),Ep=a("li"),IK=a("strong"),Yso=o("m2m_100"),Kso=o(" \u2014 "),fS=a("a"),Zso=o("M2M100Model"),elo=o(" (M2M100 model)"),olo=l(),yp=a("li"),jK=a("strong"),rlo=o("marian"),tlo=o(" \u2014 "),mS=a("a"),alo=o("MarianModel"),nlo=o(" (Marian model)"),slo=l(),wp=a("li"),DK=a("strong"),llo=o("maskformer"),ilo=o(" \u2014 "),gS=a("a"),dlo=o("MaskFormerModel"),clo=o(" (MaskFormer model)"),flo=l(),Ap=a("li"),NK=a("strong"),mlo=o("mbart"),glo=o(" \u2014 "),hS=a("a"),hlo=o("MBartModel"),plo=o(" (mBART model)"),_lo=l(),Lp=a("li"),qK=a("strong"),ulo=o("megatron-bert"),blo=o(" \u2014 "),pS=a("a"),vlo=o("MegatronBertModel"),Tlo=o(" (MegatronBert model)"),Flo=l(),Bp=a("li"),OK=a("strong"),Clo=o("mobilebert"),Mlo=o(" \u2014 "),_S=a("a"),Elo=o("MobileBertModel"),ylo=o(" (MobileBERT model)"),wlo=l(),xp=a("li"),GK=a("strong"),Alo=o("mpnet"),Llo=o(" \u2014 "),uS=a("a"),Blo=o("MPNetModel"),xlo=o(" (MPNet model)"),klo=l(),kp=a("li"),XK=a("strong"),Rlo=o("mt5"),Slo=o(" \u2014 "),bS=a("a"),Plo=o("MT5Model"),$lo=o(" (mT5 model)"),Ilo=l(),Rp=a("li"),VK=a("strong"),jlo=o("nystromformer"),Dlo=o(" \u2014 "),vS=a("a"),Nlo=o("NystromformerModel"),qlo=o(" (Nystromformer model)"),Olo=l(),Sp=a("li"),zK=a("strong"),Glo=o("openai-gpt"),Xlo=o(" \u2014 "),TS=a("a"),Vlo=o("OpenAIGPTModel"),zlo=o(" (OpenAI GPT model)"),Wlo=l(),Pp=a("li"),WK=a("strong"),Qlo=o("pegasus"),Hlo=o(" \u2014 "),FS=a("a"),Ulo=o("PegasusModel"),Jlo=o(" (Pegasus model)"),Ylo=l(),$p=a("li"),QK=a("strong"),Klo=o("perceiver"),Zlo=o(" \u2014 "),CS=a("a"),eio=o("PerceiverModel"),oio=o(" (Perceiver model)"),rio=l(),Ip=a("li"),HK=a("strong"),tio=o("plbart"),aio=o(" \u2014 "),MS=a("a"),nio=o("PLBartModel"),sio=o(" (PLBart model)"),lio=l(),jp=a("li"),UK=a("strong"),iio=o("poolformer"),dio=o(" \u2014 "),ES=a("a"),cio=o("PoolFormerModel"),fio=o(" (PoolFormer model)"),mio=l(),Dp=a("li"),JK=a("strong"),gio=o("prophetnet"),hio=o(" \u2014 "),yS=a("a"),pio=o("ProphetNetModel"),_io=o(" (ProphetNet model)"),uio=l(),Np=a("li"),YK=a("strong"),bio=o("qdqbert"),vio=o(" \u2014 "),wS=a("a"),Tio=o("QDQBertModel"),Fio=o(" (QDQBert model)"),Cio=l(),qp=a("li"),KK=a("strong"),Mio=o("reformer"),Eio=o(" \u2014 "),AS=a("a"),yio=o("ReformerModel"),wio=o(" (Reformer model)"),Aio=l(),Op=a("li"),ZK=a("strong"),Lio=o("rembert"),Bio=o(" \u2014 "),LS=a("a"),xio=o("RemBertModel"),kio=o(" (RemBERT model)"),Rio=l(),Gp=a("li"),eZ=a("strong"),Sio=o("resnet"),Pio=o(" \u2014 "),BS=a("a"),$io=o("ResNetModel"),Iio=o(" (ResNet model)"),jio=l(),Xp=a("li"),oZ=a("strong"),Dio=o("retribert"),Nio=o(" \u2014 "),xS=a("a"),qio=o("RetriBertModel"),Oio=o(" (RetriBERT model)"),Gio=l(),Vp=a("li"),rZ=a("strong"),Xio=o("roberta"),Vio=o(" \u2014 "),kS=a("a"),zio=o("RobertaModel"),Wio=o(" (RoBERTa model)"),Qio=l(),zp=a("li"),tZ=a("strong"),Hio=o("roformer"),Uio=o(" \u2014 "),RS=a("a"),Jio=o("RoFormerModel"),Yio=o(" (RoFormer model)"),Kio=l(),Wp=a("li"),aZ=a("strong"),Zio=o("segformer"),edo=o(" \u2014 "),SS=a("a"),odo=o("SegformerModel"),rdo=o(" (SegFormer model)"),tdo=l(),Qp=a("li"),nZ=a("strong"),ado=o("sew"),ndo=o(" \u2014 "),PS=a("a"),sdo=o("SEWModel"),ldo=o(" (SEW model)"),ido=l(),Hp=a("li"),sZ=a("strong"),ddo=o("sew-d"),cdo=o(" \u2014 "),$S=a("a"),fdo=o("SEWDModel"),mdo=o(" (SEW-D model)"),gdo=l(),Up=a("li"),lZ=a("strong"),hdo=o("speech_to_text"),pdo=o(" \u2014 "),IS=a("a"),_do=o("Speech2TextModel"),udo=o(" (Speech2Text model)"),bdo=l(),Jp=a("li"),iZ=a("strong"),vdo=o("splinter"),Tdo=o(" \u2014 "),jS=a("a"),Fdo=o("SplinterModel"),Cdo=o(" (Splinter model)"),Mdo=l(),Yp=a("li"),dZ=a("strong"),Edo=o("squeezebert"),ydo=o(" \u2014 "),DS=a("a"),wdo=o("SqueezeBertModel"),Ado=o(" (SqueezeBERT model)"),Ldo=l(),Kp=a("li"),cZ=a("strong"),Bdo=o("swin"),xdo=o(" \u2014 "),NS=a("a"),kdo=o("SwinModel"),Rdo=o(" (Swin model)"),Sdo=l(),Zp=a("li"),fZ=a("strong"),Pdo=o("t5"),$do=o(" \u2014 "),qS=a("a"),Ido=o("T5Model"),jdo=o(" (T5 model)"),Ddo=l(),e_=a("li"),mZ=a("strong"),Ndo=o("tapas"),qdo=o(" \u2014 "),OS=a("a"),Odo=o("TapasModel"),Gdo=o(" (TAPAS model)"),Xdo=l(),o_=a("li"),gZ=a("strong"),Vdo=o("transfo-xl"),zdo=o(" \u2014 "),GS=a("a"),Wdo=o("TransfoXLModel"),Qdo=o(" (Transformer-XL model)"),Hdo=l(),r_=a("li"),hZ=a("strong"),Udo=o("unispeech"),Jdo=o(" \u2014 "),XS=a("a"),Ydo=o("UniSpeechModel"),Kdo=o(" (UniSpeech model)"),Zdo=l(),t_=a("li"),pZ=a("strong"),eco=o("unispeech-sat"),oco=o(" \u2014 "),VS=a("a"),rco=o("UniSpeechSatModel"),tco=o(" (UniSpeechSat model)"),aco=l(),a_=a("li"),_Z=a("strong"),nco=o("vilt"),sco=o(" \u2014 "),zS=a("a"),lco=o("ViltModel"),ico=o(" (ViLT model)"),dco=l(),n_=a("li"),uZ=a("strong"),cco=o("vision-text-dual-encoder"),fco=o(" \u2014 "),WS=a("a"),mco=o("VisionTextDualEncoderModel"),gco=o(" (VisionTextDualEncoder model)"),hco=l(),s_=a("li"),bZ=a("strong"),pco=o("visual_bert"),_co=o(" \u2014 "),QS=a("a"),uco=o("VisualBertModel"),bco=o(" (VisualBert model)"),vco=l(),l_=a("li"),vZ=a("strong"),Tco=o("vit"),Fco=o(" \u2014 "),HS=a("a"),Cco=o("ViTModel"),Mco=o(" (ViT model)"),Eco=l(),i_=a("li"),TZ=a("strong"),yco=o("vit_mae"),wco=o(" \u2014 "),US=a("a"),Aco=o("ViTMAEModel"),Lco=o(" (ViTMAE model)"),Bco=l(),d_=a("li"),FZ=a("strong"),xco=o("wav2vec2"),kco=o(" \u2014 "),JS=a("a"),Rco=o("Wav2Vec2Model"),Sco=o(" (Wav2Vec2 model)"),Pco=l(),c_=a("li"),CZ=a("strong"),$co=o("wavlm"),Ico=o(" \u2014 "),YS=a("a"),jco=o("WavLMModel"),Dco=o(" (WavLM model)"),Nco=l(),f_=a("li"),MZ=a("strong"),qco=o("xglm"),Oco=o(" \u2014 "),KS=a("a"),Gco=o("XGLMModel"),Xco=o(" (XGLM model)"),Vco=l(),m_=a("li"),EZ=a("strong"),zco=o("xlm"),Wco=o(" \u2014 "),ZS=a("a"),Qco=o("XLMModel"),Hco=o(" (XLM model)"),Uco=l(),g_=a("li"),yZ=a("strong"),Jco=o("xlm-prophetnet"),Yco=o(" \u2014 "),eP=a("a"),Kco=o("XLMProphetNetModel"),Zco=o(" (XLMProphetNet model)"),efo=l(),h_=a("li"),wZ=a("strong"),ofo=o("xlm-roberta"),rfo=o(" \u2014 "),oP=a("a"),tfo=o("XLMRobertaModel"),afo=o(" (XLM-RoBERTa model)"),nfo=l(),p_=a("li"),AZ=a("strong"),sfo=o("xlm-roberta-xl"),lfo=o(" \u2014 "),rP=a("a"),ifo=o("XLMRobertaXLModel"),dfo=o(" (XLM-RoBERTa-XL model)"),cfo=l(),__=a("li"),LZ=a("strong"),ffo=o("xlnet"),mfo=o(" \u2014 "),tP=a("a"),gfo=o("XLNetModel"),hfo=o(" (XLNet model)"),pfo=l(),u_=a("li"),BZ=a("strong"),_fo=o("yoso"),ufo=o(" \u2014 "),aP=a("a"),bfo=o("YosoModel"),vfo=o(" (YOSO model)"),Tfo=l(),b_=a("p"),Ffo=o("The model is set in evaluation mode by default using "),xZ=a("code"),Cfo=o("model.eval()"),Mfo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kZ=a("code"),Efo=o("model.train()"),yfo=l(),RZ=a("p"),wfo=o("Examples:"),Afo=l(),f($E.$$.fragment),Bxe=l(),Zi=a("h2"),v_=a("a"),SZ=a("span"),f(IE.$$.fragment),Lfo=l(),PZ=a("span"),Bfo=o("AutoModelForPreTraining"),xxe=l(),Yo=a("div"),f(jE.$$.fragment),xfo=l(),ed=a("p"),kfo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),$Z=a("code"),Rfo=o("from_pretrained()"),Sfo=o("class method or the "),IZ=a("code"),Pfo=o("from_config()"),$fo=o(`class
method.`),Ifo=l(),DE=a("p"),jfo=o("This class cannot be instantiated directly using "),jZ=a("code"),Dfo=o("__init__()"),Nfo=o(" (throws an error)."),qfo=l(),zr=a("div"),f(NE.$$.fragment),Ofo=l(),DZ=a("p"),Gfo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Xfo=l(),od=a("p"),Vfo=o(`Note:
Loading a model from its configuration file does `),NZ=a("strong"),zfo=o("not"),Wfo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qZ=a("code"),Qfo=o("from_pretrained()"),Hfo=o("to load the model weights."),Ufo=l(),OZ=a("p"),Jfo=o("Examples:"),Yfo=l(),f(qE.$$.fragment),Kfo=l(),Ne=a("div"),f(OE.$$.fragment),Zfo=l(),GZ=a("p"),emo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),omo=l(),Va=a("p"),rmo=o("The model class to instantiate is selected based on the "),XZ=a("code"),tmo=o("model_type"),amo=o(` property of the config object (either
passed as an argument or loaded from `),VZ=a("code"),nmo=o("pretrained_model_name_or_path"),smo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zZ=a("code"),lmo=o("pretrained_model_name_or_path"),imo=o(":"),dmo=l(),k=a("ul"),T_=a("li"),WZ=a("strong"),cmo=o("albert"),fmo=o(" \u2014 "),nP=a("a"),mmo=o("AlbertForPreTraining"),gmo=o(" (ALBERT model)"),hmo=l(),F_=a("li"),QZ=a("strong"),pmo=o("bart"),_mo=o(" \u2014 "),sP=a("a"),umo=o("BartForConditionalGeneration"),bmo=o(" (BART model)"),vmo=l(),C_=a("li"),HZ=a("strong"),Tmo=o("bert"),Fmo=o(" \u2014 "),lP=a("a"),Cmo=o("BertForPreTraining"),Mmo=o(" (BERT model)"),Emo=l(),M_=a("li"),UZ=a("strong"),ymo=o("big_bird"),wmo=o(" \u2014 "),iP=a("a"),Amo=o("BigBirdForPreTraining"),Lmo=o(" (BigBird model)"),Bmo=l(),E_=a("li"),JZ=a("strong"),xmo=o("camembert"),kmo=o(" \u2014 "),dP=a("a"),Rmo=o("CamembertForMaskedLM"),Smo=o(" (CamemBERT model)"),Pmo=l(),y_=a("li"),YZ=a("strong"),$mo=o("ctrl"),Imo=o(" \u2014 "),cP=a("a"),jmo=o("CTRLLMHeadModel"),Dmo=o(" (CTRL model)"),Nmo=l(),w_=a("li"),KZ=a("strong"),qmo=o("data2vec-text"),Omo=o(" \u2014 "),fP=a("a"),Gmo=o("Data2VecTextForMaskedLM"),Xmo=o(" (Data2VecText model)"),Vmo=l(),A_=a("li"),ZZ=a("strong"),zmo=o("deberta"),Wmo=o(" \u2014 "),mP=a("a"),Qmo=o("DebertaForMaskedLM"),Hmo=o(" (DeBERTa model)"),Umo=l(),L_=a("li"),eee=a("strong"),Jmo=o("deberta-v2"),Ymo=o(" \u2014 "),gP=a("a"),Kmo=o("DebertaV2ForMaskedLM"),Zmo=o(" (DeBERTa-v2 model)"),ego=l(),B_=a("li"),oee=a("strong"),ogo=o("distilbert"),rgo=o(" \u2014 "),hP=a("a"),tgo=o("DistilBertForMaskedLM"),ago=o(" (DistilBERT model)"),ngo=l(),x_=a("li"),ree=a("strong"),sgo=o("electra"),lgo=o(" \u2014 "),pP=a("a"),igo=o("ElectraForPreTraining"),dgo=o(" (ELECTRA model)"),cgo=l(),k_=a("li"),tee=a("strong"),fgo=o("flaubert"),mgo=o(" \u2014 "),_P=a("a"),ggo=o("FlaubertWithLMHeadModel"),hgo=o(" (FlauBERT model)"),pgo=l(),R_=a("li"),aee=a("strong"),_go=o("fnet"),ugo=o(" \u2014 "),uP=a("a"),bgo=o("FNetForPreTraining"),vgo=o(" (FNet model)"),Tgo=l(),S_=a("li"),nee=a("strong"),Fgo=o("fsmt"),Cgo=o(" \u2014 "),bP=a("a"),Mgo=o("FSMTForConditionalGeneration"),Ego=o(" (FairSeq Machine-Translation model)"),ygo=l(),P_=a("li"),see=a("strong"),wgo=o("funnel"),Ago=o(" \u2014 "),vP=a("a"),Lgo=o("FunnelForPreTraining"),Bgo=o(" (Funnel Transformer model)"),xgo=l(),$_=a("li"),lee=a("strong"),kgo=o("gpt2"),Rgo=o(" \u2014 "),TP=a("a"),Sgo=o("GPT2LMHeadModel"),Pgo=o(" (OpenAI GPT-2 model)"),$go=l(),I_=a("li"),iee=a("strong"),Igo=o("ibert"),jgo=o(" \u2014 "),FP=a("a"),Dgo=o("IBertForMaskedLM"),Ngo=o(" (I-BERT model)"),qgo=l(),j_=a("li"),dee=a("strong"),Ogo=o("layoutlm"),Ggo=o(" \u2014 "),CP=a("a"),Xgo=o("LayoutLMForMaskedLM"),Vgo=o(" (LayoutLM model)"),zgo=l(),D_=a("li"),cee=a("strong"),Wgo=o("longformer"),Qgo=o(" \u2014 "),MP=a("a"),Hgo=o("LongformerForMaskedLM"),Ugo=o(" (Longformer model)"),Jgo=l(),N_=a("li"),fee=a("strong"),Ygo=o("lxmert"),Kgo=o(" \u2014 "),EP=a("a"),Zgo=o("LxmertForPreTraining"),eho=o(" (LXMERT model)"),oho=l(),q_=a("li"),mee=a("strong"),rho=o("megatron-bert"),tho=o(" \u2014 "),yP=a("a"),aho=o("MegatronBertForPreTraining"),nho=o(" (MegatronBert model)"),sho=l(),O_=a("li"),gee=a("strong"),lho=o("mobilebert"),iho=o(" \u2014 "),wP=a("a"),dho=o("MobileBertForPreTraining"),cho=o(" (MobileBERT model)"),fho=l(),G_=a("li"),hee=a("strong"),mho=o("mpnet"),gho=o(" \u2014 "),AP=a("a"),hho=o("MPNetForMaskedLM"),pho=o(" (MPNet model)"),_ho=l(),X_=a("li"),pee=a("strong"),uho=o("openai-gpt"),bho=o(" \u2014 "),LP=a("a"),vho=o("OpenAIGPTLMHeadModel"),Tho=o(" (OpenAI GPT model)"),Fho=l(),V_=a("li"),_ee=a("strong"),Cho=o("retribert"),Mho=o(" \u2014 "),BP=a("a"),Eho=o("RetriBertModel"),yho=o(" (RetriBERT model)"),who=l(),z_=a("li"),uee=a("strong"),Aho=o("roberta"),Lho=o(" \u2014 "),xP=a("a"),Bho=o("RobertaForMaskedLM"),xho=o(" (RoBERTa model)"),kho=l(),W_=a("li"),bee=a("strong"),Rho=o("squeezebert"),Sho=o(" \u2014 "),kP=a("a"),Pho=o("SqueezeBertForMaskedLM"),$ho=o(" (SqueezeBERT model)"),Iho=l(),Q_=a("li"),vee=a("strong"),jho=o("t5"),Dho=o(" \u2014 "),RP=a("a"),Nho=o("T5ForConditionalGeneration"),qho=o(" (T5 model)"),Oho=l(),H_=a("li"),Tee=a("strong"),Gho=o("tapas"),Xho=o(" \u2014 "),SP=a("a"),Vho=o("TapasForMaskedLM"),zho=o(" (TAPAS model)"),Who=l(),U_=a("li"),Fee=a("strong"),Qho=o("transfo-xl"),Hho=o(" \u2014 "),PP=a("a"),Uho=o("TransfoXLLMHeadModel"),Jho=o(" (Transformer-XL model)"),Yho=l(),J_=a("li"),Cee=a("strong"),Kho=o("unispeech"),Zho=o(" \u2014 "),$P=a("a"),epo=o("UniSpeechForPreTraining"),opo=o(" (UniSpeech model)"),rpo=l(),Y_=a("li"),Mee=a("strong"),tpo=o("unispeech-sat"),apo=o(" \u2014 "),IP=a("a"),npo=o("UniSpeechSatForPreTraining"),spo=o(" (UniSpeechSat model)"),lpo=l(),K_=a("li"),Eee=a("strong"),ipo=o("visual_bert"),dpo=o(" \u2014 "),jP=a("a"),cpo=o("VisualBertForPreTraining"),fpo=o(" (VisualBert model)"),mpo=l(),Z_=a("li"),yee=a("strong"),gpo=o("vit_mae"),hpo=o(" \u2014 "),DP=a("a"),ppo=o("ViTMAEForPreTraining"),_po=o(" (ViTMAE model)"),upo=l(),eu=a("li"),wee=a("strong"),bpo=o("wav2vec2"),vpo=o(" \u2014 "),NP=a("a"),Tpo=o("Wav2Vec2ForPreTraining"),Fpo=o(" (Wav2Vec2 model)"),Cpo=l(),ou=a("li"),Aee=a("strong"),Mpo=o("xlm"),Epo=o(" \u2014 "),qP=a("a"),ypo=o("XLMWithLMHeadModel"),wpo=o(" (XLM model)"),Apo=l(),ru=a("li"),Lee=a("strong"),Lpo=o("xlm-roberta"),Bpo=o(" \u2014 "),OP=a("a"),xpo=o("XLMRobertaForMaskedLM"),kpo=o(" (XLM-RoBERTa model)"),Rpo=l(),tu=a("li"),Bee=a("strong"),Spo=o("xlm-roberta-xl"),Ppo=o(" \u2014 "),GP=a("a"),$po=o("XLMRobertaXLForMaskedLM"),Ipo=o(" (XLM-RoBERTa-XL model)"),jpo=l(),au=a("li"),xee=a("strong"),Dpo=o("xlnet"),Npo=o(" \u2014 "),XP=a("a"),qpo=o("XLNetLMHeadModel"),Opo=o(" (XLNet model)"),Gpo=l(),nu=a("p"),Xpo=o("The model is set in evaluation mode by default using "),kee=a("code"),Vpo=o("model.eval()"),zpo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ree=a("code"),Wpo=o("model.train()"),Qpo=l(),See=a("p"),Hpo=o("Examples:"),Upo=l(),f(GE.$$.fragment),kxe=l(),rd=a("h2"),su=a("a"),Pee=a("span"),f(XE.$$.fragment),Jpo=l(),$ee=a("span"),Ypo=o("AutoModelForCausalLM"),Rxe=l(),Ko=a("div"),f(VE.$$.fragment),Kpo=l(),td=a("p"),Zpo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Iee=a("code"),e_o=o("from_pretrained()"),o_o=o("class method or the "),jee=a("code"),r_o=o("from_config()"),t_o=o(`class
method.`),a_o=l(),zE=a("p"),n_o=o("This class cannot be instantiated directly using "),Dee=a("code"),s_o=o("__init__()"),l_o=o(" (throws an error)."),i_o=l(),Wr=a("div"),f(WE.$$.fragment),d_o=l(),Nee=a("p"),c_o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),f_o=l(),ad=a("p"),m_o=o(`Note:
Loading a model from its configuration file does `),qee=a("strong"),g_o=o("not"),h_o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Oee=a("code"),p_o=o("from_pretrained()"),__o=o("to load the model weights."),u_o=l(),Gee=a("p"),b_o=o("Examples:"),v_o=l(),f(QE.$$.fragment),T_o=l(),qe=a("div"),f(HE.$$.fragment),F_o=l(),Xee=a("p"),C_o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),M_o=l(),za=a("p"),E_o=o("The model class to instantiate is selected based on the "),Vee=a("code"),y_o=o("model_type"),w_o=o(` property of the config object (either
passed as an argument or loaded from `),zee=a("code"),A_o=o("pretrained_model_name_or_path"),L_o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wee=a("code"),B_o=o("pretrained_model_name_or_path"),x_o=o(":"),k_o=l(),$=a("ul"),lu=a("li"),Qee=a("strong"),R_o=o("bart"),S_o=o(" \u2014 "),VP=a("a"),P_o=o("BartForCausalLM"),$_o=o(" (BART model)"),I_o=l(),iu=a("li"),Hee=a("strong"),j_o=o("bert"),D_o=o(" \u2014 "),zP=a("a"),N_o=o("BertLMHeadModel"),q_o=o(" (BERT model)"),O_o=l(),du=a("li"),Uee=a("strong"),G_o=o("bert-generation"),X_o=o(" \u2014 "),WP=a("a"),V_o=o("BertGenerationDecoder"),z_o=o(" (Bert Generation model)"),W_o=l(),cu=a("li"),Jee=a("strong"),Q_o=o("big_bird"),H_o=o(" \u2014 "),QP=a("a"),U_o=o("BigBirdForCausalLM"),J_o=o(" (BigBird model)"),Y_o=l(),fu=a("li"),Yee=a("strong"),K_o=o("bigbird_pegasus"),Z_o=o(" \u2014 "),HP=a("a"),euo=o("BigBirdPegasusForCausalLM"),ouo=o(" (BigBirdPegasus model)"),ruo=l(),mu=a("li"),Kee=a("strong"),tuo=o("blenderbot"),auo=o(" \u2014 "),UP=a("a"),nuo=o("BlenderbotForCausalLM"),suo=o(" (Blenderbot model)"),luo=l(),gu=a("li"),Zee=a("strong"),iuo=o("blenderbot-small"),duo=o(" \u2014 "),JP=a("a"),cuo=o("BlenderbotSmallForCausalLM"),fuo=o(" (BlenderbotSmall model)"),muo=l(),hu=a("li"),eoe=a("strong"),guo=o("camembert"),huo=o(" \u2014 "),YP=a("a"),puo=o("CamembertForCausalLM"),_uo=o(" (CamemBERT model)"),uuo=l(),pu=a("li"),ooe=a("strong"),buo=o("ctrl"),vuo=o(" \u2014 "),KP=a("a"),Tuo=o("CTRLLMHeadModel"),Fuo=o(" (CTRL model)"),Cuo=l(),_u=a("li"),roe=a("strong"),Muo=o("data2vec-text"),Euo=o(" \u2014 "),ZP=a("a"),yuo=o("Data2VecTextForCausalLM"),wuo=o(" (Data2VecText model)"),Auo=l(),uu=a("li"),toe=a("strong"),Luo=o("electra"),Buo=o(" \u2014 "),e$=a("a"),xuo=o("ElectraForCausalLM"),kuo=o(" (ELECTRA model)"),Ruo=l(),bu=a("li"),aoe=a("strong"),Suo=o("gpt2"),Puo=o(" \u2014 "),o$=a("a"),$uo=o("GPT2LMHeadModel"),Iuo=o(" (OpenAI GPT-2 model)"),juo=l(),vu=a("li"),noe=a("strong"),Duo=o("gpt_neo"),Nuo=o(" \u2014 "),r$=a("a"),quo=o("GPTNeoForCausalLM"),Ouo=o(" (GPT Neo model)"),Guo=l(),Tu=a("li"),soe=a("strong"),Xuo=o("gptj"),Vuo=o(" \u2014 "),t$=a("a"),zuo=o("GPTJForCausalLM"),Wuo=o(" (GPT-J model)"),Quo=l(),Fu=a("li"),loe=a("strong"),Huo=o("marian"),Uuo=o(" \u2014 "),a$=a("a"),Juo=o("MarianForCausalLM"),Yuo=o(" (Marian model)"),Kuo=l(),Cu=a("li"),ioe=a("strong"),Zuo=o("mbart"),e1o=o(" \u2014 "),n$=a("a"),o1o=o("MBartForCausalLM"),r1o=o(" (mBART model)"),t1o=l(),Mu=a("li"),doe=a("strong"),a1o=o("megatron-bert"),n1o=o(" \u2014 "),s$=a("a"),s1o=o("MegatronBertForCausalLM"),l1o=o(" (MegatronBert model)"),i1o=l(),Eu=a("li"),coe=a("strong"),d1o=o("openai-gpt"),c1o=o(" \u2014 "),l$=a("a"),f1o=o("OpenAIGPTLMHeadModel"),m1o=o(" (OpenAI GPT model)"),g1o=l(),yu=a("li"),foe=a("strong"),h1o=o("pegasus"),p1o=o(" \u2014 "),i$=a("a"),_1o=o("PegasusForCausalLM"),u1o=o(" (Pegasus model)"),b1o=l(),wu=a("li"),moe=a("strong"),v1o=o("plbart"),T1o=o(" \u2014 "),d$=a("a"),F1o=o("PLBartForCausalLM"),C1o=o(" (PLBart model)"),M1o=l(),Au=a("li"),goe=a("strong"),E1o=o("prophetnet"),y1o=o(" \u2014 "),c$=a("a"),w1o=o("ProphetNetForCausalLM"),A1o=o(" (ProphetNet model)"),L1o=l(),Lu=a("li"),hoe=a("strong"),B1o=o("qdqbert"),x1o=o(" \u2014 "),f$=a("a"),k1o=o("QDQBertLMHeadModel"),R1o=o(" (QDQBert model)"),S1o=l(),Bu=a("li"),poe=a("strong"),P1o=o("reformer"),$1o=o(" \u2014 "),m$=a("a"),I1o=o("ReformerModelWithLMHead"),j1o=o(" (Reformer model)"),D1o=l(),xu=a("li"),_oe=a("strong"),N1o=o("rembert"),q1o=o(" \u2014 "),g$=a("a"),O1o=o("RemBertForCausalLM"),G1o=o(" (RemBERT model)"),X1o=l(),ku=a("li"),uoe=a("strong"),V1o=o("roberta"),z1o=o(" \u2014 "),h$=a("a"),W1o=o("RobertaForCausalLM"),Q1o=o(" (RoBERTa model)"),H1o=l(),Ru=a("li"),boe=a("strong"),U1o=o("roformer"),J1o=o(" \u2014 "),p$=a("a"),Y1o=o("RoFormerForCausalLM"),K1o=o(" (RoFormer model)"),Z1o=l(),Su=a("li"),voe=a("strong"),e7o=o("speech_to_text_2"),o7o=o(" \u2014 "),_$=a("a"),r7o=o("Speech2Text2ForCausalLM"),t7o=o(" (Speech2Text2 model)"),a7o=l(),Pu=a("li"),Toe=a("strong"),n7o=o("transfo-xl"),s7o=o(" \u2014 "),u$=a("a"),l7o=o("TransfoXLLMHeadModel"),i7o=o(" (Transformer-XL model)"),d7o=l(),$u=a("li"),Foe=a("strong"),c7o=o("trocr"),f7o=o(" \u2014 "),b$=a("a"),m7o=o("TrOCRForCausalLM"),g7o=o(" (TrOCR model)"),h7o=l(),Iu=a("li"),Coe=a("strong"),p7o=o("xglm"),_7o=o(" \u2014 "),v$=a("a"),u7o=o("XGLMForCausalLM"),b7o=o(" (XGLM model)"),v7o=l(),ju=a("li"),Moe=a("strong"),T7o=o("xlm"),F7o=o(" \u2014 "),T$=a("a"),C7o=o("XLMWithLMHeadModel"),M7o=o(" (XLM model)"),E7o=l(),Du=a("li"),Eoe=a("strong"),y7o=o("xlm-prophetnet"),w7o=o(" \u2014 "),F$=a("a"),A7o=o("XLMProphetNetForCausalLM"),L7o=o(" (XLMProphetNet model)"),B7o=l(),Nu=a("li"),yoe=a("strong"),x7o=o("xlm-roberta"),k7o=o(" \u2014 "),C$=a("a"),R7o=o("XLMRobertaForCausalLM"),S7o=o(" (XLM-RoBERTa model)"),P7o=l(),qu=a("li"),woe=a("strong"),$7o=o("xlm-roberta-xl"),I7o=o(" \u2014 "),M$=a("a"),j7o=o("XLMRobertaXLForCausalLM"),D7o=o(" (XLM-RoBERTa-XL model)"),N7o=l(),Ou=a("li"),Aoe=a("strong"),q7o=o("xlnet"),O7o=o(" \u2014 "),E$=a("a"),G7o=o("XLNetLMHeadModel"),X7o=o(" (XLNet model)"),V7o=l(),Gu=a("p"),z7o=o("The model is set in evaluation mode by default using "),Loe=a("code"),W7o=o("model.eval()"),Q7o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Boe=a("code"),H7o=o("model.train()"),U7o=l(),xoe=a("p"),J7o=o("Examples:"),Y7o=l(),f(UE.$$.fragment),Sxe=l(),nd=a("h2"),Xu=a("a"),koe=a("span"),f(JE.$$.fragment),K7o=l(),Roe=a("span"),Z7o=o("AutoModelForMaskedLM"),Pxe=l(),Zo=a("div"),f(YE.$$.fragment),ebo=l(),sd=a("p"),obo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Soe=a("code"),rbo=o("from_pretrained()"),tbo=o("class method or the "),Poe=a("code"),abo=o("from_config()"),nbo=o(`class
method.`),sbo=l(),KE=a("p"),lbo=o("This class cannot be instantiated directly using "),$oe=a("code"),ibo=o("__init__()"),dbo=o(" (throws an error)."),cbo=l(),Qr=a("div"),f(ZE.$$.fragment),fbo=l(),Ioe=a("p"),mbo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),gbo=l(),ld=a("p"),hbo=o(`Note:
Loading a model from its configuration file does `),joe=a("strong"),pbo=o("not"),_bo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=a("code"),ubo=o("from_pretrained()"),bbo=o("to load the model weights."),vbo=l(),Noe=a("p"),Tbo=o("Examples:"),Fbo=l(),f(e3.$$.fragment),Cbo=l(),Oe=a("div"),f(o3.$$.fragment),Mbo=l(),qoe=a("p"),Ebo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ybo=l(),Wa=a("p"),wbo=o("The model class to instantiate is selected based on the "),Ooe=a("code"),Abo=o("model_type"),Lbo=o(` property of the config object (either
passed as an argument or loaded from `),Goe=a("code"),Bbo=o("pretrained_model_name_or_path"),xbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xoe=a("code"),kbo=o("pretrained_model_name_or_path"),Rbo=o(":"),Sbo=l(),I=a("ul"),Vu=a("li"),Voe=a("strong"),Pbo=o("albert"),$bo=o(" \u2014 "),y$=a("a"),Ibo=o("AlbertForMaskedLM"),jbo=o(" (ALBERT model)"),Dbo=l(),zu=a("li"),zoe=a("strong"),Nbo=o("bart"),qbo=o(" \u2014 "),w$=a("a"),Obo=o("BartForConditionalGeneration"),Gbo=o(" (BART model)"),Xbo=l(),Wu=a("li"),Woe=a("strong"),Vbo=o("bert"),zbo=o(" \u2014 "),A$=a("a"),Wbo=o("BertForMaskedLM"),Qbo=o(" (BERT model)"),Hbo=l(),Qu=a("li"),Qoe=a("strong"),Ubo=o("big_bird"),Jbo=o(" \u2014 "),L$=a("a"),Ybo=o("BigBirdForMaskedLM"),Kbo=o(" (BigBird model)"),Zbo=l(),Hu=a("li"),Hoe=a("strong"),e5o=o("camembert"),o5o=o(" \u2014 "),B$=a("a"),r5o=o("CamembertForMaskedLM"),t5o=o(" (CamemBERT model)"),a5o=l(),Uu=a("li"),Uoe=a("strong"),n5o=o("convbert"),s5o=o(" \u2014 "),x$=a("a"),l5o=o("ConvBertForMaskedLM"),i5o=o(" (ConvBERT model)"),d5o=l(),Ju=a("li"),Joe=a("strong"),c5o=o("data2vec-text"),f5o=o(" \u2014 "),k$=a("a"),m5o=o("Data2VecTextForMaskedLM"),g5o=o(" (Data2VecText model)"),h5o=l(),Yu=a("li"),Yoe=a("strong"),p5o=o("deberta"),_5o=o(" \u2014 "),R$=a("a"),u5o=o("DebertaForMaskedLM"),b5o=o(" (DeBERTa model)"),v5o=l(),Ku=a("li"),Koe=a("strong"),T5o=o("deberta-v2"),F5o=o(" \u2014 "),S$=a("a"),C5o=o("DebertaV2ForMaskedLM"),M5o=o(" (DeBERTa-v2 model)"),E5o=l(),Zu=a("li"),Zoe=a("strong"),y5o=o("distilbert"),w5o=o(" \u2014 "),P$=a("a"),A5o=o("DistilBertForMaskedLM"),L5o=o(" (DistilBERT model)"),B5o=l(),e1=a("li"),ere=a("strong"),x5o=o("electra"),k5o=o(" \u2014 "),$$=a("a"),R5o=o("ElectraForMaskedLM"),S5o=o(" (ELECTRA model)"),P5o=l(),o1=a("li"),ore=a("strong"),$5o=o("flaubert"),I5o=o(" \u2014 "),I$=a("a"),j5o=o("FlaubertWithLMHeadModel"),D5o=o(" (FlauBERT model)"),N5o=l(),r1=a("li"),rre=a("strong"),q5o=o("fnet"),O5o=o(" \u2014 "),j$=a("a"),G5o=o("FNetForMaskedLM"),X5o=o(" (FNet model)"),V5o=l(),t1=a("li"),tre=a("strong"),z5o=o("funnel"),W5o=o(" \u2014 "),D$=a("a"),Q5o=o("FunnelForMaskedLM"),H5o=o(" (Funnel Transformer model)"),U5o=l(),a1=a("li"),are=a("strong"),J5o=o("ibert"),Y5o=o(" \u2014 "),N$=a("a"),K5o=o("IBertForMaskedLM"),Z5o=o(" (I-BERT model)"),e2o=l(),n1=a("li"),nre=a("strong"),o2o=o("layoutlm"),r2o=o(" \u2014 "),q$=a("a"),t2o=o("LayoutLMForMaskedLM"),a2o=o(" (LayoutLM model)"),n2o=l(),s1=a("li"),sre=a("strong"),s2o=o("longformer"),l2o=o(" \u2014 "),O$=a("a"),i2o=o("LongformerForMaskedLM"),d2o=o(" (Longformer model)"),c2o=l(),l1=a("li"),lre=a("strong"),f2o=o("mbart"),m2o=o(" \u2014 "),G$=a("a"),g2o=o("MBartForConditionalGeneration"),h2o=o(" (mBART model)"),p2o=l(),i1=a("li"),ire=a("strong"),_2o=o("megatron-bert"),u2o=o(" \u2014 "),X$=a("a"),b2o=o("MegatronBertForMaskedLM"),v2o=o(" (MegatronBert model)"),T2o=l(),d1=a("li"),dre=a("strong"),F2o=o("mobilebert"),C2o=o(" \u2014 "),V$=a("a"),M2o=o("MobileBertForMaskedLM"),E2o=o(" (MobileBERT model)"),y2o=l(),c1=a("li"),cre=a("strong"),w2o=o("mpnet"),A2o=o(" \u2014 "),z$=a("a"),L2o=o("MPNetForMaskedLM"),B2o=o(" (MPNet model)"),x2o=l(),f1=a("li"),fre=a("strong"),k2o=o("nystromformer"),R2o=o(" \u2014 "),W$=a("a"),S2o=o("NystromformerForMaskedLM"),P2o=o(" (Nystromformer model)"),$2o=l(),m1=a("li"),mre=a("strong"),I2o=o("perceiver"),j2o=o(" \u2014 "),Q$=a("a"),D2o=o("PerceiverForMaskedLM"),N2o=o(" (Perceiver model)"),q2o=l(),g1=a("li"),gre=a("strong"),O2o=o("qdqbert"),G2o=o(" \u2014 "),H$=a("a"),X2o=o("QDQBertForMaskedLM"),V2o=o(" (QDQBert model)"),z2o=l(),h1=a("li"),hre=a("strong"),W2o=o("reformer"),Q2o=o(" \u2014 "),U$=a("a"),H2o=o("ReformerForMaskedLM"),U2o=o(" (Reformer model)"),J2o=l(),p1=a("li"),pre=a("strong"),Y2o=o("rembert"),K2o=o(" \u2014 "),J$=a("a"),Z2o=o("RemBertForMaskedLM"),evo=o(" (RemBERT model)"),ovo=l(),_1=a("li"),_re=a("strong"),rvo=o("roberta"),tvo=o(" \u2014 "),Y$=a("a"),avo=o("RobertaForMaskedLM"),nvo=o(" (RoBERTa model)"),svo=l(),u1=a("li"),ure=a("strong"),lvo=o("roformer"),ivo=o(" \u2014 "),K$=a("a"),dvo=o("RoFormerForMaskedLM"),cvo=o(" (RoFormer model)"),fvo=l(),b1=a("li"),bre=a("strong"),mvo=o("squeezebert"),gvo=o(" \u2014 "),Z$=a("a"),hvo=o("SqueezeBertForMaskedLM"),pvo=o(" (SqueezeBERT model)"),_vo=l(),v1=a("li"),vre=a("strong"),uvo=o("tapas"),bvo=o(" \u2014 "),eI=a("a"),vvo=o("TapasForMaskedLM"),Tvo=o(" (TAPAS model)"),Fvo=l(),T1=a("li"),Tre=a("strong"),Cvo=o("wav2vec2"),Mvo=o(" \u2014 "),Fre=a("code"),Evo=o("Wav2Vec2ForMaskedLM"),yvo=o("(Wav2Vec2 model)"),wvo=l(),F1=a("li"),Cre=a("strong"),Avo=o("xlm"),Lvo=o(" \u2014 "),oI=a("a"),Bvo=o("XLMWithLMHeadModel"),xvo=o(" (XLM model)"),kvo=l(),C1=a("li"),Mre=a("strong"),Rvo=o("xlm-roberta"),Svo=o(" \u2014 "),rI=a("a"),Pvo=o("XLMRobertaForMaskedLM"),$vo=o(" (XLM-RoBERTa model)"),Ivo=l(),M1=a("li"),Ere=a("strong"),jvo=o("xlm-roberta-xl"),Dvo=o(" \u2014 "),tI=a("a"),Nvo=o("XLMRobertaXLForMaskedLM"),qvo=o(" (XLM-RoBERTa-XL model)"),Ovo=l(),E1=a("li"),yre=a("strong"),Gvo=o("yoso"),Xvo=o(" \u2014 "),aI=a("a"),Vvo=o("YosoForMaskedLM"),zvo=o(" (YOSO model)"),Wvo=l(),y1=a("p"),Qvo=o("The model is set in evaluation mode by default using "),wre=a("code"),Hvo=o("model.eval()"),Uvo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Are=a("code"),Jvo=o("model.train()"),Yvo=l(),Lre=a("p"),Kvo=o("Examples:"),Zvo=l(),f(r3.$$.fragment),$xe=l(),id=a("h2"),w1=a("a"),Bre=a("span"),f(t3.$$.fragment),e0o=l(),xre=a("span"),o0o=o("AutoModelForSeq2SeqLM"),Ixe=l(),er=a("div"),f(a3.$$.fragment),r0o=l(),dd=a("p"),t0o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kre=a("code"),a0o=o("from_pretrained()"),n0o=o("class method or the "),Rre=a("code"),s0o=o("from_config()"),l0o=o(`class
method.`),i0o=l(),n3=a("p"),d0o=o("This class cannot be instantiated directly using "),Sre=a("code"),c0o=o("__init__()"),f0o=o(" (throws an error)."),m0o=l(),Hr=a("div"),f(s3.$$.fragment),g0o=l(),Pre=a("p"),h0o=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),p0o=l(),cd=a("p"),_0o=o(`Note:
Loading a model from its configuration file does `),$re=a("strong"),u0o=o("not"),b0o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ire=a("code"),v0o=o("from_pretrained()"),T0o=o("to load the model weights."),F0o=l(),jre=a("p"),C0o=o("Examples:"),M0o=l(),f(l3.$$.fragment),E0o=l(),Ge=a("div"),f(i3.$$.fragment),y0o=l(),Dre=a("p"),w0o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),A0o=l(),Qa=a("p"),L0o=o("The model class to instantiate is selected based on the "),Nre=a("code"),B0o=o("model_type"),x0o=o(` property of the config object (either
passed as an argument or loaded from `),qre=a("code"),k0o=o("pretrained_model_name_or_path"),R0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ore=a("code"),S0o=o("pretrained_model_name_or_path"),P0o=o(":"),$0o=l(),ne=a("ul"),A1=a("li"),Gre=a("strong"),I0o=o("bart"),j0o=o(" \u2014 "),nI=a("a"),D0o=o("BartForConditionalGeneration"),N0o=o(" (BART model)"),q0o=l(),L1=a("li"),Xre=a("strong"),O0o=o("bigbird_pegasus"),G0o=o(" \u2014 "),sI=a("a"),X0o=o("BigBirdPegasusForConditionalGeneration"),V0o=o(" (BigBirdPegasus model)"),z0o=l(),B1=a("li"),Vre=a("strong"),W0o=o("blenderbot"),Q0o=o(" \u2014 "),lI=a("a"),H0o=o("BlenderbotForConditionalGeneration"),U0o=o(" (Blenderbot model)"),J0o=l(),x1=a("li"),zre=a("strong"),Y0o=o("blenderbot-small"),K0o=o(" \u2014 "),iI=a("a"),Z0o=o("BlenderbotSmallForConditionalGeneration"),eTo=o(" (BlenderbotSmall model)"),oTo=l(),k1=a("li"),Wre=a("strong"),rTo=o("encoder-decoder"),tTo=o(" \u2014 "),dI=a("a"),aTo=o("EncoderDecoderModel"),nTo=o(" (Encoder decoder model)"),sTo=l(),R1=a("li"),Qre=a("strong"),lTo=o("fsmt"),iTo=o(" \u2014 "),cI=a("a"),dTo=o("FSMTForConditionalGeneration"),cTo=o(" (FairSeq Machine-Translation model)"),fTo=l(),S1=a("li"),Hre=a("strong"),mTo=o("led"),gTo=o(" \u2014 "),fI=a("a"),hTo=o("LEDForConditionalGeneration"),pTo=o(" (LED model)"),_To=l(),P1=a("li"),Ure=a("strong"),uTo=o("m2m_100"),bTo=o(" \u2014 "),mI=a("a"),vTo=o("M2M100ForConditionalGeneration"),TTo=o(" (M2M100 model)"),FTo=l(),$1=a("li"),Jre=a("strong"),CTo=o("marian"),MTo=o(" \u2014 "),gI=a("a"),ETo=o("MarianMTModel"),yTo=o(" (Marian model)"),wTo=l(),I1=a("li"),Yre=a("strong"),ATo=o("mbart"),LTo=o(" \u2014 "),hI=a("a"),BTo=o("MBartForConditionalGeneration"),xTo=o(" (mBART model)"),kTo=l(),j1=a("li"),Kre=a("strong"),RTo=o("mt5"),STo=o(" \u2014 "),pI=a("a"),PTo=o("MT5ForConditionalGeneration"),$To=o(" (mT5 model)"),ITo=l(),D1=a("li"),Zre=a("strong"),jTo=o("pegasus"),DTo=o(" \u2014 "),_I=a("a"),NTo=o("PegasusForConditionalGeneration"),qTo=o(" (Pegasus model)"),OTo=l(),N1=a("li"),ete=a("strong"),GTo=o("plbart"),XTo=o(" \u2014 "),uI=a("a"),VTo=o("PLBartForConditionalGeneration"),zTo=o(" (PLBart model)"),WTo=l(),q1=a("li"),ote=a("strong"),QTo=o("prophetnet"),HTo=o(" \u2014 "),bI=a("a"),UTo=o("ProphetNetForConditionalGeneration"),JTo=o(" (ProphetNet model)"),YTo=l(),O1=a("li"),rte=a("strong"),KTo=o("t5"),ZTo=o(" \u2014 "),vI=a("a"),eFo=o("T5ForConditionalGeneration"),oFo=o(" (T5 model)"),rFo=l(),G1=a("li"),tte=a("strong"),tFo=o("xlm-prophetnet"),aFo=o(" \u2014 "),TI=a("a"),nFo=o("XLMProphetNetForConditionalGeneration"),sFo=o(" (XLMProphetNet model)"),lFo=l(),X1=a("p"),iFo=o("The model is set in evaluation mode by default using "),ate=a("code"),dFo=o("model.eval()"),cFo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nte=a("code"),fFo=o("model.train()"),mFo=l(),ste=a("p"),gFo=o("Examples:"),hFo=l(),f(d3.$$.fragment),jxe=l(),fd=a("h2"),V1=a("a"),lte=a("span"),f(c3.$$.fragment),pFo=l(),ite=a("span"),_Fo=o("AutoModelForSequenceClassification"),Dxe=l(),or=a("div"),f(f3.$$.fragment),uFo=l(),md=a("p"),bFo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),dte=a("code"),vFo=o("from_pretrained()"),TFo=o("class method or the "),cte=a("code"),FFo=o("from_config()"),CFo=o(`class
method.`),MFo=l(),m3=a("p"),EFo=o("This class cannot be instantiated directly using "),fte=a("code"),yFo=o("__init__()"),wFo=o(" (throws an error)."),AFo=l(),Ur=a("div"),f(g3.$$.fragment),LFo=l(),mte=a("p"),BFo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),xFo=l(),gd=a("p"),kFo=o(`Note:
Loading a model from its configuration file does `),gte=a("strong"),RFo=o("not"),SFo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hte=a("code"),PFo=o("from_pretrained()"),$Fo=o("to load the model weights."),IFo=l(),pte=a("p"),jFo=o("Examples:"),DFo=l(),f(h3.$$.fragment),NFo=l(),Xe=a("div"),f(p3.$$.fragment),qFo=l(),_te=a("p"),OFo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),GFo=l(),Ha=a("p"),XFo=o("The model class to instantiate is selected based on the "),ute=a("code"),VFo=o("model_type"),zFo=o(` property of the config object (either
passed as an argument or loaded from `),bte=a("code"),WFo=o("pretrained_model_name_or_path"),QFo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vte=a("code"),HFo=o("pretrained_model_name_or_path"),UFo=o(":"),JFo=l(),A=a("ul"),z1=a("li"),Tte=a("strong"),YFo=o("albert"),KFo=o(" \u2014 "),FI=a("a"),ZFo=o("AlbertForSequenceClassification"),eCo=o(" (ALBERT model)"),oCo=l(),W1=a("li"),Fte=a("strong"),rCo=o("bart"),tCo=o(" \u2014 "),CI=a("a"),aCo=o("BartForSequenceClassification"),nCo=o(" (BART model)"),sCo=l(),Q1=a("li"),Cte=a("strong"),lCo=o("bert"),iCo=o(" \u2014 "),MI=a("a"),dCo=o("BertForSequenceClassification"),cCo=o(" (BERT model)"),fCo=l(),H1=a("li"),Mte=a("strong"),mCo=o("big_bird"),gCo=o(" \u2014 "),EI=a("a"),hCo=o("BigBirdForSequenceClassification"),pCo=o(" (BigBird model)"),_Co=l(),U1=a("li"),Ete=a("strong"),uCo=o("bigbird_pegasus"),bCo=o(" \u2014 "),yI=a("a"),vCo=o("BigBirdPegasusForSequenceClassification"),TCo=o(" (BigBirdPegasus model)"),FCo=l(),J1=a("li"),yte=a("strong"),CCo=o("camembert"),MCo=o(" \u2014 "),wI=a("a"),ECo=o("CamembertForSequenceClassification"),yCo=o(" (CamemBERT model)"),wCo=l(),Y1=a("li"),wte=a("strong"),ACo=o("canine"),LCo=o(" \u2014 "),AI=a("a"),BCo=o("CanineForSequenceClassification"),xCo=o(" (Canine model)"),kCo=l(),K1=a("li"),Ate=a("strong"),RCo=o("convbert"),SCo=o(" \u2014 "),LI=a("a"),PCo=o("ConvBertForSequenceClassification"),$Co=o(" (ConvBERT model)"),ICo=l(),Z1=a("li"),Lte=a("strong"),jCo=o("ctrl"),DCo=o(" \u2014 "),BI=a("a"),NCo=o("CTRLForSequenceClassification"),qCo=o(" (CTRL model)"),OCo=l(),e7=a("li"),Bte=a("strong"),GCo=o("data2vec-text"),XCo=o(" \u2014 "),xI=a("a"),VCo=o("Data2VecTextForSequenceClassification"),zCo=o(" (Data2VecText model)"),WCo=l(),o7=a("li"),xte=a("strong"),QCo=o("deberta"),HCo=o(" \u2014 "),kI=a("a"),UCo=o("DebertaForSequenceClassification"),JCo=o(" (DeBERTa model)"),YCo=l(),r7=a("li"),kte=a("strong"),KCo=o("deberta-v2"),ZCo=o(" \u2014 "),RI=a("a"),eMo=o("DebertaV2ForSequenceClassification"),oMo=o(" (DeBERTa-v2 model)"),rMo=l(),t7=a("li"),Rte=a("strong"),tMo=o("distilbert"),aMo=o(" \u2014 "),SI=a("a"),nMo=o("DistilBertForSequenceClassification"),sMo=o(" (DistilBERT model)"),lMo=l(),a7=a("li"),Ste=a("strong"),iMo=o("electra"),dMo=o(" \u2014 "),PI=a("a"),cMo=o("ElectraForSequenceClassification"),fMo=o(" (ELECTRA model)"),mMo=l(),n7=a("li"),Pte=a("strong"),gMo=o("flaubert"),hMo=o(" \u2014 "),$I=a("a"),pMo=o("FlaubertForSequenceClassification"),_Mo=o(" (FlauBERT model)"),uMo=l(),s7=a("li"),$te=a("strong"),bMo=o("fnet"),vMo=o(" \u2014 "),II=a("a"),TMo=o("FNetForSequenceClassification"),FMo=o(" (FNet model)"),CMo=l(),l7=a("li"),Ite=a("strong"),MMo=o("funnel"),EMo=o(" \u2014 "),jI=a("a"),yMo=o("FunnelForSequenceClassification"),wMo=o(" (Funnel Transformer model)"),AMo=l(),i7=a("li"),jte=a("strong"),LMo=o("gpt2"),BMo=o(" \u2014 "),DI=a("a"),xMo=o("GPT2ForSequenceClassification"),kMo=o(" (OpenAI GPT-2 model)"),RMo=l(),d7=a("li"),Dte=a("strong"),SMo=o("gpt_neo"),PMo=o(" \u2014 "),NI=a("a"),$Mo=o("GPTNeoForSequenceClassification"),IMo=o(" (GPT Neo model)"),jMo=l(),c7=a("li"),Nte=a("strong"),DMo=o("gptj"),NMo=o(" \u2014 "),qI=a("a"),qMo=o("GPTJForSequenceClassification"),OMo=o(" (GPT-J model)"),GMo=l(),f7=a("li"),qte=a("strong"),XMo=o("ibert"),VMo=o(" \u2014 "),OI=a("a"),zMo=o("IBertForSequenceClassification"),WMo=o(" (I-BERT model)"),QMo=l(),m7=a("li"),Ote=a("strong"),HMo=o("layoutlm"),UMo=o(" \u2014 "),GI=a("a"),JMo=o("LayoutLMForSequenceClassification"),YMo=o(" (LayoutLM model)"),KMo=l(),g7=a("li"),Gte=a("strong"),ZMo=o("layoutlmv2"),e4o=o(" \u2014 "),XI=a("a"),o4o=o("LayoutLMv2ForSequenceClassification"),r4o=o(" (LayoutLMv2 model)"),t4o=l(),h7=a("li"),Xte=a("strong"),a4o=o("led"),n4o=o(" \u2014 "),VI=a("a"),s4o=o("LEDForSequenceClassification"),l4o=o(" (LED model)"),i4o=l(),p7=a("li"),Vte=a("strong"),d4o=o("longformer"),c4o=o(" \u2014 "),zI=a("a"),f4o=o("LongformerForSequenceClassification"),m4o=o(" (Longformer model)"),g4o=l(),_7=a("li"),zte=a("strong"),h4o=o("mbart"),p4o=o(" \u2014 "),WI=a("a"),_4o=o("MBartForSequenceClassification"),u4o=o(" (mBART model)"),b4o=l(),u7=a("li"),Wte=a("strong"),v4o=o("megatron-bert"),T4o=o(" \u2014 "),QI=a("a"),F4o=o("MegatronBertForSequenceClassification"),C4o=o(" (MegatronBert model)"),M4o=l(),b7=a("li"),Qte=a("strong"),E4o=o("mobilebert"),y4o=o(" \u2014 "),HI=a("a"),w4o=o("MobileBertForSequenceClassification"),A4o=o(" (MobileBERT model)"),L4o=l(),v7=a("li"),Hte=a("strong"),B4o=o("mpnet"),x4o=o(" \u2014 "),UI=a("a"),k4o=o("MPNetForSequenceClassification"),R4o=o(" (MPNet model)"),S4o=l(),T7=a("li"),Ute=a("strong"),P4o=o("nystromformer"),$4o=o(" \u2014 "),JI=a("a"),I4o=o("NystromformerForSequenceClassification"),j4o=o(" (Nystromformer model)"),D4o=l(),F7=a("li"),Jte=a("strong"),N4o=o("openai-gpt"),q4o=o(" \u2014 "),YI=a("a"),O4o=o("OpenAIGPTForSequenceClassification"),G4o=o(" (OpenAI GPT model)"),X4o=l(),C7=a("li"),Yte=a("strong"),V4o=o("perceiver"),z4o=o(" \u2014 "),KI=a("a"),W4o=o("PerceiverForSequenceClassification"),Q4o=o(" (Perceiver model)"),H4o=l(),M7=a("li"),Kte=a("strong"),U4o=o("plbart"),J4o=o(" \u2014 "),ZI=a("a"),Y4o=o("PLBartForSequenceClassification"),K4o=o(" (PLBart model)"),Z4o=l(),E7=a("li"),Zte=a("strong"),eEo=o("qdqbert"),oEo=o(" \u2014 "),ej=a("a"),rEo=o("QDQBertForSequenceClassification"),tEo=o(" (QDQBert model)"),aEo=l(),y7=a("li"),eae=a("strong"),nEo=o("reformer"),sEo=o(" \u2014 "),oj=a("a"),lEo=o("ReformerForSequenceClassification"),iEo=o(" (Reformer model)"),dEo=l(),w7=a("li"),oae=a("strong"),cEo=o("rembert"),fEo=o(" \u2014 "),rj=a("a"),mEo=o("RemBertForSequenceClassification"),gEo=o(" (RemBERT model)"),hEo=l(),A7=a("li"),rae=a("strong"),pEo=o("roberta"),_Eo=o(" \u2014 "),tj=a("a"),uEo=o("RobertaForSequenceClassification"),bEo=o(" (RoBERTa model)"),vEo=l(),L7=a("li"),tae=a("strong"),TEo=o("roformer"),FEo=o(" \u2014 "),aj=a("a"),CEo=o("RoFormerForSequenceClassification"),MEo=o(" (RoFormer model)"),EEo=l(),B7=a("li"),aae=a("strong"),yEo=o("squeezebert"),wEo=o(" \u2014 "),nj=a("a"),AEo=o("SqueezeBertForSequenceClassification"),LEo=o(" (SqueezeBERT model)"),BEo=l(),x7=a("li"),nae=a("strong"),xEo=o("tapas"),kEo=o(" \u2014 "),sj=a("a"),REo=o("TapasForSequenceClassification"),SEo=o(" (TAPAS model)"),PEo=l(),k7=a("li"),sae=a("strong"),$Eo=o("transfo-xl"),IEo=o(" \u2014 "),lj=a("a"),jEo=o("TransfoXLForSequenceClassification"),DEo=o(" (Transformer-XL model)"),NEo=l(),R7=a("li"),lae=a("strong"),qEo=o("xlm"),OEo=o(" \u2014 "),ij=a("a"),GEo=o("XLMForSequenceClassification"),XEo=o(" (XLM model)"),VEo=l(),S7=a("li"),iae=a("strong"),zEo=o("xlm-roberta"),WEo=o(" \u2014 "),dj=a("a"),QEo=o("XLMRobertaForSequenceClassification"),HEo=o(" (XLM-RoBERTa model)"),UEo=l(),P7=a("li"),dae=a("strong"),JEo=o("xlm-roberta-xl"),YEo=o(" \u2014 "),cj=a("a"),KEo=o("XLMRobertaXLForSequenceClassification"),ZEo=o(" (XLM-RoBERTa-XL model)"),e3o=l(),$7=a("li"),cae=a("strong"),o3o=o("xlnet"),r3o=o(" \u2014 "),fj=a("a"),t3o=o("XLNetForSequenceClassification"),a3o=o(" (XLNet model)"),n3o=l(),I7=a("li"),fae=a("strong"),s3o=o("yoso"),l3o=o(" \u2014 "),mj=a("a"),i3o=o("YosoForSequenceClassification"),d3o=o(" (YOSO model)"),c3o=l(),j7=a("p"),f3o=o("The model is set in evaluation mode by default using "),mae=a("code"),m3o=o("model.eval()"),g3o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gae=a("code"),h3o=o("model.train()"),p3o=l(),hae=a("p"),_3o=o("Examples:"),u3o=l(),f(_3.$$.fragment),Nxe=l(),hd=a("h2"),D7=a("a"),pae=a("span"),f(u3.$$.fragment),b3o=l(),_ae=a("span"),v3o=o("AutoModelForMultipleChoice"),qxe=l(),rr=a("div"),f(b3.$$.fragment),T3o=l(),pd=a("p"),F3o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),uae=a("code"),C3o=o("from_pretrained()"),M3o=o("class method or the "),bae=a("code"),E3o=o("from_config()"),y3o=o(`class
method.`),w3o=l(),v3=a("p"),A3o=o("This class cannot be instantiated directly using "),vae=a("code"),L3o=o("__init__()"),B3o=o(" (throws an error)."),x3o=l(),Jr=a("div"),f(T3.$$.fragment),k3o=l(),Tae=a("p"),R3o=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),S3o=l(),_d=a("p"),P3o=o(`Note:
Loading a model from its configuration file does `),Fae=a("strong"),$3o=o("not"),I3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cae=a("code"),j3o=o("from_pretrained()"),D3o=o("to load the model weights."),N3o=l(),Mae=a("p"),q3o=o("Examples:"),O3o=l(),f(F3.$$.fragment),G3o=l(),Ve=a("div"),f(C3.$$.fragment),X3o=l(),Eae=a("p"),V3o=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),z3o=l(),Ua=a("p"),W3o=o("The model class to instantiate is selected based on the "),yae=a("code"),Q3o=o("model_type"),H3o=o(` property of the config object (either
passed as an argument or loaded from `),wae=a("code"),U3o=o("pretrained_model_name_or_path"),J3o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aae=a("code"),Y3o=o("pretrained_model_name_or_path"),K3o=o(":"),Z3o=l(),O=a("ul"),N7=a("li"),Lae=a("strong"),eyo=o("albert"),oyo=o(" \u2014 "),gj=a("a"),ryo=o("AlbertForMultipleChoice"),tyo=o(" (ALBERT model)"),ayo=l(),q7=a("li"),Bae=a("strong"),nyo=o("bert"),syo=o(" \u2014 "),hj=a("a"),lyo=o("BertForMultipleChoice"),iyo=o(" (BERT model)"),dyo=l(),O7=a("li"),xae=a("strong"),cyo=o("big_bird"),fyo=o(" \u2014 "),pj=a("a"),myo=o("BigBirdForMultipleChoice"),gyo=o(" (BigBird model)"),hyo=l(),G7=a("li"),kae=a("strong"),pyo=o("camembert"),_yo=o(" \u2014 "),_j=a("a"),uyo=o("CamembertForMultipleChoice"),byo=o(" (CamemBERT model)"),vyo=l(),X7=a("li"),Rae=a("strong"),Tyo=o("canine"),Fyo=o(" \u2014 "),uj=a("a"),Cyo=o("CanineForMultipleChoice"),Myo=o(" (Canine model)"),Eyo=l(),V7=a("li"),Sae=a("strong"),yyo=o("convbert"),wyo=o(" \u2014 "),bj=a("a"),Ayo=o("ConvBertForMultipleChoice"),Lyo=o(" (ConvBERT model)"),Byo=l(),z7=a("li"),Pae=a("strong"),xyo=o("data2vec-text"),kyo=o(" \u2014 "),vj=a("a"),Ryo=o("Data2VecTextForMultipleChoice"),Syo=o(" (Data2VecText model)"),Pyo=l(),W7=a("li"),$ae=a("strong"),$yo=o("distilbert"),Iyo=o(" \u2014 "),Tj=a("a"),jyo=o("DistilBertForMultipleChoice"),Dyo=o(" (DistilBERT model)"),Nyo=l(),Q7=a("li"),Iae=a("strong"),qyo=o("electra"),Oyo=o(" \u2014 "),Fj=a("a"),Gyo=o("ElectraForMultipleChoice"),Xyo=o(" (ELECTRA model)"),Vyo=l(),H7=a("li"),jae=a("strong"),zyo=o("flaubert"),Wyo=o(" \u2014 "),Cj=a("a"),Qyo=o("FlaubertForMultipleChoice"),Hyo=o(" (FlauBERT model)"),Uyo=l(),U7=a("li"),Dae=a("strong"),Jyo=o("fnet"),Yyo=o(" \u2014 "),Mj=a("a"),Kyo=o("FNetForMultipleChoice"),Zyo=o(" (FNet model)"),ewo=l(),J7=a("li"),Nae=a("strong"),owo=o("funnel"),rwo=o(" \u2014 "),Ej=a("a"),two=o("FunnelForMultipleChoice"),awo=o(" (Funnel Transformer model)"),nwo=l(),Y7=a("li"),qae=a("strong"),swo=o("ibert"),lwo=o(" \u2014 "),yj=a("a"),iwo=o("IBertForMultipleChoice"),dwo=o(" (I-BERT model)"),cwo=l(),K7=a("li"),Oae=a("strong"),fwo=o("longformer"),mwo=o(" \u2014 "),wj=a("a"),gwo=o("LongformerForMultipleChoice"),hwo=o(" (Longformer model)"),pwo=l(),Z7=a("li"),Gae=a("strong"),_wo=o("megatron-bert"),uwo=o(" \u2014 "),Aj=a("a"),bwo=o("MegatronBertForMultipleChoice"),vwo=o(" (MegatronBert model)"),Two=l(),eb=a("li"),Xae=a("strong"),Fwo=o("mobilebert"),Cwo=o(" \u2014 "),Lj=a("a"),Mwo=o("MobileBertForMultipleChoice"),Ewo=o(" (MobileBERT model)"),ywo=l(),ob=a("li"),Vae=a("strong"),wwo=o("mpnet"),Awo=o(" \u2014 "),Bj=a("a"),Lwo=o("MPNetForMultipleChoice"),Bwo=o(" (MPNet model)"),xwo=l(),rb=a("li"),zae=a("strong"),kwo=o("nystromformer"),Rwo=o(" \u2014 "),xj=a("a"),Swo=o("NystromformerForMultipleChoice"),Pwo=o(" (Nystromformer model)"),$wo=l(),tb=a("li"),Wae=a("strong"),Iwo=o("qdqbert"),jwo=o(" \u2014 "),kj=a("a"),Dwo=o("QDQBertForMultipleChoice"),Nwo=o(" (QDQBert model)"),qwo=l(),ab=a("li"),Qae=a("strong"),Owo=o("rembert"),Gwo=o(" \u2014 "),Rj=a("a"),Xwo=o("RemBertForMultipleChoice"),Vwo=o(" (RemBERT model)"),zwo=l(),nb=a("li"),Hae=a("strong"),Wwo=o("roberta"),Qwo=o(" \u2014 "),Sj=a("a"),Hwo=o("RobertaForMultipleChoice"),Uwo=o(" (RoBERTa model)"),Jwo=l(),sb=a("li"),Uae=a("strong"),Ywo=o("roformer"),Kwo=o(" \u2014 "),Pj=a("a"),Zwo=o("RoFormerForMultipleChoice"),e6o=o(" (RoFormer model)"),o6o=l(),lb=a("li"),Jae=a("strong"),r6o=o("squeezebert"),t6o=o(" \u2014 "),$j=a("a"),a6o=o("SqueezeBertForMultipleChoice"),n6o=o(" (SqueezeBERT model)"),s6o=l(),ib=a("li"),Yae=a("strong"),l6o=o("xlm"),i6o=o(" \u2014 "),Ij=a("a"),d6o=o("XLMForMultipleChoice"),c6o=o(" (XLM model)"),f6o=l(),db=a("li"),Kae=a("strong"),m6o=o("xlm-roberta"),g6o=o(" \u2014 "),jj=a("a"),h6o=o("XLMRobertaForMultipleChoice"),p6o=o(" (XLM-RoBERTa model)"),_6o=l(),cb=a("li"),Zae=a("strong"),u6o=o("xlm-roberta-xl"),b6o=o(" \u2014 "),Dj=a("a"),v6o=o("XLMRobertaXLForMultipleChoice"),T6o=o(" (XLM-RoBERTa-XL model)"),F6o=l(),fb=a("li"),ene=a("strong"),C6o=o("xlnet"),M6o=o(" \u2014 "),Nj=a("a"),E6o=o("XLNetForMultipleChoice"),y6o=o(" (XLNet model)"),w6o=l(),mb=a("li"),one=a("strong"),A6o=o("yoso"),L6o=o(" \u2014 "),qj=a("a"),B6o=o("YosoForMultipleChoice"),x6o=o(" (YOSO model)"),k6o=l(),gb=a("p"),R6o=o("The model is set in evaluation mode by default using "),rne=a("code"),S6o=o("model.eval()"),P6o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tne=a("code"),$6o=o("model.train()"),I6o=l(),ane=a("p"),j6o=o("Examples:"),D6o=l(),f(M3.$$.fragment),Oxe=l(),ud=a("h2"),hb=a("a"),nne=a("span"),f(E3.$$.fragment),N6o=l(),sne=a("span"),q6o=o("AutoModelForNextSentencePrediction"),Gxe=l(),tr=a("div"),f(y3.$$.fragment),O6o=l(),bd=a("p"),G6o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),lne=a("code"),X6o=o("from_pretrained()"),V6o=o("class method or the "),ine=a("code"),z6o=o("from_config()"),W6o=o(`class
method.`),Q6o=l(),w3=a("p"),H6o=o("This class cannot be instantiated directly using "),dne=a("code"),U6o=o("__init__()"),J6o=o(" (throws an error)."),Y6o=l(),Yr=a("div"),f(A3.$$.fragment),K6o=l(),cne=a("p"),Z6o=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),eAo=l(),vd=a("p"),oAo=o(`Note:
Loading a model from its configuration file does `),fne=a("strong"),rAo=o("not"),tAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mne=a("code"),aAo=o("from_pretrained()"),nAo=o("to load the model weights."),sAo=l(),gne=a("p"),lAo=o("Examples:"),iAo=l(),f(L3.$$.fragment),dAo=l(),ze=a("div"),f(B3.$$.fragment),cAo=l(),hne=a("p"),fAo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),mAo=l(),Ja=a("p"),gAo=o("The model class to instantiate is selected based on the "),pne=a("code"),hAo=o("model_type"),pAo=o(` property of the config object (either
passed as an argument or loaded from `),_ne=a("code"),_Ao=o("pretrained_model_name_or_path"),uAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),une=a("code"),bAo=o("pretrained_model_name_or_path"),vAo=o(":"),TAo=l(),da=a("ul"),pb=a("li"),bne=a("strong"),FAo=o("bert"),CAo=o(" \u2014 "),Oj=a("a"),MAo=o("BertForNextSentencePrediction"),EAo=o(" (BERT model)"),yAo=l(),_b=a("li"),vne=a("strong"),wAo=o("fnet"),AAo=o(" \u2014 "),Gj=a("a"),LAo=o("FNetForNextSentencePrediction"),BAo=o(" (FNet model)"),xAo=l(),ub=a("li"),Tne=a("strong"),kAo=o("megatron-bert"),RAo=o(" \u2014 "),Xj=a("a"),SAo=o("MegatronBertForNextSentencePrediction"),PAo=o(" (MegatronBert model)"),$Ao=l(),bb=a("li"),Fne=a("strong"),IAo=o("mobilebert"),jAo=o(" \u2014 "),Vj=a("a"),DAo=o("MobileBertForNextSentencePrediction"),NAo=o(" (MobileBERT model)"),qAo=l(),vb=a("li"),Cne=a("strong"),OAo=o("qdqbert"),GAo=o(" \u2014 "),zj=a("a"),XAo=o("QDQBertForNextSentencePrediction"),VAo=o(" (QDQBert model)"),zAo=l(),Tb=a("p"),WAo=o("The model is set in evaluation mode by default using "),Mne=a("code"),QAo=o("model.eval()"),HAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ene=a("code"),UAo=o("model.train()"),JAo=l(),yne=a("p"),YAo=o("Examples:"),KAo=l(),f(x3.$$.fragment),Xxe=l(),Td=a("h2"),Fb=a("a"),wne=a("span"),f(k3.$$.fragment),ZAo=l(),Ane=a("span"),eLo=o("AutoModelForTokenClassification"),Vxe=l(),ar=a("div"),f(R3.$$.fragment),oLo=l(),Fd=a("p"),rLo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Lne=a("code"),tLo=o("from_pretrained()"),aLo=o("class method or the "),Bne=a("code"),nLo=o("from_config()"),sLo=o(`class
method.`),lLo=l(),S3=a("p"),iLo=o("This class cannot be instantiated directly using "),xne=a("code"),dLo=o("__init__()"),cLo=o(" (throws an error)."),fLo=l(),Kr=a("div"),f(P3.$$.fragment),mLo=l(),kne=a("p"),gLo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),hLo=l(),Cd=a("p"),pLo=o(`Note:
Loading a model from its configuration file does `),Rne=a("strong"),_Lo=o("not"),uLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sne=a("code"),bLo=o("from_pretrained()"),vLo=o("to load the model weights."),TLo=l(),Pne=a("p"),FLo=o("Examples:"),CLo=l(),f($3.$$.fragment),MLo=l(),We=a("div"),f(I3.$$.fragment),ELo=l(),$ne=a("p"),yLo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),wLo=l(),Ya=a("p"),ALo=o("The model class to instantiate is selected based on the "),Ine=a("code"),LLo=o("model_type"),BLo=o(` property of the config object (either
passed as an argument or loaded from `),jne=a("code"),xLo=o("pretrained_model_name_or_path"),kLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dne=a("code"),RLo=o("pretrained_model_name_or_path"),SLo=o(":"),PLo=l(),N=a("ul"),Cb=a("li"),Nne=a("strong"),$Lo=o("albert"),ILo=o(" \u2014 "),Wj=a("a"),jLo=o("AlbertForTokenClassification"),DLo=o(" (ALBERT model)"),NLo=l(),Mb=a("li"),qne=a("strong"),qLo=o("bert"),OLo=o(" \u2014 "),Qj=a("a"),GLo=o("BertForTokenClassification"),XLo=o(" (BERT model)"),VLo=l(),Eb=a("li"),One=a("strong"),zLo=o("big_bird"),WLo=o(" \u2014 "),Hj=a("a"),QLo=o("BigBirdForTokenClassification"),HLo=o(" (BigBird model)"),ULo=l(),yb=a("li"),Gne=a("strong"),JLo=o("camembert"),YLo=o(" \u2014 "),Uj=a("a"),KLo=o("CamembertForTokenClassification"),ZLo=o(" (CamemBERT model)"),e8o=l(),wb=a("li"),Xne=a("strong"),o8o=o("canine"),r8o=o(" \u2014 "),Jj=a("a"),t8o=o("CanineForTokenClassification"),a8o=o(" (Canine model)"),n8o=l(),Ab=a("li"),Vne=a("strong"),s8o=o("convbert"),l8o=o(" \u2014 "),Yj=a("a"),i8o=o("ConvBertForTokenClassification"),d8o=o(" (ConvBERT model)"),c8o=l(),Lb=a("li"),zne=a("strong"),f8o=o("data2vec-text"),m8o=o(" \u2014 "),Kj=a("a"),g8o=o("Data2VecTextForTokenClassification"),h8o=o(" (Data2VecText model)"),p8o=l(),Bb=a("li"),Wne=a("strong"),_8o=o("deberta"),u8o=o(" \u2014 "),Zj=a("a"),b8o=o("DebertaForTokenClassification"),v8o=o(" (DeBERTa model)"),T8o=l(),xb=a("li"),Qne=a("strong"),F8o=o("deberta-v2"),C8o=o(" \u2014 "),eD=a("a"),M8o=o("DebertaV2ForTokenClassification"),E8o=o(" (DeBERTa-v2 model)"),y8o=l(),kb=a("li"),Hne=a("strong"),w8o=o("distilbert"),A8o=o(" \u2014 "),oD=a("a"),L8o=o("DistilBertForTokenClassification"),B8o=o(" (DistilBERT model)"),x8o=l(),Rb=a("li"),Une=a("strong"),k8o=o("electra"),R8o=o(" \u2014 "),rD=a("a"),S8o=o("ElectraForTokenClassification"),P8o=o(" (ELECTRA model)"),$8o=l(),Sb=a("li"),Jne=a("strong"),I8o=o("flaubert"),j8o=o(" \u2014 "),tD=a("a"),D8o=o("FlaubertForTokenClassification"),N8o=o(" (FlauBERT model)"),q8o=l(),Pb=a("li"),Yne=a("strong"),O8o=o("fnet"),G8o=o(" \u2014 "),aD=a("a"),X8o=o("FNetForTokenClassification"),V8o=o(" (FNet model)"),z8o=l(),$b=a("li"),Kne=a("strong"),W8o=o("funnel"),Q8o=o(" \u2014 "),nD=a("a"),H8o=o("FunnelForTokenClassification"),U8o=o(" (Funnel Transformer model)"),J8o=l(),Ib=a("li"),Zne=a("strong"),Y8o=o("gpt2"),K8o=o(" \u2014 "),sD=a("a"),Z8o=o("GPT2ForTokenClassification"),e9o=o(" (OpenAI GPT-2 model)"),o9o=l(),jb=a("li"),ese=a("strong"),r9o=o("ibert"),t9o=o(" \u2014 "),lD=a("a"),a9o=o("IBertForTokenClassification"),n9o=o(" (I-BERT model)"),s9o=l(),Db=a("li"),ose=a("strong"),l9o=o("layoutlm"),i9o=o(" \u2014 "),iD=a("a"),d9o=o("LayoutLMForTokenClassification"),c9o=o(" (LayoutLM model)"),f9o=l(),Nb=a("li"),rse=a("strong"),m9o=o("layoutlmv2"),g9o=o(" \u2014 "),dD=a("a"),h9o=o("LayoutLMv2ForTokenClassification"),p9o=o(" (LayoutLMv2 model)"),_9o=l(),qb=a("li"),tse=a("strong"),u9o=o("longformer"),b9o=o(" \u2014 "),cD=a("a"),v9o=o("LongformerForTokenClassification"),T9o=o(" (Longformer model)"),F9o=l(),Ob=a("li"),ase=a("strong"),C9o=o("megatron-bert"),M9o=o(" \u2014 "),fD=a("a"),E9o=o("MegatronBertForTokenClassification"),y9o=o(" (MegatronBert model)"),w9o=l(),Gb=a("li"),nse=a("strong"),A9o=o("mobilebert"),L9o=o(" \u2014 "),mD=a("a"),B9o=o("MobileBertForTokenClassification"),x9o=o(" (MobileBERT model)"),k9o=l(),Xb=a("li"),sse=a("strong"),R9o=o("mpnet"),S9o=o(" \u2014 "),gD=a("a"),P9o=o("MPNetForTokenClassification"),$9o=o(" (MPNet model)"),I9o=l(),Vb=a("li"),lse=a("strong"),j9o=o("nystromformer"),D9o=o(" \u2014 "),hD=a("a"),N9o=o("NystromformerForTokenClassification"),q9o=o(" (Nystromformer model)"),O9o=l(),zb=a("li"),ise=a("strong"),G9o=o("qdqbert"),X9o=o(" \u2014 "),pD=a("a"),V9o=o("QDQBertForTokenClassification"),z9o=o(" (QDQBert model)"),W9o=l(),Wb=a("li"),dse=a("strong"),Q9o=o("rembert"),H9o=o(" \u2014 "),_D=a("a"),U9o=o("RemBertForTokenClassification"),J9o=o(" (RemBERT model)"),Y9o=l(),Qb=a("li"),cse=a("strong"),K9o=o("roberta"),Z9o=o(" \u2014 "),uD=a("a"),eBo=o("RobertaForTokenClassification"),oBo=o(" (RoBERTa model)"),rBo=l(),Hb=a("li"),fse=a("strong"),tBo=o("roformer"),aBo=o(" \u2014 "),bD=a("a"),nBo=o("RoFormerForTokenClassification"),sBo=o(" (RoFormer model)"),lBo=l(),Ub=a("li"),mse=a("strong"),iBo=o("squeezebert"),dBo=o(" \u2014 "),vD=a("a"),cBo=o("SqueezeBertForTokenClassification"),fBo=o(" (SqueezeBERT model)"),mBo=l(),Jb=a("li"),gse=a("strong"),gBo=o("xlm"),hBo=o(" \u2014 "),TD=a("a"),pBo=o("XLMForTokenClassification"),_Bo=o(" (XLM model)"),uBo=l(),Yb=a("li"),hse=a("strong"),bBo=o("xlm-roberta"),vBo=o(" \u2014 "),FD=a("a"),TBo=o("XLMRobertaForTokenClassification"),FBo=o(" (XLM-RoBERTa model)"),CBo=l(),Kb=a("li"),pse=a("strong"),MBo=o("xlm-roberta-xl"),EBo=o(" \u2014 "),CD=a("a"),yBo=o("XLMRobertaXLForTokenClassification"),wBo=o(" (XLM-RoBERTa-XL model)"),ABo=l(),Zb=a("li"),_se=a("strong"),LBo=o("xlnet"),BBo=o(" \u2014 "),MD=a("a"),xBo=o("XLNetForTokenClassification"),kBo=o(" (XLNet model)"),RBo=l(),e5=a("li"),use=a("strong"),SBo=o("yoso"),PBo=o(" \u2014 "),ED=a("a"),$Bo=o("YosoForTokenClassification"),IBo=o(" (YOSO model)"),jBo=l(),o5=a("p"),DBo=o("The model is set in evaluation mode by default using "),bse=a("code"),NBo=o("model.eval()"),qBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vse=a("code"),OBo=o("model.train()"),GBo=l(),Tse=a("p"),XBo=o("Examples:"),VBo=l(),f(j3.$$.fragment),zxe=l(),Md=a("h2"),r5=a("a"),Fse=a("span"),f(D3.$$.fragment),zBo=l(),Cse=a("span"),WBo=o("AutoModelForQuestionAnswering"),Wxe=l(),nr=a("div"),f(N3.$$.fragment),QBo=l(),Ed=a("p"),HBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Mse=a("code"),UBo=o("from_pretrained()"),JBo=o("class method or the "),Ese=a("code"),YBo=o("from_config()"),KBo=o(`class
method.`),ZBo=l(),q3=a("p"),exo=o("This class cannot be instantiated directly using "),yse=a("code"),oxo=o("__init__()"),rxo=o(" (throws an error)."),txo=l(),Zr=a("div"),f(O3.$$.fragment),axo=l(),wse=a("p"),nxo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),sxo=l(),yd=a("p"),lxo=o(`Note:
Loading a model from its configuration file does `),Ase=a("strong"),ixo=o("not"),dxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lse=a("code"),cxo=o("from_pretrained()"),fxo=o("to load the model weights."),mxo=l(),Bse=a("p"),gxo=o("Examples:"),hxo=l(),f(G3.$$.fragment),pxo=l(),Qe=a("div"),f(X3.$$.fragment),_xo=l(),xse=a("p"),uxo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),bxo=l(),Ka=a("p"),vxo=o("The model class to instantiate is selected based on the "),kse=a("code"),Txo=o("model_type"),Fxo=o(` property of the config object (either
passed as an argument or loaded from `),Rse=a("code"),Cxo=o("pretrained_model_name_or_path"),Mxo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sse=a("code"),Exo=o("pretrained_model_name_or_path"),yxo=o(":"),wxo=l(),R=a("ul"),t5=a("li"),Pse=a("strong"),Axo=o("albert"),Lxo=o(" \u2014 "),yD=a("a"),Bxo=o("AlbertForQuestionAnswering"),xxo=o(" (ALBERT model)"),kxo=l(),a5=a("li"),$se=a("strong"),Rxo=o("bart"),Sxo=o(" \u2014 "),wD=a("a"),Pxo=o("BartForQuestionAnswering"),$xo=o(" (BART model)"),Ixo=l(),n5=a("li"),Ise=a("strong"),jxo=o("bert"),Dxo=o(" \u2014 "),AD=a("a"),Nxo=o("BertForQuestionAnswering"),qxo=o(" (BERT model)"),Oxo=l(),s5=a("li"),jse=a("strong"),Gxo=o("big_bird"),Xxo=o(" \u2014 "),LD=a("a"),Vxo=o("BigBirdForQuestionAnswering"),zxo=o(" (BigBird model)"),Wxo=l(),l5=a("li"),Dse=a("strong"),Qxo=o("bigbird_pegasus"),Hxo=o(" \u2014 "),BD=a("a"),Uxo=o("BigBirdPegasusForQuestionAnswering"),Jxo=o(" (BigBirdPegasus model)"),Yxo=l(),i5=a("li"),Nse=a("strong"),Kxo=o("camembert"),Zxo=o(" \u2014 "),xD=a("a"),eko=o("CamembertForQuestionAnswering"),oko=o(" (CamemBERT model)"),rko=l(),d5=a("li"),qse=a("strong"),tko=o("canine"),ako=o(" \u2014 "),kD=a("a"),nko=o("CanineForQuestionAnswering"),sko=o(" (Canine model)"),lko=l(),c5=a("li"),Ose=a("strong"),iko=o("convbert"),dko=o(" \u2014 "),RD=a("a"),cko=o("ConvBertForQuestionAnswering"),fko=o(" (ConvBERT model)"),mko=l(),f5=a("li"),Gse=a("strong"),gko=o("data2vec-text"),hko=o(" \u2014 "),SD=a("a"),pko=o("Data2VecTextForQuestionAnswering"),_ko=o(" (Data2VecText model)"),uko=l(),m5=a("li"),Xse=a("strong"),bko=o("deberta"),vko=o(" \u2014 "),PD=a("a"),Tko=o("DebertaForQuestionAnswering"),Fko=o(" (DeBERTa model)"),Cko=l(),g5=a("li"),Vse=a("strong"),Mko=o("deberta-v2"),Eko=o(" \u2014 "),$D=a("a"),yko=o("DebertaV2ForQuestionAnswering"),wko=o(" (DeBERTa-v2 model)"),Ako=l(),h5=a("li"),zse=a("strong"),Lko=o("distilbert"),Bko=o(" \u2014 "),ID=a("a"),xko=o("DistilBertForQuestionAnswering"),kko=o(" (DistilBERT model)"),Rko=l(),p5=a("li"),Wse=a("strong"),Sko=o("electra"),Pko=o(" \u2014 "),jD=a("a"),$ko=o("ElectraForQuestionAnswering"),Iko=o(" (ELECTRA model)"),jko=l(),_5=a("li"),Qse=a("strong"),Dko=o("flaubert"),Nko=o(" \u2014 "),DD=a("a"),qko=o("FlaubertForQuestionAnsweringSimple"),Oko=o(" (FlauBERT model)"),Gko=l(),u5=a("li"),Hse=a("strong"),Xko=o("fnet"),Vko=o(" \u2014 "),ND=a("a"),zko=o("FNetForQuestionAnswering"),Wko=o(" (FNet model)"),Qko=l(),b5=a("li"),Use=a("strong"),Hko=o("funnel"),Uko=o(" \u2014 "),qD=a("a"),Jko=o("FunnelForQuestionAnswering"),Yko=o(" (Funnel Transformer model)"),Kko=l(),v5=a("li"),Jse=a("strong"),Zko=o("gptj"),eRo=o(" \u2014 "),OD=a("a"),oRo=o("GPTJForQuestionAnswering"),rRo=o(" (GPT-J model)"),tRo=l(),T5=a("li"),Yse=a("strong"),aRo=o("ibert"),nRo=o(" \u2014 "),GD=a("a"),sRo=o("IBertForQuestionAnswering"),lRo=o(" (I-BERT model)"),iRo=l(),F5=a("li"),Kse=a("strong"),dRo=o("layoutlmv2"),cRo=o(" \u2014 "),XD=a("a"),fRo=o("LayoutLMv2ForQuestionAnswering"),mRo=o(" (LayoutLMv2 model)"),gRo=l(),C5=a("li"),Zse=a("strong"),hRo=o("led"),pRo=o(" \u2014 "),VD=a("a"),_Ro=o("LEDForQuestionAnswering"),uRo=o(" (LED model)"),bRo=l(),M5=a("li"),ele=a("strong"),vRo=o("longformer"),TRo=o(" \u2014 "),zD=a("a"),FRo=o("LongformerForQuestionAnswering"),CRo=o(" (Longformer model)"),MRo=l(),E5=a("li"),ole=a("strong"),ERo=o("lxmert"),yRo=o(" \u2014 "),WD=a("a"),wRo=o("LxmertForQuestionAnswering"),ARo=o(" (LXMERT model)"),LRo=l(),y5=a("li"),rle=a("strong"),BRo=o("mbart"),xRo=o(" \u2014 "),QD=a("a"),kRo=o("MBartForQuestionAnswering"),RRo=o(" (mBART model)"),SRo=l(),w5=a("li"),tle=a("strong"),PRo=o("megatron-bert"),$Ro=o(" \u2014 "),HD=a("a"),IRo=o("MegatronBertForQuestionAnswering"),jRo=o(" (MegatronBert model)"),DRo=l(),A5=a("li"),ale=a("strong"),NRo=o("mobilebert"),qRo=o(" \u2014 "),UD=a("a"),ORo=o("MobileBertForQuestionAnswering"),GRo=o(" (MobileBERT model)"),XRo=l(),L5=a("li"),nle=a("strong"),VRo=o("mpnet"),zRo=o(" \u2014 "),JD=a("a"),WRo=o("MPNetForQuestionAnswering"),QRo=o(" (MPNet model)"),HRo=l(),B5=a("li"),sle=a("strong"),URo=o("nystromformer"),JRo=o(" \u2014 "),YD=a("a"),YRo=o("NystromformerForQuestionAnswering"),KRo=o(" (Nystromformer model)"),ZRo=l(),x5=a("li"),lle=a("strong"),eSo=o("qdqbert"),oSo=o(" \u2014 "),KD=a("a"),rSo=o("QDQBertForQuestionAnswering"),tSo=o(" (QDQBert model)"),aSo=l(),k5=a("li"),ile=a("strong"),nSo=o("reformer"),sSo=o(" \u2014 "),ZD=a("a"),lSo=o("ReformerForQuestionAnswering"),iSo=o(" (Reformer model)"),dSo=l(),R5=a("li"),dle=a("strong"),cSo=o("rembert"),fSo=o(" \u2014 "),eN=a("a"),mSo=o("RemBertForQuestionAnswering"),gSo=o(" (RemBERT model)"),hSo=l(),S5=a("li"),cle=a("strong"),pSo=o("roberta"),_So=o(" \u2014 "),oN=a("a"),uSo=o("RobertaForQuestionAnswering"),bSo=o(" (RoBERTa model)"),vSo=l(),P5=a("li"),fle=a("strong"),TSo=o("roformer"),FSo=o(" \u2014 "),rN=a("a"),CSo=o("RoFormerForQuestionAnswering"),MSo=o(" (RoFormer model)"),ESo=l(),$5=a("li"),mle=a("strong"),ySo=o("splinter"),wSo=o(" \u2014 "),tN=a("a"),ASo=o("SplinterForQuestionAnswering"),LSo=o(" (Splinter model)"),BSo=l(),I5=a("li"),gle=a("strong"),xSo=o("squeezebert"),kSo=o(" \u2014 "),aN=a("a"),RSo=o("SqueezeBertForQuestionAnswering"),SSo=o(" (SqueezeBERT model)"),PSo=l(),j5=a("li"),hle=a("strong"),$So=o("xlm"),ISo=o(" \u2014 "),nN=a("a"),jSo=o("XLMForQuestionAnsweringSimple"),DSo=o(" (XLM model)"),NSo=l(),D5=a("li"),ple=a("strong"),qSo=o("xlm-roberta"),OSo=o(" \u2014 "),sN=a("a"),GSo=o("XLMRobertaForQuestionAnswering"),XSo=o(" (XLM-RoBERTa model)"),VSo=l(),N5=a("li"),_le=a("strong"),zSo=o("xlm-roberta-xl"),WSo=o(" \u2014 "),lN=a("a"),QSo=o("XLMRobertaXLForQuestionAnswering"),HSo=o(" (XLM-RoBERTa-XL model)"),USo=l(),q5=a("li"),ule=a("strong"),JSo=o("xlnet"),YSo=o(" \u2014 "),iN=a("a"),KSo=o("XLNetForQuestionAnsweringSimple"),ZSo=o(" (XLNet model)"),ePo=l(),O5=a("li"),ble=a("strong"),oPo=o("yoso"),rPo=o(" \u2014 "),dN=a("a"),tPo=o("YosoForQuestionAnswering"),aPo=o(" (YOSO model)"),nPo=l(),G5=a("p"),sPo=o("The model is set in evaluation mode by default using "),vle=a("code"),lPo=o("model.eval()"),iPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tle=a("code"),dPo=o("model.train()"),cPo=l(),Fle=a("p"),fPo=o("Examples:"),mPo=l(),f(V3.$$.fragment),Qxe=l(),wd=a("h2"),X5=a("a"),Cle=a("span"),f(z3.$$.fragment),gPo=l(),Mle=a("span"),hPo=o("AutoModelForTableQuestionAnswering"),Hxe=l(),sr=a("div"),f(W3.$$.fragment),pPo=l(),Ad=a("p"),_Po=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Ele=a("code"),uPo=o("from_pretrained()"),bPo=o("class method or the "),yle=a("code"),vPo=o("from_config()"),TPo=o(`class
method.`),FPo=l(),Q3=a("p"),CPo=o("This class cannot be instantiated directly using "),wle=a("code"),MPo=o("__init__()"),EPo=o(" (throws an error)."),yPo=l(),et=a("div"),f(H3.$$.fragment),wPo=l(),Ale=a("p"),APo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),LPo=l(),Ld=a("p"),BPo=o(`Note:
Loading a model from its configuration file does `),Lle=a("strong"),xPo=o("not"),kPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ble=a("code"),RPo=o("from_pretrained()"),SPo=o("to load the model weights."),PPo=l(),xle=a("p"),$Po=o("Examples:"),IPo=l(),f(U3.$$.fragment),jPo=l(),He=a("div"),f(J3.$$.fragment),DPo=l(),kle=a("p"),NPo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),qPo=l(),Za=a("p"),OPo=o("The model class to instantiate is selected based on the "),Rle=a("code"),GPo=o("model_type"),XPo=o(` property of the config object (either
passed as an argument or loaded from `),Sle=a("code"),VPo=o("pretrained_model_name_or_path"),zPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ple=a("code"),WPo=o("pretrained_model_name_or_path"),QPo=o(":"),HPo=l(),$le=a("ul"),V5=a("li"),Ile=a("strong"),UPo=o("tapas"),JPo=o(" \u2014 "),cN=a("a"),YPo=o("TapasForQuestionAnswering"),KPo=o(" (TAPAS model)"),ZPo=l(),z5=a("p"),e$o=o("The model is set in evaluation mode by default using "),jle=a("code"),o$o=o("model.eval()"),r$o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dle=a("code"),t$o=o("model.train()"),a$o=l(),Nle=a("p"),n$o=o("Examples:"),s$o=l(),f(Y3.$$.fragment),Uxe=l(),Bd=a("h2"),W5=a("a"),qle=a("span"),f(K3.$$.fragment),l$o=l(),Ole=a("span"),i$o=o("AutoModelForImageClassification"),Jxe=l(),lr=a("div"),f(Z3.$$.fragment),d$o=l(),xd=a("p"),c$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Gle=a("code"),f$o=o("from_pretrained()"),m$o=o("class method or the "),Xle=a("code"),g$o=o("from_config()"),h$o=o(`class
method.`),p$o=l(),ey=a("p"),_$o=o("This class cannot be instantiated directly using "),Vle=a("code"),u$o=o("__init__()"),b$o=o(" (throws an error)."),v$o=l(),ot=a("div"),f(oy.$$.fragment),T$o=l(),zle=a("p"),F$o=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),C$o=l(),kd=a("p"),M$o=o(`Note:
Loading a model from its configuration file does `),Wle=a("strong"),E$o=o("not"),y$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qle=a("code"),w$o=o("from_pretrained()"),A$o=o("to load the model weights."),L$o=l(),Hle=a("p"),B$o=o("Examples:"),x$o=l(),f(ry.$$.fragment),k$o=l(),Ue=a("div"),f(ty.$$.fragment),R$o=l(),Ule=a("p"),S$o=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),P$o=l(),en=a("p"),$$o=o("The model class to instantiate is selected based on the "),Jle=a("code"),I$o=o("model_type"),j$o=o(` property of the config object (either
passed as an argument or loaded from `),Yle=a("code"),D$o=o("pretrained_model_name_or_path"),N$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kle=a("code"),q$o=o("pretrained_model_name_or_path"),O$o=o(":"),G$o=l(),pe=a("ul"),Q5=a("li"),Zle=a("strong"),X$o=o("beit"),V$o=o(" \u2014 "),fN=a("a"),z$o=o("BeitForImageClassification"),W$o=o(" (BEiT model)"),Q$o=l(),H5=a("li"),eie=a("strong"),H$o=o("convnext"),U$o=o(" \u2014 "),mN=a("a"),J$o=o("ConvNextForImageClassification"),Y$o=o(" (ConvNext model)"),K$o=l(),qs=a("li"),oie=a("strong"),Z$o=o("deit"),eIo=o(" \u2014 "),gN=a("a"),oIo=o("DeiTForImageClassification"),rIo=o(" or "),hN=a("a"),tIo=o("DeiTForImageClassificationWithTeacher"),aIo=o(" (DeiT model)"),nIo=l(),U5=a("li"),rie=a("strong"),sIo=o("imagegpt"),lIo=o(" \u2014 "),pN=a("a"),iIo=o("ImageGPTForImageClassification"),dIo=o(" (ImageGPT model)"),cIo=l(),fa=a("li"),tie=a("strong"),fIo=o("perceiver"),mIo=o(" \u2014 "),_N=a("a"),gIo=o("PerceiverForImageClassificationLearned"),hIo=o(" or "),uN=a("a"),pIo=o("PerceiverForImageClassificationFourier"),_Io=o(" or "),bN=a("a"),uIo=o("PerceiverForImageClassificationConvProcessing"),bIo=o(" (Perceiver model)"),vIo=l(),J5=a("li"),aie=a("strong"),TIo=o("poolformer"),FIo=o(" \u2014 "),vN=a("a"),CIo=o("PoolFormerForImageClassification"),MIo=o(" (PoolFormer model)"),EIo=l(),Y5=a("li"),nie=a("strong"),yIo=o("resnet"),wIo=o(" \u2014 "),TN=a("a"),AIo=o("ResNetForImageClassification"),LIo=o(" (ResNet model)"),BIo=l(),K5=a("li"),sie=a("strong"),xIo=o("segformer"),kIo=o(" \u2014 "),FN=a("a"),RIo=o("SegformerForImageClassification"),SIo=o(" (SegFormer model)"),PIo=l(),Z5=a("li"),lie=a("strong"),$Io=o("swin"),IIo=o(" \u2014 "),CN=a("a"),jIo=o("SwinForImageClassification"),DIo=o(" (Swin model)"),NIo=l(),e2=a("li"),iie=a("strong"),qIo=o("vit"),OIo=o(" \u2014 "),MN=a("a"),GIo=o("ViTForImageClassification"),XIo=o(" (ViT model)"),VIo=l(),o2=a("p"),zIo=o("The model is set in evaluation mode by default using "),die=a("code"),WIo=o("model.eval()"),QIo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cie=a("code"),HIo=o("model.train()"),UIo=l(),fie=a("p"),JIo=o("Examples:"),YIo=l(),f(ay.$$.fragment),Yxe=l(),Rd=a("h2"),r2=a("a"),mie=a("span"),f(ny.$$.fragment),KIo=l(),gie=a("span"),ZIo=o("AutoModelForVision2Seq"),Kxe=l(),ir=a("div"),f(sy.$$.fragment),ejo=l(),Sd=a("p"),ojo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hie=a("code"),rjo=o("from_pretrained()"),tjo=o("class method or the "),pie=a("code"),ajo=o("from_config()"),njo=o(`class
method.`),sjo=l(),ly=a("p"),ljo=o("This class cannot be instantiated directly using "),_ie=a("code"),ijo=o("__init__()"),djo=o(" (throws an error)."),cjo=l(),rt=a("div"),f(iy.$$.fragment),fjo=l(),uie=a("p"),mjo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),gjo=l(),Pd=a("p"),hjo=o(`Note:
Loading a model from its configuration file does `),bie=a("strong"),pjo=o("not"),_jo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vie=a("code"),ujo=o("from_pretrained()"),bjo=o("to load the model weights."),vjo=l(),Tie=a("p"),Tjo=o("Examples:"),Fjo=l(),f(dy.$$.fragment),Cjo=l(),Je=a("div"),f(cy.$$.fragment),Mjo=l(),Fie=a("p"),Ejo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),yjo=l(),on=a("p"),wjo=o("The model class to instantiate is selected based on the "),Cie=a("code"),Ajo=o("model_type"),Ljo=o(` property of the config object (either
passed as an argument or loaded from `),Mie=a("code"),Bjo=o("pretrained_model_name_or_path"),xjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Eie=a("code"),kjo=o("pretrained_model_name_or_path"),Rjo=o(":"),Sjo=l(),yie=a("ul"),t2=a("li"),wie=a("strong"),Pjo=o("vision-encoder-decoder"),$jo=o(" \u2014 "),EN=a("a"),Ijo=o("VisionEncoderDecoderModel"),jjo=o(" (Vision Encoder decoder model)"),Djo=l(),a2=a("p"),Njo=o("The model is set in evaluation mode by default using "),Aie=a("code"),qjo=o("model.eval()"),Ojo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lie=a("code"),Gjo=o("model.train()"),Xjo=l(),Bie=a("p"),Vjo=o("Examples:"),zjo=l(),f(fy.$$.fragment),Zxe=l(),$d=a("h2"),n2=a("a"),xie=a("span"),f(my.$$.fragment),Wjo=l(),kie=a("span"),Qjo=o("AutoModelForAudioClassification"),eke=l(),dr=a("div"),f(gy.$$.fragment),Hjo=l(),Id=a("p"),Ujo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Rie=a("code"),Jjo=o("from_pretrained()"),Yjo=o("class method or the "),Sie=a("code"),Kjo=o("from_config()"),Zjo=o(`class
method.`),eDo=l(),hy=a("p"),oDo=o("This class cannot be instantiated directly using "),Pie=a("code"),rDo=o("__init__()"),tDo=o(" (throws an error)."),aDo=l(),tt=a("div"),f(py.$$.fragment),nDo=l(),$ie=a("p"),sDo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),lDo=l(),jd=a("p"),iDo=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),dDo=o("not"),cDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jie=a("code"),fDo=o("from_pretrained()"),mDo=o("to load the model weights."),gDo=l(),Die=a("p"),hDo=o("Examples:"),pDo=l(),f(_y.$$.fragment),_Do=l(),Ye=a("div"),f(uy.$$.fragment),uDo=l(),Nie=a("p"),bDo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),vDo=l(),rn=a("p"),TDo=o("The model class to instantiate is selected based on the "),qie=a("code"),FDo=o("model_type"),CDo=o(` property of the config object (either
passed as an argument or loaded from `),Oie=a("code"),MDo=o("pretrained_model_name_or_path"),EDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gie=a("code"),yDo=o("pretrained_model_name_or_path"),wDo=o(":"),ADo=l(),ke=a("ul"),s2=a("li"),Xie=a("strong"),LDo=o("data2vec-audio"),BDo=o(" \u2014 "),yN=a("a"),xDo=o("Data2VecAudioForSequenceClassification"),kDo=o(" (Data2VecAudio model)"),RDo=l(),l2=a("li"),Vie=a("strong"),SDo=o("hubert"),PDo=o(" \u2014 "),wN=a("a"),$Do=o("HubertForSequenceClassification"),IDo=o(" (Hubert model)"),jDo=l(),i2=a("li"),zie=a("strong"),DDo=o("sew"),NDo=o(" \u2014 "),AN=a("a"),qDo=o("SEWForSequenceClassification"),ODo=o(" (SEW model)"),GDo=l(),d2=a("li"),Wie=a("strong"),XDo=o("sew-d"),VDo=o(" \u2014 "),LN=a("a"),zDo=o("SEWDForSequenceClassification"),WDo=o(" (SEW-D model)"),QDo=l(),c2=a("li"),Qie=a("strong"),HDo=o("unispeech"),UDo=o(" \u2014 "),BN=a("a"),JDo=o("UniSpeechForSequenceClassification"),YDo=o(" (UniSpeech model)"),KDo=l(),f2=a("li"),Hie=a("strong"),ZDo=o("unispeech-sat"),eNo=o(" \u2014 "),xN=a("a"),oNo=o("UniSpeechSatForSequenceClassification"),rNo=o(" (UniSpeechSat model)"),tNo=l(),m2=a("li"),Uie=a("strong"),aNo=o("wav2vec2"),nNo=o(" \u2014 "),kN=a("a"),sNo=o("Wav2Vec2ForSequenceClassification"),lNo=o(" (Wav2Vec2 model)"),iNo=l(),g2=a("li"),Jie=a("strong"),dNo=o("wavlm"),cNo=o(" \u2014 "),RN=a("a"),fNo=o("WavLMForSequenceClassification"),mNo=o(" (WavLM model)"),gNo=l(),h2=a("p"),hNo=o("The model is set in evaluation mode by default using "),Yie=a("code"),pNo=o("model.eval()"),_No=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kie=a("code"),uNo=o("model.train()"),bNo=l(),Zie=a("p"),vNo=o("Examples:"),TNo=l(),f(by.$$.fragment),oke=l(),Dd=a("h2"),p2=a("a"),ede=a("span"),f(vy.$$.fragment),FNo=l(),ode=a("span"),CNo=o("AutoModelForAudioFrameClassification"),rke=l(),cr=a("div"),f(Ty.$$.fragment),MNo=l(),Nd=a("p"),ENo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),rde=a("code"),yNo=o("from_pretrained()"),wNo=o("class method or the "),tde=a("code"),ANo=o("from_config()"),LNo=o(`class
method.`),BNo=l(),Fy=a("p"),xNo=o("This class cannot be instantiated directly using "),ade=a("code"),kNo=o("__init__()"),RNo=o(" (throws an error)."),SNo=l(),at=a("div"),f(Cy.$$.fragment),PNo=l(),nde=a("p"),$No=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),INo=l(),qd=a("p"),jNo=o(`Note:
Loading a model from its configuration file does `),sde=a("strong"),DNo=o("not"),NNo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lde=a("code"),qNo=o("from_pretrained()"),ONo=o("to load the model weights."),GNo=l(),ide=a("p"),XNo=o("Examples:"),VNo=l(),f(My.$$.fragment),zNo=l(),Ke=a("div"),f(Ey.$$.fragment),WNo=l(),dde=a("p"),QNo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),HNo=l(),tn=a("p"),UNo=o("The model class to instantiate is selected based on the "),cde=a("code"),JNo=o("model_type"),YNo=o(` property of the config object (either
passed as an argument or loaded from `),fde=a("code"),KNo=o("pretrained_model_name_or_path"),ZNo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mde=a("code"),eqo=o("pretrained_model_name_or_path"),oqo=o(":"),rqo=l(),an=a("ul"),_2=a("li"),gde=a("strong"),tqo=o("data2vec-audio"),aqo=o(" \u2014 "),SN=a("a"),nqo=o("Data2VecAudioForAudioFrameClassification"),sqo=o(" (Data2VecAudio model)"),lqo=l(),u2=a("li"),hde=a("strong"),iqo=o("unispeech-sat"),dqo=o(" \u2014 "),PN=a("a"),cqo=o("UniSpeechSatForAudioFrameClassification"),fqo=o(" (UniSpeechSat model)"),mqo=l(),b2=a("li"),pde=a("strong"),gqo=o("wav2vec2"),hqo=o(" \u2014 "),$N=a("a"),pqo=o("Wav2Vec2ForAudioFrameClassification"),_qo=o(" (Wav2Vec2 model)"),uqo=l(),v2=a("li"),_de=a("strong"),bqo=o("wavlm"),vqo=o(" \u2014 "),IN=a("a"),Tqo=o("WavLMForAudioFrameClassification"),Fqo=o(" (WavLM model)"),Cqo=l(),T2=a("p"),Mqo=o("The model is set in evaluation mode by default using "),ude=a("code"),Eqo=o("model.eval()"),yqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bde=a("code"),wqo=o("model.train()"),Aqo=l(),vde=a("p"),Lqo=o("Examples:"),Bqo=l(),f(yy.$$.fragment),tke=l(),Od=a("h2"),F2=a("a"),Tde=a("span"),f(wy.$$.fragment),xqo=l(),Fde=a("span"),kqo=o("AutoModelForCTC"),ake=l(),fr=a("div"),f(Ay.$$.fragment),Rqo=l(),Gd=a("p"),Sqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Cde=a("code"),Pqo=o("from_pretrained()"),$qo=o("class method or the "),Mde=a("code"),Iqo=o("from_config()"),jqo=o(`class
method.`),Dqo=l(),Ly=a("p"),Nqo=o("This class cannot be instantiated directly using "),Ede=a("code"),qqo=o("__init__()"),Oqo=o(" (throws an error)."),Gqo=l(),nt=a("div"),f(By.$$.fragment),Xqo=l(),yde=a("p"),Vqo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),zqo=l(),Xd=a("p"),Wqo=o(`Note:
Loading a model from its configuration file does `),wde=a("strong"),Qqo=o("not"),Hqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ade=a("code"),Uqo=o("from_pretrained()"),Jqo=o("to load the model weights."),Yqo=l(),Lde=a("p"),Kqo=o("Examples:"),Zqo=l(),f(xy.$$.fragment),eOo=l(),Ze=a("div"),f(ky.$$.fragment),oOo=l(),Bde=a("p"),rOo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),tOo=l(),nn=a("p"),aOo=o("The model class to instantiate is selected based on the "),xde=a("code"),nOo=o("model_type"),sOo=o(` property of the config object (either
passed as an argument or loaded from `),kde=a("code"),lOo=o("pretrained_model_name_or_path"),iOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rde=a("code"),dOo=o("pretrained_model_name_or_path"),cOo=o(":"),fOo=l(),Re=a("ul"),C2=a("li"),Sde=a("strong"),mOo=o("data2vec-audio"),gOo=o(" \u2014 "),jN=a("a"),hOo=o("Data2VecAudioForCTC"),pOo=o(" (Data2VecAudio model)"),_Oo=l(),M2=a("li"),Pde=a("strong"),uOo=o("hubert"),bOo=o(" \u2014 "),DN=a("a"),vOo=o("HubertForCTC"),TOo=o(" (Hubert model)"),FOo=l(),E2=a("li"),$de=a("strong"),COo=o("sew"),MOo=o(" \u2014 "),NN=a("a"),EOo=o("SEWForCTC"),yOo=o(" (SEW model)"),wOo=l(),y2=a("li"),Ide=a("strong"),AOo=o("sew-d"),LOo=o(" \u2014 "),qN=a("a"),BOo=o("SEWDForCTC"),xOo=o(" (SEW-D model)"),kOo=l(),w2=a("li"),jde=a("strong"),ROo=o("unispeech"),SOo=o(" \u2014 "),ON=a("a"),POo=o("UniSpeechForCTC"),$Oo=o(" (UniSpeech model)"),IOo=l(),A2=a("li"),Dde=a("strong"),jOo=o("unispeech-sat"),DOo=o(" \u2014 "),GN=a("a"),NOo=o("UniSpeechSatForCTC"),qOo=o(" (UniSpeechSat model)"),OOo=l(),L2=a("li"),Nde=a("strong"),GOo=o("wav2vec2"),XOo=o(" \u2014 "),XN=a("a"),VOo=o("Wav2Vec2ForCTC"),zOo=o(" (Wav2Vec2 model)"),WOo=l(),B2=a("li"),qde=a("strong"),QOo=o("wavlm"),HOo=o(" \u2014 "),VN=a("a"),UOo=o("WavLMForCTC"),JOo=o(" (WavLM model)"),YOo=l(),x2=a("p"),KOo=o("The model is set in evaluation mode by default using "),Ode=a("code"),ZOo=o("model.eval()"),eGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gde=a("code"),oGo=o("model.train()"),rGo=l(),Xde=a("p"),tGo=o("Examples:"),aGo=l(),f(Ry.$$.fragment),nke=l(),Vd=a("h2"),k2=a("a"),Vde=a("span"),f(Sy.$$.fragment),nGo=l(),zde=a("span"),sGo=o("AutoModelForSpeechSeq2Seq"),ske=l(),mr=a("div"),f(Py.$$.fragment),lGo=l(),zd=a("p"),iGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Wde=a("code"),dGo=o("from_pretrained()"),cGo=o("class method or the "),Qde=a("code"),fGo=o("from_config()"),mGo=o(`class
method.`),gGo=l(),$y=a("p"),hGo=o("This class cannot be instantiated directly using "),Hde=a("code"),pGo=o("__init__()"),_Go=o(" (throws an error)."),uGo=l(),st=a("div"),f(Iy.$$.fragment),bGo=l(),Ude=a("p"),vGo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),TGo=l(),Wd=a("p"),FGo=o(`Note:
Loading a model from its configuration file does `),Jde=a("strong"),CGo=o("not"),MGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yde=a("code"),EGo=o("from_pretrained()"),yGo=o("to load the model weights."),wGo=l(),Kde=a("p"),AGo=o("Examples:"),LGo=l(),f(jy.$$.fragment),BGo=l(),eo=a("div"),f(Dy.$$.fragment),xGo=l(),Zde=a("p"),kGo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),RGo=l(),sn=a("p"),SGo=o("The model class to instantiate is selected based on the "),ece=a("code"),PGo=o("model_type"),$Go=o(` property of the config object (either
passed as an argument or loaded from `),oce=a("code"),IGo=o("pretrained_model_name_or_path"),jGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rce=a("code"),DGo=o("pretrained_model_name_or_path"),NGo=o(":"),qGo=l(),Ny=a("ul"),R2=a("li"),tce=a("strong"),OGo=o("speech-encoder-decoder"),GGo=o(" \u2014 "),zN=a("a"),XGo=o("SpeechEncoderDecoderModel"),VGo=o(" (Speech Encoder decoder model)"),zGo=l(),S2=a("li"),ace=a("strong"),WGo=o("speech_to_text"),QGo=o(" \u2014 "),WN=a("a"),HGo=o("Speech2TextForConditionalGeneration"),UGo=o(" (Speech2Text model)"),JGo=l(),P2=a("p"),YGo=o("The model is set in evaluation mode by default using "),nce=a("code"),KGo=o("model.eval()"),ZGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sce=a("code"),eXo=o("model.train()"),oXo=l(),lce=a("p"),rXo=o("Examples:"),tXo=l(),f(qy.$$.fragment),lke=l(),Qd=a("h2"),$2=a("a"),ice=a("span"),f(Oy.$$.fragment),aXo=l(),dce=a("span"),nXo=o("AutoModelForAudioXVector"),ike=l(),gr=a("div"),f(Gy.$$.fragment),sXo=l(),Hd=a("p"),lXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),cce=a("code"),iXo=o("from_pretrained()"),dXo=o("class method or the "),fce=a("code"),cXo=o("from_config()"),fXo=o(`class
method.`),mXo=l(),Xy=a("p"),gXo=o("This class cannot be instantiated directly using "),mce=a("code"),hXo=o("__init__()"),pXo=o(" (throws an error)."),_Xo=l(),lt=a("div"),f(Vy.$$.fragment),uXo=l(),gce=a("p"),bXo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),vXo=l(),Ud=a("p"),TXo=o(`Note:
Loading a model from its configuration file does `),hce=a("strong"),FXo=o("not"),CXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pce=a("code"),MXo=o("from_pretrained()"),EXo=o("to load the model weights."),yXo=l(),_ce=a("p"),wXo=o("Examples:"),AXo=l(),f(zy.$$.fragment),LXo=l(),oo=a("div"),f(Wy.$$.fragment),BXo=l(),uce=a("p"),xXo=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),kXo=l(),ln=a("p"),RXo=o("The model class to instantiate is selected based on the "),bce=a("code"),SXo=o("model_type"),PXo=o(` property of the config object (either
passed as an argument or loaded from `),vce=a("code"),$Xo=o("pretrained_model_name_or_path"),IXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tce=a("code"),jXo=o("pretrained_model_name_or_path"),DXo=o(":"),NXo=l(),dn=a("ul"),I2=a("li"),Fce=a("strong"),qXo=o("data2vec-audio"),OXo=o(" \u2014 "),QN=a("a"),GXo=o("Data2VecAudioForXVector"),XXo=o(" (Data2VecAudio model)"),VXo=l(),j2=a("li"),Cce=a("strong"),zXo=o("unispeech-sat"),WXo=o(" \u2014 "),HN=a("a"),QXo=o("UniSpeechSatForXVector"),HXo=o(" (UniSpeechSat model)"),UXo=l(),D2=a("li"),Mce=a("strong"),JXo=o("wav2vec2"),YXo=o(" \u2014 "),UN=a("a"),KXo=o("Wav2Vec2ForXVector"),ZXo=o(" (Wav2Vec2 model)"),eVo=l(),N2=a("li"),Ece=a("strong"),oVo=o("wavlm"),rVo=o(" \u2014 "),JN=a("a"),tVo=o("WavLMForXVector"),aVo=o(" (WavLM model)"),nVo=l(),q2=a("p"),sVo=o("The model is set in evaluation mode by default using "),yce=a("code"),lVo=o("model.eval()"),iVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wce=a("code"),dVo=o("model.train()"),cVo=l(),Ace=a("p"),fVo=o("Examples:"),mVo=l(),f(Qy.$$.fragment),dke=l(),Jd=a("h2"),O2=a("a"),Lce=a("span"),f(Hy.$$.fragment),gVo=l(),Bce=a("span"),hVo=o("AutoModelForMaskedImageModeling"),cke=l(),hr=a("div"),f(Uy.$$.fragment),pVo=l(),Yd=a("p"),_Vo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xce=a("code"),uVo=o("from_pretrained()"),bVo=o("class method or the "),kce=a("code"),vVo=o("from_config()"),TVo=o(`class
method.`),FVo=l(),Jy=a("p"),CVo=o("This class cannot be instantiated directly using "),Rce=a("code"),MVo=o("__init__()"),EVo=o(" (throws an error)."),yVo=l(),it=a("div"),f(Yy.$$.fragment),wVo=l(),Sce=a("p"),AVo=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),LVo=l(),Kd=a("p"),BVo=o(`Note:
Loading a model from its configuration file does `),Pce=a("strong"),xVo=o("not"),kVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ce=a("code"),RVo=o("from_pretrained()"),SVo=o("to load the model weights."),PVo=l(),Ice=a("p"),$Vo=o("Examples:"),IVo=l(),f(Ky.$$.fragment),jVo=l(),ro=a("div"),f(Zy.$$.fragment),DVo=l(),jce=a("p"),NVo=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),qVo=l(),cn=a("p"),OVo=o("The model class to instantiate is selected based on the "),Dce=a("code"),GVo=o("model_type"),XVo=o(` property of the config object (either
passed as an argument or loaded from `),Nce=a("code"),VVo=o("pretrained_model_name_or_path"),zVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qce=a("code"),WVo=o("pretrained_model_name_or_path"),QVo=o(":"),HVo=l(),Zd=a("ul"),G2=a("li"),Oce=a("strong"),UVo=o("deit"),JVo=o(" \u2014 "),YN=a("a"),YVo=o("DeiTForMaskedImageModeling"),KVo=o(" (DeiT model)"),ZVo=l(),X2=a("li"),Gce=a("strong"),ezo=o("swin"),ozo=o(" \u2014 "),KN=a("a"),rzo=o("SwinForMaskedImageModeling"),tzo=o(" (Swin model)"),azo=l(),V2=a("li"),Xce=a("strong"),nzo=o("vit"),szo=o(" \u2014 "),ZN=a("a"),lzo=o("ViTForMaskedImageModeling"),izo=o(" (ViT model)"),dzo=l(),z2=a("p"),czo=o("The model is set in evaluation mode by default using "),Vce=a("code"),fzo=o("model.eval()"),mzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zce=a("code"),gzo=o("model.train()"),hzo=l(),Wce=a("p"),pzo=o("Examples:"),_zo=l(),f(ew.$$.fragment),fke=l(),ec=a("h2"),W2=a("a"),Qce=a("span"),f(ow.$$.fragment),uzo=l(),Hce=a("span"),bzo=o("AutoModelForObjectDetection"),mke=l(),pr=a("div"),f(rw.$$.fragment),vzo=l(),oc=a("p"),Tzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Uce=a("code"),Fzo=o("from_pretrained()"),Czo=o("class method or the "),Jce=a("code"),Mzo=o("from_config()"),Ezo=o(`class
method.`),yzo=l(),tw=a("p"),wzo=o("This class cannot be instantiated directly using "),Yce=a("code"),Azo=o("__init__()"),Lzo=o(" (throws an error)."),Bzo=l(),dt=a("div"),f(aw.$$.fragment),xzo=l(),Kce=a("p"),kzo=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Rzo=l(),rc=a("p"),Szo=o(`Note:
Loading a model from its configuration file does `),Zce=a("strong"),Pzo=o("not"),$zo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),efe=a("code"),Izo=o("from_pretrained()"),jzo=o("to load the model weights."),Dzo=l(),ofe=a("p"),Nzo=o("Examples:"),qzo=l(),f(nw.$$.fragment),Ozo=l(),to=a("div"),f(sw.$$.fragment),Gzo=l(),rfe=a("p"),Xzo=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Vzo=l(),fn=a("p"),zzo=o("The model class to instantiate is selected based on the "),tfe=a("code"),Wzo=o("model_type"),Qzo=o(` property of the config object (either
passed as an argument or loaded from `),afe=a("code"),Hzo=o("pretrained_model_name_or_path"),Uzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nfe=a("code"),Jzo=o("pretrained_model_name_or_path"),Yzo=o(":"),Kzo=l(),sfe=a("ul"),Q2=a("li"),lfe=a("strong"),Zzo=o("detr"),eWo=o(" \u2014 "),eq=a("a"),oWo=o("DetrForObjectDetection"),rWo=o(" (DETR model)"),tWo=l(),H2=a("p"),aWo=o("The model is set in evaluation mode by default using "),ife=a("code"),nWo=o("model.eval()"),sWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dfe=a("code"),lWo=o("model.train()"),iWo=l(),cfe=a("p"),dWo=o("Examples:"),cWo=l(),f(lw.$$.fragment),gke=l(),tc=a("h2"),U2=a("a"),ffe=a("span"),f(iw.$$.fragment),fWo=l(),mfe=a("span"),mWo=o("AutoModelForImageSegmentation"),hke=l(),_r=a("div"),f(dw.$$.fragment),gWo=l(),ac=a("p"),hWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),gfe=a("code"),pWo=o("from_pretrained()"),_Wo=o("class method or the "),hfe=a("code"),uWo=o("from_config()"),bWo=o(`class
method.`),vWo=l(),cw=a("p"),TWo=o("This class cannot be instantiated directly using "),pfe=a("code"),FWo=o("__init__()"),CWo=o(" (throws an error)."),MWo=l(),ct=a("div"),f(fw.$$.fragment),EWo=l(),_fe=a("p"),yWo=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),wWo=l(),nc=a("p"),AWo=o(`Note:
Loading a model from its configuration file does `),ufe=a("strong"),LWo=o("not"),BWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bfe=a("code"),xWo=o("from_pretrained()"),kWo=o("to load the model weights."),RWo=l(),vfe=a("p"),SWo=o("Examples:"),PWo=l(),f(mw.$$.fragment),$Wo=l(),ao=a("div"),f(gw.$$.fragment),IWo=l(),Tfe=a("p"),jWo=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),DWo=l(),mn=a("p"),NWo=o("The model class to instantiate is selected based on the "),Ffe=a("code"),qWo=o("model_type"),OWo=o(` property of the config object (either
passed as an argument or loaded from `),Cfe=a("code"),GWo=o("pretrained_model_name_or_path"),XWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mfe=a("code"),VWo=o("pretrained_model_name_or_path"),zWo=o(":"),WWo=l(),Efe=a("ul"),J2=a("li"),yfe=a("strong"),QWo=o("detr"),HWo=o(" \u2014 "),oq=a("a"),UWo=o("DetrForSegmentation"),JWo=o(" (DETR model)"),YWo=l(),Y2=a("p"),KWo=o("The model is set in evaluation mode by default using "),wfe=a("code"),ZWo=o("model.eval()"),eQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Afe=a("code"),oQo=o("model.train()"),rQo=l(),Lfe=a("p"),tQo=o("Examples:"),aQo=l(),f(hw.$$.fragment),pke=l(),sc=a("h2"),K2=a("a"),Bfe=a("span"),f(pw.$$.fragment),nQo=l(),xfe=a("span"),sQo=o("AutoModelForSemanticSegmentation"),_ke=l(),ur=a("div"),f(_w.$$.fragment),lQo=l(),lc=a("p"),iQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),kfe=a("code"),dQo=o("from_pretrained()"),cQo=o("class method or the "),Rfe=a("code"),fQo=o("from_config()"),mQo=o(`class
method.`),gQo=l(),uw=a("p"),hQo=o("This class cannot be instantiated directly using "),Sfe=a("code"),pQo=o("__init__()"),_Qo=o(" (throws an error)."),uQo=l(),ft=a("div"),f(bw.$$.fragment),bQo=l(),Pfe=a("p"),vQo=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),TQo=l(),ic=a("p"),FQo=o(`Note:
Loading a model from its configuration file does `),$fe=a("strong"),CQo=o("not"),MQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ife=a("code"),EQo=o("from_pretrained()"),yQo=o("to load the model weights."),wQo=l(),jfe=a("p"),AQo=o("Examples:"),LQo=l(),f(vw.$$.fragment),BQo=l(),no=a("div"),f(Tw.$$.fragment),xQo=l(),Dfe=a("p"),kQo=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),RQo=l(),gn=a("p"),SQo=o("The model class to instantiate is selected based on the "),Nfe=a("code"),PQo=o("model_type"),$Qo=o(` property of the config object (either
passed as an argument or loaded from `),qfe=a("code"),IQo=o("pretrained_model_name_or_path"),jQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ofe=a("code"),DQo=o("pretrained_model_name_or_path"),NQo=o(":"),qQo=l(),Fw=a("ul"),Z2=a("li"),Gfe=a("strong"),OQo=o("beit"),GQo=o(" \u2014 "),rq=a("a"),XQo=o("BeitForSemanticSegmentation"),VQo=o(" (BEiT model)"),zQo=l(),ev=a("li"),Xfe=a("strong"),WQo=o("segformer"),QQo=o(" \u2014 "),tq=a("a"),HQo=o("SegformerForSemanticSegmentation"),UQo=o(" (SegFormer model)"),JQo=l(),ov=a("p"),YQo=o("The model is set in evaluation mode by default using "),Vfe=a("code"),KQo=o("model.eval()"),ZQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=a("code"),eHo=o("model.train()"),oHo=l(),Wfe=a("p"),rHo=o("Examples:"),tHo=l(),f(Cw.$$.fragment),uke=l(),dc=a("h2"),rv=a("a"),Qfe=a("span"),f(Mw.$$.fragment),aHo=l(),Hfe=a("span"),nHo=o("AutoModelForInstanceSegmentation"),bke=l(),br=a("div"),f(Ew.$$.fragment),sHo=l(),cc=a("p"),lHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Ufe=a("code"),iHo=o("from_pretrained()"),dHo=o("class method or the "),Jfe=a("code"),cHo=o("from_config()"),fHo=o(`class
method.`),mHo=l(),yw=a("p"),gHo=o("This class cannot be instantiated directly using "),Yfe=a("code"),hHo=o("__init__()"),pHo=o(" (throws an error)."),_Ho=l(),mt=a("div"),f(ww.$$.fragment),uHo=l(),Kfe=a("p"),bHo=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),vHo=l(),fc=a("p"),THo=o(`Note:
Loading a model from its configuration file does `),Zfe=a("strong"),FHo=o("not"),CHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eme=a("code"),MHo=o("from_pretrained()"),EHo=o("to load the model weights."),yHo=l(),ome=a("p"),wHo=o("Examples:"),AHo=l(),f(Aw.$$.fragment),LHo=l(),so=a("div"),f(Lw.$$.fragment),BHo=l(),rme=a("p"),xHo=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),kHo=l(),hn=a("p"),RHo=o("The model class to instantiate is selected based on the "),tme=a("code"),SHo=o("model_type"),PHo=o(` property of the config object (either
passed as an argument or loaded from `),ame=a("code"),$Ho=o("pretrained_model_name_or_path"),IHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nme=a("code"),jHo=o("pretrained_model_name_or_path"),DHo=o(":"),NHo=l(),sme=a("ul"),tv=a("li"),lme=a("strong"),qHo=o("maskformer"),OHo=o(" \u2014 "),aq=a("a"),GHo=o("MaskFormerForInstanceSegmentation"),XHo=o(" (MaskFormer model)"),VHo=l(),av=a("p"),zHo=o("The model is set in evaluation mode by default using "),ime=a("code"),WHo=o("model.eval()"),QHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dme=a("code"),HHo=o("model.train()"),UHo=l(),cme=a("p"),JHo=o("Examples:"),YHo=l(),f(Bw.$$.fragment),vke=l(),mc=a("h2"),nv=a("a"),fme=a("span"),f(xw.$$.fragment),KHo=l(),mme=a("span"),ZHo=o("TFAutoModel"),Tke=l(),vr=a("div"),f(kw.$$.fragment),eUo=l(),gc=a("p"),oUo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gme=a("code"),rUo=o("from_pretrained()"),tUo=o("class method or the "),hme=a("code"),aUo=o("from_config()"),nUo=o(`class
method.`),sUo=l(),Rw=a("p"),lUo=o("This class cannot be instantiated directly using "),pme=a("code"),iUo=o("__init__()"),dUo=o(" (throws an error)."),cUo=l(),gt=a("div"),f(Sw.$$.fragment),fUo=l(),_me=a("p"),mUo=o("Instantiates one of the base model classes of the library from a configuration."),gUo=l(),hc=a("p"),hUo=o(`Note:
Loading a model from its configuration file does `),ume=a("strong"),pUo=o("not"),_Uo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bme=a("code"),uUo=o("from_pretrained()"),bUo=o("to load the model weights."),vUo=l(),vme=a("p"),TUo=o("Examples:"),FUo=l(),f(Pw.$$.fragment),CUo=l(),ho=a("div"),f($w.$$.fragment),MUo=l(),Tme=a("p"),EUo=o("Instantiate one of the base model classes of the library from a pretrained model."),yUo=l(),pn=a("p"),wUo=o("The model class to instantiate is selected based on the "),Fme=a("code"),AUo=o("model_type"),LUo=o(` property of the config object (either
passed as an argument or loaded from `),Cme=a("code"),BUo=o("pretrained_model_name_or_path"),xUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mme=a("code"),kUo=o("pretrained_model_name_or_path"),RUo=o(":"),SUo=l(),B=a("ul"),sv=a("li"),Eme=a("strong"),PUo=o("albert"),$Uo=o(" \u2014 "),nq=a("a"),IUo=o("TFAlbertModel"),jUo=o(" (ALBERT model)"),DUo=l(),lv=a("li"),yme=a("strong"),NUo=o("bart"),qUo=o(" \u2014 "),sq=a("a"),OUo=o("TFBartModel"),GUo=o(" (BART model)"),XUo=l(),iv=a("li"),wme=a("strong"),VUo=o("bert"),zUo=o(" \u2014 "),lq=a("a"),WUo=o("TFBertModel"),QUo=o(" (BERT model)"),HUo=l(),dv=a("li"),Ame=a("strong"),UUo=o("blenderbot"),JUo=o(" \u2014 "),iq=a("a"),YUo=o("TFBlenderbotModel"),KUo=o(" (Blenderbot model)"),ZUo=l(),cv=a("li"),Lme=a("strong"),eJo=o("blenderbot-small"),oJo=o(" \u2014 "),dq=a("a"),rJo=o("TFBlenderbotSmallModel"),tJo=o(" (BlenderbotSmall model)"),aJo=l(),fv=a("li"),Bme=a("strong"),nJo=o("camembert"),sJo=o(" \u2014 "),cq=a("a"),lJo=o("TFCamembertModel"),iJo=o(" (CamemBERT model)"),dJo=l(),mv=a("li"),xme=a("strong"),cJo=o("clip"),fJo=o(" \u2014 "),fq=a("a"),mJo=o("TFCLIPModel"),gJo=o(" (CLIP model)"),hJo=l(),gv=a("li"),kme=a("strong"),pJo=o("convbert"),_Jo=o(" \u2014 "),mq=a("a"),uJo=o("TFConvBertModel"),bJo=o(" (ConvBERT model)"),vJo=l(),hv=a("li"),Rme=a("strong"),TJo=o("convnext"),FJo=o(" \u2014 "),gq=a("a"),CJo=o("TFConvNextModel"),MJo=o(" (ConvNext model)"),EJo=l(),pv=a("li"),Sme=a("strong"),yJo=o("ctrl"),wJo=o(" \u2014 "),hq=a("a"),AJo=o("TFCTRLModel"),LJo=o(" (CTRL model)"),BJo=l(),_v=a("li"),Pme=a("strong"),xJo=o("deberta"),kJo=o(" \u2014 "),pq=a("a"),RJo=o("TFDebertaModel"),SJo=o(" (DeBERTa model)"),PJo=l(),uv=a("li"),$me=a("strong"),$Jo=o("deberta-v2"),IJo=o(" \u2014 "),_q=a("a"),jJo=o("TFDebertaV2Model"),DJo=o(" (DeBERTa-v2 model)"),NJo=l(),bv=a("li"),Ime=a("strong"),qJo=o("distilbert"),OJo=o(" \u2014 "),uq=a("a"),GJo=o("TFDistilBertModel"),XJo=o(" (DistilBERT model)"),VJo=l(),vv=a("li"),jme=a("strong"),zJo=o("dpr"),WJo=o(" \u2014 "),bq=a("a"),QJo=o("TFDPRQuestionEncoder"),HJo=o(" (DPR model)"),UJo=l(),Tv=a("li"),Dme=a("strong"),JJo=o("electra"),YJo=o(" \u2014 "),vq=a("a"),KJo=o("TFElectraModel"),ZJo=o(" (ELECTRA model)"),eYo=l(),Fv=a("li"),Nme=a("strong"),oYo=o("flaubert"),rYo=o(" \u2014 "),Tq=a("a"),tYo=o("TFFlaubertModel"),aYo=o(" (FlauBERT model)"),nYo=l(),Os=a("li"),qme=a("strong"),sYo=o("funnel"),lYo=o(" \u2014 "),Fq=a("a"),iYo=o("TFFunnelModel"),dYo=o(" or "),Cq=a("a"),cYo=o("TFFunnelBaseModel"),fYo=o(" (Funnel Transformer model)"),mYo=l(),Cv=a("li"),Ome=a("strong"),gYo=o("gpt2"),hYo=o(" \u2014 "),Mq=a("a"),pYo=o("TFGPT2Model"),_Yo=o(" (OpenAI GPT-2 model)"),uYo=l(),Mv=a("li"),Gme=a("strong"),bYo=o("hubert"),vYo=o(" \u2014 "),Eq=a("a"),TYo=o("TFHubertModel"),FYo=o(" (Hubert model)"),CYo=l(),Ev=a("li"),Xme=a("strong"),MYo=o("layoutlm"),EYo=o(" \u2014 "),yq=a("a"),yYo=o("TFLayoutLMModel"),wYo=o(" (LayoutLM model)"),AYo=l(),yv=a("li"),Vme=a("strong"),LYo=o("led"),BYo=o(" \u2014 "),wq=a("a"),xYo=o("TFLEDModel"),kYo=o(" (LED model)"),RYo=l(),wv=a("li"),zme=a("strong"),SYo=o("longformer"),PYo=o(" \u2014 "),Aq=a("a"),$Yo=o("TFLongformerModel"),IYo=o(" (Longformer model)"),jYo=l(),Av=a("li"),Wme=a("strong"),DYo=o("lxmert"),NYo=o(" \u2014 "),Lq=a("a"),qYo=o("TFLxmertModel"),OYo=o(" (LXMERT model)"),GYo=l(),Lv=a("li"),Qme=a("strong"),XYo=o("marian"),VYo=o(" \u2014 "),Bq=a("a"),zYo=o("TFMarianModel"),WYo=o(" (Marian model)"),QYo=l(),Bv=a("li"),Hme=a("strong"),HYo=o("mbart"),UYo=o(" \u2014 "),xq=a("a"),JYo=o("TFMBartModel"),YYo=o(" (mBART model)"),KYo=l(),xv=a("li"),Ume=a("strong"),ZYo=o("mobilebert"),eKo=o(" \u2014 "),kq=a("a"),oKo=o("TFMobileBertModel"),rKo=o(" (MobileBERT model)"),tKo=l(),kv=a("li"),Jme=a("strong"),aKo=o("mpnet"),nKo=o(" \u2014 "),Rq=a("a"),sKo=o("TFMPNetModel"),lKo=o(" (MPNet model)"),iKo=l(),Rv=a("li"),Yme=a("strong"),dKo=o("mt5"),cKo=o(" \u2014 "),Sq=a("a"),fKo=o("TFMT5Model"),mKo=o(" (mT5 model)"),gKo=l(),Sv=a("li"),Kme=a("strong"),hKo=o("openai-gpt"),pKo=o(" \u2014 "),Pq=a("a"),_Ko=o("TFOpenAIGPTModel"),uKo=o(" (OpenAI GPT model)"),bKo=l(),Pv=a("li"),Zme=a("strong"),vKo=o("pegasus"),TKo=o(" \u2014 "),$q=a("a"),FKo=o("TFPegasusModel"),CKo=o(" (Pegasus model)"),MKo=l(),$v=a("li"),ege=a("strong"),EKo=o("rembert"),yKo=o(" \u2014 "),Iq=a("a"),wKo=o("TFRemBertModel"),AKo=o(" (RemBERT model)"),LKo=l(),Iv=a("li"),oge=a("strong"),BKo=o("roberta"),xKo=o(" \u2014 "),jq=a("a"),kKo=o("TFRobertaModel"),RKo=o(" (RoBERTa model)"),SKo=l(),jv=a("li"),rge=a("strong"),PKo=o("roformer"),$Ko=o(" \u2014 "),Dq=a("a"),IKo=o("TFRoFormerModel"),jKo=o(" (RoFormer model)"),DKo=l(),Dv=a("li"),tge=a("strong"),NKo=o("speech_to_text"),qKo=o(" \u2014 "),Nq=a("a"),OKo=o("TFSpeech2TextModel"),GKo=o(" (Speech2Text model)"),XKo=l(),Nv=a("li"),age=a("strong"),VKo=o("t5"),zKo=o(" \u2014 "),qq=a("a"),WKo=o("TFT5Model"),QKo=o(" (T5 model)"),HKo=l(),qv=a("li"),nge=a("strong"),UKo=o("tapas"),JKo=o(" \u2014 "),Oq=a("a"),YKo=o("TFTapasModel"),KKo=o(" (TAPAS model)"),ZKo=l(),Ov=a("li"),sge=a("strong"),eZo=o("transfo-xl"),oZo=o(" \u2014 "),Gq=a("a"),rZo=o("TFTransfoXLModel"),tZo=o(" (Transformer-XL model)"),aZo=l(),Gv=a("li"),lge=a("strong"),nZo=o("vit"),sZo=o(" \u2014 "),Xq=a("a"),lZo=o("TFViTModel"),iZo=o(" (ViT model)"),dZo=l(),Xv=a("li"),ige=a("strong"),cZo=o("wav2vec2"),fZo=o(" \u2014 "),Vq=a("a"),mZo=o("TFWav2Vec2Model"),gZo=o(" (Wav2Vec2 model)"),hZo=l(),Vv=a("li"),dge=a("strong"),pZo=o("xlm"),_Zo=o(" \u2014 "),zq=a("a"),uZo=o("TFXLMModel"),bZo=o(" (XLM model)"),vZo=l(),zv=a("li"),cge=a("strong"),TZo=o("xlm-roberta"),FZo=o(" \u2014 "),Wq=a("a"),CZo=o("TFXLMRobertaModel"),MZo=o(" (XLM-RoBERTa model)"),EZo=l(),Wv=a("li"),fge=a("strong"),yZo=o("xlnet"),wZo=o(" \u2014 "),Qq=a("a"),AZo=o("TFXLNetModel"),LZo=o(" (XLNet model)"),BZo=l(),mge=a("p"),xZo=o("Examples:"),kZo=l(),f(Iw.$$.fragment),Fke=l(),pc=a("h2"),Qv=a("a"),gge=a("span"),f(jw.$$.fragment),RZo=l(),hge=a("span"),SZo=o("TFAutoModelForPreTraining"),Cke=l(),Tr=a("div"),f(Dw.$$.fragment),PZo=l(),_c=a("p"),$Zo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pge=a("code"),IZo=o("from_pretrained()"),jZo=o("class method or the "),_ge=a("code"),DZo=o("from_config()"),NZo=o(`class
method.`),qZo=l(),Nw=a("p"),OZo=o("This class cannot be instantiated directly using "),uge=a("code"),GZo=o("__init__()"),XZo=o(" (throws an error)."),VZo=l(),ht=a("div"),f(qw.$$.fragment),zZo=l(),bge=a("p"),WZo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),QZo=l(),uc=a("p"),HZo=o(`Note:
Loading a model from its configuration file does `),vge=a("strong"),UZo=o("not"),JZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tge=a("code"),YZo=o("from_pretrained()"),KZo=o("to load the model weights."),ZZo=l(),Fge=a("p"),eer=o("Examples:"),oer=l(),f(Ow.$$.fragment),rer=l(),po=a("div"),f(Gw.$$.fragment),ter=l(),Cge=a("p"),aer=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ner=l(),_n=a("p"),ser=o("The model class to instantiate is selected based on the "),Mge=a("code"),ler=o("model_type"),ier=o(` property of the config object (either
passed as an argument or loaded from `),Ege=a("code"),der=o("pretrained_model_name_or_path"),cer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yge=a("code"),fer=o("pretrained_model_name_or_path"),mer=o(":"),ger=l(),H=a("ul"),Hv=a("li"),wge=a("strong"),her=o("albert"),per=o(" \u2014 "),Hq=a("a"),_er=o("TFAlbertForPreTraining"),uer=o(" (ALBERT model)"),ber=l(),Uv=a("li"),Age=a("strong"),ver=o("bart"),Ter=o(" \u2014 "),Uq=a("a"),Fer=o("TFBartForConditionalGeneration"),Cer=o(" (BART model)"),Mer=l(),Jv=a("li"),Lge=a("strong"),Eer=o("bert"),yer=o(" \u2014 "),Jq=a("a"),wer=o("TFBertForPreTraining"),Aer=o(" (BERT model)"),Ler=l(),Yv=a("li"),Bge=a("strong"),Ber=o("camembert"),xer=o(" \u2014 "),Yq=a("a"),ker=o("TFCamembertForMaskedLM"),Rer=o(" (CamemBERT model)"),Ser=l(),Kv=a("li"),xge=a("strong"),Per=o("ctrl"),$er=o(" \u2014 "),Kq=a("a"),Ier=o("TFCTRLLMHeadModel"),jer=o(" (CTRL model)"),Der=l(),Zv=a("li"),kge=a("strong"),Ner=o("distilbert"),qer=o(" \u2014 "),Zq=a("a"),Oer=o("TFDistilBertForMaskedLM"),Ger=o(" (DistilBERT model)"),Xer=l(),e0=a("li"),Rge=a("strong"),Ver=o("electra"),zer=o(" \u2014 "),eO=a("a"),Wer=o("TFElectraForPreTraining"),Qer=o(" (ELECTRA model)"),Her=l(),o0=a("li"),Sge=a("strong"),Uer=o("flaubert"),Jer=o(" \u2014 "),oO=a("a"),Yer=o("TFFlaubertWithLMHeadModel"),Ker=o(" (FlauBERT model)"),Zer=l(),r0=a("li"),Pge=a("strong"),eor=o("funnel"),oor=o(" \u2014 "),rO=a("a"),ror=o("TFFunnelForPreTraining"),tor=o(" (Funnel Transformer model)"),aor=l(),t0=a("li"),$ge=a("strong"),nor=o("gpt2"),sor=o(" \u2014 "),tO=a("a"),lor=o("TFGPT2LMHeadModel"),ior=o(" (OpenAI GPT-2 model)"),dor=l(),a0=a("li"),Ige=a("strong"),cor=o("layoutlm"),mor=o(" \u2014 "),aO=a("a"),gor=o("TFLayoutLMForMaskedLM"),hor=o(" (LayoutLM model)"),por=l(),n0=a("li"),jge=a("strong"),_or=o("lxmert"),uor=o(" \u2014 "),nO=a("a"),bor=o("TFLxmertForPreTraining"),vor=o(" (LXMERT model)"),Tor=l(),s0=a("li"),Dge=a("strong"),For=o("mobilebert"),Cor=o(" \u2014 "),sO=a("a"),Mor=o("TFMobileBertForPreTraining"),Eor=o(" (MobileBERT model)"),yor=l(),l0=a("li"),Nge=a("strong"),wor=o("mpnet"),Aor=o(" \u2014 "),lO=a("a"),Lor=o("TFMPNetForMaskedLM"),Bor=o(" (MPNet model)"),xor=l(),i0=a("li"),qge=a("strong"),kor=o("openai-gpt"),Ror=o(" \u2014 "),iO=a("a"),Sor=o("TFOpenAIGPTLMHeadModel"),Por=o(" (OpenAI GPT model)"),$or=l(),d0=a("li"),Oge=a("strong"),Ior=o("roberta"),jor=o(" \u2014 "),dO=a("a"),Dor=o("TFRobertaForMaskedLM"),Nor=o(" (RoBERTa model)"),qor=l(),c0=a("li"),Gge=a("strong"),Oor=o("t5"),Gor=o(" \u2014 "),cO=a("a"),Xor=o("TFT5ForConditionalGeneration"),Vor=o(" (T5 model)"),zor=l(),f0=a("li"),Xge=a("strong"),Wor=o("tapas"),Qor=o(" \u2014 "),fO=a("a"),Hor=o("TFTapasForMaskedLM"),Uor=o(" (TAPAS model)"),Jor=l(),m0=a("li"),Vge=a("strong"),Yor=o("transfo-xl"),Kor=o(" \u2014 "),mO=a("a"),Zor=o("TFTransfoXLLMHeadModel"),err=o(" (Transformer-XL model)"),orr=l(),g0=a("li"),zge=a("strong"),rrr=o("xlm"),trr=o(" \u2014 "),gO=a("a"),arr=o("TFXLMWithLMHeadModel"),nrr=o(" (XLM model)"),srr=l(),h0=a("li"),Wge=a("strong"),lrr=o("xlm-roberta"),irr=o(" \u2014 "),hO=a("a"),drr=o("TFXLMRobertaForMaskedLM"),crr=o(" (XLM-RoBERTa model)"),frr=l(),p0=a("li"),Qge=a("strong"),mrr=o("xlnet"),grr=o(" \u2014 "),pO=a("a"),hrr=o("TFXLNetLMHeadModel"),prr=o(" (XLNet model)"),_rr=l(),Hge=a("p"),urr=o("Examples:"),brr=l(),f(Xw.$$.fragment),Mke=l(),bc=a("h2"),_0=a("a"),Uge=a("span"),f(Vw.$$.fragment),vrr=l(),Jge=a("span"),Trr=o("TFAutoModelForCausalLM"),Eke=l(),Fr=a("div"),f(zw.$$.fragment),Frr=l(),vc=a("p"),Crr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yge=a("code"),Mrr=o("from_pretrained()"),Err=o("class method or the "),Kge=a("code"),yrr=o("from_config()"),wrr=o(`class
method.`),Arr=l(),Ww=a("p"),Lrr=o("This class cannot be instantiated directly using "),Zge=a("code"),Brr=o("__init__()"),xrr=o(" (throws an error)."),krr=l(),pt=a("div"),f(Qw.$$.fragment),Rrr=l(),ehe=a("p"),Srr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Prr=l(),Tc=a("p"),$rr=o(`Note:
Loading a model from its configuration file does `),ohe=a("strong"),Irr=o("not"),jrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rhe=a("code"),Drr=o("from_pretrained()"),Nrr=o("to load the model weights."),qrr=l(),the=a("p"),Orr=o("Examples:"),Grr=l(),f(Hw.$$.fragment),Xrr=l(),_o=a("div"),f(Uw.$$.fragment),Vrr=l(),ahe=a("p"),zrr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Wrr=l(),un=a("p"),Qrr=o("The model class to instantiate is selected based on the "),nhe=a("code"),Hrr=o("model_type"),Urr=o(` property of the config object (either
passed as an argument or loaded from `),she=a("code"),Jrr=o("pretrained_model_name_or_path"),Yrr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lhe=a("code"),Krr=o("pretrained_model_name_or_path"),Zrr=o(":"),etr=l(),_e=a("ul"),u0=a("li"),ihe=a("strong"),otr=o("bert"),rtr=o(" \u2014 "),_O=a("a"),ttr=o("TFBertLMHeadModel"),atr=o(" (BERT model)"),ntr=l(),b0=a("li"),dhe=a("strong"),str=o("ctrl"),ltr=o(" \u2014 "),uO=a("a"),itr=o("TFCTRLLMHeadModel"),dtr=o(" (CTRL model)"),ctr=l(),v0=a("li"),che=a("strong"),ftr=o("gpt2"),mtr=o(" \u2014 "),bO=a("a"),gtr=o("TFGPT2LMHeadModel"),htr=o(" (OpenAI GPT-2 model)"),ptr=l(),T0=a("li"),fhe=a("strong"),_tr=o("openai-gpt"),utr=o(" \u2014 "),vO=a("a"),btr=o("TFOpenAIGPTLMHeadModel"),vtr=o(" (OpenAI GPT model)"),Ttr=l(),F0=a("li"),mhe=a("strong"),Ftr=o("rembert"),Ctr=o(" \u2014 "),TO=a("a"),Mtr=o("TFRemBertForCausalLM"),Etr=o(" (RemBERT model)"),ytr=l(),C0=a("li"),ghe=a("strong"),wtr=o("roberta"),Atr=o(" \u2014 "),FO=a("a"),Ltr=o("TFRobertaForCausalLM"),Btr=o(" (RoBERTa model)"),xtr=l(),M0=a("li"),hhe=a("strong"),ktr=o("roformer"),Rtr=o(" \u2014 "),CO=a("a"),Str=o("TFRoFormerForCausalLM"),Ptr=o(" (RoFormer model)"),$tr=l(),E0=a("li"),phe=a("strong"),Itr=o("transfo-xl"),jtr=o(" \u2014 "),MO=a("a"),Dtr=o("TFTransfoXLLMHeadModel"),Ntr=o(" (Transformer-XL model)"),qtr=l(),y0=a("li"),_he=a("strong"),Otr=o("xlm"),Gtr=o(" \u2014 "),EO=a("a"),Xtr=o("TFXLMWithLMHeadModel"),Vtr=o(" (XLM model)"),ztr=l(),w0=a("li"),uhe=a("strong"),Wtr=o("xlnet"),Qtr=o(" \u2014 "),yO=a("a"),Htr=o("TFXLNetLMHeadModel"),Utr=o(" (XLNet model)"),Jtr=l(),bhe=a("p"),Ytr=o("Examples:"),Ktr=l(),f(Jw.$$.fragment),yke=l(),Fc=a("h2"),A0=a("a"),vhe=a("span"),f(Yw.$$.fragment),Ztr=l(),The=a("span"),ear=o("TFAutoModelForImageClassification"),wke=l(),Cr=a("div"),f(Kw.$$.fragment),oar=l(),Cc=a("p"),rar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Fhe=a("code"),tar=o("from_pretrained()"),aar=o("class method or the "),Che=a("code"),nar=o("from_config()"),sar=o(`class
method.`),lar=l(),Zw=a("p"),iar=o("This class cannot be instantiated directly using "),Mhe=a("code"),dar=o("__init__()"),car=o(" (throws an error)."),far=l(),_t=a("div"),f(e6.$$.fragment),mar=l(),Ehe=a("p"),gar=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),har=l(),Mc=a("p"),par=o(`Note:
Loading a model from its configuration file does `),yhe=a("strong"),_ar=o("not"),uar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),whe=a("code"),bar=o("from_pretrained()"),Tar=o("to load the model weights."),Far=l(),Ahe=a("p"),Car=o("Examples:"),Mar=l(),f(o6.$$.fragment),Ear=l(),uo=a("div"),f(r6.$$.fragment),yar=l(),Lhe=a("p"),war=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Aar=l(),bn=a("p"),Lar=o("The model class to instantiate is selected based on the "),Bhe=a("code"),Bar=o("model_type"),xar=o(` property of the config object (either
passed as an argument or loaded from `),xhe=a("code"),kar=o("pretrained_model_name_or_path"),Rar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),khe=a("code"),Sar=o("pretrained_model_name_or_path"),Par=o(":"),$ar=l(),t6=a("ul"),L0=a("li"),Rhe=a("strong"),Iar=o("convnext"),jar=o(" \u2014 "),wO=a("a"),Dar=o("TFConvNextForImageClassification"),Nar=o(" (ConvNext model)"),qar=l(),B0=a("li"),She=a("strong"),Oar=o("vit"),Gar=o(" \u2014 "),AO=a("a"),Xar=o("TFViTForImageClassification"),Var=o(" (ViT model)"),zar=l(),Phe=a("p"),War=o("Examples:"),Qar=l(),f(a6.$$.fragment),Ake=l(),Ec=a("h2"),x0=a("a"),$he=a("span"),f(n6.$$.fragment),Har=l(),Ihe=a("span"),Uar=o("TFAutoModelForMaskedLM"),Lke=l(),Mr=a("div"),f(s6.$$.fragment),Jar=l(),yc=a("p"),Yar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jhe=a("code"),Kar=o("from_pretrained()"),Zar=o("class method or the "),Dhe=a("code"),enr=o("from_config()"),onr=o(`class
method.`),rnr=l(),l6=a("p"),tnr=o("This class cannot be instantiated directly using "),Nhe=a("code"),anr=o("__init__()"),nnr=o(" (throws an error)."),snr=l(),ut=a("div"),f(i6.$$.fragment),lnr=l(),qhe=a("p"),inr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dnr=l(),wc=a("p"),cnr=o(`Note:
Loading a model from its configuration file does `),Ohe=a("strong"),fnr=o("not"),mnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ghe=a("code"),gnr=o("from_pretrained()"),hnr=o("to load the model weights."),pnr=l(),Xhe=a("p"),_nr=o("Examples:"),unr=l(),f(d6.$$.fragment),bnr=l(),bo=a("div"),f(c6.$$.fragment),vnr=l(),Vhe=a("p"),Tnr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Fnr=l(),vn=a("p"),Cnr=o("The model class to instantiate is selected based on the "),zhe=a("code"),Mnr=o("model_type"),Enr=o(` property of the config object (either
passed as an argument or loaded from `),Whe=a("code"),ynr=o("pretrained_model_name_or_path"),wnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qhe=a("code"),Anr=o("pretrained_model_name_or_path"),Lnr=o(":"),Bnr=l(),Y=a("ul"),k0=a("li"),Hhe=a("strong"),xnr=o("albert"),knr=o(" \u2014 "),LO=a("a"),Rnr=o("TFAlbertForMaskedLM"),Snr=o(" (ALBERT model)"),Pnr=l(),R0=a("li"),Uhe=a("strong"),$nr=o("bert"),Inr=o(" \u2014 "),BO=a("a"),jnr=o("TFBertForMaskedLM"),Dnr=o(" (BERT model)"),Nnr=l(),S0=a("li"),Jhe=a("strong"),qnr=o("camembert"),Onr=o(" \u2014 "),xO=a("a"),Gnr=o("TFCamembertForMaskedLM"),Xnr=o(" (CamemBERT model)"),Vnr=l(),P0=a("li"),Yhe=a("strong"),znr=o("convbert"),Wnr=o(" \u2014 "),kO=a("a"),Qnr=o("TFConvBertForMaskedLM"),Hnr=o(" (ConvBERT model)"),Unr=l(),$0=a("li"),Khe=a("strong"),Jnr=o("deberta"),Ynr=o(" \u2014 "),RO=a("a"),Knr=o("TFDebertaForMaskedLM"),Znr=o(" (DeBERTa model)"),esr=l(),I0=a("li"),Zhe=a("strong"),osr=o("deberta-v2"),rsr=o(" \u2014 "),SO=a("a"),tsr=o("TFDebertaV2ForMaskedLM"),asr=o(" (DeBERTa-v2 model)"),nsr=l(),j0=a("li"),epe=a("strong"),ssr=o("distilbert"),lsr=o(" \u2014 "),PO=a("a"),isr=o("TFDistilBertForMaskedLM"),dsr=o(" (DistilBERT model)"),csr=l(),D0=a("li"),ope=a("strong"),fsr=o("electra"),msr=o(" \u2014 "),$O=a("a"),gsr=o("TFElectraForMaskedLM"),hsr=o(" (ELECTRA model)"),psr=l(),N0=a("li"),rpe=a("strong"),_sr=o("flaubert"),usr=o(" \u2014 "),IO=a("a"),bsr=o("TFFlaubertWithLMHeadModel"),vsr=o(" (FlauBERT model)"),Tsr=l(),q0=a("li"),tpe=a("strong"),Fsr=o("funnel"),Csr=o(" \u2014 "),jO=a("a"),Msr=o("TFFunnelForMaskedLM"),Esr=o(" (Funnel Transformer model)"),ysr=l(),O0=a("li"),ape=a("strong"),wsr=o("layoutlm"),Asr=o(" \u2014 "),DO=a("a"),Lsr=o("TFLayoutLMForMaskedLM"),Bsr=o(" (LayoutLM model)"),xsr=l(),G0=a("li"),npe=a("strong"),ksr=o("longformer"),Rsr=o(" \u2014 "),NO=a("a"),Ssr=o("TFLongformerForMaskedLM"),Psr=o(" (Longformer model)"),$sr=l(),X0=a("li"),spe=a("strong"),Isr=o("mobilebert"),jsr=o(" \u2014 "),qO=a("a"),Dsr=o("TFMobileBertForMaskedLM"),Nsr=o(" (MobileBERT model)"),qsr=l(),V0=a("li"),lpe=a("strong"),Osr=o("mpnet"),Gsr=o(" \u2014 "),OO=a("a"),Xsr=o("TFMPNetForMaskedLM"),Vsr=o(" (MPNet model)"),zsr=l(),z0=a("li"),ipe=a("strong"),Wsr=o("rembert"),Qsr=o(" \u2014 "),GO=a("a"),Hsr=o("TFRemBertForMaskedLM"),Usr=o(" (RemBERT model)"),Jsr=l(),W0=a("li"),dpe=a("strong"),Ysr=o("roberta"),Ksr=o(" \u2014 "),XO=a("a"),Zsr=o("TFRobertaForMaskedLM"),elr=o(" (RoBERTa model)"),olr=l(),Q0=a("li"),cpe=a("strong"),rlr=o("roformer"),tlr=o(" \u2014 "),VO=a("a"),alr=o("TFRoFormerForMaskedLM"),nlr=o(" (RoFormer model)"),slr=l(),H0=a("li"),fpe=a("strong"),llr=o("tapas"),ilr=o(" \u2014 "),zO=a("a"),dlr=o("TFTapasForMaskedLM"),clr=o(" (TAPAS model)"),flr=l(),U0=a("li"),mpe=a("strong"),mlr=o("xlm"),glr=o(" \u2014 "),WO=a("a"),hlr=o("TFXLMWithLMHeadModel"),plr=o(" (XLM model)"),_lr=l(),J0=a("li"),gpe=a("strong"),ulr=o("xlm-roberta"),blr=o(" \u2014 "),QO=a("a"),vlr=o("TFXLMRobertaForMaskedLM"),Tlr=o(" (XLM-RoBERTa model)"),Flr=l(),hpe=a("p"),Clr=o("Examples:"),Mlr=l(),f(f6.$$.fragment),Bke=l(),Ac=a("h2"),Y0=a("a"),ppe=a("span"),f(m6.$$.fragment),Elr=l(),_pe=a("span"),ylr=o("TFAutoModelForSeq2SeqLM"),xke=l(),Er=a("div"),f(g6.$$.fragment),wlr=l(),Lc=a("p"),Alr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),upe=a("code"),Llr=o("from_pretrained()"),Blr=o("class method or the "),bpe=a("code"),xlr=o("from_config()"),klr=o(`class
method.`),Rlr=l(),h6=a("p"),Slr=o("This class cannot be instantiated directly using "),vpe=a("code"),Plr=o("__init__()"),$lr=o(" (throws an error)."),Ilr=l(),bt=a("div"),f(p6.$$.fragment),jlr=l(),Tpe=a("p"),Dlr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Nlr=l(),Bc=a("p"),qlr=o(`Note:
Loading a model from its configuration file does `),Fpe=a("strong"),Olr=o("not"),Glr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cpe=a("code"),Xlr=o("from_pretrained()"),Vlr=o("to load the model weights."),zlr=l(),Mpe=a("p"),Wlr=o("Examples:"),Qlr=l(),f(_6.$$.fragment),Hlr=l(),vo=a("div"),f(u6.$$.fragment),Ulr=l(),Epe=a("p"),Jlr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ylr=l(),Tn=a("p"),Klr=o("The model class to instantiate is selected based on the "),ype=a("code"),Zlr=o("model_type"),eir=o(` property of the config object (either
passed as an argument or loaded from `),wpe=a("code"),oir=o("pretrained_model_name_or_path"),rir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ape=a("code"),tir=o("pretrained_model_name_or_path"),air=o(":"),nir=l(),ue=a("ul"),K0=a("li"),Lpe=a("strong"),sir=o("bart"),lir=o(" \u2014 "),HO=a("a"),iir=o("TFBartForConditionalGeneration"),dir=o(" (BART model)"),cir=l(),Z0=a("li"),Bpe=a("strong"),fir=o("blenderbot"),mir=o(" \u2014 "),UO=a("a"),gir=o("TFBlenderbotForConditionalGeneration"),hir=o(" (Blenderbot model)"),pir=l(),eT=a("li"),xpe=a("strong"),_ir=o("blenderbot-small"),uir=o(" \u2014 "),JO=a("a"),bir=o("TFBlenderbotSmallForConditionalGeneration"),vir=o(" (BlenderbotSmall model)"),Tir=l(),oT=a("li"),kpe=a("strong"),Fir=o("encoder-decoder"),Cir=o(" \u2014 "),YO=a("a"),Mir=o("TFEncoderDecoderModel"),Eir=o(" (Encoder decoder model)"),yir=l(),rT=a("li"),Rpe=a("strong"),wir=o("led"),Air=o(" \u2014 "),KO=a("a"),Lir=o("TFLEDForConditionalGeneration"),Bir=o(" (LED model)"),xir=l(),tT=a("li"),Spe=a("strong"),kir=o("marian"),Rir=o(" \u2014 "),ZO=a("a"),Sir=o("TFMarianMTModel"),Pir=o(" (Marian model)"),$ir=l(),aT=a("li"),Ppe=a("strong"),Iir=o("mbart"),jir=o(" \u2014 "),eG=a("a"),Dir=o("TFMBartForConditionalGeneration"),Nir=o(" (mBART model)"),qir=l(),nT=a("li"),$pe=a("strong"),Oir=o("mt5"),Gir=o(" \u2014 "),oG=a("a"),Xir=o("TFMT5ForConditionalGeneration"),Vir=o(" (mT5 model)"),zir=l(),sT=a("li"),Ipe=a("strong"),Wir=o("pegasus"),Qir=o(" \u2014 "),rG=a("a"),Hir=o("TFPegasusForConditionalGeneration"),Uir=o(" (Pegasus model)"),Jir=l(),lT=a("li"),jpe=a("strong"),Yir=o("t5"),Kir=o(" \u2014 "),tG=a("a"),Zir=o("TFT5ForConditionalGeneration"),edr=o(" (T5 model)"),odr=l(),Dpe=a("p"),rdr=o("Examples:"),tdr=l(),f(b6.$$.fragment),kke=l(),xc=a("h2"),iT=a("a"),Npe=a("span"),f(v6.$$.fragment),adr=l(),qpe=a("span"),ndr=o("TFAutoModelForSequenceClassification"),Rke=l(),yr=a("div"),f(T6.$$.fragment),sdr=l(),kc=a("p"),ldr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Ope=a("code"),idr=o("from_pretrained()"),ddr=o("class method or the "),Gpe=a("code"),cdr=o("from_config()"),fdr=o(`class
method.`),mdr=l(),F6=a("p"),gdr=o("This class cannot be instantiated directly using "),Xpe=a("code"),hdr=o("__init__()"),pdr=o(" (throws an error)."),_dr=l(),vt=a("div"),f(C6.$$.fragment),udr=l(),Vpe=a("p"),bdr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),vdr=l(),Rc=a("p"),Tdr=o(`Note:
Loading a model from its configuration file does `),zpe=a("strong"),Fdr=o("not"),Cdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wpe=a("code"),Mdr=o("from_pretrained()"),Edr=o("to load the model weights."),ydr=l(),Qpe=a("p"),wdr=o("Examples:"),Adr=l(),f(M6.$$.fragment),Ldr=l(),To=a("div"),f(E6.$$.fragment),Bdr=l(),Hpe=a("p"),xdr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),kdr=l(),Fn=a("p"),Rdr=o("The model class to instantiate is selected based on the "),Upe=a("code"),Sdr=o("model_type"),Pdr=o(` property of the config object (either
passed as an argument or loaded from `),Jpe=a("code"),$dr=o("pretrained_model_name_or_path"),Idr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ype=a("code"),jdr=o("pretrained_model_name_or_path"),Ddr=o(":"),Ndr=l(),V=a("ul"),dT=a("li"),Kpe=a("strong"),qdr=o("albert"),Odr=o(" \u2014 "),aG=a("a"),Gdr=o("TFAlbertForSequenceClassification"),Xdr=o(" (ALBERT model)"),Vdr=l(),cT=a("li"),Zpe=a("strong"),zdr=o("bert"),Wdr=o(" \u2014 "),nG=a("a"),Qdr=o("TFBertForSequenceClassification"),Hdr=o(" (BERT model)"),Udr=l(),fT=a("li"),e_e=a("strong"),Jdr=o("camembert"),Ydr=o(" \u2014 "),sG=a("a"),Kdr=o("TFCamembertForSequenceClassification"),Zdr=o(" (CamemBERT model)"),ecr=l(),mT=a("li"),o_e=a("strong"),ocr=o("convbert"),rcr=o(" \u2014 "),lG=a("a"),tcr=o("TFConvBertForSequenceClassification"),acr=o(" (ConvBERT model)"),ncr=l(),gT=a("li"),r_e=a("strong"),scr=o("ctrl"),lcr=o(" \u2014 "),iG=a("a"),icr=o("TFCTRLForSequenceClassification"),dcr=o(" (CTRL model)"),ccr=l(),hT=a("li"),t_e=a("strong"),fcr=o("deberta"),mcr=o(" \u2014 "),dG=a("a"),gcr=o("TFDebertaForSequenceClassification"),hcr=o(" (DeBERTa model)"),pcr=l(),pT=a("li"),a_e=a("strong"),_cr=o("deberta-v2"),ucr=o(" \u2014 "),cG=a("a"),bcr=o("TFDebertaV2ForSequenceClassification"),vcr=o(" (DeBERTa-v2 model)"),Tcr=l(),_T=a("li"),n_e=a("strong"),Fcr=o("distilbert"),Ccr=o(" \u2014 "),fG=a("a"),Mcr=o("TFDistilBertForSequenceClassification"),Ecr=o(" (DistilBERT model)"),ycr=l(),uT=a("li"),s_e=a("strong"),wcr=o("electra"),Acr=o(" \u2014 "),mG=a("a"),Lcr=o("TFElectraForSequenceClassification"),Bcr=o(" (ELECTRA model)"),xcr=l(),bT=a("li"),l_e=a("strong"),kcr=o("flaubert"),Rcr=o(" \u2014 "),gG=a("a"),Scr=o("TFFlaubertForSequenceClassification"),Pcr=o(" (FlauBERT model)"),$cr=l(),vT=a("li"),i_e=a("strong"),Icr=o("funnel"),jcr=o(" \u2014 "),hG=a("a"),Dcr=o("TFFunnelForSequenceClassification"),Ncr=o(" (Funnel Transformer model)"),qcr=l(),TT=a("li"),d_e=a("strong"),Ocr=o("gpt2"),Gcr=o(" \u2014 "),pG=a("a"),Xcr=o("TFGPT2ForSequenceClassification"),Vcr=o(" (OpenAI GPT-2 model)"),zcr=l(),FT=a("li"),c_e=a("strong"),Wcr=o("layoutlm"),Qcr=o(" \u2014 "),_G=a("a"),Hcr=o("TFLayoutLMForSequenceClassification"),Ucr=o(" (LayoutLM model)"),Jcr=l(),CT=a("li"),f_e=a("strong"),Ycr=o("longformer"),Kcr=o(" \u2014 "),uG=a("a"),Zcr=o("TFLongformerForSequenceClassification"),efr=o(" (Longformer model)"),ofr=l(),MT=a("li"),m_e=a("strong"),rfr=o("mobilebert"),tfr=o(" \u2014 "),bG=a("a"),afr=o("TFMobileBertForSequenceClassification"),nfr=o(" (MobileBERT model)"),sfr=l(),ET=a("li"),g_e=a("strong"),lfr=o("mpnet"),ifr=o(" \u2014 "),vG=a("a"),dfr=o("TFMPNetForSequenceClassification"),cfr=o(" (MPNet model)"),ffr=l(),yT=a("li"),h_e=a("strong"),mfr=o("openai-gpt"),gfr=o(" \u2014 "),TG=a("a"),hfr=o("TFOpenAIGPTForSequenceClassification"),pfr=o(" (OpenAI GPT model)"),_fr=l(),wT=a("li"),p_e=a("strong"),ufr=o("rembert"),bfr=o(" \u2014 "),FG=a("a"),vfr=o("TFRemBertForSequenceClassification"),Tfr=o(" (RemBERT model)"),Ffr=l(),AT=a("li"),__e=a("strong"),Cfr=o("roberta"),Mfr=o(" \u2014 "),CG=a("a"),Efr=o("TFRobertaForSequenceClassification"),yfr=o(" (RoBERTa model)"),wfr=l(),LT=a("li"),u_e=a("strong"),Afr=o("roformer"),Lfr=o(" \u2014 "),MG=a("a"),Bfr=o("TFRoFormerForSequenceClassification"),xfr=o(" (RoFormer model)"),kfr=l(),BT=a("li"),b_e=a("strong"),Rfr=o("tapas"),Sfr=o(" \u2014 "),EG=a("a"),Pfr=o("TFTapasForSequenceClassification"),$fr=o(" (TAPAS model)"),Ifr=l(),xT=a("li"),v_e=a("strong"),jfr=o("transfo-xl"),Dfr=o(" \u2014 "),yG=a("a"),Nfr=o("TFTransfoXLForSequenceClassification"),qfr=o(" (Transformer-XL model)"),Ofr=l(),kT=a("li"),T_e=a("strong"),Gfr=o("xlm"),Xfr=o(" \u2014 "),wG=a("a"),Vfr=o("TFXLMForSequenceClassification"),zfr=o(" (XLM model)"),Wfr=l(),RT=a("li"),F_e=a("strong"),Qfr=o("xlm-roberta"),Hfr=o(" \u2014 "),AG=a("a"),Ufr=o("TFXLMRobertaForSequenceClassification"),Jfr=o(" (XLM-RoBERTa model)"),Yfr=l(),ST=a("li"),C_e=a("strong"),Kfr=o("xlnet"),Zfr=o(" \u2014 "),LG=a("a"),emr=o("TFXLNetForSequenceClassification"),omr=o(" (XLNet model)"),rmr=l(),M_e=a("p"),tmr=o("Examples:"),amr=l(),f(y6.$$.fragment),Ske=l(),Sc=a("h2"),PT=a("a"),E_e=a("span"),f(w6.$$.fragment),nmr=l(),y_e=a("span"),smr=o("TFAutoModelForMultipleChoice"),Pke=l(),wr=a("div"),f(A6.$$.fragment),lmr=l(),Pc=a("p"),imr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),w_e=a("code"),dmr=o("from_pretrained()"),cmr=o("class method or the "),A_e=a("code"),fmr=o("from_config()"),mmr=o(`class
method.`),gmr=l(),L6=a("p"),hmr=o("This class cannot be instantiated directly using "),L_e=a("code"),pmr=o("__init__()"),_mr=o(" (throws an error)."),umr=l(),Tt=a("div"),f(B6.$$.fragment),bmr=l(),B_e=a("p"),vmr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Tmr=l(),$c=a("p"),Fmr=o(`Note:
Loading a model from its configuration file does `),x_e=a("strong"),Cmr=o("not"),Mmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),k_e=a("code"),Emr=o("from_pretrained()"),ymr=o("to load the model weights."),wmr=l(),R_e=a("p"),Amr=o("Examples:"),Lmr=l(),f(x6.$$.fragment),Bmr=l(),Fo=a("div"),f(k6.$$.fragment),xmr=l(),S_e=a("p"),kmr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Rmr=l(),Cn=a("p"),Smr=o("The model class to instantiate is selected based on the "),P_e=a("code"),Pmr=o("model_type"),$mr=o(` property of the config object (either
passed as an argument or loaded from `),$_e=a("code"),Imr=o("pretrained_model_name_or_path"),jmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I_e=a("code"),Dmr=o("pretrained_model_name_or_path"),Nmr=o(":"),qmr=l(),ae=a("ul"),$T=a("li"),j_e=a("strong"),Omr=o("albert"),Gmr=o(" \u2014 "),BG=a("a"),Xmr=o("TFAlbertForMultipleChoice"),Vmr=o(" (ALBERT model)"),zmr=l(),IT=a("li"),D_e=a("strong"),Wmr=o("bert"),Qmr=o(" \u2014 "),xG=a("a"),Hmr=o("TFBertForMultipleChoice"),Umr=o(" (BERT model)"),Jmr=l(),jT=a("li"),N_e=a("strong"),Ymr=o("camembert"),Kmr=o(" \u2014 "),kG=a("a"),Zmr=o("TFCamembertForMultipleChoice"),egr=o(" (CamemBERT model)"),ogr=l(),DT=a("li"),q_e=a("strong"),rgr=o("convbert"),tgr=o(" \u2014 "),RG=a("a"),agr=o("TFConvBertForMultipleChoice"),ngr=o(" (ConvBERT model)"),sgr=l(),NT=a("li"),O_e=a("strong"),lgr=o("distilbert"),igr=o(" \u2014 "),SG=a("a"),dgr=o("TFDistilBertForMultipleChoice"),cgr=o(" (DistilBERT model)"),fgr=l(),qT=a("li"),G_e=a("strong"),mgr=o("electra"),ggr=o(" \u2014 "),PG=a("a"),hgr=o("TFElectraForMultipleChoice"),pgr=o(" (ELECTRA model)"),_gr=l(),OT=a("li"),X_e=a("strong"),ugr=o("flaubert"),bgr=o(" \u2014 "),$G=a("a"),vgr=o("TFFlaubertForMultipleChoice"),Tgr=o(" (FlauBERT model)"),Fgr=l(),GT=a("li"),V_e=a("strong"),Cgr=o("funnel"),Mgr=o(" \u2014 "),IG=a("a"),Egr=o("TFFunnelForMultipleChoice"),ygr=o(" (Funnel Transformer model)"),wgr=l(),XT=a("li"),z_e=a("strong"),Agr=o("longformer"),Lgr=o(" \u2014 "),jG=a("a"),Bgr=o("TFLongformerForMultipleChoice"),xgr=o(" (Longformer model)"),kgr=l(),VT=a("li"),W_e=a("strong"),Rgr=o("mobilebert"),Sgr=o(" \u2014 "),DG=a("a"),Pgr=o("TFMobileBertForMultipleChoice"),$gr=o(" (MobileBERT model)"),Igr=l(),zT=a("li"),Q_e=a("strong"),jgr=o("mpnet"),Dgr=o(" \u2014 "),NG=a("a"),Ngr=o("TFMPNetForMultipleChoice"),qgr=o(" (MPNet model)"),Ogr=l(),WT=a("li"),H_e=a("strong"),Ggr=o("rembert"),Xgr=o(" \u2014 "),qG=a("a"),Vgr=o("TFRemBertForMultipleChoice"),zgr=o(" (RemBERT model)"),Wgr=l(),QT=a("li"),U_e=a("strong"),Qgr=o("roberta"),Hgr=o(" \u2014 "),OG=a("a"),Ugr=o("TFRobertaForMultipleChoice"),Jgr=o(" (RoBERTa model)"),Ygr=l(),HT=a("li"),J_e=a("strong"),Kgr=o("roformer"),Zgr=o(" \u2014 "),GG=a("a"),ehr=o("TFRoFormerForMultipleChoice"),ohr=o(" (RoFormer model)"),rhr=l(),UT=a("li"),Y_e=a("strong"),thr=o("xlm"),ahr=o(" \u2014 "),XG=a("a"),nhr=o("TFXLMForMultipleChoice"),shr=o(" (XLM model)"),lhr=l(),JT=a("li"),K_e=a("strong"),ihr=o("xlm-roberta"),dhr=o(" \u2014 "),VG=a("a"),chr=o("TFXLMRobertaForMultipleChoice"),fhr=o(" (XLM-RoBERTa model)"),mhr=l(),YT=a("li"),Z_e=a("strong"),ghr=o("xlnet"),hhr=o(" \u2014 "),zG=a("a"),phr=o("TFXLNetForMultipleChoice"),_hr=o(" (XLNet model)"),uhr=l(),eue=a("p"),bhr=o("Examples:"),vhr=l(),f(R6.$$.fragment),$ke=l(),Ic=a("h2"),KT=a("a"),oue=a("span"),f(S6.$$.fragment),Thr=l(),rue=a("span"),Fhr=o("TFAutoModelForTableQuestionAnswering"),Ike=l(),Ar=a("div"),f(P6.$$.fragment),Chr=l(),jc=a("p"),Mhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),tue=a("code"),Ehr=o("from_pretrained()"),yhr=o("class method or the "),aue=a("code"),whr=o("from_config()"),Ahr=o(`class
method.`),Lhr=l(),$6=a("p"),Bhr=o("This class cannot be instantiated directly using "),nue=a("code"),xhr=o("__init__()"),khr=o(" (throws an error)."),Rhr=l(),Ft=a("div"),f(I6.$$.fragment),Shr=l(),sue=a("p"),Phr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$hr=l(),Dc=a("p"),Ihr=o(`Note:
Loading a model from its configuration file does `),lue=a("strong"),jhr=o("not"),Dhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iue=a("code"),Nhr=o("from_pretrained()"),qhr=o("to load the model weights."),Ohr=l(),due=a("p"),Ghr=o("Examples:"),Xhr=l(),f(j6.$$.fragment),Vhr=l(),Co=a("div"),f(D6.$$.fragment),zhr=l(),cue=a("p"),Whr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Qhr=l(),Mn=a("p"),Hhr=o("The model class to instantiate is selected based on the "),fue=a("code"),Uhr=o("model_type"),Jhr=o(` property of the config object (either
passed as an argument or loaded from `),mue=a("code"),Yhr=o("pretrained_model_name_or_path"),Khr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gue=a("code"),Zhr=o("pretrained_model_name_or_path"),epr=o(":"),opr=l(),hue=a("ul"),ZT=a("li"),pue=a("strong"),rpr=o("tapas"),tpr=o(" \u2014 "),WG=a("a"),apr=o("TFTapasForQuestionAnswering"),npr=o(" (TAPAS model)"),spr=l(),_ue=a("p"),lpr=o("Examples:"),ipr=l(),f(N6.$$.fragment),jke=l(),Nc=a("h2"),eF=a("a"),uue=a("span"),f(q6.$$.fragment),dpr=l(),bue=a("span"),cpr=o("TFAutoModelForTokenClassification"),Dke=l(),Lr=a("div"),f(O6.$$.fragment),fpr=l(),qc=a("p"),mpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),vue=a("code"),gpr=o("from_pretrained()"),hpr=o("class method or the "),Tue=a("code"),ppr=o("from_config()"),_pr=o(`class
method.`),upr=l(),G6=a("p"),bpr=o("This class cannot be instantiated directly using "),Fue=a("code"),vpr=o("__init__()"),Tpr=o(" (throws an error)."),Fpr=l(),Ct=a("div"),f(X6.$$.fragment),Cpr=l(),Cue=a("p"),Mpr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Epr=l(),Oc=a("p"),ypr=o(`Note:
Loading a model from its configuration file does `),Mue=a("strong"),wpr=o("not"),Apr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eue=a("code"),Lpr=o("from_pretrained()"),Bpr=o("to load the model weights."),xpr=l(),yue=a("p"),kpr=o("Examples:"),Rpr=l(),f(V6.$$.fragment),Spr=l(),Mo=a("div"),f(z6.$$.fragment),Ppr=l(),wue=a("p"),$pr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ipr=l(),En=a("p"),jpr=o("The model class to instantiate is selected based on the "),Aue=a("code"),Dpr=o("model_type"),Npr=o(` property of the config object (either
passed as an argument or loaded from `),Lue=a("code"),qpr=o("pretrained_model_name_or_path"),Opr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bue=a("code"),Gpr=o("pretrained_model_name_or_path"),Xpr=o(":"),Vpr=l(),K=a("ul"),oF=a("li"),xue=a("strong"),zpr=o("albert"),Wpr=o(" \u2014 "),QG=a("a"),Qpr=o("TFAlbertForTokenClassification"),Hpr=o(" (ALBERT model)"),Upr=l(),rF=a("li"),kue=a("strong"),Jpr=o("bert"),Ypr=o(" \u2014 "),HG=a("a"),Kpr=o("TFBertForTokenClassification"),Zpr=o(" (BERT model)"),e_r=l(),tF=a("li"),Rue=a("strong"),o_r=o("camembert"),r_r=o(" \u2014 "),UG=a("a"),t_r=o("TFCamembertForTokenClassification"),a_r=o(" (CamemBERT model)"),n_r=l(),aF=a("li"),Sue=a("strong"),s_r=o("convbert"),l_r=o(" \u2014 "),JG=a("a"),i_r=o("TFConvBertForTokenClassification"),d_r=o(" (ConvBERT model)"),c_r=l(),nF=a("li"),Pue=a("strong"),f_r=o("deberta"),m_r=o(" \u2014 "),YG=a("a"),g_r=o("TFDebertaForTokenClassification"),h_r=o(" (DeBERTa model)"),p_r=l(),sF=a("li"),$ue=a("strong"),__r=o("deberta-v2"),u_r=o(" \u2014 "),KG=a("a"),b_r=o("TFDebertaV2ForTokenClassification"),v_r=o(" (DeBERTa-v2 model)"),T_r=l(),lF=a("li"),Iue=a("strong"),F_r=o("distilbert"),C_r=o(" \u2014 "),ZG=a("a"),M_r=o("TFDistilBertForTokenClassification"),E_r=o(" (DistilBERT model)"),y_r=l(),iF=a("li"),jue=a("strong"),w_r=o("electra"),A_r=o(" \u2014 "),eX=a("a"),L_r=o("TFElectraForTokenClassification"),B_r=o(" (ELECTRA model)"),x_r=l(),dF=a("li"),Due=a("strong"),k_r=o("flaubert"),R_r=o(" \u2014 "),oX=a("a"),S_r=o("TFFlaubertForTokenClassification"),P_r=o(" (FlauBERT model)"),$_r=l(),cF=a("li"),Nue=a("strong"),I_r=o("funnel"),j_r=o(" \u2014 "),rX=a("a"),D_r=o("TFFunnelForTokenClassification"),N_r=o(" (Funnel Transformer model)"),q_r=l(),fF=a("li"),que=a("strong"),O_r=o("layoutlm"),G_r=o(" \u2014 "),tX=a("a"),X_r=o("TFLayoutLMForTokenClassification"),V_r=o(" (LayoutLM model)"),z_r=l(),mF=a("li"),Oue=a("strong"),W_r=o("longformer"),Q_r=o(" \u2014 "),aX=a("a"),H_r=o("TFLongformerForTokenClassification"),U_r=o(" (Longformer model)"),J_r=l(),gF=a("li"),Gue=a("strong"),Y_r=o("mobilebert"),K_r=o(" \u2014 "),nX=a("a"),Z_r=o("TFMobileBertForTokenClassification"),eur=o(" (MobileBERT model)"),our=l(),hF=a("li"),Xue=a("strong"),rur=o("mpnet"),tur=o(" \u2014 "),sX=a("a"),aur=o("TFMPNetForTokenClassification"),nur=o(" (MPNet model)"),sur=l(),pF=a("li"),Vue=a("strong"),lur=o("rembert"),iur=o(" \u2014 "),lX=a("a"),dur=o("TFRemBertForTokenClassification"),cur=o(" (RemBERT model)"),fur=l(),_F=a("li"),zue=a("strong"),mur=o("roberta"),gur=o(" \u2014 "),iX=a("a"),hur=o("TFRobertaForTokenClassification"),pur=o(" (RoBERTa model)"),_ur=l(),uF=a("li"),Wue=a("strong"),uur=o("roformer"),bur=o(" \u2014 "),dX=a("a"),vur=o("TFRoFormerForTokenClassification"),Tur=o(" (RoFormer model)"),Fur=l(),bF=a("li"),Que=a("strong"),Cur=o("xlm"),Mur=o(" \u2014 "),cX=a("a"),Eur=o("TFXLMForTokenClassification"),yur=o(" (XLM model)"),wur=l(),vF=a("li"),Hue=a("strong"),Aur=o("xlm-roberta"),Lur=o(" \u2014 "),fX=a("a"),Bur=o("TFXLMRobertaForTokenClassification"),xur=o(" (XLM-RoBERTa model)"),kur=l(),TF=a("li"),Uue=a("strong"),Rur=o("xlnet"),Sur=o(" \u2014 "),mX=a("a"),Pur=o("TFXLNetForTokenClassification"),$ur=o(" (XLNet model)"),Iur=l(),Jue=a("p"),jur=o("Examples:"),Dur=l(),f(W6.$$.fragment),Nke=l(),Gc=a("h2"),FF=a("a"),Yue=a("span"),f(Q6.$$.fragment),Nur=l(),Kue=a("span"),qur=o("TFAutoModelForQuestionAnswering"),qke=l(),Br=a("div"),f(H6.$$.fragment),Our=l(),Xc=a("p"),Gur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Zue=a("code"),Xur=o("from_pretrained()"),Vur=o("class method or the "),e1e=a("code"),zur=o("from_config()"),Wur=o(`class
method.`),Qur=l(),U6=a("p"),Hur=o("This class cannot be instantiated directly using "),o1e=a("code"),Uur=o("__init__()"),Jur=o(" (throws an error)."),Yur=l(),Mt=a("div"),f(J6.$$.fragment),Kur=l(),r1e=a("p"),Zur=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),e1r=l(),Vc=a("p"),o1r=o(`Note:
Loading a model from its configuration file does `),t1e=a("strong"),r1r=o("not"),t1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),a1e=a("code"),a1r=o("from_pretrained()"),n1r=o("to load the model weights."),s1r=l(),n1e=a("p"),l1r=o("Examples:"),i1r=l(),f(Y6.$$.fragment),d1r=l(),Eo=a("div"),f(K6.$$.fragment),c1r=l(),s1e=a("p"),f1r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),m1r=l(),yn=a("p"),g1r=o("The model class to instantiate is selected based on the "),l1e=a("code"),h1r=o("model_type"),p1r=o(` property of the config object (either
passed as an argument or loaded from `),i1e=a("code"),_1r=o("pretrained_model_name_or_path"),u1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d1e=a("code"),b1r=o("pretrained_model_name_or_path"),v1r=o(":"),T1r=l(),Z=a("ul"),CF=a("li"),c1e=a("strong"),F1r=o("albert"),C1r=o(" \u2014 "),gX=a("a"),M1r=o("TFAlbertForQuestionAnswering"),E1r=o(" (ALBERT model)"),y1r=l(),MF=a("li"),f1e=a("strong"),w1r=o("bert"),A1r=o(" \u2014 "),hX=a("a"),L1r=o("TFBertForQuestionAnswering"),B1r=o(" (BERT model)"),x1r=l(),EF=a("li"),m1e=a("strong"),k1r=o("camembert"),R1r=o(" \u2014 "),pX=a("a"),S1r=o("TFCamembertForQuestionAnswering"),P1r=o(" (CamemBERT model)"),$1r=l(),yF=a("li"),g1e=a("strong"),I1r=o("convbert"),j1r=o(" \u2014 "),_X=a("a"),D1r=o("TFConvBertForQuestionAnswering"),N1r=o(" (ConvBERT model)"),q1r=l(),wF=a("li"),h1e=a("strong"),O1r=o("deberta"),G1r=o(" \u2014 "),uX=a("a"),X1r=o("TFDebertaForQuestionAnswering"),V1r=o(" (DeBERTa model)"),z1r=l(),AF=a("li"),p1e=a("strong"),W1r=o("deberta-v2"),Q1r=o(" \u2014 "),bX=a("a"),H1r=o("TFDebertaV2ForQuestionAnswering"),U1r=o(" (DeBERTa-v2 model)"),J1r=l(),LF=a("li"),_1e=a("strong"),Y1r=o("distilbert"),K1r=o(" \u2014 "),vX=a("a"),Z1r=o("TFDistilBertForQuestionAnswering"),e7r=o(" (DistilBERT model)"),o7r=l(),BF=a("li"),u1e=a("strong"),r7r=o("electra"),t7r=o(" \u2014 "),TX=a("a"),a7r=o("TFElectraForQuestionAnswering"),n7r=o(" (ELECTRA model)"),s7r=l(),xF=a("li"),b1e=a("strong"),l7r=o("flaubert"),i7r=o(" \u2014 "),FX=a("a"),d7r=o("TFFlaubertForQuestionAnsweringSimple"),c7r=o(" (FlauBERT model)"),f7r=l(),kF=a("li"),v1e=a("strong"),m7r=o("funnel"),g7r=o(" \u2014 "),CX=a("a"),h7r=o("TFFunnelForQuestionAnswering"),p7r=o(" (Funnel Transformer model)"),_7r=l(),RF=a("li"),T1e=a("strong"),u7r=o("longformer"),b7r=o(" \u2014 "),MX=a("a"),v7r=o("TFLongformerForQuestionAnswering"),T7r=o(" (Longformer model)"),F7r=l(),SF=a("li"),F1e=a("strong"),C7r=o("mobilebert"),M7r=o(" \u2014 "),EX=a("a"),E7r=o("TFMobileBertForQuestionAnswering"),y7r=o(" (MobileBERT model)"),w7r=l(),PF=a("li"),C1e=a("strong"),A7r=o("mpnet"),L7r=o(" \u2014 "),yX=a("a"),B7r=o("TFMPNetForQuestionAnswering"),x7r=o(" (MPNet model)"),k7r=l(),$F=a("li"),M1e=a("strong"),R7r=o("rembert"),S7r=o(" \u2014 "),wX=a("a"),P7r=o("TFRemBertForQuestionAnswering"),$7r=o(" (RemBERT model)"),I7r=l(),IF=a("li"),E1e=a("strong"),j7r=o("roberta"),D7r=o(" \u2014 "),AX=a("a"),N7r=o("TFRobertaForQuestionAnswering"),q7r=o(" (RoBERTa model)"),O7r=l(),jF=a("li"),y1e=a("strong"),G7r=o("roformer"),X7r=o(" \u2014 "),LX=a("a"),V7r=o("TFRoFormerForQuestionAnswering"),z7r=o(" (RoFormer model)"),W7r=l(),DF=a("li"),w1e=a("strong"),Q7r=o("xlm"),H7r=o(" \u2014 "),BX=a("a"),U7r=o("TFXLMForQuestionAnsweringSimple"),J7r=o(" (XLM model)"),Y7r=l(),NF=a("li"),A1e=a("strong"),K7r=o("xlm-roberta"),Z7r=o(" \u2014 "),xX=a("a"),ebr=o("TFXLMRobertaForQuestionAnswering"),obr=o(" (XLM-RoBERTa model)"),rbr=l(),qF=a("li"),L1e=a("strong"),tbr=o("xlnet"),abr=o(" \u2014 "),kX=a("a"),nbr=o("TFXLNetForQuestionAnsweringSimple"),sbr=o(" (XLNet model)"),lbr=l(),B1e=a("p"),ibr=o("Examples:"),dbr=l(),f(Z6.$$.fragment),Oke=l(),zc=a("h2"),OF=a("a"),x1e=a("span"),f(eA.$$.fragment),cbr=l(),k1e=a("span"),fbr=o("TFAutoModelForVision2Seq"),Gke=l(),xr=a("div"),f(oA.$$.fragment),mbr=l(),Wc=a("p"),gbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),R1e=a("code"),hbr=o("from_pretrained()"),pbr=o("class method or the "),S1e=a("code"),_br=o("from_config()"),ubr=o(`class
method.`),bbr=l(),rA=a("p"),vbr=o("This class cannot be instantiated directly using "),P1e=a("code"),Tbr=o("__init__()"),Fbr=o(" (throws an error)."),Cbr=l(),Et=a("div"),f(tA.$$.fragment),Mbr=l(),$1e=a("p"),Ebr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ybr=l(),Qc=a("p"),wbr=o(`Note:
Loading a model from its configuration file does `),I1e=a("strong"),Abr=o("not"),Lbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),j1e=a("code"),Bbr=o("from_pretrained()"),xbr=o("to load the model weights."),kbr=l(),D1e=a("p"),Rbr=o("Examples:"),Sbr=l(),f(aA.$$.fragment),Pbr=l(),yo=a("div"),f(nA.$$.fragment),$br=l(),N1e=a("p"),Ibr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),jbr=l(),wn=a("p"),Dbr=o("The model class to instantiate is selected based on the "),q1e=a("code"),Nbr=o("model_type"),qbr=o(` property of the config object (either
passed as an argument or loaded from `),O1e=a("code"),Obr=o("pretrained_model_name_or_path"),Gbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G1e=a("code"),Xbr=o("pretrained_model_name_or_path"),Vbr=o(":"),zbr=l(),X1e=a("ul"),GF=a("li"),V1e=a("strong"),Wbr=o("vision-encoder-decoder"),Qbr=o(" \u2014 "),RX=a("a"),Hbr=o("TFVisionEncoderDecoderModel"),Ubr=o(" (Vision Encoder decoder model)"),Jbr=l(),z1e=a("p"),Ybr=o("Examples:"),Kbr=l(),f(sA.$$.fragment),Xke=l(),Hc=a("h2"),XF=a("a"),W1e=a("span"),f(lA.$$.fragment),Zbr=l(),Q1e=a("span"),e5r=o("TFAutoModelForSpeechSeq2Seq"),Vke=l(),kr=a("div"),f(iA.$$.fragment),o5r=l(),Uc=a("p"),r5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),H1e=a("code"),t5r=o("from_pretrained()"),a5r=o("class method or the "),U1e=a("code"),n5r=o("from_config()"),s5r=o(`class
method.`),l5r=l(),dA=a("p"),i5r=o("This class cannot be instantiated directly using "),J1e=a("code"),d5r=o("__init__()"),c5r=o(" (throws an error)."),f5r=l(),yt=a("div"),f(cA.$$.fragment),m5r=l(),Y1e=a("p"),g5r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),h5r=l(),Jc=a("p"),p5r=o(`Note:
Loading a model from its configuration file does `),K1e=a("strong"),_5r=o("not"),u5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Z1e=a("code"),b5r=o("from_pretrained()"),v5r=o("to load the model weights."),T5r=l(),e7e=a("p"),F5r=o("Examples:"),C5r=l(),f(fA.$$.fragment),M5r=l(),wo=a("div"),f(mA.$$.fragment),E5r=l(),o7e=a("p"),y5r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),w5r=l(),An=a("p"),A5r=o("The model class to instantiate is selected based on the "),r7e=a("code"),L5r=o("model_type"),B5r=o(` property of the config object (either
passed as an argument or loaded from `),t7e=a("code"),x5r=o("pretrained_model_name_or_path"),k5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a7e=a("code"),R5r=o("pretrained_model_name_or_path"),S5r=o(":"),P5r=l(),n7e=a("ul"),VF=a("li"),s7e=a("strong"),$5r=o("speech_to_text"),I5r=o(" \u2014 "),SX=a("a"),j5r=o("TFSpeech2TextForConditionalGeneration"),D5r=o(" (Speech2Text model)"),N5r=l(),l7e=a("p"),q5r=o("Examples:"),O5r=l(),f(gA.$$.fragment),zke=l(),Yc=a("h2"),zF=a("a"),i7e=a("span"),f(hA.$$.fragment),G5r=l(),d7e=a("span"),X5r=o("FlaxAutoModel"),Wke=l(),Rr=a("div"),f(pA.$$.fragment),V5r=l(),Kc=a("p"),z5r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),c7e=a("code"),W5r=o("from_pretrained()"),Q5r=o("class method or the "),f7e=a("code"),H5r=o("from_config()"),U5r=o(`class
method.`),J5r=l(),_A=a("p"),Y5r=o("This class cannot be instantiated directly using "),m7e=a("code"),K5r=o("__init__()"),Z5r=o(" (throws an error)."),e2r=l(),wt=a("div"),f(uA.$$.fragment),o2r=l(),g7e=a("p"),r2r=o("Instantiates one of the base model classes of the library from a configuration."),t2r=l(),Zc=a("p"),a2r=o(`Note:
Loading a model from its configuration file does `),h7e=a("strong"),n2r=o("not"),s2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),p7e=a("code"),l2r=o("from_pretrained()"),i2r=o("to load the model weights."),d2r=l(),_7e=a("p"),c2r=o("Examples:"),f2r=l(),f(bA.$$.fragment),m2r=l(),Ao=a("div"),f(vA.$$.fragment),g2r=l(),u7e=a("p"),h2r=o("Instantiate one of the base model classes of the library from a pretrained model."),p2r=l(),Ln=a("p"),_2r=o("The model class to instantiate is selected based on the "),b7e=a("code"),u2r=o("model_type"),b2r=o(` property of the config object (either
passed as an argument or loaded from `),v7e=a("code"),v2r=o("pretrained_model_name_or_path"),T2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T7e=a("code"),F2r=o("pretrained_model_name_or_path"),C2r=o(":"),M2r=l(),z=a("ul"),WF=a("li"),F7e=a("strong"),E2r=o("albert"),y2r=o(" \u2014 "),PX=a("a"),w2r=o("FlaxAlbertModel"),A2r=o(" (ALBERT model)"),L2r=l(),QF=a("li"),C7e=a("strong"),B2r=o("bart"),x2r=o(" \u2014 "),$X=a("a"),k2r=o("FlaxBartModel"),R2r=o(" (BART model)"),S2r=l(),HF=a("li"),M7e=a("strong"),P2r=o("beit"),$2r=o(" \u2014 "),IX=a("a"),I2r=o("FlaxBeitModel"),j2r=o(" (BEiT model)"),D2r=l(),UF=a("li"),E7e=a("strong"),N2r=o("bert"),q2r=o(" \u2014 "),jX=a("a"),O2r=o("FlaxBertModel"),G2r=o(" (BERT model)"),X2r=l(),JF=a("li"),y7e=a("strong"),V2r=o("big_bird"),z2r=o(" \u2014 "),DX=a("a"),W2r=o("FlaxBigBirdModel"),Q2r=o(" (BigBird model)"),H2r=l(),YF=a("li"),w7e=a("strong"),U2r=o("blenderbot"),J2r=o(" \u2014 "),NX=a("a"),Y2r=o("FlaxBlenderbotModel"),K2r=o(" (Blenderbot model)"),Z2r=l(),KF=a("li"),A7e=a("strong"),evr=o("blenderbot-small"),ovr=o(" \u2014 "),qX=a("a"),rvr=o("FlaxBlenderbotSmallModel"),tvr=o(" (BlenderbotSmall model)"),avr=l(),ZF=a("li"),L7e=a("strong"),nvr=o("clip"),svr=o(" \u2014 "),OX=a("a"),lvr=o("FlaxCLIPModel"),ivr=o(" (CLIP model)"),dvr=l(),eC=a("li"),B7e=a("strong"),cvr=o("distilbert"),fvr=o(" \u2014 "),GX=a("a"),mvr=o("FlaxDistilBertModel"),gvr=o(" (DistilBERT model)"),hvr=l(),oC=a("li"),x7e=a("strong"),pvr=o("electra"),_vr=o(" \u2014 "),XX=a("a"),uvr=o("FlaxElectraModel"),bvr=o(" (ELECTRA model)"),vvr=l(),rC=a("li"),k7e=a("strong"),Tvr=o("gpt2"),Fvr=o(" \u2014 "),VX=a("a"),Cvr=o("FlaxGPT2Model"),Mvr=o(" (OpenAI GPT-2 model)"),Evr=l(),tC=a("li"),R7e=a("strong"),yvr=o("gpt_neo"),wvr=o(" \u2014 "),zX=a("a"),Avr=o("FlaxGPTNeoModel"),Lvr=o(" (GPT Neo model)"),Bvr=l(),aC=a("li"),S7e=a("strong"),xvr=o("gptj"),kvr=o(" \u2014 "),WX=a("a"),Rvr=o("FlaxGPTJModel"),Svr=o(" (GPT-J model)"),Pvr=l(),nC=a("li"),P7e=a("strong"),$vr=o("marian"),Ivr=o(" \u2014 "),QX=a("a"),jvr=o("FlaxMarianModel"),Dvr=o(" (Marian model)"),Nvr=l(),sC=a("li"),$7e=a("strong"),qvr=o("mbart"),Ovr=o(" \u2014 "),HX=a("a"),Gvr=o("FlaxMBartModel"),Xvr=o(" (mBART model)"),Vvr=l(),lC=a("li"),I7e=a("strong"),zvr=o("mt5"),Wvr=o(" \u2014 "),UX=a("a"),Qvr=o("FlaxMT5Model"),Hvr=o(" (mT5 model)"),Uvr=l(),iC=a("li"),j7e=a("strong"),Jvr=o("pegasus"),Yvr=o(" \u2014 "),JX=a("a"),Kvr=o("FlaxPegasusModel"),Zvr=o(" (Pegasus model)"),e0r=l(),dC=a("li"),D7e=a("strong"),o0r=o("roberta"),r0r=o(" \u2014 "),YX=a("a"),t0r=o("FlaxRobertaModel"),a0r=o(" (RoBERTa model)"),n0r=l(),cC=a("li"),N7e=a("strong"),s0r=o("roformer"),l0r=o(" \u2014 "),KX=a("a"),i0r=o("FlaxRoFormerModel"),d0r=o(" (RoFormer model)"),c0r=l(),fC=a("li"),q7e=a("strong"),f0r=o("t5"),m0r=o(" \u2014 "),ZX=a("a"),g0r=o("FlaxT5Model"),h0r=o(" (T5 model)"),p0r=l(),mC=a("li"),O7e=a("strong"),_0r=o("vision-text-dual-encoder"),u0r=o(" \u2014 "),eV=a("a"),b0r=o("FlaxVisionTextDualEncoderModel"),v0r=o(" (VisionTextDualEncoder model)"),T0r=l(),gC=a("li"),G7e=a("strong"),F0r=o("vit"),C0r=o(" \u2014 "),oV=a("a"),M0r=o("FlaxViTModel"),E0r=o(" (ViT model)"),y0r=l(),hC=a("li"),X7e=a("strong"),w0r=o("wav2vec2"),A0r=o(" \u2014 "),rV=a("a"),L0r=o("FlaxWav2Vec2Model"),B0r=o(" (Wav2Vec2 model)"),x0r=l(),pC=a("li"),V7e=a("strong"),k0r=o("xglm"),R0r=o(" \u2014 "),tV=a("a"),S0r=o("FlaxXGLMModel"),P0r=o(" (XGLM model)"),$0r=l(),_C=a("li"),z7e=a("strong"),I0r=o("xlm-roberta"),j0r=o(" \u2014 "),aV=a("a"),D0r=o("FlaxXLMRobertaModel"),N0r=o(" (XLM-RoBERTa model)"),q0r=l(),W7e=a("p"),O0r=o("Examples:"),G0r=l(),f(TA.$$.fragment),Qke=l(),ef=a("h2"),uC=a("a"),Q7e=a("span"),f(FA.$$.fragment),X0r=l(),H7e=a("span"),V0r=o("FlaxAutoModelForCausalLM"),Hke=l(),Sr=a("div"),f(CA.$$.fragment),z0r=l(),of=a("p"),W0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),U7e=a("code"),Q0r=o("from_pretrained()"),H0r=o("class method or the "),J7e=a("code"),U0r=o("from_config()"),J0r=o(`class
method.`),Y0r=l(),MA=a("p"),K0r=o("This class cannot be instantiated directly using "),Y7e=a("code"),Z0r=o("__init__()"),eTr=o(" (throws an error)."),oTr=l(),At=a("div"),f(EA.$$.fragment),rTr=l(),K7e=a("p"),tTr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),aTr=l(),rf=a("p"),nTr=o(`Note:
Loading a model from its configuration file does `),Z7e=a("strong"),sTr=o("not"),lTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ebe=a("code"),iTr=o("from_pretrained()"),dTr=o("to load the model weights."),cTr=l(),obe=a("p"),fTr=o("Examples:"),mTr=l(),f(yA.$$.fragment),gTr=l(),Lo=a("div"),f(wA.$$.fragment),hTr=l(),rbe=a("p"),pTr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),_Tr=l(),Bn=a("p"),uTr=o("The model class to instantiate is selected based on the "),tbe=a("code"),bTr=o("model_type"),vTr=o(` property of the config object (either
passed as an argument or loaded from `),abe=a("code"),TTr=o("pretrained_model_name_or_path"),FTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=a("code"),CTr=o("pretrained_model_name_or_path"),MTr=o(":"),ETr=l(),xn=a("ul"),bC=a("li"),sbe=a("strong"),yTr=o("gpt2"),wTr=o(" \u2014 "),nV=a("a"),ATr=o("FlaxGPT2LMHeadModel"),LTr=o(" (OpenAI GPT-2 model)"),BTr=l(),vC=a("li"),lbe=a("strong"),xTr=o("gpt_neo"),kTr=o(" \u2014 "),sV=a("a"),RTr=o("FlaxGPTNeoForCausalLM"),STr=o(" (GPT Neo model)"),PTr=l(),TC=a("li"),ibe=a("strong"),$Tr=o("gptj"),ITr=o(" \u2014 "),lV=a("a"),jTr=o("FlaxGPTJForCausalLM"),DTr=o(" (GPT-J model)"),NTr=l(),FC=a("li"),dbe=a("strong"),qTr=o("xglm"),OTr=o(" \u2014 "),iV=a("a"),GTr=o("FlaxXGLMForCausalLM"),XTr=o(" (XGLM model)"),VTr=l(),cbe=a("p"),zTr=o("Examples:"),WTr=l(),f(AA.$$.fragment),Uke=l(),tf=a("h2"),CC=a("a"),fbe=a("span"),f(LA.$$.fragment),QTr=l(),mbe=a("span"),HTr=o("FlaxAutoModelForPreTraining"),Jke=l(),Pr=a("div"),f(BA.$$.fragment),UTr=l(),af=a("p"),JTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gbe=a("code"),YTr=o("from_pretrained()"),KTr=o("class method or the "),hbe=a("code"),ZTr=o("from_config()"),eFr=o(`class
method.`),oFr=l(),xA=a("p"),rFr=o("This class cannot be instantiated directly using "),pbe=a("code"),tFr=o("__init__()"),aFr=o(" (throws an error)."),nFr=l(),Lt=a("div"),f(kA.$$.fragment),sFr=l(),_be=a("p"),lFr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),iFr=l(),nf=a("p"),dFr=o(`Note:
Loading a model from its configuration file does `),ube=a("strong"),cFr=o("not"),fFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bbe=a("code"),mFr=o("from_pretrained()"),gFr=o("to load the model weights."),hFr=l(),vbe=a("p"),pFr=o("Examples:"),_Fr=l(),f(RA.$$.fragment),uFr=l(),Bo=a("div"),f(SA.$$.fragment),bFr=l(),Tbe=a("p"),vFr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),TFr=l(),kn=a("p"),FFr=o("The model class to instantiate is selected based on the "),Fbe=a("code"),CFr=o("model_type"),MFr=o(` property of the config object (either
passed as an argument or loaded from `),Cbe=a("code"),EFr=o("pretrained_model_name_or_path"),yFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mbe=a("code"),wFr=o("pretrained_model_name_or_path"),AFr=o(":"),LFr=l(),ce=a("ul"),MC=a("li"),Ebe=a("strong"),BFr=o("albert"),xFr=o(" \u2014 "),dV=a("a"),kFr=o("FlaxAlbertForPreTraining"),RFr=o(" (ALBERT model)"),SFr=l(),EC=a("li"),ybe=a("strong"),PFr=o("bart"),$Fr=o(" \u2014 "),cV=a("a"),IFr=o("FlaxBartForConditionalGeneration"),jFr=o(" (BART model)"),DFr=l(),yC=a("li"),wbe=a("strong"),NFr=o("bert"),qFr=o(" \u2014 "),fV=a("a"),OFr=o("FlaxBertForPreTraining"),GFr=o(" (BERT model)"),XFr=l(),wC=a("li"),Abe=a("strong"),VFr=o("big_bird"),zFr=o(" \u2014 "),mV=a("a"),WFr=o("FlaxBigBirdForPreTraining"),QFr=o(" (BigBird model)"),HFr=l(),AC=a("li"),Lbe=a("strong"),UFr=o("electra"),JFr=o(" \u2014 "),gV=a("a"),YFr=o("FlaxElectraForPreTraining"),KFr=o(" (ELECTRA model)"),ZFr=l(),LC=a("li"),Bbe=a("strong"),eCr=o("mbart"),oCr=o(" \u2014 "),hV=a("a"),rCr=o("FlaxMBartForConditionalGeneration"),tCr=o(" (mBART model)"),aCr=l(),BC=a("li"),xbe=a("strong"),nCr=o("mt5"),sCr=o(" \u2014 "),pV=a("a"),lCr=o("FlaxMT5ForConditionalGeneration"),iCr=o(" (mT5 model)"),dCr=l(),xC=a("li"),kbe=a("strong"),cCr=o("roberta"),fCr=o(" \u2014 "),_V=a("a"),mCr=o("FlaxRobertaForMaskedLM"),gCr=o(" (RoBERTa model)"),hCr=l(),kC=a("li"),Rbe=a("strong"),pCr=o("roformer"),_Cr=o(" \u2014 "),uV=a("a"),uCr=o("FlaxRoFormerForMaskedLM"),bCr=o(" (RoFormer model)"),vCr=l(),RC=a("li"),Sbe=a("strong"),TCr=o("t5"),FCr=o(" \u2014 "),bV=a("a"),CCr=o("FlaxT5ForConditionalGeneration"),MCr=o(" (T5 model)"),ECr=l(),SC=a("li"),Pbe=a("strong"),yCr=o("wav2vec2"),wCr=o(" \u2014 "),vV=a("a"),ACr=o("FlaxWav2Vec2ForPreTraining"),LCr=o(" (Wav2Vec2 model)"),BCr=l(),PC=a("li"),$be=a("strong"),xCr=o("xlm-roberta"),kCr=o(" \u2014 "),TV=a("a"),RCr=o("FlaxXLMRobertaForMaskedLM"),SCr=o(" (XLM-RoBERTa model)"),PCr=l(),Ibe=a("p"),$Cr=o("Examples:"),ICr=l(),f(PA.$$.fragment),Yke=l(),sf=a("h2"),$C=a("a"),jbe=a("span"),f($A.$$.fragment),jCr=l(),Dbe=a("span"),DCr=o("FlaxAutoModelForMaskedLM"),Kke=l(),$r=a("div"),f(IA.$$.fragment),NCr=l(),lf=a("p"),qCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Nbe=a("code"),OCr=o("from_pretrained()"),GCr=o("class method or the "),qbe=a("code"),XCr=o("from_config()"),VCr=o(`class
method.`),zCr=l(),jA=a("p"),WCr=o("This class cannot be instantiated directly using "),Obe=a("code"),QCr=o("__init__()"),HCr=o(" (throws an error)."),UCr=l(),Bt=a("div"),f(DA.$$.fragment),JCr=l(),Gbe=a("p"),YCr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),KCr=l(),df=a("p"),ZCr=o(`Note:
Loading a model from its configuration file does `),Xbe=a("strong"),eMr=o("not"),oMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vbe=a("code"),rMr=o("from_pretrained()"),tMr=o("to load the model weights."),aMr=l(),zbe=a("p"),nMr=o("Examples:"),sMr=l(),f(NA.$$.fragment),lMr=l(),xo=a("div"),f(qA.$$.fragment),iMr=l(),Wbe=a("p"),dMr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),cMr=l(),Rn=a("p"),fMr=o("The model class to instantiate is selected based on the "),Qbe=a("code"),mMr=o("model_type"),gMr=o(` property of the config object (either
passed as an argument or loaded from `),Hbe=a("code"),hMr=o("pretrained_model_name_or_path"),pMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ube=a("code"),_Mr=o("pretrained_model_name_or_path"),uMr=o(":"),bMr=l(),be=a("ul"),IC=a("li"),Jbe=a("strong"),vMr=o("albert"),TMr=o(" \u2014 "),FV=a("a"),FMr=o("FlaxAlbertForMaskedLM"),CMr=o(" (ALBERT model)"),MMr=l(),jC=a("li"),Ybe=a("strong"),EMr=o("bart"),yMr=o(" \u2014 "),CV=a("a"),wMr=o("FlaxBartForConditionalGeneration"),AMr=o(" (BART model)"),LMr=l(),DC=a("li"),Kbe=a("strong"),BMr=o("bert"),xMr=o(" \u2014 "),MV=a("a"),kMr=o("FlaxBertForMaskedLM"),RMr=o(" (BERT model)"),SMr=l(),NC=a("li"),Zbe=a("strong"),PMr=o("big_bird"),$Mr=o(" \u2014 "),EV=a("a"),IMr=o("FlaxBigBirdForMaskedLM"),jMr=o(" (BigBird model)"),DMr=l(),qC=a("li"),e5e=a("strong"),NMr=o("distilbert"),qMr=o(" \u2014 "),yV=a("a"),OMr=o("FlaxDistilBertForMaskedLM"),GMr=o(" (DistilBERT model)"),XMr=l(),OC=a("li"),o5e=a("strong"),VMr=o("electra"),zMr=o(" \u2014 "),wV=a("a"),WMr=o("FlaxElectraForMaskedLM"),QMr=o(" (ELECTRA model)"),HMr=l(),GC=a("li"),r5e=a("strong"),UMr=o("mbart"),JMr=o(" \u2014 "),AV=a("a"),YMr=o("FlaxMBartForConditionalGeneration"),KMr=o(" (mBART model)"),ZMr=l(),XC=a("li"),t5e=a("strong"),e4r=o("roberta"),o4r=o(" \u2014 "),LV=a("a"),r4r=o("FlaxRobertaForMaskedLM"),t4r=o(" (RoBERTa model)"),a4r=l(),VC=a("li"),a5e=a("strong"),n4r=o("roformer"),s4r=o(" \u2014 "),BV=a("a"),l4r=o("FlaxRoFormerForMaskedLM"),i4r=o(" (RoFormer model)"),d4r=l(),zC=a("li"),n5e=a("strong"),c4r=o("xlm-roberta"),f4r=o(" \u2014 "),xV=a("a"),m4r=o("FlaxXLMRobertaForMaskedLM"),g4r=o(" (XLM-RoBERTa model)"),h4r=l(),s5e=a("p"),p4r=o("Examples:"),_4r=l(),f(OA.$$.fragment),Zke=l(),cf=a("h2"),WC=a("a"),l5e=a("span"),f(GA.$$.fragment),u4r=l(),i5e=a("span"),b4r=o("FlaxAutoModelForSeq2SeqLM"),eRe=l(),Ir=a("div"),f(XA.$$.fragment),v4r=l(),ff=a("p"),T4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),d5e=a("code"),F4r=o("from_pretrained()"),C4r=o("class method or the "),c5e=a("code"),M4r=o("from_config()"),E4r=o(`class
method.`),y4r=l(),VA=a("p"),w4r=o("This class cannot be instantiated directly using "),f5e=a("code"),A4r=o("__init__()"),L4r=o(" (throws an error)."),B4r=l(),xt=a("div"),f(zA.$$.fragment),x4r=l(),m5e=a("p"),k4r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),R4r=l(),mf=a("p"),S4r=o(`Note:
Loading a model from its configuration file does `),g5e=a("strong"),P4r=o("not"),$4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),h5e=a("code"),I4r=o("from_pretrained()"),j4r=o("to load the model weights."),D4r=l(),p5e=a("p"),N4r=o("Examples:"),q4r=l(),f(WA.$$.fragment),O4r=l(),ko=a("div"),f(QA.$$.fragment),G4r=l(),_5e=a("p"),X4r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),V4r=l(),Sn=a("p"),z4r=o("The model class to instantiate is selected based on the "),u5e=a("code"),W4r=o("model_type"),Q4r=o(` property of the config object (either
passed as an argument or loaded from `),b5e=a("code"),H4r=o("pretrained_model_name_or_path"),U4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v5e=a("code"),J4r=o("pretrained_model_name_or_path"),Y4r=o(":"),K4r=l(),Ce=a("ul"),QC=a("li"),T5e=a("strong"),Z4r=o("bart"),eEr=o(" \u2014 "),kV=a("a"),oEr=o("FlaxBartForConditionalGeneration"),rEr=o(" (BART model)"),tEr=l(),HC=a("li"),F5e=a("strong"),aEr=o("blenderbot"),nEr=o(" \u2014 "),RV=a("a"),sEr=o("FlaxBlenderbotForConditionalGeneration"),lEr=o(" (Blenderbot model)"),iEr=l(),UC=a("li"),C5e=a("strong"),dEr=o("blenderbot-small"),cEr=o(" \u2014 "),SV=a("a"),fEr=o("FlaxBlenderbotSmallForConditionalGeneration"),mEr=o(" (BlenderbotSmall model)"),gEr=l(),JC=a("li"),M5e=a("strong"),hEr=o("encoder-decoder"),pEr=o(" \u2014 "),PV=a("a"),_Er=o("FlaxEncoderDecoderModel"),uEr=o(" (Encoder decoder model)"),bEr=l(),YC=a("li"),E5e=a("strong"),vEr=o("marian"),TEr=o(" \u2014 "),$V=a("a"),FEr=o("FlaxMarianMTModel"),CEr=o(" (Marian model)"),MEr=l(),KC=a("li"),y5e=a("strong"),EEr=o("mbart"),yEr=o(" \u2014 "),IV=a("a"),wEr=o("FlaxMBartForConditionalGeneration"),AEr=o(" (mBART model)"),LEr=l(),ZC=a("li"),w5e=a("strong"),BEr=o("mt5"),xEr=o(" \u2014 "),jV=a("a"),kEr=o("FlaxMT5ForConditionalGeneration"),REr=o(" (mT5 model)"),SEr=l(),eM=a("li"),A5e=a("strong"),PEr=o("pegasus"),$Er=o(" \u2014 "),DV=a("a"),IEr=o("FlaxPegasusForConditionalGeneration"),jEr=o(" (Pegasus model)"),DEr=l(),oM=a("li"),L5e=a("strong"),NEr=o("t5"),qEr=o(" \u2014 "),NV=a("a"),OEr=o("FlaxT5ForConditionalGeneration"),GEr=o(" (T5 model)"),XEr=l(),B5e=a("p"),VEr=o("Examples:"),zEr=l(),f(HA.$$.fragment),oRe=l(),gf=a("h2"),rM=a("a"),x5e=a("span"),f(UA.$$.fragment),WEr=l(),k5e=a("span"),QEr=o("FlaxAutoModelForSequenceClassification"),rRe=l(),jr=a("div"),f(JA.$$.fragment),HEr=l(),hf=a("p"),UEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),R5e=a("code"),JEr=o("from_pretrained()"),YEr=o("class method or the "),S5e=a("code"),KEr=o("from_config()"),ZEr=o(`class
method.`),e3r=l(),YA=a("p"),o3r=o("This class cannot be instantiated directly using "),P5e=a("code"),r3r=o("__init__()"),t3r=o(" (throws an error)."),a3r=l(),kt=a("div"),f(KA.$$.fragment),n3r=l(),$5e=a("p"),s3r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),l3r=l(),pf=a("p"),i3r=o(`Note:
Loading a model from its configuration file does `),I5e=a("strong"),d3r=o("not"),c3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),j5e=a("code"),f3r=o("from_pretrained()"),m3r=o("to load the model weights."),g3r=l(),D5e=a("p"),h3r=o("Examples:"),p3r=l(),f(ZA.$$.fragment),_3r=l(),Ro=a("div"),f(eL.$$.fragment),u3r=l(),N5e=a("p"),b3r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),v3r=l(),Pn=a("p"),T3r=o("The model class to instantiate is selected based on the "),q5e=a("code"),F3r=o("model_type"),C3r=o(` property of the config object (either
passed as an argument or loaded from `),O5e=a("code"),M3r=o("pretrained_model_name_or_path"),E3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G5e=a("code"),y3r=o("pretrained_model_name_or_path"),w3r=o(":"),A3r=l(),ve=a("ul"),tM=a("li"),X5e=a("strong"),L3r=o("albert"),B3r=o(" \u2014 "),qV=a("a"),x3r=o("FlaxAlbertForSequenceClassification"),k3r=o(" (ALBERT model)"),R3r=l(),aM=a("li"),V5e=a("strong"),S3r=o("bart"),P3r=o(" \u2014 "),OV=a("a"),$3r=o("FlaxBartForSequenceClassification"),I3r=o(" (BART model)"),j3r=l(),nM=a("li"),z5e=a("strong"),D3r=o("bert"),N3r=o(" \u2014 "),GV=a("a"),q3r=o("FlaxBertForSequenceClassification"),O3r=o(" (BERT model)"),G3r=l(),sM=a("li"),W5e=a("strong"),X3r=o("big_bird"),V3r=o(" \u2014 "),XV=a("a"),z3r=o("FlaxBigBirdForSequenceClassification"),W3r=o(" (BigBird model)"),Q3r=l(),lM=a("li"),Q5e=a("strong"),H3r=o("distilbert"),U3r=o(" \u2014 "),VV=a("a"),J3r=o("FlaxDistilBertForSequenceClassification"),Y3r=o(" (DistilBERT model)"),K3r=l(),iM=a("li"),H5e=a("strong"),Z3r=o("electra"),eyr=o(" \u2014 "),zV=a("a"),oyr=o("FlaxElectraForSequenceClassification"),ryr=o(" (ELECTRA model)"),tyr=l(),dM=a("li"),U5e=a("strong"),ayr=o("mbart"),nyr=o(" \u2014 "),WV=a("a"),syr=o("FlaxMBartForSequenceClassification"),lyr=o(" (mBART model)"),iyr=l(),cM=a("li"),J5e=a("strong"),dyr=o("roberta"),cyr=o(" \u2014 "),QV=a("a"),fyr=o("FlaxRobertaForSequenceClassification"),myr=o(" (RoBERTa model)"),gyr=l(),fM=a("li"),Y5e=a("strong"),hyr=o("roformer"),pyr=o(" \u2014 "),HV=a("a"),_yr=o("FlaxRoFormerForSequenceClassification"),uyr=o(" (RoFormer model)"),byr=l(),mM=a("li"),K5e=a("strong"),vyr=o("xlm-roberta"),Tyr=o(" \u2014 "),UV=a("a"),Fyr=o("FlaxXLMRobertaForSequenceClassification"),Cyr=o(" (XLM-RoBERTa model)"),Myr=l(),Z5e=a("p"),Eyr=o("Examples:"),yyr=l(),f(oL.$$.fragment),tRe=l(),_f=a("h2"),gM=a("a"),e2e=a("span"),f(rL.$$.fragment),wyr=l(),o2e=a("span"),Ayr=o("FlaxAutoModelForQuestionAnswering"),aRe=l(),Dr=a("div"),f(tL.$$.fragment),Lyr=l(),uf=a("p"),Byr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),r2e=a("code"),xyr=o("from_pretrained()"),kyr=o("class method or the "),t2e=a("code"),Ryr=o("from_config()"),Syr=o(`class
method.`),Pyr=l(),aL=a("p"),$yr=o("This class cannot be instantiated directly using "),a2e=a("code"),Iyr=o("__init__()"),jyr=o(" (throws an error)."),Dyr=l(),Rt=a("div"),f(nL.$$.fragment),Nyr=l(),n2e=a("p"),qyr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Oyr=l(),bf=a("p"),Gyr=o(`Note:
Loading a model from its configuration file does `),s2e=a("strong"),Xyr=o("not"),Vyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),l2e=a("code"),zyr=o("from_pretrained()"),Wyr=o("to load the model weights."),Qyr=l(),i2e=a("p"),Hyr=o("Examples:"),Uyr=l(),f(sL.$$.fragment),Jyr=l(),So=a("div"),f(lL.$$.fragment),Yyr=l(),d2e=a("p"),Kyr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Zyr=l(),$n=a("p"),ewr=o("The model class to instantiate is selected based on the "),c2e=a("code"),owr=o("model_type"),rwr=o(` property of the config object (either
passed as an argument or loaded from `),f2e=a("code"),twr=o("pretrained_model_name_or_path"),awr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m2e=a("code"),nwr=o("pretrained_model_name_or_path"),swr=o(":"),lwr=l(),Te=a("ul"),hM=a("li"),g2e=a("strong"),iwr=o("albert"),dwr=o(" \u2014 "),JV=a("a"),cwr=o("FlaxAlbertForQuestionAnswering"),fwr=o(" (ALBERT model)"),mwr=l(),pM=a("li"),h2e=a("strong"),gwr=o("bart"),hwr=o(" \u2014 "),YV=a("a"),pwr=o("FlaxBartForQuestionAnswering"),_wr=o(" (BART model)"),uwr=l(),_M=a("li"),p2e=a("strong"),bwr=o("bert"),vwr=o(" \u2014 "),KV=a("a"),Twr=o("FlaxBertForQuestionAnswering"),Fwr=o(" (BERT model)"),Cwr=l(),uM=a("li"),_2e=a("strong"),Mwr=o("big_bird"),Ewr=o(" \u2014 "),ZV=a("a"),ywr=o("FlaxBigBirdForQuestionAnswering"),wwr=o(" (BigBird model)"),Awr=l(),bM=a("li"),u2e=a("strong"),Lwr=o("distilbert"),Bwr=o(" \u2014 "),ez=a("a"),xwr=o("FlaxDistilBertForQuestionAnswering"),kwr=o(" (DistilBERT model)"),Rwr=l(),vM=a("li"),b2e=a("strong"),Swr=o("electra"),Pwr=o(" \u2014 "),oz=a("a"),$wr=o("FlaxElectraForQuestionAnswering"),Iwr=o(" (ELECTRA model)"),jwr=l(),TM=a("li"),v2e=a("strong"),Dwr=o("mbart"),Nwr=o(" \u2014 "),rz=a("a"),qwr=o("FlaxMBartForQuestionAnswering"),Owr=o(" (mBART model)"),Gwr=l(),FM=a("li"),T2e=a("strong"),Xwr=o("roberta"),Vwr=o(" \u2014 "),tz=a("a"),zwr=o("FlaxRobertaForQuestionAnswering"),Wwr=o(" (RoBERTa model)"),Qwr=l(),CM=a("li"),F2e=a("strong"),Hwr=o("roformer"),Uwr=o(" \u2014 "),az=a("a"),Jwr=o("FlaxRoFormerForQuestionAnswering"),Ywr=o(" (RoFormer model)"),Kwr=l(),MM=a("li"),C2e=a("strong"),Zwr=o("xlm-roberta"),e6r=o(" \u2014 "),nz=a("a"),o6r=o("FlaxXLMRobertaForQuestionAnswering"),r6r=o(" (XLM-RoBERTa model)"),t6r=l(),M2e=a("p"),a6r=o("Examples:"),n6r=l(),f(iL.$$.fragment),nRe=l(),vf=a("h2"),EM=a("a"),E2e=a("span"),f(dL.$$.fragment),s6r=l(),y2e=a("span"),l6r=o("FlaxAutoModelForTokenClassification"),sRe=l(),Nr=a("div"),f(cL.$$.fragment),i6r=l(),Tf=a("p"),d6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),w2e=a("code"),c6r=o("from_pretrained()"),f6r=o("class method or the "),A2e=a("code"),m6r=o("from_config()"),g6r=o(`class
method.`),h6r=l(),fL=a("p"),p6r=o("This class cannot be instantiated directly using "),L2e=a("code"),_6r=o("__init__()"),u6r=o(" (throws an error)."),b6r=l(),St=a("div"),f(mL.$$.fragment),v6r=l(),B2e=a("p"),T6r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),F6r=l(),Ff=a("p"),C6r=o(`Note:
Loading a model from its configuration file does `),x2e=a("strong"),M6r=o("not"),E6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),k2e=a("code"),y6r=o("from_pretrained()"),w6r=o("to load the model weights."),A6r=l(),R2e=a("p"),L6r=o("Examples:"),B6r=l(),f(gL.$$.fragment),x6r=l(),Po=a("div"),f(hL.$$.fragment),k6r=l(),S2e=a("p"),R6r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),S6r=l(),In=a("p"),P6r=o("The model class to instantiate is selected based on the "),P2e=a("code"),$6r=o("model_type"),I6r=o(` property of the config object (either
passed as an argument or loaded from `),$2e=a("code"),j6r=o("pretrained_model_name_or_path"),D6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=a("code"),N6r=o("pretrained_model_name_or_path"),q6r=o(":"),O6r=l(),Se=a("ul"),yM=a("li"),j2e=a("strong"),G6r=o("albert"),X6r=o(" \u2014 "),sz=a("a"),V6r=o("FlaxAlbertForTokenClassification"),z6r=o(" (ALBERT model)"),W6r=l(),wM=a("li"),D2e=a("strong"),Q6r=o("bert"),H6r=o(" \u2014 "),lz=a("a"),U6r=o("FlaxBertForTokenClassification"),J6r=o(" (BERT model)"),Y6r=l(),AM=a("li"),N2e=a("strong"),K6r=o("big_bird"),Z6r=o(" \u2014 "),iz=a("a"),eAr=o("FlaxBigBirdForTokenClassification"),oAr=o(" (BigBird model)"),rAr=l(),LM=a("li"),q2e=a("strong"),tAr=o("distilbert"),aAr=o(" \u2014 "),dz=a("a"),nAr=o("FlaxDistilBertForTokenClassification"),sAr=o(" (DistilBERT model)"),lAr=l(),BM=a("li"),O2e=a("strong"),iAr=o("electra"),dAr=o(" \u2014 "),cz=a("a"),cAr=o("FlaxElectraForTokenClassification"),fAr=o(" (ELECTRA model)"),mAr=l(),xM=a("li"),G2e=a("strong"),gAr=o("roberta"),hAr=o(" \u2014 "),fz=a("a"),pAr=o("FlaxRobertaForTokenClassification"),_Ar=o(" (RoBERTa model)"),uAr=l(),kM=a("li"),X2e=a("strong"),bAr=o("roformer"),vAr=o(" \u2014 "),mz=a("a"),TAr=o("FlaxRoFormerForTokenClassification"),FAr=o(" (RoFormer model)"),CAr=l(),RM=a("li"),V2e=a("strong"),MAr=o("xlm-roberta"),EAr=o(" \u2014 "),gz=a("a"),yAr=o("FlaxXLMRobertaForTokenClassification"),wAr=o(" (XLM-RoBERTa model)"),AAr=l(),z2e=a("p"),LAr=o("Examples:"),BAr=l(),f(pL.$$.fragment),lRe=l(),Cf=a("h2"),SM=a("a"),W2e=a("span"),f(_L.$$.fragment),xAr=l(),Q2e=a("span"),kAr=o("FlaxAutoModelForMultipleChoice"),iRe=l(),qr=a("div"),f(uL.$$.fragment),RAr=l(),Mf=a("p"),SAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),H2e=a("code"),PAr=o("from_pretrained()"),$Ar=o("class method or the "),U2e=a("code"),IAr=o("from_config()"),jAr=o(`class
method.`),DAr=l(),bL=a("p"),NAr=o("This class cannot be instantiated directly using "),J2e=a("code"),qAr=o("__init__()"),OAr=o(" (throws an error)."),GAr=l(),Pt=a("div"),f(vL.$$.fragment),XAr=l(),Y2e=a("p"),VAr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),zAr=l(),Ef=a("p"),WAr=o(`Note:
Loading a model from its configuration file does `),K2e=a("strong"),QAr=o("not"),HAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Z2e=a("code"),UAr=o("from_pretrained()"),JAr=o("to load the model weights."),YAr=l(),eve=a("p"),KAr=o("Examples:"),ZAr=l(),f(TL.$$.fragment),eLr=l(),$o=a("div"),f(FL.$$.fragment),oLr=l(),ove=a("p"),rLr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),tLr=l(),jn=a("p"),aLr=o("The model class to instantiate is selected based on the "),rve=a("code"),nLr=o("model_type"),sLr=o(` property of the config object (either
passed as an argument or loaded from `),tve=a("code"),lLr=o("pretrained_model_name_or_path"),iLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=a("code"),dLr=o("pretrained_model_name_or_path"),cLr=o(":"),fLr=l(),Pe=a("ul"),PM=a("li"),nve=a("strong"),mLr=o("albert"),gLr=o(" \u2014 "),hz=a("a"),hLr=o("FlaxAlbertForMultipleChoice"),pLr=o(" (ALBERT model)"),_Lr=l(),$M=a("li"),sve=a("strong"),uLr=o("bert"),bLr=o(" \u2014 "),pz=a("a"),vLr=o("FlaxBertForMultipleChoice"),TLr=o(" (BERT model)"),FLr=l(),IM=a("li"),lve=a("strong"),CLr=o("big_bird"),MLr=o(" \u2014 "),_z=a("a"),ELr=o("FlaxBigBirdForMultipleChoice"),yLr=o(" (BigBird model)"),wLr=l(),jM=a("li"),ive=a("strong"),ALr=o("distilbert"),LLr=o(" \u2014 "),uz=a("a"),BLr=o("FlaxDistilBertForMultipleChoice"),xLr=o(" (DistilBERT model)"),kLr=l(),DM=a("li"),dve=a("strong"),RLr=o("electra"),SLr=o(" \u2014 "),bz=a("a"),PLr=o("FlaxElectraForMultipleChoice"),$Lr=o(" (ELECTRA model)"),ILr=l(),NM=a("li"),cve=a("strong"),jLr=o("roberta"),DLr=o(" \u2014 "),vz=a("a"),NLr=o("FlaxRobertaForMultipleChoice"),qLr=o(" (RoBERTa model)"),OLr=l(),qM=a("li"),fve=a("strong"),GLr=o("roformer"),XLr=o(" \u2014 "),Tz=a("a"),VLr=o("FlaxRoFormerForMultipleChoice"),zLr=o(" (RoFormer model)"),WLr=l(),OM=a("li"),mve=a("strong"),QLr=o("xlm-roberta"),HLr=o(" \u2014 "),Fz=a("a"),ULr=o("FlaxXLMRobertaForMultipleChoice"),JLr=o(" (XLM-RoBERTa model)"),YLr=l(),gve=a("p"),KLr=o("Examples:"),ZLr=l(),f(CL.$$.fragment),dRe=l(),yf=a("h2"),GM=a("a"),hve=a("span"),f(ML.$$.fragment),e8r=l(),pve=a("span"),o8r=o("FlaxAutoModelForNextSentencePrediction"),cRe=l(),Or=a("div"),f(EL.$$.fragment),r8r=l(),wf=a("p"),t8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),_ve=a("code"),a8r=o("from_pretrained()"),n8r=o("class method or the "),uve=a("code"),s8r=o("from_config()"),l8r=o(`class
method.`),i8r=l(),yL=a("p"),d8r=o("This class cannot be instantiated directly using "),bve=a("code"),c8r=o("__init__()"),f8r=o(" (throws an error)."),m8r=l(),$t=a("div"),f(wL.$$.fragment),g8r=l(),vve=a("p"),h8r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),p8r=l(),Af=a("p"),_8r=o(`Note:
Loading a model from its configuration file does `),Tve=a("strong"),u8r=o("not"),b8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fve=a("code"),v8r=o("from_pretrained()"),T8r=o("to load the model weights."),F8r=l(),Cve=a("p"),C8r=o("Examples:"),M8r=l(),f(AL.$$.fragment),E8r=l(),Io=a("div"),f(LL.$$.fragment),y8r=l(),Mve=a("p"),w8r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),A8r=l(),Dn=a("p"),L8r=o("The model class to instantiate is selected based on the "),Eve=a("code"),B8r=o("model_type"),x8r=o(` property of the config object (either
passed as an argument or loaded from `),yve=a("code"),k8r=o("pretrained_model_name_or_path"),R8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wve=a("code"),S8r=o("pretrained_model_name_or_path"),P8r=o(":"),$8r=l(),Ave=a("ul"),XM=a("li"),Lve=a("strong"),I8r=o("bert"),j8r=o(" \u2014 "),Cz=a("a"),D8r=o("FlaxBertForNextSentencePrediction"),N8r=o(" (BERT model)"),q8r=l(),Bve=a("p"),O8r=o("Examples:"),G8r=l(),f(BL.$$.fragment),fRe=l(),Lf=a("h2"),VM=a("a"),xve=a("span"),f(xL.$$.fragment),X8r=l(),kve=a("span"),V8r=o("FlaxAutoModelForImageClassification"),mRe=l(),Gr=a("div"),f(kL.$$.fragment),z8r=l(),Bf=a("p"),W8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Rve=a("code"),Q8r=o("from_pretrained()"),H8r=o("class method or the "),Sve=a("code"),U8r=o("from_config()"),J8r=o(`class
method.`),Y8r=l(),RL=a("p"),K8r=o("This class cannot be instantiated directly using "),Pve=a("code"),Z8r=o("__init__()"),e9r=o(" (throws an error)."),o9r=l(),It=a("div"),f(SL.$$.fragment),r9r=l(),$ve=a("p"),t9r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),a9r=l(),xf=a("p"),n9r=o(`Note:
Loading a model from its configuration file does `),Ive=a("strong"),s9r=o("not"),l9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jve=a("code"),i9r=o("from_pretrained()"),d9r=o("to load the model weights."),c9r=l(),Dve=a("p"),f9r=o("Examples:"),m9r=l(),f(PL.$$.fragment),g9r=l(),jo=a("div"),f($L.$$.fragment),h9r=l(),Nve=a("p"),p9r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_9r=l(),Nn=a("p"),u9r=o("The model class to instantiate is selected based on the "),qve=a("code"),b9r=o("model_type"),v9r=o(` property of the config object (either
passed as an argument or loaded from `),Ove=a("code"),T9r=o("pretrained_model_name_or_path"),F9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gve=a("code"),C9r=o("pretrained_model_name_or_path"),M9r=o(":"),E9r=l(),IL=a("ul"),zM=a("li"),Xve=a("strong"),y9r=o("beit"),w9r=o(" \u2014 "),Mz=a("a"),A9r=o("FlaxBeitForImageClassification"),L9r=o(" (BEiT model)"),B9r=l(),WM=a("li"),Vve=a("strong"),x9r=o("vit"),k9r=o(" \u2014 "),Ez=a("a"),R9r=o("FlaxViTForImageClassification"),S9r=o(" (ViT model)"),P9r=l(),zve=a("p"),$9r=o("Examples:"),I9r=l(),f(jL.$$.fragment),gRe=l(),kf=a("h2"),QM=a("a"),Wve=a("span"),f(DL.$$.fragment),j9r=l(),Qve=a("span"),D9r=o("FlaxAutoModelForVision2Seq"),hRe=l(),Xr=a("div"),f(NL.$$.fragment),N9r=l(),Rf=a("p"),q9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Hve=a("code"),O9r=o("from_pretrained()"),G9r=o("class method or the "),Uve=a("code"),X9r=o("from_config()"),V9r=o(`class
method.`),z9r=l(),qL=a("p"),W9r=o("This class cannot be instantiated directly using "),Jve=a("code"),Q9r=o("__init__()"),H9r=o(" (throws an error)."),U9r=l(),jt=a("div"),f(OL.$$.fragment),J9r=l(),Yve=a("p"),Y9r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),K9r=l(),Sf=a("p"),Z9r=o(`Note:
Loading a model from its configuration file does `),Kve=a("strong"),eBr=o("not"),oBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zve=a("code"),rBr=o("from_pretrained()"),tBr=o("to load the model weights."),aBr=l(),e0e=a("p"),nBr=o("Examples:"),sBr=l(),f(GL.$$.fragment),lBr=l(),Do=a("div"),f(XL.$$.fragment),iBr=l(),o0e=a("p"),dBr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),cBr=l(),qn=a("p"),fBr=o("The model class to instantiate is selected based on the "),r0e=a("code"),mBr=o("model_type"),gBr=o(` property of the config object (either
passed as an argument or loaded from `),t0e=a("code"),hBr=o("pretrained_model_name_or_path"),pBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=a("code"),_Br=o("pretrained_model_name_or_path"),uBr=o(":"),bBr=l(),n0e=a("ul"),HM=a("li"),s0e=a("strong"),vBr=o("vision-encoder-decoder"),TBr=o(" \u2014 "),yz=a("a"),FBr=o("FlaxVisionEncoderDecoderModel"),CBr=o(" (Vision Encoder decoder model)"),MBr=l(),l0e=a("p"),EBr=o("Examples:"),yBr=l(),f(VL.$$.fragment),this.h()},l(c){const u=sTt('[data-svelte="svelte-1phssyn"]',document.head);J=n(u,"META",{name:!0,content:!0}),u.forEach(t),$e=i(c),de=n(c,"H1",{class:!0});var zL=s(de);ge=n(zL,"A",{id:!0,class:!0,href:!0});var i0e=s(ge);io=n(i0e,"SPAN",{});var d0e=s(io);m(fe.$$.fragment,d0e),d0e.forEach(t),i0e.forEach(t),Fe=i(zL),Vo=n(zL,"SPAN",{});var ABr=s(Vo);Ii=r(ABr,"Auto Classes"),ABr.forEach(t),zL.forEach(t),$f=i(c),ca=n(c,"P",{});var _Re=s(ca);ji=r(_Re,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Di=n(_Re,"CODE",{});var LBr=s(Di);U4=r(LBr,"from_pretrained()"),LBr.forEach(t),If=r(_Re,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),_Re.forEach(t),Be=i(c),co=n(c,"P",{});var UM=s(co);Ni=r(UM,"Instantiating one of "),On=n(UM,"A",{href:!0});var BBr=s(On);J4=r(BBr,"AutoConfig"),BBr.forEach(t),Gn=r(UM,", "),Xn=n(UM,"A",{href:!0});var xBr=s(Xn);Y4=r(xBr,"AutoModel"),xBr.forEach(t),qi=r(UM,`, and
`),Vn=n(UM,"A",{href:!0});var kBr=s(Vn);K4=r(kBr,"AutoTokenizer"),kBr.forEach(t),Oi=r(UM," will directly create a class of the relevant architecture. For instance"),UM.forEach(t),jf=i(c),m(Na.$$.fragment,c),fo=i(c),he=n(c,"P",{});var uRe=s(he);G8=r(uRe,"will create a model that is an instance of "),Gi=n(uRe,"A",{href:!0});var RBr=s(Gi);X8=r(RBr,"BertModel"),RBr.forEach(t),V8=r(uRe,"."),uRe.forEach(t),zo=i(c),qa=n(c,"P",{});var bRe=s(qa);z8=r(bRe,"There is one class of "),Df=n(bRe,"CODE",{});var SBr=s(Df);W8=r(SBr,"AutoModel"),SBr.forEach(t),LPe=r(bRe," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),bRe.forEach(t),hxe=i(c),Xi=n(c,"H2",{class:!0});var vRe=s(Xi);Nf=n(vRe,"A",{id:!0,class:!0,href:!0});var PBr=s(Nf);bQ=n(PBr,"SPAN",{});var $Br=s(bQ);m(Z4.$$.fragment,$Br),$Br.forEach(t),PBr.forEach(t),BPe=i(vRe),vQ=n(vRe,"SPAN",{});var IBr=s(vQ);xPe=r(IBr,"Extending the Auto Classes"),IBr.forEach(t),vRe.forEach(t),pxe=i(c),zn=n(c,"P",{});var wz=s(zn);kPe=r(wz,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),TQ=n(wz,"CODE",{});var jBr=s(TQ);RPe=r(jBr,"NewModel"),jBr.forEach(t),SPe=r(wz,", make sure you have a "),FQ=n(wz,"CODE",{});var DBr=s(FQ);PPe=r(DBr,"NewModelConfig"),DBr.forEach(t),$Pe=r(wz,` then you can add those to the auto
classes like this:`),wz.forEach(t),_xe=i(c),m(eE.$$.fragment,c),uxe=i(c),Q8=n(c,"P",{});var NBr=s(Q8);IPe=r(NBr,"You will then be able to use the auto classes like you would usually do!"),NBr.forEach(t),bxe=i(c),m(qf.$$.fragment,c),vxe=i(c),Vi=n(c,"H2",{class:!0});var TRe=s(Vi);Of=n(TRe,"A",{id:!0,class:!0,href:!0});var qBr=s(Of);CQ=n(qBr,"SPAN",{});var OBr=s(CQ);m(oE.$$.fragment,OBr),OBr.forEach(t),qBr.forEach(t),jPe=i(TRe),MQ=n(TRe,"SPAN",{});var GBr=s(MQ);DPe=r(GBr,"AutoConfig"),GBr.forEach(t),TRe.forEach(t),Txe=i(c),Wo=n(c,"DIV",{class:!0});var Gs=s(Wo);m(rE.$$.fragment,Gs),NPe=i(Gs),tE=n(Gs,"P",{});var FRe=s(tE);qPe=r(FRe,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),H8=n(FRe,"A",{href:!0});var XBr=s(H8);OPe=r(XBr,"from_pretrained()"),XBr.forEach(t),GPe=r(FRe," class method."),FRe.forEach(t),XPe=i(Gs),aE=n(Gs,"P",{});var CRe=s(aE);VPe=r(CRe,"This class cannot be instantiated directly using "),EQ=n(CRe,"CODE",{});var VBr=s(EQ);zPe=r(VBr,"__init__()"),VBr.forEach(t),WPe=r(CRe," (throws an error)."),CRe.forEach(t),QPe=i(Gs),mo=n(Gs,"DIV",{class:!0});var ma=s(mo);m(nE.$$.fragment,ma),HPe=i(ma),yQ=n(ma,"P",{});var zBr=s(yQ);UPe=r(zBr,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),zBr.forEach(t),JPe=i(ma),zi=n(ma,"P",{});var Az=s(zi);YPe=r(Az,"The configuration class to instantiate is selected based on the "),wQ=n(Az,"CODE",{});var WBr=s(wQ);KPe=r(WBr,"model_type"),WBr.forEach(t),ZPe=r(Az,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),AQ=n(Az,"CODE",{});var QBr=s(AQ);e$e=r(QBr,"pretrained_model_name_or_path"),QBr.forEach(t),o$e=r(Az,":"),Az.forEach(t),r$e=i(ma),v=n(ma,"UL",{});var T=s(v);Gf=n(T,"LI",{});var c0e=s(Gf);LQ=n(c0e,"STRONG",{});var HBr=s(LQ);t$e=r(HBr,"albert"),HBr.forEach(t),a$e=r(c0e," \u2014 "),U8=n(c0e,"A",{href:!0});var UBr=s(U8);n$e=r(UBr,"AlbertConfig"),UBr.forEach(t),s$e=r(c0e," (ALBERT model)"),c0e.forEach(t),l$e=i(T),Xf=n(T,"LI",{});var f0e=s(Xf);BQ=n(f0e,"STRONG",{});var JBr=s(BQ);i$e=r(JBr,"bart"),JBr.forEach(t),d$e=r(f0e," \u2014 "),J8=n(f0e,"A",{href:!0});var YBr=s(J8);c$e=r(YBr,"BartConfig"),YBr.forEach(t),f$e=r(f0e," (BART model)"),f0e.forEach(t),m$e=i(T),Vf=n(T,"LI",{});var m0e=s(Vf);xQ=n(m0e,"STRONG",{});var KBr=s(xQ);g$e=r(KBr,"beit"),KBr.forEach(t),h$e=r(m0e," \u2014 "),Y8=n(m0e,"A",{href:!0});var ZBr=s(Y8);p$e=r(ZBr,"BeitConfig"),ZBr.forEach(t),_$e=r(m0e," (BEiT model)"),m0e.forEach(t),u$e=i(T),zf=n(T,"LI",{});var g0e=s(zf);kQ=n(g0e,"STRONG",{});var exr=s(kQ);b$e=r(exr,"bert"),exr.forEach(t),v$e=r(g0e," \u2014 "),K8=n(g0e,"A",{href:!0});var oxr=s(K8);T$e=r(oxr,"BertConfig"),oxr.forEach(t),F$e=r(g0e," (BERT model)"),g0e.forEach(t),C$e=i(T),Wf=n(T,"LI",{});var h0e=s(Wf);RQ=n(h0e,"STRONG",{});var rxr=s(RQ);M$e=r(rxr,"bert-generation"),rxr.forEach(t),E$e=r(h0e," \u2014 "),Z8=n(h0e,"A",{href:!0});var txr=s(Z8);y$e=r(txr,"BertGenerationConfig"),txr.forEach(t),w$e=r(h0e," (Bert Generation model)"),h0e.forEach(t),A$e=i(T),Qf=n(T,"LI",{});var p0e=s(Qf);SQ=n(p0e,"STRONG",{});var axr=s(SQ);L$e=r(axr,"big_bird"),axr.forEach(t),B$e=r(p0e," \u2014 "),e9=n(p0e,"A",{href:!0});var nxr=s(e9);x$e=r(nxr,"BigBirdConfig"),nxr.forEach(t),k$e=r(p0e," (BigBird model)"),p0e.forEach(t),R$e=i(T),Hf=n(T,"LI",{});var _0e=s(Hf);PQ=n(_0e,"STRONG",{});var sxr=s(PQ);S$e=r(sxr,"bigbird_pegasus"),sxr.forEach(t),P$e=r(_0e," \u2014 "),o9=n(_0e,"A",{href:!0});var lxr=s(o9);$$e=r(lxr,"BigBirdPegasusConfig"),lxr.forEach(t),I$e=r(_0e," (BigBirdPegasus model)"),_0e.forEach(t),j$e=i(T),Uf=n(T,"LI",{});var u0e=s(Uf);$Q=n(u0e,"STRONG",{});var ixr=s($Q);D$e=r(ixr,"blenderbot"),ixr.forEach(t),N$e=r(u0e," \u2014 "),r9=n(u0e,"A",{href:!0});var dxr=s(r9);q$e=r(dxr,"BlenderbotConfig"),dxr.forEach(t),O$e=r(u0e," (Blenderbot model)"),u0e.forEach(t),G$e=i(T),Jf=n(T,"LI",{});var b0e=s(Jf);IQ=n(b0e,"STRONG",{});var cxr=s(IQ);X$e=r(cxr,"blenderbot-small"),cxr.forEach(t),V$e=r(b0e," \u2014 "),t9=n(b0e,"A",{href:!0});var fxr=s(t9);z$e=r(fxr,"BlenderbotSmallConfig"),fxr.forEach(t),W$e=r(b0e," (BlenderbotSmall model)"),b0e.forEach(t),Q$e=i(T),Yf=n(T,"LI",{});var v0e=s(Yf);jQ=n(v0e,"STRONG",{});var mxr=s(jQ);H$e=r(mxr,"camembert"),mxr.forEach(t),U$e=r(v0e," \u2014 "),a9=n(v0e,"A",{href:!0});var gxr=s(a9);J$e=r(gxr,"CamembertConfig"),gxr.forEach(t),Y$e=r(v0e," (CamemBERT model)"),v0e.forEach(t),K$e=i(T),Kf=n(T,"LI",{});var T0e=s(Kf);DQ=n(T0e,"STRONG",{});var hxr=s(DQ);Z$e=r(hxr,"canine"),hxr.forEach(t),eIe=r(T0e," \u2014 "),n9=n(T0e,"A",{href:!0});var pxr=s(n9);oIe=r(pxr,"CanineConfig"),pxr.forEach(t),rIe=r(T0e," (Canine model)"),T0e.forEach(t),tIe=i(T),Zf=n(T,"LI",{});var F0e=s(Zf);NQ=n(F0e,"STRONG",{});var _xr=s(NQ);aIe=r(_xr,"clip"),_xr.forEach(t),nIe=r(F0e," \u2014 "),s9=n(F0e,"A",{href:!0});var uxr=s(s9);sIe=r(uxr,"CLIPConfig"),uxr.forEach(t),lIe=r(F0e," (CLIP model)"),F0e.forEach(t),iIe=i(T),em=n(T,"LI",{});var C0e=s(em);qQ=n(C0e,"STRONG",{});var bxr=s(qQ);dIe=r(bxr,"convbert"),bxr.forEach(t),cIe=r(C0e," \u2014 "),l9=n(C0e,"A",{href:!0});var vxr=s(l9);fIe=r(vxr,"ConvBertConfig"),vxr.forEach(t),mIe=r(C0e," (ConvBERT model)"),C0e.forEach(t),gIe=i(T),om=n(T,"LI",{});var M0e=s(om);OQ=n(M0e,"STRONG",{});var Txr=s(OQ);hIe=r(Txr,"convnext"),Txr.forEach(t),pIe=r(M0e," \u2014 "),i9=n(M0e,"A",{href:!0});var Fxr=s(i9);_Ie=r(Fxr,"ConvNextConfig"),Fxr.forEach(t),uIe=r(M0e," (ConvNext model)"),M0e.forEach(t),bIe=i(T),rm=n(T,"LI",{});var E0e=s(rm);GQ=n(E0e,"STRONG",{});var Cxr=s(GQ);vIe=r(Cxr,"ctrl"),Cxr.forEach(t),TIe=r(E0e," \u2014 "),d9=n(E0e,"A",{href:!0});var Mxr=s(d9);FIe=r(Mxr,"CTRLConfig"),Mxr.forEach(t),CIe=r(E0e," (CTRL model)"),E0e.forEach(t),MIe=i(T),tm=n(T,"LI",{});var y0e=s(tm);XQ=n(y0e,"STRONG",{});var Exr=s(XQ);EIe=r(Exr,"data2vec-audio"),Exr.forEach(t),yIe=r(y0e," \u2014 "),c9=n(y0e,"A",{href:!0});var yxr=s(c9);wIe=r(yxr,"Data2VecAudioConfig"),yxr.forEach(t),AIe=r(y0e," (Data2VecAudio model)"),y0e.forEach(t),LIe=i(T),am=n(T,"LI",{});var w0e=s(am);VQ=n(w0e,"STRONG",{});var wxr=s(VQ);BIe=r(wxr,"data2vec-text"),wxr.forEach(t),xIe=r(w0e," \u2014 "),f9=n(w0e,"A",{href:!0});var Axr=s(f9);kIe=r(Axr,"Data2VecTextConfig"),Axr.forEach(t),RIe=r(w0e," (Data2VecText model)"),w0e.forEach(t),SIe=i(T),nm=n(T,"LI",{});var A0e=s(nm);zQ=n(A0e,"STRONG",{});var Lxr=s(zQ);PIe=r(Lxr,"deberta"),Lxr.forEach(t),$Ie=r(A0e," \u2014 "),m9=n(A0e,"A",{href:!0});var Bxr=s(m9);IIe=r(Bxr,"DebertaConfig"),Bxr.forEach(t),jIe=r(A0e," (DeBERTa model)"),A0e.forEach(t),DIe=i(T),sm=n(T,"LI",{});var L0e=s(sm);WQ=n(L0e,"STRONG",{});var xxr=s(WQ);NIe=r(xxr,"deberta-v2"),xxr.forEach(t),qIe=r(L0e," \u2014 "),g9=n(L0e,"A",{href:!0});var kxr=s(g9);OIe=r(kxr,"DebertaV2Config"),kxr.forEach(t),GIe=r(L0e," (DeBERTa-v2 model)"),L0e.forEach(t),XIe=i(T),lm=n(T,"LI",{});var B0e=s(lm);QQ=n(B0e,"STRONG",{});var Rxr=s(QQ);VIe=r(Rxr,"deit"),Rxr.forEach(t),zIe=r(B0e," \u2014 "),h9=n(B0e,"A",{href:!0});var Sxr=s(h9);WIe=r(Sxr,"DeiTConfig"),Sxr.forEach(t),QIe=r(B0e," (DeiT model)"),B0e.forEach(t),HIe=i(T),im=n(T,"LI",{});var x0e=s(im);HQ=n(x0e,"STRONG",{});var Pxr=s(HQ);UIe=r(Pxr,"detr"),Pxr.forEach(t),JIe=r(x0e," \u2014 "),p9=n(x0e,"A",{href:!0});var $xr=s(p9);YIe=r($xr,"DetrConfig"),$xr.forEach(t),KIe=r(x0e," (DETR model)"),x0e.forEach(t),ZIe=i(T),dm=n(T,"LI",{});var k0e=s(dm);UQ=n(k0e,"STRONG",{});var Ixr=s(UQ);eje=r(Ixr,"distilbert"),Ixr.forEach(t),oje=r(k0e," \u2014 "),_9=n(k0e,"A",{href:!0});var jxr=s(_9);rje=r(jxr,"DistilBertConfig"),jxr.forEach(t),tje=r(k0e," (DistilBERT model)"),k0e.forEach(t),aje=i(T),cm=n(T,"LI",{});var R0e=s(cm);JQ=n(R0e,"STRONG",{});var Dxr=s(JQ);nje=r(Dxr,"dpr"),Dxr.forEach(t),sje=r(R0e," \u2014 "),u9=n(R0e,"A",{href:!0});var Nxr=s(u9);lje=r(Nxr,"DPRConfig"),Nxr.forEach(t),ije=r(R0e," (DPR model)"),R0e.forEach(t),dje=i(T),fm=n(T,"LI",{});var S0e=s(fm);YQ=n(S0e,"STRONG",{});var qxr=s(YQ);cje=r(qxr,"electra"),qxr.forEach(t),fje=r(S0e," \u2014 "),b9=n(S0e,"A",{href:!0});var Oxr=s(b9);mje=r(Oxr,"ElectraConfig"),Oxr.forEach(t),gje=r(S0e," (ELECTRA model)"),S0e.forEach(t),hje=i(T),mm=n(T,"LI",{});var P0e=s(mm);KQ=n(P0e,"STRONG",{});var Gxr=s(KQ);pje=r(Gxr,"encoder-decoder"),Gxr.forEach(t),_je=r(P0e," \u2014 "),v9=n(P0e,"A",{href:!0});var Xxr=s(v9);uje=r(Xxr,"EncoderDecoderConfig"),Xxr.forEach(t),bje=r(P0e," (Encoder decoder model)"),P0e.forEach(t),vje=i(T),gm=n(T,"LI",{});var $0e=s(gm);ZQ=n($0e,"STRONG",{});var Vxr=s(ZQ);Tje=r(Vxr,"flaubert"),Vxr.forEach(t),Fje=r($0e," \u2014 "),T9=n($0e,"A",{href:!0});var zxr=s(T9);Cje=r(zxr,"FlaubertConfig"),zxr.forEach(t),Mje=r($0e," (FlauBERT model)"),$0e.forEach(t),Eje=i(T),hm=n(T,"LI",{});var I0e=s(hm);eH=n(I0e,"STRONG",{});var Wxr=s(eH);yje=r(Wxr,"fnet"),Wxr.forEach(t),wje=r(I0e," \u2014 "),F9=n(I0e,"A",{href:!0});var Qxr=s(F9);Aje=r(Qxr,"FNetConfig"),Qxr.forEach(t),Lje=r(I0e," (FNet model)"),I0e.forEach(t),Bje=i(T),pm=n(T,"LI",{});var j0e=s(pm);oH=n(j0e,"STRONG",{});var Hxr=s(oH);xje=r(Hxr,"fsmt"),Hxr.forEach(t),kje=r(j0e," \u2014 "),C9=n(j0e,"A",{href:!0});var Uxr=s(C9);Rje=r(Uxr,"FSMTConfig"),Uxr.forEach(t),Sje=r(j0e," (FairSeq Machine-Translation model)"),j0e.forEach(t),Pje=i(T),_m=n(T,"LI",{});var D0e=s(_m);rH=n(D0e,"STRONG",{});var Jxr=s(rH);$je=r(Jxr,"funnel"),Jxr.forEach(t),Ije=r(D0e," \u2014 "),M9=n(D0e,"A",{href:!0});var Yxr=s(M9);jje=r(Yxr,"FunnelConfig"),Yxr.forEach(t),Dje=r(D0e," (Funnel Transformer model)"),D0e.forEach(t),Nje=i(T),um=n(T,"LI",{});var N0e=s(um);tH=n(N0e,"STRONG",{});var Kxr=s(tH);qje=r(Kxr,"gpt2"),Kxr.forEach(t),Oje=r(N0e," \u2014 "),E9=n(N0e,"A",{href:!0});var Zxr=s(E9);Gje=r(Zxr,"GPT2Config"),Zxr.forEach(t),Xje=r(N0e," (OpenAI GPT-2 model)"),N0e.forEach(t),Vje=i(T),bm=n(T,"LI",{});var q0e=s(bm);aH=n(q0e,"STRONG",{});var ekr=s(aH);zje=r(ekr,"gpt_neo"),ekr.forEach(t),Wje=r(q0e," \u2014 "),y9=n(q0e,"A",{href:!0});var okr=s(y9);Qje=r(okr,"GPTNeoConfig"),okr.forEach(t),Hje=r(q0e," (GPT Neo model)"),q0e.forEach(t),Uje=i(T),vm=n(T,"LI",{});var O0e=s(vm);nH=n(O0e,"STRONG",{});var rkr=s(nH);Jje=r(rkr,"gptj"),rkr.forEach(t),Yje=r(O0e," \u2014 "),w9=n(O0e,"A",{href:!0});var tkr=s(w9);Kje=r(tkr,"GPTJConfig"),tkr.forEach(t),Zje=r(O0e," (GPT-J model)"),O0e.forEach(t),eDe=i(T),Tm=n(T,"LI",{});var G0e=s(Tm);sH=n(G0e,"STRONG",{});var akr=s(sH);oDe=r(akr,"hubert"),akr.forEach(t),rDe=r(G0e," \u2014 "),A9=n(G0e,"A",{href:!0});var nkr=s(A9);tDe=r(nkr,"HubertConfig"),nkr.forEach(t),aDe=r(G0e," (Hubert model)"),G0e.forEach(t),nDe=i(T),Fm=n(T,"LI",{});var X0e=s(Fm);lH=n(X0e,"STRONG",{});var skr=s(lH);sDe=r(skr,"ibert"),skr.forEach(t),lDe=r(X0e," \u2014 "),L9=n(X0e,"A",{href:!0});var lkr=s(L9);iDe=r(lkr,"IBertConfig"),lkr.forEach(t),dDe=r(X0e," (I-BERT model)"),X0e.forEach(t),cDe=i(T),Cm=n(T,"LI",{});var V0e=s(Cm);iH=n(V0e,"STRONG",{});var ikr=s(iH);fDe=r(ikr,"imagegpt"),ikr.forEach(t),mDe=r(V0e," \u2014 "),B9=n(V0e,"A",{href:!0});var dkr=s(B9);gDe=r(dkr,"ImageGPTConfig"),dkr.forEach(t),hDe=r(V0e," (ImageGPT model)"),V0e.forEach(t),pDe=i(T),Mm=n(T,"LI",{});var z0e=s(Mm);dH=n(z0e,"STRONG",{});var ckr=s(dH);_De=r(ckr,"layoutlm"),ckr.forEach(t),uDe=r(z0e," \u2014 "),x9=n(z0e,"A",{href:!0});var fkr=s(x9);bDe=r(fkr,"LayoutLMConfig"),fkr.forEach(t),vDe=r(z0e," (LayoutLM model)"),z0e.forEach(t),TDe=i(T),Em=n(T,"LI",{});var W0e=s(Em);cH=n(W0e,"STRONG",{});var mkr=s(cH);FDe=r(mkr,"layoutlmv2"),mkr.forEach(t),CDe=r(W0e," \u2014 "),k9=n(W0e,"A",{href:!0});var gkr=s(k9);MDe=r(gkr,"LayoutLMv2Config"),gkr.forEach(t),EDe=r(W0e," (LayoutLMv2 model)"),W0e.forEach(t),yDe=i(T),ym=n(T,"LI",{});var Q0e=s(ym);fH=n(Q0e,"STRONG",{});var hkr=s(fH);wDe=r(hkr,"led"),hkr.forEach(t),ADe=r(Q0e," \u2014 "),R9=n(Q0e,"A",{href:!0});var pkr=s(R9);LDe=r(pkr,"LEDConfig"),pkr.forEach(t),BDe=r(Q0e," (LED model)"),Q0e.forEach(t),xDe=i(T),wm=n(T,"LI",{});var H0e=s(wm);mH=n(H0e,"STRONG",{});var _kr=s(mH);kDe=r(_kr,"longformer"),_kr.forEach(t),RDe=r(H0e," \u2014 "),S9=n(H0e,"A",{href:!0});var ukr=s(S9);SDe=r(ukr,"LongformerConfig"),ukr.forEach(t),PDe=r(H0e," (Longformer model)"),H0e.forEach(t),$De=i(T),Am=n(T,"LI",{});var U0e=s(Am);gH=n(U0e,"STRONG",{});var bkr=s(gH);IDe=r(bkr,"luke"),bkr.forEach(t),jDe=r(U0e," \u2014 "),P9=n(U0e,"A",{href:!0});var vkr=s(P9);DDe=r(vkr,"LukeConfig"),vkr.forEach(t),NDe=r(U0e," (LUKE model)"),U0e.forEach(t),qDe=i(T),Lm=n(T,"LI",{});var J0e=s(Lm);hH=n(J0e,"STRONG",{});var Tkr=s(hH);ODe=r(Tkr,"lxmert"),Tkr.forEach(t),GDe=r(J0e," \u2014 "),$9=n(J0e,"A",{href:!0});var Fkr=s($9);XDe=r(Fkr,"LxmertConfig"),Fkr.forEach(t),VDe=r(J0e," (LXMERT model)"),J0e.forEach(t),zDe=i(T),Bm=n(T,"LI",{});var Y0e=s(Bm);pH=n(Y0e,"STRONG",{});var Ckr=s(pH);WDe=r(Ckr,"m2m_100"),Ckr.forEach(t),QDe=r(Y0e," \u2014 "),I9=n(Y0e,"A",{href:!0});var Mkr=s(I9);HDe=r(Mkr,"M2M100Config"),Mkr.forEach(t),UDe=r(Y0e," (M2M100 model)"),Y0e.forEach(t),JDe=i(T),xm=n(T,"LI",{});var K0e=s(xm);_H=n(K0e,"STRONG",{});var Ekr=s(_H);YDe=r(Ekr,"marian"),Ekr.forEach(t),KDe=r(K0e," \u2014 "),j9=n(K0e,"A",{href:!0});var ykr=s(j9);ZDe=r(ykr,"MarianConfig"),ykr.forEach(t),eNe=r(K0e," (Marian model)"),K0e.forEach(t),oNe=i(T),km=n(T,"LI",{});var Z0e=s(km);uH=n(Z0e,"STRONG",{});var wkr=s(uH);rNe=r(wkr,"maskformer"),wkr.forEach(t),tNe=r(Z0e," \u2014 "),D9=n(Z0e,"A",{href:!0});var Akr=s(D9);aNe=r(Akr,"MaskFormerConfig"),Akr.forEach(t),nNe=r(Z0e," (MaskFormer model)"),Z0e.forEach(t),sNe=i(T),Rm=n(T,"LI",{});var eTe=s(Rm);bH=n(eTe,"STRONG",{});var Lkr=s(bH);lNe=r(Lkr,"mbart"),Lkr.forEach(t),iNe=r(eTe," \u2014 "),N9=n(eTe,"A",{href:!0});var Bkr=s(N9);dNe=r(Bkr,"MBartConfig"),Bkr.forEach(t),cNe=r(eTe," (mBART model)"),eTe.forEach(t),fNe=i(T),Sm=n(T,"LI",{});var oTe=s(Sm);vH=n(oTe,"STRONG",{});var xkr=s(vH);mNe=r(xkr,"megatron-bert"),xkr.forEach(t),gNe=r(oTe," \u2014 "),q9=n(oTe,"A",{href:!0});var kkr=s(q9);hNe=r(kkr,"MegatronBertConfig"),kkr.forEach(t),pNe=r(oTe," (MegatronBert model)"),oTe.forEach(t),_Ne=i(T),Pm=n(T,"LI",{});var rTe=s(Pm);TH=n(rTe,"STRONG",{});var Rkr=s(TH);uNe=r(Rkr,"mobilebert"),Rkr.forEach(t),bNe=r(rTe," \u2014 "),O9=n(rTe,"A",{href:!0});var Skr=s(O9);vNe=r(Skr,"MobileBertConfig"),Skr.forEach(t),TNe=r(rTe," (MobileBERT model)"),rTe.forEach(t),FNe=i(T),$m=n(T,"LI",{});var tTe=s($m);FH=n(tTe,"STRONG",{});var Pkr=s(FH);CNe=r(Pkr,"mpnet"),Pkr.forEach(t),MNe=r(tTe," \u2014 "),G9=n(tTe,"A",{href:!0});var $kr=s(G9);ENe=r($kr,"MPNetConfig"),$kr.forEach(t),yNe=r(tTe," (MPNet model)"),tTe.forEach(t),wNe=i(T),Im=n(T,"LI",{});var aTe=s(Im);CH=n(aTe,"STRONG",{});var Ikr=s(CH);ANe=r(Ikr,"mt5"),Ikr.forEach(t),LNe=r(aTe," \u2014 "),X9=n(aTe,"A",{href:!0});var jkr=s(X9);BNe=r(jkr,"MT5Config"),jkr.forEach(t),xNe=r(aTe," (mT5 model)"),aTe.forEach(t),kNe=i(T),jm=n(T,"LI",{});var nTe=s(jm);MH=n(nTe,"STRONG",{});var Dkr=s(MH);RNe=r(Dkr,"nystromformer"),Dkr.forEach(t),SNe=r(nTe," \u2014 "),V9=n(nTe,"A",{href:!0});var Nkr=s(V9);PNe=r(Nkr,"NystromformerConfig"),Nkr.forEach(t),$Ne=r(nTe," (Nystromformer model)"),nTe.forEach(t),INe=i(T),Dm=n(T,"LI",{});var sTe=s(Dm);EH=n(sTe,"STRONG",{});var qkr=s(EH);jNe=r(qkr,"openai-gpt"),qkr.forEach(t),DNe=r(sTe," \u2014 "),z9=n(sTe,"A",{href:!0});var Okr=s(z9);NNe=r(Okr,"OpenAIGPTConfig"),Okr.forEach(t),qNe=r(sTe," (OpenAI GPT model)"),sTe.forEach(t),ONe=i(T),Nm=n(T,"LI",{});var lTe=s(Nm);yH=n(lTe,"STRONG",{});var Gkr=s(yH);GNe=r(Gkr,"pegasus"),Gkr.forEach(t),XNe=r(lTe," \u2014 "),W9=n(lTe,"A",{href:!0});var Xkr=s(W9);VNe=r(Xkr,"PegasusConfig"),Xkr.forEach(t),zNe=r(lTe," (Pegasus model)"),lTe.forEach(t),WNe=i(T),qm=n(T,"LI",{});var iTe=s(qm);wH=n(iTe,"STRONG",{});var Vkr=s(wH);QNe=r(Vkr,"perceiver"),Vkr.forEach(t),HNe=r(iTe," \u2014 "),Q9=n(iTe,"A",{href:!0});var zkr=s(Q9);UNe=r(zkr,"PerceiverConfig"),zkr.forEach(t),JNe=r(iTe," (Perceiver model)"),iTe.forEach(t),YNe=i(T),Om=n(T,"LI",{});var dTe=s(Om);AH=n(dTe,"STRONG",{});var Wkr=s(AH);KNe=r(Wkr,"plbart"),Wkr.forEach(t),ZNe=r(dTe," \u2014 "),H9=n(dTe,"A",{href:!0});var Qkr=s(H9);eqe=r(Qkr,"PLBartConfig"),Qkr.forEach(t),oqe=r(dTe," (PLBart model)"),dTe.forEach(t),rqe=i(T),Gm=n(T,"LI",{});var cTe=s(Gm);LH=n(cTe,"STRONG",{});var Hkr=s(LH);tqe=r(Hkr,"poolformer"),Hkr.forEach(t),aqe=r(cTe," \u2014 "),U9=n(cTe,"A",{href:!0});var Ukr=s(U9);nqe=r(Ukr,"PoolFormerConfig"),Ukr.forEach(t),sqe=r(cTe," (PoolFormer model)"),cTe.forEach(t),lqe=i(T),Xm=n(T,"LI",{});var fTe=s(Xm);BH=n(fTe,"STRONG",{});var Jkr=s(BH);iqe=r(Jkr,"prophetnet"),Jkr.forEach(t),dqe=r(fTe," \u2014 "),J9=n(fTe,"A",{href:!0});var Ykr=s(J9);cqe=r(Ykr,"ProphetNetConfig"),Ykr.forEach(t),fqe=r(fTe," (ProphetNet model)"),fTe.forEach(t),mqe=i(T),Vm=n(T,"LI",{});var mTe=s(Vm);xH=n(mTe,"STRONG",{});var Kkr=s(xH);gqe=r(Kkr,"qdqbert"),Kkr.forEach(t),hqe=r(mTe," \u2014 "),Y9=n(mTe,"A",{href:!0});var Zkr=s(Y9);pqe=r(Zkr,"QDQBertConfig"),Zkr.forEach(t),_qe=r(mTe," (QDQBert model)"),mTe.forEach(t),uqe=i(T),zm=n(T,"LI",{});var gTe=s(zm);kH=n(gTe,"STRONG",{});var eRr=s(kH);bqe=r(eRr,"rag"),eRr.forEach(t),vqe=r(gTe," \u2014 "),K9=n(gTe,"A",{href:!0});var oRr=s(K9);Tqe=r(oRr,"RagConfig"),oRr.forEach(t),Fqe=r(gTe," (RAG model)"),gTe.forEach(t),Cqe=i(T),Wm=n(T,"LI",{});var hTe=s(Wm);RH=n(hTe,"STRONG",{});var rRr=s(RH);Mqe=r(rRr,"realm"),rRr.forEach(t),Eqe=r(hTe," \u2014 "),Z9=n(hTe,"A",{href:!0});var tRr=s(Z9);yqe=r(tRr,"RealmConfig"),tRr.forEach(t),wqe=r(hTe," (Realm model)"),hTe.forEach(t),Aqe=i(T),Qm=n(T,"LI",{});var pTe=s(Qm);SH=n(pTe,"STRONG",{});var aRr=s(SH);Lqe=r(aRr,"reformer"),aRr.forEach(t),Bqe=r(pTe," \u2014 "),eB=n(pTe,"A",{href:!0});var nRr=s(eB);xqe=r(nRr,"ReformerConfig"),nRr.forEach(t),kqe=r(pTe," (Reformer model)"),pTe.forEach(t),Rqe=i(T),Hm=n(T,"LI",{});var _Te=s(Hm);PH=n(_Te,"STRONG",{});var sRr=s(PH);Sqe=r(sRr,"rembert"),sRr.forEach(t),Pqe=r(_Te," \u2014 "),oB=n(_Te,"A",{href:!0});var lRr=s(oB);$qe=r(lRr,"RemBertConfig"),lRr.forEach(t),Iqe=r(_Te," (RemBERT model)"),_Te.forEach(t),jqe=i(T),Um=n(T,"LI",{});var uTe=s(Um);$H=n(uTe,"STRONG",{});var iRr=s($H);Dqe=r(iRr,"resnet"),iRr.forEach(t),Nqe=r(uTe," \u2014 "),rB=n(uTe,"A",{href:!0});var dRr=s(rB);qqe=r(dRr,"ResNetConfig"),dRr.forEach(t),Oqe=r(uTe," (ResNet model)"),uTe.forEach(t),Gqe=i(T),Jm=n(T,"LI",{});var bTe=s(Jm);IH=n(bTe,"STRONG",{});var cRr=s(IH);Xqe=r(cRr,"retribert"),cRr.forEach(t),Vqe=r(bTe," \u2014 "),tB=n(bTe,"A",{href:!0});var fRr=s(tB);zqe=r(fRr,"RetriBertConfig"),fRr.forEach(t),Wqe=r(bTe," (RetriBERT model)"),bTe.forEach(t),Qqe=i(T),Ym=n(T,"LI",{});var vTe=s(Ym);jH=n(vTe,"STRONG",{});var mRr=s(jH);Hqe=r(mRr,"roberta"),mRr.forEach(t),Uqe=r(vTe," \u2014 "),aB=n(vTe,"A",{href:!0});var gRr=s(aB);Jqe=r(gRr,"RobertaConfig"),gRr.forEach(t),Yqe=r(vTe," (RoBERTa model)"),vTe.forEach(t),Kqe=i(T),Km=n(T,"LI",{});var TTe=s(Km);DH=n(TTe,"STRONG",{});var hRr=s(DH);Zqe=r(hRr,"roformer"),hRr.forEach(t),eOe=r(TTe," \u2014 "),nB=n(TTe,"A",{href:!0});var pRr=s(nB);oOe=r(pRr,"RoFormerConfig"),pRr.forEach(t),rOe=r(TTe," (RoFormer model)"),TTe.forEach(t),tOe=i(T),Zm=n(T,"LI",{});var FTe=s(Zm);NH=n(FTe,"STRONG",{});var _Rr=s(NH);aOe=r(_Rr,"segformer"),_Rr.forEach(t),nOe=r(FTe," \u2014 "),sB=n(FTe,"A",{href:!0});var uRr=s(sB);sOe=r(uRr,"SegformerConfig"),uRr.forEach(t),lOe=r(FTe," (SegFormer model)"),FTe.forEach(t),iOe=i(T),eg=n(T,"LI",{});var CTe=s(eg);qH=n(CTe,"STRONG",{});var bRr=s(qH);dOe=r(bRr,"sew"),bRr.forEach(t),cOe=r(CTe," \u2014 "),lB=n(CTe,"A",{href:!0});var vRr=s(lB);fOe=r(vRr,"SEWConfig"),vRr.forEach(t),mOe=r(CTe," (SEW model)"),CTe.forEach(t),gOe=i(T),og=n(T,"LI",{});var MTe=s(og);OH=n(MTe,"STRONG",{});var TRr=s(OH);hOe=r(TRr,"sew-d"),TRr.forEach(t),pOe=r(MTe," \u2014 "),iB=n(MTe,"A",{href:!0});var FRr=s(iB);_Oe=r(FRr,"SEWDConfig"),FRr.forEach(t),uOe=r(MTe," (SEW-D model)"),MTe.forEach(t),bOe=i(T),rg=n(T,"LI",{});var ETe=s(rg);GH=n(ETe,"STRONG",{});var CRr=s(GH);vOe=r(CRr,"speech-encoder-decoder"),CRr.forEach(t),TOe=r(ETe," \u2014 "),dB=n(ETe,"A",{href:!0});var MRr=s(dB);FOe=r(MRr,"SpeechEncoderDecoderConfig"),MRr.forEach(t),COe=r(ETe," (Speech Encoder decoder model)"),ETe.forEach(t),MOe=i(T),tg=n(T,"LI",{});var yTe=s(tg);XH=n(yTe,"STRONG",{});var ERr=s(XH);EOe=r(ERr,"speech_to_text"),ERr.forEach(t),yOe=r(yTe," \u2014 "),cB=n(yTe,"A",{href:!0});var yRr=s(cB);wOe=r(yRr,"Speech2TextConfig"),yRr.forEach(t),AOe=r(yTe," (Speech2Text model)"),yTe.forEach(t),LOe=i(T),ag=n(T,"LI",{});var wTe=s(ag);VH=n(wTe,"STRONG",{});var wRr=s(VH);BOe=r(wRr,"speech_to_text_2"),wRr.forEach(t),xOe=r(wTe," \u2014 "),fB=n(wTe,"A",{href:!0});var ARr=s(fB);kOe=r(ARr,"Speech2Text2Config"),ARr.forEach(t),ROe=r(wTe," (Speech2Text2 model)"),wTe.forEach(t),SOe=i(T),ng=n(T,"LI",{});var ATe=s(ng);zH=n(ATe,"STRONG",{});var LRr=s(zH);POe=r(LRr,"splinter"),LRr.forEach(t),$Oe=r(ATe," \u2014 "),mB=n(ATe,"A",{href:!0});var BRr=s(mB);IOe=r(BRr,"SplinterConfig"),BRr.forEach(t),jOe=r(ATe," (Splinter model)"),ATe.forEach(t),DOe=i(T),sg=n(T,"LI",{});var LTe=s(sg);WH=n(LTe,"STRONG",{});var xRr=s(WH);NOe=r(xRr,"squeezebert"),xRr.forEach(t),qOe=r(LTe," \u2014 "),gB=n(LTe,"A",{href:!0});var kRr=s(gB);OOe=r(kRr,"SqueezeBertConfig"),kRr.forEach(t),GOe=r(LTe," (SqueezeBERT model)"),LTe.forEach(t),XOe=i(T),lg=n(T,"LI",{});var BTe=s(lg);QH=n(BTe,"STRONG",{});var RRr=s(QH);VOe=r(RRr,"swin"),RRr.forEach(t),zOe=r(BTe," \u2014 "),hB=n(BTe,"A",{href:!0});var SRr=s(hB);WOe=r(SRr,"SwinConfig"),SRr.forEach(t),QOe=r(BTe," (Swin model)"),BTe.forEach(t),HOe=i(T),ig=n(T,"LI",{});var xTe=s(ig);HH=n(xTe,"STRONG",{});var PRr=s(HH);UOe=r(PRr,"t5"),PRr.forEach(t),JOe=r(xTe," \u2014 "),pB=n(xTe,"A",{href:!0});var $Rr=s(pB);YOe=r($Rr,"T5Config"),$Rr.forEach(t),KOe=r(xTe," (T5 model)"),xTe.forEach(t),ZOe=i(T),dg=n(T,"LI",{});var kTe=s(dg);UH=n(kTe,"STRONG",{});var IRr=s(UH);eGe=r(IRr,"tapas"),IRr.forEach(t),oGe=r(kTe," \u2014 "),_B=n(kTe,"A",{href:!0});var jRr=s(_B);rGe=r(jRr,"TapasConfig"),jRr.forEach(t),tGe=r(kTe," (TAPAS model)"),kTe.forEach(t),aGe=i(T),cg=n(T,"LI",{});var RTe=s(cg);JH=n(RTe,"STRONG",{});var DRr=s(JH);nGe=r(DRr,"transfo-xl"),DRr.forEach(t),sGe=r(RTe," \u2014 "),uB=n(RTe,"A",{href:!0});var NRr=s(uB);lGe=r(NRr,"TransfoXLConfig"),NRr.forEach(t),iGe=r(RTe," (Transformer-XL model)"),RTe.forEach(t),dGe=i(T),fg=n(T,"LI",{});var STe=s(fg);YH=n(STe,"STRONG",{});var qRr=s(YH);cGe=r(qRr,"trocr"),qRr.forEach(t),fGe=r(STe," \u2014 "),bB=n(STe,"A",{href:!0});var ORr=s(bB);mGe=r(ORr,"TrOCRConfig"),ORr.forEach(t),gGe=r(STe," (TrOCR model)"),STe.forEach(t),hGe=i(T),mg=n(T,"LI",{});var PTe=s(mg);KH=n(PTe,"STRONG",{});var GRr=s(KH);pGe=r(GRr,"unispeech"),GRr.forEach(t),_Ge=r(PTe," \u2014 "),vB=n(PTe,"A",{href:!0});var XRr=s(vB);uGe=r(XRr,"UniSpeechConfig"),XRr.forEach(t),bGe=r(PTe," (UniSpeech model)"),PTe.forEach(t),vGe=i(T),gg=n(T,"LI",{});var $Te=s(gg);ZH=n($Te,"STRONG",{});var VRr=s(ZH);TGe=r(VRr,"unispeech-sat"),VRr.forEach(t),FGe=r($Te," \u2014 "),TB=n($Te,"A",{href:!0});var zRr=s(TB);CGe=r(zRr,"UniSpeechSatConfig"),zRr.forEach(t),MGe=r($Te," (UniSpeechSat model)"),$Te.forEach(t),EGe=i(T),hg=n(T,"LI",{});var ITe=s(hg);eU=n(ITe,"STRONG",{});var WRr=s(eU);yGe=r(WRr,"vilt"),WRr.forEach(t),wGe=r(ITe," \u2014 "),FB=n(ITe,"A",{href:!0});var QRr=s(FB);AGe=r(QRr,"ViltConfig"),QRr.forEach(t),LGe=r(ITe," (ViLT model)"),ITe.forEach(t),BGe=i(T),pg=n(T,"LI",{});var jTe=s(pg);oU=n(jTe,"STRONG",{});var HRr=s(oU);xGe=r(HRr,"vision-encoder-decoder"),HRr.forEach(t),kGe=r(jTe," \u2014 "),CB=n(jTe,"A",{href:!0});var URr=s(CB);RGe=r(URr,"VisionEncoderDecoderConfig"),URr.forEach(t),SGe=r(jTe," (Vision Encoder decoder model)"),jTe.forEach(t),PGe=i(T),_g=n(T,"LI",{});var DTe=s(_g);rU=n(DTe,"STRONG",{});var JRr=s(rU);$Ge=r(JRr,"vision-text-dual-encoder"),JRr.forEach(t),IGe=r(DTe," \u2014 "),MB=n(DTe,"A",{href:!0});var YRr=s(MB);jGe=r(YRr,"VisionTextDualEncoderConfig"),YRr.forEach(t),DGe=r(DTe," (VisionTextDualEncoder model)"),DTe.forEach(t),NGe=i(T),ug=n(T,"LI",{});var NTe=s(ug);tU=n(NTe,"STRONG",{});var KRr=s(tU);qGe=r(KRr,"visual_bert"),KRr.forEach(t),OGe=r(NTe," \u2014 "),EB=n(NTe,"A",{href:!0});var ZRr=s(EB);GGe=r(ZRr,"VisualBertConfig"),ZRr.forEach(t),XGe=r(NTe," (VisualBert model)"),NTe.forEach(t),VGe=i(T),bg=n(T,"LI",{});var qTe=s(bg);aU=n(qTe,"STRONG",{});var eSr=s(aU);zGe=r(eSr,"vit"),eSr.forEach(t),WGe=r(qTe," \u2014 "),yB=n(qTe,"A",{href:!0});var oSr=s(yB);QGe=r(oSr,"ViTConfig"),oSr.forEach(t),HGe=r(qTe," (ViT model)"),qTe.forEach(t),UGe=i(T),vg=n(T,"LI",{});var OTe=s(vg);nU=n(OTe,"STRONG",{});var rSr=s(nU);JGe=r(rSr,"vit_mae"),rSr.forEach(t),YGe=r(OTe," \u2014 "),wB=n(OTe,"A",{href:!0});var tSr=s(wB);KGe=r(tSr,"ViTMAEConfig"),tSr.forEach(t),ZGe=r(OTe," (ViTMAE model)"),OTe.forEach(t),eXe=i(T),Tg=n(T,"LI",{});var GTe=s(Tg);sU=n(GTe,"STRONG",{});var aSr=s(sU);oXe=r(aSr,"wav2vec2"),aSr.forEach(t),rXe=r(GTe," \u2014 "),AB=n(GTe,"A",{href:!0});var nSr=s(AB);tXe=r(nSr,"Wav2Vec2Config"),nSr.forEach(t),aXe=r(GTe," (Wav2Vec2 model)"),GTe.forEach(t),nXe=i(T),Fg=n(T,"LI",{});var XTe=s(Fg);lU=n(XTe,"STRONG",{});var sSr=s(lU);sXe=r(sSr,"wavlm"),sSr.forEach(t),lXe=r(XTe," \u2014 "),LB=n(XTe,"A",{href:!0});var lSr=s(LB);iXe=r(lSr,"WavLMConfig"),lSr.forEach(t),dXe=r(XTe," (WavLM model)"),XTe.forEach(t),cXe=i(T),Cg=n(T,"LI",{});var VTe=s(Cg);iU=n(VTe,"STRONG",{});var iSr=s(iU);fXe=r(iSr,"xglm"),iSr.forEach(t),mXe=r(VTe," \u2014 "),BB=n(VTe,"A",{href:!0});var dSr=s(BB);gXe=r(dSr,"XGLMConfig"),dSr.forEach(t),hXe=r(VTe," (XGLM model)"),VTe.forEach(t),pXe=i(T),Mg=n(T,"LI",{});var zTe=s(Mg);dU=n(zTe,"STRONG",{});var cSr=s(dU);_Xe=r(cSr,"xlm"),cSr.forEach(t),uXe=r(zTe," \u2014 "),xB=n(zTe,"A",{href:!0});var fSr=s(xB);bXe=r(fSr,"XLMConfig"),fSr.forEach(t),vXe=r(zTe," (XLM model)"),zTe.forEach(t),TXe=i(T),Eg=n(T,"LI",{});var WTe=s(Eg);cU=n(WTe,"STRONG",{});var mSr=s(cU);FXe=r(mSr,"xlm-prophetnet"),mSr.forEach(t),CXe=r(WTe," \u2014 "),kB=n(WTe,"A",{href:!0});var gSr=s(kB);MXe=r(gSr,"XLMProphetNetConfig"),gSr.forEach(t),EXe=r(WTe," (XLMProphetNet model)"),WTe.forEach(t),yXe=i(T),yg=n(T,"LI",{});var QTe=s(yg);fU=n(QTe,"STRONG",{});var hSr=s(fU);wXe=r(hSr,"xlm-roberta"),hSr.forEach(t),AXe=r(QTe," \u2014 "),RB=n(QTe,"A",{href:!0});var pSr=s(RB);LXe=r(pSr,"XLMRobertaConfig"),pSr.forEach(t),BXe=r(QTe," (XLM-RoBERTa model)"),QTe.forEach(t),xXe=i(T),wg=n(T,"LI",{});var HTe=s(wg);mU=n(HTe,"STRONG",{});var _Sr=s(mU);kXe=r(_Sr,"xlm-roberta-xl"),_Sr.forEach(t),RXe=r(HTe," \u2014 "),SB=n(HTe,"A",{href:!0});var uSr=s(SB);SXe=r(uSr,"XLMRobertaXLConfig"),uSr.forEach(t),PXe=r(HTe," (XLM-RoBERTa-XL model)"),HTe.forEach(t),$Xe=i(T),Ag=n(T,"LI",{});var UTe=s(Ag);gU=n(UTe,"STRONG",{});var bSr=s(gU);IXe=r(bSr,"xlnet"),bSr.forEach(t),jXe=r(UTe," \u2014 "),PB=n(UTe,"A",{href:!0});var vSr=s(PB);DXe=r(vSr,"XLNetConfig"),vSr.forEach(t),NXe=r(UTe," (XLNet model)"),UTe.forEach(t),qXe=i(T),Lg=n(T,"LI",{});var JTe=s(Lg);hU=n(JTe,"STRONG",{});var TSr=s(hU);OXe=r(TSr,"yoso"),TSr.forEach(t),GXe=r(JTe," \u2014 "),$B=n(JTe,"A",{href:!0});var FSr=s($B);XXe=r(FSr,"YosoConfig"),FSr.forEach(t),VXe=r(JTe," (YOSO model)"),JTe.forEach(t),T.forEach(t),zXe=i(ma),pU=n(ma,"P",{});var CSr=s(pU);WXe=r(CSr,"Examples:"),CSr.forEach(t),QXe=i(ma),m(sE.$$.fragment,ma),ma.forEach(t),HXe=i(Gs),Bg=n(Gs,"DIV",{class:!0});var MRe=s(Bg);m(lE.$$.fragment,MRe),UXe=i(MRe),_U=n(MRe,"P",{});var MSr=s(_U);JXe=r(MSr,"Register a new configuration for this class."),MSr.forEach(t),MRe.forEach(t),Gs.forEach(t),Fxe=i(c),Wi=n(c,"H2",{class:!0});var ERe=s(Wi);xg=n(ERe,"A",{id:!0,class:!0,href:!0});var ESr=s(xg);uU=n(ESr,"SPAN",{});var ySr=s(uU);m(iE.$$.fragment,ySr),ySr.forEach(t),ESr.forEach(t),YXe=i(ERe),bU=n(ERe,"SPAN",{});var wSr=s(bU);KXe=r(wSr,"AutoTokenizer"),wSr.forEach(t),ERe.forEach(t),Cxe=i(c),Qo=n(c,"DIV",{class:!0});var Xs=s(Qo);m(dE.$$.fragment,Xs),ZXe=i(Xs),cE=n(Xs,"P",{});var yRe=s(cE);eVe=r(yRe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),IB=n(yRe,"A",{href:!0});var ASr=s(IB);oVe=r(ASr,"AutoTokenizer.from_pretrained()"),ASr.forEach(t),rVe=r(yRe," class method."),yRe.forEach(t),tVe=i(Xs),fE=n(Xs,"P",{});var wRe=s(fE);aVe=r(wRe,"This class cannot be instantiated directly using "),vU=n(wRe,"CODE",{});var LSr=s(vU);nVe=r(LSr,"__init__()"),LSr.forEach(t),sVe=r(wRe," (throws an error)."),wRe.forEach(t),lVe=i(Xs),go=n(Xs,"DIV",{class:!0});var ga=s(go);m(mE.$$.fragment,ga),iVe=i(ga),TU=n(ga,"P",{});var BSr=s(TU);dVe=r(BSr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),BSr.forEach(t),cVe=i(ga),Oa=n(ga,"P",{});var JM=s(Oa);fVe=r(JM,"The tokenizer class to instantiate is selected based on the "),FU=n(JM,"CODE",{});var xSr=s(FU);mVe=r(xSr,"model_type"),xSr.forEach(t),gVe=r(JM,` property of the config object (either
passed as an argument or loaded from `),CU=n(JM,"CODE",{});var kSr=s(CU);hVe=r(kSr,"pretrained_model_name_or_path"),kSr.forEach(t),pVe=r(JM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MU=n(JM,"CODE",{});var RSr=s(MU);_Ve=r(RSr,"pretrained_model_name_or_path"),RSr.forEach(t),uVe=r(JM,":"),JM.forEach(t),bVe=i(ga),E=n(ga,"UL",{});var y=s(E);Wn=n(y,"LI",{});var WL=s(Wn);EU=n(WL,"STRONG",{});var SSr=s(EU);vVe=r(SSr,"albert"),SSr.forEach(t),TVe=r(WL," \u2014 "),jB=n(WL,"A",{href:!0});var PSr=s(jB);FVe=r(PSr,"AlbertTokenizer"),PSr.forEach(t),CVe=r(WL," or "),DB=n(WL,"A",{href:!0});var $Sr=s(DB);MVe=r($Sr,"AlbertTokenizerFast"),$Sr.forEach(t),EVe=r(WL," (ALBERT model)"),WL.forEach(t),yVe=i(y),Qn=n(y,"LI",{});var QL=s(Qn);yU=n(QL,"STRONG",{});var ISr=s(yU);wVe=r(ISr,"bart"),ISr.forEach(t),AVe=r(QL," \u2014 "),NB=n(QL,"A",{href:!0});var jSr=s(NB);LVe=r(jSr,"BartTokenizer"),jSr.forEach(t),BVe=r(QL," or "),qB=n(QL,"A",{href:!0});var DSr=s(qB);xVe=r(DSr,"BartTokenizerFast"),DSr.forEach(t),kVe=r(QL," (BART model)"),QL.forEach(t),RVe=i(y),Hn=n(y,"LI",{});var HL=s(Hn);wU=n(HL,"STRONG",{});var NSr=s(wU);SVe=r(NSr,"barthez"),NSr.forEach(t),PVe=r(HL," \u2014 "),OB=n(HL,"A",{href:!0});var qSr=s(OB);$Ve=r(qSr,"BarthezTokenizer"),qSr.forEach(t),IVe=r(HL," or "),GB=n(HL,"A",{href:!0});var OSr=s(GB);jVe=r(OSr,"BarthezTokenizerFast"),OSr.forEach(t),DVe=r(HL," (BARThez model)"),HL.forEach(t),NVe=i(y),kg=n(y,"LI",{});var YTe=s(kg);AU=n(YTe,"STRONG",{});var GSr=s(AU);qVe=r(GSr,"bartpho"),GSr.forEach(t),OVe=r(YTe," \u2014 "),XB=n(YTe,"A",{href:!0});var XSr=s(XB);GVe=r(XSr,"BartphoTokenizer"),XSr.forEach(t),XVe=r(YTe," (BARTpho model)"),YTe.forEach(t),VVe=i(y),Un=n(y,"LI",{});var UL=s(Un);LU=n(UL,"STRONG",{});var VSr=s(LU);zVe=r(VSr,"bert"),VSr.forEach(t),WVe=r(UL," \u2014 "),VB=n(UL,"A",{href:!0});var zSr=s(VB);QVe=r(zSr,"BertTokenizer"),zSr.forEach(t),HVe=r(UL," or "),zB=n(UL,"A",{href:!0});var WSr=s(zB);UVe=r(WSr,"BertTokenizerFast"),WSr.forEach(t),JVe=r(UL," (BERT model)"),UL.forEach(t),YVe=i(y),Rg=n(y,"LI",{});var KTe=s(Rg);BU=n(KTe,"STRONG",{});var QSr=s(BU);KVe=r(QSr,"bert-generation"),QSr.forEach(t),ZVe=r(KTe," \u2014 "),WB=n(KTe,"A",{href:!0});var HSr=s(WB);eze=r(HSr,"BertGenerationTokenizer"),HSr.forEach(t),oze=r(KTe," (Bert Generation model)"),KTe.forEach(t),rze=i(y),Sg=n(y,"LI",{});var ZTe=s(Sg);xU=n(ZTe,"STRONG",{});var USr=s(xU);tze=r(USr,"bert-japanese"),USr.forEach(t),aze=r(ZTe," \u2014 "),QB=n(ZTe,"A",{href:!0});var JSr=s(QB);nze=r(JSr,"BertJapaneseTokenizer"),JSr.forEach(t),sze=r(ZTe," (BertJapanese model)"),ZTe.forEach(t),lze=i(y),Pg=n(y,"LI",{});var eFe=s(Pg);kU=n(eFe,"STRONG",{});var YSr=s(kU);ize=r(YSr,"bertweet"),YSr.forEach(t),dze=r(eFe," \u2014 "),HB=n(eFe,"A",{href:!0});var KSr=s(HB);cze=r(KSr,"BertweetTokenizer"),KSr.forEach(t),fze=r(eFe," (Bertweet model)"),eFe.forEach(t),mze=i(y),Jn=n(y,"LI",{});var JL=s(Jn);RU=n(JL,"STRONG",{});var ZSr=s(RU);gze=r(ZSr,"big_bird"),ZSr.forEach(t),hze=r(JL," \u2014 "),UB=n(JL,"A",{href:!0});var ePr=s(UB);pze=r(ePr,"BigBirdTokenizer"),ePr.forEach(t),_ze=r(JL," or "),JB=n(JL,"A",{href:!0});var oPr=s(JB);uze=r(oPr,"BigBirdTokenizerFast"),oPr.forEach(t),bze=r(JL," (BigBird model)"),JL.forEach(t),vze=i(y),Yn=n(y,"LI",{});var YL=s(Yn);SU=n(YL,"STRONG",{});var rPr=s(SU);Tze=r(rPr,"bigbird_pegasus"),rPr.forEach(t),Fze=r(YL," \u2014 "),YB=n(YL,"A",{href:!0});var tPr=s(YB);Cze=r(tPr,"PegasusTokenizer"),tPr.forEach(t),Mze=r(YL," or "),KB=n(YL,"A",{href:!0});var aPr=s(KB);Eze=r(aPr,"PegasusTokenizerFast"),aPr.forEach(t),yze=r(YL," (BigBirdPegasus model)"),YL.forEach(t),wze=i(y),Kn=n(y,"LI",{});var KL=s(Kn);PU=n(KL,"STRONG",{});var nPr=s(PU);Aze=r(nPr,"blenderbot"),nPr.forEach(t),Lze=r(KL," \u2014 "),ZB=n(KL,"A",{href:!0});var sPr=s(ZB);Bze=r(sPr,"BlenderbotTokenizer"),sPr.forEach(t),xze=r(KL," or "),ex=n(KL,"A",{href:!0});var lPr=s(ex);kze=r(lPr,"BlenderbotTokenizerFast"),lPr.forEach(t),Rze=r(KL," (Blenderbot model)"),KL.forEach(t),Sze=i(y),$g=n(y,"LI",{});var oFe=s($g);$U=n(oFe,"STRONG",{});var iPr=s($U);Pze=r(iPr,"blenderbot-small"),iPr.forEach(t),$ze=r(oFe," \u2014 "),ox=n(oFe,"A",{href:!0});var dPr=s(ox);Ize=r(dPr,"BlenderbotSmallTokenizer"),dPr.forEach(t),jze=r(oFe," (BlenderbotSmall model)"),oFe.forEach(t),Dze=i(y),Ig=n(y,"LI",{});var rFe=s(Ig);IU=n(rFe,"STRONG",{});var cPr=s(IU);Nze=r(cPr,"byt5"),cPr.forEach(t),qze=r(rFe," \u2014 "),rx=n(rFe,"A",{href:!0});var fPr=s(rx);Oze=r(fPr,"ByT5Tokenizer"),fPr.forEach(t),Gze=r(rFe," (ByT5 model)"),rFe.forEach(t),Xze=i(y),Zn=n(y,"LI",{});var ZL=s(Zn);jU=n(ZL,"STRONG",{});var mPr=s(jU);Vze=r(mPr,"camembert"),mPr.forEach(t),zze=r(ZL," \u2014 "),tx=n(ZL,"A",{href:!0});var gPr=s(tx);Wze=r(gPr,"CamembertTokenizer"),gPr.forEach(t),Qze=r(ZL," or "),ax=n(ZL,"A",{href:!0});var hPr=s(ax);Hze=r(hPr,"CamembertTokenizerFast"),hPr.forEach(t),Uze=r(ZL," (CamemBERT model)"),ZL.forEach(t),Jze=i(y),jg=n(y,"LI",{});var tFe=s(jg);DU=n(tFe,"STRONG",{});var pPr=s(DU);Yze=r(pPr,"canine"),pPr.forEach(t),Kze=r(tFe," \u2014 "),nx=n(tFe,"A",{href:!0});var _Pr=s(nx);Zze=r(_Pr,"CanineTokenizer"),_Pr.forEach(t),eWe=r(tFe," (Canine model)"),tFe.forEach(t),oWe=i(y),es=n(y,"LI",{});var e8=s(es);NU=n(e8,"STRONG",{});var uPr=s(NU);rWe=r(uPr,"clip"),uPr.forEach(t),tWe=r(e8," \u2014 "),sx=n(e8,"A",{href:!0});var bPr=s(sx);aWe=r(bPr,"CLIPTokenizer"),bPr.forEach(t),nWe=r(e8," or "),lx=n(e8,"A",{href:!0});var vPr=s(lx);sWe=r(vPr,"CLIPTokenizerFast"),vPr.forEach(t),lWe=r(e8," (CLIP model)"),e8.forEach(t),iWe=i(y),os=n(y,"LI",{});var o8=s(os);qU=n(o8,"STRONG",{});var TPr=s(qU);dWe=r(TPr,"convbert"),TPr.forEach(t),cWe=r(o8," \u2014 "),ix=n(o8,"A",{href:!0});var FPr=s(ix);fWe=r(FPr,"ConvBertTokenizer"),FPr.forEach(t),mWe=r(o8," or "),dx=n(o8,"A",{href:!0});var CPr=s(dx);gWe=r(CPr,"ConvBertTokenizerFast"),CPr.forEach(t),hWe=r(o8," (ConvBERT model)"),o8.forEach(t),pWe=i(y),rs=n(y,"LI",{});var r8=s(rs);OU=n(r8,"STRONG",{});var MPr=s(OU);_We=r(MPr,"cpm"),MPr.forEach(t),uWe=r(r8," \u2014 "),cx=n(r8,"A",{href:!0});var EPr=s(cx);bWe=r(EPr,"CpmTokenizer"),EPr.forEach(t),vWe=r(r8," or "),GU=n(r8,"CODE",{});var yPr=s(GU);TWe=r(yPr,"CpmTokenizerFast"),yPr.forEach(t),FWe=r(r8," (CPM model)"),r8.forEach(t),CWe=i(y),Dg=n(y,"LI",{});var aFe=s(Dg);XU=n(aFe,"STRONG",{});var wPr=s(XU);MWe=r(wPr,"ctrl"),wPr.forEach(t),EWe=r(aFe," \u2014 "),fx=n(aFe,"A",{href:!0});var APr=s(fx);yWe=r(APr,"CTRLTokenizer"),APr.forEach(t),wWe=r(aFe," (CTRL model)"),aFe.forEach(t),AWe=i(y),ts=n(y,"LI",{});var t8=s(ts);VU=n(t8,"STRONG",{});var LPr=s(VU);LWe=r(LPr,"deberta"),LPr.forEach(t),BWe=r(t8," \u2014 "),mx=n(t8,"A",{href:!0});var BPr=s(mx);xWe=r(BPr,"DebertaTokenizer"),BPr.forEach(t),kWe=r(t8," or "),gx=n(t8,"A",{href:!0});var xPr=s(gx);RWe=r(xPr,"DebertaTokenizerFast"),xPr.forEach(t),SWe=r(t8," (DeBERTa model)"),t8.forEach(t),PWe=i(y),Ng=n(y,"LI",{});var nFe=s(Ng);zU=n(nFe,"STRONG",{});var kPr=s(zU);$We=r(kPr,"deberta-v2"),kPr.forEach(t),IWe=r(nFe," \u2014 "),hx=n(nFe,"A",{href:!0});var RPr=s(hx);jWe=r(RPr,"DebertaV2Tokenizer"),RPr.forEach(t),DWe=r(nFe," (DeBERTa-v2 model)"),nFe.forEach(t),NWe=i(y),as=n(y,"LI",{});var a8=s(as);WU=n(a8,"STRONG",{});var SPr=s(WU);qWe=r(SPr,"distilbert"),SPr.forEach(t),OWe=r(a8," \u2014 "),px=n(a8,"A",{href:!0});var PPr=s(px);GWe=r(PPr,"DistilBertTokenizer"),PPr.forEach(t),XWe=r(a8," or "),_x=n(a8,"A",{href:!0});var $Pr=s(_x);VWe=r($Pr,"DistilBertTokenizerFast"),$Pr.forEach(t),zWe=r(a8," (DistilBERT model)"),a8.forEach(t),WWe=i(y),ns=n(y,"LI",{});var n8=s(ns);QU=n(n8,"STRONG",{});var IPr=s(QU);QWe=r(IPr,"dpr"),IPr.forEach(t),HWe=r(n8," \u2014 "),ux=n(n8,"A",{href:!0});var jPr=s(ux);UWe=r(jPr,"DPRQuestionEncoderTokenizer"),jPr.forEach(t),JWe=r(n8," or "),bx=n(n8,"A",{href:!0});var DPr=s(bx);YWe=r(DPr,"DPRQuestionEncoderTokenizerFast"),DPr.forEach(t),KWe=r(n8," (DPR model)"),n8.forEach(t),ZWe=i(y),ss=n(y,"LI",{});var s8=s(ss);HU=n(s8,"STRONG",{});var NPr=s(HU);eQe=r(NPr,"electra"),NPr.forEach(t),oQe=r(s8," \u2014 "),vx=n(s8,"A",{href:!0});var qPr=s(vx);rQe=r(qPr,"ElectraTokenizer"),qPr.forEach(t),tQe=r(s8," or "),Tx=n(s8,"A",{href:!0});var OPr=s(Tx);aQe=r(OPr,"ElectraTokenizerFast"),OPr.forEach(t),nQe=r(s8," (ELECTRA model)"),s8.forEach(t),sQe=i(y),qg=n(y,"LI",{});var sFe=s(qg);UU=n(sFe,"STRONG",{});var GPr=s(UU);lQe=r(GPr,"flaubert"),GPr.forEach(t),iQe=r(sFe," \u2014 "),Fx=n(sFe,"A",{href:!0});var XPr=s(Fx);dQe=r(XPr,"FlaubertTokenizer"),XPr.forEach(t),cQe=r(sFe," (FlauBERT model)"),sFe.forEach(t),fQe=i(y),ls=n(y,"LI",{});var l8=s(ls);JU=n(l8,"STRONG",{});var VPr=s(JU);mQe=r(VPr,"fnet"),VPr.forEach(t),gQe=r(l8," \u2014 "),Cx=n(l8,"A",{href:!0});var zPr=s(Cx);hQe=r(zPr,"FNetTokenizer"),zPr.forEach(t),pQe=r(l8," or "),Mx=n(l8,"A",{href:!0});var WPr=s(Mx);_Qe=r(WPr,"FNetTokenizerFast"),WPr.forEach(t),uQe=r(l8," (FNet model)"),l8.forEach(t),bQe=i(y),Og=n(y,"LI",{});var lFe=s(Og);YU=n(lFe,"STRONG",{});var QPr=s(YU);vQe=r(QPr,"fsmt"),QPr.forEach(t),TQe=r(lFe," \u2014 "),Ex=n(lFe,"A",{href:!0});var HPr=s(Ex);FQe=r(HPr,"FSMTTokenizer"),HPr.forEach(t),CQe=r(lFe," (FairSeq Machine-Translation model)"),lFe.forEach(t),MQe=i(y),is=n(y,"LI",{});var i8=s(is);KU=n(i8,"STRONG",{});var UPr=s(KU);EQe=r(UPr,"funnel"),UPr.forEach(t),yQe=r(i8," \u2014 "),yx=n(i8,"A",{href:!0});var JPr=s(yx);wQe=r(JPr,"FunnelTokenizer"),JPr.forEach(t),AQe=r(i8," or "),wx=n(i8,"A",{href:!0});var YPr=s(wx);LQe=r(YPr,"FunnelTokenizerFast"),YPr.forEach(t),BQe=r(i8," (Funnel Transformer model)"),i8.forEach(t),xQe=i(y),ds=n(y,"LI",{});var d8=s(ds);ZU=n(d8,"STRONG",{});var KPr=s(ZU);kQe=r(KPr,"gpt2"),KPr.forEach(t),RQe=r(d8," \u2014 "),Ax=n(d8,"A",{href:!0});var ZPr=s(Ax);SQe=r(ZPr,"GPT2Tokenizer"),ZPr.forEach(t),PQe=r(d8," or "),Lx=n(d8,"A",{href:!0});var e$r=s(Lx);$Qe=r(e$r,"GPT2TokenizerFast"),e$r.forEach(t),IQe=r(d8," (OpenAI GPT-2 model)"),d8.forEach(t),jQe=i(y),cs=n(y,"LI",{});var c8=s(cs);eJ=n(c8,"STRONG",{});var o$r=s(eJ);DQe=r(o$r,"gpt_neo"),o$r.forEach(t),NQe=r(c8," \u2014 "),Bx=n(c8,"A",{href:!0});var r$r=s(Bx);qQe=r(r$r,"GPT2Tokenizer"),r$r.forEach(t),OQe=r(c8," or "),xx=n(c8,"A",{href:!0});var t$r=s(xx);GQe=r(t$r,"GPT2TokenizerFast"),t$r.forEach(t),XQe=r(c8," (GPT Neo model)"),c8.forEach(t),VQe=i(y),fs=n(y,"LI",{});var f8=s(fs);oJ=n(f8,"STRONG",{});var a$r=s(oJ);zQe=r(a$r,"herbert"),a$r.forEach(t),WQe=r(f8," \u2014 "),kx=n(f8,"A",{href:!0});var n$r=s(kx);QQe=r(n$r,"HerbertTokenizer"),n$r.forEach(t),HQe=r(f8," or "),Rx=n(f8,"A",{href:!0});var s$r=s(Rx);UQe=r(s$r,"HerbertTokenizerFast"),s$r.forEach(t),JQe=r(f8," (HerBERT model)"),f8.forEach(t),YQe=i(y),Gg=n(y,"LI",{});var iFe=s(Gg);rJ=n(iFe,"STRONG",{});var l$r=s(rJ);KQe=r(l$r,"hubert"),l$r.forEach(t),ZQe=r(iFe," \u2014 "),Sx=n(iFe,"A",{href:!0});var i$r=s(Sx);eHe=r(i$r,"Wav2Vec2CTCTokenizer"),i$r.forEach(t),oHe=r(iFe," (Hubert model)"),iFe.forEach(t),rHe=i(y),ms=n(y,"LI",{});var m8=s(ms);tJ=n(m8,"STRONG",{});var d$r=s(tJ);tHe=r(d$r,"ibert"),d$r.forEach(t),aHe=r(m8," \u2014 "),Px=n(m8,"A",{href:!0});var c$r=s(Px);nHe=r(c$r,"RobertaTokenizer"),c$r.forEach(t),sHe=r(m8," or "),$x=n(m8,"A",{href:!0});var f$r=s($x);lHe=r(f$r,"RobertaTokenizerFast"),f$r.forEach(t),iHe=r(m8," (I-BERT model)"),m8.forEach(t),dHe=i(y),gs=n(y,"LI",{});var g8=s(gs);aJ=n(g8,"STRONG",{});var m$r=s(aJ);cHe=r(m$r,"layoutlm"),m$r.forEach(t),fHe=r(g8," \u2014 "),Ix=n(g8,"A",{href:!0});var g$r=s(Ix);mHe=r(g$r,"LayoutLMTokenizer"),g$r.forEach(t),gHe=r(g8," or "),jx=n(g8,"A",{href:!0});var h$r=s(jx);hHe=r(h$r,"LayoutLMTokenizerFast"),h$r.forEach(t),pHe=r(g8," (LayoutLM model)"),g8.forEach(t),_He=i(y),hs=n(y,"LI",{});var h8=s(hs);nJ=n(h8,"STRONG",{});var p$r=s(nJ);uHe=r(p$r,"layoutlmv2"),p$r.forEach(t),bHe=r(h8," \u2014 "),Dx=n(h8,"A",{href:!0});var _$r=s(Dx);vHe=r(_$r,"LayoutLMv2Tokenizer"),_$r.forEach(t),THe=r(h8," or "),Nx=n(h8,"A",{href:!0});var u$r=s(Nx);FHe=r(u$r,"LayoutLMv2TokenizerFast"),u$r.forEach(t),CHe=r(h8," (LayoutLMv2 model)"),h8.forEach(t),MHe=i(y),ps=n(y,"LI",{});var p8=s(ps);sJ=n(p8,"STRONG",{});var b$r=s(sJ);EHe=r(b$r,"layoutxlm"),b$r.forEach(t),yHe=r(p8," \u2014 "),qx=n(p8,"A",{href:!0});var v$r=s(qx);wHe=r(v$r,"LayoutXLMTokenizer"),v$r.forEach(t),AHe=r(p8," or "),Ox=n(p8,"A",{href:!0});var T$r=s(Ox);LHe=r(T$r,"LayoutXLMTokenizerFast"),T$r.forEach(t),BHe=r(p8," (LayoutXLM model)"),p8.forEach(t),xHe=i(y),_s=n(y,"LI",{});var _8=s(_s);lJ=n(_8,"STRONG",{});var F$r=s(lJ);kHe=r(F$r,"led"),F$r.forEach(t),RHe=r(_8," \u2014 "),Gx=n(_8,"A",{href:!0});var C$r=s(Gx);SHe=r(C$r,"LEDTokenizer"),C$r.forEach(t),PHe=r(_8," or "),Xx=n(_8,"A",{href:!0});var M$r=s(Xx);$He=r(M$r,"LEDTokenizerFast"),M$r.forEach(t),IHe=r(_8," (LED model)"),_8.forEach(t),jHe=i(y),us=n(y,"LI",{});var u8=s(us);iJ=n(u8,"STRONG",{});var E$r=s(iJ);DHe=r(E$r,"longformer"),E$r.forEach(t),NHe=r(u8," \u2014 "),Vx=n(u8,"A",{href:!0});var y$r=s(Vx);qHe=r(y$r,"LongformerTokenizer"),y$r.forEach(t),OHe=r(u8," or "),zx=n(u8,"A",{href:!0});var w$r=s(zx);GHe=r(w$r,"LongformerTokenizerFast"),w$r.forEach(t),XHe=r(u8," (Longformer model)"),u8.forEach(t),VHe=i(y),Xg=n(y,"LI",{});var dFe=s(Xg);dJ=n(dFe,"STRONG",{});var A$r=s(dJ);zHe=r(A$r,"luke"),A$r.forEach(t),WHe=r(dFe," \u2014 "),Wx=n(dFe,"A",{href:!0});var L$r=s(Wx);QHe=r(L$r,"LukeTokenizer"),L$r.forEach(t),HHe=r(dFe," (LUKE model)"),dFe.forEach(t),UHe=i(y),bs=n(y,"LI",{});var b8=s(bs);cJ=n(b8,"STRONG",{});var B$r=s(cJ);JHe=r(B$r,"lxmert"),B$r.forEach(t),YHe=r(b8," \u2014 "),Qx=n(b8,"A",{href:!0});var x$r=s(Qx);KHe=r(x$r,"LxmertTokenizer"),x$r.forEach(t),ZHe=r(b8," or "),Hx=n(b8,"A",{href:!0});var k$r=s(Hx);eUe=r(k$r,"LxmertTokenizerFast"),k$r.forEach(t),oUe=r(b8," (LXMERT model)"),b8.forEach(t),rUe=i(y),Vg=n(y,"LI",{});var cFe=s(Vg);fJ=n(cFe,"STRONG",{});var R$r=s(fJ);tUe=r(R$r,"m2m_100"),R$r.forEach(t),aUe=r(cFe," \u2014 "),Ux=n(cFe,"A",{href:!0});var S$r=s(Ux);nUe=r(S$r,"M2M100Tokenizer"),S$r.forEach(t),sUe=r(cFe," (M2M100 model)"),cFe.forEach(t),lUe=i(y),zg=n(y,"LI",{});var fFe=s(zg);mJ=n(fFe,"STRONG",{});var P$r=s(mJ);iUe=r(P$r,"marian"),P$r.forEach(t),dUe=r(fFe," \u2014 "),Jx=n(fFe,"A",{href:!0});var $$r=s(Jx);cUe=r($$r,"MarianTokenizer"),$$r.forEach(t),fUe=r(fFe," (Marian model)"),fFe.forEach(t),mUe=i(y),vs=n(y,"LI",{});var v8=s(vs);gJ=n(v8,"STRONG",{});var I$r=s(gJ);gUe=r(I$r,"mbart"),I$r.forEach(t),hUe=r(v8," \u2014 "),Yx=n(v8,"A",{href:!0});var j$r=s(Yx);pUe=r(j$r,"MBartTokenizer"),j$r.forEach(t),_Ue=r(v8," or "),Kx=n(v8,"A",{href:!0});var D$r=s(Kx);uUe=r(D$r,"MBartTokenizerFast"),D$r.forEach(t),bUe=r(v8," (mBART model)"),v8.forEach(t),vUe=i(y),Ts=n(y,"LI",{});var T8=s(Ts);hJ=n(T8,"STRONG",{});var N$r=s(hJ);TUe=r(N$r,"mbart50"),N$r.forEach(t),FUe=r(T8," \u2014 "),Zx=n(T8,"A",{href:!0});var q$r=s(Zx);CUe=r(q$r,"MBart50Tokenizer"),q$r.forEach(t),MUe=r(T8," or "),ek=n(T8,"A",{href:!0});var O$r=s(ek);EUe=r(O$r,"MBart50TokenizerFast"),O$r.forEach(t),yUe=r(T8," (mBART-50 model)"),T8.forEach(t),wUe=i(y),Wg=n(y,"LI",{});var mFe=s(Wg);pJ=n(mFe,"STRONG",{});var G$r=s(pJ);AUe=r(G$r,"mluke"),G$r.forEach(t),LUe=r(mFe," \u2014 "),ok=n(mFe,"A",{href:!0});var X$r=s(ok);BUe=r(X$r,"MLukeTokenizer"),X$r.forEach(t),xUe=r(mFe," (mLUKE model)"),mFe.forEach(t),kUe=i(y),Fs=n(y,"LI",{});var F8=s(Fs);_J=n(F8,"STRONG",{});var V$r=s(_J);RUe=r(V$r,"mobilebert"),V$r.forEach(t),SUe=r(F8," \u2014 "),rk=n(F8,"A",{href:!0});var z$r=s(rk);PUe=r(z$r,"MobileBertTokenizer"),z$r.forEach(t),$Ue=r(F8," or "),tk=n(F8,"A",{href:!0});var W$r=s(tk);IUe=r(W$r,"MobileBertTokenizerFast"),W$r.forEach(t),jUe=r(F8," (MobileBERT model)"),F8.forEach(t),DUe=i(y),Cs=n(y,"LI",{});var C8=s(Cs);uJ=n(C8,"STRONG",{});var Q$r=s(uJ);NUe=r(Q$r,"mpnet"),Q$r.forEach(t),qUe=r(C8," \u2014 "),ak=n(C8,"A",{href:!0});var H$r=s(ak);OUe=r(H$r,"MPNetTokenizer"),H$r.forEach(t),GUe=r(C8," or "),nk=n(C8,"A",{href:!0});var U$r=s(nk);XUe=r(U$r,"MPNetTokenizerFast"),U$r.forEach(t),VUe=r(C8," (MPNet model)"),C8.forEach(t),zUe=i(y),Ms=n(y,"LI",{});var M8=s(Ms);bJ=n(M8,"STRONG",{});var J$r=s(bJ);WUe=r(J$r,"mt5"),J$r.forEach(t),QUe=r(M8," \u2014 "),sk=n(M8,"A",{href:!0});var Y$r=s(sk);HUe=r(Y$r,"MT5Tokenizer"),Y$r.forEach(t),UUe=r(M8," or "),lk=n(M8,"A",{href:!0});var K$r=s(lk);JUe=r(K$r,"MT5TokenizerFast"),K$r.forEach(t),YUe=r(M8," (mT5 model)"),M8.forEach(t),KUe=i(y),Es=n(y,"LI",{});var E8=s(Es);vJ=n(E8,"STRONG",{});var Z$r=s(vJ);ZUe=r(Z$r,"openai-gpt"),Z$r.forEach(t),eJe=r(E8," \u2014 "),ik=n(E8,"A",{href:!0});var eIr=s(ik);oJe=r(eIr,"OpenAIGPTTokenizer"),eIr.forEach(t),rJe=r(E8," or "),dk=n(E8,"A",{href:!0});var oIr=s(dk);tJe=r(oIr,"OpenAIGPTTokenizerFast"),oIr.forEach(t),aJe=r(E8," (OpenAI GPT model)"),E8.forEach(t),nJe=i(y),ys=n(y,"LI",{});var y8=s(ys);TJ=n(y8,"STRONG",{});var rIr=s(TJ);sJe=r(rIr,"pegasus"),rIr.forEach(t),lJe=r(y8," \u2014 "),ck=n(y8,"A",{href:!0});var tIr=s(ck);iJe=r(tIr,"PegasusTokenizer"),tIr.forEach(t),dJe=r(y8," or "),fk=n(y8,"A",{href:!0});var aIr=s(fk);cJe=r(aIr,"PegasusTokenizerFast"),aIr.forEach(t),fJe=r(y8," (Pegasus model)"),y8.forEach(t),mJe=i(y),Qg=n(y,"LI",{});var gFe=s(Qg);FJ=n(gFe,"STRONG",{});var nIr=s(FJ);gJe=r(nIr,"perceiver"),nIr.forEach(t),hJe=r(gFe," \u2014 "),mk=n(gFe,"A",{href:!0});var sIr=s(mk);pJe=r(sIr,"PerceiverTokenizer"),sIr.forEach(t),_Je=r(gFe," (Perceiver model)"),gFe.forEach(t),uJe=i(y),Hg=n(y,"LI",{});var hFe=s(Hg);CJ=n(hFe,"STRONG",{});var lIr=s(CJ);bJe=r(lIr,"phobert"),lIr.forEach(t),vJe=r(hFe," \u2014 "),gk=n(hFe,"A",{href:!0});var iIr=s(gk);TJe=r(iIr,"PhobertTokenizer"),iIr.forEach(t),FJe=r(hFe," (PhoBERT model)"),hFe.forEach(t),CJe=i(y),Ug=n(y,"LI",{});var pFe=s(Ug);MJ=n(pFe,"STRONG",{});var dIr=s(MJ);MJe=r(dIr,"plbart"),dIr.forEach(t),EJe=r(pFe," \u2014 "),hk=n(pFe,"A",{href:!0});var cIr=s(hk);yJe=r(cIr,"PLBartTokenizer"),cIr.forEach(t),wJe=r(pFe," (PLBart model)"),pFe.forEach(t),AJe=i(y),Jg=n(y,"LI",{});var _Fe=s(Jg);EJ=n(_Fe,"STRONG",{});var fIr=s(EJ);LJe=r(fIr,"prophetnet"),fIr.forEach(t),BJe=r(_Fe," \u2014 "),pk=n(_Fe,"A",{href:!0});var mIr=s(pk);xJe=r(mIr,"ProphetNetTokenizer"),mIr.forEach(t),kJe=r(_Fe," (ProphetNet model)"),_Fe.forEach(t),RJe=i(y),ws=n(y,"LI",{});var w8=s(ws);yJ=n(w8,"STRONG",{});var gIr=s(yJ);SJe=r(gIr,"qdqbert"),gIr.forEach(t),PJe=r(w8," \u2014 "),_k=n(w8,"A",{href:!0});var hIr=s(_k);$Je=r(hIr,"BertTokenizer"),hIr.forEach(t),IJe=r(w8," or "),uk=n(w8,"A",{href:!0});var pIr=s(uk);jJe=r(pIr,"BertTokenizerFast"),pIr.forEach(t),DJe=r(w8," (QDQBert model)"),w8.forEach(t),NJe=i(y),Yg=n(y,"LI",{});var uFe=s(Yg);wJ=n(uFe,"STRONG",{});var _Ir=s(wJ);qJe=r(_Ir,"rag"),_Ir.forEach(t),OJe=r(uFe," \u2014 "),bk=n(uFe,"A",{href:!0});var uIr=s(bk);GJe=r(uIr,"RagTokenizer"),uIr.forEach(t),XJe=r(uFe," (RAG model)"),uFe.forEach(t),VJe=i(y),As=n(y,"LI",{});var A8=s(As);AJ=n(A8,"STRONG",{});var bIr=s(AJ);zJe=r(bIr,"realm"),bIr.forEach(t),WJe=r(A8," \u2014 "),vk=n(A8,"A",{href:!0});var vIr=s(vk);QJe=r(vIr,"RealmTokenizer"),vIr.forEach(t),HJe=r(A8," or "),Tk=n(A8,"A",{href:!0});var TIr=s(Tk);UJe=r(TIr,"RealmTokenizerFast"),TIr.forEach(t),JJe=r(A8," (Realm model)"),A8.forEach(t),YJe=i(y),Ls=n(y,"LI",{});var L8=s(Ls);LJ=n(L8,"STRONG",{});var FIr=s(LJ);KJe=r(FIr,"reformer"),FIr.forEach(t),ZJe=r(L8," \u2014 "),Fk=n(L8,"A",{href:!0});var CIr=s(Fk);eYe=r(CIr,"ReformerTokenizer"),CIr.forEach(t),oYe=r(L8," or "),Ck=n(L8,"A",{href:!0});var MIr=s(Ck);rYe=r(MIr,"ReformerTokenizerFast"),MIr.forEach(t),tYe=r(L8," (Reformer model)"),L8.forEach(t),aYe=i(y),Bs=n(y,"LI",{});var B8=s(Bs);BJ=n(B8,"STRONG",{});var EIr=s(BJ);nYe=r(EIr,"rembert"),EIr.forEach(t),sYe=r(B8," \u2014 "),Mk=n(B8,"A",{href:!0});var yIr=s(Mk);lYe=r(yIr,"RemBertTokenizer"),yIr.forEach(t),iYe=r(B8," or "),Ek=n(B8,"A",{href:!0});var wIr=s(Ek);dYe=r(wIr,"RemBertTokenizerFast"),wIr.forEach(t),cYe=r(B8," (RemBERT model)"),B8.forEach(t),fYe=i(y),xs=n(y,"LI",{});var x8=s(xs);xJ=n(x8,"STRONG",{});var AIr=s(xJ);mYe=r(AIr,"retribert"),AIr.forEach(t),gYe=r(x8," \u2014 "),yk=n(x8,"A",{href:!0});var LIr=s(yk);hYe=r(LIr,"RetriBertTokenizer"),LIr.forEach(t),pYe=r(x8," or "),wk=n(x8,"A",{href:!0});var BIr=s(wk);_Ye=r(BIr,"RetriBertTokenizerFast"),BIr.forEach(t),uYe=r(x8," (RetriBERT model)"),x8.forEach(t),bYe=i(y),ks=n(y,"LI",{});var k8=s(ks);kJ=n(k8,"STRONG",{});var xIr=s(kJ);vYe=r(xIr,"roberta"),xIr.forEach(t),TYe=r(k8," \u2014 "),Ak=n(k8,"A",{href:!0});var kIr=s(Ak);FYe=r(kIr,"RobertaTokenizer"),kIr.forEach(t),CYe=r(k8," or "),Lk=n(k8,"A",{href:!0});var RIr=s(Lk);MYe=r(RIr,"RobertaTokenizerFast"),RIr.forEach(t),EYe=r(k8," (RoBERTa model)"),k8.forEach(t),yYe=i(y),Rs=n(y,"LI",{});var R8=s(Rs);RJ=n(R8,"STRONG",{});var SIr=s(RJ);wYe=r(SIr,"roformer"),SIr.forEach(t),AYe=r(R8," \u2014 "),Bk=n(R8,"A",{href:!0});var PIr=s(Bk);LYe=r(PIr,"RoFormerTokenizer"),PIr.forEach(t),BYe=r(R8," or "),xk=n(R8,"A",{href:!0});var $Ir=s(xk);xYe=r($Ir,"RoFormerTokenizerFast"),$Ir.forEach(t),kYe=r(R8," (RoFormer model)"),R8.forEach(t),RYe=i(y),Kg=n(y,"LI",{});var bFe=s(Kg);SJ=n(bFe,"STRONG",{});var IIr=s(SJ);SYe=r(IIr,"speech_to_text"),IIr.forEach(t),PYe=r(bFe," \u2014 "),kk=n(bFe,"A",{href:!0});var jIr=s(kk);$Ye=r(jIr,"Speech2TextTokenizer"),jIr.forEach(t),IYe=r(bFe," (Speech2Text model)"),bFe.forEach(t),jYe=i(y),Zg=n(y,"LI",{});var vFe=s(Zg);PJ=n(vFe,"STRONG",{});var DIr=s(PJ);DYe=r(DIr,"speech_to_text_2"),DIr.forEach(t),NYe=r(vFe," \u2014 "),Rk=n(vFe,"A",{href:!0});var NIr=s(Rk);qYe=r(NIr,"Speech2Text2Tokenizer"),NIr.forEach(t),OYe=r(vFe," (Speech2Text2 model)"),vFe.forEach(t),GYe=i(y),Ss=n(y,"LI",{});var S8=s(Ss);$J=n(S8,"STRONG",{});var qIr=s($J);XYe=r(qIr,"splinter"),qIr.forEach(t),VYe=r(S8," \u2014 "),Sk=n(S8,"A",{href:!0});var OIr=s(Sk);zYe=r(OIr,"SplinterTokenizer"),OIr.forEach(t),WYe=r(S8," or "),Pk=n(S8,"A",{href:!0});var GIr=s(Pk);QYe=r(GIr,"SplinterTokenizerFast"),GIr.forEach(t),HYe=r(S8," (Splinter model)"),S8.forEach(t),UYe=i(y),Ps=n(y,"LI",{});var P8=s(Ps);IJ=n(P8,"STRONG",{});var XIr=s(IJ);JYe=r(XIr,"squeezebert"),XIr.forEach(t),YYe=r(P8," \u2014 "),$k=n(P8,"A",{href:!0});var VIr=s($k);KYe=r(VIr,"SqueezeBertTokenizer"),VIr.forEach(t),ZYe=r(P8," or "),Ik=n(P8,"A",{href:!0});var zIr=s(Ik);eKe=r(zIr,"SqueezeBertTokenizerFast"),zIr.forEach(t),oKe=r(P8," (SqueezeBERT model)"),P8.forEach(t),rKe=i(y),$s=n(y,"LI",{});var $8=s($s);jJ=n($8,"STRONG",{});var WIr=s(jJ);tKe=r(WIr,"t5"),WIr.forEach(t),aKe=r($8," \u2014 "),jk=n($8,"A",{href:!0});var QIr=s(jk);nKe=r(QIr,"T5Tokenizer"),QIr.forEach(t),sKe=r($8," or "),Dk=n($8,"A",{href:!0});var HIr=s(Dk);lKe=r(HIr,"T5TokenizerFast"),HIr.forEach(t),iKe=r($8," (T5 model)"),$8.forEach(t),dKe=i(y),eh=n(y,"LI",{});var TFe=s(eh);DJ=n(TFe,"STRONG",{});var UIr=s(DJ);cKe=r(UIr,"tapas"),UIr.forEach(t),fKe=r(TFe," \u2014 "),Nk=n(TFe,"A",{href:!0});var JIr=s(Nk);mKe=r(JIr,"TapasTokenizer"),JIr.forEach(t),gKe=r(TFe," (TAPAS model)"),TFe.forEach(t),hKe=i(y),oh=n(y,"LI",{});var FFe=s(oh);NJ=n(FFe,"STRONG",{});var YIr=s(NJ);pKe=r(YIr,"transfo-xl"),YIr.forEach(t),_Ke=r(FFe," \u2014 "),qk=n(FFe,"A",{href:!0});var KIr=s(qk);uKe=r(KIr,"TransfoXLTokenizer"),KIr.forEach(t),bKe=r(FFe," (Transformer-XL model)"),FFe.forEach(t),vKe=i(y),rh=n(y,"LI",{});var CFe=s(rh);qJ=n(CFe,"STRONG",{});var ZIr=s(qJ);TKe=r(ZIr,"wav2vec2"),ZIr.forEach(t),FKe=r(CFe," \u2014 "),Ok=n(CFe,"A",{href:!0});var ejr=s(Ok);CKe=r(ejr,"Wav2Vec2CTCTokenizer"),ejr.forEach(t),MKe=r(CFe," (Wav2Vec2 model)"),CFe.forEach(t),EKe=i(y),th=n(y,"LI",{});var MFe=s(th);OJ=n(MFe,"STRONG",{});var ojr=s(OJ);yKe=r(ojr,"wav2vec2_phoneme"),ojr.forEach(t),wKe=r(MFe," \u2014 "),Gk=n(MFe,"A",{href:!0});var rjr=s(Gk);AKe=r(rjr,"Wav2Vec2PhonemeCTCTokenizer"),rjr.forEach(t),LKe=r(MFe," (Wav2Vec2Phoneme model)"),MFe.forEach(t),BKe=i(y),Is=n(y,"LI",{});var I8=s(Is);GJ=n(I8,"STRONG",{});var tjr=s(GJ);xKe=r(tjr,"xglm"),tjr.forEach(t),kKe=r(I8," \u2014 "),Xk=n(I8,"A",{href:!0});var ajr=s(Xk);RKe=r(ajr,"XGLMTokenizer"),ajr.forEach(t),SKe=r(I8," or "),Vk=n(I8,"A",{href:!0});var njr=s(Vk);PKe=r(njr,"XGLMTokenizerFast"),njr.forEach(t),$Ke=r(I8," (XGLM model)"),I8.forEach(t),IKe=i(y),ah=n(y,"LI",{});var EFe=s(ah);XJ=n(EFe,"STRONG",{});var sjr=s(XJ);jKe=r(sjr,"xlm"),sjr.forEach(t),DKe=r(EFe," \u2014 "),zk=n(EFe,"A",{href:!0});var ljr=s(zk);NKe=r(ljr,"XLMTokenizer"),ljr.forEach(t),qKe=r(EFe," (XLM model)"),EFe.forEach(t),OKe=i(y),nh=n(y,"LI",{});var yFe=s(nh);VJ=n(yFe,"STRONG",{});var ijr=s(VJ);GKe=r(ijr,"xlm-prophetnet"),ijr.forEach(t),XKe=r(yFe," \u2014 "),Wk=n(yFe,"A",{href:!0});var djr=s(Wk);VKe=r(djr,"XLMProphetNetTokenizer"),djr.forEach(t),zKe=r(yFe," (XLMProphetNet model)"),yFe.forEach(t),WKe=i(y),js=n(y,"LI",{});var j8=s(js);zJ=n(j8,"STRONG",{});var cjr=s(zJ);QKe=r(cjr,"xlm-roberta"),cjr.forEach(t),HKe=r(j8," \u2014 "),Qk=n(j8,"A",{href:!0});var fjr=s(Qk);UKe=r(fjr,"XLMRobertaTokenizer"),fjr.forEach(t),JKe=r(j8," or "),Hk=n(j8,"A",{href:!0});var mjr=s(Hk);YKe=r(mjr,"XLMRobertaTokenizerFast"),mjr.forEach(t),KKe=r(j8," (XLM-RoBERTa model)"),j8.forEach(t),ZKe=i(y),Ds=n(y,"LI",{});var D8=s(Ds);WJ=n(D8,"STRONG",{});var gjr=s(WJ);eZe=r(gjr,"xlnet"),gjr.forEach(t),oZe=r(D8," \u2014 "),Uk=n(D8,"A",{href:!0});var hjr=s(Uk);rZe=r(hjr,"XLNetTokenizer"),hjr.forEach(t),tZe=r(D8," or "),Jk=n(D8,"A",{href:!0});var pjr=s(Jk);aZe=r(pjr,"XLNetTokenizerFast"),pjr.forEach(t),nZe=r(D8," (XLNet model)"),D8.forEach(t),y.forEach(t),sZe=i(ga),QJ=n(ga,"P",{});var _jr=s(QJ);lZe=r(_jr,"Examples:"),_jr.forEach(t),iZe=i(ga),m(gE.$$.fragment,ga),ga.forEach(t),dZe=i(Xs),sh=n(Xs,"DIV",{class:!0});var ARe=s(sh);m(hE.$$.fragment,ARe),cZe=i(ARe),HJ=n(ARe,"P",{});var ujr=s(HJ);fZe=r(ujr,"Register a new tokenizer in this mapping."),ujr.forEach(t),ARe.forEach(t),Xs.forEach(t),Mxe=i(c),Qi=n(c,"H2",{class:!0});var LRe=s(Qi);lh=n(LRe,"A",{id:!0,class:!0,href:!0});var bjr=s(lh);UJ=n(bjr,"SPAN",{});var vjr=s(UJ);m(pE.$$.fragment,vjr),vjr.forEach(t),bjr.forEach(t),mZe=i(LRe),JJ=n(LRe,"SPAN",{});var Tjr=s(JJ);gZe=r(Tjr,"AutoFeatureExtractor"),Tjr.forEach(t),LRe.forEach(t),Exe=i(c),Ho=n(c,"DIV",{class:!0});var Vs=s(Ho);m(_E.$$.fragment,Vs),hZe=i(Vs),uE=n(Vs,"P",{});var BRe=s(uE);pZe=r(BRe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Yk=n(BRe,"A",{href:!0});var Fjr=s(Yk);_Ze=r(Fjr,"AutoFeatureExtractor.from_pretrained()"),Fjr.forEach(t),uZe=r(BRe," class method."),BRe.forEach(t),bZe=i(Vs),bE=n(Vs,"P",{});var xRe=s(bE);vZe=r(xRe,"This class cannot be instantiated directly using "),YJ=n(xRe,"CODE",{});var Cjr=s(YJ);TZe=r(Cjr,"__init__()"),Cjr.forEach(t),FZe=r(xRe," (throws an error)."),xRe.forEach(t),CZe=i(Vs),Ie=n(Vs,"DIV",{class:!0});var Dt=s(Ie);m(vE.$$.fragment,Dt),MZe=i(Dt),KJ=n(Dt,"P",{});var Mjr=s(KJ);EZe=r(Mjr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Mjr.forEach(t),yZe=i(Dt),Ga=n(Dt,"P",{});var YM=s(Ga);wZe=r(YM,"The feature extractor class to instantiate is selected based on the "),ZJ=n(YM,"CODE",{});var Ejr=s(ZJ);AZe=r(Ejr,"model_type"),Ejr.forEach(t),LZe=r(YM,` property of the config object
(either passed as an argument or loaded from `),eY=n(YM,"CODE",{});var yjr=s(eY);BZe=r(yjr,"pretrained_model_name_or_path"),yjr.forEach(t),xZe=r(YM,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),oY=n(YM,"CODE",{});var wjr=s(oY);kZe=r(wjr,"pretrained_model_name_or_path"),wjr.forEach(t),RZe=r(YM,":"),YM.forEach(t),SZe=i(Dt),te=n(Dt,"UL",{});var se=s(te);ih=n(se,"LI",{});var wFe=s(ih);rY=n(wFe,"STRONG",{});var Ajr=s(rY);PZe=r(Ajr,"beit"),Ajr.forEach(t),$Ze=r(wFe," \u2014 "),Kk=n(wFe,"A",{href:!0});var Ljr=s(Kk);IZe=r(Ljr,"BeitFeatureExtractor"),Ljr.forEach(t),jZe=r(wFe," (BEiT model)"),wFe.forEach(t),DZe=i(se),dh=n(se,"LI",{});var AFe=s(dh);tY=n(AFe,"STRONG",{});var Bjr=s(tY);NZe=r(Bjr,"clip"),Bjr.forEach(t),qZe=r(AFe," \u2014 "),Zk=n(AFe,"A",{href:!0});var xjr=s(Zk);OZe=r(xjr,"CLIPFeatureExtractor"),xjr.forEach(t),GZe=r(AFe," (CLIP model)"),AFe.forEach(t),XZe=i(se),ch=n(se,"LI",{});var LFe=s(ch);aY=n(LFe,"STRONG",{});var kjr=s(aY);VZe=r(kjr,"convnext"),kjr.forEach(t),zZe=r(LFe," \u2014 "),eR=n(LFe,"A",{href:!0});var Rjr=s(eR);WZe=r(Rjr,"ConvNextFeatureExtractor"),Rjr.forEach(t),QZe=r(LFe," (ConvNext model)"),LFe.forEach(t),HZe=i(se),fh=n(se,"LI",{});var BFe=s(fh);nY=n(BFe,"STRONG",{});var Sjr=s(nY);UZe=r(Sjr,"deit"),Sjr.forEach(t),JZe=r(BFe," \u2014 "),oR=n(BFe,"A",{href:!0});var Pjr=s(oR);YZe=r(Pjr,"DeiTFeatureExtractor"),Pjr.forEach(t),KZe=r(BFe," (DeiT model)"),BFe.forEach(t),ZZe=i(se),mh=n(se,"LI",{});var xFe=s(mh);sY=n(xFe,"STRONG",{});var $jr=s(sY);eeo=r($jr,"detr"),$jr.forEach(t),oeo=r(xFe," \u2014 "),rR=n(xFe,"A",{href:!0});var Ijr=s(rR);reo=r(Ijr,"DetrFeatureExtractor"),Ijr.forEach(t),teo=r(xFe," (DETR model)"),xFe.forEach(t),aeo=i(se),gh=n(se,"LI",{});var kFe=s(gh);lY=n(kFe,"STRONG",{});var jjr=s(lY);neo=r(jjr,"hubert"),jjr.forEach(t),seo=r(kFe," \u2014 "),tR=n(kFe,"A",{href:!0});var Djr=s(tR);leo=r(Djr,"Wav2Vec2FeatureExtractor"),Djr.forEach(t),ieo=r(kFe," (Hubert model)"),kFe.forEach(t),deo=i(se),hh=n(se,"LI",{});var RFe=s(hh);iY=n(RFe,"STRONG",{});var Njr=s(iY);ceo=r(Njr,"layoutlmv2"),Njr.forEach(t),feo=r(RFe," \u2014 "),aR=n(RFe,"A",{href:!0});var qjr=s(aR);meo=r(qjr,"LayoutLMv2FeatureExtractor"),qjr.forEach(t),geo=r(RFe," (LayoutLMv2 model)"),RFe.forEach(t),heo=i(se),ph=n(se,"LI",{});var SFe=s(ph);dY=n(SFe,"STRONG",{});var Ojr=s(dY);peo=r(Ojr,"maskformer"),Ojr.forEach(t),_eo=r(SFe," \u2014 "),nR=n(SFe,"A",{href:!0});var Gjr=s(nR);ueo=r(Gjr,"MaskFormerFeatureExtractor"),Gjr.forEach(t),beo=r(SFe," (MaskFormer model)"),SFe.forEach(t),veo=i(se),_h=n(se,"LI",{});var PFe=s(_h);cY=n(PFe,"STRONG",{});var Xjr=s(cY);Teo=r(Xjr,"perceiver"),Xjr.forEach(t),Feo=r(PFe," \u2014 "),sR=n(PFe,"A",{href:!0});var Vjr=s(sR);Ceo=r(Vjr,"PerceiverFeatureExtractor"),Vjr.forEach(t),Meo=r(PFe," (Perceiver model)"),PFe.forEach(t),Eeo=i(se),uh=n(se,"LI",{});var $Fe=s(uh);fY=n($Fe,"STRONG",{});var zjr=s(fY);yeo=r(zjr,"poolformer"),zjr.forEach(t),weo=r($Fe," \u2014 "),lR=n($Fe,"A",{href:!0});var Wjr=s(lR);Aeo=r(Wjr,"PoolFormerFeatureExtractor"),Wjr.forEach(t),Leo=r($Fe," (PoolFormer model)"),$Fe.forEach(t),Beo=i(se),bh=n(se,"LI",{});var IFe=s(bh);mY=n(IFe,"STRONG",{});var Qjr=s(mY);xeo=r(Qjr,"resnet"),Qjr.forEach(t),keo=r(IFe," \u2014 "),iR=n(IFe,"A",{href:!0});var Hjr=s(iR);Reo=r(Hjr,"ConvNextFeatureExtractor"),Hjr.forEach(t),Seo=r(IFe," (ResNet model)"),IFe.forEach(t),Peo=i(se),vh=n(se,"LI",{});var jFe=s(vh);gY=n(jFe,"STRONG",{});var Ujr=s(gY);$eo=r(Ujr,"segformer"),Ujr.forEach(t),Ieo=r(jFe," \u2014 "),dR=n(jFe,"A",{href:!0});var Jjr=s(dR);jeo=r(Jjr,"SegformerFeatureExtractor"),Jjr.forEach(t),Deo=r(jFe," (SegFormer model)"),jFe.forEach(t),Neo=i(se),Th=n(se,"LI",{});var DFe=s(Th);hY=n(DFe,"STRONG",{});var Yjr=s(hY);qeo=r(Yjr,"speech_to_text"),Yjr.forEach(t),Oeo=r(DFe," \u2014 "),cR=n(DFe,"A",{href:!0});var Kjr=s(cR);Geo=r(Kjr,"Speech2TextFeatureExtractor"),Kjr.forEach(t),Xeo=r(DFe," (Speech2Text model)"),DFe.forEach(t),Veo=i(se),Fh=n(se,"LI",{});var NFe=s(Fh);pY=n(NFe,"STRONG",{});var Zjr=s(pY);zeo=r(Zjr,"swin"),Zjr.forEach(t),Weo=r(NFe," \u2014 "),fR=n(NFe,"A",{href:!0});var eDr=s(fR);Qeo=r(eDr,"ViTFeatureExtractor"),eDr.forEach(t),Heo=r(NFe," (Swin model)"),NFe.forEach(t),Ueo=i(se),Ch=n(se,"LI",{});var qFe=s(Ch);_Y=n(qFe,"STRONG",{});var oDr=s(_Y);Jeo=r(oDr,"vit"),oDr.forEach(t),Yeo=r(qFe," \u2014 "),mR=n(qFe,"A",{href:!0});var rDr=s(mR);Keo=r(rDr,"ViTFeatureExtractor"),rDr.forEach(t),Zeo=r(qFe," (ViT model)"),qFe.forEach(t),eoo=i(se),Mh=n(se,"LI",{});var OFe=s(Mh);uY=n(OFe,"STRONG",{});var tDr=s(uY);ooo=r(tDr,"vit_mae"),tDr.forEach(t),roo=r(OFe," \u2014 "),gR=n(OFe,"A",{href:!0});var aDr=s(gR);too=r(aDr,"ViTFeatureExtractor"),aDr.forEach(t),aoo=r(OFe," (ViTMAE model)"),OFe.forEach(t),noo=i(se),Eh=n(se,"LI",{});var GFe=s(Eh);bY=n(GFe,"STRONG",{});var nDr=s(bY);soo=r(nDr,"wav2vec2"),nDr.forEach(t),loo=r(GFe," \u2014 "),hR=n(GFe,"A",{href:!0});var sDr=s(hR);ioo=r(sDr,"Wav2Vec2FeatureExtractor"),sDr.forEach(t),doo=r(GFe," (Wav2Vec2 model)"),GFe.forEach(t),se.forEach(t),coo=i(Dt),m(yh.$$.fragment,Dt),foo=i(Dt),vY=n(Dt,"P",{});var lDr=s(vY);moo=r(lDr,"Examples:"),lDr.forEach(t),goo=i(Dt),m(TE.$$.fragment,Dt),Dt.forEach(t),hoo=i(Vs),wh=n(Vs,"DIV",{class:!0});var kRe=s(wh);m(FE.$$.fragment,kRe),poo=i(kRe),TY=n(kRe,"P",{});var iDr=s(TY);_oo=r(iDr,"Register a new feature extractor for this class."),iDr.forEach(t),kRe.forEach(t),Vs.forEach(t),yxe=i(c),Hi=n(c,"H2",{class:!0});var RRe=s(Hi);Ah=n(RRe,"A",{id:!0,class:!0,href:!0});var dDr=s(Ah);FY=n(dDr,"SPAN",{});var cDr=s(FY);m(CE.$$.fragment,cDr),cDr.forEach(t),dDr.forEach(t),uoo=i(RRe),CY=n(RRe,"SPAN",{});var fDr=s(CY);boo=r(fDr,"AutoProcessor"),fDr.forEach(t),RRe.forEach(t),wxe=i(c),Uo=n(c,"DIV",{class:!0});var zs=s(Uo);m(ME.$$.fragment,zs),voo=i(zs),EE=n(zs,"P",{});var SRe=s(EE);Too=r(SRe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),pR=n(SRe,"A",{href:!0});var mDr=s(pR);Foo=r(mDr,"AutoProcessor.from_pretrained()"),mDr.forEach(t),Coo=r(SRe," class method."),SRe.forEach(t),Moo=i(zs),yE=n(zs,"P",{});var PRe=s(yE);Eoo=r(PRe,"This class cannot be instantiated directly using "),MY=n(PRe,"CODE",{});var gDr=s(MY);yoo=r(gDr,"__init__()"),gDr.forEach(t),woo=r(PRe," (throws an error)."),PRe.forEach(t),Aoo=i(zs),je=n(zs,"DIV",{class:!0});var Nt=s(je);m(wE.$$.fragment,Nt),Loo=i(Nt),EY=n(Nt,"P",{});var hDr=s(EY);Boo=r(hDr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),hDr.forEach(t),xoo=i(Nt),Ui=n(Nt,"P",{});var Lz=s(Ui);koo=r(Lz,"The processor class to instantiate is selected based on the "),yY=n(Lz,"CODE",{});var pDr=s(yY);Roo=r(pDr,"model_type"),pDr.forEach(t),Soo=r(Lz,` property of the config object (either
passed as an argument or loaded from `),wY=n(Lz,"CODE",{});var _Dr=s(wY);Poo=r(_Dr,"pretrained_model_name_or_path"),_Dr.forEach(t),$oo=r(Lz," if possible):"),Lz.forEach(t),Ioo=i(Nt),xe=n(Nt,"UL",{});var No=s(xe);Lh=n(No,"LI",{});var XFe=s(Lh);AY=n(XFe,"STRONG",{});var uDr=s(AY);joo=r(uDr,"clip"),uDr.forEach(t),Doo=r(XFe," \u2014 "),_R=n(XFe,"A",{href:!0});var bDr=s(_R);Noo=r(bDr,"CLIPProcessor"),bDr.forEach(t),qoo=r(XFe," (CLIP model)"),XFe.forEach(t),Ooo=i(No),Bh=n(No,"LI",{});var VFe=s(Bh);LY=n(VFe,"STRONG",{});var vDr=s(LY);Goo=r(vDr,"layoutlmv2"),vDr.forEach(t),Xoo=r(VFe," \u2014 "),uR=n(VFe,"A",{href:!0});var TDr=s(uR);Voo=r(TDr,"LayoutLMv2Processor"),TDr.forEach(t),zoo=r(VFe," (LayoutLMv2 model)"),VFe.forEach(t),Woo=i(No),xh=n(No,"LI",{});var zFe=s(xh);BY=n(zFe,"STRONG",{});var FDr=s(BY);Qoo=r(FDr,"layoutxlm"),FDr.forEach(t),Hoo=r(zFe," \u2014 "),bR=n(zFe,"A",{href:!0});var CDr=s(bR);Uoo=r(CDr,"LayoutXLMProcessor"),CDr.forEach(t),Joo=r(zFe," (LayoutXLM model)"),zFe.forEach(t),Yoo=i(No),kh=n(No,"LI",{});var WFe=s(kh);xY=n(WFe,"STRONG",{});var MDr=s(xY);Koo=r(MDr,"speech_to_text"),MDr.forEach(t),Zoo=r(WFe," \u2014 "),vR=n(WFe,"A",{href:!0});var EDr=s(vR);ero=r(EDr,"Speech2TextProcessor"),EDr.forEach(t),oro=r(WFe," (Speech2Text model)"),WFe.forEach(t),rro=i(No),Rh=n(No,"LI",{});var QFe=s(Rh);kY=n(QFe,"STRONG",{});var yDr=s(kY);tro=r(yDr,"speech_to_text_2"),yDr.forEach(t),aro=r(QFe," \u2014 "),TR=n(QFe,"A",{href:!0});var wDr=s(TR);nro=r(wDr,"Speech2Text2Processor"),wDr.forEach(t),sro=r(QFe," (Speech2Text2 model)"),QFe.forEach(t),lro=i(No),Sh=n(No,"LI",{});var HFe=s(Sh);RY=n(HFe,"STRONG",{});var ADr=s(RY);iro=r(ADr,"trocr"),ADr.forEach(t),dro=r(HFe," \u2014 "),FR=n(HFe,"A",{href:!0});var LDr=s(FR);cro=r(LDr,"TrOCRProcessor"),LDr.forEach(t),fro=r(HFe," (TrOCR model)"),HFe.forEach(t),mro=i(No),Ph=n(No,"LI",{});var UFe=s(Ph);SY=n(UFe,"STRONG",{});var BDr=s(SY);gro=r(BDr,"vision-text-dual-encoder"),BDr.forEach(t),hro=r(UFe," \u2014 "),CR=n(UFe,"A",{href:!0});var xDr=s(CR);pro=r(xDr,"VisionTextDualEncoderProcessor"),xDr.forEach(t),_ro=r(UFe," (VisionTextDualEncoder model)"),UFe.forEach(t),uro=i(No),$h=n(No,"LI",{});var JFe=s($h);PY=n(JFe,"STRONG",{});var kDr=s(PY);bro=r(kDr,"wav2vec2"),kDr.forEach(t),vro=r(JFe," \u2014 "),MR=n(JFe,"A",{href:!0});var RDr=s(MR);Tro=r(RDr,"Wav2Vec2Processor"),RDr.forEach(t),Fro=r(JFe," (Wav2Vec2 model)"),JFe.forEach(t),No.forEach(t),Cro=i(Nt),m(Ih.$$.fragment,Nt),Mro=i(Nt),$Y=n(Nt,"P",{});var SDr=s($Y);Ero=r(SDr,"Examples:"),SDr.forEach(t),yro=i(Nt),m(AE.$$.fragment,Nt),Nt.forEach(t),wro=i(zs),jh=n(zs,"DIV",{class:!0});var $Re=s(jh);m(LE.$$.fragment,$Re),Aro=i($Re),IY=n($Re,"P",{});var PDr=s(IY);Lro=r(PDr,"Register a new processor for this class."),PDr.forEach(t),$Re.forEach(t),zs.forEach(t),Axe=i(c),Ji=n(c,"H2",{class:!0});var IRe=s(Ji);Dh=n(IRe,"A",{id:!0,class:!0,href:!0});var $Dr=s(Dh);jY=n($Dr,"SPAN",{});var IDr=s(jY);m(BE.$$.fragment,IDr),IDr.forEach(t),$Dr.forEach(t),Bro=i(IRe),DY=n(IRe,"SPAN",{});var jDr=s(DY);xro=r(jDr,"AutoModel"),jDr.forEach(t),IRe.forEach(t),Lxe=i(c),Jo=n(c,"DIV",{class:!0});var Ws=s(Jo);m(xE.$$.fragment,Ws),kro=i(Ws),Yi=n(Ws,"P",{});var Bz=s(Yi);Rro=r(Bz,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),NY=n(Bz,"CODE",{});var DDr=s(NY);Sro=r(DDr,"from_pretrained()"),DDr.forEach(t),Pro=r(Bz,"class method or the "),qY=n(Bz,"CODE",{});var NDr=s(qY);$ro=r(NDr,"from_config()"),NDr.forEach(t),Iro=r(Bz,`class
method.`),Bz.forEach(t),jro=i(Ws),kE=n(Ws,"P",{});var jRe=s(kE);Dro=r(jRe,"This class cannot be instantiated directly using "),OY=n(jRe,"CODE",{});var qDr=s(OY);Nro=r(qDr,"__init__()"),qDr.forEach(t),qro=r(jRe," (throws an error)."),jRe.forEach(t),Oro=i(Ws),Vr=n(Ws,"DIV",{class:!0});var Qs=s(Vr);m(RE.$$.fragment,Qs),Gro=i(Qs),GY=n(Qs,"P",{});var ODr=s(GY);Xro=r(ODr,"Instantiates one of the base model classes of the library from a configuration."),ODr.forEach(t),Vro=i(Qs),Ki=n(Qs,"P",{});var xz=s(Ki);zro=r(xz,`Note:
Loading a model from its configuration file does `),XY=n(xz,"STRONG",{});var GDr=s(XY);Wro=r(GDr,"not"),GDr.forEach(t),Qro=r(xz,` load the model weights. It only affects the
model\u2019s configuration. Use `),VY=n(xz,"CODE",{});var XDr=s(VY);Hro=r(XDr,"from_pretrained()"),XDr.forEach(t),Uro=r(xz,"to load the model weights."),xz.forEach(t),Jro=i(Qs),zY=n(Qs,"P",{});var VDr=s(zY);Yro=r(VDr,"Examples:"),VDr.forEach(t),Kro=i(Qs),m(SE.$$.fragment,Qs),Qs.forEach(t),Zro=i(Ws),De=n(Ws,"DIV",{class:!0});var qt=s(De);m(PE.$$.fragment,qt),eto=i(qt),WY=n(qt,"P",{});var zDr=s(WY);oto=r(zDr,"Instantiate one of the base model classes of the library from a pretrained model."),zDr.forEach(t),rto=i(qt),Xa=n(qt,"P",{});var KM=s(Xa);tto=r(KM,"The model class to instantiate is selected based on the "),QY=n(KM,"CODE",{});var WDr=s(QY);ato=r(WDr,"model_type"),WDr.forEach(t),nto=r(KM,` property of the config object (either
passed as an argument or loaded from `),HY=n(KM,"CODE",{});var QDr=s(HY);sto=r(QDr,"pretrained_model_name_or_path"),QDr.forEach(t),lto=r(KM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UY=n(KM,"CODE",{});var HDr=s(UY);ito=r(HDr,"pretrained_model_name_or_path"),HDr.forEach(t),dto=r(KM,":"),KM.forEach(t),cto=i(qt),F=n(qt,"UL",{});var C=s(F);Nh=n(C,"LI",{});var YFe=s(Nh);JY=n(YFe,"STRONG",{});var UDr=s(JY);fto=r(UDr,"albert"),UDr.forEach(t),mto=r(YFe," \u2014 "),ER=n(YFe,"A",{href:!0});var JDr=s(ER);gto=r(JDr,"AlbertModel"),JDr.forEach(t),hto=r(YFe," (ALBERT model)"),YFe.forEach(t),pto=i(C),qh=n(C,"LI",{});var KFe=s(qh);YY=n(KFe,"STRONG",{});var YDr=s(YY);_to=r(YDr,"bart"),YDr.forEach(t),uto=r(KFe," \u2014 "),yR=n(KFe,"A",{href:!0});var KDr=s(yR);bto=r(KDr,"BartModel"),KDr.forEach(t),vto=r(KFe," (BART model)"),KFe.forEach(t),Tto=i(C),Oh=n(C,"LI",{});var ZFe=s(Oh);KY=n(ZFe,"STRONG",{});var ZDr=s(KY);Fto=r(ZDr,"beit"),ZDr.forEach(t),Cto=r(ZFe," \u2014 "),wR=n(ZFe,"A",{href:!0});var eNr=s(wR);Mto=r(eNr,"BeitModel"),eNr.forEach(t),Eto=r(ZFe," (BEiT model)"),ZFe.forEach(t),yto=i(C),Gh=n(C,"LI",{});var eCe=s(Gh);ZY=n(eCe,"STRONG",{});var oNr=s(ZY);wto=r(oNr,"bert"),oNr.forEach(t),Ato=r(eCe," \u2014 "),AR=n(eCe,"A",{href:!0});var rNr=s(AR);Lto=r(rNr,"BertModel"),rNr.forEach(t),Bto=r(eCe," (BERT model)"),eCe.forEach(t),xto=i(C),Xh=n(C,"LI",{});var oCe=s(Xh);eK=n(oCe,"STRONG",{});var tNr=s(eK);kto=r(tNr,"bert-generation"),tNr.forEach(t),Rto=r(oCe," \u2014 "),LR=n(oCe,"A",{href:!0});var aNr=s(LR);Sto=r(aNr,"BertGenerationEncoder"),aNr.forEach(t),Pto=r(oCe," (Bert Generation model)"),oCe.forEach(t),$to=i(C),Vh=n(C,"LI",{});var rCe=s(Vh);oK=n(rCe,"STRONG",{});var nNr=s(oK);Ito=r(nNr,"big_bird"),nNr.forEach(t),jto=r(rCe," \u2014 "),BR=n(rCe,"A",{href:!0});var sNr=s(BR);Dto=r(sNr,"BigBirdModel"),sNr.forEach(t),Nto=r(rCe," (BigBird model)"),rCe.forEach(t),qto=i(C),zh=n(C,"LI",{});var tCe=s(zh);rK=n(tCe,"STRONG",{});var lNr=s(rK);Oto=r(lNr,"bigbird_pegasus"),lNr.forEach(t),Gto=r(tCe," \u2014 "),xR=n(tCe,"A",{href:!0});var iNr=s(xR);Xto=r(iNr,"BigBirdPegasusModel"),iNr.forEach(t),Vto=r(tCe," (BigBirdPegasus model)"),tCe.forEach(t),zto=i(C),Wh=n(C,"LI",{});var aCe=s(Wh);tK=n(aCe,"STRONG",{});var dNr=s(tK);Wto=r(dNr,"blenderbot"),dNr.forEach(t),Qto=r(aCe," \u2014 "),kR=n(aCe,"A",{href:!0});var cNr=s(kR);Hto=r(cNr,"BlenderbotModel"),cNr.forEach(t),Uto=r(aCe," (Blenderbot model)"),aCe.forEach(t),Jto=i(C),Qh=n(C,"LI",{});var nCe=s(Qh);aK=n(nCe,"STRONG",{});var fNr=s(aK);Yto=r(fNr,"blenderbot-small"),fNr.forEach(t),Kto=r(nCe," \u2014 "),RR=n(nCe,"A",{href:!0});var mNr=s(RR);Zto=r(mNr,"BlenderbotSmallModel"),mNr.forEach(t),eao=r(nCe," (BlenderbotSmall model)"),nCe.forEach(t),oao=i(C),Hh=n(C,"LI",{});var sCe=s(Hh);nK=n(sCe,"STRONG",{});var gNr=s(nK);rao=r(gNr,"camembert"),gNr.forEach(t),tao=r(sCe," \u2014 "),SR=n(sCe,"A",{href:!0});var hNr=s(SR);aao=r(hNr,"CamembertModel"),hNr.forEach(t),nao=r(sCe," (CamemBERT model)"),sCe.forEach(t),sao=i(C),Uh=n(C,"LI",{});var lCe=s(Uh);sK=n(lCe,"STRONG",{});var pNr=s(sK);lao=r(pNr,"canine"),pNr.forEach(t),iao=r(lCe," \u2014 "),PR=n(lCe,"A",{href:!0});var _Nr=s(PR);dao=r(_Nr,"CanineModel"),_Nr.forEach(t),cao=r(lCe," (Canine model)"),lCe.forEach(t),fao=i(C),Jh=n(C,"LI",{});var iCe=s(Jh);lK=n(iCe,"STRONG",{});var uNr=s(lK);mao=r(uNr,"clip"),uNr.forEach(t),gao=r(iCe," \u2014 "),$R=n(iCe,"A",{href:!0});var bNr=s($R);hao=r(bNr,"CLIPModel"),bNr.forEach(t),pao=r(iCe," (CLIP model)"),iCe.forEach(t),_ao=i(C),Yh=n(C,"LI",{});var dCe=s(Yh);iK=n(dCe,"STRONG",{});var vNr=s(iK);uao=r(vNr,"convbert"),vNr.forEach(t),bao=r(dCe," \u2014 "),IR=n(dCe,"A",{href:!0});var TNr=s(IR);vao=r(TNr,"ConvBertModel"),TNr.forEach(t),Tao=r(dCe," (ConvBERT model)"),dCe.forEach(t),Fao=i(C),Kh=n(C,"LI",{});var cCe=s(Kh);dK=n(cCe,"STRONG",{});var FNr=s(dK);Cao=r(FNr,"convnext"),FNr.forEach(t),Mao=r(cCe," \u2014 "),jR=n(cCe,"A",{href:!0});var CNr=s(jR);Eao=r(CNr,"ConvNextModel"),CNr.forEach(t),yao=r(cCe," (ConvNext model)"),cCe.forEach(t),wao=i(C),Zh=n(C,"LI",{});var fCe=s(Zh);cK=n(fCe,"STRONG",{});var MNr=s(cK);Aao=r(MNr,"ctrl"),MNr.forEach(t),Lao=r(fCe," \u2014 "),DR=n(fCe,"A",{href:!0});var ENr=s(DR);Bao=r(ENr,"CTRLModel"),ENr.forEach(t),xao=r(fCe," (CTRL model)"),fCe.forEach(t),kao=i(C),ep=n(C,"LI",{});var mCe=s(ep);fK=n(mCe,"STRONG",{});var yNr=s(fK);Rao=r(yNr,"data2vec-audio"),yNr.forEach(t),Sao=r(mCe," \u2014 "),NR=n(mCe,"A",{href:!0});var wNr=s(NR);Pao=r(wNr,"Data2VecAudioModel"),wNr.forEach(t),$ao=r(mCe," (Data2VecAudio model)"),mCe.forEach(t),Iao=i(C),op=n(C,"LI",{});var gCe=s(op);mK=n(gCe,"STRONG",{});var ANr=s(mK);jao=r(ANr,"data2vec-text"),ANr.forEach(t),Dao=r(gCe," \u2014 "),qR=n(gCe,"A",{href:!0});var LNr=s(qR);Nao=r(LNr,"Data2VecTextModel"),LNr.forEach(t),qao=r(gCe," (Data2VecText model)"),gCe.forEach(t),Oao=i(C),rp=n(C,"LI",{});var hCe=s(rp);gK=n(hCe,"STRONG",{});var BNr=s(gK);Gao=r(BNr,"deberta"),BNr.forEach(t),Xao=r(hCe," \u2014 "),OR=n(hCe,"A",{href:!0});var xNr=s(OR);Vao=r(xNr,"DebertaModel"),xNr.forEach(t),zao=r(hCe," (DeBERTa model)"),hCe.forEach(t),Wao=i(C),tp=n(C,"LI",{});var pCe=s(tp);hK=n(pCe,"STRONG",{});var kNr=s(hK);Qao=r(kNr,"deberta-v2"),kNr.forEach(t),Hao=r(pCe," \u2014 "),GR=n(pCe,"A",{href:!0});var RNr=s(GR);Uao=r(RNr,"DebertaV2Model"),RNr.forEach(t),Jao=r(pCe," (DeBERTa-v2 model)"),pCe.forEach(t),Yao=i(C),ap=n(C,"LI",{});var _Ce=s(ap);pK=n(_Ce,"STRONG",{});var SNr=s(pK);Kao=r(SNr,"deit"),SNr.forEach(t),Zao=r(_Ce," \u2014 "),XR=n(_Ce,"A",{href:!0});var PNr=s(XR);eno=r(PNr,"DeiTModel"),PNr.forEach(t),ono=r(_Ce," (DeiT model)"),_Ce.forEach(t),rno=i(C),np=n(C,"LI",{});var uCe=s(np);_K=n(uCe,"STRONG",{});var $Nr=s(_K);tno=r($Nr,"detr"),$Nr.forEach(t),ano=r(uCe," \u2014 "),VR=n(uCe,"A",{href:!0});var INr=s(VR);nno=r(INr,"DetrModel"),INr.forEach(t),sno=r(uCe," (DETR model)"),uCe.forEach(t),lno=i(C),sp=n(C,"LI",{});var bCe=s(sp);uK=n(bCe,"STRONG",{});var jNr=s(uK);ino=r(jNr,"distilbert"),jNr.forEach(t),dno=r(bCe," \u2014 "),zR=n(bCe,"A",{href:!0});var DNr=s(zR);cno=r(DNr,"DistilBertModel"),DNr.forEach(t),fno=r(bCe," (DistilBERT model)"),bCe.forEach(t),mno=i(C),lp=n(C,"LI",{});var vCe=s(lp);bK=n(vCe,"STRONG",{});var NNr=s(bK);gno=r(NNr,"dpr"),NNr.forEach(t),hno=r(vCe," \u2014 "),WR=n(vCe,"A",{href:!0});var qNr=s(WR);pno=r(qNr,"DPRQuestionEncoder"),qNr.forEach(t),_no=r(vCe," (DPR model)"),vCe.forEach(t),uno=i(C),ip=n(C,"LI",{});var TCe=s(ip);vK=n(TCe,"STRONG",{});var ONr=s(vK);bno=r(ONr,"electra"),ONr.forEach(t),vno=r(TCe," \u2014 "),QR=n(TCe,"A",{href:!0});var GNr=s(QR);Tno=r(GNr,"ElectraModel"),GNr.forEach(t),Fno=r(TCe," (ELECTRA model)"),TCe.forEach(t),Cno=i(C),dp=n(C,"LI",{});var FCe=s(dp);TK=n(FCe,"STRONG",{});var XNr=s(TK);Mno=r(XNr,"flaubert"),XNr.forEach(t),Eno=r(FCe," \u2014 "),HR=n(FCe,"A",{href:!0});var VNr=s(HR);yno=r(VNr,"FlaubertModel"),VNr.forEach(t),wno=r(FCe," (FlauBERT model)"),FCe.forEach(t),Ano=i(C),cp=n(C,"LI",{});var CCe=s(cp);FK=n(CCe,"STRONG",{});var zNr=s(FK);Lno=r(zNr,"fnet"),zNr.forEach(t),Bno=r(CCe," \u2014 "),UR=n(CCe,"A",{href:!0});var WNr=s(UR);xno=r(WNr,"FNetModel"),WNr.forEach(t),kno=r(CCe," (FNet model)"),CCe.forEach(t),Rno=i(C),fp=n(C,"LI",{});var MCe=s(fp);CK=n(MCe,"STRONG",{});var QNr=s(CK);Sno=r(QNr,"fsmt"),QNr.forEach(t),Pno=r(MCe," \u2014 "),JR=n(MCe,"A",{href:!0});var HNr=s(JR);$no=r(HNr,"FSMTModel"),HNr.forEach(t),Ino=r(MCe," (FairSeq Machine-Translation model)"),MCe.forEach(t),jno=i(C),Ns=n(C,"LI",{});var N8=s(Ns);MK=n(N8,"STRONG",{});var UNr=s(MK);Dno=r(UNr,"funnel"),UNr.forEach(t),Nno=r(N8," \u2014 "),YR=n(N8,"A",{href:!0});var JNr=s(YR);qno=r(JNr,"FunnelModel"),JNr.forEach(t),Ono=r(N8," or "),KR=n(N8,"A",{href:!0});var YNr=s(KR);Gno=r(YNr,"FunnelBaseModel"),YNr.forEach(t),Xno=r(N8," (Funnel Transformer model)"),N8.forEach(t),Vno=i(C),mp=n(C,"LI",{});var ECe=s(mp);EK=n(ECe,"STRONG",{});var KNr=s(EK);zno=r(KNr,"gpt2"),KNr.forEach(t),Wno=r(ECe," \u2014 "),ZR=n(ECe,"A",{href:!0});var ZNr=s(ZR);Qno=r(ZNr,"GPT2Model"),ZNr.forEach(t),Hno=r(ECe," (OpenAI GPT-2 model)"),ECe.forEach(t),Uno=i(C),gp=n(C,"LI",{});var yCe=s(gp);yK=n(yCe,"STRONG",{});var eqr=s(yK);Jno=r(eqr,"gpt_neo"),eqr.forEach(t),Yno=r(yCe," \u2014 "),eS=n(yCe,"A",{href:!0});var oqr=s(eS);Kno=r(oqr,"GPTNeoModel"),oqr.forEach(t),Zno=r(yCe," (GPT Neo model)"),yCe.forEach(t),eso=i(C),hp=n(C,"LI",{});var wCe=s(hp);wK=n(wCe,"STRONG",{});var rqr=s(wK);oso=r(rqr,"gptj"),rqr.forEach(t),rso=r(wCe," \u2014 "),oS=n(wCe,"A",{href:!0});var tqr=s(oS);tso=r(tqr,"GPTJModel"),tqr.forEach(t),aso=r(wCe," (GPT-J model)"),wCe.forEach(t),nso=i(C),pp=n(C,"LI",{});var ACe=s(pp);AK=n(ACe,"STRONG",{});var aqr=s(AK);sso=r(aqr,"hubert"),aqr.forEach(t),lso=r(ACe," \u2014 "),rS=n(ACe,"A",{href:!0});var nqr=s(rS);iso=r(nqr,"HubertModel"),nqr.forEach(t),dso=r(ACe," (Hubert model)"),ACe.forEach(t),cso=i(C),_p=n(C,"LI",{});var LCe=s(_p);LK=n(LCe,"STRONG",{});var sqr=s(LK);fso=r(sqr,"ibert"),sqr.forEach(t),mso=r(LCe," \u2014 "),tS=n(LCe,"A",{href:!0});var lqr=s(tS);gso=r(lqr,"IBertModel"),lqr.forEach(t),hso=r(LCe," (I-BERT model)"),LCe.forEach(t),pso=i(C),up=n(C,"LI",{});var BCe=s(up);BK=n(BCe,"STRONG",{});var iqr=s(BK);_so=r(iqr,"imagegpt"),iqr.forEach(t),uso=r(BCe," \u2014 "),aS=n(BCe,"A",{href:!0});var dqr=s(aS);bso=r(dqr,"ImageGPTModel"),dqr.forEach(t),vso=r(BCe," (ImageGPT model)"),BCe.forEach(t),Tso=i(C),bp=n(C,"LI",{});var xCe=s(bp);xK=n(xCe,"STRONG",{});var cqr=s(xK);Fso=r(cqr,"layoutlm"),cqr.forEach(t),Cso=r(xCe," \u2014 "),nS=n(xCe,"A",{href:!0});var fqr=s(nS);Mso=r(fqr,"LayoutLMModel"),fqr.forEach(t),Eso=r(xCe," (LayoutLM model)"),xCe.forEach(t),yso=i(C),vp=n(C,"LI",{});var kCe=s(vp);kK=n(kCe,"STRONG",{});var mqr=s(kK);wso=r(mqr,"layoutlmv2"),mqr.forEach(t),Aso=r(kCe," \u2014 "),sS=n(kCe,"A",{href:!0});var gqr=s(sS);Lso=r(gqr,"LayoutLMv2Model"),gqr.forEach(t),Bso=r(kCe," (LayoutLMv2 model)"),kCe.forEach(t),xso=i(C),Tp=n(C,"LI",{});var RCe=s(Tp);RK=n(RCe,"STRONG",{});var hqr=s(RK);kso=r(hqr,"led"),hqr.forEach(t),Rso=r(RCe," \u2014 "),lS=n(RCe,"A",{href:!0});var pqr=s(lS);Sso=r(pqr,"LEDModel"),pqr.forEach(t),Pso=r(RCe," (LED model)"),RCe.forEach(t),$so=i(C),Fp=n(C,"LI",{});var SCe=s(Fp);SK=n(SCe,"STRONG",{});var _qr=s(SK);Iso=r(_qr,"longformer"),_qr.forEach(t),jso=r(SCe," \u2014 "),iS=n(SCe,"A",{href:!0});var uqr=s(iS);Dso=r(uqr,"LongformerModel"),uqr.forEach(t),Nso=r(SCe," (Longformer model)"),SCe.forEach(t),qso=i(C),Cp=n(C,"LI",{});var PCe=s(Cp);PK=n(PCe,"STRONG",{});var bqr=s(PK);Oso=r(bqr,"luke"),bqr.forEach(t),Gso=r(PCe," \u2014 "),dS=n(PCe,"A",{href:!0});var vqr=s(dS);Xso=r(vqr,"LukeModel"),vqr.forEach(t),Vso=r(PCe," (LUKE model)"),PCe.forEach(t),zso=i(C),Mp=n(C,"LI",{});var $Ce=s(Mp);$K=n($Ce,"STRONG",{});var Tqr=s($K);Wso=r(Tqr,"lxmert"),Tqr.forEach(t),Qso=r($Ce," \u2014 "),cS=n($Ce,"A",{href:!0});var Fqr=s(cS);Hso=r(Fqr,"LxmertModel"),Fqr.forEach(t),Uso=r($Ce," (LXMERT model)"),$Ce.forEach(t),Jso=i(C),Ep=n(C,"LI",{});var ICe=s(Ep);IK=n(ICe,"STRONG",{});var Cqr=s(IK);Yso=r(Cqr,"m2m_100"),Cqr.forEach(t),Kso=r(ICe," \u2014 "),fS=n(ICe,"A",{href:!0});var Mqr=s(fS);Zso=r(Mqr,"M2M100Model"),Mqr.forEach(t),elo=r(ICe," (M2M100 model)"),ICe.forEach(t),olo=i(C),yp=n(C,"LI",{});var jCe=s(yp);jK=n(jCe,"STRONG",{});var Eqr=s(jK);rlo=r(Eqr,"marian"),Eqr.forEach(t),tlo=r(jCe," \u2014 "),mS=n(jCe,"A",{href:!0});var yqr=s(mS);alo=r(yqr,"MarianModel"),yqr.forEach(t),nlo=r(jCe," (Marian model)"),jCe.forEach(t),slo=i(C),wp=n(C,"LI",{});var DCe=s(wp);DK=n(DCe,"STRONG",{});var wqr=s(DK);llo=r(wqr,"maskformer"),wqr.forEach(t),ilo=r(DCe," \u2014 "),gS=n(DCe,"A",{href:!0});var Aqr=s(gS);dlo=r(Aqr,"MaskFormerModel"),Aqr.forEach(t),clo=r(DCe," (MaskFormer model)"),DCe.forEach(t),flo=i(C),Ap=n(C,"LI",{});var NCe=s(Ap);NK=n(NCe,"STRONG",{});var Lqr=s(NK);mlo=r(Lqr,"mbart"),Lqr.forEach(t),glo=r(NCe," \u2014 "),hS=n(NCe,"A",{href:!0});var Bqr=s(hS);hlo=r(Bqr,"MBartModel"),Bqr.forEach(t),plo=r(NCe," (mBART model)"),NCe.forEach(t),_lo=i(C),Lp=n(C,"LI",{});var qCe=s(Lp);qK=n(qCe,"STRONG",{});var xqr=s(qK);ulo=r(xqr,"megatron-bert"),xqr.forEach(t),blo=r(qCe," \u2014 "),pS=n(qCe,"A",{href:!0});var kqr=s(pS);vlo=r(kqr,"MegatronBertModel"),kqr.forEach(t),Tlo=r(qCe," (MegatronBert model)"),qCe.forEach(t),Flo=i(C),Bp=n(C,"LI",{});var OCe=s(Bp);OK=n(OCe,"STRONG",{});var Rqr=s(OK);Clo=r(Rqr,"mobilebert"),Rqr.forEach(t),Mlo=r(OCe," \u2014 "),_S=n(OCe,"A",{href:!0});var Sqr=s(_S);Elo=r(Sqr,"MobileBertModel"),Sqr.forEach(t),ylo=r(OCe," (MobileBERT model)"),OCe.forEach(t),wlo=i(C),xp=n(C,"LI",{});var GCe=s(xp);GK=n(GCe,"STRONG",{});var Pqr=s(GK);Alo=r(Pqr,"mpnet"),Pqr.forEach(t),Llo=r(GCe," \u2014 "),uS=n(GCe,"A",{href:!0});var $qr=s(uS);Blo=r($qr,"MPNetModel"),$qr.forEach(t),xlo=r(GCe," (MPNet model)"),GCe.forEach(t),klo=i(C),kp=n(C,"LI",{});var XCe=s(kp);XK=n(XCe,"STRONG",{});var Iqr=s(XK);Rlo=r(Iqr,"mt5"),Iqr.forEach(t),Slo=r(XCe," \u2014 "),bS=n(XCe,"A",{href:!0});var jqr=s(bS);Plo=r(jqr,"MT5Model"),jqr.forEach(t),$lo=r(XCe," (mT5 model)"),XCe.forEach(t),Ilo=i(C),Rp=n(C,"LI",{});var VCe=s(Rp);VK=n(VCe,"STRONG",{});var Dqr=s(VK);jlo=r(Dqr,"nystromformer"),Dqr.forEach(t),Dlo=r(VCe," \u2014 "),vS=n(VCe,"A",{href:!0});var Nqr=s(vS);Nlo=r(Nqr,"NystromformerModel"),Nqr.forEach(t),qlo=r(VCe," (Nystromformer model)"),VCe.forEach(t),Olo=i(C),Sp=n(C,"LI",{});var zCe=s(Sp);zK=n(zCe,"STRONG",{});var qqr=s(zK);Glo=r(qqr,"openai-gpt"),qqr.forEach(t),Xlo=r(zCe," \u2014 "),TS=n(zCe,"A",{href:!0});var Oqr=s(TS);Vlo=r(Oqr,"OpenAIGPTModel"),Oqr.forEach(t),zlo=r(zCe," (OpenAI GPT model)"),zCe.forEach(t),Wlo=i(C),Pp=n(C,"LI",{});var WCe=s(Pp);WK=n(WCe,"STRONG",{});var Gqr=s(WK);Qlo=r(Gqr,"pegasus"),Gqr.forEach(t),Hlo=r(WCe," \u2014 "),FS=n(WCe,"A",{href:!0});var Xqr=s(FS);Ulo=r(Xqr,"PegasusModel"),Xqr.forEach(t),Jlo=r(WCe," (Pegasus model)"),WCe.forEach(t),Ylo=i(C),$p=n(C,"LI",{});var QCe=s($p);QK=n(QCe,"STRONG",{});var Vqr=s(QK);Klo=r(Vqr,"perceiver"),Vqr.forEach(t),Zlo=r(QCe," \u2014 "),CS=n(QCe,"A",{href:!0});var zqr=s(CS);eio=r(zqr,"PerceiverModel"),zqr.forEach(t),oio=r(QCe," (Perceiver model)"),QCe.forEach(t),rio=i(C),Ip=n(C,"LI",{});var HCe=s(Ip);HK=n(HCe,"STRONG",{});var Wqr=s(HK);tio=r(Wqr,"plbart"),Wqr.forEach(t),aio=r(HCe," \u2014 "),MS=n(HCe,"A",{href:!0});var Qqr=s(MS);nio=r(Qqr,"PLBartModel"),Qqr.forEach(t),sio=r(HCe," (PLBart model)"),HCe.forEach(t),lio=i(C),jp=n(C,"LI",{});var UCe=s(jp);UK=n(UCe,"STRONG",{});var Hqr=s(UK);iio=r(Hqr,"poolformer"),Hqr.forEach(t),dio=r(UCe," \u2014 "),ES=n(UCe,"A",{href:!0});var Uqr=s(ES);cio=r(Uqr,"PoolFormerModel"),Uqr.forEach(t),fio=r(UCe," (PoolFormer model)"),UCe.forEach(t),mio=i(C),Dp=n(C,"LI",{});var JCe=s(Dp);JK=n(JCe,"STRONG",{});var Jqr=s(JK);gio=r(Jqr,"prophetnet"),Jqr.forEach(t),hio=r(JCe," \u2014 "),yS=n(JCe,"A",{href:!0});var Yqr=s(yS);pio=r(Yqr,"ProphetNetModel"),Yqr.forEach(t),_io=r(JCe," (ProphetNet model)"),JCe.forEach(t),uio=i(C),Np=n(C,"LI",{});var YCe=s(Np);YK=n(YCe,"STRONG",{});var Kqr=s(YK);bio=r(Kqr,"qdqbert"),Kqr.forEach(t),vio=r(YCe," \u2014 "),wS=n(YCe,"A",{href:!0});var Zqr=s(wS);Tio=r(Zqr,"QDQBertModel"),Zqr.forEach(t),Fio=r(YCe," (QDQBert model)"),YCe.forEach(t),Cio=i(C),qp=n(C,"LI",{});var KCe=s(qp);KK=n(KCe,"STRONG",{});var eOr=s(KK);Mio=r(eOr,"reformer"),eOr.forEach(t),Eio=r(KCe," \u2014 "),AS=n(KCe,"A",{href:!0});var oOr=s(AS);yio=r(oOr,"ReformerModel"),oOr.forEach(t),wio=r(KCe," (Reformer model)"),KCe.forEach(t),Aio=i(C),Op=n(C,"LI",{});var ZCe=s(Op);ZK=n(ZCe,"STRONG",{});var rOr=s(ZK);Lio=r(rOr,"rembert"),rOr.forEach(t),Bio=r(ZCe," \u2014 "),LS=n(ZCe,"A",{href:!0});var tOr=s(LS);xio=r(tOr,"RemBertModel"),tOr.forEach(t),kio=r(ZCe," (RemBERT model)"),ZCe.forEach(t),Rio=i(C),Gp=n(C,"LI",{});var eMe=s(Gp);eZ=n(eMe,"STRONG",{});var aOr=s(eZ);Sio=r(aOr,"resnet"),aOr.forEach(t),Pio=r(eMe," \u2014 "),BS=n(eMe,"A",{href:!0});var nOr=s(BS);$io=r(nOr,"ResNetModel"),nOr.forEach(t),Iio=r(eMe," (ResNet model)"),eMe.forEach(t),jio=i(C),Xp=n(C,"LI",{});var oMe=s(Xp);oZ=n(oMe,"STRONG",{});var sOr=s(oZ);Dio=r(sOr,"retribert"),sOr.forEach(t),Nio=r(oMe," \u2014 "),xS=n(oMe,"A",{href:!0});var lOr=s(xS);qio=r(lOr,"RetriBertModel"),lOr.forEach(t),Oio=r(oMe," (RetriBERT model)"),oMe.forEach(t),Gio=i(C),Vp=n(C,"LI",{});var rMe=s(Vp);rZ=n(rMe,"STRONG",{});var iOr=s(rZ);Xio=r(iOr,"roberta"),iOr.forEach(t),Vio=r(rMe," \u2014 "),kS=n(rMe,"A",{href:!0});var dOr=s(kS);zio=r(dOr,"RobertaModel"),dOr.forEach(t),Wio=r(rMe," (RoBERTa model)"),rMe.forEach(t),Qio=i(C),zp=n(C,"LI",{});var tMe=s(zp);tZ=n(tMe,"STRONG",{});var cOr=s(tZ);Hio=r(cOr,"roformer"),cOr.forEach(t),Uio=r(tMe," \u2014 "),RS=n(tMe,"A",{href:!0});var fOr=s(RS);Jio=r(fOr,"RoFormerModel"),fOr.forEach(t),Yio=r(tMe," (RoFormer model)"),tMe.forEach(t),Kio=i(C),Wp=n(C,"LI",{});var aMe=s(Wp);aZ=n(aMe,"STRONG",{});var mOr=s(aZ);Zio=r(mOr,"segformer"),mOr.forEach(t),edo=r(aMe," \u2014 "),SS=n(aMe,"A",{href:!0});var gOr=s(SS);odo=r(gOr,"SegformerModel"),gOr.forEach(t),rdo=r(aMe," (SegFormer model)"),aMe.forEach(t),tdo=i(C),Qp=n(C,"LI",{});var nMe=s(Qp);nZ=n(nMe,"STRONG",{});var hOr=s(nZ);ado=r(hOr,"sew"),hOr.forEach(t),ndo=r(nMe," \u2014 "),PS=n(nMe,"A",{href:!0});var pOr=s(PS);sdo=r(pOr,"SEWModel"),pOr.forEach(t),ldo=r(nMe," (SEW model)"),nMe.forEach(t),ido=i(C),Hp=n(C,"LI",{});var sMe=s(Hp);sZ=n(sMe,"STRONG",{});var _Or=s(sZ);ddo=r(_Or,"sew-d"),_Or.forEach(t),cdo=r(sMe," \u2014 "),$S=n(sMe,"A",{href:!0});var uOr=s($S);fdo=r(uOr,"SEWDModel"),uOr.forEach(t),mdo=r(sMe," (SEW-D model)"),sMe.forEach(t),gdo=i(C),Up=n(C,"LI",{});var lMe=s(Up);lZ=n(lMe,"STRONG",{});var bOr=s(lZ);hdo=r(bOr,"speech_to_text"),bOr.forEach(t),pdo=r(lMe," \u2014 "),IS=n(lMe,"A",{href:!0});var vOr=s(IS);_do=r(vOr,"Speech2TextModel"),vOr.forEach(t),udo=r(lMe," (Speech2Text model)"),lMe.forEach(t),bdo=i(C),Jp=n(C,"LI",{});var iMe=s(Jp);iZ=n(iMe,"STRONG",{});var TOr=s(iZ);vdo=r(TOr,"splinter"),TOr.forEach(t),Tdo=r(iMe," \u2014 "),jS=n(iMe,"A",{href:!0});var FOr=s(jS);Fdo=r(FOr,"SplinterModel"),FOr.forEach(t),Cdo=r(iMe," (Splinter model)"),iMe.forEach(t),Mdo=i(C),Yp=n(C,"LI",{});var dMe=s(Yp);dZ=n(dMe,"STRONG",{});var COr=s(dZ);Edo=r(COr,"squeezebert"),COr.forEach(t),ydo=r(dMe," \u2014 "),DS=n(dMe,"A",{href:!0});var MOr=s(DS);wdo=r(MOr,"SqueezeBertModel"),MOr.forEach(t),Ado=r(dMe," (SqueezeBERT model)"),dMe.forEach(t),Ldo=i(C),Kp=n(C,"LI",{});var cMe=s(Kp);cZ=n(cMe,"STRONG",{});var EOr=s(cZ);Bdo=r(EOr,"swin"),EOr.forEach(t),xdo=r(cMe," \u2014 "),NS=n(cMe,"A",{href:!0});var yOr=s(NS);kdo=r(yOr,"SwinModel"),yOr.forEach(t),Rdo=r(cMe," (Swin model)"),cMe.forEach(t),Sdo=i(C),Zp=n(C,"LI",{});var fMe=s(Zp);fZ=n(fMe,"STRONG",{});var wOr=s(fZ);Pdo=r(wOr,"t5"),wOr.forEach(t),$do=r(fMe," \u2014 "),qS=n(fMe,"A",{href:!0});var AOr=s(qS);Ido=r(AOr,"T5Model"),AOr.forEach(t),jdo=r(fMe," (T5 model)"),fMe.forEach(t),Ddo=i(C),e_=n(C,"LI",{});var mMe=s(e_);mZ=n(mMe,"STRONG",{});var LOr=s(mZ);Ndo=r(LOr,"tapas"),LOr.forEach(t),qdo=r(mMe," \u2014 "),OS=n(mMe,"A",{href:!0});var BOr=s(OS);Odo=r(BOr,"TapasModel"),BOr.forEach(t),Gdo=r(mMe," (TAPAS model)"),mMe.forEach(t),Xdo=i(C),o_=n(C,"LI",{});var gMe=s(o_);gZ=n(gMe,"STRONG",{});var xOr=s(gZ);Vdo=r(xOr,"transfo-xl"),xOr.forEach(t),zdo=r(gMe," \u2014 "),GS=n(gMe,"A",{href:!0});var kOr=s(GS);Wdo=r(kOr,"TransfoXLModel"),kOr.forEach(t),Qdo=r(gMe," (Transformer-XL model)"),gMe.forEach(t),Hdo=i(C),r_=n(C,"LI",{});var hMe=s(r_);hZ=n(hMe,"STRONG",{});var ROr=s(hZ);Udo=r(ROr,"unispeech"),ROr.forEach(t),Jdo=r(hMe," \u2014 "),XS=n(hMe,"A",{href:!0});var SOr=s(XS);Ydo=r(SOr,"UniSpeechModel"),SOr.forEach(t),Kdo=r(hMe," (UniSpeech model)"),hMe.forEach(t),Zdo=i(C),t_=n(C,"LI",{});var pMe=s(t_);pZ=n(pMe,"STRONG",{});var POr=s(pZ);eco=r(POr,"unispeech-sat"),POr.forEach(t),oco=r(pMe," \u2014 "),VS=n(pMe,"A",{href:!0});var $Or=s(VS);rco=r($Or,"UniSpeechSatModel"),$Or.forEach(t),tco=r(pMe," (UniSpeechSat model)"),pMe.forEach(t),aco=i(C),a_=n(C,"LI",{});var _Me=s(a_);_Z=n(_Me,"STRONG",{});var IOr=s(_Z);nco=r(IOr,"vilt"),IOr.forEach(t),sco=r(_Me," \u2014 "),zS=n(_Me,"A",{href:!0});var jOr=s(zS);lco=r(jOr,"ViltModel"),jOr.forEach(t),ico=r(_Me," (ViLT model)"),_Me.forEach(t),dco=i(C),n_=n(C,"LI",{});var uMe=s(n_);uZ=n(uMe,"STRONG",{});var DOr=s(uZ);cco=r(DOr,"vision-text-dual-encoder"),DOr.forEach(t),fco=r(uMe," \u2014 "),WS=n(uMe,"A",{href:!0});var NOr=s(WS);mco=r(NOr,"VisionTextDualEncoderModel"),NOr.forEach(t),gco=r(uMe," (VisionTextDualEncoder model)"),uMe.forEach(t),hco=i(C),s_=n(C,"LI",{});var bMe=s(s_);bZ=n(bMe,"STRONG",{});var qOr=s(bZ);pco=r(qOr,"visual_bert"),qOr.forEach(t),_co=r(bMe," \u2014 "),QS=n(bMe,"A",{href:!0});var OOr=s(QS);uco=r(OOr,"VisualBertModel"),OOr.forEach(t),bco=r(bMe," (VisualBert model)"),bMe.forEach(t),vco=i(C),l_=n(C,"LI",{});var vMe=s(l_);vZ=n(vMe,"STRONG",{});var GOr=s(vZ);Tco=r(GOr,"vit"),GOr.forEach(t),Fco=r(vMe," \u2014 "),HS=n(vMe,"A",{href:!0});var XOr=s(HS);Cco=r(XOr,"ViTModel"),XOr.forEach(t),Mco=r(vMe," (ViT model)"),vMe.forEach(t),Eco=i(C),i_=n(C,"LI",{});var TMe=s(i_);TZ=n(TMe,"STRONG",{});var VOr=s(TZ);yco=r(VOr,"vit_mae"),VOr.forEach(t),wco=r(TMe," \u2014 "),US=n(TMe,"A",{href:!0});var zOr=s(US);Aco=r(zOr,"ViTMAEModel"),zOr.forEach(t),Lco=r(TMe," (ViTMAE model)"),TMe.forEach(t),Bco=i(C),d_=n(C,"LI",{});var FMe=s(d_);FZ=n(FMe,"STRONG",{});var WOr=s(FZ);xco=r(WOr,"wav2vec2"),WOr.forEach(t),kco=r(FMe," \u2014 "),JS=n(FMe,"A",{href:!0});var QOr=s(JS);Rco=r(QOr,"Wav2Vec2Model"),QOr.forEach(t),Sco=r(FMe," (Wav2Vec2 model)"),FMe.forEach(t),Pco=i(C),c_=n(C,"LI",{});var CMe=s(c_);CZ=n(CMe,"STRONG",{});var HOr=s(CZ);$co=r(HOr,"wavlm"),HOr.forEach(t),Ico=r(CMe," \u2014 "),YS=n(CMe,"A",{href:!0});var UOr=s(YS);jco=r(UOr,"WavLMModel"),UOr.forEach(t),Dco=r(CMe," (WavLM model)"),CMe.forEach(t),Nco=i(C),f_=n(C,"LI",{});var MMe=s(f_);MZ=n(MMe,"STRONG",{});var JOr=s(MZ);qco=r(JOr,"xglm"),JOr.forEach(t),Oco=r(MMe," \u2014 "),KS=n(MMe,"A",{href:!0});var YOr=s(KS);Gco=r(YOr,"XGLMModel"),YOr.forEach(t),Xco=r(MMe," (XGLM model)"),MMe.forEach(t),Vco=i(C),m_=n(C,"LI",{});var EMe=s(m_);EZ=n(EMe,"STRONG",{});var KOr=s(EZ);zco=r(KOr,"xlm"),KOr.forEach(t),Wco=r(EMe," \u2014 "),ZS=n(EMe,"A",{href:!0});var ZOr=s(ZS);Qco=r(ZOr,"XLMModel"),ZOr.forEach(t),Hco=r(EMe," (XLM model)"),EMe.forEach(t),Uco=i(C),g_=n(C,"LI",{});var yMe=s(g_);yZ=n(yMe,"STRONG",{});var eGr=s(yZ);Jco=r(eGr,"xlm-prophetnet"),eGr.forEach(t),Yco=r(yMe," \u2014 "),eP=n(yMe,"A",{href:!0});var oGr=s(eP);Kco=r(oGr,"XLMProphetNetModel"),oGr.forEach(t),Zco=r(yMe," (XLMProphetNet model)"),yMe.forEach(t),efo=i(C),h_=n(C,"LI",{});var wMe=s(h_);wZ=n(wMe,"STRONG",{});var rGr=s(wZ);ofo=r(rGr,"xlm-roberta"),rGr.forEach(t),rfo=r(wMe," \u2014 "),oP=n(wMe,"A",{href:!0});var tGr=s(oP);tfo=r(tGr,"XLMRobertaModel"),tGr.forEach(t),afo=r(wMe," (XLM-RoBERTa model)"),wMe.forEach(t),nfo=i(C),p_=n(C,"LI",{});var AMe=s(p_);AZ=n(AMe,"STRONG",{});var aGr=s(AZ);sfo=r(aGr,"xlm-roberta-xl"),aGr.forEach(t),lfo=r(AMe," \u2014 "),rP=n(AMe,"A",{href:!0});var nGr=s(rP);ifo=r(nGr,"XLMRobertaXLModel"),nGr.forEach(t),dfo=r(AMe," (XLM-RoBERTa-XL model)"),AMe.forEach(t),cfo=i(C),__=n(C,"LI",{});var LMe=s(__);LZ=n(LMe,"STRONG",{});var sGr=s(LZ);ffo=r(sGr,"xlnet"),sGr.forEach(t),mfo=r(LMe," \u2014 "),tP=n(LMe,"A",{href:!0});var lGr=s(tP);gfo=r(lGr,"XLNetModel"),lGr.forEach(t),hfo=r(LMe," (XLNet model)"),LMe.forEach(t),pfo=i(C),u_=n(C,"LI",{});var BMe=s(u_);BZ=n(BMe,"STRONG",{});var iGr=s(BZ);_fo=r(iGr,"yoso"),iGr.forEach(t),ufo=r(BMe," \u2014 "),aP=n(BMe,"A",{href:!0});var dGr=s(aP);bfo=r(dGr,"YosoModel"),dGr.forEach(t),vfo=r(BMe," (YOSO model)"),BMe.forEach(t),C.forEach(t),Tfo=i(qt),b_=n(qt,"P",{});var xMe=s(b_);Ffo=r(xMe,"The model is set in evaluation mode by default using "),xZ=n(xMe,"CODE",{});var cGr=s(xZ);Cfo=r(cGr,"model.eval()"),cGr.forEach(t),Mfo=r(xMe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kZ=n(xMe,"CODE",{});var fGr=s(kZ);Efo=r(fGr,"model.train()"),fGr.forEach(t),xMe.forEach(t),yfo=i(qt),RZ=n(qt,"P",{});var mGr=s(RZ);wfo=r(mGr,"Examples:"),mGr.forEach(t),Afo=i(qt),m($E.$$.fragment,qt),qt.forEach(t),Ws.forEach(t),Bxe=i(c),Zi=n(c,"H2",{class:!0});var DRe=s(Zi);v_=n(DRe,"A",{id:!0,class:!0,href:!0});var gGr=s(v_);SZ=n(gGr,"SPAN",{});var hGr=s(SZ);m(IE.$$.fragment,hGr),hGr.forEach(t),gGr.forEach(t),Lfo=i(DRe),PZ=n(DRe,"SPAN",{});var pGr=s(PZ);Bfo=r(pGr,"AutoModelForPreTraining"),pGr.forEach(t),DRe.forEach(t),xxe=i(c),Yo=n(c,"DIV",{class:!0});var Hs=s(Yo);m(jE.$$.fragment,Hs),xfo=i(Hs),ed=n(Hs,"P",{});var kz=s(ed);kfo=r(kz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),$Z=n(kz,"CODE",{});var _Gr=s($Z);Rfo=r(_Gr,"from_pretrained()"),_Gr.forEach(t),Sfo=r(kz,"class method or the "),IZ=n(kz,"CODE",{});var uGr=s(IZ);Pfo=r(uGr,"from_config()"),uGr.forEach(t),$fo=r(kz,`class
method.`),kz.forEach(t),Ifo=i(Hs),DE=n(Hs,"P",{});var NRe=s(DE);jfo=r(NRe,"This class cannot be instantiated directly using "),jZ=n(NRe,"CODE",{});var bGr=s(jZ);Dfo=r(bGr,"__init__()"),bGr.forEach(t),Nfo=r(NRe," (throws an error)."),NRe.forEach(t),qfo=i(Hs),zr=n(Hs,"DIV",{class:!0});var Us=s(zr);m(NE.$$.fragment,Us),Ofo=i(Us),DZ=n(Us,"P",{});var vGr=s(DZ);Gfo=r(vGr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),vGr.forEach(t),Xfo=i(Us),od=n(Us,"P",{});var Rz=s(od);Vfo=r(Rz,`Note:
Loading a model from its configuration file does `),NZ=n(Rz,"STRONG",{});var TGr=s(NZ);zfo=r(TGr,"not"),TGr.forEach(t),Wfo=r(Rz,` load the model weights. It only affects the
model\u2019s configuration. Use `),qZ=n(Rz,"CODE",{});var FGr=s(qZ);Qfo=r(FGr,"from_pretrained()"),FGr.forEach(t),Hfo=r(Rz,"to load the model weights."),Rz.forEach(t),Ufo=i(Us),OZ=n(Us,"P",{});var CGr=s(OZ);Jfo=r(CGr,"Examples:"),CGr.forEach(t),Yfo=i(Us),m(qE.$$.fragment,Us),Us.forEach(t),Kfo=i(Hs),Ne=n(Hs,"DIV",{class:!0});var Ot=s(Ne);m(OE.$$.fragment,Ot),Zfo=i(Ot),GZ=n(Ot,"P",{});var MGr=s(GZ);emo=r(MGr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),MGr.forEach(t),omo=i(Ot),Va=n(Ot,"P",{});var ZM=s(Va);rmo=r(ZM,"The model class to instantiate is selected based on the "),XZ=n(ZM,"CODE",{});var EGr=s(XZ);tmo=r(EGr,"model_type"),EGr.forEach(t),amo=r(ZM,` property of the config object (either
passed as an argument or loaded from `),VZ=n(ZM,"CODE",{});var yGr=s(VZ);nmo=r(yGr,"pretrained_model_name_or_path"),yGr.forEach(t),smo=r(ZM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zZ=n(ZM,"CODE",{});var wGr=s(zZ);lmo=r(wGr,"pretrained_model_name_or_path"),wGr.forEach(t),imo=r(ZM,":"),ZM.forEach(t),dmo=i(Ot),k=n(Ot,"UL",{});var S=s(k);T_=n(S,"LI",{});var kMe=s(T_);WZ=n(kMe,"STRONG",{});var AGr=s(WZ);cmo=r(AGr,"albert"),AGr.forEach(t),fmo=r(kMe," \u2014 "),nP=n(kMe,"A",{href:!0});var LGr=s(nP);mmo=r(LGr,"AlbertForPreTraining"),LGr.forEach(t),gmo=r(kMe," (ALBERT model)"),kMe.forEach(t),hmo=i(S),F_=n(S,"LI",{});var RMe=s(F_);QZ=n(RMe,"STRONG",{});var BGr=s(QZ);pmo=r(BGr,"bart"),BGr.forEach(t),_mo=r(RMe," \u2014 "),sP=n(RMe,"A",{href:!0});var xGr=s(sP);umo=r(xGr,"BartForConditionalGeneration"),xGr.forEach(t),bmo=r(RMe," (BART model)"),RMe.forEach(t),vmo=i(S),C_=n(S,"LI",{});var SMe=s(C_);HZ=n(SMe,"STRONG",{});var kGr=s(HZ);Tmo=r(kGr,"bert"),kGr.forEach(t),Fmo=r(SMe," \u2014 "),lP=n(SMe,"A",{href:!0});var RGr=s(lP);Cmo=r(RGr,"BertForPreTraining"),RGr.forEach(t),Mmo=r(SMe," (BERT model)"),SMe.forEach(t),Emo=i(S),M_=n(S,"LI",{});var PMe=s(M_);UZ=n(PMe,"STRONG",{});var SGr=s(UZ);ymo=r(SGr,"big_bird"),SGr.forEach(t),wmo=r(PMe," \u2014 "),iP=n(PMe,"A",{href:!0});var PGr=s(iP);Amo=r(PGr,"BigBirdForPreTraining"),PGr.forEach(t),Lmo=r(PMe," (BigBird model)"),PMe.forEach(t),Bmo=i(S),E_=n(S,"LI",{});var $Me=s(E_);JZ=n($Me,"STRONG",{});var $Gr=s(JZ);xmo=r($Gr,"camembert"),$Gr.forEach(t),kmo=r($Me," \u2014 "),dP=n($Me,"A",{href:!0});var IGr=s(dP);Rmo=r(IGr,"CamembertForMaskedLM"),IGr.forEach(t),Smo=r($Me," (CamemBERT model)"),$Me.forEach(t),Pmo=i(S),y_=n(S,"LI",{});var IMe=s(y_);YZ=n(IMe,"STRONG",{});var jGr=s(YZ);$mo=r(jGr,"ctrl"),jGr.forEach(t),Imo=r(IMe," \u2014 "),cP=n(IMe,"A",{href:!0});var DGr=s(cP);jmo=r(DGr,"CTRLLMHeadModel"),DGr.forEach(t),Dmo=r(IMe," (CTRL model)"),IMe.forEach(t),Nmo=i(S),w_=n(S,"LI",{});var jMe=s(w_);KZ=n(jMe,"STRONG",{});var NGr=s(KZ);qmo=r(NGr,"data2vec-text"),NGr.forEach(t),Omo=r(jMe," \u2014 "),fP=n(jMe,"A",{href:!0});var qGr=s(fP);Gmo=r(qGr,"Data2VecTextForMaskedLM"),qGr.forEach(t),Xmo=r(jMe," (Data2VecText model)"),jMe.forEach(t),Vmo=i(S),A_=n(S,"LI",{});var DMe=s(A_);ZZ=n(DMe,"STRONG",{});var OGr=s(ZZ);zmo=r(OGr,"deberta"),OGr.forEach(t),Wmo=r(DMe," \u2014 "),mP=n(DMe,"A",{href:!0});var GGr=s(mP);Qmo=r(GGr,"DebertaForMaskedLM"),GGr.forEach(t),Hmo=r(DMe," (DeBERTa model)"),DMe.forEach(t),Umo=i(S),L_=n(S,"LI",{});var NMe=s(L_);eee=n(NMe,"STRONG",{});var XGr=s(eee);Jmo=r(XGr,"deberta-v2"),XGr.forEach(t),Ymo=r(NMe," \u2014 "),gP=n(NMe,"A",{href:!0});var VGr=s(gP);Kmo=r(VGr,"DebertaV2ForMaskedLM"),VGr.forEach(t),Zmo=r(NMe," (DeBERTa-v2 model)"),NMe.forEach(t),ego=i(S),B_=n(S,"LI",{});var qMe=s(B_);oee=n(qMe,"STRONG",{});var zGr=s(oee);ogo=r(zGr,"distilbert"),zGr.forEach(t),rgo=r(qMe," \u2014 "),hP=n(qMe,"A",{href:!0});var WGr=s(hP);tgo=r(WGr,"DistilBertForMaskedLM"),WGr.forEach(t),ago=r(qMe," (DistilBERT model)"),qMe.forEach(t),ngo=i(S),x_=n(S,"LI",{});var OMe=s(x_);ree=n(OMe,"STRONG",{});var QGr=s(ree);sgo=r(QGr,"electra"),QGr.forEach(t),lgo=r(OMe," \u2014 "),pP=n(OMe,"A",{href:!0});var HGr=s(pP);igo=r(HGr,"ElectraForPreTraining"),HGr.forEach(t),dgo=r(OMe," (ELECTRA model)"),OMe.forEach(t),cgo=i(S),k_=n(S,"LI",{});var GMe=s(k_);tee=n(GMe,"STRONG",{});var UGr=s(tee);fgo=r(UGr,"flaubert"),UGr.forEach(t),mgo=r(GMe," \u2014 "),_P=n(GMe,"A",{href:!0});var JGr=s(_P);ggo=r(JGr,"FlaubertWithLMHeadModel"),JGr.forEach(t),hgo=r(GMe," (FlauBERT model)"),GMe.forEach(t),pgo=i(S),R_=n(S,"LI",{});var XMe=s(R_);aee=n(XMe,"STRONG",{});var YGr=s(aee);_go=r(YGr,"fnet"),YGr.forEach(t),ugo=r(XMe," \u2014 "),uP=n(XMe,"A",{href:!0});var KGr=s(uP);bgo=r(KGr,"FNetForPreTraining"),KGr.forEach(t),vgo=r(XMe," (FNet model)"),XMe.forEach(t),Tgo=i(S),S_=n(S,"LI",{});var VMe=s(S_);nee=n(VMe,"STRONG",{});var ZGr=s(nee);Fgo=r(ZGr,"fsmt"),ZGr.forEach(t),Cgo=r(VMe," \u2014 "),bP=n(VMe,"A",{href:!0});var eXr=s(bP);Mgo=r(eXr,"FSMTForConditionalGeneration"),eXr.forEach(t),Ego=r(VMe," (FairSeq Machine-Translation model)"),VMe.forEach(t),ygo=i(S),P_=n(S,"LI",{});var zMe=s(P_);see=n(zMe,"STRONG",{});var oXr=s(see);wgo=r(oXr,"funnel"),oXr.forEach(t),Ago=r(zMe," \u2014 "),vP=n(zMe,"A",{href:!0});var rXr=s(vP);Lgo=r(rXr,"FunnelForPreTraining"),rXr.forEach(t),Bgo=r(zMe," (Funnel Transformer model)"),zMe.forEach(t),xgo=i(S),$_=n(S,"LI",{});var WMe=s($_);lee=n(WMe,"STRONG",{});var tXr=s(lee);kgo=r(tXr,"gpt2"),tXr.forEach(t),Rgo=r(WMe," \u2014 "),TP=n(WMe,"A",{href:!0});var aXr=s(TP);Sgo=r(aXr,"GPT2LMHeadModel"),aXr.forEach(t),Pgo=r(WMe," (OpenAI GPT-2 model)"),WMe.forEach(t),$go=i(S),I_=n(S,"LI",{});var QMe=s(I_);iee=n(QMe,"STRONG",{});var nXr=s(iee);Igo=r(nXr,"ibert"),nXr.forEach(t),jgo=r(QMe," \u2014 "),FP=n(QMe,"A",{href:!0});var sXr=s(FP);Dgo=r(sXr,"IBertForMaskedLM"),sXr.forEach(t),Ngo=r(QMe," (I-BERT model)"),QMe.forEach(t),qgo=i(S),j_=n(S,"LI",{});var HMe=s(j_);dee=n(HMe,"STRONG",{});var lXr=s(dee);Ogo=r(lXr,"layoutlm"),lXr.forEach(t),Ggo=r(HMe," \u2014 "),CP=n(HMe,"A",{href:!0});var iXr=s(CP);Xgo=r(iXr,"LayoutLMForMaskedLM"),iXr.forEach(t),Vgo=r(HMe," (LayoutLM model)"),HMe.forEach(t),zgo=i(S),D_=n(S,"LI",{});var UMe=s(D_);cee=n(UMe,"STRONG",{});var dXr=s(cee);Wgo=r(dXr,"longformer"),dXr.forEach(t),Qgo=r(UMe," \u2014 "),MP=n(UMe,"A",{href:!0});var cXr=s(MP);Hgo=r(cXr,"LongformerForMaskedLM"),cXr.forEach(t),Ugo=r(UMe," (Longformer model)"),UMe.forEach(t),Jgo=i(S),N_=n(S,"LI",{});var JMe=s(N_);fee=n(JMe,"STRONG",{});var fXr=s(fee);Ygo=r(fXr,"lxmert"),fXr.forEach(t),Kgo=r(JMe," \u2014 "),EP=n(JMe,"A",{href:!0});var mXr=s(EP);Zgo=r(mXr,"LxmertForPreTraining"),mXr.forEach(t),eho=r(JMe," (LXMERT model)"),JMe.forEach(t),oho=i(S),q_=n(S,"LI",{});var YMe=s(q_);mee=n(YMe,"STRONG",{});var gXr=s(mee);rho=r(gXr,"megatron-bert"),gXr.forEach(t),tho=r(YMe," \u2014 "),yP=n(YMe,"A",{href:!0});var hXr=s(yP);aho=r(hXr,"MegatronBertForPreTraining"),hXr.forEach(t),nho=r(YMe," (MegatronBert model)"),YMe.forEach(t),sho=i(S),O_=n(S,"LI",{});var KMe=s(O_);gee=n(KMe,"STRONG",{});var pXr=s(gee);lho=r(pXr,"mobilebert"),pXr.forEach(t),iho=r(KMe," \u2014 "),wP=n(KMe,"A",{href:!0});var _Xr=s(wP);dho=r(_Xr,"MobileBertForPreTraining"),_Xr.forEach(t),cho=r(KMe," (MobileBERT model)"),KMe.forEach(t),fho=i(S),G_=n(S,"LI",{});var ZMe=s(G_);hee=n(ZMe,"STRONG",{});var uXr=s(hee);mho=r(uXr,"mpnet"),uXr.forEach(t),gho=r(ZMe," \u2014 "),AP=n(ZMe,"A",{href:!0});var bXr=s(AP);hho=r(bXr,"MPNetForMaskedLM"),bXr.forEach(t),pho=r(ZMe," (MPNet model)"),ZMe.forEach(t),_ho=i(S),X_=n(S,"LI",{});var e4e=s(X_);pee=n(e4e,"STRONG",{});var vXr=s(pee);uho=r(vXr,"openai-gpt"),vXr.forEach(t),bho=r(e4e," \u2014 "),LP=n(e4e,"A",{href:!0});var TXr=s(LP);vho=r(TXr,"OpenAIGPTLMHeadModel"),TXr.forEach(t),Tho=r(e4e," (OpenAI GPT model)"),e4e.forEach(t),Fho=i(S),V_=n(S,"LI",{});var o4e=s(V_);_ee=n(o4e,"STRONG",{});var FXr=s(_ee);Cho=r(FXr,"retribert"),FXr.forEach(t),Mho=r(o4e," \u2014 "),BP=n(o4e,"A",{href:!0});var CXr=s(BP);Eho=r(CXr,"RetriBertModel"),CXr.forEach(t),yho=r(o4e," (RetriBERT model)"),o4e.forEach(t),who=i(S),z_=n(S,"LI",{});var r4e=s(z_);uee=n(r4e,"STRONG",{});var MXr=s(uee);Aho=r(MXr,"roberta"),MXr.forEach(t),Lho=r(r4e," \u2014 "),xP=n(r4e,"A",{href:!0});var EXr=s(xP);Bho=r(EXr,"RobertaForMaskedLM"),EXr.forEach(t),xho=r(r4e," (RoBERTa model)"),r4e.forEach(t),kho=i(S),W_=n(S,"LI",{});var t4e=s(W_);bee=n(t4e,"STRONG",{});var yXr=s(bee);Rho=r(yXr,"squeezebert"),yXr.forEach(t),Sho=r(t4e," \u2014 "),kP=n(t4e,"A",{href:!0});var wXr=s(kP);Pho=r(wXr,"SqueezeBertForMaskedLM"),wXr.forEach(t),$ho=r(t4e," (SqueezeBERT model)"),t4e.forEach(t),Iho=i(S),Q_=n(S,"LI",{});var a4e=s(Q_);vee=n(a4e,"STRONG",{});var AXr=s(vee);jho=r(AXr,"t5"),AXr.forEach(t),Dho=r(a4e," \u2014 "),RP=n(a4e,"A",{href:!0});var LXr=s(RP);Nho=r(LXr,"T5ForConditionalGeneration"),LXr.forEach(t),qho=r(a4e," (T5 model)"),a4e.forEach(t),Oho=i(S),H_=n(S,"LI",{});var n4e=s(H_);Tee=n(n4e,"STRONG",{});var BXr=s(Tee);Gho=r(BXr,"tapas"),BXr.forEach(t),Xho=r(n4e," \u2014 "),SP=n(n4e,"A",{href:!0});var xXr=s(SP);Vho=r(xXr,"TapasForMaskedLM"),xXr.forEach(t),zho=r(n4e," (TAPAS model)"),n4e.forEach(t),Who=i(S),U_=n(S,"LI",{});var s4e=s(U_);Fee=n(s4e,"STRONG",{});var kXr=s(Fee);Qho=r(kXr,"transfo-xl"),kXr.forEach(t),Hho=r(s4e," \u2014 "),PP=n(s4e,"A",{href:!0});var RXr=s(PP);Uho=r(RXr,"TransfoXLLMHeadModel"),RXr.forEach(t),Jho=r(s4e," (Transformer-XL model)"),s4e.forEach(t),Yho=i(S),J_=n(S,"LI",{});var l4e=s(J_);Cee=n(l4e,"STRONG",{});var SXr=s(Cee);Kho=r(SXr,"unispeech"),SXr.forEach(t),Zho=r(l4e," \u2014 "),$P=n(l4e,"A",{href:!0});var PXr=s($P);epo=r(PXr,"UniSpeechForPreTraining"),PXr.forEach(t),opo=r(l4e," (UniSpeech model)"),l4e.forEach(t),rpo=i(S),Y_=n(S,"LI",{});var i4e=s(Y_);Mee=n(i4e,"STRONG",{});var $Xr=s(Mee);tpo=r($Xr,"unispeech-sat"),$Xr.forEach(t),apo=r(i4e," \u2014 "),IP=n(i4e,"A",{href:!0});var IXr=s(IP);npo=r(IXr,"UniSpeechSatForPreTraining"),IXr.forEach(t),spo=r(i4e," (UniSpeechSat model)"),i4e.forEach(t),lpo=i(S),K_=n(S,"LI",{});var d4e=s(K_);Eee=n(d4e,"STRONG",{});var jXr=s(Eee);ipo=r(jXr,"visual_bert"),jXr.forEach(t),dpo=r(d4e," \u2014 "),jP=n(d4e,"A",{href:!0});var DXr=s(jP);cpo=r(DXr,"VisualBertForPreTraining"),DXr.forEach(t),fpo=r(d4e," (VisualBert model)"),d4e.forEach(t),mpo=i(S),Z_=n(S,"LI",{});var c4e=s(Z_);yee=n(c4e,"STRONG",{});var NXr=s(yee);gpo=r(NXr,"vit_mae"),NXr.forEach(t),hpo=r(c4e," \u2014 "),DP=n(c4e,"A",{href:!0});var qXr=s(DP);ppo=r(qXr,"ViTMAEForPreTraining"),qXr.forEach(t),_po=r(c4e," (ViTMAE model)"),c4e.forEach(t),upo=i(S),eu=n(S,"LI",{});var f4e=s(eu);wee=n(f4e,"STRONG",{});var OXr=s(wee);bpo=r(OXr,"wav2vec2"),OXr.forEach(t),vpo=r(f4e," \u2014 "),NP=n(f4e,"A",{href:!0});var GXr=s(NP);Tpo=r(GXr,"Wav2Vec2ForPreTraining"),GXr.forEach(t),Fpo=r(f4e," (Wav2Vec2 model)"),f4e.forEach(t),Cpo=i(S),ou=n(S,"LI",{});var m4e=s(ou);Aee=n(m4e,"STRONG",{});var XXr=s(Aee);Mpo=r(XXr,"xlm"),XXr.forEach(t),Epo=r(m4e," \u2014 "),qP=n(m4e,"A",{href:!0});var VXr=s(qP);ypo=r(VXr,"XLMWithLMHeadModel"),VXr.forEach(t),wpo=r(m4e," (XLM model)"),m4e.forEach(t),Apo=i(S),ru=n(S,"LI",{});var g4e=s(ru);Lee=n(g4e,"STRONG",{});var zXr=s(Lee);Lpo=r(zXr,"xlm-roberta"),zXr.forEach(t),Bpo=r(g4e," \u2014 "),OP=n(g4e,"A",{href:!0});var WXr=s(OP);xpo=r(WXr,"XLMRobertaForMaskedLM"),WXr.forEach(t),kpo=r(g4e," (XLM-RoBERTa model)"),g4e.forEach(t),Rpo=i(S),tu=n(S,"LI",{});var h4e=s(tu);Bee=n(h4e,"STRONG",{});var QXr=s(Bee);Spo=r(QXr,"xlm-roberta-xl"),QXr.forEach(t),Ppo=r(h4e," \u2014 "),GP=n(h4e,"A",{href:!0});var HXr=s(GP);$po=r(HXr,"XLMRobertaXLForMaskedLM"),HXr.forEach(t),Ipo=r(h4e," (XLM-RoBERTa-XL model)"),h4e.forEach(t),jpo=i(S),au=n(S,"LI",{});var p4e=s(au);xee=n(p4e,"STRONG",{});var UXr=s(xee);Dpo=r(UXr,"xlnet"),UXr.forEach(t),Npo=r(p4e," \u2014 "),XP=n(p4e,"A",{href:!0});var JXr=s(XP);qpo=r(JXr,"XLNetLMHeadModel"),JXr.forEach(t),Opo=r(p4e," (XLNet model)"),p4e.forEach(t),S.forEach(t),Gpo=i(Ot),nu=n(Ot,"P",{});var _4e=s(nu);Xpo=r(_4e,"The model is set in evaluation mode by default using "),kee=n(_4e,"CODE",{});var YXr=s(kee);Vpo=r(YXr,"model.eval()"),YXr.forEach(t),zpo=r(_4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ree=n(_4e,"CODE",{});var KXr=s(Ree);Wpo=r(KXr,"model.train()"),KXr.forEach(t),_4e.forEach(t),Qpo=i(Ot),See=n(Ot,"P",{});var ZXr=s(See);Hpo=r(ZXr,"Examples:"),ZXr.forEach(t),Upo=i(Ot),m(GE.$$.fragment,Ot),Ot.forEach(t),Hs.forEach(t),kxe=i(c),rd=n(c,"H2",{class:!0});var qRe=s(rd);su=n(qRe,"A",{id:!0,class:!0,href:!0});var eVr=s(su);Pee=n(eVr,"SPAN",{});var oVr=s(Pee);m(XE.$$.fragment,oVr),oVr.forEach(t),eVr.forEach(t),Jpo=i(qRe),$ee=n(qRe,"SPAN",{});var rVr=s($ee);Ypo=r(rVr,"AutoModelForCausalLM"),rVr.forEach(t),qRe.forEach(t),Rxe=i(c),Ko=n(c,"DIV",{class:!0});var Js=s(Ko);m(VE.$$.fragment,Js),Kpo=i(Js),td=n(Js,"P",{});var Sz=s(td);Zpo=r(Sz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Iee=n(Sz,"CODE",{});var tVr=s(Iee);e_o=r(tVr,"from_pretrained()"),tVr.forEach(t),o_o=r(Sz,"class method or the "),jee=n(Sz,"CODE",{});var aVr=s(jee);r_o=r(aVr,"from_config()"),aVr.forEach(t),t_o=r(Sz,`class
method.`),Sz.forEach(t),a_o=i(Js),zE=n(Js,"P",{});var ORe=s(zE);n_o=r(ORe,"This class cannot be instantiated directly using "),Dee=n(ORe,"CODE",{});var nVr=s(Dee);s_o=r(nVr,"__init__()"),nVr.forEach(t),l_o=r(ORe," (throws an error)."),ORe.forEach(t),i_o=i(Js),Wr=n(Js,"DIV",{class:!0});var Ys=s(Wr);m(WE.$$.fragment,Ys),d_o=i(Ys),Nee=n(Ys,"P",{});var sVr=s(Nee);c_o=r(sVr,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),sVr.forEach(t),f_o=i(Ys),ad=n(Ys,"P",{});var Pz=s(ad);m_o=r(Pz,`Note:
Loading a model from its configuration file does `),qee=n(Pz,"STRONG",{});var lVr=s(qee);g_o=r(lVr,"not"),lVr.forEach(t),h_o=r(Pz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Oee=n(Pz,"CODE",{});var iVr=s(Oee);p_o=r(iVr,"from_pretrained()"),iVr.forEach(t),__o=r(Pz,"to load the model weights."),Pz.forEach(t),u_o=i(Ys),Gee=n(Ys,"P",{});var dVr=s(Gee);b_o=r(dVr,"Examples:"),dVr.forEach(t),v_o=i(Ys),m(QE.$$.fragment,Ys),Ys.forEach(t),T_o=i(Js),qe=n(Js,"DIV",{class:!0});var Gt=s(qe);m(HE.$$.fragment,Gt),F_o=i(Gt),Xee=n(Gt,"P",{});var cVr=s(Xee);C_o=r(cVr,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cVr.forEach(t),M_o=i(Gt),za=n(Gt,"P",{});var e4=s(za);E_o=r(e4,"The model class to instantiate is selected based on the "),Vee=n(e4,"CODE",{});var fVr=s(Vee);y_o=r(fVr,"model_type"),fVr.forEach(t),w_o=r(e4,` property of the config object (either
passed as an argument or loaded from `),zee=n(e4,"CODE",{});var mVr=s(zee);A_o=r(mVr,"pretrained_model_name_or_path"),mVr.forEach(t),L_o=r(e4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wee=n(e4,"CODE",{});var gVr=s(Wee);B_o=r(gVr,"pretrained_model_name_or_path"),gVr.forEach(t),x_o=r(e4,":"),e4.forEach(t),k_o=i(Gt),$=n(Gt,"UL",{});var j=s($);lu=n(j,"LI",{});var u4e=s(lu);Qee=n(u4e,"STRONG",{});var hVr=s(Qee);R_o=r(hVr,"bart"),hVr.forEach(t),S_o=r(u4e," \u2014 "),VP=n(u4e,"A",{href:!0});var pVr=s(VP);P_o=r(pVr,"BartForCausalLM"),pVr.forEach(t),$_o=r(u4e," (BART model)"),u4e.forEach(t),I_o=i(j),iu=n(j,"LI",{});var b4e=s(iu);Hee=n(b4e,"STRONG",{});var _Vr=s(Hee);j_o=r(_Vr,"bert"),_Vr.forEach(t),D_o=r(b4e," \u2014 "),zP=n(b4e,"A",{href:!0});var uVr=s(zP);N_o=r(uVr,"BertLMHeadModel"),uVr.forEach(t),q_o=r(b4e," (BERT model)"),b4e.forEach(t),O_o=i(j),du=n(j,"LI",{});var v4e=s(du);Uee=n(v4e,"STRONG",{});var bVr=s(Uee);G_o=r(bVr,"bert-generation"),bVr.forEach(t),X_o=r(v4e," \u2014 "),WP=n(v4e,"A",{href:!0});var vVr=s(WP);V_o=r(vVr,"BertGenerationDecoder"),vVr.forEach(t),z_o=r(v4e," (Bert Generation model)"),v4e.forEach(t),W_o=i(j),cu=n(j,"LI",{});var T4e=s(cu);Jee=n(T4e,"STRONG",{});var TVr=s(Jee);Q_o=r(TVr,"big_bird"),TVr.forEach(t),H_o=r(T4e," \u2014 "),QP=n(T4e,"A",{href:!0});var FVr=s(QP);U_o=r(FVr,"BigBirdForCausalLM"),FVr.forEach(t),J_o=r(T4e," (BigBird model)"),T4e.forEach(t),Y_o=i(j),fu=n(j,"LI",{});var F4e=s(fu);Yee=n(F4e,"STRONG",{});var CVr=s(Yee);K_o=r(CVr,"bigbird_pegasus"),CVr.forEach(t),Z_o=r(F4e," \u2014 "),HP=n(F4e,"A",{href:!0});var MVr=s(HP);euo=r(MVr,"BigBirdPegasusForCausalLM"),MVr.forEach(t),ouo=r(F4e," (BigBirdPegasus model)"),F4e.forEach(t),ruo=i(j),mu=n(j,"LI",{});var C4e=s(mu);Kee=n(C4e,"STRONG",{});var EVr=s(Kee);tuo=r(EVr,"blenderbot"),EVr.forEach(t),auo=r(C4e," \u2014 "),UP=n(C4e,"A",{href:!0});var yVr=s(UP);nuo=r(yVr,"BlenderbotForCausalLM"),yVr.forEach(t),suo=r(C4e," (Blenderbot model)"),C4e.forEach(t),luo=i(j),gu=n(j,"LI",{});var M4e=s(gu);Zee=n(M4e,"STRONG",{});var wVr=s(Zee);iuo=r(wVr,"blenderbot-small"),wVr.forEach(t),duo=r(M4e," \u2014 "),JP=n(M4e,"A",{href:!0});var AVr=s(JP);cuo=r(AVr,"BlenderbotSmallForCausalLM"),AVr.forEach(t),fuo=r(M4e," (BlenderbotSmall model)"),M4e.forEach(t),muo=i(j),hu=n(j,"LI",{});var E4e=s(hu);eoe=n(E4e,"STRONG",{});var LVr=s(eoe);guo=r(LVr,"camembert"),LVr.forEach(t),huo=r(E4e," \u2014 "),YP=n(E4e,"A",{href:!0});var BVr=s(YP);puo=r(BVr,"CamembertForCausalLM"),BVr.forEach(t),_uo=r(E4e," (CamemBERT model)"),E4e.forEach(t),uuo=i(j),pu=n(j,"LI",{});var y4e=s(pu);ooe=n(y4e,"STRONG",{});var xVr=s(ooe);buo=r(xVr,"ctrl"),xVr.forEach(t),vuo=r(y4e," \u2014 "),KP=n(y4e,"A",{href:!0});var kVr=s(KP);Tuo=r(kVr,"CTRLLMHeadModel"),kVr.forEach(t),Fuo=r(y4e," (CTRL model)"),y4e.forEach(t),Cuo=i(j),_u=n(j,"LI",{});var w4e=s(_u);roe=n(w4e,"STRONG",{});var RVr=s(roe);Muo=r(RVr,"data2vec-text"),RVr.forEach(t),Euo=r(w4e," \u2014 "),ZP=n(w4e,"A",{href:!0});var SVr=s(ZP);yuo=r(SVr,"Data2VecTextForCausalLM"),SVr.forEach(t),wuo=r(w4e," (Data2VecText model)"),w4e.forEach(t),Auo=i(j),uu=n(j,"LI",{});var A4e=s(uu);toe=n(A4e,"STRONG",{});var PVr=s(toe);Luo=r(PVr,"electra"),PVr.forEach(t),Buo=r(A4e," \u2014 "),e$=n(A4e,"A",{href:!0});var $Vr=s(e$);xuo=r($Vr,"ElectraForCausalLM"),$Vr.forEach(t),kuo=r(A4e," (ELECTRA model)"),A4e.forEach(t),Ruo=i(j),bu=n(j,"LI",{});var L4e=s(bu);aoe=n(L4e,"STRONG",{});var IVr=s(aoe);Suo=r(IVr,"gpt2"),IVr.forEach(t),Puo=r(L4e," \u2014 "),o$=n(L4e,"A",{href:!0});var jVr=s(o$);$uo=r(jVr,"GPT2LMHeadModel"),jVr.forEach(t),Iuo=r(L4e," (OpenAI GPT-2 model)"),L4e.forEach(t),juo=i(j),vu=n(j,"LI",{});var B4e=s(vu);noe=n(B4e,"STRONG",{});var DVr=s(noe);Duo=r(DVr,"gpt_neo"),DVr.forEach(t),Nuo=r(B4e," \u2014 "),r$=n(B4e,"A",{href:!0});var NVr=s(r$);quo=r(NVr,"GPTNeoForCausalLM"),NVr.forEach(t),Ouo=r(B4e," (GPT Neo model)"),B4e.forEach(t),Guo=i(j),Tu=n(j,"LI",{});var x4e=s(Tu);soe=n(x4e,"STRONG",{});var qVr=s(soe);Xuo=r(qVr,"gptj"),qVr.forEach(t),Vuo=r(x4e," \u2014 "),t$=n(x4e,"A",{href:!0});var OVr=s(t$);zuo=r(OVr,"GPTJForCausalLM"),OVr.forEach(t),Wuo=r(x4e," (GPT-J model)"),x4e.forEach(t),Quo=i(j),Fu=n(j,"LI",{});var k4e=s(Fu);loe=n(k4e,"STRONG",{});var GVr=s(loe);Huo=r(GVr,"marian"),GVr.forEach(t),Uuo=r(k4e," \u2014 "),a$=n(k4e,"A",{href:!0});var XVr=s(a$);Juo=r(XVr,"MarianForCausalLM"),XVr.forEach(t),Yuo=r(k4e," (Marian model)"),k4e.forEach(t),Kuo=i(j),Cu=n(j,"LI",{});var R4e=s(Cu);ioe=n(R4e,"STRONG",{});var VVr=s(ioe);Zuo=r(VVr,"mbart"),VVr.forEach(t),e1o=r(R4e," \u2014 "),n$=n(R4e,"A",{href:!0});var zVr=s(n$);o1o=r(zVr,"MBartForCausalLM"),zVr.forEach(t),r1o=r(R4e," (mBART model)"),R4e.forEach(t),t1o=i(j),Mu=n(j,"LI",{});var S4e=s(Mu);doe=n(S4e,"STRONG",{});var WVr=s(doe);a1o=r(WVr,"megatron-bert"),WVr.forEach(t),n1o=r(S4e," \u2014 "),s$=n(S4e,"A",{href:!0});var QVr=s(s$);s1o=r(QVr,"MegatronBertForCausalLM"),QVr.forEach(t),l1o=r(S4e," (MegatronBert model)"),S4e.forEach(t),i1o=i(j),Eu=n(j,"LI",{});var P4e=s(Eu);coe=n(P4e,"STRONG",{});var HVr=s(coe);d1o=r(HVr,"openai-gpt"),HVr.forEach(t),c1o=r(P4e," \u2014 "),l$=n(P4e,"A",{href:!0});var UVr=s(l$);f1o=r(UVr,"OpenAIGPTLMHeadModel"),UVr.forEach(t),m1o=r(P4e," (OpenAI GPT model)"),P4e.forEach(t),g1o=i(j),yu=n(j,"LI",{});var $4e=s(yu);foe=n($4e,"STRONG",{});var JVr=s(foe);h1o=r(JVr,"pegasus"),JVr.forEach(t),p1o=r($4e," \u2014 "),i$=n($4e,"A",{href:!0});var YVr=s(i$);_1o=r(YVr,"PegasusForCausalLM"),YVr.forEach(t),u1o=r($4e," (Pegasus model)"),$4e.forEach(t),b1o=i(j),wu=n(j,"LI",{});var I4e=s(wu);moe=n(I4e,"STRONG",{});var KVr=s(moe);v1o=r(KVr,"plbart"),KVr.forEach(t),T1o=r(I4e," \u2014 "),d$=n(I4e,"A",{href:!0});var ZVr=s(d$);F1o=r(ZVr,"PLBartForCausalLM"),ZVr.forEach(t),C1o=r(I4e," (PLBart model)"),I4e.forEach(t),M1o=i(j),Au=n(j,"LI",{});var j4e=s(Au);goe=n(j4e,"STRONG",{});var ezr=s(goe);E1o=r(ezr,"prophetnet"),ezr.forEach(t),y1o=r(j4e," \u2014 "),c$=n(j4e,"A",{href:!0});var ozr=s(c$);w1o=r(ozr,"ProphetNetForCausalLM"),ozr.forEach(t),A1o=r(j4e," (ProphetNet model)"),j4e.forEach(t),L1o=i(j),Lu=n(j,"LI",{});var D4e=s(Lu);hoe=n(D4e,"STRONG",{});var rzr=s(hoe);B1o=r(rzr,"qdqbert"),rzr.forEach(t),x1o=r(D4e," \u2014 "),f$=n(D4e,"A",{href:!0});var tzr=s(f$);k1o=r(tzr,"QDQBertLMHeadModel"),tzr.forEach(t),R1o=r(D4e," (QDQBert model)"),D4e.forEach(t),S1o=i(j),Bu=n(j,"LI",{});var N4e=s(Bu);poe=n(N4e,"STRONG",{});var azr=s(poe);P1o=r(azr,"reformer"),azr.forEach(t),$1o=r(N4e," \u2014 "),m$=n(N4e,"A",{href:!0});var nzr=s(m$);I1o=r(nzr,"ReformerModelWithLMHead"),nzr.forEach(t),j1o=r(N4e," (Reformer model)"),N4e.forEach(t),D1o=i(j),xu=n(j,"LI",{});var q4e=s(xu);_oe=n(q4e,"STRONG",{});var szr=s(_oe);N1o=r(szr,"rembert"),szr.forEach(t),q1o=r(q4e," \u2014 "),g$=n(q4e,"A",{href:!0});var lzr=s(g$);O1o=r(lzr,"RemBertForCausalLM"),lzr.forEach(t),G1o=r(q4e," (RemBERT model)"),q4e.forEach(t),X1o=i(j),ku=n(j,"LI",{});var O4e=s(ku);uoe=n(O4e,"STRONG",{});var izr=s(uoe);V1o=r(izr,"roberta"),izr.forEach(t),z1o=r(O4e," \u2014 "),h$=n(O4e,"A",{href:!0});var dzr=s(h$);W1o=r(dzr,"RobertaForCausalLM"),dzr.forEach(t),Q1o=r(O4e," (RoBERTa model)"),O4e.forEach(t),H1o=i(j),Ru=n(j,"LI",{});var G4e=s(Ru);boe=n(G4e,"STRONG",{});var czr=s(boe);U1o=r(czr,"roformer"),czr.forEach(t),J1o=r(G4e," \u2014 "),p$=n(G4e,"A",{href:!0});var fzr=s(p$);Y1o=r(fzr,"RoFormerForCausalLM"),fzr.forEach(t),K1o=r(G4e," (RoFormer model)"),G4e.forEach(t),Z1o=i(j),Su=n(j,"LI",{});var X4e=s(Su);voe=n(X4e,"STRONG",{});var mzr=s(voe);e7o=r(mzr,"speech_to_text_2"),mzr.forEach(t),o7o=r(X4e," \u2014 "),_$=n(X4e,"A",{href:!0});var gzr=s(_$);r7o=r(gzr,"Speech2Text2ForCausalLM"),gzr.forEach(t),t7o=r(X4e," (Speech2Text2 model)"),X4e.forEach(t),a7o=i(j),Pu=n(j,"LI",{});var V4e=s(Pu);Toe=n(V4e,"STRONG",{});var hzr=s(Toe);n7o=r(hzr,"transfo-xl"),hzr.forEach(t),s7o=r(V4e," \u2014 "),u$=n(V4e,"A",{href:!0});var pzr=s(u$);l7o=r(pzr,"TransfoXLLMHeadModel"),pzr.forEach(t),i7o=r(V4e," (Transformer-XL model)"),V4e.forEach(t),d7o=i(j),$u=n(j,"LI",{});var z4e=s($u);Foe=n(z4e,"STRONG",{});var _zr=s(Foe);c7o=r(_zr,"trocr"),_zr.forEach(t),f7o=r(z4e," \u2014 "),b$=n(z4e,"A",{href:!0});var uzr=s(b$);m7o=r(uzr,"TrOCRForCausalLM"),uzr.forEach(t),g7o=r(z4e," (TrOCR model)"),z4e.forEach(t),h7o=i(j),Iu=n(j,"LI",{});var W4e=s(Iu);Coe=n(W4e,"STRONG",{});var bzr=s(Coe);p7o=r(bzr,"xglm"),bzr.forEach(t),_7o=r(W4e," \u2014 "),v$=n(W4e,"A",{href:!0});var vzr=s(v$);u7o=r(vzr,"XGLMForCausalLM"),vzr.forEach(t),b7o=r(W4e," (XGLM model)"),W4e.forEach(t),v7o=i(j),ju=n(j,"LI",{});var Q4e=s(ju);Moe=n(Q4e,"STRONG",{});var Tzr=s(Moe);T7o=r(Tzr,"xlm"),Tzr.forEach(t),F7o=r(Q4e," \u2014 "),T$=n(Q4e,"A",{href:!0});var Fzr=s(T$);C7o=r(Fzr,"XLMWithLMHeadModel"),Fzr.forEach(t),M7o=r(Q4e," (XLM model)"),Q4e.forEach(t),E7o=i(j),Du=n(j,"LI",{});var H4e=s(Du);Eoe=n(H4e,"STRONG",{});var Czr=s(Eoe);y7o=r(Czr,"xlm-prophetnet"),Czr.forEach(t),w7o=r(H4e," \u2014 "),F$=n(H4e,"A",{href:!0});var Mzr=s(F$);A7o=r(Mzr,"XLMProphetNetForCausalLM"),Mzr.forEach(t),L7o=r(H4e," (XLMProphetNet model)"),H4e.forEach(t),B7o=i(j),Nu=n(j,"LI",{});var U4e=s(Nu);yoe=n(U4e,"STRONG",{});var Ezr=s(yoe);x7o=r(Ezr,"xlm-roberta"),Ezr.forEach(t),k7o=r(U4e," \u2014 "),C$=n(U4e,"A",{href:!0});var yzr=s(C$);R7o=r(yzr,"XLMRobertaForCausalLM"),yzr.forEach(t),S7o=r(U4e," (XLM-RoBERTa model)"),U4e.forEach(t),P7o=i(j),qu=n(j,"LI",{});var J4e=s(qu);woe=n(J4e,"STRONG",{});var wzr=s(woe);$7o=r(wzr,"xlm-roberta-xl"),wzr.forEach(t),I7o=r(J4e," \u2014 "),M$=n(J4e,"A",{href:!0});var Azr=s(M$);j7o=r(Azr,"XLMRobertaXLForCausalLM"),Azr.forEach(t),D7o=r(J4e," (XLM-RoBERTa-XL model)"),J4e.forEach(t),N7o=i(j),Ou=n(j,"LI",{});var Y4e=s(Ou);Aoe=n(Y4e,"STRONG",{});var Lzr=s(Aoe);q7o=r(Lzr,"xlnet"),Lzr.forEach(t),O7o=r(Y4e," \u2014 "),E$=n(Y4e,"A",{href:!0});var Bzr=s(E$);G7o=r(Bzr,"XLNetLMHeadModel"),Bzr.forEach(t),X7o=r(Y4e," (XLNet model)"),Y4e.forEach(t),j.forEach(t),V7o=i(Gt),Gu=n(Gt,"P",{});var K4e=s(Gu);z7o=r(K4e,"The model is set in evaluation mode by default using "),Loe=n(K4e,"CODE",{});var xzr=s(Loe);W7o=r(xzr,"model.eval()"),xzr.forEach(t),Q7o=r(K4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Boe=n(K4e,"CODE",{});var kzr=s(Boe);H7o=r(kzr,"model.train()"),kzr.forEach(t),K4e.forEach(t),U7o=i(Gt),xoe=n(Gt,"P",{});var Rzr=s(xoe);J7o=r(Rzr,"Examples:"),Rzr.forEach(t),Y7o=i(Gt),m(UE.$$.fragment,Gt),Gt.forEach(t),Js.forEach(t),Sxe=i(c),nd=n(c,"H2",{class:!0});var GRe=s(nd);Xu=n(GRe,"A",{id:!0,class:!0,href:!0});var Szr=s(Xu);koe=n(Szr,"SPAN",{});var Pzr=s(koe);m(JE.$$.fragment,Pzr),Pzr.forEach(t),Szr.forEach(t),K7o=i(GRe),Roe=n(GRe,"SPAN",{});var $zr=s(Roe);Z7o=r($zr,"AutoModelForMaskedLM"),$zr.forEach(t),GRe.forEach(t),Pxe=i(c),Zo=n(c,"DIV",{class:!0});var Ks=s(Zo);m(YE.$$.fragment,Ks),ebo=i(Ks),sd=n(Ks,"P",{});var $z=s(sd);obo=r($z,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Soe=n($z,"CODE",{});var Izr=s(Soe);rbo=r(Izr,"from_pretrained()"),Izr.forEach(t),tbo=r($z,"class method or the "),Poe=n($z,"CODE",{});var jzr=s(Poe);abo=r(jzr,"from_config()"),jzr.forEach(t),nbo=r($z,`class
method.`),$z.forEach(t),sbo=i(Ks),KE=n(Ks,"P",{});var XRe=s(KE);lbo=r(XRe,"This class cannot be instantiated directly using "),$oe=n(XRe,"CODE",{});var Dzr=s($oe);ibo=r(Dzr,"__init__()"),Dzr.forEach(t),dbo=r(XRe," (throws an error)."),XRe.forEach(t),cbo=i(Ks),Qr=n(Ks,"DIV",{class:!0});var Zs=s(Qr);m(ZE.$$.fragment,Zs),fbo=i(Zs),Ioe=n(Zs,"P",{});var Nzr=s(Ioe);mbo=r(Nzr,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Nzr.forEach(t),gbo=i(Zs),ld=n(Zs,"P",{});var Iz=s(ld);hbo=r(Iz,`Note:
Loading a model from its configuration file does `),joe=n(Iz,"STRONG",{});var qzr=s(joe);pbo=r(qzr,"not"),qzr.forEach(t),_bo=r(Iz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=n(Iz,"CODE",{});var Ozr=s(Doe);ubo=r(Ozr,"from_pretrained()"),Ozr.forEach(t),bbo=r(Iz,"to load the model weights."),Iz.forEach(t),vbo=i(Zs),Noe=n(Zs,"P",{});var Gzr=s(Noe);Tbo=r(Gzr,"Examples:"),Gzr.forEach(t),Fbo=i(Zs),m(e3.$$.fragment,Zs),Zs.forEach(t),Cbo=i(Ks),Oe=n(Ks,"DIV",{class:!0});var Xt=s(Oe);m(o3.$$.fragment,Xt),Mbo=i(Xt),qoe=n(Xt,"P",{});var Xzr=s(qoe);Ebo=r(Xzr,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xzr.forEach(t),ybo=i(Xt),Wa=n(Xt,"P",{});var o4=s(Wa);wbo=r(o4,"The model class to instantiate is selected based on the "),Ooe=n(o4,"CODE",{});var Vzr=s(Ooe);Abo=r(Vzr,"model_type"),Vzr.forEach(t),Lbo=r(o4,` property of the config object (either
passed as an argument or loaded from `),Goe=n(o4,"CODE",{});var zzr=s(Goe);Bbo=r(zzr,"pretrained_model_name_or_path"),zzr.forEach(t),xbo=r(o4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xoe=n(o4,"CODE",{});var Wzr=s(Xoe);kbo=r(Wzr,"pretrained_model_name_or_path"),Wzr.forEach(t),Rbo=r(o4,":"),o4.forEach(t),Sbo=i(Xt),I=n(Xt,"UL",{});var D=s(I);Vu=n(D,"LI",{});var Z4e=s(Vu);Voe=n(Z4e,"STRONG",{});var Qzr=s(Voe);Pbo=r(Qzr,"albert"),Qzr.forEach(t),$bo=r(Z4e," \u2014 "),y$=n(Z4e,"A",{href:!0});var Hzr=s(y$);Ibo=r(Hzr,"AlbertForMaskedLM"),Hzr.forEach(t),jbo=r(Z4e," (ALBERT model)"),Z4e.forEach(t),Dbo=i(D),zu=n(D,"LI",{});var eEe=s(zu);zoe=n(eEe,"STRONG",{});var Uzr=s(zoe);Nbo=r(Uzr,"bart"),Uzr.forEach(t),qbo=r(eEe," \u2014 "),w$=n(eEe,"A",{href:!0});var Jzr=s(w$);Obo=r(Jzr,"BartForConditionalGeneration"),Jzr.forEach(t),Gbo=r(eEe," (BART model)"),eEe.forEach(t),Xbo=i(D),Wu=n(D,"LI",{});var oEe=s(Wu);Woe=n(oEe,"STRONG",{});var Yzr=s(Woe);Vbo=r(Yzr,"bert"),Yzr.forEach(t),zbo=r(oEe," \u2014 "),A$=n(oEe,"A",{href:!0});var Kzr=s(A$);Wbo=r(Kzr,"BertForMaskedLM"),Kzr.forEach(t),Qbo=r(oEe," (BERT model)"),oEe.forEach(t),Hbo=i(D),Qu=n(D,"LI",{});var rEe=s(Qu);Qoe=n(rEe,"STRONG",{});var Zzr=s(Qoe);Ubo=r(Zzr,"big_bird"),Zzr.forEach(t),Jbo=r(rEe," \u2014 "),L$=n(rEe,"A",{href:!0});var eWr=s(L$);Ybo=r(eWr,"BigBirdForMaskedLM"),eWr.forEach(t),Kbo=r(rEe," (BigBird model)"),rEe.forEach(t),Zbo=i(D),Hu=n(D,"LI",{});var tEe=s(Hu);Hoe=n(tEe,"STRONG",{});var oWr=s(Hoe);e5o=r(oWr,"camembert"),oWr.forEach(t),o5o=r(tEe," \u2014 "),B$=n(tEe,"A",{href:!0});var rWr=s(B$);r5o=r(rWr,"CamembertForMaskedLM"),rWr.forEach(t),t5o=r(tEe," (CamemBERT model)"),tEe.forEach(t),a5o=i(D),Uu=n(D,"LI",{});var aEe=s(Uu);Uoe=n(aEe,"STRONG",{});var tWr=s(Uoe);n5o=r(tWr,"convbert"),tWr.forEach(t),s5o=r(aEe," \u2014 "),x$=n(aEe,"A",{href:!0});var aWr=s(x$);l5o=r(aWr,"ConvBertForMaskedLM"),aWr.forEach(t),i5o=r(aEe," (ConvBERT model)"),aEe.forEach(t),d5o=i(D),Ju=n(D,"LI",{});var nEe=s(Ju);Joe=n(nEe,"STRONG",{});var nWr=s(Joe);c5o=r(nWr,"data2vec-text"),nWr.forEach(t),f5o=r(nEe," \u2014 "),k$=n(nEe,"A",{href:!0});var sWr=s(k$);m5o=r(sWr,"Data2VecTextForMaskedLM"),sWr.forEach(t),g5o=r(nEe," (Data2VecText model)"),nEe.forEach(t),h5o=i(D),Yu=n(D,"LI",{});var sEe=s(Yu);Yoe=n(sEe,"STRONG",{});var lWr=s(Yoe);p5o=r(lWr,"deberta"),lWr.forEach(t),_5o=r(sEe," \u2014 "),R$=n(sEe,"A",{href:!0});var iWr=s(R$);u5o=r(iWr,"DebertaForMaskedLM"),iWr.forEach(t),b5o=r(sEe," (DeBERTa model)"),sEe.forEach(t),v5o=i(D),Ku=n(D,"LI",{});var lEe=s(Ku);Koe=n(lEe,"STRONG",{});var dWr=s(Koe);T5o=r(dWr,"deberta-v2"),dWr.forEach(t),F5o=r(lEe," \u2014 "),S$=n(lEe,"A",{href:!0});var cWr=s(S$);C5o=r(cWr,"DebertaV2ForMaskedLM"),cWr.forEach(t),M5o=r(lEe," (DeBERTa-v2 model)"),lEe.forEach(t),E5o=i(D),Zu=n(D,"LI",{});var iEe=s(Zu);Zoe=n(iEe,"STRONG",{});var fWr=s(Zoe);y5o=r(fWr,"distilbert"),fWr.forEach(t),w5o=r(iEe," \u2014 "),P$=n(iEe,"A",{href:!0});var mWr=s(P$);A5o=r(mWr,"DistilBertForMaskedLM"),mWr.forEach(t),L5o=r(iEe," (DistilBERT model)"),iEe.forEach(t),B5o=i(D),e1=n(D,"LI",{});var dEe=s(e1);ere=n(dEe,"STRONG",{});var gWr=s(ere);x5o=r(gWr,"electra"),gWr.forEach(t),k5o=r(dEe," \u2014 "),$$=n(dEe,"A",{href:!0});var hWr=s($$);R5o=r(hWr,"ElectraForMaskedLM"),hWr.forEach(t),S5o=r(dEe," (ELECTRA model)"),dEe.forEach(t),P5o=i(D),o1=n(D,"LI",{});var cEe=s(o1);ore=n(cEe,"STRONG",{});var pWr=s(ore);$5o=r(pWr,"flaubert"),pWr.forEach(t),I5o=r(cEe," \u2014 "),I$=n(cEe,"A",{href:!0});var _Wr=s(I$);j5o=r(_Wr,"FlaubertWithLMHeadModel"),_Wr.forEach(t),D5o=r(cEe," (FlauBERT model)"),cEe.forEach(t),N5o=i(D),r1=n(D,"LI",{});var fEe=s(r1);rre=n(fEe,"STRONG",{});var uWr=s(rre);q5o=r(uWr,"fnet"),uWr.forEach(t),O5o=r(fEe," \u2014 "),j$=n(fEe,"A",{href:!0});var bWr=s(j$);G5o=r(bWr,"FNetForMaskedLM"),bWr.forEach(t),X5o=r(fEe," (FNet model)"),fEe.forEach(t),V5o=i(D),t1=n(D,"LI",{});var mEe=s(t1);tre=n(mEe,"STRONG",{});var vWr=s(tre);z5o=r(vWr,"funnel"),vWr.forEach(t),W5o=r(mEe," \u2014 "),D$=n(mEe,"A",{href:!0});var TWr=s(D$);Q5o=r(TWr,"FunnelForMaskedLM"),TWr.forEach(t),H5o=r(mEe," (Funnel Transformer model)"),mEe.forEach(t),U5o=i(D),a1=n(D,"LI",{});var gEe=s(a1);are=n(gEe,"STRONG",{});var FWr=s(are);J5o=r(FWr,"ibert"),FWr.forEach(t),Y5o=r(gEe," \u2014 "),N$=n(gEe,"A",{href:!0});var CWr=s(N$);K5o=r(CWr,"IBertForMaskedLM"),CWr.forEach(t),Z5o=r(gEe," (I-BERT model)"),gEe.forEach(t),e2o=i(D),n1=n(D,"LI",{});var hEe=s(n1);nre=n(hEe,"STRONG",{});var MWr=s(nre);o2o=r(MWr,"layoutlm"),MWr.forEach(t),r2o=r(hEe," \u2014 "),q$=n(hEe,"A",{href:!0});var EWr=s(q$);t2o=r(EWr,"LayoutLMForMaskedLM"),EWr.forEach(t),a2o=r(hEe," (LayoutLM model)"),hEe.forEach(t),n2o=i(D),s1=n(D,"LI",{});var pEe=s(s1);sre=n(pEe,"STRONG",{});var yWr=s(sre);s2o=r(yWr,"longformer"),yWr.forEach(t),l2o=r(pEe," \u2014 "),O$=n(pEe,"A",{href:!0});var wWr=s(O$);i2o=r(wWr,"LongformerForMaskedLM"),wWr.forEach(t),d2o=r(pEe," (Longformer model)"),pEe.forEach(t),c2o=i(D),l1=n(D,"LI",{});var _Ee=s(l1);lre=n(_Ee,"STRONG",{});var AWr=s(lre);f2o=r(AWr,"mbart"),AWr.forEach(t),m2o=r(_Ee," \u2014 "),G$=n(_Ee,"A",{href:!0});var LWr=s(G$);g2o=r(LWr,"MBartForConditionalGeneration"),LWr.forEach(t),h2o=r(_Ee," (mBART model)"),_Ee.forEach(t),p2o=i(D),i1=n(D,"LI",{});var uEe=s(i1);ire=n(uEe,"STRONG",{});var BWr=s(ire);_2o=r(BWr,"megatron-bert"),BWr.forEach(t),u2o=r(uEe," \u2014 "),X$=n(uEe,"A",{href:!0});var xWr=s(X$);b2o=r(xWr,"MegatronBertForMaskedLM"),xWr.forEach(t),v2o=r(uEe," (MegatronBert model)"),uEe.forEach(t),T2o=i(D),d1=n(D,"LI",{});var bEe=s(d1);dre=n(bEe,"STRONG",{});var kWr=s(dre);F2o=r(kWr,"mobilebert"),kWr.forEach(t),C2o=r(bEe," \u2014 "),V$=n(bEe,"A",{href:!0});var RWr=s(V$);M2o=r(RWr,"MobileBertForMaskedLM"),RWr.forEach(t),E2o=r(bEe," (MobileBERT model)"),bEe.forEach(t),y2o=i(D),c1=n(D,"LI",{});var vEe=s(c1);cre=n(vEe,"STRONG",{});var SWr=s(cre);w2o=r(SWr,"mpnet"),SWr.forEach(t),A2o=r(vEe," \u2014 "),z$=n(vEe,"A",{href:!0});var PWr=s(z$);L2o=r(PWr,"MPNetForMaskedLM"),PWr.forEach(t),B2o=r(vEe," (MPNet model)"),vEe.forEach(t),x2o=i(D),f1=n(D,"LI",{});var TEe=s(f1);fre=n(TEe,"STRONG",{});var $Wr=s(fre);k2o=r($Wr,"nystromformer"),$Wr.forEach(t),R2o=r(TEe," \u2014 "),W$=n(TEe,"A",{href:!0});var IWr=s(W$);S2o=r(IWr,"NystromformerForMaskedLM"),IWr.forEach(t),P2o=r(TEe," (Nystromformer model)"),TEe.forEach(t),$2o=i(D),m1=n(D,"LI",{});var FEe=s(m1);mre=n(FEe,"STRONG",{});var jWr=s(mre);I2o=r(jWr,"perceiver"),jWr.forEach(t),j2o=r(FEe," \u2014 "),Q$=n(FEe,"A",{href:!0});var DWr=s(Q$);D2o=r(DWr,"PerceiverForMaskedLM"),DWr.forEach(t),N2o=r(FEe," (Perceiver model)"),FEe.forEach(t),q2o=i(D),g1=n(D,"LI",{});var CEe=s(g1);gre=n(CEe,"STRONG",{});var NWr=s(gre);O2o=r(NWr,"qdqbert"),NWr.forEach(t),G2o=r(CEe," \u2014 "),H$=n(CEe,"A",{href:!0});var qWr=s(H$);X2o=r(qWr,"QDQBertForMaskedLM"),qWr.forEach(t),V2o=r(CEe," (QDQBert model)"),CEe.forEach(t),z2o=i(D),h1=n(D,"LI",{});var MEe=s(h1);hre=n(MEe,"STRONG",{});var OWr=s(hre);W2o=r(OWr,"reformer"),OWr.forEach(t),Q2o=r(MEe," \u2014 "),U$=n(MEe,"A",{href:!0});var GWr=s(U$);H2o=r(GWr,"ReformerForMaskedLM"),GWr.forEach(t),U2o=r(MEe," (Reformer model)"),MEe.forEach(t),J2o=i(D),p1=n(D,"LI",{});var EEe=s(p1);pre=n(EEe,"STRONG",{});var XWr=s(pre);Y2o=r(XWr,"rembert"),XWr.forEach(t),K2o=r(EEe," \u2014 "),J$=n(EEe,"A",{href:!0});var VWr=s(J$);Z2o=r(VWr,"RemBertForMaskedLM"),VWr.forEach(t),evo=r(EEe," (RemBERT model)"),EEe.forEach(t),ovo=i(D),_1=n(D,"LI",{});var yEe=s(_1);_re=n(yEe,"STRONG",{});var zWr=s(_re);rvo=r(zWr,"roberta"),zWr.forEach(t),tvo=r(yEe," \u2014 "),Y$=n(yEe,"A",{href:!0});var WWr=s(Y$);avo=r(WWr,"RobertaForMaskedLM"),WWr.forEach(t),nvo=r(yEe," (RoBERTa model)"),yEe.forEach(t),svo=i(D),u1=n(D,"LI",{});var wEe=s(u1);ure=n(wEe,"STRONG",{});var QWr=s(ure);lvo=r(QWr,"roformer"),QWr.forEach(t),ivo=r(wEe," \u2014 "),K$=n(wEe,"A",{href:!0});var HWr=s(K$);dvo=r(HWr,"RoFormerForMaskedLM"),HWr.forEach(t),cvo=r(wEe," (RoFormer model)"),wEe.forEach(t),fvo=i(D),b1=n(D,"LI",{});var AEe=s(b1);bre=n(AEe,"STRONG",{});var UWr=s(bre);mvo=r(UWr,"squeezebert"),UWr.forEach(t),gvo=r(AEe," \u2014 "),Z$=n(AEe,"A",{href:!0});var JWr=s(Z$);hvo=r(JWr,"SqueezeBertForMaskedLM"),JWr.forEach(t),pvo=r(AEe," (SqueezeBERT model)"),AEe.forEach(t),_vo=i(D),v1=n(D,"LI",{});var LEe=s(v1);vre=n(LEe,"STRONG",{});var YWr=s(vre);uvo=r(YWr,"tapas"),YWr.forEach(t),bvo=r(LEe," \u2014 "),eI=n(LEe,"A",{href:!0});var KWr=s(eI);vvo=r(KWr,"TapasForMaskedLM"),KWr.forEach(t),Tvo=r(LEe," (TAPAS model)"),LEe.forEach(t),Fvo=i(D),T1=n(D,"LI",{});var BEe=s(T1);Tre=n(BEe,"STRONG",{});var ZWr=s(Tre);Cvo=r(ZWr,"wav2vec2"),ZWr.forEach(t),Mvo=r(BEe," \u2014 "),Fre=n(BEe,"CODE",{});var eQr=s(Fre);Evo=r(eQr,"Wav2Vec2ForMaskedLM"),eQr.forEach(t),yvo=r(BEe,"(Wav2Vec2 model)"),BEe.forEach(t),wvo=i(D),F1=n(D,"LI",{});var xEe=s(F1);Cre=n(xEe,"STRONG",{});var oQr=s(Cre);Avo=r(oQr,"xlm"),oQr.forEach(t),Lvo=r(xEe," \u2014 "),oI=n(xEe,"A",{href:!0});var rQr=s(oI);Bvo=r(rQr,"XLMWithLMHeadModel"),rQr.forEach(t),xvo=r(xEe," (XLM model)"),xEe.forEach(t),kvo=i(D),C1=n(D,"LI",{});var kEe=s(C1);Mre=n(kEe,"STRONG",{});var tQr=s(Mre);Rvo=r(tQr,"xlm-roberta"),tQr.forEach(t),Svo=r(kEe," \u2014 "),rI=n(kEe,"A",{href:!0});var aQr=s(rI);Pvo=r(aQr,"XLMRobertaForMaskedLM"),aQr.forEach(t),$vo=r(kEe," (XLM-RoBERTa model)"),kEe.forEach(t),Ivo=i(D),M1=n(D,"LI",{});var REe=s(M1);Ere=n(REe,"STRONG",{});var nQr=s(Ere);jvo=r(nQr,"xlm-roberta-xl"),nQr.forEach(t),Dvo=r(REe," \u2014 "),tI=n(REe,"A",{href:!0});var sQr=s(tI);Nvo=r(sQr,"XLMRobertaXLForMaskedLM"),sQr.forEach(t),qvo=r(REe," (XLM-RoBERTa-XL model)"),REe.forEach(t),Ovo=i(D),E1=n(D,"LI",{});var SEe=s(E1);yre=n(SEe,"STRONG",{});var lQr=s(yre);Gvo=r(lQr,"yoso"),lQr.forEach(t),Xvo=r(SEe," \u2014 "),aI=n(SEe,"A",{href:!0});var iQr=s(aI);Vvo=r(iQr,"YosoForMaskedLM"),iQr.forEach(t),zvo=r(SEe," (YOSO model)"),SEe.forEach(t),D.forEach(t),Wvo=i(Xt),y1=n(Xt,"P",{});var PEe=s(y1);Qvo=r(PEe,"The model is set in evaluation mode by default using "),wre=n(PEe,"CODE",{});var dQr=s(wre);Hvo=r(dQr,"model.eval()"),dQr.forEach(t),Uvo=r(PEe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Are=n(PEe,"CODE",{});var cQr=s(Are);Jvo=r(cQr,"model.train()"),cQr.forEach(t),PEe.forEach(t),Yvo=i(Xt),Lre=n(Xt,"P",{});var fQr=s(Lre);Kvo=r(fQr,"Examples:"),fQr.forEach(t),Zvo=i(Xt),m(r3.$$.fragment,Xt),Xt.forEach(t),Ks.forEach(t),$xe=i(c),id=n(c,"H2",{class:!0});var VRe=s(id);w1=n(VRe,"A",{id:!0,class:!0,href:!0});var mQr=s(w1);Bre=n(mQr,"SPAN",{});var gQr=s(Bre);m(t3.$$.fragment,gQr),gQr.forEach(t),mQr.forEach(t),e0o=i(VRe),xre=n(VRe,"SPAN",{});var hQr=s(xre);o0o=r(hQr,"AutoModelForSeq2SeqLM"),hQr.forEach(t),VRe.forEach(t),Ixe=i(c),er=n(c,"DIV",{class:!0});var el=s(er);m(a3.$$.fragment,el),r0o=i(el),dd=n(el,"P",{});var jz=s(dd);t0o=r(jz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kre=n(jz,"CODE",{});var pQr=s(kre);a0o=r(pQr,"from_pretrained()"),pQr.forEach(t),n0o=r(jz,"class method or the "),Rre=n(jz,"CODE",{});var _Qr=s(Rre);s0o=r(_Qr,"from_config()"),_Qr.forEach(t),l0o=r(jz,`class
method.`),jz.forEach(t),i0o=i(el),n3=n(el,"P",{});var zRe=s(n3);d0o=r(zRe,"This class cannot be instantiated directly using "),Sre=n(zRe,"CODE",{});var uQr=s(Sre);c0o=r(uQr,"__init__()"),uQr.forEach(t),f0o=r(zRe," (throws an error)."),zRe.forEach(t),m0o=i(el),Hr=n(el,"DIV",{class:!0});var ol=s(Hr);m(s3.$$.fragment,ol),g0o=i(ol),Pre=n(ol,"P",{});var bQr=s(Pre);h0o=r(bQr,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bQr.forEach(t),p0o=i(ol),cd=n(ol,"P",{});var Dz=s(cd);_0o=r(Dz,`Note:
Loading a model from its configuration file does `),$re=n(Dz,"STRONG",{});var vQr=s($re);u0o=r(vQr,"not"),vQr.forEach(t),b0o=r(Dz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ire=n(Dz,"CODE",{});var TQr=s(Ire);v0o=r(TQr,"from_pretrained()"),TQr.forEach(t),T0o=r(Dz,"to load the model weights."),Dz.forEach(t),F0o=i(ol),jre=n(ol,"P",{});var FQr=s(jre);C0o=r(FQr,"Examples:"),FQr.forEach(t),M0o=i(ol),m(l3.$$.fragment,ol),ol.forEach(t),E0o=i(el),Ge=n(el,"DIV",{class:!0});var Vt=s(Ge);m(i3.$$.fragment,Vt),y0o=i(Vt),Dre=n(Vt,"P",{});var CQr=s(Dre);w0o=r(CQr,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),CQr.forEach(t),A0o=i(Vt),Qa=n(Vt,"P",{});var r4=s(Qa);L0o=r(r4,"The model class to instantiate is selected based on the "),Nre=n(r4,"CODE",{});var MQr=s(Nre);B0o=r(MQr,"model_type"),MQr.forEach(t),x0o=r(r4,` property of the config object (either
passed as an argument or loaded from `),qre=n(r4,"CODE",{});var EQr=s(qre);k0o=r(EQr,"pretrained_model_name_or_path"),EQr.forEach(t),R0o=r(r4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ore=n(r4,"CODE",{});var yQr=s(Ore);S0o=r(yQr,"pretrained_model_name_or_path"),yQr.forEach(t),P0o=r(r4,":"),r4.forEach(t),$0o=i(Vt),ne=n(Vt,"UL",{});var ie=s(ne);A1=n(ie,"LI",{});var $Ee=s(A1);Gre=n($Ee,"STRONG",{});var wQr=s(Gre);I0o=r(wQr,"bart"),wQr.forEach(t),j0o=r($Ee," \u2014 "),nI=n($Ee,"A",{href:!0});var AQr=s(nI);D0o=r(AQr,"BartForConditionalGeneration"),AQr.forEach(t),N0o=r($Ee," (BART model)"),$Ee.forEach(t),q0o=i(ie),L1=n(ie,"LI",{});var IEe=s(L1);Xre=n(IEe,"STRONG",{});var LQr=s(Xre);O0o=r(LQr,"bigbird_pegasus"),LQr.forEach(t),G0o=r(IEe," \u2014 "),sI=n(IEe,"A",{href:!0});var BQr=s(sI);X0o=r(BQr,"BigBirdPegasusForConditionalGeneration"),BQr.forEach(t),V0o=r(IEe," (BigBirdPegasus model)"),IEe.forEach(t),z0o=i(ie),B1=n(ie,"LI",{});var jEe=s(B1);Vre=n(jEe,"STRONG",{});var xQr=s(Vre);W0o=r(xQr,"blenderbot"),xQr.forEach(t),Q0o=r(jEe," \u2014 "),lI=n(jEe,"A",{href:!0});var kQr=s(lI);H0o=r(kQr,"BlenderbotForConditionalGeneration"),kQr.forEach(t),U0o=r(jEe," (Blenderbot model)"),jEe.forEach(t),J0o=i(ie),x1=n(ie,"LI",{});var DEe=s(x1);zre=n(DEe,"STRONG",{});var RQr=s(zre);Y0o=r(RQr,"blenderbot-small"),RQr.forEach(t),K0o=r(DEe," \u2014 "),iI=n(DEe,"A",{href:!0});var SQr=s(iI);Z0o=r(SQr,"BlenderbotSmallForConditionalGeneration"),SQr.forEach(t),eTo=r(DEe," (BlenderbotSmall model)"),DEe.forEach(t),oTo=i(ie),k1=n(ie,"LI",{});var NEe=s(k1);Wre=n(NEe,"STRONG",{});var PQr=s(Wre);rTo=r(PQr,"encoder-decoder"),PQr.forEach(t),tTo=r(NEe," \u2014 "),dI=n(NEe,"A",{href:!0});var $Qr=s(dI);aTo=r($Qr,"EncoderDecoderModel"),$Qr.forEach(t),nTo=r(NEe," (Encoder decoder model)"),NEe.forEach(t),sTo=i(ie),R1=n(ie,"LI",{});var qEe=s(R1);Qre=n(qEe,"STRONG",{});var IQr=s(Qre);lTo=r(IQr,"fsmt"),IQr.forEach(t),iTo=r(qEe," \u2014 "),cI=n(qEe,"A",{href:!0});var jQr=s(cI);dTo=r(jQr,"FSMTForConditionalGeneration"),jQr.forEach(t),cTo=r(qEe," (FairSeq Machine-Translation model)"),qEe.forEach(t),fTo=i(ie),S1=n(ie,"LI",{});var OEe=s(S1);Hre=n(OEe,"STRONG",{});var DQr=s(Hre);mTo=r(DQr,"led"),DQr.forEach(t),gTo=r(OEe," \u2014 "),fI=n(OEe,"A",{href:!0});var NQr=s(fI);hTo=r(NQr,"LEDForConditionalGeneration"),NQr.forEach(t),pTo=r(OEe," (LED model)"),OEe.forEach(t),_To=i(ie),P1=n(ie,"LI",{});var GEe=s(P1);Ure=n(GEe,"STRONG",{});var qQr=s(Ure);uTo=r(qQr,"m2m_100"),qQr.forEach(t),bTo=r(GEe," \u2014 "),mI=n(GEe,"A",{href:!0});var OQr=s(mI);vTo=r(OQr,"M2M100ForConditionalGeneration"),OQr.forEach(t),TTo=r(GEe," (M2M100 model)"),GEe.forEach(t),FTo=i(ie),$1=n(ie,"LI",{});var XEe=s($1);Jre=n(XEe,"STRONG",{});var GQr=s(Jre);CTo=r(GQr,"marian"),GQr.forEach(t),MTo=r(XEe," \u2014 "),gI=n(XEe,"A",{href:!0});var XQr=s(gI);ETo=r(XQr,"MarianMTModel"),XQr.forEach(t),yTo=r(XEe," (Marian model)"),XEe.forEach(t),wTo=i(ie),I1=n(ie,"LI",{});var VEe=s(I1);Yre=n(VEe,"STRONG",{});var VQr=s(Yre);ATo=r(VQr,"mbart"),VQr.forEach(t),LTo=r(VEe," \u2014 "),hI=n(VEe,"A",{href:!0});var zQr=s(hI);BTo=r(zQr,"MBartForConditionalGeneration"),zQr.forEach(t),xTo=r(VEe," (mBART model)"),VEe.forEach(t),kTo=i(ie),j1=n(ie,"LI",{});var zEe=s(j1);Kre=n(zEe,"STRONG",{});var WQr=s(Kre);RTo=r(WQr,"mt5"),WQr.forEach(t),STo=r(zEe," \u2014 "),pI=n(zEe,"A",{href:!0});var QQr=s(pI);PTo=r(QQr,"MT5ForConditionalGeneration"),QQr.forEach(t),$To=r(zEe," (mT5 model)"),zEe.forEach(t),ITo=i(ie),D1=n(ie,"LI",{});var WEe=s(D1);Zre=n(WEe,"STRONG",{});var HQr=s(Zre);jTo=r(HQr,"pegasus"),HQr.forEach(t),DTo=r(WEe," \u2014 "),_I=n(WEe,"A",{href:!0});var UQr=s(_I);NTo=r(UQr,"PegasusForConditionalGeneration"),UQr.forEach(t),qTo=r(WEe," (Pegasus model)"),WEe.forEach(t),OTo=i(ie),N1=n(ie,"LI",{});var QEe=s(N1);ete=n(QEe,"STRONG",{});var JQr=s(ete);GTo=r(JQr,"plbart"),JQr.forEach(t),XTo=r(QEe," \u2014 "),uI=n(QEe,"A",{href:!0});var YQr=s(uI);VTo=r(YQr,"PLBartForConditionalGeneration"),YQr.forEach(t),zTo=r(QEe," (PLBart model)"),QEe.forEach(t),WTo=i(ie),q1=n(ie,"LI",{});var HEe=s(q1);ote=n(HEe,"STRONG",{});var KQr=s(ote);QTo=r(KQr,"prophetnet"),KQr.forEach(t),HTo=r(HEe," \u2014 "),bI=n(HEe,"A",{href:!0});var ZQr=s(bI);UTo=r(ZQr,"ProphetNetForConditionalGeneration"),ZQr.forEach(t),JTo=r(HEe," (ProphetNet model)"),HEe.forEach(t),YTo=i(ie),O1=n(ie,"LI",{});var UEe=s(O1);rte=n(UEe,"STRONG",{});var eHr=s(rte);KTo=r(eHr,"t5"),eHr.forEach(t),ZTo=r(UEe," \u2014 "),vI=n(UEe,"A",{href:!0});var oHr=s(vI);eFo=r(oHr,"T5ForConditionalGeneration"),oHr.forEach(t),oFo=r(UEe," (T5 model)"),UEe.forEach(t),rFo=i(ie),G1=n(ie,"LI",{});var JEe=s(G1);tte=n(JEe,"STRONG",{});var rHr=s(tte);tFo=r(rHr,"xlm-prophetnet"),rHr.forEach(t),aFo=r(JEe," \u2014 "),TI=n(JEe,"A",{href:!0});var tHr=s(TI);nFo=r(tHr,"XLMProphetNetForConditionalGeneration"),tHr.forEach(t),sFo=r(JEe," (XLMProphetNet model)"),JEe.forEach(t),ie.forEach(t),lFo=i(Vt),X1=n(Vt,"P",{});var YEe=s(X1);iFo=r(YEe,"The model is set in evaluation mode by default using "),ate=n(YEe,"CODE",{});var aHr=s(ate);dFo=r(aHr,"model.eval()"),aHr.forEach(t),cFo=r(YEe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nte=n(YEe,"CODE",{});var nHr=s(nte);fFo=r(nHr,"model.train()"),nHr.forEach(t),YEe.forEach(t),mFo=i(Vt),ste=n(Vt,"P",{});var sHr=s(ste);gFo=r(sHr,"Examples:"),sHr.forEach(t),hFo=i(Vt),m(d3.$$.fragment,Vt),Vt.forEach(t),el.forEach(t),jxe=i(c),fd=n(c,"H2",{class:!0});var WRe=s(fd);V1=n(WRe,"A",{id:!0,class:!0,href:!0});var lHr=s(V1);lte=n(lHr,"SPAN",{});var iHr=s(lte);m(c3.$$.fragment,iHr),iHr.forEach(t),lHr.forEach(t),pFo=i(WRe),ite=n(WRe,"SPAN",{});var dHr=s(ite);_Fo=r(dHr,"AutoModelForSequenceClassification"),dHr.forEach(t),WRe.forEach(t),Dxe=i(c),or=n(c,"DIV",{class:!0});var rl=s(or);m(f3.$$.fragment,rl),uFo=i(rl),md=n(rl,"P",{});var Nz=s(md);bFo=r(Nz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),dte=n(Nz,"CODE",{});var cHr=s(dte);vFo=r(cHr,"from_pretrained()"),cHr.forEach(t),TFo=r(Nz,"class method or the "),cte=n(Nz,"CODE",{});var fHr=s(cte);FFo=r(fHr,"from_config()"),fHr.forEach(t),CFo=r(Nz,`class
method.`),Nz.forEach(t),MFo=i(rl),m3=n(rl,"P",{});var QRe=s(m3);EFo=r(QRe,"This class cannot be instantiated directly using "),fte=n(QRe,"CODE",{});var mHr=s(fte);yFo=r(mHr,"__init__()"),mHr.forEach(t),wFo=r(QRe," (throws an error)."),QRe.forEach(t),AFo=i(rl),Ur=n(rl,"DIV",{class:!0});var tl=s(Ur);m(g3.$$.fragment,tl),LFo=i(tl),mte=n(tl,"P",{});var gHr=s(mte);BFo=r(gHr,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),gHr.forEach(t),xFo=i(tl),gd=n(tl,"P",{});var qz=s(gd);kFo=r(qz,`Note:
Loading a model from its configuration file does `),gte=n(qz,"STRONG",{});var hHr=s(gte);RFo=r(hHr,"not"),hHr.forEach(t),SFo=r(qz,` load the model weights. It only affects the
model\u2019s configuration. Use `),hte=n(qz,"CODE",{});var pHr=s(hte);PFo=r(pHr,"from_pretrained()"),pHr.forEach(t),$Fo=r(qz,"to load the model weights."),qz.forEach(t),IFo=i(tl),pte=n(tl,"P",{});var _Hr=s(pte);jFo=r(_Hr,"Examples:"),_Hr.forEach(t),DFo=i(tl),m(h3.$$.fragment,tl),tl.forEach(t),NFo=i(rl),Xe=n(rl,"DIV",{class:!0});var zt=s(Xe);m(p3.$$.fragment,zt),qFo=i(zt),_te=n(zt,"P",{});var uHr=s(_te);OFo=r(uHr,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uHr.forEach(t),GFo=i(zt),Ha=n(zt,"P",{});var t4=s(Ha);XFo=r(t4,"The model class to instantiate is selected based on the "),ute=n(t4,"CODE",{});var bHr=s(ute);VFo=r(bHr,"model_type"),bHr.forEach(t),zFo=r(t4,` property of the config object (either
passed as an argument or loaded from `),bte=n(t4,"CODE",{});var vHr=s(bte);WFo=r(vHr,"pretrained_model_name_or_path"),vHr.forEach(t),QFo=r(t4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vte=n(t4,"CODE",{});var THr=s(vte);HFo=r(THr,"pretrained_model_name_or_path"),THr.forEach(t),UFo=r(t4,":"),t4.forEach(t),JFo=i(zt),A=n(zt,"UL",{});var L=s(A);z1=n(L,"LI",{});var KEe=s(z1);Tte=n(KEe,"STRONG",{});var FHr=s(Tte);YFo=r(FHr,"albert"),FHr.forEach(t),KFo=r(KEe," \u2014 "),FI=n(KEe,"A",{href:!0});var CHr=s(FI);ZFo=r(CHr,"AlbertForSequenceClassification"),CHr.forEach(t),eCo=r(KEe," (ALBERT model)"),KEe.forEach(t),oCo=i(L),W1=n(L,"LI",{});var ZEe=s(W1);Fte=n(ZEe,"STRONG",{});var MHr=s(Fte);rCo=r(MHr,"bart"),MHr.forEach(t),tCo=r(ZEe," \u2014 "),CI=n(ZEe,"A",{href:!0});var EHr=s(CI);aCo=r(EHr,"BartForSequenceClassification"),EHr.forEach(t),nCo=r(ZEe," (BART model)"),ZEe.forEach(t),sCo=i(L),Q1=n(L,"LI",{});var e3e=s(Q1);Cte=n(e3e,"STRONG",{});var yHr=s(Cte);lCo=r(yHr,"bert"),yHr.forEach(t),iCo=r(e3e," \u2014 "),MI=n(e3e,"A",{href:!0});var wHr=s(MI);dCo=r(wHr,"BertForSequenceClassification"),wHr.forEach(t),cCo=r(e3e," (BERT model)"),e3e.forEach(t),fCo=i(L),H1=n(L,"LI",{});var o3e=s(H1);Mte=n(o3e,"STRONG",{});var AHr=s(Mte);mCo=r(AHr,"big_bird"),AHr.forEach(t),gCo=r(o3e," \u2014 "),EI=n(o3e,"A",{href:!0});var LHr=s(EI);hCo=r(LHr,"BigBirdForSequenceClassification"),LHr.forEach(t),pCo=r(o3e," (BigBird model)"),o3e.forEach(t),_Co=i(L),U1=n(L,"LI",{});var r3e=s(U1);Ete=n(r3e,"STRONG",{});var BHr=s(Ete);uCo=r(BHr,"bigbird_pegasus"),BHr.forEach(t),bCo=r(r3e," \u2014 "),yI=n(r3e,"A",{href:!0});var xHr=s(yI);vCo=r(xHr,"BigBirdPegasusForSequenceClassification"),xHr.forEach(t),TCo=r(r3e," (BigBirdPegasus model)"),r3e.forEach(t),FCo=i(L),J1=n(L,"LI",{});var t3e=s(J1);yte=n(t3e,"STRONG",{});var kHr=s(yte);CCo=r(kHr,"camembert"),kHr.forEach(t),MCo=r(t3e," \u2014 "),wI=n(t3e,"A",{href:!0});var RHr=s(wI);ECo=r(RHr,"CamembertForSequenceClassification"),RHr.forEach(t),yCo=r(t3e," (CamemBERT model)"),t3e.forEach(t),wCo=i(L),Y1=n(L,"LI",{});var a3e=s(Y1);wte=n(a3e,"STRONG",{});var SHr=s(wte);ACo=r(SHr,"canine"),SHr.forEach(t),LCo=r(a3e," \u2014 "),AI=n(a3e,"A",{href:!0});var PHr=s(AI);BCo=r(PHr,"CanineForSequenceClassification"),PHr.forEach(t),xCo=r(a3e," (Canine model)"),a3e.forEach(t),kCo=i(L),K1=n(L,"LI",{});var n3e=s(K1);Ate=n(n3e,"STRONG",{});var $Hr=s(Ate);RCo=r($Hr,"convbert"),$Hr.forEach(t),SCo=r(n3e," \u2014 "),LI=n(n3e,"A",{href:!0});var IHr=s(LI);PCo=r(IHr,"ConvBertForSequenceClassification"),IHr.forEach(t),$Co=r(n3e," (ConvBERT model)"),n3e.forEach(t),ICo=i(L),Z1=n(L,"LI",{});var s3e=s(Z1);Lte=n(s3e,"STRONG",{});var jHr=s(Lte);jCo=r(jHr,"ctrl"),jHr.forEach(t),DCo=r(s3e," \u2014 "),BI=n(s3e,"A",{href:!0});var DHr=s(BI);NCo=r(DHr,"CTRLForSequenceClassification"),DHr.forEach(t),qCo=r(s3e," (CTRL model)"),s3e.forEach(t),OCo=i(L),e7=n(L,"LI",{});var l3e=s(e7);Bte=n(l3e,"STRONG",{});var NHr=s(Bte);GCo=r(NHr,"data2vec-text"),NHr.forEach(t),XCo=r(l3e," \u2014 "),xI=n(l3e,"A",{href:!0});var qHr=s(xI);VCo=r(qHr,"Data2VecTextForSequenceClassification"),qHr.forEach(t),zCo=r(l3e," (Data2VecText model)"),l3e.forEach(t),WCo=i(L),o7=n(L,"LI",{});var i3e=s(o7);xte=n(i3e,"STRONG",{});var OHr=s(xte);QCo=r(OHr,"deberta"),OHr.forEach(t),HCo=r(i3e," \u2014 "),kI=n(i3e,"A",{href:!0});var GHr=s(kI);UCo=r(GHr,"DebertaForSequenceClassification"),GHr.forEach(t),JCo=r(i3e," (DeBERTa model)"),i3e.forEach(t),YCo=i(L),r7=n(L,"LI",{});var d3e=s(r7);kte=n(d3e,"STRONG",{});var XHr=s(kte);KCo=r(XHr,"deberta-v2"),XHr.forEach(t),ZCo=r(d3e," \u2014 "),RI=n(d3e,"A",{href:!0});var VHr=s(RI);eMo=r(VHr,"DebertaV2ForSequenceClassification"),VHr.forEach(t),oMo=r(d3e," (DeBERTa-v2 model)"),d3e.forEach(t),rMo=i(L),t7=n(L,"LI",{});var c3e=s(t7);Rte=n(c3e,"STRONG",{});var zHr=s(Rte);tMo=r(zHr,"distilbert"),zHr.forEach(t),aMo=r(c3e," \u2014 "),SI=n(c3e,"A",{href:!0});var WHr=s(SI);nMo=r(WHr,"DistilBertForSequenceClassification"),WHr.forEach(t),sMo=r(c3e," (DistilBERT model)"),c3e.forEach(t),lMo=i(L),a7=n(L,"LI",{});var f3e=s(a7);Ste=n(f3e,"STRONG",{});var QHr=s(Ste);iMo=r(QHr,"electra"),QHr.forEach(t),dMo=r(f3e," \u2014 "),PI=n(f3e,"A",{href:!0});var HHr=s(PI);cMo=r(HHr,"ElectraForSequenceClassification"),HHr.forEach(t),fMo=r(f3e," (ELECTRA model)"),f3e.forEach(t),mMo=i(L),n7=n(L,"LI",{});var m3e=s(n7);Pte=n(m3e,"STRONG",{});var UHr=s(Pte);gMo=r(UHr,"flaubert"),UHr.forEach(t),hMo=r(m3e," \u2014 "),$I=n(m3e,"A",{href:!0});var JHr=s($I);pMo=r(JHr,"FlaubertForSequenceClassification"),JHr.forEach(t),_Mo=r(m3e," (FlauBERT model)"),m3e.forEach(t),uMo=i(L),s7=n(L,"LI",{});var g3e=s(s7);$te=n(g3e,"STRONG",{});var YHr=s($te);bMo=r(YHr,"fnet"),YHr.forEach(t),vMo=r(g3e," \u2014 "),II=n(g3e,"A",{href:!0});var KHr=s(II);TMo=r(KHr,"FNetForSequenceClassification"),KHr.forEach(t),FMo=r(g3e," (FNet model)"),g3e.forEach(t),CMo=i(L),l7=n(L,"LI",{});var h3e=s(l7);Ite=n(h3e,"STRONG",{});var ZHr=s(Ite);MMo=r(ZHr,"funnel"),ZHr.forEach(t),EMo=r(h3e," \u2014 "),jI=n(h3e,"A",{href:!0});var eUr=s(jI);yMo=r(eUr,"FunnelForSequenceClassification"),eUr.forEach(t),wMo=r(h3e," (Funnel Transformer model)"),h3e.forEach(t),AMo=i(L),i7=n(L,"LI",{});var p3e=s(i7);jte=n(p3e,"STRONG",{});var oUr=s(jte);LMo=r(oUr,"gpt2"),oUr.forEach(t),BMo=r(p3e," \u2014 "),DI=n(p3e,"A",{href:!0});var rUr=s(DI);xMo=r(rUr,"GPT2ForSequenceClassification"),rUr.forEach(t),kMo=r(p3e," (OpenAI GPT-2 model)"),p3e.forEach(t),RMo=i(L),d7=n(L,"LI",{});var _3e=s(d7);Dte=n(_3e,"STRONG",{});var tUr=s(Dte);SMo=r(tUr,"gpt_neo"),tUr.forEach(t),PMo=r(_3e," \u2014 "),NI=n(_3e,"A",{href:!0});var aUr=s(NI);$Mo=r(aUr,"GPTNeoForSequenceClassification"),aUr.forEach(t),IMo=r(_3e," (GPT Neo model)"),_3e.forEach(t),jMo=i(L),c7=n(L,"LI",{});var u3e=s(c7);Nte=n(u3e,"STRONG",{});var nUr=s(Nte);DMo=r(nUr,"gptj"),nUr.forEach(t),NMo=r(u3e," \u2014 "),qI=n(u3e,"A",{href:!0});var sUr=s(qI);qMo=r(sUr,"GPTJForSequenceClassification"),sUr.forEach(t),OMo=r(u3e," (GPT-J model)"),u3e.forEach(t),GMo=i(L),f7=n(L,"LI",{});var b3e=s(f7);qte=n(b3e,"STRONG",{});var lUr=s(qte);XMo=r(lUr,"ibert"),lUr.forEach(t),VMo=r(b3e," \u2014 "),OI=n(b3e,"A",{href:!0});var iUr=s(OI);zMo=r(iUr,"IBertForSequenceClassification"),iUr.forEach(t),WMo=r(b3e," (I-BERT model)"),b3e.forEach(t),QMo=i(L),m7=n(L,"LI",{});var v3e=s(m7);Ote=n(v3e,"STRONG",{});var dUr=s(Ote);HMo=r(dUr,"layoutlm"),dUr.forEach(t),UMo=r(v3e," \u2014 "),GI=n(v3e,"A",{href:!0});var cUr=s(GI);JMo=r(cUr,"LayoutLMForSequenceClassification"),cUr.forEach(t),YMo=r(v3e," (LayoutLM model)"),v3e.forEach(t),KMo=i(L),g7=n(L,"LI",{});var T3e=s(g7);Gte=n(T3e,"STRONG",{});var fUr=s(Gte);ZMo=r(fUr,"layoutlmv2"),fUr.forEach(t),e4o=r(T3e," \u2014 "),XI=n(T3e,"A",{href:!0});var mUr=s(XI);o4o=r(mUr,"LayoutLMv2ForSequenceClassification"),mUr.forEach(t),r4o=r(T3e," (LayoutLMv2 model)"),T3e.forEach(t),t4o=i(L),h7=n(L,"LI",{});var F3e=s(h7);Xte=n(F3e,"STRONG",{});var gUr=s(Xte);a4o=r(gUr,"led"),gUr.forEach(t),n4o=r(F3e," \u2014 "),VI=n(F3e,"A",{href:!0});var hUr=s(VI);s4o=r(hUr,"LEDForSequenceClassification"),hUr.forEach(t),l4o=r(F3e," (LED model)"),F3e.forEach(t),i4o=i(L),p7=n(L,"LI",{});var C3e=s(p7);Vte=n(C3e,"STRONG",{});var pUr=s(Vte);d4o=r(pUr,"longformer"),pUr.forEach(t),c4o=r(C3e," \u2014 "),zI=n(C3e,"A",{href:!0});var _Ur=s(zI);f4o=r(_Ur,"LongformerForSequenceClassification"),_Ur.forEach(t),m4o=r(C3e," (Longformer model)"),C3e.forEach(t),g4o=i(L),_7=n(L,"LI",{});var M3e=s(_7);zte=n(M3e,"STRONG",{});var uUr=s(zte);h4o=r(uUr,"mbart"),uUr.forEach(t),p4o=r(M3e," \u2014 "),WI=n(M3e,"A",{href:!0});var bUr=s(WI);_4o=r(bUr,"MBartForSequenceClassification"),bUr.forEach(t),u4o=r(M3e," (mBART model)"),M3e.forEach(t),b4o=i(L),u7=n(L,"LI",{});var E3e=s(u7);Wte=n(E3e,"STRONG",{});var vUr=s(Wte);v4o=r(vUr,"megatron-bert"),vUr.forEach(t),T4o=r(E3e," \u2014 "),QI=n(E3e,"A",{href:!0});var TUr=s(QI);F4o=r(TUr,"MegatronBertForSequenceClassification"),TUr.forEach(t),C4o=r(E3e," (MegatronBert model)"),E3e.forEach(t),M4o=i(L),b7=n(L,"LI",{});var y3e=s(b7);Qte=n(y3e,"STRONG",{});var FUr=s(Qte);E4o=r(FUr,"mobilebert"),FUr.forEach(t),y4o=r(y3e," \u2014 "),HI=n(y3e,"A",{href:!0});var CUr=s(HI);w4o=r(CUr,"MobileBertForSequenceClassification"),CUr.forEach(t),A4o=r(y3e," (MobileBERT model)"),y3e.forEach(t),L4o=i(L),v7=n(L,"LI",{});var w3e=s(v7);Hte=n(w3e,"STRONG",{});var MUr=s(Hte);B4o=r(MUr,"mpnet"),MUr.forEach(t),x4o=r(w3e," \u2014 "),UI=n(w3e,"A",{href:!0});var EUr=s(UI);k4o=r(EUr,"MPNetForSequenceClassification"),EUr.forEach(t),R4o=r(w3e," (MPNet model)"),w3e.forEach(t),S4o=i(L),T7=n(L,"LI",{});var A3e=s(T7);Ute=n(A3e,"STRONG",{});var yUr=s(Ute);P4o=r(yUr,"nystromformer"),yUr.forEach(t),$4o=r(A3e," \u2014 "),JI=n(A3e,"A",{href:!0});var wUr=s(JI);I4o=r(wUr,"NystromformerForSequenceClassification"),wUr.forEach(t),j4o=r(A3e," (Nystromformer model)"),A3e.forEach(t),D4o=i(L),F7=n(L,"LI",{});var L3e=s(F7);Jte=n(L3e,"STRONG",{});var AUr=s(Jte);N4o=r(AUr,"openai-gpt"),AUr.forEach(t),q4o=r(L3e," \u2014 "),YI=n(L3e,"A",{href:!0});var LUr=s(YI);O4o=r(LUr,"OpenAIGPTForSequenceClassification"),LUr.forEach(t),G4o=r(L3e," (OpenAI GPT model)"),L3e.forEach(t),X4o=i(L),C7=n(L,"LI",{});var B3e=s(C7);Yte=n(B3e,"STRONG",{});var BUr=s(Yte);V4o=r(BUr,"perceiver"),BUr.forEach(t),z4o=r(B3e," \u2014 "),KI=n(B3e,"A",{href:!0});var xUr=s(KI);W4o=r(xUr,"PerceiverForSequenceClassification"),xUr.forEach(t),Q4o=r(B3e," (Perceiver model)"),B3e.forEach(t),H4o=i(L),M7=n(L,"LI",{});var x3e=s(M7);Kte=n(x3e,"STRONG",{});var kUr=s(Kte);U4o=r(kUr,"plbart"),kUr.forEach(t),J4o=r(x3e," \u2014 "),ZI=n(x3e,"A",{href:!0});var RUr=s(ZI);Y4o=r(RUr,"PLBartForSequenceClassification"),RUr.forEach(t),K4o=r(x3e," (PLBart model)"),x3e.forEach(t),Z4o=i(L),E7=n(L,"LI",{});var k3e=s(E7);Zte=n(k3e,"STRONG",{});var SUr=s(Zte);eEo=r(SUr,"qdqbert"),SUr.forEach(t),oEo=r(k3e," \u2014 "),ej=n(k3e,"A",{href:!0});var PUr=s(ej);rEo=r(PUr,"QDQBertForSequenceClassification"),PUr.forEach(t),tEo=r(k3e," (QDQBert model)"),k3e.forEach(t),aEo=i(L),y7=n(L,"LI",{});var R3e=s(y7);eae=n(R3e,"STRONG",{});var $Ur=s(eae);nEo=r($Ur,"reformer"),$Ur.forEach(t),sEo=r(R3e," \u2014 "),oj=n(R3e,"A",{href:!0});var IUr=s(oj);lEo=r(IUr,"ReformerForSequenceClassification"),IUr.forEach(t),iEo=r(R3e," (Reformer model)"),R3e.forEach(t),dEo=i(L),w7=n(L,"LI",{});var S3e=s(w7);oae=n(S3e,"STRONG",{});var jUr=s(oae);cEo=r(jUr,"rembert"),jUr.forEach(t),fEo=r(S3e," \u2014 "),rj=n(S3e,"A",{href:!0});var DUr=s(rj);mEo=r(DUr,"RemBertForSequenceClassification"),DUr.forEach(t),gEo=r(S3e," (RemBERT model)"),S3e.forEach(t),hEo=i(L),A7=n(L,"LI",{});var P3e=s(A7);rae=n(P3e,"STRONG",{});var NUr=s(rae);pEo=r(NUr,"roberta"),NUr.forEach(t),_Eo=r(P3e," \u2014 "),tj=n(P3e,"A",{href:!0});var qUr=s(tj);uEo=r(qUr,"RobertaForSequenceClassification"),qUr.forEach(t),bEo=r(P3e," (RoBERTa model)"),P3e.forEach(t),vEo=i(L),L7=n(L,"LI",{});var $3e=s(L7);tae=n($3e,"STRONG",{});var OUr=s(tae);TEo=r(OUr,"roformer"),OUr.forEach(t),FEo=r($3e," \u2014 "),aj=n($3e,"A",{href:!0});var GUr=s(aj);CEo=r(GUr,"RoFormerForSequenceClassification"),GUr.forEach(t),MEo=r($3e," (RoFormer model)"),$3e.forEach(t),EEo=i(L),B7=n(L,"LI",{});var I3e=s(B7);aae=n(I3e,"STRONG",{});var XUr=s(aae);yEo=r(XUr,"squeezebert"),XUr.forEach(t),wEo=r(I3e," \u2014 "),nj=n(I3e,"A",{href:!0});var VUr=s(nj);AEo=r(VUr,"SqueezeBertForSequenceClassification"),VUr.forEach(t),LEo=r(I3e," (SqueezeBERT model)"),I3e.forEach(t),BEo=i(L),x7=n(L,"LI",{});var j3e=s(x7);nae=n(j3e,"STRONG",{});var zUr=s(nae);xEo=r(zUr,"tapas"),zUr.forEach(t),kEo=r(j3e," \u2014 "),sj=n(j3e,"A",{href:!0});var WUr=s(sj);REo=r(WUr,"TapasForSequenceClassification"),WUr.forEach(t),SEo=r(j3e," (TAPAS model)"),j3e.forEach(t),PEo=i(L),k7=n(L,"LI",{});var D3e=s(k7);sae=n(D3e,"STRONG",{});var QUr=s(sae);$Eo=r(QUr,"transfo-xl"),QUr.forEach(t),IEo=r(D3e," \u2014 "),lj=n(D3e,"A",{href:!0});var HUr=s(lj);jEo=r(HUr,"TransfoXLForSequenceClassification"),HUr.forEach(t),DEo=r(D3e," (Transformer-XL model)"),D3e.forEach(t),NEo=i(L),R7=n(L,"LI",{});var N3e=s(R7);lae=n(N3e,"STRONG",{});var UUr=s(lae);qEo=r(UUr,"xlm"),UUr.forEach(t),OEo=r(N3e," \u2014 "),ij=n(N3e,"A",{href:!0});var JUr=s(ij);GEo=r(JUr,"XLMForSequenceClassification"),JUr.forEach(t),XEo=r(N3e," (XLM model)"),N3e.forEach(t),VEo=i(L),S7=n(L,"LI",{});var q3e=s(S7);iae=n(q3e,"STRONG",{});var YUr=s(iae);zEo=r(YUr,"xlm-roberta"),YUr.forEach(t),WEo=r(q3e," \u2014 "),dj=n(q3e,"A",{href:!0});var KUr=s(dj);QEo=r(KUr,"XLMRobertaForSequenceClassification"),KUr.forEach(t),HEo=r(q3e," (XLM-RoBERTa model)"),q3e.forEach(t),UEo=i(L),P7=n(L,"LI",{});var O3e=s(P7);dae=n(O3e,"STRONG",{});var ZUr=s(dae);JEo=r(ZUr,"xlm-roberta-xl"),ZUr.forEach(t),YEo=r(O3e," \u2014 "),cj=n(O3e,"A",{href:!0});var eJr=s(cj);KEo=r(eJr,"XLMRobertaXLForSequenceClassification"),eJr.forEach(t),ZEo=r(O3e," (XLM-RoBERTa-XL model)"),O3e.forEach(t),e3o=i(L),$7=n(L,"LI",{});var G3e=s($7);cae=n(G3e,"STRONG",{});var oJr=s(cae);o3o=r(oJr,"xlnet"),oJr.forEach(t),r3o=r(G3e," \u2014 "),fj=n(G3e,"A",{href:!0});var rJr=s(fj);t3o=r(rJr,"XLNetForSequenceClassification"),rJr.forEach(t),a3o=r(G3e," (XLNet model)"),G3e.forEach(t),n3o=i(L),I7=n(L,"LI",{});var X3e=s(I7);fae=n(X3e,"STRONG",{});var tJr=s(fae);s3o=r(tJr,"yoso"),tJr.forEach(t),l3o=r(X3e," \u2014 "),mj=n(X3e,"A",{href:!0});var aJr=s(mj);i3o=r(aJr,"YosoForSequenceClassification"),aJr.forEach(t),d3o=r(X3e," (YOSO model)"),X3e.forEach(t),L.forEach(t),c3o=i(zt),j7=n(zt,"P",{});var V3e=s(j7);f3o=r(V3e,"The model is set in evaluation mode by default using "),mae=n(V3e,"CODE",{});var nJr=s(mae);m3o=r(nJr,"model.eval()"),nJr.forEach(t),g3o=r(V3e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gae=n(V3e,"CODE",{});var sJr=s(gae);h3o=r(sJr,"model.train()"),sJr.forEach(t),V3e.forEach(t),p3o=i(zt),hae=n(zt,"P",{});var lJr=s(hae);_3o=r(lJr,"Examples:"),lJr.forEach(t),u3o=i(zt),m(_3.$$.fragment,zt),zt.forEach(t),rl.forEach(t),Nxe=i(c),hd=n(c,"H2",{class:!0});var HRe=s(hd);D7=n(HRe,"A",{id:!0,class:!0,href:!0});var iJr=s(D7);pae=n(iJr,"SPAN",{});var dJr=s(pae);m(u3.$$.fragment,dJr),dJr.forEach(t),iJr.forEach(t),b3o=i(HRe),_ae=n(HRe,"SPAN",{});var cJr=s(_ae);v3o=r(cJr,"AutoModelForMultipleChoice"),cJr.forEach(t),HRe.forEach(t),qxe=i(c),rr=n(c,"DIV",{class:!0});var al=s(rr);m(b3.$$.fragment,al),T3o=i(al),pd=n(al,"P",{});var Oz=s(pd);F3o=r(Oz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),uae=n(Oz,"CODE",{});var fJr=s(uae);C3o=r(fJr,"from_pretrained()"),fJr.forEach(t),M3o=r(Oz,"class method or the "),bae=n(Oz,"CODE",{});var mJr=s(bae);E3o=r(mJr,"from_config()"),mJr.forEach(t),y3o=r(Oz,`class
method.`),Oz.forEach(t),w3o=i(al),v3=n(al,"P",{});var URe=s(v3);A3o=r(URe,"This class cannot be instantiated directly using "),vae=n(URe,"CODE",{});var gJr=s(vae);L3o=r(gJr,"__init__()"),gJr.forEach(t),B3o=r(URe," (throws an error)."),URe.forEach(t),x3o=i(al),Jr=n(al,"DIV",{class:!0});var nl=s(Jr);m(T3.$$.fragment,nl),k3o=i(nl),Tae=n(nl,"P",{});var hJr=s(Tae);R3o=r(hJr,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),hJr.forEach(t),S3o=i(nl),_d=n(nl,"P",{});var Gz=s(_d);P3o=r(Gz,`Note:
Loading a model from its configuration file does `),Fae=n(Gz,"STRONG",{});var pJr=s(Fae);$3o=r(pJr,"not"),pJr.forEach(t),I3o=r(Gz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cae=n(Gz,"CODE",{});var _Jr=s(Cae);j3o=r(_Jr,"from_pretrained()"),_Jr.forEach(t),D3o=r(Gz,"to load the model weights."),Gz.forEach(t),N3o=i(nl),Mae=n(nl,"P",{});var uJr=s(Mae);q3o=r(uJr,"Examples:"),uJr.forEach(t),O3o=i(nl),m(F3.$$.fragment,nl),nl.forEach(t),G3o=i(al),Ve=n(al,"DIV",{class:!0});var Wt=s(Ve);m(C3.$$.fragment,Wt),X3o=i(Wt),Eae=n(Wt,"P",{});var bJr=s(Eae);V3o=r(bJr,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),bJr.forEach(t),z3o=i(Wt),Ua=n(Wt,"P",{});var a4=s(Ua);W3o=r(a4,"The model class to instantiate is selected based on the "),yae=n(a4,"CODE",{});var vJr=s(yae);Q3o=r(vJr,"model_type"),vJr.forEach(t),H3o=r(a4,` property of the config object (either
passed as an argument or loaded from `),wae=n(a4,"CODE",{});var TJr=s(wae);U3o=r(TJr,"pretrained_model_name_or_path"),TJr.forEach(t),J3o=r(a4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aae=n(a4,"CODE",{});var FJr=s(Aae);Y3o=r(FJr,"pretrained_model_name_or_path"),FJr.forEach(t),K3o=r(a4,":"),a4.forEach(t),Z3o=i(Wt),O=n(Wt,"UL",{});var G=s(O);N7=n(G,"LI",{});var z3e=s(N7);Lae=n(z3e,"STRONG",{});var CJr=s(Lae);eyo=r(CJr,"albert"),CJr.forEach(t),oyo=r(z3e," \u2014 "),gj=n(z3e,"A",{href:!0});var MJr=s(gj);ryo=r(MJr,"AlbertForMultipleChoice"),MJr.forEach(t),tyo=r(z3e," (ALBERT model)"),z3e.forEach(t),ayo=i(G),q7=n(G,"LI",{});var W3e=s(q7);Bae=n(W3e,"STRONG",{});var EJr=s(Bae);nyo=r(EJr,"bert"),EJr.forEach(t),syo=r(W3e," \u2014 "),hj=n(W3e,"A",{href:!0});var yJr=s(hj);lyo=r(yJr,"BertForMultipleChoice"),yJr.forEach(t),iyo=r(W3e," (BERT model)"),W3e.forEach(t),dyo=i(G),O7=n(G,"LI",{});var Q3e=s(O7);xae=n(Q3e,"STRONG",{});var wJr=s(xae);cyo=r(wJr,"big_bird"),wJr.forEach(t),fyo=r(Q3e," \u2014 "),pj=n(Q3e,"A",{href:!0});var AJr=s(pj);myo=r(AJr,"BigBirdForMultipleChoice"),AJr.forEach(t),gyo=r(Q3e," (BigBird model)"),Q3e.forEach(t),hyo=i(G),G7=n(G,"LI",{});var H3e=s(G7);kae=n(H3e,"STRONG",{});var LJr=s(kae);pyo=r(LJr,"camembert"),LJr.forEach(t),_yo=r(H3e," \u2014 "),_j=n(H3e,"A",{href:!0});var BJr=s(_j);uyo=r(BJr,"CamembertForMultipleChoice"),BJr.forEach(t),byo=r(H3e," (CamemBERT model)"),H3e.forEach(t),vyo=i(G),X7=n(G,"LI",{});var U3e=s(X7);Rae=n(U3e,"STRONG",{});var xJr=s(Rae);Tyo=r(xJr,"canine"),xJr.forEach(t),Fyo=r(U3e," \u2014 "),uj=n(U3e,"A",{href:!0});var kJr=s(uj);Cyo=r(kJr,"CanineForMultipleChoice"),kJr.forEach(t),Myo=r(U3e," (Canine model)"),U3e.forEach(t),Eyo=i(G),V7=n(G,"LI",{});var J3e=s(V7);Sae=n(J3e,"STRONG",{});var RJr=s(Sae);yyo=r(RJr,"convbert"),RJr.forEach(t),wyo=r(J3e," \u2014 "),bj=n(J3e,"A",{href:!0});var SJr=s(bj);Ayo=r(SJr,"ConvBertForMultipleChoice"),SJr.forEach(t),Lyo=r(J3e," (ConvBERT model)"),J3e.forEach(t),Byo=i(G),z7=n(G,"LI",{});var Y3e=s(z7);Pae=n(Y3e,"STRONG",{});var PJr=s(Pae);xyo=r(PJr,"data2vec-text"),PJr.forEach(t),kyo=r(Y3e," \u2014 "),vj=n(Y3e,"A",{href:!0});var $Jr=s(vj);Ryo=r($Jr,"Data2VecTextForMultipleChoice"),$Jr.forEach(t),Syo=r(Y3e," (Data2VecText model)"),Y3e.forEach(t),Pyo=i(G),W7=n(G,"LI",{});var K3e=s(W7);$ae=n(K3e,"STRONG",{});var IJr=s($ae);$yo=r(IJr,"distilbert"),IJr.forEach(t),Iyo=r(K3e," \u2014 "),Tj=n(K3e,"A",{href:!0});var jJr=s(Tj);jyo=r(jJr,"DistilBertForMultipleChoice"),jJr.forEach(t),Dyo=r(K3e," (DistilBERT model)"),K3e.forEach(t),Nyo=i(G),Q7=n(G,"LI",{});var Z3e=s(Q7);Iae=n(Z3e,"STRONG",{});var DJr=s(Iae);qyo=r(DJr,"electra"),DJr.forEach(t),Oyo=r(Z3e," \u2014 "),Fj=n(Z3e,"A",{href:!0});var NJr=s(Fj);Gyo=r(NJr,"ElectraForMultipleChoice"),NJr.forEach(t),Xyo=r(Z3e," (ELECTRA model)"),Z3e.forEach(t),Vyo=i(G),H7=n(G,"LI",{});var eye=s(H7);jae=n(eye,"STRONG",{});var qJr=s(jae);zyo=r(qJr,"flaubert"),qJr.forEach(t),Wyo=r(eye," \u2014 "),Cj=n(eye,"A",{href:!0});var OJr=s(Cj);Qyo=r(OJr,"FlaubertForMultipleChoice"),OJr.forEach(t),Hyo=r(eye," (FlauBERT model)"),eye.forEach(t),Uyo=i(G),U7=n(G,"LI",{});var oye=s(U7);Dae=n(oye,"STRONG",{});var GJr=s(Dae);Jyo=r(GJr,"fnet"),GJr.forEach(t),Yyo=r(oye," \u2014 "),Mj=n(oye,"A",{href:!0});var XJr=s(Mj);Kyo=r(XJr,"FNetForMultipleChoice"),XJr.forEach(t),Zyo=r(oye," (FNet model)"),oye.forEach(t),ewo=i(G),J7=n(G,"LI",{});var rye=s(J7);Nae=n(rye,"STRONG",{});var VJr=s(Nae);owo=r(VJr,"funnel"),VJr.forEach(t),rwo=r(rye," \u2014 "),Ej=n(rye,"A",{href:!0});var zJr=s(Ej);two=r(zJr,"FunnelForMultipleChoice"),zJr.forEach(t),awo=r(rye," (Funnel Transformer model)"),rye.forEach(t),nwo=i(G),Y7=n(G,"LI",{});var tye=s(Y7);qae=n(tye,"STRONG",{});var WJr=s(qae);swo=r(WJr,"ibert"),WJr.forEach(t),lwo=r(tye," \u2014 "),yj=n(tye,"A",{href:!0});var QJr=s(yj);iwo=r(QJr,"IBertForMultipleChoice"),QJr.forEach(t),dwo=r(tye," (I-BERT model)"),tye.forEach(t),cwo=i(G),K7=n(G,"LI",{});var aye=s(K7);Oae=n(aye,"STRONG",{});var HJr=s(Oae);fwo=r(HJr,"longformer"),HJr.forEach(t),mwo=r(aye," \u2014 "),wj=n(aye,"A",{href:!0});var UJr=s(wj);gwo=r(UJr,"LongformerForMultipleChoice"),UJr.forEach(t),hwo=r(aye," (Longformer model)"),aye.forEach(t),pwo=i(G),Z7=n(G,"LI",{});var nye=s(Z7);Gae=n(nye,"STRONG",{});var JJr=s(Gae);_wo=r(JJr,"megatron-bert"),JJr.forEach(t),uwo=r(nye," \u2014 "),Aj=n(nye,"A",{href:!0});var YJr=s(Aj);bwo=r(YJr,"MegatronBertForMultipleChoice"),YJr.forEach(t),vwo=r(nye," (MegatronBert model)"),nye.forEach(t),Two=i(G),eb=n(G,"LI",{});var sye=s(eb);Xae=n(sye,"STRONG",{});var KJr=s(Xae);Fwo=r(KJr,"mobilebert"),KJr.forEach(t),Cwo=r(sye," \u2014 "),Lj=n(sye,"A",{href:!0});var ZJr=s(Lj);Mwo=r(ZJr,"MobileBertForMultipleChoice"),ZJr.forEach(t),Ewo=r(sye," (MobileBERT model)"),sye.forEach(t),ywo=i(G),ob=n(G,"LI",{});var lye=s(ob);Vae=n(lye,"STRONG",{});var eYr=s(Vae);wwo=r(eYr,"mpnet"),eYr.forEach(t),Awo=r(lye," \u2014 "),Bj=n(lye,"A",{href:!0});var oYr=s(Bj);Lwo=r(oYr,"MPNetForMultipleChoice"),oYr.forEach(t),Bwo=r(lye," (MPNet model)"),lye.forEach(t),xwo=i(G),rb=n(G,"LI",{});var iye=s(rb);zae=n(iye,"STRONG",{});var rYr=s(zae);kwo=r(rYr,"nystromformer"),rYr.forEach(t),Rwo=r(iye," \u2014 "),xj=n(iye,"A",{href:!0});var tYr=s(xj);Swo=r(tYr,"NystromformerForMultipleChoice"),tYr.forEach(t),Pwo=r(iye," (Nystromformer model)"),iye.forEach(t),$wo=i(G),tb=n(G,"LI",{});var dye=s(tb);Wae=n(dye,"STRONG",{});var aYr=s(Wae);Iwo=r(aYr,"qdqbert"),aYr.forEach(t),jwo=r(dye," \u2014 "),kj=n(dye,"A",{href:!0});var nYr=s(kj);Dwo=r(nYr,"QDQBertForMultipleChoice"),nYr.forEach(t),Nwo=r(dye," (QDQBert model)"),dye.forEach(t),qwo=i(G),ab=n(G,"LI",{});var cye=s(ab);Qae=n(cye,"STRONG",{});var sYr=s(Qae);Owo=r(sYr,"rembert"),sYr.forEach(t),Gwo=r(cye," \u2014 "),Rj=n(cye,"A",{href:!0});var lYr=s(Rj);Xwo=r(lYr,"RemBertForMultipleChoice"),lYr.forEach(t),Vwo=r(cye," (RemBERT model)"),cye.forEach(t),zwo=i(G),nb=n(G,"LI",{});var fye=s(nb);Hae=n(fye,"STRONG",{});var iYr=s(Hae);Wwo=r(iYr,"roberta"),iYr.forEach(t),Qwo=r(fye," \u2014 "),Sj=n(fye,"A",{href:!0});var dYr=s(Sj);Hwo=r(dYr,"RobertaForMultipleChoice"),dYr.forEach(t),Uwo=r(fye," (RoBERTa model)"),fye.forEach(t),Jwo=i(G),sb=n(G,"LI",{});var mye=s(sb);Uae=n(mye,"STRONG",{});var cYr=s(Uae);Ywo=r(cYr,"roformer"),cYr.forEach(t),Kwo=r(mye," \u2014 "),Pj=n(mye,"A",{href:!0});var fYr=s(Pj);Zwo=r(fYr,"RoFormerForMultipleChoice"),fYr.forEach(t),e6o=r(mye," (RoFormer model)"),mye.forEach(t),o6o=i(G),lb=n(G,"LI",{});var gye=s(lb);Jae=n(gye,"STRONG",{});var mYr=s(Jae);r6o=r(mYr,"squeezebert"),mYr.forEach(t),t6o=r(gye," \u2014 "),$j=n(gye,"A",{href:!0});var gYr=s($j);a6o=r(gYr,"SqueezeBertForMultipleChoice"),gYr.forEach(t),n6o=r(gye," (SqueezeBERT model)"),gye.forEach(t),s6o=i(G),ib=n(G,"LI",{});var hye=s(ib);Yae=n(hye,"STRONG",{});var hYr=s(Yae);l6o=r(hYr,"xlm"),hYr.forEach(t),i6o=r(hye," \u2014 "),Ij=n(hye,"A",{href:!0});var pYr=s(Ij);d6o=r(pYr,"XLMForMultipleChoice"),pYr.forEach(t),c6o=r(hye," (XLM model)"),hye.forEach(t),f6o=i(G),db=n(G,"LI",{});var pye=s(db);Kae=n(pye,"STRONG",{});var _Yr=s(Kae);m6o=r(_Yr,"xlm-roberta"),_Yr.forEach(t),g6o=r(pye," \u2014 "),jj=n(pye,"A",{href:!0});var uYr=s(jj);h6o=r(uYr,"XLMRobertaForMultipleChoice"),uYr.forEach(t),p6o=r(pye," (XLM-RoBERTa model)"),pye.forEach(t),_6o=i(G),cb=n(G,"LI",{});var _ye=s(cb);Zae=n(_ye,"STRONG",{});var bYr=s(Zae);u6o=r(bYr,"xlm-roberta-xl"),bYr.forEach(t),b6o=r(_ye," \u2014 "),Dj=n(_ye,"A",{href:!0});var vYr=s(Dj);v6o=r(vYr,"XLMRobertaXLForMultipleChoice"),vYr.forEach(t),T6o=r(_ye," (XLM-RoBERTa-XL model)"),_ye.forEach(t),F6o=i(G),fb=n(G,"LI",{});var uye=s(fb);ene=n(uye,"STRONG",{});var TYr=s(ene);C6o=r(TYr,"xlnet"),TYr.forEach(t),M6o=r(uye," \u2014 "),Nj=n(uye,"A",{href:!0});var FYr=s(Nj);E6o=r(FYr,"XLNetForMultipleChoice"),FYr.forEach(t),y6o=r(uye," (XLNet model)"),uye.forEach(t),w6o=i(G),mb=n(G,"LI",{});var bye=s(mb);one=n(bye,"STRONG",{});var CYr=s(one);A6o=r(CYr,"yoso"),CYr.forEach(t),L6o=r(bye," \u2014 "),qj=n(bye,"A",{href:!0});var MYr=s(qj);B6o=r(MYr,"YosoForMultipleChoice"),MYr.forEach(t),x6o=r(bye," (YOSO model)"),bye.forEach(t),G.forEach(t),k6o=i(Wt),gb=n(Wt,"P",{});var vye=s(gb);R6o=r(vye,"The model is set in evaluation mode by default using "),rne=n(vye,"CODE",{});var EYr=s(rne);S6o=r(EYr,"model.eval()"),EYr.forEach(t),P6o=r(vye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tne=n(vye,"CODE",{});var yYr=s(tne);$6o=r(yYr,"model.train()"),yYr.forEach(t),vye.forEach(t),I6o=i(Wt),ane=n(Wt,"P",{});var wYr=s(ane);j6o=r(wYr,"Examples:"),wYr.forEach(t),D6o=i(Wt),m(M3.$$.fragment,Wt),Wt.forEach(t),al.forEach(t),Oxe=i(c),ud=n(c,"H2",{class:!0});var JRe=s(ud);hb=n(JRe,"A",{id:!0,class:!0,href:!0});var AYr=s(hb);nne=n(AYr,"SPAN",{});var LYr=s(nne);m(E3.$$.fragment,LYr),LYr.forEach(t),AYr.forEach(t),N6o=i(JRe),sne=n(JRe,"SPAN",{});var BYr=s(sne);q6o=r(BYr,"AutoModelForNextSentencePrediction"),BYr.forEach(t),JRe.forEach(t),Gxe=i(c),tr=n(c,"DIV",{class:!0});var sl=s(tr);m(y3.$$.fragment,sl),O6o=i(sl),bd=n(sl,"P",{});var Xz=s(bd);G6o=r(Xz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),lne=n(Xz,"CODE",{});var xYr=s(lne);X6o=r(xYr,"from_pretrained()"),xYr.forEach(t),V6o=r(Xz,"class method or the "),ine=n(Xz,"CODE",{});var kYr=s(ine);z6o=r(kYr,"from_config()"),kYr.forEach(t),W6o=r(Xz,`class
method.`),Xz.forEach(t),Q6o=i(sl),w3=n(sl,"P",{});var YRe=s(w3);H6o=r(YRe,"This class cannot be instantiated directly using "),dne=n(YRe,"CODE",{});var RYr=s(dne);U6o=r(RYr,"__init__()"),RYr.forEach(t),J6o=r(YRe," (throws an error)."),YRe.forEach(t),Y6o=i(sl),Yr=n(sl,"DIV",{class:!0});var ll=s(Yr);m(A3.$$.fragment,ll),K6o=i(ll),cne=n(ll,"P",{});var SYr=s(cne);Z6o=r(SYr,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),SYr.forEach(t),eAo=i(ll),vd=n(ll,"P",{});var Vz=s(vd);oAo=r(Vz,`Note:
Loading a model from its configuration file does `),fne=n(Vz,"STRONG",{});var PYr=s(fne);rAo=r(PYr,"not"),PYr.forEach(t),tAo=r(Vz,` load the model weights. It only affects the
model\u2019s configuration. Use `),mne=n(Vz,"CODE",{});var $Yr=s(mne);aAo=r($Yr,"from_pretrained()"),$Yr.forEach(t),nAo=r(Vz,"to load the model weights."),Vz.forEach(t),sAo=i(ll),gne=n(ll,"P",{});var IYr=s(gne);lAo=r(IYr,"Examples:"),IYr.forEach(t),iAo=i(ll),m(L3.$$.fragment,ll),ll.forEach(t),dAo=i(sl),ze=n(sl,"DIV",{class:!0});var Qt=s(ze);m(B3.$$.fragment,Qt),cAo=i(Qt),hne=n(Qt,"P",{});var jYr=s(hne);fAo=r(jYr,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),jYr.forEach(t),mAo=i(Qt),Ja=n(Qt,"P",{});var n4=s(Ja);gAo=r(n4,"The model class to instantiate is selected based on the "),pne=n(n4,"CODE",{});var DYr=s(pne);hAo=r(DYr,"model_type"),DYr.forEach(t),pAo=r(n4,` property of the config object (either
passed as an argument or loaded from `),_ne=n(n4,"CODE",{});var NYr=s(_ne);_Ao=r(NYr,"pretrained_model_name_or_path"),NYr.forEach(t),uAo=r(n4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),une=n(n4,"CODE",{});var qYr=s(une);bAo=r(qYr,"pretrained_model_name_or_path"),qYr.forEach(t),vAo=r(n4,":"),n4.forEach(t),TAo=i(Qt),da=n(Qt,"UL",{});var il=s(da);pb=n(il,"LI",{});var Tye=s(pb);bne=n(Tye,"STRONG",{});var OYr=s(bne);FAo=r(OYr,"bert"),OYr.forEach(t),CAo=r(Tye," \u2014 "),Oj=n(Tye,"A",{href:!0});var GYr=s(Oj);MAo=r(GYr,"BertForNextSentencePrediction"),GYr.forEach(t),EAo=r(Tye," (BERT model)"),Tye.forEach(t),yAo=i(il),_b=n(il,"LI",{});var Fye=s(_b);vne=n(Fye,"STRONG",{});var XYr=s(vne);wAo=r(XYr,"fnet"),XYr.forEach(t),AAo=r(Fye," \u2014 "),Gj=n(Fye,"A",{href:!0});var VYr=s(Gj);LAo=r(VYr,"FNetForNextSentencePrediction"),VYr.forEach(t),BAo=r(Fye," (FNet model)"),Fye.forEach(t),xAo=i(il),ub=n(il,"LI",{});var Cye=s(ub);Tne=n(Cye,"STRONG",{});var zYr=s(Tne);kAo=r(zYr,"megatron-bert"),zYr.forEach(t),RAo=r(Cye," \u2014 "),Xj=n(Cye,"A",{href:!0});var WYr=s(Xj);SAo=r(WYr,"MegatronBertForNextSentencePrediction"),WYr.forEach(t),PAo=r(Cye," (MegatronBert model)"),Cye.forEach(t),$Ao=i(il),bb=n(il,"LI",{});var Mye=s(bb);Fne=n(Mye,"STRONG",{});var QYr=s(Fne);IAo=r(QYr,"mobilebert"),QYr.forEach(t),jAo=r(Mye," \u2014 "),Vj=n(Mye,"A",{href:!0});var HYr=s(Vj);DAo=r(HYr,"MobileBertForNextSentencePrediction"),HYr.forEach(t),NAo=r(Mye," (MobileBERT model)"),Mye.forEach(t),qAo=i(il),vb=n(il,"LI",{});var Eye=s(vb);Cne=n(Eye,"STRONG",{});var UYr=s(Cne);OAo=r(UYr,"qdqbert"),UYr.forEach(t),GAo=r(Eye," \u2014 "),zj=n(Eye,"A",{href:!0});var JYr=s(zj);XAo=r(JYr,"QDQBertForNextSentencePrediction"),JYr.forEach(t),VAo=r(Eye," (QDQBert model)"),Eye.forEach(t),il.forEach(t),zAo=i(Qt),Tb=n(Qt,"P",{});var yye=s(Tb);WAo=r(yye,"The model is set in evaluation mode by default using "),Mne=n(yye,"CODE",{});var YYr=s(Mne);QAo=r(YYr,"model.eval()"),YYr.forEach(t),HAo=r(yye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ene=n(yye,"CODE",{});var KYr=s(Ene);UAo=r(KYr,"model.train()"),KYr.forEach(t),yye.forEach(t),JAo=i(Qt),yne=n(Qt,"P",{});var ZYr=s(yne);YAo=r(ZYr,"Examples:"),ZYr.forEach(t),KAo=i(Qt),m(x3.$$.fragment,Qt),Qt.forEach(t),sl.forEach(t),Xxe=i(c),Td=n(c,"H2",{class:!0});var KRe=s(Td);Fb=n(KRe,"A",{id:!0,class:!0,href:!0});var eKr=s(Fb);wne=n(eKr,"SPAN",{});var oKr=s(wne);m(k3.$$.fragment,oKr),oKr.forEach(t),eKr.forEach(t),ZAo=i(KRe),Ane=n(KRe,"SPAN",{});var rKr=s(Ane);eLo=r(rKr,"AutoModelForTokenClassification"),rKr.forEach(t),KRe.forEach(t),Vxe=i(c),ar=n(c,"DIV",{class:!0});var dl=s(ar);m(R3.$$.fragment,dl),oLo=i(dl),Fd=n(dl,"P",{});var zz=s(Fd);rLo=r(zz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Lne=n(zz,"CODE",{});var tKr=s(Lne);tLo=r(tKr,"from_pretrained()"),tKr.forEach(t),aLo=r(zz,"class method or the "),Bne=n(zz,"CODE",{});var aKr=s(Bne);nLo=r(aKr,"from_config()"),aKr.forEach(t),sLo=r(zz,`class
method.`),zz.forEach(t),lLo=i(dl),S3=n(dl,"P",{});var ZRe=s(S3);iLo=r(ZRe,"This class cannot be instantiated directly using "),xne=n(ZRe,"CODE",{});var nKr=s(xne);dLo=r(nKr,"__init__()"),nKr.forEach(t),cLo=r(ZRe," (throws an error)."),ZRe.forEach(t),fLo=i(dl),Kr=n(dl,"DIV",{class:!0});var cl=s(Kr);m(P3.$$.fragment,cl),mLo=i(cl),kne=n(cl,"P",{});var sKr=s(kne);gLo=r(sKr,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),sKr.forEach(t),hLo=i(cl),Cd=n(cl,"P",{});var Wz=s(Cd);pLo=r(Wz,`Note:
Loading a model from its configuration file does `),Rne=n(Wz,"STRONG",{});var lKr=s(Rne);_Lo=r(lKr,"not"),lKr.forEach(t),uLo=r(Wz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sne=n(Wz,"CODE",{});var iKr=s(Sne);bLo=r(iKr,"from_pretrained()"),iKr.forEach(t),vLo=r(Wz,"to load the model weights."),Wz.forEach(t),TLo=i(cl),Pne=n(cl,"P",{});var dKr=s(Pne);FLo=r(dKr,"Examples:"),dKr.forEach(t),CLo=i(cl),m($3.$$.fragment,cl),cl.forEach(t),MLo=i(dl),We=n(dl,"DIV",{class:!0});var Ht=s(We);m(I3.$$.fragment,Ht),ELo=i(Ht),$ne=n(Ht,"P",{});var cKr=s($ne);yLo=r(cKr,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cKr.forEach(t),wLo=i(Ht),Ya=n(Ht,"P",{});var s4=s(Ya);ALo=r(s4,"The model class to instantiate is selected based on the "),Ine=n(s4,"CODE",{});var fKr=s(Ine);LLo=r(fKr,"model_type"),fKr.forEach(t),BLo=r(s4,` property of the config object (either
passed as an argument or loaded from `),jne=n(s4,"CODE",{});var mKr=s(jne);xLo=r(mKr,"pretrained_model_name_or_path"),mKr.forEach(t),kLo=r(s4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dne=n(s4,"CODE",{});var gKr=s(Dne);RLo=r(gKr,"pretrained_model_name_or_path"),gKr.forEach(t),SLo=r(s4,":"),s4.forEach(t),PLo=i(Ht),N=n(Ht,"UL",{});var q=s(N);Cb=n(q,"LI",{});var wye=s(Cb);Nne=n(wye,"STRONG",{});var hKr=s(Nne);$Lo=r(hKr,"albert"),hKr.forEach(t),ILo=r(wye," \u2014 "),Wj=n(wye,"A",{href:!0});var pKr=s(Wj);jLo=r(pKr,"AlbertForTokenClassification"),pKr.forEach(t),DLo=r(wye," (ALBERT model)"),wye.forEach(t),NLo=i(q),Mb=n(q,"LI",{});var Aye=s(Mb);qne=n(Aye,"STRONG",{});var _Kr=s(qne);qLo=r(_Kr,"bert"),_Kr.forEach(t),OLo=r(Aye," \u2014 "),Qj=n(Aye,"A",{href:!0});var uKr=s(Qj);GLo=r(uKr,"BertForTokenClassification"),uKr.forEach(t),XLo=r(Aye," (BERT model)"),Aye.forEach(t),VLo=i(q),Eb=n(q,"LI",{});var Lye=s(Eb);One=n(Lye,"STRONG",{});var bKr=s(One);zLo=r(bKr,"big_bird"),bKr.forEach(t),WLo=r(Lye," \u2014 "),Hj=n(Lye,"A",{href:!0});var vKr=s(Hj);QLo=r(vKr,"BigBirdForTokenClassification"),vKr.forEach(t),HLo=r(Lye," (BigBird model)"),Lye.forEach(t),ULo=i(q),yb=n(q,"LI",{});var Bye=s(yb);Gne=n(Bye,"STRONG",{});var TKr=s(Gne);JLo=r(TKr,"camembert"),TKr.forEach(t),YLo=r(Bye," \u2014 "),Uj=n(Bye,"A",{href:!0});var FKr=s(Uj);KLo=r(FKr,"CamembertForTokenClassification"),FKr.forEach(t),ZLo=r(Bye," (CamemBERT model)"),Bye.forEach(t),e8o=i(q),wb=n(q,"LI",{});var xye=s(wb);Xne=n(xye,"STRONG",{});var CKr=s(Xne);o8o=r(CKr,"canine"),CKr.forEach(t),r8o=r(xye," \u2014 "),Jj=n(xye,"A",{href:!0});var MKr=s(Jj);t8o=r(MKr,"CanineForTokenClassification"),MKr.forEach(t),a8o=r(xye," (Canine model)"),xye.forEach(t),n8o=i(q),Ab=n(q,"LI",{});var kye=s(Ab);Vne=n(kye,"STRONG",{});var EKr=s(Vne);s8o=r(EKr,"convbert"),EKr.forEach(t),l8o=r(kye," \u2014 "),Yj=n(kye,"A",{href:!0});var yKr=s(Yj);i8o=r(yKr,"ConvBertForTokenClassification"),yKr.forEach(t),d8o=r(kye," (ConvBERT model)"),kye.forEach(t),c8o=i(q),Lb=n(q,"LI",{});var Rye=s(Lb);zne=n(Rye,"STRONG",{});var wKr=s(zne);f8o=r(wKr,"data2vec-text"),wKr.forEach(t),m8o=r(Rye," \u2014 "),Kj=n(Rye,"A",{href:!0});var AKr=s(Kj);g8o=r(AKr,"Data2VecTextForTokenClassification"),AKr.forEach(t),h8o=r(Rye," (Data2VecText model)"),Rye.forEach(t),p8o=i(q),Bb=n(q,"LI",{});var Sye=s(Bb);Wne=n(Sye,"STRONG",{});var LKr=s(Wne);_8o=r(LKr,"deberta"),LKr.forEach(t),u8o=r(Sye," \u2014 "),Zj=n(Sye,"A",{href:!0});var BKr=s(Zj);b8o=r(BKr,"DebertaForTokenClassification"),BKr.forEach(t),v8o=r(Sye," (DeBERTa model)"),Sye.forEach(t),T8o=i(q),xb=n(q,"LI",{});var Pye=s(xb);Qne=n(Pye,"STRONG",{});var xKr=s(Qne);F8o=r(xKr,"deberta-v2"),xKr.forEach(t),C8o=r(Pye," \u2014 "),eD=n(Pye,"A",{href:!0});var kKr=s(eD);M8o=r(kKr,"DebertaV2ForTokenClassification"),kKr.forEach(t),E8o=r(Pye," (DeBERTa-v2 model)"),Pye.forEach(t),y8o=i(q),kb=n(q,"LI",{});var $ye=s(kb);Hne=n($ye,"STRONG",{});var RKr=s(Hne);w8o=r(RKr,"distilbert"),RKr.forEach(t),A8o=r($ye," \u2014 "),oD=n($ye,"A",{href:!0});var SKr=s(oD);L8o=r(SKr,"DistilBertForTokenClassification"),SKr.forEach(t),B8o=r($ye," (DistilBERT model)"),$ye.forEach(t),x8o=i(q),Rb=n(q,"LI",{});var Iye=s(Rb);Une=n(Iye,"STRONG",{});var PKr=s(Une);k8o=r(PKr,"electra"),PKr.forEach(t),R8o=r(Iye," \u2014 "),rD=n(Iye,"A",{href:!0});var $Kr=s(rD);S8o=r($Kr,"ElectraForTokenClassification"),$Kr.forEach(t),P8o=r(Iye," (ELECTRA model)"),Iye.forEach(t),$8o=i(q),Sb=n(q,"LI",{});var jye=s(Sb);Jne=n(jye,"STRONG",{});var IKr=s(Jne);I8o=r(IKr,"flaubert"),IKr.forEach(t),j8o=r(jye," \u2014 "),tD=n(jye,"A",{href:!0});var jKr=s(tD);D8o=r(jKr,"FlaubertForTokenClassification"),jKr.forEach(t),N8o=r(jye," (FlauBERT model)"),jye.forEach(t),q8o=i(q),Pb=n(q,"LI",{});var Dye=s(Pb);Yne=n(Dye,"STRONG",{});var DKr=s(Yne);O8o=r(DKr,"fnet"),DKr.forEach(t),G8o=r(Dye," \u2014 "),aD=n(Dye,"A",{href:!0});var NKr=s(aD);X8o=r(NKr,"FNetForTokenClassification"),NKr.forEach(t),V8o=r(Dye," (FNet model)"),Dye.forEach(t),z8o=i(q),$b=n(q,"LI",{});var Nye=s($b);Kne=n(Nye,"STRONG",{});var qKr=s(Kne);W8o=r(qKr,"funnel"),qKr.forEach(t),Q8o=r(Nye," \u2014 "),nD=n(Nye,"A",{href:!0});var OKr=s(nD);H8o=r(OKr,"FunnelForTokenClassification"),OKr.forEach(t),U8o=r(Nye," (Funnel Transformer model)"),Nye.forEach(t),J8o=i(q),Ib=n(q,"LI",{});var qye=s(Ib);Zne=n(qye,"STRONG",{});var GKr=s(Zne);Y8o=r(GKr,"gpt2"),GKr.forEach(t),K8o=r(qye," \u2014 "),sD=n(qye,"A",{href:!0});var XKr=s(sD);Z8o=r(XKr,"GPT2ForTokenClassification"),XKr.forEach(t),e9o=r(qye," (OpenAI GPT-2 model)"),qye.forEach(t),o9o=i(q),jb=n(q,"LI",{});var Oye=s(jb);ese=n(Oye,"STRONG",{});var VKr=s(ese);r9o=r(VKr,"ibert"),VKr.forEach(t),t9o=r(Oye," \u2014 "),lD=n(Oye,"A",{href:!0});var zKr=s(lD);a9o=r(zKr,"IBertForTokenClassification"),zKr.forEach(t),n9o=r(Oye," (I-BERT model)"),Oye.forEach(t),s9o=i(q),Db=n(q,"LI",{});var Gye=s(Db);ose=n(Gye,"STRONG",{});var WKr=s(ose);l9o=r(WKr,"layoutlm"),WKr.forEach(t),i9o=r(Gye," \u2014 "),iD=n(Gye,"A",{href:!0});var QKr=s(iD);d9o=r(QKr,"LayoutLMForTokenClassification"),QKr.forEach(t),c9o=r(Gye," (LayoutLM model)"),Gye.forEach(t),f9o=i(q),Nb=n(q,"LI",{});var Xye=s(Nb);rse=n(Xye,"STRONG",{});var HKr=s(rse);m9o=r(HKr,"layoutlmv2"),HKr.forEach(t),g9o=r(Xye," \u2014 "),dD=n(Xye,"A",{href:!0});var UKr=s(dD);h9o=r(UKr,"LayoutLMv2ForTokenClassification"),UKr.forEach(t),p9o=r(Xye," (LayoutLMv2 model)"),Xye.forEach(t),_9o=i(q),qb=n(q,"LI",{});var Vye=s(qb);tse=n(Vye,"STRONG",{});var JKr=s(tse);u9o=r(JKr,"longformer"),JKr.forEach(t),b9o=r(Vye," \u2014 "),cD=n(Vye,"A",{href:!0});var YKr=s(cD);v9o=r(YKr,"LongformerForTokenClassification"),YKr.forEach(t),T9o=r(Vye," (Longformer model)"),Vye.forEach(t),F9o=i(q),Ob=n(q,"LI",{});var zye=s(Ob);ase=n(zye,"STRONG",{});var KKr=s(ase);C9o=r(KKr,"megatron-bert"),KKr.forEach(t),M9o=r(zye," \u2014 "),fD=n(zye,"A",{href:!0});var ZKr=s(fD);E9o=r(ZKr,"MegatronBertForTokenClassification"),ZKr.forEach(t),y9o=r(zye," (MegatronBert model)"),zye.forEach(t),w9o=i(q),Gb=n(q,"LI",{});var Wye=s(Gb);nse=n(Wye,"STRONG",{});var eZr=s(nse);A9o=r(eZr,"mobilebert"),eZr.forEach(t),L9o=r(Wye," \u2014 "),mD=n(Wye,"A",{href:!0});var oZr=s(mD);B9o=r(oZr,"MobileBertForTokenClassification"),oZr.forEach(t),x9o=r(Wye," (MobileBERT model)"),Wye.forEach(t),k9o=i(q),Xb=n(q,"LI",{});var Qye=s(Xb);sse=n(Qye,"STRONG",{});var rZr=s(sse);R9o=r(rZr,"mpnet"),rZr.forEach(t),S9o=r(Qye," \u2014 "),gD=n(Qye,"A",{href:!0});var tZr=s(gD);P9o=r(tZr,"MPNetForTokenClassification"),tZr.forEach(t),$9o=r(Qye," (MPNet model)"),Qye.forEach(t),I9o=i(q),Vb=n(q,"LI",{});var Hye=s(Vb);lse=n(Hye,"STRONG",{});var aZr=s(lse);j9o=r(aZr,"nystromformer"),aZr.forEach(t),D9o=r(Hye," \u2014 "),hD=n(Hye,"A",{href:!0});var nZr=s(hD);N9o=r(nZr,"NystromformerForTokenClassification"),nZr.forEach(t),q9o=r(Hye," (Nystromformer model)"),Hye.forEach(t),O9o=i(q),zb=n(q,"LI",{});var Uye=s(zb);ise=n(Uye,"STRONG",{});var sZr=s(ise);G9o=r(sZr,"qdqbert"),sZr.forEach(t),X9o=r(Uye," \u2014 "),pD=n(Uye,"A",{href:!0});var lZr=s(pD);V9o=r(lZr,"QDQBertForTokenClassification"),lZr.forEach(t),z9o=r(Uye," (QDQBert model)"),Uye.forEach(t),W9o=i(q),Wb=n(q,"LI",{});var Jye=s(Wb);dse=n(Jye,"STRONG",{});var iZr=s(dse);Q9o=r(iZr,"rembert"),iZr.forEach(t),H9o=r(Jye," \u2014 "),_D=n(Jye,"A",{href:!0});var dZr=s(_D);U9o=r(dZr,"RemBertForTokenClassification"),dZr.forEach(t),J9o=r(Jye," (RemBERT model)"),Jye.forEach(t),Y9o=i(q),Qb=n(q,"LI",{});var Yye=s(Qb);cse=n(Yye,"STRONG",{});var cZr=s(cse);K9o=r(cZr,"roberta"),cZr.forEach(t),Z9o=r(Yye," \u2014 "),uD=n(Yye,"A",{href:!0});var fZr=s(uD);eBo=r(fZr,"RobertaForTokenClassification"),fZr.forEach(t),oBo=r(Yye," (RoBERTa model)"),Yye.forEach(t),rBo=i(q),Hb=n(q,"LI",{});var Kye=s(Hb);fse=n(Kye,"STRONG",{});var mZr=s(fse);tBo=r(mZr,"roformer"),mZr.forEach(t),aBo=r(Kye," \u2014 "),bD=n(Kye,"A",{href:!0});var gZr=s(bD);nBo=r(gZr,"RoFormerForTokenClassification"),gZr.forEach(t),sBo=r(Kye," (RoFormer model)"),Kye.forEach(t),lBo=i(q),Ub=n(q,"LI",{});var Zye=s(Ub);mse=n(Zye,"STRONG",{});var hZr=s(mse);iBo=r(hZr,"squeezebert"),hZr.forEach(t),dBo=r(Zye," \u2014 "),vD=n(Zye,"A",{href:!0});var pZr=s(vD);cBo=r(pZr,"SqueezeBertForTokenClassification"),pZr.forEach(t),fBo=r(Zye," (SqueezeBERT model)"),Zye.forEach(t),mBo=i(q),Jb=n(q,"LI",{});var ewe=s(Jb);gse=n(ewe,"STRONG",{});var _Zr=s(gse);gBo=r(_Zr,"xlm"),_Zr.forEach(t),hBo=r(ewe," \u2014 "),TD=n(ewe,"A",{href:!0});var uZr=s(TD);pBo=r(uZr,"XLMForTokenClassification"),uZr.forEach(t),_Bo=r(ewe," (XLM model)"),ewe.forEach(t),uBo=i(q),Yb=n(q,"LI",{});var owe=s(Yb);hse=n(owe,"STRONG",{});var bZr=s(hse);bBo=r(bZr,"xlm-roberta"),bZr.forEach(t),vBo=r(owe," \u2014 "),FD=n(owe,"A",{href:!0});var vZr=s(FD);TBo=r(vZr,"XLMRobertaForTokenClassification"),vZr.forEach(t),FBo=r(owe," (XLM-RoBERTa model)"),owe.forEach(t),CBo=i(q),Kb=n(q,"LI",{});var rwe=s(Kb);pse=n(rwe,"STRONG",{});var TZr=s(pse);MBo=r(TZr,"xlm-roberta-xl"),TZr.forEach(t),EBo=r(rwe," \u2014 "),CD=n(rwe,"A",{href:!0});var FZr=s(CD);yBo=r(FZr,"XLMRobertaXLForTokenClassification"),FZr.forEach(t),wBo=r(rwe," (XLM-RoBERTa-XL model)"),rwe.forEach(t),ABo=i(q),Zb=n(q,"LI",{});var twe=s(Zb);_se=n(twe,"STRONG",{});var CZr=s(_se);LBo=r(CZr,"xlnet"),CZr.forEach(t),BBo=r(twe," \u2014 "),MD=n(twe,"A",{href:!0});var MZr=s(MD);xBo=r(MZr,"XLNetForTokenClassification"),MZr.forEach(t),kBo=r(twe," (XLNet model)"),twe.forEach(t),RBo=i(q),e5=n(q,"LI",{});var awe=s(e5);use=n(awe,"STRONG",{});var EZr=s(use);SBo=r(EZr,"yoso"),EZr.forEach(t),PBo=r(awe," \u2014 "),ED=n(awe,"A",{href:!0});var yZr=s(ED);$Bo=r(yZr,"YosoForTokenClassification"),yZr.forEach(t),IBo=r(awe," (YOSO model)"),awe.forEach(t),q.forEach(t),jBo=i(Ht),o5=n(Ht,"P",{});var nwe=s(o5);DBo=r(nwe,"The model is set in evaluation mode by default using "),bse=n(nwe,"CODE",{});var wZr=s(bse);NBo=r(wZr,"model.eval()"),wZr.forEach(t),qBo=r(nwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vse=n(nwe,"CODE",{});var AZr=s(vse);OBo=r(AZr,"model.train()"),AZr.forEach(t),nwe.forEach(t),GBo=i(Ht),Tse=n(Ht,"P",{});var LZr=s(Tse);XBo=r(LZr,"Examples:"),LZr.forEach(t),VBo=i(Ht),m(j3.$$.fragment,Ht),Ht.forEach(t),dl.forEach(t),zxe=i(c),Md=n(c,"H2",{class:!0});var eSe=s(Md);r5=n(eSe,"A",{id:!0,class:!0,href:!0});var BZr=s(r5);Fse=n(BZr,"SPAN",{});var xZr=s(Fse);m(D3.$$.fragment,xZr),xZr.forEach(t),BZr.forEach(t),zBo=i(eSe),Cse=n(eSe,"SPAN",{});var kZr=s(Cse);WBo=r(kZr,"AutoModelForQuestionAnswering"),kZr.forEach(t),eSe.forEach(t),Wxe=i(c),nr=n(c,"DIV",{class:!0});var fl=s(nr);m(N3.$$.fragment,fl),QBo=i(fl),Ed=n(fl,"P",{});var Qz=s(Ed);HBo=r(Qz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Mse=n(Qz,"CODE",{});var RZr=s(Mse);UBo=r(RZr,"from_pretrained()"),RZr.forEach(t),JBo=r(Qz,"class method or the "),Ese=n(Qz,"CODE",{});var SZr=s(Ese);YBo=r(SZr,"from_config()"),SZr.forEach(t),KBo=r(Qz,`class
method.`),Qz.forEach(t),ZBo=i(fl),q3=n(fl,"P",{});var oSe=s(q3);exo=r(oSe,"This class cannot be instantiated directly using "),yse=n(oSe,"CODE",{});var PZr=s(yse);oxo=r(PZr,"__init__()"),PZr.forEach(t),rxo=r(oSe," (throws an error)."),oSe.forEach(t),txo=i(fl),Zr=n(fl,"DIV",{class:!0});var ml=s(Zr);m(O3.$$.fragment,ml),axo=i(ml),wse=n(ml,"P",{});var $Zr=s(wse);nxo=r($Zr,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),$Zr.forEach(t),sxo=i(ml),yd=n(ml,"P",{});var Hz=s(yd);lxo=r(Hz,`Note:
Loading a model from its configuration file does `),Ase=n(Hz,"STRONG",{});var IZr=s(Ase);ixo=r(IZr,"not"),IZr.forEach(t),dxo=r(Hz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lse=n(Hz,"CODE",{});var jZr=s(Lse);cxo=r(jZr,"from_pretrained()"),jZr.forEach(t),fxo=r(Hz,"to load the model weights."),Hz.forEach(t),mxo=i(ml),Bse=n(ml,"P",{});var DZr=s(Bse);gxo=r(DZr,"Examples:"),DZr.forEach(t),hxo=i(ml),m(G3.$$.fragment,ml),ml.forEach(t),pxo=i(fl),Qe=n(fl,"DIV",{class:!0});var Ut=s(Qe);m(X3.$$.fragment,Ut),_xo=i(Ut),xse=n(Ut,"P",{});var NZr=s(xse);uxo=r(NZr,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),NZr.forEach(t),bxo=i(Ut),Ka=n(Ut,"P",{});var l4=s(Ka);vxo=r(l4,"The model class to instantiate is selected based on the "),kse=n(l4,"CODE",{});var qZr=s(kse);Txo=r(qZr,"model_type"),qZr.forEach(t),Fxo=r(l4,` property of the config object (either
passed as an argument or loaded from `),Rse=n(l4,"CODE",{});var OZr=s(Rse);Cxo=r(OZr,"pretrained_model_name_or_path"),OZr.forEach(t),Mxo=r(l4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sse=n(l4,"CODE",{});var GZr=s(Sse);Exo=r(GZr,"pretrained_model_name_or_path"),GZr.forEach(t),yxo=r(l4,":"),l4.forEach(t),wxo=i(Ut),R=n(Ut,"UL",{});var P=s(R);t5=n(P,"LI",{});var swe=s(t5);Pse=n(swe,"STRONG",{});var XZr=s(Pse);Axo=r(XZr,"albert"),XZr.forEach(t),Lxo=r(swe," \u2014 "),yD=n(swe,"A",{href:!0});var VZr=s(yD);Bxo=r(VZr,"AlbertForQuestionAnswering"),VZr.forEach(t),xxo=r(swe," (ALBERT model)"),swe.forEach(t),kxo=i(P),a5=n(P,"LI",{});var lwe=s(a5);$se=n(lwe,"STRONG",{});var zZr=s($se);Rxo=r(zZr,"bart"),zZr.forEach(t),Sxo=r(lwe," \u2014 "),wD=n(lwe,"A",{href:!0});var WZr=s(wD);Pxo=r(WZr,"BartForQuestionAnswering"),WZr.forEach(t),$xo=r(lwe," (BART model)"),lwe.forEach(t),Ixo=i(P),n5=n(P,"LI",{});var iwe=s(n5);Ise=n(iwe,"STRONG",{});var QZr=s(Ise);jxo=r(QZr,"bert"),QZr.forEach(t),Dxo=r(iwe," \u2014 "),AD=n(iwe,"A",{href:!0});var HZr=s(AD);Nxo=r(HZr,"BertForQuestionAnswering"),HZr.forEach(t),qxo=r(iwe," (BERT model)"),iwe.forEach(t),Oxo=i(P),s5=n(P,"LI",{});var dwe=s(s5);jse=n(dwe,"STRONG",{});var UZr=s(jse);Gxo=r(UZr,"big_bird"),UZr.forEach(t),Xxo=r(dwe," \u2014 "),LD=n(dwe,"A",{href:!0});var JZr=s(LD);Vxo=r(JZr,"BigBirdForQuestionAnswering"),JZr.forEach(t),zxo=r(dwe," (BigBird model)"),dwe.forEach(t),Wxo=i(P),l5=n(P,"LI",{});var cwe=s(l5);Dse=n(cwe,"STRONG",{});var YZr=s(Dse);Qxo=r(YZr,"bigbird_pegasus"),YZr.forEach(t),Hxo=r(cwe," \u2014 "),BD=n(cwe,"A",{href:!0});var KZr=s(BD);Uxo=r(KZr,"BigBirdPegasusForQuestionAnswering"),KZr.forEach(t),Jxo=r(cwe," (BigBirdPegasus model)"),cwe.forEach(t),Yxo=i(P),i5=n(P,"LI",{});var fwe=s(i5);Nse=n(fwe,"STRONG",{});var ZZr=s(Nse);Kxo=r(ZZr,"camembert"),ZZr.forEach(t),Zxo=r(fwe," \u2014 "),xD=n(fwe,"A",{href:!0});var eet=s(xD);eko=r(eet,"CamembertForQuestionAnswering"),eet.forEach(t),oko=r(fwe," (CamemBERT model)"),fwe.forEach(t),rko=i(P),d5=n(P,"LI",{});var mwe=s(d5);qse=n(mwe,"STRONG",{});var oet=s(qse);tko=r(oet,"canine"),oet.forEach(t),ako=r(mwe," \u2014 "),kD=n(mwe,"A",{href:!0});var ret=s(kD);nko=r(ret,"CanineForQuestionAnswering"),ret.forEach(t),sko=r(mwe," (Canine model)"),mwe.forEach(t),lko=i(P),c5=n(P,"LI",{});var gwe=s(c5);Ose=n(gwe,"STRONG",{});var tet=s(Ose);iko=r(tet,"convbert"),tet.forEach(t),dko=r(gwe," \u2014 "),RD=n(gwe,"A",{href:!0});var aet=s(RD);cko=r(aet,"ConvBertForQuestionAnswering"),aet.forEach(t),fko=r(gwe," (ConvBERT model)"),gwe.forEach(t),mko=i(P),f5=n(P,"LI",{});var hwe=s(f5);Gse=n(hwe,"STRONG",{});var net=s(Gse);gko=r(net,"data2vec-text"),net.forEach(t),hko=r(hwe," \u2014 "),SD=n(hwe,"A",{href:!0});var set=s(SD);pko=r(set,"Data2VecTextForQuestionAnswering"),set.forEach(t),_ko=r(hwe," (Data2VecText model)"),hwe.forEach(t),uko=i(P),m5=n(P,"LI",{});var pwe=s(m5);Xse=n(pwe,"STRONG",{});var iet=s(Xse);bko=r(iet,"deberta"),iet.forEach(t),vko=r(pwe," \u2014 "),PD=n(pwe,"A",{href:!0});var det=s(PD);Tko=r(det,"DebertaForQuestionAnswering"),det.forEach(t),Fko=r(pwe," (DeBERTa model)"),pwe.forEach(t),Cko=i(P),g5=n(P,"LI",{});var _we=s(g5);Vse=n(_we,"STRONG",{});var cet=s(Vse);Mko=r(cet,"deberta-v2"),cet.forEach(t),Eko=r(_we," \u2014 "),$D=n(_we,"A",{href:!0});var fet=s($D);yko=r(fet,"DebertaV2ForQuestionAnswering"),fet.forEach(t),wko=r(_we," (DeBERTa-v2 model)"),_we.forEach(t),Ako=i(P),h5=n(P,"LI",{});var uwe=s(h5);zse=n(uwe,"STRONG",{});var met=s(zse);Lko=r(met,"distilbert"),met.forEach(t),Bko=r(uwe," \u2014 "),ID=n(uwe,"A",{href:!0});var get=s(ID);xko=r(get,"DistilBertForQuestionAnswering"),get.forEach(t),kko=r(uwe," (DistilBERT model)"),uwe.forEach(t),Rko=i(P),p5=n(P,"LI",{});var bwe=s(p5);Wse=n(bwe,"STRONG",{});var het=s(Wse);Sko=r(het,"electra"),het.forEach(t),Pko=r(bwe," \u2014 "),jD=n(bwe,"A",{href:!0});var pet=s(jD);$ko=r(pet,"ElectraForQuestionAnswering"),pet.forEach(t),Iko=r(bwe," (ELECTRA model)"),bwe.forEach(t),jko=i(P),_5=n(P,"LI",{});var vwe=s(_5);Qse=n(vwe,"STRONG",{});var _et=s(Qse);Dko=r(_et,"flaubert"),_et.forEach(t),Nko=r(vwe," \u2014 "),DD=n(vwe,"A",{href:!0});var uet=s(DD);qko=r(uet,"FlaubertForQuestionAnsweringSimple"),uet.forEach(t),Oko=r(vwe," (FlauBERT model)"),vwe.forEach(t),Gko=i(P),u5=n(P,"LI",{});var Twe=s(u5);Hse=n(Twe,"STRONG",{});var bet=s(Hse);Xko=r(bet,"fnet"),bet.forEach(t),Vko=r(Twe," \u2014 "),ND=n(Twe,"A",{href:!0});var vet=s(ND);zko=r(vet,"FNetForQuestionAnswering"),vet.forEach(t),Wko=r(Twe," (FNet model)"),Twe.forEach(t),Qko=i(P),b5=n(P,"LI",{});var Fwe=s(b5);Use=n(Fwe,"STRONG",{});var Tet=s(Use);Hko=r(Tet,"funnel"),Tet.forEach(t),Uko=r(Fwe," \u2014 "),qD=n(Fwe,"A",{href:!0});var Fet=s(qD);Jko=r(Fet,"FunnelForQuestionAnswering"),Fet.forEach(t),Yko=r(Fwe," (Funnel Transformer model)"),Fwe.forEach(t),Kko=i(P),v5=n(P,"LI",{});var Cwe=s(v5);Jse=n(Cwe,"STRONG",{});var Cet=s(Jse);Zko=r(Cet,"gptj"),Cet.forEach(t),eRo=r(Cwe," \u2014 "),OD=n(Cwe,"A",{href:!0});var Met=s(OD);oRo=r(Met,"GPTJForQuestionAnswering"),Met.forEach(t),rRo=r(Cwe," (GPT-J model)"),Cwe.forEach(t),tRo=i(P),T5=n(P,"LI",{});var Mwe=s(T5);Yse=n(Mwe,"STRONG",{});var Eet=s(Yse);aRo=r(Eet,"ibert"),Eet.forEach(t),nRo=r(Mwe," \u2014 "),GD=n(Mwe,"A",{href:!0});var yet=s(GD);sRo=r(yet,"IBertForQuestionAnswering"),yet.forEach(t),lRo=r(Mwe," (I-BERT model)"),Mwe.forEach(t),iRo=i(P),F5=n(P,"LI",{});var Ewe=s(F5);Kse=n(Ewe,"STRONG",{});var wet=s(Kse);dRo=r(wet,"layoutlmv2"),wet.forEach(t),cRo=r(Ewe," \u2014 "),XD=n(Ewe,"A",{href:!0});var Aet=s(XD);fRo=r(Aet,"LayoutLMv2ForQuestionAnswering"),Aet.forEach(t),mRo=r(Ewe," (LayoutLMv2 model)"),Ewe.forEach(t),gRo=i(P),C5=n(P,"LI",{});var ywe=s(C5);Zse=n(ywe,"STRONG",{});var Let=s(Zse);hRo=r(Let,"led"),Let.forEach(t),pRo=r(ywe," \u2014 "),VD=n(ywe,"A",{href:!0});var Bet=s(VD);_Ro=r(Bet,"LEDForQuestionAnswering"),Bet.forEach(t),uRo=r(ywe," (LED model)"),ywe.forEach(t),bRo=i(P),M5=n(P,"LI",{});var wwe=s(M5);ele=n(wwe,"STRONG",{});var xet=s(ele);vRo=r(xet,"longformer"),xet.forEach(t),TRo=r(wwe," \u2014 "),zD=n(wwe,"A",{href:!0});var ket=s(zD);FRo=r(ket,"LongformerForQuestionAnswering"),ket.forEach(t),CRo=r(wwe," (Longformer model)"),wwe.forEach(t),MRo=i(P),E5=n(P,"LI",{});var Awe=s(E5);ole=n(Awe,"STRONG",{});var Ret=s(ole);ERo=r(Ret,"lxmert"),Ret.forEach(t),yRo=r(Awe," \u2014 "),WD=n(Awe,"A",{href:!0});var Set=s(WD);wRo=r(Set,"LxmertForQuestionAnswering"),Set.forEach(t),ARo=r(Awe," (LXMERT model)"),Awe.forEach(t),LRo=i(P),y5=n(P,"LI",{});var Lwe=s(y5);rle=n(Lwe,"STRONG",{});var Pet=s(rle);BRo=r(Pet,"mbart"),Pet.forEach(t),xRo=r(Lwe," \u2014 "),QD=n(Lwe,"A",{href:!0});var $et=s(QD);kRo=r($et,"MBartForQuestionAnswering"),$et.forEach(t),RRo=r(Lwe," (mBART model)"),Lwe.forEach(t),SRo=i(P),w5=n(P,"LI",{});var Bwe=s(w5);tle=n(Bwe,"STRONG",{});var Iet=s(tle);PRo=r(Iet,"megatron-bert"),Iet.forEach(t),$Ro=r(Bwe," \u2014 "),HD=n(Bwe,"A",{href:!0});var jet=s(HD);IRo=r(jet,"MegatronBertForQuestionAnswering"),jet.forEach(t),jRo=r(Bwe," (MegatronBert model)"),Bwe.forEach(t),DRo=i(P),A5=n(P,"LI",{});var xwe=s(A5);ale=n(xwe,"STRONG",{});var Det=s(ale);NRo=r(Det,"mobilebert"),Det.forEach(t),qRo=r(xwe," \u2014 "),UD=n(xwe,"A",{href:!0});var Net=s(UD);ORo=r(Net,"MobileBertForQuestionAnswering"),Net.forEach(t),GRo=r(xwe," (MobileBERT model)"),xwe.forEach(t),XRo=i(P),L5=n(P,"LI",{});var kwe=s(L5);nle=n(kwe,"STRONG",{});var qet=s(nle);VRo=r(qet,"mpnet"),qet.forEach(t),zRo=r(kwe," \u2014 "),JD=n(kwe,"A",{href:!0});var Oet=s(JD);WRo=r(Oet,"MPNetForQuestionAnswering"),Oet.forEach(t),QRo=r(kwe," (MPNet model)"),kwe.forEach(t),HRo=i(P),B5=n(P,"LI",{});var Rwe=s(B5);sle=n(Rwe,"STRONG",{});var Get=s(sle);URo=r(Get,"nystromformer"),Get.forEach(t),JRo=r(Rwe," \u2014 "),YD=n(Rwe,"A",{href:!0});var Xet=s(YD);YRo=r(Xet,"NystromformerForQuestionAnswering"),Xet.forEach(t),KRo=r(Rwe," (Nystromformer model)"),Rwe.forEach(t),ZRo=i(P),x5=n(P,"LI",{});var Swe=s(x5);lle=n(Swe,"STRONG",{});var Vet=s(lle);eSo=r(Vet,"qdqbert"),Vet.forEach(t),oSo=r(Swe," \u2014 "),KD=n(Swe,"A",{href:!0});var zet=s(KD);rSo=r(zet,"QDQBertForQuestionAnswering"),zet.forEach(t),tSo=r(Swe," (QDQBert model)"),Swe.forEach(t),aSo=i(P),k5=n(P,"LI",{});var Pwe=s(k5);ile=n(Pwe,"STRONG",{});var Wet=s(ile);nSo=r(Wet,"reformer"),Wet.forEach(t),sSo=r(Pwe," \u2014 "),ZD=n(Pwe,"A",{href:!0});var Qet=s(ZD);lSo=r(Qet,"ReformerForQuestionAnswering"),Qet.forEach(t),iSo=r(Pwe," (Reformer model)"),Pwe.forEach(t),dSo=i(P),R5=n(P,"LI",{});var $we=s(R5);dle=n($we,"STRONG",{});var Het=s(dle);cSo=r(Het,"rembert"),Het.forEach(t),fSo=r($we," \u2014 "),eN=n($we,"A",{href:!0});var Uet=s(eN);mSo=r(Uet,"RemBertForQuestionAnswering"),Uet.forEach(t),gSo=r($we," (RemBERT model)"),$we.forEach(t),hSo=i(P),S5=n(P,"LI",{});var Iwe=s(S5);cle=n(Iwe,"STRONG",{});var Jet=s(cle);pSo=r(Jet,"roberta"),Jet.forEach(t),_So=r(Iwe," \u2014 "),oN=n(Iwe,"A",{href:!0});var Yet=s(oN);uSo=r(Yet,"RobertaForQuestionAnswering"),Yet.forEach(t),bSo=r(Iwe," (RoBERTa model)"),Iwe.forEach(t),vSo=i(P),P5=n(P,"LI",{});var jwe=s(P5);fle=n(jwe,"STRONG",{});var Ket=s(fle);TSo=r(Ket,"roformer"),Ket.forEach(t),FSo=r(jwe," \u2014 "),rN=n(jwe,"A",{href:!0});var Zet=s(rN);CSo=r(Zet,"RoFormerForQuestionAnswering"),Zet.forEach(t),MSo=r(jwe," (RoFormer model)"),jwe.forEach(t),ESo=i(P),$5=n(P,"LI",{});var Dwe=s($5);mle=n(Dwe,"STRONG",{});var eot=s(mle);ySo=r(eot,"splinter"),eot.forEach(t),wSo=r(Dwe," \u2014 "),tN=n(Dwe,"A",{href:!0});var oot=s(tN);ASo=r(oot,"SplinterForQuestionAnswering"),oot.forEach(t),LSo=r(Dwe," (Splinter model)"),Dwe.forEach(t),BSo=i(P),I5=n(P,"LI",{});var Nwe=s(I5);gle=n(Nwe,"STRONG",{});var rot=s(gle);xSo=r(rot,"squeezebert"),rot.forEach(t),kSo=r(Nwe," \u2014 "),aN=n(Nwe,"A",{href:!0});var tot=s(aN);RSo=r(tot,"SqueezeBertForQuestionAnswering"),tot.forEach(t),SSo=r(Nwe," (SqueezeBERT model)"),Nwe.forEach(t),PSo=i(P),j5=n(P,"LI",{});var qwe=s(j5);hle=n(qwe,"STRONG",{});var aot=s(hle);$So=r(aot,"xlm"),aot.forEach(t),ISo=r(qwe," \u2014 "),nN=n(qwe,"A",{href:!0});var not=s(nN);jSo=r(not,"XLMForQuestionAnsweringSimple"),not.forEach(t),DSo=r(qwe," (XLM model)"),qwe.forEach(t),NSo=i(P),D5=n(P,"LI",{});var Owe=s(D5);ple=n(Owe,"STRONG",{});var sot=s(ple);qSo=r(sot,"xlm-roberta"),sot.forEach(t),OSo=r(Owe," \u2014 "),sN=n(Owe,"A",{href:!0});var lot=s(sN);GSo=r(lot,"XLMRobertaForQuestionAnswering"),lot.forEach(t),XSo=r(Owe," (XLM-RoBERTa model)"),Owe.forEach(t),VSo=i(P),N5=n(P,"LI",{});var Gwe=s(N5);_le=n(Gwe,"STRONG",{});var iot=s(_le);zSo=r(iot,"xlm-roberta-xl"),iot.forEach(t),WSo=r(Gwe," \u2014 "),lN=n(Gwe,"A",{href:!0});var dot=s(lN);QSo=r(dot,"XLMRobertaXLForQuestionAnswering"),dot.forEach(t),HSo=r(Gwe," (XLM-RoBERTa-XL model)"),Gwe.forEach(t),USo=i(P),q5=n(P,"LI",{});var Xwe=s(q5);ule=n(Xwe,"STRONG",{});var cot=s(ule);JSo=r(cot,"xlnet"),cot.forEach(t),YSo=r(Xwe," \u2014 "),iN=n(Xwe,"A",{href:!0});var fot=s(iN);KSo=r(fot,"XLNetForQuestionAnsweringSimple"),fot.forEach(t),ZSo=r(Xwe," (XLNet model)"),Xwe.forEach(t),ePo=i(P),O5=n(P,"LI",{});var Vwe=s(O5);ble=n(Vwe,"STRONG",{});var mot=s(ble);oPo=r(mot,"yoso"),mot.forEach(t),rPo=r(Vwe," \u2014 "),dN=n(Vwe,"A",{href:!0});var got=s(dN);tPo=r(got,"YosoForQuestionAnswering"),got.forEach(t),aPo=r(Vwe," (YOSO model)"),Vwe.forEach(t),P.forEach(t),nPo=i(Ut),G5=n(Ut,"P",{});var zwe=s(G5);sPo=r(zwe,"The model is set in evaluation mode by default using "),vle=n(zwe,"CODE",{});var hot=s(vle);lPo=r(hot,"model.eval()"),hot.forEach(t),iPo=r(zwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tle=n(zwe,"CODE",{});var pot=s(Tle);dPo=r(pot,"model.train()"),pot.forEach(t),zwe.forEach(t),cPo=i(Ut),Fle=n(Ut,"P",{});var _ot=s(Fle);fPo=r(_ot,"Examples:"),_ot.forEach(t),mPo=i(Ut),m(V3.$$.fragment,Ut),Ut.forEach(t),fl.forEach(t),Qxe=i(c),wd=n(c,"H2",{class:!0});var rSe=s(wd);X5=n(rSe,"A",{id:!0,class:!0,href:!0});var uot=s(X5);Cle=n(uot,"SPAN",{});var bot=s(Cle);m(z3.$$.fragment,bot),bot.forEach(t),uot.forEach(t),gPo=i(rSe),Mle=n(rSe,"SPAN",{});var vot=s(Mle);hPo=r(vot,"AutoModelForTableQuestionAnswering"),vot.forEach(t),rSe.forEach(t),Hxe=i(c),sr=n(c,"DIV",{class:!0});var gl=s(sr);m(W3.$$.fragment,gl),pPo=i(gl),Ad=n(gl,"P",{});var Uz=s(Ad);_Po=r(Uz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Ele=n(Uz,"CODE",{});var Tot=s(Ele);uPo=r(Tot,"from_pretrained()"),Tot.forEach(t),bPo=r(Uz,"class method or the "),yle=n(Uz,"CODE",{});var Fot=s(yle);vPo=r(Fot,"from_config()"),Fot.forEach(t),TPo=r(Uz,`class
method.`),Uz.forEach(t),FPo=i(gl),Q3=n(gl,"P",{});var tSe=s(Q3);CPo=r(tSe,"This class cannot be instantiated directly using "),wle=n(tSe,"CODE",{});var Cot=s(wle);MPo=r(Cot,"__init__()"),Cot.forEach(t),EPo=r(tSe," (throws an error)."),tSe.forEach(t),yPo=i(gl),et=n(gl,"DIV",{class:!0});var hl=s(et);m(H3.$$.fragment,hl),wPo=i(hl),Ale=n(hl,"P",{});var Mot=s(Ale);APo=r(Mot,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Mot.forEach(t),LPo=i(hl),Ld=n(hl,"P",{});var Jz=s(Ld);BPo=r(Jz,`Note:
Loading a model from its configuration file does `),Lle=n(Jz,"STRONG",{});var Eot=s(Lle);xPo=r(Eot,"not"),Eot.forEach(t),kPo=r(Jz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ble=n(Jz,"CODE",{});var yot=s(Ble);RPo=r(yot,"from_pretrained()"),yot.forEach(t),SPo=r(Jz,"to load the model weights."),Jz.forEach(t),PPo=i(hl),xle=n(hl,"P",{});var wot=s(xle);$Po=r(wot,"Examples:"),wot.forEach(t),IPo=i(hl),m(U3.$$.fragment,hl),hl.forEach(t),jPo=i(gl),He=n(gl,"DIV",{class:!0});var Jt=s(He);m(J3.$$.fragment,Jt),DPo=i(Jt),kle=n(Jt,"P",{});var Aot=s(kle);NPo=r(Aot,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Aot.forEach(t),qPo=i(Jt),Za=n(Jt,"P",{});var i4=s(Za);OPo=r(i4,"The model class to instantiate is selected based on the "),Rle=n(i4,"CODE",{});var Lot=s(Rle);GPo=r(Lot,"model_type"),Lot.forEach(t),XPo=r(i4,` property of the config object (either
passed as an argument or loaded from `),Sle=n(i4,"CODE",{});var Bot=s(Sle);VPo=r(Bot,"pretrained_model_name_or_path"),Bot.forEach(t),zPo=r(i4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ple=n(i4,"CODE",{});var xot=s(Ple);WPo=r(xot,"pretrained_model_name_or_path"),xot.forEach(t),QPo=r(i4,":"),i4.forEach(t),HPo=i(Jt),$le=n(Jt,"UL",{});var kot=s($le);V5=n(kot,"LI",{});var Wwe=s(V5);Ile=n(Wwe,"STRONG",{});var Rot=s(Ile);UPo=r(Rot,"tapas"),Rot.forEach(t),JPo=r(Wwe," \u2014 "),cN=n(Wwe,"A",{href:!0});var Sot=s(cN);YPo=r(Sot,"TapasForQuestionAnswering"),Sot.forEach(t),KPo=r(Wwe," (TAPAS model)"),Wwe.forEach(t),kot.forEach(t),ZPo=i(Jt),z5=n(Jt,"P",{});var Qwe=s(z5);e$o=r(Qwe,"The model is set in evaluation mode by default using "),jle=n(Qwe,"CODE",{});var Pot=s(jle);o$o=r(Pot,"model.eval()"),Pot.forEach(t),r$o=r(Qwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dle=n(Qwe,"CODE",{});var $ot=s(Dle);t$o=r($ot,"model.train()"),$ot.forEach(t),Qwe.forEach(t),a$o=i(Jt),Nle=n(Jt,"P",{});var Iot=s(Nle);n$o=r(Iot,"Examples:"),Iot.forEach(t),s$o=i(Jt),m(Y3.$$.fragment,Jt),Jt.forEach(t),gl.forEach(t),Uxe=i(c),Bd=n(c,"H2",{class:!0});var aSe=s(Bd);W5=n(aSe,"A",{id:!0,class:!0,href:!0});var jot=s(W5);qle=n(jot,"SPAN",{});var Dot=s(qle);m(K3.$$.fragment,Dot),Dot.forEach(t),jot.forEach(t),l$o=i(aSe),Ole=n(aSe,"SPAN",{});var Not=s(Ole);i$o=r(Not,"AutoModelForImageClassification"),Not.forEach(t),aSe.forEach(t),Jxe=i(c),lr=n(c,"DIV",{class:!0});var pl=s(lr);m(Z3.$$.fragment,pl),d$o=i(pl),xd=n(pl,"P",{});var Yz=s(xd);c$o=r(Yz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Gle=n(Yz,"CODE",{});var qot=s(Gle);f$o=r(qot,"from_pretrained()"),qot.forEach(t),m$o=r(Yz,"class method or the "),Xle=n(Yz,"CODE",{});var Oot=s(Xle);g$o=r(Oot,"from_config()"),Oot.forEach(t),h$o=r(Yz,`class
method.`),Yz.forEach(t),p$o=i(pl),ey=n(pl,"P",{});var nSe=s(ey);_$o=r(nSe,"This class cannot be instantiated directly using "),Vle=n(nSe,"CODE",{});var Got=s(Vle);u$o=r(Got,"__init__()"),Got.forEach(t),b$o=r(nSe," (throws an error)."),nSe.forEach(t),v$o=i(pl),ot=n(pl,"DIV",{class:!0});var _l=s(ot);m(oy.$$.fragment,_l),T$o=i(_l),zle=n(_l,"P",{});var Xot=s(zle);F$o=r(Xot,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Xot.forEach(t),C$o=i(_l),kd=n(_l,"P",{});var Kz=s(kd);M$o=r(Kz,`Note:
Loading a model from its configuration file does `),Wle=n(Kz,"STRONG",{});var Vot=s(Wle);E$o=r(Vot,"not"),Vot.forEach(t),y$o=r(Kz,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qle=n(Kz,"CODE",{});var zot=s(Qle);w$o=r(zot,"from_pretrained()"),zot.forEach(t),A$o=r(Kz,"to load the model weights."),Kz.forEach(t),L$o=i(_l),Hle=n(_l,"P",{});var Wot=s(Hle);B$o=r(Wot,"Examples:"),Wot.forEach(t),x$o=i(_l),m(ry.$$.fragment,_l),_l.forEach(t),k$o=i(pl),Ue=n(pl,"DIV",{class:!0});var Yt=s(Ue);m(ty.$$.fragment,Yt),R$o=i(Yt),Ule=n(Yt,"P",{});var Qot=s(Ule);S$o=r(Qot,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Qot.forEach(t),P$o=i(Yt),en=n(Yt,"P",{});var d4=s(en);$$o=r(d4,"The model class to instantiate is selected based on the "),Jle=n(d4,"CODE",{});var Hot=s(Jle);I$o=r(Hot,"model_type"),Hot.forEach(t),j$o=r(d4,` property of the config object (either
passed as an argument or loaded from `),Yle=n(d4,"CODE",{});var Uot=s(Yle);D$o=r(Uot,"pretrained_model_name_or_path"),Uot.forEach(t),N$o=r(d4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kle=n(d4,"CODE",{});var Jot=s(Kle);q$o=r(Jot,"pretrained_model_name_or_path"),Jot.forEach(t),O$o=r(d4,":"),d4.forEach(t),G$o=i(Yt),pe=n(Yt,"UL",{});var Me=s(pe);Q5=n(Me,"LI",{});var Hwe=s(Q5);Zle=n(Hwe,"STRONG",{});var Yot=s(Zle);X$o=r(Yot,"beit"),Yot.forEach(t),V$o=r(Hwe," \u2014 "),fN=n(Hwe,"A",{href:!0});var Kot=s(fN);z$o=r(Kot,"BeitForImageClassification"),Kot.forEach(t),W$o=r(Hwe," (BEiT model)"),Hwe.forEach(t),Q$o=i(Me),H5=n(Me,"LI",{});var Uwe=s(H5);eie=n(Uwe,"STRONG",{});var Zot=s(eie);H$o=r(Zot,"convnext"),Zot.forEach(t),U$o=r(Uwe," \u2014 "),mN=n(Uwe,"A",{href:!0});var ert=s(mN);J$o=r(ert,"ConvNextForImageClassification"),ert.forEach(t),Y$o=r(Uwe," (ConvNext model)"),Uwe.forEach(t),K$o=i(Me),qs=n(Me,"LI",{});var q8=s(qs);oie=n(q8,"STRONG",{});var ort=s(oie);Z$o=r(ort,"deit"),ort.forEach(t),eIo=r(q8," \u2014 "),gN=n(q8,"A",{href:!0});var rrt=s(gN);oIo=r(rrt,"DeiTForImageClassification"),rrt.forEach(t),rIo=r(q8," or "),hN=n(q8,"A",{href:!0});var trt=s(hN);tIo=r(trt,"DeiTForImageClassificationWithTeacher"),trt.forEach(t),aIo=r(q8," (DeiT model)"),q8.forEach(t),nIo=i(Me),U5=n(Me,"LI",{});var Jwe=s(U5);rie=n(Jwe,"STRONG",{});var art=s(rie);sIo=r(art,"imagegpt"),art.forEach(t),lIo=r(Jwe," \u2014 "),pN=n(Jwe,"A",{href:!0});var nrt=s(pN);iIo=r(nrt,"ImageGPTForImageClassification"),nrt.forEach(t),dIo=r(Jwe," (ImageGPT model)"),Jwe.forEach(t),cIo=i(Me),fa=n(Me,"LI",{});var Pf=s(fa);tie=n(Pf,"STRONG",{});var srt=s(tie);fIo=r(srt,"perceiver"),srt.forEach(t),mIo=r(Pf," \u2014 "),_N=n(Pf,"A",{href:!0});var lrt=s(_N);gIo=r(lrt,"PerceiverForImageClassificationLearned"),lrt.forEach(t),hIo=r(Pf," or "),uN=n(Pf,"A",{href:!0});var irt=s(uN);pIo=r(irt,"PerceiverForImageClassificationFourier"),irt.forEach(t),_Io=r(Pf," or "),bN=n(Pf,"A",{href:!0});var drt=s(bN);uIo=r(drt,"PerceiverForImageClassificationConvProcessing"),drt.forEach(t),bIo=r(Pf," (Perceiver model)"),Pf.forEach(t),vIo=i(Me),J5=n(Me,"LI",{});var Ywe=s(J5);aie=n(Ywe,"STRONG",{});var crt=s(aie);TIo=r(crt,"poolformer"),crt.forEach(t),FIo=r(Ywe," \u2014 "),vN=n(Ywe,"A",{href:!0});var frt=s(vN);CIo=r(frt,"PoolFormerForImageClassification"),frt.forEach(t),MIo=r(Ywe," (PoolFormer model)"),Ywe.forEach(t),EIo=i(Me),Y5=n(Me,"LI",{});var Kwe=s(Y5);nie=n(Kwe,"STRONG",{});var mrt=s(nie);yIo=r(mrt,"resnet"),mrt.forEach(t),wIo=r(Kwe," \u2014 "),TN=n(Kwe,"A",{href:!0});var grt=s(TN);AIo=r(grt,"ResNetForImageClassification"),grt.forEach(t),LIo=r(Kwe," (ResNet model)"),Kwe.forEach(t),BIo=i(Me),K5=n(Me,"LI",{});var Zwe=s(K5);sie=n(Zwe,"STRONG",{});var hrt=s(sie);xIo=r(hrt,"segformer"),hrt.forEach(t),kIo=r(Zwe," \u2014 "),FN=n(Zwe,"A",{href:!0});var prt=s(FN);RIo=r(prt,"SegformerForImageClassification"),prt.forEach(t),SIo=r(Zwe," (SegFormer model)"),Zwe.forEach(t),PIo=i(Me),Z5=n(Me,"LI",{});var e6e=s(Z5);lie=n(e6e,"STRONG",{});var _rt=s(lie);$Io=r(_rt,"swin"),_rt.forEach(t),IIo=r(e6e," \u2014 "),CN=n(e6e,"A",{href:!0});var urt=s(CN);jIo=r(urt,"SwinForImageClassification"),urt.forEach(t),DIo=r(e6e," (Swin model)"),e6e.forEach(t),NIo=i(Me),e2=n(Me,"LI",{});var o6e=s(e2);iie=n(o6e,"STRONG",{});var brt=s(iie);qIo=r(brt,"vit"),brt.forEach(t),OIo=r(o6e," \u2014 "),MN=n(o6e,"A",{href:!0});var vrt=s(MN);GIo=r(vrt,"ViTForImageClassification"),vrt.forEach(t),XIo=r(o6e," (ViT model)"),o6e.forEach(t),Me.forEach(t),VIo=i(Yt),o2=n(Yt,"P",{});var r6e=s(o2);zIo=r(r6e,"The model is set in evaluation mode by default using "),die=n(r6e,"CODE",{});var Trt=s(die);WIo=r(Trt,"model.eval()"),Trt.forEach(t),QIo=r(r6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cie=n(r6e,"CODE",{});var Frt=s(cie);HIo=r(Frt,"model.train()"),Frt.forEach(t),r6e.forEach(t),UIo=i(Yt),fie=n(Yt,"P",{});var Crt=s(fie);JIo=r(Crt,"Examples:"),Crt.forEach(t),YIo=i(Yt),m(ay.$$.fragment,Yt),Yt.forEach(t),pl.forEach(t),Yxe=i(c),Rd=n(c,"H2",{class:!0});var sSe=s(Rd);r2=n(sSe,"A",{id:!0,class:!0,href:!0});var Mrt=s(r2);mie=n(Mrt,"SPAN",{});var Ert=s(mie);m(ny.$$.fragment,Ert),Ert.forEach(t),Mrt.forEach(t),KIo=i(sSe),gie=n(sSe,"SPAN",{});var yrt=s(gie);ZIo=r(yrt,"AutoModelForVision2Seq"),yrt.forEach(t),sSe.forEach(t),Kxe=i(c),ir=n(c,"DIV",{class:!0});var ul=s(ir);m(sy.$$.fragment,ul),ejo=i(ul),Sd=n(ul,"P",{});var Zz=s(Sd);ojo=r(Zz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hie=n(Zz,"CODE",{});var wrt=s(hie);rjo=r(wrt,"from_pretrained()"),wrt.forEach(t),tjo=r(Zz,"class method or the "),pie=n(Zz,"CODE",{});var Art=s(pie);ajo=r(Art,"from_config()"),Art.forEach(t),njo=r(Zz,`class
method.`),Zz.forEach(t),sjo=i(ul),ly=n(ul,"P",{});var lSe=s(ly);ljo=r(lSe,"This class cannot be instantiated directly using "),_ie=n(lSe,"CODE",{});var Lrt=s(_ie);ijo=r(Lrt,"__init__()"),Lrt.forEach(t),djo=r(lSe," (throws an error)."),lSe.forEach(t),cjo=i(ul),rt=n(ul,"DIV",{class:!0});var bl=s(rt);m(iy.$$.fragment,bl),fjo=i(bl),uie=n(bl,"P",{});var Brt=s(uie);mjo=r(Brt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Brt.forEach(t),gjo=i(bl),Pd=n(bl,"P",{});var eW=s(Pd);hjo=r(eW,`Note:
Loading a model from its configuration file does `),bie=n(eW,"STRONG",{});var xrt=s(bie);pjo=r(xrt,"not"),xrt.forEach(t),_jo=r(eW,` load the model weights. It only affects the
model\u2019s configuration. Use `),vie=n(eW,"CODE",{});var krt=s(vie);ujo=r(krt,"from_pretrained()"),krt.forEach(t),bjo=r(eW,"to load the model weights."),eW.forEach(t),vjo=i(bl),Tie=n(bl,"P",{});var Rrt=s(Tie);Tjo=r(Rrt,"Examples:"),Rrt.forEach(t),Fjo=i(bl),m(dy.$$.fragment,bl),bl.forEach(t),Cjo=i(ul),Je=n(ul,"DIV",{class:!0});var Kt=s(Je);m(cy.$$.fragment,Kt),Mjo=i(Kt),Fie=n(Kt,"P",{});var Srt=s(Fie);Ejo=r(Srt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Srt.forEach(t),yjo=i(Kt),on=n(Kt,"P",{});var c4=s(on);wjo=r(c4,"The model class to instantiate is selected based on the "),Cie=n(c4,"CODE",{});var Prt=s(Cie);Ajo=r(Prt,"model_type"),Prt.forEach(t),Ljo=r(c4,` property of the config object (either
passed as an argument or loaded from `),Mie=n(c4,"CODE",{});var $rt=s(Mie);Bjo=r($rt,"pretrained_model_name_or_path"),$rt.forEach(t),xjo=r(c4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Eie=n(c4,"CODE",{});var Irt=s(Eie);kjo=r(Irt,"pretrained_model_name_or_path"),Irt.forEach(t),Rjo=r(c4,":"),c4.forEach(t),Sjo=i(Kt),yie=n(Kt,"UL",{});var jrt=s(yie);t2=n(jrt,"LI",{});var t6e=s(t2);wie=n(t6e,"STRONG",{});var Drt=s(wie);Pjo=r(Drt,"vision-encoder-decoder"),Drt.forEach(t),$jo=r(t6e," \u2014 "),EN=n(t6e,"A",{href:!0});var Nrt=s(EN);Ijo=r(Nrt,"VisionEncoderDecoderModel"),Nrt.forEach(t),jjo=r(t6e," (Vision Encoder decoder model)"),t6e.forEach(t),jrt.forEach(t),Djo=i(Kt),a2=n(Kt,"P",{});var a6e=s(a2);Njo=r(a6e,"The model is set in evaluation mode by default using "),Aie=n(a6e,"CODE",{});var qrt=s(Aie);qjo=r(qrt,"model.eval()"),qrt.forEach(t),Ojo=r(a6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lie=n(a6e,"CODE",{});var Ort=s(Lie);Gjo=r(Ort,"model.train()"),Ort.forEach(t),a6e.forEach(t),Xjo=i(Kt),Bie=n(Kt,"P",{});var Grt=s(Bie);Vjo=r(Grt,"Examples:"),Grt.forEach(t),zjo=i(Kt),m(fy.$$.fragment,Kt),Kt.forEach(t),ul.forEach(t),Zxe=i(c),$d=n(c,"H2",{class:!0});var iSe=s($d);n2=n(iSe,"A",{id:!0,class:!0,href:!0});var Xrt=s(n2);xie=n(Xrt,"SPAN",{});var Vrt=s(xie);m(my.$$.fragment,Vrt),Vrt.forEach(t),Xrt.forEach(t),Wjo=i(iSe),kie=n(iSe,"SPAN",{});var zrt=s(kie);Qjo=r(zrt,"AutoModelForAudioClassification"),zrt.forEach(t),iSe.forEach(t),eke=i(c),dr=n(c,"DIV",{class:!0});var vl=s(dr);m(gy.$$.fragment,vl),Hjo=i(vl),Id=n(vl,"P",{});var oW=s(Id);Ujo=r(oW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Rie=n(oW,"CODE",{});var Wrt=s(Rie);Jjo=r(Wrt,"from_pretrained()"),Wrt.forEach(t),Yjo=r(oW,"class method or the "),Sie=n(oW,"CODE",{});var Qrt=s(Sie);Kjo=r(Qrt,"from_config()"),Qrt.forEach(t),Zjo=r(oW,`class
method.`),oW.forEach(t),eDo=i(vl),hy=n(vl,"P",{});var dSe=s(hy);oDo=r(dSe,"This class cannot be instantiated directly using "),Pie=n(dSe,"CODE",{});var Hrt=s(Pie);rDo=r(Hrt,"__init__()"),Hrt.forEach(t),tDo=r(dSe," (throws an error)."),dSe.forEach(t),aDo=i(vl),tt=n(vl,"DIV",{class:!0});var Tl=s(tt);m(py.$$.fragment,Tl),nDo=i(Tl),$ie=n(Tl,"P",{});var Urt=s($ie);sDo=r(Urt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Urt.forEach(t),lDo=i(Tl),jd=n(Tl,"P",{});var rW=s(jd);iDo=r(rW,`Note:
Loading a model from its configuration file does `),Iie=n(rW,"STRONG",{});var Jrt=s(Iie);dDo=r(Jrt,"not"),Jrt.forEach(t),cDo=r(rW,` load the model weights. It only affects the
model\u2019s configuration. Use `),jie=n(rW,"CODE",{});var Yrt=s(jie);fDo=r(Yrt,"from_pretrained()"),Yrt.forEach(t),mDo=r(rW,"to load the model weights."),rW.forEach(t),gDo=i(Tl),Die=n(Tl,"P",{});var Krt=s(Die);hDo=r(Krt,"Examples:"),Krt.forEach(t),pDo=i(Tl),m(_y.$$.fragment,Tl),Tl.forEach(t),_Do=i(vl),Ye=n(vl,"DIV",{class:!0});var Zt=s(Ye);m(uy.$$.fragment,Zt),uDo=i(Zt),Nie=n(Zt,"P",{});var Zrt=s(Nie);bDo=r(Zrt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Zrt.forEach(t),vDo=i(Zt),rn=n(Zt,"P",{});var f4=s(rn);TDo=r(f4,"The model class to instantiate is selected based on the "),qie=n(f4,"CODE",{});var ett=s(qie);FDo=r(ett,"model_type"),ett.forEach(t),CDo=r(f4,` property of the config object (either
passed as an argument or loaded from `),Oie=n(f4,"CODE",{});var ott=s(Oie);MDo=r(ott,"pretrained_model_name_or_path"),ott.forEach(t),EDo=r(f4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gie=n(f4,"CODE",{});var rtt=s(Gie);yDo=r(rtt,"pretrained_model_name_or_path"),rtt.forEach(t),wDo=r(f4,":"),f4.forEach(t),ADo=i(Zt),ke=n(Zt,"UL",{});var qo=s(ke);s2=n(qo,"LI",{});var n6e=s(s2);Xie=n(n6e,"STRONG",{});var ttt=s(Xie);LDo=r(ttt,"data2vec-audio"),ttt.forEach(t),BDo=r(n6e," \u2014 "),yN=n(n6e,"A",{href:!0});var att=s(yN);xDo=r(att,"Data2VecAudioForSequenceClassification"),att.forEach(t),kDo=r(n6e," (Data2VecAudio model)"),n6e.forEach(t),RDo=i(qo),l2=n(qo,"LI",{});var s6e=s(l2);Vie=n(s6e,"STRONG",{});var ntt=s(Vie);SDo=r(ntt,"hubert"),ntt.forEach(t),PDo=r(s6e," \u2014 "),wN=n(s6e,"A",{href:!0});var stt=s(wN);$Do=r(stt,"HubertForSequenceClassification"),stt.forEach(t),IDo=r(s6e," (Hubert model)"),s6e.forEach(t),jDo=i(qo),i2=n(qo,"LI",{});var l6e=s(i2);zie=n(l6e,"STRONG",{});var ltt=s(zie);DDo=r(ltt,"sew"),ltt.forEach(t),NDo=r(l6e," \u2014 "),AN=n(l6e,"A",{href:!0});var itt=s(AN);qDo=r(itt,"SEWForSequenceClassification"),itt.forEach(t),ODo=r(l6e," (SEW model)"),l6e.forEach(t),GDo=i(qo),d2=n(qo,"LI",{});var i6e=s(d2);Wie=n(i6e,"STRONG",{});var dtt=s(Wie);XDo=r(dtt,"sew-d"),dtt.forEach(t),VDo=r(i6e," \u2014 "),LN=n(i6e,"A",{href:!0});var ctt=s(LN);zDo=r(ctt,"SEWDForSequenceClassification"),ctt.forEach(t),WDo=r(i6e," (SEW-D model)"),i6e.forEach(t),QDo=i(qo),c2=n(qo,"LI",{});var d6e=s(c2);Qie=n(d6e,"STRONG",{});var ftt=s(Qie);HDo=r(ftt,"unispeech"),ftt.forEach(t),UDo=r(d6e," \u2014 "),BN=n(d6e,"A",{href:!0});var mtt=s(BN);JDo=r(mtt,"UniSpeechForSequenceClassification"),mtt.forEach(t),YDo=r(d6e," (UniSpeech model)"),d6e.forEach(t),KDo=i(qo),f2=n(qo,"LI",{});var c6e=s(f2);Hie=n(c6e,"STRONG",{});var gtt=s(Hie);ZDo=r(gtt,"unispeech-sat"),gtt.forEach(t),eNo=r(c6e," \u2014 "),xN=n(c6e,"A",{href:!0});var htt=s(xN);oNo=r(htt,"UniSpeechSatForSequenceClassification"),htt.forEach(t),rNo=r(c6e," (UniSpeechSat model)"),c6e.forEach(t),tNo=i(qo),m2=n(qo,"LI",{});var f6e=s(m2);Uie=n(f6e,"STRONG",{});var ptt=s(Uie);aNo=r(ptt,"wav2vec2"),ptt.forEach(t),nNo=r(f6e," \u2014 "),kN=n(f6e,"A",{href:!0});var _tt=s(kN);sNo=r(_tt,"Wav2Vec2ForSequenceClassification"),_tt.forEach(t),lNo=r(f6e," (Wav2Vec2 model)"),f6e.forEach(t),iNo=i(qo),g2=n(qo,"LI",{});var m6e=s(g2);Jie=n(m6e,"STRONG",{});var utt=s(Jie);dNo=r(utt,"wavlm"),utt.forEach(t),cNo=r(m6e," \u2014 "),RN=n(m6e,"A",{href:!0});var btt=s(RN);fNo=r(btt,"WavLMForSequenceClassification"),btt.forEach(t),mNo=r(m6e," (WavLM model)"),m6e.forEach(t),qo.forEach(t),gNo=i(Zt),h2=n(Zt,"P",{});var g6e=s(h2);hNo=r(g6e,"The model is set in evaluation mode by default using "),Yie=n(g6e,"CODE",{});var vtt=s(Yie);pNo=r(vtt,"model.eval()"),vtt.forEach(t),_No=r(g6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kie=n(g6e,"CODE",{});var Ttt=s(Kie);uNo=r(Ttt,"model.train()"),Ttt.forEach(t),g6e.forEach(t),bNo=i(Zt),Zie=n(Zt,"P",{});var Ftt=s(Zie);vNo=r(Ftt,"Examples:"),Ftt.forEach(t),TNo=i(Zt),m(by.$$.fragment,Zt),Zt.forEach(t),vl.forEach(t),oke=i(c),Dd=n(c,"H2",{class:!0});var cSe=s(Dd);p2=n(cSe,"A",{id:!0,class:!0,href:!0});var Ctt=s(p2);ede=n(Ctt,"SPAN",{});var Mtt=s(ede);m(vy.$$.fragment,Mtt),Mtt.forEach(t),Ctt.forEach(t),FNo=i(cSe),ode=n(cSe,"SPAN",{});var Ett=s(ode);CNo=r(Ett,"AutoModelForAudioFrameClassification"),Ett.forEach(t),cSe.forEach(t),rke=i(c),cr=n(c,"DIV",{class:!0});var Fl=s(cr);m(Ty.$$.fragment,Fl),MNo=i(Fl),Nd=n(Fl,"P",{});var tW=s(Nd);ENo=r(tW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),rde=n(tW,"CODE",{});var ytt=s(rde);yNo=r(ytt,"from_pretrained()"),ytt.forEach(t),wNo=r(tW,"class method or the "),tde=n(tW,"CODE",{});var wtt=s(tde);ANo=r(wtt,"from_config()"),wtt.forEach(t),LNo=r(tW,`class
method.`),tW.forEach(t),BNo=i(Fl),Fy=n(Fl,"P",{});var fSe=s(Fy);xNo=r(fSe,"This class cannot be instantiated directly using "),ade=n(fSe,"CODE",{});var Att=s(ade);kNo=r(Att,"__init__()"),Att.forEach(t),RNo=r(fSe," (throws an error)."),fSe.forEach(t),SNo=i(Fl),at=n(Fl,"DIV",{class:!0});var Cl=s(at);m(Cy.$$.fragment,Cl),PNo=i(Cl),nde=n(Cl,"P",{});var Ltt=s(nde);$No=r(Ltt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Ltt.forEach(t),INo=i(Cl),qd=n(Cl,"P",{});var aW=s(qd);jNo=r(aW,`Note:
Loading a model from its configuration file does `),sde=n(aW,"STRONG",{});var Btt=s(sde);DNo=r(Btt,"not"),Btt.forEach(t),NNo=r(aW,` load the model weights. It only affects the
model\u2019s configuration. Use `),lde=n(aW,"CODE",{});var xtt=s(lde);qNo=r(xtt,"from_pretrained()"),xtt.forEach(t),ONo=r(aW,"to load the model weights."),aW.forEach(t),GNo=i(Cl),ide=n(Cl,"P",{});var ktt=s(ide);XNo=r(ktt,"Examples:"),ktt.forEach(t),VNo=i(Cl),m(My.$$.fragment,Cl),Cl.forEach(t),zNo=i(Fl),Ke=n(Fl,"DIV",{class:!0});var ea=s(Ke);m(Ey.$$.fragment,ea),WNo=i(ea),dde=n(ea,"P",{});var Rtt=s(dde);QNo=r(Rtt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Rtt.forEach(t),HNo=i(ea),tn=n(ea,"P",{});var m4=s(tn);UNo=r(m4,"The model class to instantiate is selected based on the "),cde=n(m4,"CODE",{});var Stt=s(cde);JNo=r(Stt,"model_type"),Stt.forEach(t),YNo=r(m4,` property of the config object (either
passed as an argument or loaded from `),fde=n(m4,"CODE",{});var Ptt=s(fde);KNo=r(Ptt,"pretrained_model_name_or_path"),Ptt.forEach(t),ZNo=r(m4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mde=n(m4,"CODE",{});var $tt=s(mde);eqo=r($tt,"pretrained_model_name_or_path"),$tt.forEach(t),oqo=r(m4,":"),m4.forEach(t),rqo=i(ea),an=n(ea,"UL",{});var g4=s(an);_2=n(g4,"LI",{});var h6e=s(_2);gde=n(h6e,"STRONG",{});var Itt=s(gde);tqo=r(Itt,"data2vec-audio"),Itt.forEach(t),aqo=r(h6e," \u2014 "),SN=n(h6e,"A",{href:!0});var jtt=s(SN);nqo=r(jtt,"Data2VecAudioForAudioFrameClassification"),jtt.forEach(t),sqo=r(h6e," (Data2VecAudio model)"),h6e.forEach(t),lqo=i(g4),u2=n(g4,"LI",{});var p6e=s(u2);hde=n(p6e,"STRONG",{});var Dtt=s(hde);iqo=r(Dtt,"unispeech-sat"),Dtt.forEach(t),dqo=r(p6e," \u2014 "),PN=n(p6e,"A",{href:!0});var Ntt=s(PN);cqo=r(Ntt,"UniSpeechSatForAudioFrameClassification"),Ntt.forEach(t),fqo=r(p6e," (UniSpeechSat model)"),p6e.forEach(t),mqo=i(g4),b2=n(g4,"LI",{});var _6e=s(b2);pde=n(_6e,"STRONG",{});var qtt=s(pde);gqo=r(qtt,"wav2vec2"),qtt.forEach(t),hqo=r(_6e," \u2014 "),$N=n(_6e,"A",{href:!0});var Ott=s($N);pqo=r(Ott,"Wav2Vec2ForAudioFrameClassification"),Ott.forEach(t),_qo=r(_6e," (Wav2Vec2 model)"),_6e.forEach(t),uqo=i(g4),v2=n(g4,"LI",{});var u6e=s(v2);_de=n(u6e,"STRONG",{});var Gtt=s(_de);bqo=r(Gtt,"wavlm"),Gtt.forEach(t),vqo=r(u6e," \u2014 "),IN=n(u6e,"A",{href:!0});var Xtt=s(IN);Tqo=r(Xtt,"WavLMForAudioFrameClassification"),Xtt.forEach(t),Fqo=r(u6e," (WavLM model)"),u6e.forEach(t),g4.forEach(t),Cqo=i(ea),T2=n(ea,"P",{});var b6e=s(T2);Mqo=r(b6e,"The model is set in evaluation mode by default using "),ude=n(b6e,"CODE",{});var Vtt=s(ude);Eqo=r(Vtt,"model.eval()"),Vtt.forEach(t),yqo=r(b6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bde=n(b6e,"CODE",{});var ztt=s(bde);wqo=r(ztt,"model.train()"),ztt.forEach(t),b6e.forEach(t),Aqo=i(ea),vde=n(ea,"P",{});var Wtt=s(vde);Lqo=r(Wtt,"Examples:"),Wtt.forEach(t),Bqo=i(ea),m(yy.$$.fragment,ea),ea.forEach(t),Fl.forEach(t),tke=i(c),Od=n(c,"H2",{class:!0});var mSe=s(Od);F2=n(mSe,"A",{id:!0,class:!0,href:!0});var Qtt=s(F2);Tde=n(Qtt,"SPAN",{});var Htt=s(Tde);m(wy.$$.fragment,Htt),Htt.forEach(t),Qtt.forEach(t),xqo=i(mSe),Fde=n(mSe,"SPAN",{});var Utt=s(Fde);kqo=r(Utt,"AutoModelForCTC"),Utt.forEach(t),mSe.forEach(t),ake=i(c),fr=n(c,"DIV",{class:!0});var Ml=s(fr);m(Ay.$$.fragment,Ml),Rqo=i(Ml),Gd=n(Ml,"P",{});var nW=s(Gd);Sqo=r(nW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Cde=n(nW,"CODE",{});var Jtt=s(Cde);Pqo=r(Jtt,"from_pretrained()"),Jtt.forEach(t),$qo=r(nW,"class method or the "),Mde=n(nW,"CODE",{});var Ytt=s(Mde);Iqo=r(Ytt,"from_config()"),Ytt.forEach(t),jqo=r(nW,`class
method.`),nW.forEach(t),Dqo=i(Ml),Ly=n(Ml,"P",{});var gSe=s(Ly);Nqo=r(gSe,"This class cannot be instantiated directly using "),Ede=n(gSe,"CODE",{});var Ktt=s(Ede);qqo=r(Ktt,"__init__()"),Ktt.forEach(t),Oqo=r(gSe," (throws an error)."),gSe.forEach(t),Gqo=i(Ml),nt=n(Ml,"DIV",{class:!0});var El=s(nt);m(By.$$.fragment,El),Xqo=i(El),yde=n(El,"P",{});var Ztt=s(yde);Vqo=r(Ztt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Ztt.forEach(t),zqo=i(El),Xd=n(El,"P",{});var sW=s(Xd);Wqo=r(sW,`Note:
Loading a model from its configuration file does `),wde=n(sW,"STRONG",{});var eat=s(wde);Qqo=r(eat,"not"),eat.forEach(t),Hqo=r(sW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ade=n(sW,"CODE",{});var oat=s(Ade);Uqo=r(oat,"from_pretrained()"),oat.forEach(t),Jqo=r(sW,"to load the model weights."),sW.forEach(t),Yqo=i(El),Lde=n(El,"P",{});var rat=s(Lde);Kqo=r(rat,"Examples:"),rat.forEach(t),Zqo=i(El),m(xy.$$.fragment,El),El.forEach(t),eOo=i(Ml),Ze=n(Ml,"DIV",{class:!0});var oa=s(Ze);m(ky.$$.fragment,oa),oOo=i(oa),Bde=n(oa,"P",{});var tat=s(Bde);rOo=r(tat,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),tat.forEach(t),tOo=i(oa),nn=n(oa,"P",{});var h4=s(nn);aOo=r(h4,"The model class to instantiate is selected based on the "),xde=n(h4,"CODE",{});var aat=s(xde);nOo=r(aat,"model_type"),aat.forEach(t),sOo=r(h4,` property of the config object (either
passed as an argument or loaded from `),kde=n(h4,"CODE",{});var nat=s(kde);lOo=r(nat,"pretrained_model_name_or_path"),nat.forEach(t),iOo=r(h4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rde=n(h4,"CODE",{});var sat=s(Rde);dOo=r(sat,"pretrained_model_name_or_path"),sat.forEach(t),cOo=r(h4,":"),h4.forEach(t),fOo=i(oa),Re=n(oa,"UL",{});var Oo=s(Re);C2=n(Oo,"LI",{});var v6e=s(C2);Sde=n(v6e,"STRONG",{});var lat=s(Sde);mOo=r(lat,"data2vec-audio"),lat.forEach(t),gOo=r(v6e," \u2014 "),jN=n(v6e,"A",{href:!0});var iat=s(jN);hOo=r(iat,"Data2VecAudioForCTC"),iat.forEach(t),pOo=r(v6e," (Data2VecAudio model)"),v6e.forEach(t),_Oo=i(Oo),M2=n(Oo,"LI",{});var T6e=s(M2);Pde=n(T6e,"STRONG",{});var dat=s(Pde);uOo=r(dat,"hubert"),dat.forEach(t),bOo=r(T6e," \u2014 "),DN=n(T6e,"A",{href:!0});var cat=s(DN);vOo=r(cat,"HubertForCTC"),cat.forEach(t),TOo=r(T6e," (Hubert model)"),T6e.forEach(t),FOo=i(Oo),E2=n(Oo,"LI",{});var F6e=s(E2);$de=n(F6e,"STRONG",{});var fat=s($de);COo=r(fat,"sew"),fat.forEach(t),MOo=r(F6e," \u2014 "),NN=n(F6e,"A",{href:!0});var mat=s(NN);EOo=r(mat,"SEWForCTC"),mat.forEach(t),yOo=r(F6e," (SEW model)"),F6e.forEach(t),wOo=i(Oo),y2=n(Oo,"LI",{});var C6e=s(y2);Ide=n(C6e,"STRONG",{});var gat=s(Ide);AOo=r(gat,"sew-d"),gat.forEach(t),LOo=r(C6e," \u2014 "),qN=n(C6e,"A",{href:!0});var hat=s(qN);BOo=r(hat,"SEWDForCTC"),hat.forEach(t),xOo=r(C6e," (SEW-D model)"),C6e.forEach(t),kOo=i(Oo),w2=n(Oo,"LI",{});var M6e=s(w2);jde=n(M6e,"STRONG",{});var pat=s(jde);ROo=r(pat,"unispeech"),pat.forEach(t),SOo=r(M6e," \u2014 "),ON=n(M6e,"A",{href:!0});var _at=s(ON);POo=r(_at,"UniSpeechForCTC"),_at.forEach(t),$Oo=r(M6e," (UniSpeech model)"),M6e.forEach(t),IOo=i(Oo),A2=n(Oo,"LI",{});var E6e=s(A2);Dde=n(E6e,"STRONG",{});var uat=s(Dde);jOo=r(uat,"unispeech-sat"),uat.forEach(t),DOo=r(E6e," \u2014 "),GN=n(E6e,"A",{href:!0});var bat=s(GN);NOo=r(bat,"UniSpeechSatForCTC"),bat.forEach(t),qOo=r(E6e," (UniSpeechSat model)"),E6e.forEach(t),OOo=i(Oo),L2=n(Oo,"LI",{});var y6e=s(L2);Nde=n(y6e,"STRONG",{});var vat=s(Nde);GOo=r(vat,"wav2vec2"),vat.forEach(t),XOo=r(y6e," \u2014 "),XN=n(y6e,"A",{href:!0});var Tat=s(XN);VOo=r(Tat,"Wav2Vec2ForCTC"),Tat.forEach(t),zOo=r(y6e," (Wav2Vec2 model)"),y6e.forEach(t),WOo=i(Oo),B2=n(Oo,"LI",{});var w6e=s(B2);qde=n(w6e,"STRONG",{});var Fat=s(qde);QOo=r(Fat,"wavlm"),Fat.forEach(t),HOo=r(w6e," \u2014 "),VN=n(w6e,"A",{href:!0});var Cat=s(VN);UOo=r(Cat,"WavLMForCTC"),Cat.forEach(t),JOo=r(w6e," (WavLM model)"),w6e.forEach(t),Oo.forEach(t),YOo=i(oa),x2=n(oa,"P",{});var A6e=s(x2);KOo=r(A6e,"The model is set in evaluation mode by default using "),Ode=n(A6e,"CODE",{});var Mat=s(Ode);ZOo=r(Mat,"model.eval()"),Mat.forEach(t),eGo=r(A6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gde=n(A6e,"CODE",{});var Eat=s(Gde);oGo=r(Eat,"model.train()"),Eat.forEach(t),A6e.forEach(t),rGo=i(oa),Xde=n(oa,"P",{});var yat=s(Xde);tGo=r(yat,"Examples:"),yat.forEach(t),aGo=i(oa),m(Ry.$$.fragment,oa),oa.forEach(t),Ml.forEach(t),nke=i(c),Vd=n(c,"H2",{class:!0});var hSe=s(Vd);k2=n(hSe,"A",{id:!0,class:!0,href:!0});var wat=s(k2);Vde=n(wat,"SPAN",{});var Aat=s(Vde);m(Sy.$$.fragment,Aat),Aat.forEach(t),wat.forEach(t),nGo=i(hSe),zde=n(hSe,"SPAN",{});var Lat=s(zde);sGo=r(Lat,"AutoModelForSpeechSeq2Seq"),Lat.forEach(t),hSe.forEach(t),ske=i(c),mr=n(c,"DIV",{class:!0});var yl=s(mr);m(Py.$$.fragment,yl),lGo=i(yl),zd=n(yl,"P",{});var lW=s(zd);iGo=r(lW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Wde=n(lW,"CODE",{});var Bat=s(Wde);dGo=r(Bat,"from_pretrained()"),Bat.forEach(t),cGo=r(lW,"class method or the "),Qde=n(lW,"CODE",{});var xat=s(Qde);fGo=r(xat,"from_config()"),xat.forEach(t),mGo=r(lW,`class
method.`),lW.forEach(t),gGo=i(yl),$y=n(yl,"P",{});var pSe=s($y);hGo=r(pSe,"This class cannot be instantiated directly using "),Hde=n(pSe,"CODE",{});var kat=s(Hde);pGo=r(kat,"__init__()"),kat.forEach(t),_Go=r(pSe," (throws an error)."),pSe.forEach(t),uGo=i(yl),st=n(yl,"DIV",{class:!0});var wl=s(st);m(Iy.$$.fragment,wl),bGo=i(wl),Ude=n(wl,"P",{});var Rat=s(Ude);vGo=r(Rat,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Rat.forEach(t),TGo=i(wl),Wd=n(wl,"P",{});var iW=s(Wd);FGo=r(iW,`Note:
Loading a model from its configuration file does `),Jde=n(iW,"STRONG",{});var Sat=s(Jde);CGo=r(Sat,"not"),Sat.forEach(t),MGo=r(iW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yde=n(iW,"CODE",{});var Pat=s(Yde);EGo=r(Pat,"from_pretrained()"),Pat.forEach(t),yGo=r(iW,"to load the model weights."),iW.forEach(t),wGo=i(wl),Kde=n(wl,"P",{});var $at=s(Kde);AGo=r($at,"Examples:"),$at.forEach(t),LGo=i(wl),m(jy.$$.fragment,wl),wl.forEach(t),BGo=i(yl),eo=n(yl,"DIV",{class:!0});var ra=s(eo);m(Dy.$$.fragment,ra),xGo=i(ra),Zde=n(ra,"P",{});var Iat=s(Zde);kGo=r(Iat,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Iat.forEach(t),RGo=i(ra),sn=n(ra,"P",{});var p4=s(sn);SGo=r(p4,"The model class to instantiate is selected based on the "),ece=n(p4,"CODE",{});var jat=s(ece);PGo=r(jat,"model_type"),jat.forEach(t),$Go=r(p4,` property of the config object (either
passed as an argument or loaded from `),oce=n(p4,"CODE",{});var Dat=s(oce);IGo=r(Dat,"pretrained_model_name_or_path"),Dat.forEach(t),jGo=r(p4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rce=n(p4,"CODE",{});var Nat=s(rce);DGo=r(Nat,"pretrained_model_name_or_path"),Nat.forEach(t),NGo=r(p4,":"),p4.forEach(t),qGo=i(ra),Ny=n(ra,"UL",{});var _Se=s(Ny);R2=n(_Se,"LI",{});var L6e=s(R2);tce=n(L6e,"STRONG",{});var qat=s(tce);OGo=r(qat,"speech-encoder-decoder"),qat.forEach(t),GGo=r(L6e," \u2014 "),zN=n(L6e,"A",{href:!0});var Oat=s(zN);XGo=r(Oat,"SpeechEncoderDecoderModel"),Oat.forEach(t),VGo=r(L6e," (Speech Encoder decoder model)"),L6e.forEach(t),zGo=i(_Se),S2=n(_Se,"LI",{});var B6e=s(S2);ace=n(B6e,"STRONG",{});var Gat=s(ace);WGo=r(Gat,"speech_to_text"),Gat.forEach(t),QGo=r(B6e," \u2014 "),WN=n(B6e,"A",{href:!0});var Xat=s(WN);HGo=r(Xat,"Speech2TextForConditionalGeneration"),Xat.forEach(t),UGo=r(B6e," (Speech2Text model)"),B6e.forEach(t),_Se.forEach(t),JGo=i(ra),P2=n(ra,"P",{});var x6e=s(P2);YGo=r(x6e,"The model is set in evaluation mode by default using "),nce=n(x6e,"CODE",{});var Vat=s(nce);KGo=r(Vat,"model.eval()"),Vat.forEach(t),ZGo=r(x6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sce=n(x6e,"CODE",{});var zat=s(sce);eXo=r(zat,"model.train()"),zat.forEach(t),x6e.forEach(t),oXo=i(ra),lce=n(ra,"P",{});var Wat=s(lce);rXo=r(Wat,"Examples:"),Wat.forEach(t),tXo=i(ra),m(qy.$$.fragment,ra),ra.forEach(t),yl.forEach(t),lke=i(c),Qd=n(c,"H2",{class:!0});var uSe=s(Qd);$2=n(uSe,"A",{id:!0,class:!0,href:!0});var Qat=s($2);ice=n(Qat,"SPAN",{});var Hat=s(ice);m(Oy.$$.fragment,Hat),Hat.forEach(t),Qat.forEach(t),aXo=i(uSe),dce=n(uSe,"SPAN",{});var Uat=s(dce);nXo=r(Uat,"AutoModelForAudioXVector"),Uat.forEach(t),uSe.forEach(t),ike=i(c),gr=n(c,"DIV",{class:!0});var Al=s(gr);m(Gy.$$.fragment,Al),sXo=i(Al),Hd=n(Al,"P",{});var dW=s(Hd);lXo=r(dW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),cce=n(dW,"CODE",{});var Jat=s(cce);iXo=r(Jat,"from_pretrained()"),Jat.forEach(t),dXo=r(dW,"class method or the "),fce=n(dW,"CODE",{});var Yat=s(fce);cXo=r(Yat,"from_config()"),Yat.forEach(t),fXo=r(dW,`class
method.`),dW.forEach(t),mXo=i(Al),Xy=n(Al,"P",{});var bSe=s(Xy);gXo=r(bSe,"This class cannot be instantiated directly using "),mce=n(bSe,"CODE",{});var Kat=s(mce);hXo=r(Kat,"__init__()"),Kat.forEach(t),pXo=r(bSe," (throws an error)."),bSe.forEach(t),_Xo=i(Al),lt=n(Al,"DIV",{class:!0});var Ll=s(lt);m(Vy.$$.fragment,Ll),uXo=i(Ll),gce=n(Ll,"P",{});var Zat=s(gce);bXo=r(Zat,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Zat.forEach(t),vXo=i(Ll),Ud=n(Ll,"P",{});var cW=s(Ud);TXo=r(cW,`Note:
Loading a model from its configuration file does `),hce=n(cW,"STRONG",{});var ent=s(hce);FXo=r(ent,"not"),ent.forEach(t),CXo=r(cW,` load the model weights. It only affects the
model\u2019s configuration. Use `),pce=n(cW,"CODE",{});var ont=s(pce);MXo=r(ont,"from_pretrained()"),ont.forEach(t),EXo=r(cW,"to load the model weights."),cW.forEach(t),yXo=i(Ll),_ce=n(Ll,"P",{});var rnt=s(_ce);wXo=r(rnt,"Examples:"),rnt.forEach(t),AXo=i(Ll),m(zy.$$.fragment,Ll),Ll.forEach(t),LXo=i(Al),oo=n(Al,"DIV",{class:!0});var ta=s(oo);m(Wy.$$.fragment,ta),BXo=i(ta),uce=n(ta,"P",{});var tnt=s(uce);xXo=r(tnt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),tnt.forEach(t),kXo=i(ta),ln=n(ta,"P",{});var _4=s(ln);RXo=r(_4,"The model class to instantiate is selected based on the "),bce=n(_4,"CODE",{});var ant=s(bce);SXo=r(ant,"model_type"),ant.forEach(t),PXo=r(_4,` property of the config object (either
passed as an argument or loaded from `),vce=n(_4,"CODE",{});var nnt=s(vce);$Xo=r(nnt,"pretrained_model_name_or_path"),nnt.forEach(t),IXo=r(_4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tce=n(_4,"CODE",{});var snt=s(Tce);jXo=r(snt,"pretrained_model_name_or_path"),snt.forEach(t),DXo=r(_4,":"),_4.forEach(t),NXo=i(ta),dn=n(ta,"UL",{});var u4=s(dn);I2=n(u4,"LI",{});var k6e=s(I2);Fce=n(k6e,"STRONG",{});var lnt=s(Fce);qXo=r(lnt,"data2vec-audio"),lnt.forEach(t),OXo=r(k6e," \u2014 "),QN=n(k6e,"A",{href:!0});var int=s(QN);GXo=r(int,"Data2VecAudioForXVector"),int.forEach(t),XXo=r(k6e," (Data2VecAudio model)"),k6e.forEach(t),VXo=i(u4),j2=n(u4,"LI",{});var R6e=s(j2);Cce=n(R6e,"STRONG",{});var dnt=s(Cce);zXo=r(dnt,"unispeech-sat"),dnt.forEach(t),WXo=r(R6e," \u2014 "),HN=n(R6e,"A",{href:!0});var cnt=s(HN);QXo=r(cnt,"UniSpeechSatForXVector"),cnt.forEach(t),HXo=r(R6e," (UniSpeechSat model)"),R6e.forEach(t),UXo=i(u4),D2=n(u4,"LI",{});var S6e=s(D2);Mce=n(S6e,"STRONG",{});var fnt=s(Mce);JXo=r(fnt,"wav2vec2"),fnt.forEach(t),YXo=r(S6e," \u2014 "),UN=n(S6e,"A",{href:!0});var mnt=s(UN);KXo=r(mnt,"Wav2Vec2ForXVector"),mnt.forEach(t),ZXo=r(S6e," (Wav2Vec2 model)"),S6e.forEach(t),eVo=i(u4),N2=n(u4,"LI",{});var P6e=s(N2);Ece=n(P6e,"STRONG",{});var gnt=s(Ece);oVo=r(gnt,"wavlm"),gnt.forEach(t),rVo=r(P6e," \u2014 "),JN=n(P6e,"A",{href:!0});var hnt=s(JN);tVo=r(hnt,"WavLMForXVector"),hnt.forEach(t),aVo=r(P6e," (WavLM model)"),P6e.forEach(t),u4.forEach(t),nVo=i(ta),q2=n(ta,"P",{});var $6e=s(q2);sVo=r($6e,"The model is set in evaluation mode by default using "),yce=n($6e,"CODE",{});var pnt=s(yce);lVo=r(pnt,"model.eval()"),pnt.forEach(t),iVo=r($6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wce=n($6e,"CODE",{});var _nt=s(wce);dVo=r(_nt,"model.train()"),_nt.forEach(t),$6e.forEach(t),cVo=i(ta),Ace=n(ta,"P",{});var unt=s(Ace);fVo=r(unt,"Examples:"),unt.forEach(t),mVo=i(ta),m(Qy.$$.fragment,ta),ta.forEach(t),Al.forEach(t),dke=i(c),Jd=n(c,"H2",{class:!0});var vSe=s(Jd);O2=n(vSe,"A",{id:!0,class:!0,href:!0});var bnt=s(O2);Lce=n(bnt,"SPAN",{});var vnt=s(Lce);m(Hy.$$.fragment,vnt),vnt.forEach(t),bnt.forEach(t),gVo=i(vSe),Bce=n(vSe,"SPAN",{});var Tnt=s(Bce);hVo=r(Tnt,"AutoModelForMaskedImageModeling"),Tnt.forEach(t),vSe.forEach(t),cke=i(c),hr=n(c,"DIV",{class:!0});var Bl=s(hr);m(Uy.$$.fragment,Bl),pVo=i(Bl),Yd=n(Bl,"P",{});var fW=s(Yd);_Vo=r(fW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xce=n(fW,"CODE",{});var Fnt=s(xce);uVo=r(Fnt,"from_pretrained()"),Fnt.forEach(t),bVo=r(fW,"class method or the "),kce=n(fW,"CODE",{});var Cnt=s(kce);vVo=r(Cnt,"from_config()"),Cnt.forEach(t),TVo=r(fW,`class
method.`),fW.forEach(t),FVo=i(Bl),Jy=n(Bl,"P",{});var TSe=s(Jy);CVo=r(TSe,"This class cannot be instantiated directly using "),Rce=n(TSe,"CODE",{});var Mnt=s(Rce);MVo=r(Mnt,"__init__()"),Mnt.forEach(t),EVo=r(TSe," (throws an error)."),TSe.forEach(t),yVo=i(Bl),it=n(Bl,"DIV",{class:!0});var xl=s(it);m(Yy.$$.fragment,xl),wVo=i(xl),Sce=n(xl,"P",{});var Ent=s(Sce);AVo=r(Ent,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Ent.forEach(t),LVo=i(xl),Kd=n(xl,"P",{});var mW=s(Kd);BVo=r(mW,`Note:
Loading a model from its configuration file does `),Pce=n(mW,"STRONG",{});var ynt=s(Pce);xVo=r(ynt,"not"),ynt.forEach(t),kVo=r(mW,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ce=n(mW,"CODE",{});var wnt=s($ce);RVo=r(wnt,"from_pretrained()"),wnt.forEach(t),SVo=r(mW,"to load the model weights."),mW.forEach(t),PVo=i(xl),Ice=n(xl,"P",{});var Ant=s(Ice);$Vo=r(Ant,"Examples:"),Ant.forEach(t),IVo=i(xl),m(Ky.$$.fragment,xl),xl.forEach(t),jVo=i(Bl),ro=n(Bl,"DIV",{class:!0});var aa=s(ro);m(Zy.$$.fragment,aa),DVo=i(aa),jce=n(aa,"P",{});var Lnt=s(jce);NVo=r(Lnt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Lnt.forEach(t),qVo=i(aa),cn=n(aa,"P",{});var b4=s(cn);OVo=r(b4,"The model class to instantiate is selected based on the "),Dce=n(b4,"CODE",{});var Bnt=s(Dce);GVo=r(Bnt,"model_type"),Bnt.forEach(t),XVo=r(b4,` property of the config object (either
passed as an argument or loaded from `),Nce=n(b4,"CODE",{});var xnt=s(Nce);VVo=r(xnt,"pretrained_model_name_or_path"),xnt.forEach(t),zVo=r(b4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qce=n(b4,"CODE",{});var knt=s(qce);WVo=r(knt,"pretrained_model_name_or_path"),knt.forEach(t),QVo=r(b4,":"),b4.forEach(t),HVo=i(aa),Zd=n(aa,"UL",{});var gW=s(Zd);G2=n(gW,"LI",{});var I6e=s(G2);Oce=n(I6e,"STRONG",{});var Rnt=s(Oce);UVo=r(Rnt,"deit"),Rnt.forEach(t),JVo=r(I6e," \u2014 "),YN=n(I6e,"A",{href:!0});var Snt=s(YN);YVo=r(Snt,"DeiTForMaskedImageModeling"),Snt.forEach(t),KVo=r(I6e," (DeiT model)"),I6e.forEach(t),ZVo=i(gW),X2=n(gW,"LI",{});var j6e=s(X2);Gce=n(j6e,"STRONG",{});var Pnt=s(Gce);ezo=r(Pnt,"swin"),Pnt.forEach(t),ozo=r(j6e," \u2014 "),KN=n(j6e,"A",{href:!0});var $nt=s(KN);rzo=r($nt,"SwinForMaskedImageModeling"),$nt.forEach(t),tzo=r(j6e," (Swin model)"),j6e.forEach(t),azo=i(gW),V2=n(gW,"LI",{});var D6e=s(V2);Xce=n(D6e,"STRONG",{});var Int=s(Xce);nzo=r(Int,"vit"),Int.forEach(t),szo=r(D6e," \u2014 "),ZN=n(D6e,"A",{href:!0});var jnt=s(ZN);lzo=r(jnt,"ViTForMaskedImageModeling"),jnt.forEach(t),izo=r(D6e," (ViT model)"),D6e.forEach(t),gW.forEach(t),dzo=i(aa),z2=n(aa,"P",{});var N6e=s(z2);czo=r(N6e,"The model is set in evaluation mode by default using "),Vce=n(N6e,"CODE",{});var Dnt=s(Vce);fzo=r(Dnt,"model.eval()"),Dnt.forEach(t),mzo=r(N6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zce=n(N6e,"CODE",{});var Nnt=s(zce);gzo=r(Nnt,"model.train()"),Nnt.forEach(t),N6e.forEach(t),hzo=i(aa),Wce=n(aa,"P",{});var qnt=s(Wce);pzo=r(qnt,"Examples:"),qnt.forEach(t),_zo=i(aa),m(ew.$$.fragment,aa),aa.forEach(t),Bl.forEach(t),fke=i(c),ec=n(c,"H2",{class:!0});var FSe=s(ec);W2=n(FSe,"A",{id:!0,class:!0,href:!0});var Ont=s(W2);Qce=n(Ont,"SPAN",{});var Gnt=s(Qce);m(ow.$$.fragment,Gnt),Gnt.forEach(t),Ont.forEach(t),uzo=i(FSe),Hce=n(FSe,"SPAN",{});var Xnt=s(Hce);bzo=r(Xnt,"AutoModelForObjectDetection"),Xnt.forEach(t),FSe.forEach(t),mke=i(c),pr=n(c,"DIV",{class:!0});var kl=s(pr);m(rw.$$.fragment,kl),vzo=i(kl),oc=n(kl,"P",{});var hW=s(oc);Tzo=r(hW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Uce=n(hW,"CODE",{});var Vnt=s(Uce);Fzo=r(Vnt,"from_pretrained()"),Vnt.forEach(t),Czo=r(hW,"class method or the "),Jce=n(hW,"CODE",{});var znt=s(Jce);Mzo=r(znt,"from_config()"),znt.forEach(t),Ezo=r(hW,`class
method.`),hW.forEach(t),yzo=i(kl),tw=n(kl,"P",{});var CSe=s(tw);wzo=r(CSe,"This class cannot be instantiated directly using "),Yce=n(CSe,"CODE",{});var Wnt=s(Yce);Azo=r(Wnt,"__init__()"),Wnt.forEach(t),Lzo=r(CSe," (throws an error)."),CSe.forEach(t),Bzo=i(kl),dt=n(kl,"DIV",{class:!0});var Rl=s(dt);m(aw.$$.fragment,Rl),xzo=i(Rl),Kce=n(Rl,"P",{});var Qnt=s(Kce);kzo=r(Qnt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Qnt.forEach(t),Rzo=i(Rl),rc=n(Rl,"P",{});var pW=s(rc);Szo=r(pW,`Note:
Loading a model from its configuration file does `),Zce=n(pW,"STRONG",{});var Hnt=s(Zce);Pzo=r(Hnt,"not"),Hnt.forEach(t),$zo=r(pW,` load the model weights. It only affects the
model\u2019s configuration. Use `),efe=n(pW,"CODE",{});var Unt=s(efe);Izo=r(Unt,"from_pretrained()"),Unt.forEach(t),jzo=r(pW,"to load the model weights."),pW.forEach(t),Dzo=i(Rl),ofe=n(Rl,"P",{});var Jnt=s(ofe);Nzo=r(Jnt,"Examples:"),Jnt.forEach(t),qzo=i(Rl),m(nw.$$.fragment,Rl),Rl.forEach(t),Ozo=i(kl),to=n(kl,"DIV",{class:!0});var na=s(to);m(sw.$$.fragment,na),Gzo=i(na),rfe=n(na,"P",{});var Ynt=s(rfe);Xzo=r(Ynt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Ynt.forEach(t),Vzo=i(na),fn=n(na,"P",{});var v4=s(fn);zzo=r(v4,"The model class to instantiate is selected based on the "),tfe=n(v4,"CODE",{});var Knt=s(tfe);Wzo=r(Knt,"model_type"),Knt.forEach(t),Qzo=r(v4,` property of the config object (either
passed as an argument or loaded from `),afe=n(v4,"CODE",{});var Znt=s(afe);Hzo=r(Znt,"pretrained_model_name_or_path"),Znt.forEach(t),Uzo=r(v4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nfe=n(v4,"CODE",{});var est=s(nfe);Jzo=r(est,"pretrained_model_name_or_path"),est.forEach(t),Yzo=r(v4,":"),v4.forEach(t),Kzo=i(na),sfe=n(na,"UL",{});var ost=s(sfe);Q2=n(ost,"LI",{});var q6e=s(Q2);lfe=n(q6e,"STRONG",{});var rst=s(lfe);Zzo=r(rst,"detr"),rst.forEach(t),eWo=r(q6e," \u2014 "),eq=n(q6e,"A",{href:!0});var tst=s(eq);oWo=r(tst,"DetrForObjectDetection"),tst.forEach(t),rWo=r(q6e," (DETR model)"),q6e.forEach(t),ost.forEach(t),tWo=i(na),H2=n(na,"P",{});var O6e=s(H2);aWo=r(O6e,"The model is set in evaluation mode by default using "),ife=n(O6e,"CODE",{});var ast=s(ife);nWo=r(ast,"model.eval()"),ast.forEach(t),sWo=r(O6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dfe=n(O6e,"CODE",{});var nst=s(dfe);lWo=r(nst,"model.train()"),nst.forEach(t),O6e.forEach(t),iWo=i(na),cfe=n(na,"P",{});var sst=s(cfe);dWo=r(sst,"Examples:"),sst.forEach(t),cWo=i(na),m(lw.$$.fragment,na),na.forEach(t),kl.forEach(t),gke=i(c),tc=n(c,"H2",{class:!0});var MSe=s(tc);U2=n(MSe,"A",{id:!0,class:!0,href:!0});var lst=s(U2);ffe=n(lst,"SPAN",{});var ist=s(ffe);m(iw.$$.fragment,ist),ist.forEach(t),lst.forEach(t),fWo=i(MSe),mfe=n(MSe,"SPAN",{});var dst=s(mfe);mWo=r(dst,"AutoModelForImageSegmentation"),dst.forEach(t),MSe.forEach(t),hke=i(c),_r=n(c,"DIV",{class:!0});var Sl=s(_r);m(dw.$$.fragment,Sl),gWo=i(Sl),ac=n(Sl,"P",{});var _W=s(ac);hWo=r(_W,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),gfe=n(_W,"CODE",{});var cst=s(gfe);pWo=r(cst,"from_pretrained()"),cst.forEach(t),_Wo=r(_W,"class method or the "),hfe=n(_W,"CODE",{});var fst=s(hfe);uWo=r(fst,"from_config()"),fst.forEach(t),bWo=r(_W,`class
method.`),_W.forEach(t),vWo=i(Sl),cw=n(Sl,"P",{});var ESe=s(cw);TWo=r(ESe,"This class cannot be instantiated directly using "),pfe=n(ESe,"CODE",{});var mst=s(pfe);FWo=r(mst,"__init__()"),mst.forEach(t),CWo=r(ESe," (throws an error)."),ESe.forEach(t),MWo=i(Sl),ct=n(Sl,"DIV",{class:!0});var Pl=s(ct);m(fw.$$.fragment,Pl),EWo=i(Pl),_fe=n(Pl,"P",{});var gst=s(_fe);yWo=r(gst,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),gst.forEach(t),wWo=i(Pl),nc=n(Pl,"P",{});var uW=s(nc);AWo=r(uW,`Note:
Loading a model from its configuration file does `),ufe=n(uW,"STRONG",{});var hst=s(ufe);LWo=r(hst,"not"),hst.forEach(t),BWo=r(uW,` load the model weights. It only affects the
model\u2019s configuration. Use `),bfe=n(uW,"CODE",{});var pst=s(bfe);xWo=r(pst,"from_pretrained()"),pst.forEach(t),kWo=r(uW,"to load the model weights."),uW.forEach(t),RWo=i(Pl),vfe=n(Pl,"P",{});var _st=s(vfe);SWo=r(_st,"Examples:"),_st.forEach(t),PWo=i(Pl),m(mw.$$.fragment,Pl),Pl.forEach(t),$Wo=i(Sl),ao=n(Sl,"DIV",{class:!0});var sa=s(ao);m(gw.$$.fragment,sa),IWo=i(sa),Tfe=n(sa,"P",{});var ust=s(Tfe);jWo=r(ust,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),ust.forEach(t),DWo=i(sa),mn=n(sa,"P",{});var T4=s(mn);NWo=r(T4,"The model class to instantiate is selected based on the "),Ffe=n(T4,"CODE",{});var bst=s(Ffe);qWo=r(bst,"model_type"),bst.forEach(t),OWo=r(T4,` property of the config object (either
passed as an argument or loaded from `),Cfe=n(T4,"CODE",{});var vst=s(Cfe);GWo=r(vst,"pretrained_model_name_or_path"),vst.forEach(t),XWo=r(T4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mfe=n(T4,"CODE",{});var Tst=s(Mfe);VWo=r(Tst,"pretrained_model_name_or_path"),Tst.forEach(t),zWo=r(T4,":"),T4.forEach(t),WWo=i(sa),Efe=n(sa,"UL",{});var Fst=s(Efe);J2=n(Fst,"LI",{});var G6e=s(J2);yfe=n(G6e,"STRONG",{});var Cst=s(yfe);QWo=r(Cst,"detr"),Cst.forEach(t),HWo=r(G6e," \u2014 "),oq=n(G6e,"A",{href:!0});var Mst=s(oq);UWo=r(Mst,"DetrForSegmentation"),Mst.forEach(t),JWo=r(G6e," (DETR model)"),G6e.forEach(t),Fst.forEach(t),YWo=i(sa),Y2=n(sa,"P",{});var X6e=s(Y2);KWo=r(X6e,"The model is set in evaluation mode by default using "),wfe=n(X6e,"CODE",{});var Est=s(wfe);ZWo=r(Est,"model.eval()"),Est.forEach(t),eQo=r(X6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Afe=n(X6e,"CODE",{});var yst=s(Afe);oQo=r(yst,"model.train()"),yst.forEach(t),X6e.forEach(t),rQo=i(sa),Lfe=n(sa,"P",{});var wst=s(Lfe);tQo=r(wst,"Examples:"),wst.forEach(t),aQo=i(sa),m(hw.$$.fragment,sa),sa.forEach(t),Sl.forEach(t),pke=i(c),sc=n(c,"H2",{class:!0});var ySe=s(sc);K2=n(ySe,"A",{id:!0,class:!0,href:!0});var Ast=s(K2);Bfe=n(Ast,"SPAN",{});var Lst=s(Bfe);m(pw.$$.fragment,Lst),Lst.forEach(t),Ast.forEach(t),nQo=i(ySe),xfe=n(ySe,"SPAN",{});var Bst=s(xfe);sQo=r(Bst,"AutoModelForSemanticSegmentation"),Bst.forEach(t),ySe.forEach(t),_ke=i(c),ur=n(c,"DIV",{class:!0});var $l=s(ur);m(_w.$$.fragment,$l),lQo=i($l),lc=n($l,"P",{});var bW=s(lc);iQo=r(bW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),kfe=n(bW,"CODE",{});var xst=s(kfe);dQo=r(xst,"from_pretrained()"),xst.forEach(t),cQo=r(bW,"class method or the "),Rfe=n(bW,"CODE",{});var kst=s(Rfe);fQo=r(kst,"from_config()"),kst.forEach(t),mQo=r(bW,`class
method.`),bW.forEach(t),gQo=i($l),uw=n($l,"P",{});var wSe=s(uw);hQo=r(wSe,"This class cannot be instantiated directly using "),Sfe=n(wSe,"CODE",{});var Rst=s(Sfe);pQo=r(Rst,"__init__()"),Rst.forEach(t),_Qo=r(wSe," (throws an error)."),wSe.forEach(t),uQo=i($l),ft=n($l,"DIV",{class:!0});var Il=s(ft);m(bw.$$.fragment,Il),bQo=i(Il),Pfe=n(Il,"P",{});var Sst=s(Pfe);vQo=r(Sst,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Sst.forEach(t),TQo=i(Il),ic=n(Il,"P",{});var vW=s(ic);FQo=r(vW,`Note:
Loading a model from its configuration file does `),$fe=n(vW,"STRONG",{});var Pst=s($fe);CQo=r(Pst,"not"),Pst.forEach(t),MQo=r(vW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ife=n(vW,"CODE",{});var $st=s(Ife);EQo=r($st,"from_pretrained()"),$st.forEach(t),yQo=r(vW,"to load the model weights."),vW.forEach(t),wQo=i(Il),jfe=n(Il,"P",{});var Ist=s(jfe);AQo=r(Ist,"Examples:"),Ist.forEach(t),LQo=i(Il),m(vw.$$.fragment,Il),Il.forEach(t),BQo=i($l),no=n($l,"DIV",{class:!0});var la=s(no);m(Tw.$$.fragment,la),xQo=i(la),Dfe=n(la,"P",{});var jst=s(Dfe);kQo=r(jst,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),jst.forEach(t),RQo=i(la),gn=n(la,"P",{});var F4=s(gn);SQo=r(F4,"The model class to instantiate is selected based on the "),Nfe=n(F4,"CODE",{});var Dst=s(Nfe);PQo=r(Dst,"model_type"),Dst.forEach(t),$Qo=r(F4,` property of the config object (either
passed as an argument or loaded from `),qfe=n(F4,"CODE",{});var Nst=s(qfe);IQo=r(Nst,"pretrained_model_name_or_path"),Nst.forEach(t),jQo=r(F4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ofe=n(F4,"CODE",{});var qst=s(Ofe);DQo=r(qst,"pretrained_model_name_or_path"),qst.forEach(t),NQo=r(F4,":"),F4.forEach(t),qQo=i(la),Fw=n(la,"UL",{});var ASe=s(Fw);Z2=n(ASe,"LI",{});var V6e=s(Z2);Gfe=n(V6e,"STRONG",{});var Ost=s(Gfe);OQo=r(Ost,"beit"),Ost.forEach(t),GQo=r(V6e," \u2014 "),rq=n(V6e,"A",{href:!0});var Gst=s(rq);XQo=r(Gst,"BeitForSemanticSegmentation"),Gst.forEach(t),VQo=r(V6e," (BEiT model)"),V6e.forEach(t),zQo=i(ASe),ev=n(ASe,"LI",{});var z6e=s(ev);Xfe=n(z6e,"STRONG",{});var Xst=s(Xfe);WQo=r(Xst,"segformer"),Xst.forEach(t),QQo=r(z6e," \u2014 "),tq=n(z6e,"A",{href:!0});var Vst=s(tq);HQo=r(Vst,"SegformerForSemanticSegmentation"),Vst.forEach(t),UQo=r(z6e," (SegFormer model)"),z6e.forEach(t),ASe.forEach(t),JQo=i(la),ov=n(la,"P",{});var W6e=s(ov);YQo=r(W6e,"The model is set in evaluation mode by default using "),Vfe=n(W6e,"CODE",{});var zst=s(Vfe);KQo=r(zst,"model.eval()"),zst.forEach(t),ZQo=r(W6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=n(W6e,"CODE",{});var Wst=s(zfe);eHo=r(Wst,"model.train()"),Wst.forEach(t),W6e.forEach(t),oHo=i(la),Wfe=n(la,"P",{});var Qst=s(Wfe);rHo=r(Qst,"Examples:"),Qst.forEach(t),tHo=i(la),m(Cw.$$.fragment,la),la.forEach(t),$l.forEach(t),uke=i(c),dc=n(c,"H2",{class:!0});var LSe=s(dc);rv=n(LSe,"A",{id:!0,class:!0,href:!0});var Hst=s(rv);Qfe=n(Hst,"SPAN",{});var Ust=s(Qfe);m(Mw.$$.fragment,Ust),Ust.forEach(t),Hst.forEach(t),aHo=i(LSe),Hfe=n(LSe,"SPAN",{});var Jst=s(Hfe);nHo=r(Jst,"AutoModelForInstanceSegmentation"),Jst.forEach(t),LSe.forEach(t),bke=i(c),br=n(c,"DIV",{class:!0});var jl=s(br);m(Ew.$$.fragment,jl),sHo=i(jl),cc=n(jl,"P",{});var TW=s(cc);lHo=r(TW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Ufe=n(TW,"CODE",{});var Yst=s(Ufe);iHo=r(Yst,"from_pretrained()"),Yst.forEach(t),dHo=r(TW,"class method or the "),Jfe=n(TW,"CODE",{});var Kst=s(Jfe);cHo=r(Kst,"from_config()"),Kst.forEach(t),fHo=r(TW,`class
method.`),TW.forEach(t),mHo=i(jl),yw=n(jl,"P",{});var BSe=s(yw);gHo=r(BSe,"This class cannot be instantiated directly using "),Yfe=n(BSe,"CODE",{});var Zst=s(Yfe);hHo=r(Zst,"__init__()"),Zst.forEach(t),pHo=r(BSe," (throws an error)."),BSe.forEach(t),_Ho=i(jl),mt=n(jl,"DIV",{class:!0});var Dl=s(mt);m(ww.$$.fragment,Dl),uHo=i(Dl),Kfe=n(Dl,"P",{});var elt=s(Kfe);bHo=r(elt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),elt.forEach(t),vHo=i(Dl),fc=n(Dl,"P",{});var FW=s(fc);THo=r(FW,`Note:
Loading a model from its configuration file does `),Zfe=n(FW,"STRONG",{});var olt=s(Zfe);FHo=r(olt,"not"),olt.forEach(t),CHo=r(FW,` load the model weights. It only affects the
model\u2019s configuration. Use `),eme=n(FW,"CODE",{});var rlt=s(eme);MHo=r(rlt,"from_pretrained()"),rlt.forEach(t),EHo=r(FW,"to load the model weights."),FW.forEach(t),yHo=i(Dl),ome=n(Dl,"P",{});var tlt=s(ome);wHo=r(tlt,"Examples:"),tlt.forEach(t),AHo=i(Dl),m(Aw.$$.fragment,Dl),Dl.forEach(t),LHo=i(jl),so=n(jl,"DIV",{class:!0});var ia=s(so);m(Lw.$$.fragment,ia),BHo=i(ia),rme=n(ia,"P",{});var alt=s(rme);xHo=r(alt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),alt.forEach(t),kHo=i(ia),hn=n(ia,"P",{});var C4=s(hn);RHo=r(C4,"The model class to instantiate is selected based on the "),tme=n(C4,"CODE",{});var nlt=s(tme);SHo=r(nlt,"model_type"),nlt.forEach(t),PHo=r(C4,` property of the config object (either
passed as an argument or loaded from `),ame=n(C4,"CODE",{});var slt=s(ame);$Ho=r(slt,"pretrained_model_name_or_path"),slt.forEach(t),IHo=r(C4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nme=n(C4,"CODE",{});var llt=s(nme);jHo=r(llt,"pretrained_model_name_or_path"),llt.forEach(t),DHo=r(C4,":"),C4.forEach(t),NHo=i(ia),sme=n(ia,"UL",{});var ilt=s(sme);tv=n(ilt,"LI",{});var Q6e=s(tv);lme=n(Q6e,"STRONG",{});var dlt=s(lme);qHo=r(dlt,"maskformer"),dlt.forEach(t),OHo=r(Q6e," \u2014 "),aq=n(Q6e,"A",{href:!0});var clt=s(aq);GHo=r(clt,"MaskFormerForInstanceSegmentation"),clt.forEach(t),XHo=r(Q6e," (MaskFormer model)"),Q6e.forEach(t),ilt.forEach(t),VHo=i(ia),av=n(ia,"P",{});var H6e=s(av);zHo=r(H6e,"The model is set in evaluation mode by default using "),ime=n(H6e,"CODE",{});var flt=s(ime);WHo=r(flt,"model.eval()"),flt.forEach(t),QHo=r(H6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dme=n(H6e,"CODE",{});var mlt=s(dme);HHo=r(mlt,"model.train()"),mlt.forEach(t),H6e.forEach(t),UHo=i(ia),cme=n(ia,"P",{});var glt=s(cme);JHo=r(glt,"Examples:"),glt.forEach(t),YHo=i(ia),m(Bw.$$.fragment,ia),ia.forEach(t),jl.forEach(t),vke=i(c),mc=n(c,"H2",{class:!0});var xSe=s(mc);nv=n(xSe,"A",{id:!0,class:!0,href:!0});var hlt=s(nv);fme=n(hlt,"SPAN",{});var plt=s(fme);m(xw.$$.fragment,plt),plt.forEach(t),hlt.forEach(t),KHo=i(xSe),mme=n(xSe,"SPAN",{});var _lt=s(mme);ZHo=r(_lt,"TFAutoModel"),_lt.forEach(t),xSe.forEach(t),Tke=i(c),vr=n(c,"DIV",{class:!0});var Nl=s(vr);m(kw.$$.fragment,Nl),eUo=i(Nl),gc=n(Nl,"P",{});var CW=s(gc);oUo=r(CW,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gme=n(CW,"CODE",{});var ult=s(gme);rUo=r(ult,"from_pretrained()"),ult.forEach(t),tUo=r(CW,"class method or the "),hme=n(CW,"CODE",{});var blt=s(hme);aUo=r(blt,"from_config()"),blt.forEach(t),nUo=r(CW,`class
method.`),CW.forEach(t),sUo=i(Nl),Rw=n(Nl,"P",{});var kSe=s(Rw);lUo=r(kSe,"This class cannot be instantiated directly using "),pme=n(kSe,"CODE",{});var vlt=s(pme);iUo=r(vlt,"__init__()"),vlt.forEach(t),dUo=r(kSe," (throws an error)."),kSe.forEach(t),cUo=i(Nl),gt=n(Nl,"DIV",{class:!0});var ql=s(gt);m(Sw.$$.fragment,ql),fUo=i(ql),_me=n(ql,"P",{});var Tlt=s(_me);mUo=r(Tlt,"Instantiates one of the base model classes of the library from a configuration."),Tlt.forEach(t),gUo=i(ql),hc=n(ql,"P",{});var MW=s(hc);hUo=r(MW,`Note:
Loading a model from its configuration file does `),ume=n(MW,"STRONG",{});var Flt=s(ume);pUo=r(Flt,"not"),Flt.forEach(t),_Uo=r(MW,` load the model weights. It only affects the
model\u2019s configuration. Use `),bme=n(MW,"CODE",{});var Clt=s(bme);uUo=r(Clt,"from_pretrained()"),Clt.forEach(t),bUo=r(MW,"to load the model weights."),MW.forEach(t),vUo=i(ql),vme=n(ql,"P",{});var Mlt=s(vme);TUo=r(Mlt,"Examples:"),Mlt.forEach(t),FUo=i(ql),m(Pw.$$.fragment,ql),ql.forEach(t),CUo=i(Nl),ho=n(Nl,"DIV",{class:!0});var ha=s(ho);m($w.$$.fragment,ha),MUo=i(ha),Tme=n(ha,"P",{});var Elt=s(Tme);EUo=r(Elt,"Instantiate one of the base model classes of the library from a pretrained model."),Elt.forEach(t),yUo=i(ha),pn=n(ha,"P",{});var M4=s(pn);wUo=r(M4,"The model class to instantiate is selected based on the "),Fme=n(M4,"CODE",{});var ylt=s(Fme);AUo=r(ylt,"model_type"),ylt.forEach(t),LUo=r(M4,` property of the config object (either
passed as an argument or loaded from `),Cme=n(M4,"CODE",{});var wlt=s(Cme);BUo=r(wlt,"pretrained_model_name_or_path"),wlt.forEach(t),xUo=r(M4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mme=n(M4,"CODE",{});var Alt=s(Mme);kUo=r(Alt,"pretrained_model_name_or_path"),Alt.forEach(t),RUo=r(M4,":"),M4.forEach(t),SUo=i(ha),B=n(ha,"UL",{});var x=s(B);sv=n(x,"LI",{});var U6e=s(sv);Eme=n(U6e,"STRONG",{});var Llt=s(Eme);PUo=r(Llt,"albert"),Llt.forEach(t),$Uo=r(U6e," \u2014 "),nq=n(U6e,"A",{href:!0});var Blt=s(nq);IUo=r(Blt,"TFAlbertModel"),Blt.forEach(t),jUo=r(U6e," (ALBERT model)"),U6e.forEach(t),DUo=i(x),lv=n(x,"LI",{});var J6e=s(lv);yme=n(J6e,"STRONG",{});var xlt=s(yme);NUo=r(xlt,"bart"),xlt.forEach(t),qUo=r(J6e," \u2014 "),sq=n(J6e,"A",{href:!0});var klt=s(sq);OUo=r(klt,"TFBartModel"),klt.forEach(t),GUo=r(J6e," (BART model)"),J6e.forEach(t),XUo=i(x),iv=n(x,"LI",{});var Y6e=s(iv);wme=n(Y6e,"STRONG",{});var Rlt=s(wme);VUo=r(Rlt,"bert"),Rlt.forEach(t),zUo=r(Y6e," \u2014 "),lq=n(Y6e,"A",{href:!0});var Slt=s(lq);WUo=r(Slt,"TFBertModel"),Slt.forEach(t),QUo=r(Y6e," (BERT model)"),Y6e.forEach(t),HUo=i(x),dv=n(x,"LI",{});var K6e=s(dv);Ame=n(K6e,"STRONG",{});var Plt=s(Ame);UUo=r(Plt,"blenderbot"),Plt.forEach(t),JUo=r(K6e," \u2014 "),iq=n(K6e,"A",{href:!0});var $lt=s(iq);YUo=r($lt,"TFBlenderbotModel"),$lt.forEach(t),KUo=r(K6e," (Blenderbot model)"),K6e.forEach(t),ZUo=i(x),cv=n(x,"LI",{});var Z6e=s(cv);Lme=n(Z6e,"STRONG",{});var Ilt=s(Lme);eJo=r(Ilt,"blenderbot-small"),Ilt.forEach(t),oJo=r(Z6e," \u2014 "),dq=n(Z6e,"A",{href:!0});var jlt=s(dq);rJo=r(jlt,"TFBlenderbotSmallModel"),jlt.forEach(t),tJo=r(Z6e," (BlenderbotSmall model)"),Z6e.forEach(t),aJo=i(x),fv=n(x,"LI",{});var eAe=s(fv);Bme=n(eAe,"STRONG",{});var Dlt=s(Bme);nJo=r(Dlt,"camembert"),Dlt.forEach(t),sJo=r(eAe," \u2014 "),cq=n(eAe,"A",{href:!0});var Nlt=s(cq);lJo=r(Nlt,"TFCamembertModel"),Nlt.forEach(t),iJo=r(eAe," (CamemBERT model)"),eAe.forEach(t),dJo=i(x),mv=n(x,"LI",{});var oAe=s(mv);xme=n(oAe,"STRONG",{});var qlt=s(xme);cJo=r(qlt,"clip"),qlt.forEach(t),fJo=r(oAe," \u2014 "),fq=n(oAe,"A",{href:!0});var Olt=s(fq);mJo=r(Olt,"TFCLIPModel"),Olt.forEach(t),gJo=r(oAe," (CLIP model)"),oAe.forEach(t),hJo=i(x),gv=n(x,"LI",{});var rAe=s(gv);kme=n(rAe,"STRONG",{});var Glt=s(kme);pJo=r(Glt,"convbert"),Glt.forEach(t),_Jo=r(rAe," \u2014 "),mq=n(rAe,"A",{href:!0});var Xlt=s(mq);uJo=r(Xlt,"TFConvBertModel"),Xlt.forEach(t),bJo=r(rAe," (ConvBERT model)"),rAe.forEach(t),vJo=i(x),hv=n(x,"LI",{});var tAe=s(hv);Rme=n(tAe,"STRONG",{});var Vlt=s(Rme);TJo=r(Vlt,"convnext"),Vlt.forEach(t),FJo=r(tAe," \u2014 "),gq=n(tAe,"A",{href:!0});var zlt=s(gq);CJo=r(zlt,"TFConvNextModel"),zlt.forEach(t),MJo=r(tAe," (ConvNext model)"),tAe.forEach(t),EJo=i(x),pv=n(x,"LI",{});var aAe=s(pv);Sme=n(aAe,"STRONG",{});var Wlt=s(Sme);yJo=r(Wlt,"ctrl"),Wlt.forEach(t),wJo=r(aAe," \u2014 "),hq=n(aAe,"A",{href:!0});var Qlt=s(hq);AJo=r(Qlt,"TFCTRLModel"),Qlt.forEach(t),LJo=r(aAe," (CTRL model)"),aAe.forEach(t),BJo=i(x),_v=n(x,"LI",{});var nAe=s(_v);Pme=n(nAe,"STRONG",{});var Hlt=s(Pme);xJo=r(Hlt,"deberta"),Hlt.forEach(t),kJo=r(nAe," \u2014 "),pq=n(nAe,"A",{href:!0});var Ult=s(pq);RJo=r(Ult,"TFDebertaModel"),Ult.forEach(t),SJo=r(nAe," (DeBERTa model)"),nAe.forEach(t),PJo=i(x),uv=n(x,"LI",{});var sAe=s(uv);$me=n(sAe,"STRONG",{});var Jlt=s($me);$Jo=r(Jlt,"deberta-v2"),Jlt.forEach(t),IJo=r(sAe," \u2014 "),_q=n(sAe,"A",{href:!0});var Ylt=s(_q);jJo=r(Ylt,"TFDebertaV2Model"),Ylt.forEach(t),DJo=r(sAe," (DeBERTa-v2 model)"),sAe.forEach(t),NJo=i(x),bv=n(x,"LI",{});var lAe=s(bv);Ime=n(lAe,"STRONG",{});var Klt=s(Ime);qJo=r(Klt,"distilbert"),Klt.forEach(t),OJo=r(lAe," \u2014 "),uq=n(lAe,"A",{href:!0});var Zlt=s(uq);GJo=r(Zlt,"TFDistilBertModel"),Zlt.forEach(t),XJo=r(lAe," (DistilBERT model)"),lAe.forEach(t),VJo=i(x),vv=n(x,"LI",{});var iAe=s(vv);jme=n(iAe,"STRONG",{});var eit=s(jme);zJo=r(eit,"dpr"),eit.forEach(t),WJo=r(iAe," \u2014 "),bq=n(iAe,"A",{href:!0});var oit=s(bq);QJo=r(oit,"TFDPRQuestionEncoder"),oit.forEach(t),HJo=r(iAe," (DPR model)"),iAe.forEach(t),UJo=i(x),Tv=n(x,"LI",{});var dAe=s(Tv);Dme=n(dAe,"STRONG",{});var rit=s(Dme);JJo=r(rit,"electra"),rit.forEach(t),YJo=r(dAe," \u2014 "),vq=n(dAe,"A",{href:!0});var tit=s(vq);KJo=r(tit,"TFElectraModel"),tit.forEach(t),ZJo=r(dAe," (ELECTRA model)"),dAe.forEach(t),eYo=i(x),Fv=n(x,"LI",{});var cAe=s(Fv);Nme=n(cAe,"STRONG",{});var ait=s(Nme);oYo=r(ait,"flaubert"),ait.forEach(t),rYo=r(cAe," \u2014 "),Tq=n(cAe,"A",{href:!0});var nit=s(Tq);tYo=r(nit,"TFFlaubertModel"),nit.forEach(t),aYo=r(cAe," (FlauBERT model)"),cAe.forEach(t),nYo=i(x),Os=n(x,"LI",{});var O8=s(Os);qme=n(O8,"STRONG",{});var sit=s(qme);sYo=r(sit,"funnel"),sit.forEach(t),lYo=r(O8," \u2014 "),Fq=n(O8,"A",{href:!0});var lit=s(Fq);iYo=r(lit,"TFFunnelModel"),lit.forEach(t),dYo=r(O8," or "),Cq=n(O8,"A",{href:!0});var iit=s(Cq);cYo=r(iit,"TFFunnelBaseModel"),iit.forEach(t),fYo=r(O8," (Funnel Transformer model)"),O8.forEach(t),mYo=i(x),Cv=n(x,"LI",{});var fAe=s(Cv);Ome=n(fAe,"STRONG",{});var dit=s(Ome);gYo=r(dit,"gpt2"),dit.forEach(t),hYo=r(fAe," \u2014 "),Mq=n(fAe,"A",{href:!0});var cit=s(Mq);pYo=r(cit,"TFGPT2Model"),cit.forEach(t),_Yo=r(fAe," (OpenAI GPT-2 model)"),fAe.forEach(t),uYo=i(x),Mv=n(x,"LI",{});var mAe=s(Mv);Gme=n(mAe,"STRONG",{});var fit=s(Gme);bYo=r(fit,"hubert"),fit.forEach(t),vYo=r(mAe," \u2014 "),Eq=n(mAe,"A",{href:!0});var mit=s(Eq);TYo=r(mit,"TFHubertModel"),mit.forEach(t),FYo=r(mAe," (Hubert model)"),mAe.forEach(t),CYo=i(x),Ev=n(x,"LI",{});var gAe=s(Ev);Xme=n(gAe,"STRONG",{});var git=s(Xme);MYo=r(git,"layoutlm"),git.forEach(t),EYo=r(gAe," \u2014 "),yq=n(gAe,"A",{href:!0});var hit=s(yq);yYo=r(hit,"TFLayoutLMModel"),hit.forEach(t),wYo=r(gAe," (LayoutLM model)"),gAe.forEach(t),AYo=i(x),yv=n(x,"LI",{});var hAe=s(yv);Vme=n(hAe,"STRONG",{});var pit=s(Vme);LYo=r(pit,"led"),pit.forEach(t),BYo=r(hAe," \u2014 "),wq=n(hAe,"A",{href:!0});var _it=s(wq);xYo=r(_it,"TFLEDModel"),_it.forEach(t),kYo=r(hAe," (LED model)"),hAe.forEach(t),RYo=i(x),wv=n(x,"LI",{});var pAe=s(wv);zme=n(pAe,"STRONG",{});var uit=s(zme);SYo=r(uit,"longformer"),uit.forEach(t),PYo=r(pAe," \u2014 "),Aq=n(pAe,"A",{href:!0});var bit=s(Aq);$Yo=r(bit,"TFLongformerModel"),bit.forEach(t),IYo=r(pAe," (Longformer model)"),pAe.forEach(t),jYo=i(x),Av=n(x,"LI",{});var _Ae=s(Av);Wme=n(_Ae,"STRONG",{});var vit=s(Wme);DYo=r(vit,"lxmert"),vit.forEach(t),NYo=r(_Ae," \u2014 "),Lq=n(_Ae,"A",{href:!0});var Tit=s(Lq);qYo=r(Tit,"TFLxmertModel"),Tit.forEach(t),OYo=r(_Ae," (LXMERT model)"),_Ae.forEach(t),GYo=i(x),Lv=n(x,"LI",{});var uAe=s(Lv);Qme=n(uAe,"STRONG",{});var Fit=s(Qme);XYo=r(Fit,"marian"),Fit.forEach(t),VYo=r(uAe," \u2014 "),Bq=n(uAe,"A",{href:!0});var Cit=s(Bq);zYo=r(Cit,"TFMarianModel"),Cit.forEach(t),WYo=r(uAe," (Marian model)"),uAe.forEach(t),QYo=i(x),Bv=n(x,"LI",{});var bAe=s(Bv);Hme=n(bAe,"STRONG",{});var Mit=s(Hme);HYo=r(Mit,"mbart"),Mit.forEach(t),UYo=r(bAe," \u2014 "),xq=n(bAe,"A",{href:!0});var Eit=s(xq);JYo=r(Eit,"TFMBartModel"),Eit.forEach(t),YYo=r(bAe," (mBART model)"),bAe.forEach(t),KYo=i(x),xv=n(x,"LI",{});var vAe=s(xv);Ume=n(vAe,"STRONG",{});var yit=s(Ume);ZYo=r(yit,"mobilebert"),yit.forEach(t),eKo=r(vAe," \u2014 "),kq=n(vAe,"A",{href:!0});var wit=s(kq);oKo=r(wit,"TFMobileBertModel"),wit.forEach(t),rKo=r(vAe," (MobileBERT model)"),vAe.forEach(t),tKo=i(x),kv=n(x,"LI",{});var TAe=s(kv);Jme=n(TAe,"STRONG",{});var Ait=s(Jme);aKo=r(Ait,"mpnet"),Ait.forEach(t),nKo=r(TAe," \u2014 "),Rq=n(TAe,"A",{href:!0});var Lit=s(Rq);sKo=r(Lit,"TFMPNetModel"),Lit.forEach(t),lKo=r(TAe," (MPNet model)"),TAe.forEach(t),iKo=i(x),Rv=n(x,"LI",{});var FAe=s(Rv);Yme=n(FAe,"STRONG",{});var Bit=s(Yme);dKo=r(Bit,"mt5"),Bit.forEach(t),cKo=r(FAe," \u2014 "),Sq=n(FAe,"A",{href:!0});var xit=s(Sq);fKo=r(xit,"TFMT5Model"),xit.forEach(t),mKo=r(FAe," (mT5 model)"),FAe.forEach(t),gKo=i(x),Sv=n(x,"LI",{});var CAe=s(Sv);Kme=n(CAe,"STRONG",{});var kit=s(Kme);hKo=r(kit,"openai-gpt"),kit.forEach(t),pKo=r(CAe," \u2014 "),Pq=n(CAe,"A",{href:!0});var Rit=s(Pq);_Ko=r(Rit,"TFOpenAIGPTModel"),Rit.forEach(t),uKo=r(CAe," (OpenAI GPT model)"),CAe.forEach(t),bKo=i(x),Pv=n(x,"LI",{});var MAe=s(Pv);Zme=n(MAe,"STRONG",{});var Sit=s(Zme);vKo=r(Sit,"pegasus"),Sit.forEach(t),TKo=r(MAe," \u2014 "),$q=n(MAe,"A",{href:!0});var Pit=s($q);FKo=r(Pit,"TFPegasusModel"),Pit.forEach(t),CKo=r(MAe," (Pegasus model)"),MAe.forEach(t),MKo=i(x),$v=n(x,"LI",{});var EAe=s($v);ege=n(EAe,"STRONG",{});var $it=s(ege);EKo=r($it,"rembert"),$it.forEach(t),yKo=r(EAe," \u2014 "),Iq=n(EAe,"A",{href:!0});var Iit=s(Iq);wKo=r(Iit,"TFRemBertModel"),Iit.forEach(t),AKo=r(EAe," (RemBERT model)"),EAe.forEach(t),LKo=i(x),Iv=n(x,"LI",{});var yAe=s(Iv);oge=n(yAe,"STRONG",{});var jit=s(oge);BKo=r(jit,"roberta"),jit.forEach(t),xKo=r(yAe," \u2014 "),jq=n(yAe,"A",{href:!0});var Dit=s(jq);kKo=r(Dit,"TFRobertaModel"),Dit.forEach(t),RKo=r(yAe," (RoBERTa model)"),yAe.forEach(t),SKo=i(x),jv=n(x,"LI",{});var wAe=s(jv);rge=n(wAe,"STRONG",{});var Nit=s(rge);PKo=r(Nit,"roformer"),Nit.forEach(t),$Ko=r(wAe," \u2014 "),Dq=n(wAe,"A",{href:!0});var qit=s(Dq);IKo=r(qit,"TFRoFormerModel"),qit.forEach(t),jKo=r(wAe," (RoFormer model)"),wAe.forEach(t),DKo=i(x),Dv=n(x,"LI",{});var AAe=s(Dv);tge=n(AAe,"STRONG",{});var Oit=s(tge);NKo=r(Oit,"speech_to_text"),Oit.forEach(t),qKo=r(AAe," \u2014 "),Nq=n(AAe,"A",{href:!0});var Git=s(Nq);OKo=r(Git,"TFSpeech2TextModel"),Git.forEach(t),GKo=r(AAe," (Speech2Text model)"),AAe.forEach(t),XKo=i(x),Nv=n(x,"LI",{});var LAe=s(Nv);age=n(LAe,"STRONG",{});var Xit=s(age);VKo=r(Xit,"t5"),Xit.forEach(t),zKo=r(LAe," \u2014 "),qq=n(LAe,"A",{href:!0});var Vit=s(qq);WKo=r(Vit,"TFT5Model"),Vit.forEach(t),QKo=r(LAe," (T5 model)"),LAe.forEach(t),HKo=i(x),qv=n(x,"LI",{});var BAe=s(qv);nge=n(BAe,"STRONG",{});var zit=s(nge);UKo=r(zit,"tapas"),zit.forEach(t),JKo=r(BAe," \u2014 "),Oq=n(BAe,"A",{href:!0});var Wit=s(Oq);YKo=r(Wit,"TFTapasModel"),Wit.forEach(t),KKo=r(BAe," (TAPAS model)"),BAe.forEach(t),ZKo=i(x),Ov=n(x,"LI",{});var xAe=s(Ov);sge=n(xAe,"STRONG",{});var Qit=s(sge);eZo=r(Qit,"transfo-xl"),Qit.forEach(t),oZo=r(xAe," \u2014 "),Gq=n(xAe,"A",{href:!0});var Hit=s(Gq);rZo=r(Hit,"TFTransfoXLModel"),Hit.forEach(t),tZo=r(xAe," (Transformer-XL model)"),xAe.forEach(t),aZo=i(x),Gv=n(x,"LI",{});var kAe=s(Gv);lge=n(kAe,"STRONG",{});var Uit=s(lge);nZo=r(Uit,"vit"),Uit.forEach(t),sZo=r(kAe," \u2014 "),Xq=n(kAe,"A",{href:!0});var Jit=s(Xq);lZo=r(Jit,"TFViTModel"),Jit.forEach(t),iZo=r(kAe," (ViT model)"),kAe.forEach(t),dZo=i(x),Xv=n(x,"LI",{});var RAe=s(Xv);ige=n(RAe,"STRONG",{});var Yit=s(ige);cZo=r(Yit,"wav2vec2"),Yit.forEach(t),fZo=r(RAe," \u2014 "),Vq=n(RAe,"A",{href:!0});var Kit=s(Vq);mZo=r(Kit,"TFWav2Vec2Model"),Kit.forEach(t),gZo=r(RAe," (Wav2Vec2 model)"),RAe.forEach(t),hZo=i(x),Vv=n(x,"LI",{});var SAe=s(Vv);dge=n(SAe,"STRONG",{});var Zit=s(dge);pZo=r(Zit,"xlm"),Zit.forEach(t),_Zo=r(SAe," \u2014 "),zq=n(SAe,"A",{href:!0});var edt=s(zq);uZo=r(edt,"TFXLMModel"),edt.forEach(t),bZo=r(SAe," (XLM model)"),SAe.forEach(t),vZo=i(x),zv=n(x,"LI",{});var PAe=s(zv);cge=n(PAe,"STRONG",{});var odt=s(cge);TZo=r(odt,"xlm-roberta"),odt.forEach(t),FZo=r(PAe," \u2014 "),Wq=n(PAe,"A",{href:!0});var rdt=s(Wq);CZo=r(rdt,"TFXLMRobertaModel"),rdt.forEach(t),MZo=r(PAe," (XLM-RoBERTa model)"),PAe.forEach(t),EZo=i(x),Wv=n(x,"LI",{});var $Ae=s(Wv);fge=n($Ae,"STRONG",{});var tdt=s(fge);yZo=r(tdt,"xlnet"),tdt.forEach(t),wZo=r($Ae," \u2014 "),Qq=n($Ae,"A",{href:!0});var adt=s(Qq);AZo=r(adt,"TFXLNetModel"),adt.forEach(t),LZo=r($Ae," (XLNet model)"),$Ae.forEach(t),x.forEach(t),BZo=i(ha),mge=n(ha,"P",{});var ndt=s(mge);xZo=r(ndt,"Examples:"),ndt.forEach(t),kZo=i(ha),m(Iw.$$.fragment,ha),ha.forEach(t),Nl.forEach(t),Fke=i(c),pc=n(c,"H2",{class:!0});var RSe=s(pc);Qv=n(RSe,"A",{id:!0,class:!0,href:!0});var sdt=s(Qv);gge=n(sdt,"SPAN",{});var ldt=s(gge);m(jw.$$.fragment,ldt),ldt.forEach(t),sdt.forEach(t),RZo=i(RSe),hge=n(RSe,"SPAN",{});var idt=s(hge);SZo=r(idt,"TFAutoModelForPreTraining"),idt.forEach(t),RSe.forEach(t),Cke=i(c),Tr=n(c,"DIV",{class:!0});var Ol=s(Tr);m(Dw.$$.fragment,Ol),PZo=i(Ol),_c=n(Ol,"P",{});var EW=s(_c);$Zo=r(EW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pge=n(EW,"CODE",{});var ddt=s(pge);IZo=r(ddt,"from_pretrained()"),ddt.forEach(t),jZo=r(EW,"class method or the "),_ge=n(EW,"CODE",{});var cdt=s(_ge);DZo=r(cdt,"from_config()"),cdt.forEach(t),NZo=r(EW,`class
method.`),EW.forEach(t),qZo=i(Ol),Nw=n(Ol,"P",{});var SSe=s(Nw);OZo=r(SSe,"This class cannot be instantiated directly using "),uge=n(SSe,"CODE",{});var fdt=s(uge);GZo=r(fdt,"__init__()"),fdt.forEach(t),XZo=r(SSe," (throws an error)."),SSe.forEach(t),VZo=i(Ol),ht=n(Ol,"DIV",{class:!0});var Gl=s(ht);m(qw.$$.fragment,Gl),zZo=i(Gl),bge=n(Gl,"P",{});var mdt=s(bge);WZo=r(mdt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),mdt.forEach(t),QZo=i(Gl),uc=n(Gl,"P",{});var yW=s(uc);HZo=r(yW,`Note:
Loading a model from its configuration file does `),vge=n(yW,"STRONG",{});var gdt=s(vge);UZo=r(gdt,"not"),gdt.forEach(t),JZo=r(yW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tge=n(yW,"CODE",{});var hdt=s(Tge);YZo=r(hdt,"from_pretrained()"),hdt.forEach(t),KZo=r(yW,"to load the model weights."),yW.forEach(t),ZZo=i(Gl),Fge=n(Gl,"P",{});var pdt=s(Fge);eer=r(pdt,"Examples:"),pdt.forEach(t),oer=i(Gl),m(Ow.$$.fragment,Gl),Gl.forEach(t),rer=i(Ol),po=n(Ol,"DIV",{class:!0});var pa=s(po);m(Gw.$$.fragment,pa),ter=i(pa),Cge=n(pa,"P",{});var _dt=s(Cge);aer=r(_dt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),_dt.forEach(t),ner=i(pa),_n=n(pa,"P",{});var E4=s(_n);ser=r(E4,"The model class to instantiate is selected based on the "),Mge=n(E4,"CODE",{});var udt=s(Mge);ler=r(udt,"model_type"),udt.forEach(t),ier=r(E4,` property of the config object (either
passed as an argument or loaded from `),Ege=n(E4,"CODE",{});var bdt=s(Ege);der=r(bdt,"pretrained_model_name_or_path"),bdt.forEach(t),cer=r(E4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yge=n(E4,"CODE",{});var vdt=s(yge);fer=r(vdt,"pretrained_model_name_or_path"),vdt.forEach(t),mer=r(E4,":"),E4.forEach(t),ger=i(pa),H=n(pa,"UL",{});var U=s(H);Hv=n(U,"LI",{});var IAe=s(Hv);wge=n(IAe,"STRONG",{});var Tdt=s(wge);her=r(Tdt,"albert"),Tdt.forEach(t),per=r(IAe," \u2014 "),Hq=n(IAe,"A",{href:!0});var Fdt=s(Hq);_er=r(Fdt,"TFAlbertForPreTraining"),Fdt.forEach(t),uer=r(IAe," (ALBERT model)"),IAe.forEach(t),ber=i(U),Uv=n(U,"LI",{});var jAe=s(Uv);Age=n(jAe,"STRONG",{});var Cdt=s(Age);ver=r(Cdt,"bart"),Cdt.forEach(t),Ter=r(jAe," \u2014 "),Uq=n(jAe,"A",{href:!0});var Mdt=s(Uq);Fer=r(Mdt,"TFBartForConditionalGeneration"),Mdt.forEach(t),Cer=r(jAe," (BART model)"),jAe.forEach(t),Mer=i(U),Jv=n(U,"LI",{});var DAe=s(Jv);Lge=n(DAe,"STRONG",{});var Edt=s(Lge);Eer=r(Edt,"bert"),Edt.forEach(t),yer=r(DAe," \u2014 "),Jq=n(DAe,"A",{href:!0});var ydt=s(Jq);wer=r(ydt,"TFBertForPreTraining"),ydt.forEach(t),Aer=r(DAe," (BERT model)"),DAe.forEach(t),Ler=i(U),Yv=n(U,"LI",{});var NAe=s(Yv);Bge=n(NAe,"STRONG",{});var wdt=s(Bge);Ber=r(wdt,"camembert"),wdt.forEach(t),xer=r(NAe," \u2014 "),Yq=n(NAe,"A",{href:!0});var Adt=s(Yq);ker=r(Adt,"TFCamembertForMaskedLM"),Adt.forEach(t),Rer=r(NAe," (CamemBERT model)"),NAe.forEach(t),Ser=i(U),Kv=n(U,"LI",{});var qAe=s(Kv);xge=n(qAe,"STRONG",{});var Ldt=s(xge);Per=r(Ldt,"ctrl"),Ldt.forEach(t),$er=r(qAe," \u2014 "),Kq=n(qAe,"A",{href:!0});var Bdt=s(Kq);Ier=r(Bdt,"TFCTRLLMHeadModel"),Bdt.forEach(t),jer=r(qAe," (CTRL model)"),qAe.forEach(t),Der=i(U),Zv=n(U,"LI",{});var OAe=s(Zv);kge=n(OAe,"STRONG",{});var xdt=s(kge);Ner=r(xdt,"distilbert"),xdt.forEach(t),qer=r(OAe," \u2014 "),Zq=n(OAe,"A",{href:!0});var kdt=s(Zq);Oer=r(kdt,"TFDistilBertForMaskedLM"),kdt.forEach(t),Ger=r(OAe," (DistilBERT model)"),OAe.forEach(t),Xer=i(U),e0=n(U,"LI",{});var GAe=s(e0);Rge=n(GAe,"STRONG",{});var Rdt=s(Rge);Ver=r(Rdt,"electra"),Rdt.forEach(t),zer=r(GAe," \u2014 "),eO=n(GAe,"A",{href:!0});var Sdt=s(eO);Wer=r(Sdt,"TFElectraForPreTraining"),Sdt.forEach(t),Qer=r(GAe," (ELECTRA model)"),GAe.forEach(t),Her=i(U),o0=n(U,"LI",{});var XAe=s(o0);Sge=n(XAe,"STRONG",{});var Pdt=s(Sge);Uer=r(Pdt,"flaubert"),Pdt.forEach(t),Jer=r(XAe," \u2014 "),oO=n(XAe,"A",{href:!0});var $dt=s(oO);Yer=r($dt,"TFFlaubertWithLMHeadModel"),$dt.forEach(t),Ker=r(XAe," (FlauBERT model)"),XAe.forEach(t),Zer=i(U),r0=n(U,"LI",{});var VAe=s(r0);Pge=n(VAe,"STRONG",{});var Idt=s(Pge);eor=r(Idt,"funnel"),Idt.forEach(t),oor=r(VAe," \u2014 "),rO=n(VAe,"A",{href:!0});var jdt=s(rO);ror=r(jdt,"TFFunnelForPreTraining"),jdt.forEach(t),tor=r(VAe," (Funnel Transformer model)"),VAe.forEach(t),aor=i(U),t0=n(U,"LI",{});var zAe=s(t0);$ge=n(zAe,"STRONG",{});var Ddt=s($ge);nor=r(Ddt,"gpt2"),Ddt.forEach(t),sor=r(zAe," \u2014 "),tO=n(zAe,"A",{href:!0});var Ndt=s(tO);lor=r(Ndt,"TFGPT2LMHeadModel"),Ndt.forEach(t),ior=r(zAe," (OpenAI GPT-2 model)"),zAe.forEach(t),dor=i(U),a0=n(U,"LI",{});var WAe=s(a0);Ige=n(WAe,"STRONG",{});var qdt=s(Ige);cor=r(qdt,"layoutlm"),qdt.forEach(t),mor=r(WAe," \u2014 "),aO=n(WAe,"A",{href:!0});var Odt=s(aO);gor=r(Odt,"TFLayoutLMForMaskedLM"),Odt.forEach(t),hor=r(WAe," (LayoutLM model)"),WAe.forEach(t),por=i(U),n0=n(U,"LI",{});var QAe=s(n0);jge=n(QAe,"STRONG",{});var Gdt=s(jge);_or=r(Gdt,"lxmert"),Gdt.forEach(t),uor=r(QAe," \u2014 "),nO=n(QAe,"A",{href:!0});var Xdt=s(nO);bor=r(Xdt,"TFLxmertForPreTraining"),Xdt.forEach(t),vor=r(QAe," (LXMERT model)"),QAe.forEach(t),Tor=i(U),s0=n(U,"LI",{});var HAe=s(s0);Dge=n(HAe,"STRONG",{});var Vdt=s(Dge);For=r(Vdt,"mobilebert"),Vdt.forEach(t),Cor=r(HAe," \u2014 "),sO=n(HAe,"A",{href:!0});var zdt=s(sO);Mor=r(zdt,"TFMobileBertForPreTraining"),zdt.forEach(t),Eor=r(HAe," (MobileBERT model)"),HAe.forEach(t),yor=i(U),l0=n(U,"LI",{});var UAe=s(l0);Nge=n(UAe,"STRONG",{});var Wdt=s(Nge);wor=r(Wdt,"mpnet"),Wdt.forEach(t),Aor=r(UAe," \u2014 "),lO=n(UAe,"A",{href:!0});var Qdt=s(lO);Lor=r(Qdt,"TFMPNetForMaskedLM"),Qdt.forEach(t),Bor=r(UAe," (MPNet model)"),UAe.forEach(t),xor=i(U),i0=n(U,"LI",{});var JAe=s(i0);qge=n(JAe,"STRONG",{});var Hdt=s(qge);kor=r(Hdt,"openai-gpt"),Hdt.forEach(t),Ror=r(JAe," \u2014 "),iO=n(JAe,"A",{href:!0});var Udt=s(iO);Sor=r(Udt,"TFOpenAIGPTLMHeadModel"),Udt.forEach(t),Por=r(JAe," (OpenAI GPT model)"),JAe.forEach(t),$or=i(U),d0=n(U,"LI",{});var YAe=s(d0);Oge=n(YAe,"STRONG",{});var Jdt=s(Oge);Ior=r(Jdt,"roberta"),Jdt.forEach(t),jor=r(YAe," \u2014 "),dO=n(YAe,"A",{href:!0});var Ydt=s(dO);Dor=r(Ydt,"TFRobertaForMaskedLM"),Ydt.forEach(t),Nor=r(YAe," (RoBERTa model)"),YAe.forEach(t),qor=i(U),c0=n(U,"LI",{});var KAe=s(c0);Gge=n(KAe,"STRONG",{});var Kdt=s(Gge);Oor=r(Kdt,"t5"),Kdt.forEach(t),Gor=r(KAe," \u2014 "),cO=n(KAe,"A",{href:!0});var Zdt=s(cO);Xor=r(Zdt,"TFT5ForConditionalGeneration"),Zdt.forEach(t),Vor=r(KAe," (T5 model)"),KAe.forEach(t),zor=i(U),f0=n(U,"LI",{});var ZAe=s(f0);Xge=n(ZAe,"STRONG",{});var ect=s(Xge);Wor=r(ect,"tapas"),ect.forEach(t),Qor=r(ZAe," \u2014 "),fO=n(ZAe,"A",{href:!0});var oct=s(fO);Hor=r(oct,"TFTapasForMaskedLM"),oct.forEach(t),Uor=r(ZAe," (TAPAS model)"),ZAe.forEach(t),Jor=i(U),m0=n(U,"LI",{});var eLe=s(m0);Vge=n(eLe,"STRONG",{});var rct=s(Vge);Yor=r(rct,"transfo-xl"),rct.forEach(t),Kor=r(eLe," \u2014 "),mO=n(eLe,"A",{href:!0});var tct=s(mO);Zor=r(tct,"TFTransfoXLLMHeadModel"),tct.forEach(t),err=r(eLe," (Transformer-XL model)"),eLe.forEach(t),orr=i(U),g0=n(U,"LI",{});var oLe=s(g0);zge=n(oLe,"STRONG",{});var act=s(zge);rrr=r(act,"xlm"),act.forEach(t),trr=r(oLe," \u2014 "),gO=n(oLe,"A",{href:!0});var nct=s(gO);arr=r(nct,"TFXLMWithLMHeadModel"),nct.forEach(t),nrr=r(oLe," (XLM model)"),oLe.forEach(t),srr=i(U),h0=n(U,"LI",{});var rLe=s(h0);Wge=n(rLe,"STRONG",{});var sct=s(Wge);lrr=r(sct,"xlm-roberta"),sct.forEach(t),irr=r(rLe," \u2014 "),hO=n(rLe,"A",{href:!0});var lct=s(hO);drr=r(lct,"TFXLMRobertaForMaskedLM"),lct.forEach(t),crr=r(rLe," (XLM-RoBERTa model)"),rLe.forEach(t),frr=i(U),p0=n(U,"LI",{});var tLe=s(p0);Qge=n(tLe,"STRONG",{});var ict=s(Qge);mrr=r(ict,"xlnet"),ict.forEach(t),grr=r(tLe," \u2014 "),pO=n(tLe,"A",{href:!0});var dct=s(pO);hrr=r(dct,"TFXLNetLMHeadModel"),dct.forEach(t),prr=r(tLe," (XLNet model)"),tLe.forEach(t),U.forEach(t),_rr=i(pa),Hge=n(pa,"P",{});var cct=s(Hge);urr=r(cct,"Examples:"),cct.forEach(t),brr=i(pa),m(Xw.$$.fragment,pa),pa.forEach(t),Ol.forEach(t),Mke=i(c),bc=n(c,"H2",{class:!0});var PSe=s(bc);_0=n(PSe,"A",{id:!0,class:!0,href:!0});var fct=s(_0);Uge=n(fct,"SPAN",{});var mct=s(Uge);m(Vw.$$.fragment,mct),mct.forEach(t),fct.forEach(t),vrr=i(PSe),Jge=n(PSe,"SPAN",{});var gct=s(Jge);Trr=r(gct,"TFAutoModelForCausalLM"),gct.forEach(t),PSe.forEach(t),Eke=i(c),Fr=n(c,"DIV",{class:!0});var Xl=s(Fr);m(zw.$$.fragment,Xl),Frr=i(Xl),vc=n(Xl,"P",{});var wW=s(vc);Crr=r(wW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yge=n(wW,"CODE",{});var hct=s(Yge);Mrr=r(hct,"from_pretrained()"),hct.forEach(t),Err=r(wW,"class method or the "),Kge=n(wW,"CODE",{});var pct=s(Kge);yrr=r(pct,"from_config()"),pct.forEach(t),wrr=r(wW,`class
method.`),wW.forEach(t),Arr=i(Xl),Ww=n(Xl,"P",{});var $Se=s(Ww);Lrr=r($Se,"This class cannot be instantiated directly using "),Zge=n($Se,"CODE",{});var _ct=s(Zge);Brr=r(_ct,"__init__()"),_ct.forEach(t),xrr=r($Se," (throws an error)."),$Se.forEach(t),krr=i(Xl),pt=n(Xl,"DIV",{class:!0});var Vl=s(pt);m(Qw.$$.fragment,Vl),Rrr=i(Vl),ehe=n(Vl,"P",{});var uct=s(ehe);Srr=r(uct,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),uct.forEach(t),Prr=i(Vl),Tc=n(Vl,"P",{});var AW=s(Tc);$rr=r(AW,`Note:
Loading a model from its configuration file does `),ohe=n(AW,"STRONG",{});var bct=s(ohe);Irr=r(bct,"not"),bct.forEach(t),jrr=r(AW,` load the model weights. It only affects the
model\u2019s configuration. Use `),rhe=n(AW,"CODE",{});var vct=s(rhe);Drr=r(vct,"from_pretrained()"),vct.forEach(t),Nrr=r(AW,"to load the model weights."),AW.forEach(t),qrr=i(Vl),the=n(Vl,"P",{});var Tct=s(the);Orr=r(Tct,"Examples:"),Tct.forEach(t),Grr=i(Vl),m(Hw.$$.fragment,Vl),Vl.forEach(t),Xrr=i(Xl),_o=n(Xl,"DIV",{class:!0});var _a=s(_o);m(Uw.$$.fragment,_a),Vrr=i(_a),ahe=n(_a,"P",{});var Fct=s(ahe);zrr=r(Fct,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Fct.forEach(t),Wrr=i(_a),un=n(_a,"P",{});var y4=s(un);Qrr=r(y4,"The model class to instantiate is selected based on the "),nhe=n(y4,"CODE",{});var Cct=s(nhe);Hrr=r(Cct,"model_type"),Cct.forEach(t),Urr=r(y4,` property of the config object (either
passed as an argument or loaded from `),she=n(y4,"CODE",{});var Mct=s(she);Jrr=r(Mct,"pretrained_model_name_or_path"),Mct.forEach(t),Yrr=r(y4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lhe=n(y4,"CODE",{});var Ect=s(lhe);Krr=r(Ect,"pretrained_model_name_or_path"),Ect.forEach(t),Zrr=r(y4,":"),y4.forEach(t),etr=i(_a),_e=n(_a,"UL",{});var Ee=s(_e);u0=n(Ee,"LI",{});var aLe=s(u0);ihe=n(aLe,"STRONG",{});var yct=s(ihe);otr=r(yct,"bert"),yct.forEach(t),rtr=r(aLe," \u2014 "),_O=n(aLe,"A",{href:!0});var wct=s(_O);ttr=r(wct,"TFBertLMHeadModel"),wct.forEach(t),atr=r(aLe," (BERT model)"),aLe.forEach(t),ntr=i(Ee),b0=n(Ee,"LI",{});var nLe=s(b0);dhe=n(nLe,"STRONG",{});var Act=s(dhe);str=r(Act,"ctrl"),Act.forEach(t),ltr=r(nLe," \u2014 "),uO=n(nLe,"A",{href:!0});var Lct=s(uO);itr=r(Lct,"TFCTRLLMHeadModel"),Lct.forEach(t),dtr=r(nLe," (CTRL model)"),nLe.forEach(t),ctr=i(Ee),v0=n(Ee,"LI",{});var sLe=s(v0);che=n(sLe,"STRONG",{});var Bct=s(che);ftr=r(Bct,"gpt2"),Bct.forEach(t),mtr=r(sLe," \u2014 "),bO=n(sLe,"A",{href:!0});var xct=s(bO);gtr=r(xct,"TFGPT2LMHeadModel"),xct.forEach(t),htr=r(sLe," (OpenAI GPT-2 model)"),sLe.forEach(t),ptr=i(Ee),T0=n(Ee,"LI",{});var lLe=s(T0);fhe=n(lLe,"STRONG",{});var kct=s(fhe);_tr=r(kct,"openai-gpt"),kct.forEach(t),utr=r(lLe," \u2014 "),vO=n(lLe,"A",{href:!0});var Rct=s(vO);btr=r(Rct,"TFOpenAIGPTLMHeadModel"),Rct.forEach(t),vtr=r(lLe," (OpenAI GPT model)"),lLe.forEach(t),Ttr=i(Ee),F0=n(Ee,"LI",{});var iLe=s(F0);mhe=n(iLe,"STRONG",{});var Sct=s(mhe);Ftr=r(Sct,"rembert"),Sct.forEach(t),Ctr=r(iLe," \u2014 "),TO=n(iLe,"A",{href:!0});var Pct=s(TO);Mtr=r(Pct,"TFRemBertForCausalLM"),Pct.forEach(t),Etr=r(iLe," (RemBERT model)"),iLe.forEach(t),ytr=i(Ee),C0=n(Ee,"LI",{});var dLe=s(C0);ghe=n(dLe,"STRONG",{});var $ct=s(ghe);wtr=r($ct,"roberta"),$ct.forEach(t),Atr=r(dLe," \u2014 "),FO=n(dLe,"A",{href:!0});var Ict=s(FO);Ltr=r(Ict,"TFRobertaForCausalLM"),Ict.forEach(t),Btr=r(dLe," (RoBERTa model)"),dLe.forEach(t),xtr=i(Ee),M0=n(Ee,"LI",{});var cLe=s(M0);hhe=n(cLe,"STRONG",{});var jct=s(hhe);ktr=r(jct,"roformer"),jct.forEach(t),Rtr=r(cLe," \u2014 "),CO=n(cLe,"A",{href:!0});var Dct=s(CO);Str=r(Dct,"TFRoFormerForCausalLM"),Dct.forEach(t),Ptr=r(cLe," (RoFormer model)"),cLe.forEach(t),$tr=i(Ee),E0=n(Ee,"LI",{});var fLe=s(E0);phe=n(fLe,"STRONG",{});var Nct=s(phe);Itr=r(Nct,"transfo-xl"),Nct.forEach(t),jtr=r(fLe," \u2014 "),MO=n(fLe,"A",{href:!0});var qct=s(MO);Dtr=r(qct,"TFTransfoXLLMHeadModel"),qct.forEach(t),Ntr=r(fLe," (Transformer-XL model)"),fLe.forEach(t),qtr=i(Ee),y0=n(Ee,"LI",{});var mLe=s(y0);_he=n(mLe,"STRONG",{});var Oct=s(_he);Otr=r(Oct,"xlm"),Oct.forEach(t),Gtr=r(mLe," \u2014 "),EO=n(mLe,"A",{href:!0});var Gct=s(EO);Xtr=r(Gct,"TFXLMWithLMHeadModel"),Gct.forEach(t),Vtr=r(mLe," (XLM model)"),mLe.forEach(t),ztr=i(Ee),w0=n(Ee,"LI",{});var gLe=s(w0);uhe=n(gLe,"STRONG",{});var Xct=s(uhe);Wtr=r(Xct,"xlnet"),Xct.forEach(t),Qtr=r(gLe," \u2014 "),yO=n(gLe,"A",{href:!0});var Vct=s(yO);Htr=r(Vct,"TFXLNetLMHeadModel"),Vct.forEach(t),Utr=r(gLe," (XLNet model)"),gLe.forEach(t),Ee.forEach(t),Jtr=i(_a),bhe=n(_a,"P",{});var zct=s(bhe);Ytr=r(zct,"Examples:"),zct.forEach(t),Ktr=i(_a),m(Jw.$$.fragment,_a),_a.forEach(t),Xl.forEach(t),yke=i(c),Fc=n(c,"H2",{class:!0});var ISe=s(Fc);A0=n(ISe,"A",{id:!0,class:!0,href:!0});var Wct=s(A0);vhe=n(Wct,"SPAN",{});var Qct=s(vhe);m(Yw.$$.fragment,Qct),Qct.forEach(t),Wct.forEach(t),Ztr=i(ISe),The=n(ISe,"SPAN",{});var Hct=s(The);ear=r(Hct,"TFAutoModelForImageClassification"),Hct.forEach(t),ISe.forEach(t),wke=i(c),Cr=n(c,"DIV",{class:!0});var zl=s(Cr);m(Kw.$$.fragment,zl),oar=i(zl),Cc=n(zl,"P",{});var LW=s(Cc);rar=r(LW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Fhe=n(LW,"CODE",{});var Uct=s(Fhe);tar=r(Uct,"from_pretrained()"),Uct.forEach(t),aar=r(LW,"class method or the "),Che=n(LW,"CODE",{});var Jct=s(Che);nar=r(Jct,"from_config()"),Jct.forEach(t),sar=r(LW,`class
method.`),LW.forEach(t),lar=i(zl),Zw=n(zl,"P",{});var jSe=s(Zw);iar=r(jSe,"This class cannot be instantiated directly using "),Mhe=n(jSe,"CODE",{});var Yct=s(Mhe);dar=r(Yct,"__init__()"),Yct.forEach(t),car=r(jSe," (throws an error)."),jSe.forEach(t),far=i(zl),_t=n(zl,"DIV",{class:!0});var Wl=s(_t);m(e6.$$.fragment,Wl),mar=i(Wl),Ehe=n(Wl,"P",{});var Kct=s(Ehe);gar=r(Kct,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Kct.forEach(t),har=i(Wl),Mc=n(Wl,"P",{});var BW=s(Mc);par=r(BW,`Note:
Loading a model from its configuration file does `),yhe=n(BW,"STRONG",{});var Zct=s(yhe);_ar=r(Zct,"not"),Zct.forEach(t),uar=r(BW,` load the model weights. It only affects the
model\u2019s configuration. Use `),whe=n(BW,"CODE",{});var eft=s(whe);bar=r(eft,"from_pretrained()"),eft.forEach(t),Tar=r(BW,"to load the model weights."),BW.forEach(t),Far=i(Wl),Ahe=n(Wl,"P",{});var oft=s(Ahe);Car=r(oft,"Examples:"),oft.forEach(t),Mar=i(Wl),m(o6.$$.fragment,Wl),Wl.forEach(t),Ear=i(zl),uo=n(zl,"DIV",{class:!0});var ua=s(uo);m(r6.$$.fragment,ua),yar=i(ua),Lhe=n(ua,"P",{});var rft=s(Lhe);war=r(rft,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),rft.forEach(t),Aar=i(ua),bn=n(ua,"P",{});var w4=s(bn);Lar=r(w4,"The model class to instantiate is selected based on the "),Bhe=n(w4,"CODE",{});var tft=s(Bhe);Bar=r(tft,"model_type"),tft.forEach(t),xar=r(w4,` property of the config object (either
passed as an argument or loaded from `),xhe=n(w4,"CODE",{});var aft=s(xhe);kar=r(aft,"pretrained_model_name_or_path"),aft.forEach(t),Rar=r(w4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),khe=n(w4,"CODE",{});var nft=s(khe);Sar=r(nft,"pretrained_model_name_or_path"),nft.forEach(t),Par=r(w4,":"),w4.forEach(t),$ar=i(ua),t6=n(ua,"UL",{});var DSe=s(t6);L0=n(DSe,"LI",{});var hLe=s(L0);Rhe=n(hLe,"STRONG",{});var sft=s(Rhe);Iar=r(sft,"convnext"),sft.forEach(t),jar=r(hLe," \u2014 "),wO=n(hLe,"A",{href:!0});var lft=s(wO);Dar=r(lft,"TFConvNextForImageClassification"),lft.forEach(t),Nar=r(hLe," (ConvNext model)"),hLe.forEach(t),qar=i(DSe),B0=n(DSe,"LI",{});var pLe=s(B0);She=n(pLe,"STRONG",{});var ift=s(She);Oar=r(ift,"vit"),ift.forEach(t),Gar=r(pLe," \u2014 "),AO=n(pLe,"A",{href:!0});var dft=s(AO);Xar=r(dft,"TFViTForImageClassification"),dft.forEach(t),Var=r(pLe," (ViT model)"),pLe.forEach(t),DSe.forEach(t),zar=i(ua),Phe=n(ua,"P",{});var cft=s(Phe);War=r(cft,"Examples:"),cft.forEach(t),Qar=i(ua),m(a6.$$.fragment,ua),ua.forEach(t),zl.forEach(t),Ake=i(c),Ec=n(c,"H2",{class:!0});var NSe=s(Ec);x0=n(NSe,"A",{id:!0,class:!0,href:!0});var fft=s(x0);$he=n(fft,"SPAN",{});var mft=s($he);m(n6.$$.fragment,mft),mft.forEach(t),fft.forEach(t),Har=i(NSe),Ihe=n(NSe,"SPAN",{});var gft=s(Ihe);Uar=r(gft,"TFAutoModelForMaskedLM"),gft.forEach(t),NSe.forEach(t),Lke=i(c),Mr=n(c,"DIV",{class:!0});var Ql=s(Mr);m(s6.$$.fragment,Ql),Jar=i(Ql),yc=n(Ql,"P",{});var xW=s(yc);Yar=r(xW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jhe=n(xW,"CODE",{});var hft=s(jhe);Kar=r(hft,"from_pretrained()"),hft.forEach(t),Zar=r(xW,"class method or the "),Dhe=n(xW,"CODE",{});var pft=s(Dhe);enr=r(pft,"from_config()"),pft.forEach(t),onr=r(xW,`class
method.`),xW.forEach(t),rnr=i(Ql),l6=n(Ql,"P",{});var qSe=s(l6);tnr=r(qSe,"This class cannot be instantiated directly using "),Nhe=n(qSe,"CODE",{});var _ft=s(Nhe);anr=r(_ft,"__init__()"),_ft.forEach(t),nnr=r(qSe," (throws an error)."),qSe.forEach(t),snr=i(Ql),ut=n(Ql,"DIV",{class:!0});var Hl=s(ut);m(i6.$$.fragment,Hl),lnr=i(Hl),qhe=n(Hl,"P",{});var uft=s(qhe);inr=r(uft,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),uft.forEach(t),dnr=i(Hl),wc=n(Hl,"P",{});var kW=s(wc);cnr=r(kW,`Note:
Loading a model from its configuration file does `),Ohe=n(kW,"STRONG",{});var bft=s(Ohe);fnr=r(bft,"not"),bft.forEach(t),mnr=r(kW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ghe=n(kW,"CODE",{});var vft=s(Ghe);gnr=r(vft,"from_pretrained()"),vft.forEach(t),hnr=r(kW,"to load the model weights."),kW.forEach(t),pnr=i(Hl),Xhe=n(Hl,"P",{});var Tft=s(Xhe);_nr=r(Tft,"Examples:"),Tft.forEach(t),unr=i(Hl),m(d6.$$.fragment,Hl),Hl.forEach(t),bnr=i(Ql),bo=n(Ql,"DIV",{class:!0});var ba=s(bo);m(c6.$$.fragment,ba),vnr=i(ba),Vhe=n(ba,"P",{});var Fft=s(Vhe);Tnr=r(Fft,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Fft.forEach(t),Fnr=i(ba),vn=n(ba,"P",{});var A4=s(vn);Cnr=r(A4,"The model class to instantiate is selected based on the "),zhe=n(A4,"CODE",{});var Cft=s(zhe);Mnr=r(Cft,"model_type"),Cft.forEach(t),Enr=r(A4,` property of the config object (either
passed as an argument or loaded from `),Whe=n(A4,"CODE",{});var Mft=s(Whe);ynr=r(Mft,"pretrained_model_name_or_path"),Mft.forEach(t),wnr=r(A4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qhe=n(A4,"CODE",{});var Eft=s(Qhe);Anr=r(Eft,"pretrained_model_name_or_path"),Eft.forEach(t),Lnr=r(A4,":"),A4.forEach(t),Bnr=i(ba),Y=n(ba,"UL",{});var ee=s(Y);k0=n(ee,"LI",{});var _Le=s(k0);Hhe=n(_Le,"STRONG",{});var yft=s(Hhe);xnr=r(yft,"albert"),yft.forEach(t),knr=r(_Le," \u2014 "),LO=n(_Le,"A",{href:!0});var wft=s(LO);Rnr=r(wft,"TFAlbertForMaskedLM"),wft.forEach(t),Snr=r(_Le," (ALBERT model)"),_Le.forEach(t),Pnr=i(ee),R0=n(ee,"LI",{});var uLe=s(R0);Uhe=n(uLe,"STRONG",{});var Aft=s(Uhe);$nr=r(Aft,"bert"),Aft.forEach(t),Inr=r(uLe," \u2014 "),BO=n(uLe,"A",{href:!0});var Lft=s(BO);jnr=r(Lft,"TFBertForMaskedLM"),Lft.forEach(t),Dnr=r(uLe," (BERT model)"),uLe.forEach(t),Nnr=i(ee),S0=n(ee,"LI",{});var bLe=s(S0);Jhe=n(bLe,"STRONG",{});var Bft=s(Jhe);qnr=r(Bft,"camembert"),Bft.forEach(t),Onr=r(bLe," \u2014 "),xO=n(bLe,"A",{href:!0});var xft=s(xO);Gnr=r(xft,"TFCamembertForMaskedLM"),xft.forEach(t),Xnr=r(bLe," (CamemBERT model)"),bLe.forEach(t),Vnr=i(ee),P0=n(ee,"LI",{});var vLe=s(P0);Yhe=n(vLe,"STRONG",{});var kft=s(Yhe);znr=r(kft,"convbert"),kft.forEach(t),Wnr=r(vLe," \u2014 "),kO=n(vLe,"A",{href:!0});var Rft=s(kO);Qnr=r(Rft,"TFConvBertForMaskedLM"),Rft.forEach(t),Hnr=r(vLe," (ConvBERT model)"),vLe.forEach(t),Unr=i(ee),$0=n(ee,"LI",{});var TLe=s($0);Khe=n(TLe,"STRONG",{});var Sft=s(Khe);Jnr=r(Sft,"deberta"),Sft.forEach(t),Ynr=r(TLe," \u2014 "),RO=n(TLe,"A",{href:!0});var Pft=s(RO);Knr=r(Pft,"TFDebertaForMaskedLM"),Pft.forEach(t),Znr=r(TLe," (DeBERTa model)"),TLe.forEach(t),esr=i(ee),I0=n(ee,"LI",{});var FLe=s(I0);Zhe=n(FLe,"STRONG",{});var $ft=s(Zhe);osr=r($ft,"deberta-v2"),$ft.forEach(t),rsr=r(FLe," \u2014 "),SO=n(FLe,"A",{href:!0});var Ift=s(SO);tsr=r(Ift,"TFDebertaV2ForMaskedLM"),Ift.forEach(t),asr=r(FLe," (DeBERTa-v2 model)"),FLe.forEach(t),nsr=i(ee),j0=n(ee,"LI",{});var CLe=s(j0);epe=n(CLe,"STRONG",{});var jft=s(epe);ssr=r(jft,"distilbert"),jft.forEach(t),lsr=r(CLe," \u2014 "),PO=n(CLe,"A",{href:!0});var Dft=s(PO);isr=r(Dft,"TFDistilBertForMaskedLM"),Dft.forEach(t),dsr=r(CLe," (DistilBERT model)"),CLe.forEach(t),csr=i(ee),D0=n(ee,"LI",{});var MLe=s(D0);ope=n(MLe,"STRONG",{});var Nft=s(ope);fsr=r(Nft,"electra"),Nft.forEach(t),msr=r(MLe," \u2014 "),$O=n(MLe,"A",{href:!0});var qft=s($O);gsr=r(qft,"TFElectraForMaskedLM"),qft.forEach(t),hsr=r(MLe," (ELECTRA model)"),MLe.forEach(t),psr=i(ee),N0=n(ee,"LI",{});var ELe=s(N0);rpe=n(ELe,"STRONG",{});var Oft=s(rpe);_sr=r(Oft,"flaubert"),Oft.forEach(t),usr=r(ELe," \u2014 "),IO=n(ELe,"A",{href:!0});var Gft=s(IO);bsr=r(Gft,"TFFlaubertWithLMHeadModel"),Gft.forEach(t),vsr=r(ELe," (FlauBERT model)"),ELe.forEach(t),Tsr=i(ee),q0=n(ee,"LI",{});var yLe=s(q0);tpe=n(yLe,"STRONG",{});var Xft=s(tpe);Fsr=r(Xft,"funnel"),Xft.forEach(t),Csr=r(yLe," \u2014 "),jO=n(yLe,"A",{href:!0});var Vft=s(jO);Msr=r(Vft,"TFFunnelForMaskedLM"),Vft.forEach(t),Esr=r(yLe," (Funnel Transformer model)"),yLe.forEach(t),ysr=i(ee),O0=n(ee,"LI",{});var wLe=s(O0);ape=n(wLe,"STRONG",{});var zft=s(ape);wsr=r(zft,"layoutlm"),zft.forEach(t),Asr=r(wLe," \u2014 "),DO=n(wLe,"A",{href:!0});var Wft=s(DO);Lsr=r(Wft,"TFLayoutLMForMaskedLM"),Wft.forEach(t),Bsr=r(wLe," (LayoutLM model)"),wLe.forEach(t),xsr=i(ee),G0=n(ee,"LI",{});var ALe=s(G0);npe=n(ALe,"STRONG",{});var Qft=s(npe);ksr=r(Qft,"longformer"),Qft.forEach(t),Rsr=r(ALe," \u2014 "),NO=n(ALe,"A",{href:!0});var Hft=s(NO);Ssr=r(Hft,"TFLongformerForMaskedLM"),Hft.forEach(t),Psr=r(ALe," (Longformer model)"),ALe.forEach(t),$sr=i(ee),X0=n(ee,"LI",{});var LLe=s(X0);spe=n(LLe,"STRONG",{});var Uft=s(spe);Isr=r(Uft,"mobilebert"),Uft.forEach(t),jsr=r(LLe," \u2014 "),qO=n(LLe,"A",{href:!0});var Jft=s(qO);Dsr=r(Jft,"TFMobileBertForMaskedLM"),Jft.forEach(t),Nsr=r(LLe," (MobileBERT model)"),LLe.forEach(t),qsr=i(ee),V0=n(ee,"LI",{});var BLe=s(V0);lpe=n(BLe,"STRONG",{});var Yft=s(lpe);Osr=r(Yft,"mpnet"),Yft.forEach(t),Gsr=r(BLe," \u2014 "),OO=n(BLe,"A",{href:!0});var Kft=s(OO);Xsr=r(Kft,"TFMPNetForMaskedLM"),Kft.forEach(t),Vsr=r(BLe," (MPNet model)"),BLe.forEach(t),zsr=i(ee),z0=n(ee,"LI",{});var xLe=s(z0);ipe=n(xLe,"STRONG",{});var Zft=s(ipe);Wsr=r(Zft,"rembert"),Zft.forEach(t),Qsr=r(xLe," \u2014 "),GO=n(xLe,"A",{href:!0});var emt=s(GO);Hsr=r(emt,"TFRemBertForMaskedLM"),emt.forEach(t),Usr=r(xLe," (RemBERT model)"),xLe.forEach(t),Jsr=i(ee),W0=n(ee,"LI",{});var kLe=s(W0);dpe=n(kLe,"STRONG",{});var omt=s(dpe);Ysr=r(omt,"roberta"),omt.forEach(t),Ksr=r(kLe," \u2014 "),XO=n(kLe,"A",{href:!0});var rmt=s(XO);Zsr=r(rmt,"TFRobertaForMaskedLM"),rmt.forEach(t),elr=r(kLe," (RoBERTa model)"),kLe.forEach(t),olr=i(ee),Q0=n(ee,"LI",{});var RLe=s(Q0);cpe=n(RLe,"STRONG",{});var tmt=s(cpe);rlr=r(tmt,"roformer"),tmt.forEach(t),tlr=r(RLe," \u2014 "),VO=n(RLe,"A",{href:!0});var amt=s(VO);alr=r(amt,"TFRoFormerForMaskedLM"),amt.forEach(t),nlr=r(RLe," (RoFormer model)"),RLe.forEach(t),slr=i(ee),H0=n(ee,"LI",{});var SLe=s(H0);fpe=n(SLe,"STRONG",{});var nmt=s(fpe);llr=r(nmt,"tapas"),nmt.forEach(t),ilr=r(SLe," \u2014 "),zO=n(SLe,"A",{href:!0});var smt=s(zO);dlr=r(smt,"TFTapasForMaskedLM"),smt.forEach(t),clr=r(SLe," (TAPAS model)"),SLe.forEach(t),flr=i(ee),U0=n(ee,"LI",{});var PLe=s(U0);mpe=n(PLe,"STRONG",{});var lmt=s(mpe);mlr=r(lmt,"xlm"),lmt.forEach(t),glr=r(PLe," \u2014 "),WO=n(PLe,"A",{href:!0});var imt=s(WO);hlr=r(imt,"TFXLMWithLMHeadModel"),imt.forEach(t),plr=r(PLe," (XLM model)"),PLe.forEach(t),_lr=i(ee),J0=n(ee,"LI",{});var $Le=s(J0);gpe=n($Le,"STRONG",{});var dmt=s(gpe);ulr=r(dmt,"xlm-roberta"),dmt.forEach(t),blr=r($Le," \u2014 "),QO=n($Le,"A",{href:!0});var cmt=s(QO);vlr=r(cmt,"TFXLMRobertaForMaskedLM"),cmt.forEach(t),Tlr=r($Le," (XLM-RoBERTa model)"),$Le.forEach(t),ee.forEach(t),Flr=i(ba),hpe=n(ba,"P",{});var fmt=s(hpe);Clr=r(fmt,"Examples:"),fmt.forEach(t),Mlr=i(ba),m(f6.$$.fragment,ba),ba.forEach(t),Ql.forEach(t),Bke=i(c),Ac=n(c,"H2",{class:!0});var OSe=s(Ac);Y0=n(OSe,"A",{id:!0,class:!0,href:!0});var mmt=s(Y0);ppe=n(mmt,"SPAN",{});var gmt=s(ppe);m(m6.$$.fragment,gmt),gmt.forEach(t),mmt.forEach(t),Elr=i(OSe),_pe=n(OSe,"SPAN",{});var hmt=s(_pe);ylr=r(hmt,"TFAutoModelForSeq2SeqLM"),hmt.forEach(t),OSe.forEach(t),xke=i(c),Er=n(c,"DIV",{class:!0});var Ul=s(Er);m(g6.$$.fragment,Ul),wlr=i(Ul),Lc=n(Ul,"P",{});var RW=s(Lc);Alr=r(RW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),upe=n(RW,"CODE",{});var pmt=s(upe);Llr=r(pmt,"from_pretrained()"),pmt.forEach(t),Blr=r(RW,"class method or the "),bpe=n(RW,"CODE",{});var _mt=s(bpe);xlr=r(_mt,"from_config()"),_mt.forEach(t),klr=r(RW,`class
method.`),RW.forEach(t),Rlr=i(Ul),h6=n(Ul,"P",{});var GSe=s(h6);Slr=r(GSe,"This class cannot be instantiated directly using "),vpe=n(GSe,"CODE",{});var umt=s(vpe);Plr=r(umt,"__init__()"),umt.forEach(t),$lr=r(GSe," (throws an error)."),GSe.forEach(t),Ilr=i(Ul),bt=n(Ul,"DIV",{class:!0});var Jl=s(bt);m(p6.$$.fragment,Jl),jlr=i(Jl),Tpe=n(Jl,"P",{});var bmt=s(Tpe);Dlr=r(bmt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bmt.forEach(t),Nlr=i(Jl),Bc=n(Jl,"P",{});var SW=s(Bc);qlr=r(SW,`Note:
Loading a model from its configuration file does `),Fpe=n(SW,"STRONG",{});var vmt=s(Fpe);Olr=r(vmt,"not"),vmt.forEach(t),Glr=r(SW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cpe=n(SW,"CODE",{});var Tmt=s(Cpe);Xlr=r(Tmt,"from_pretrained()"),Tmt.forEach(t),Vlr=r(SW,"to load the model weights."),SW.forEach(t),zlr=i(Jl),Mpe=n(Jl,"P",{});var Fmt=s(Mpe);Wlr=r(Fmt,"Examples:"),Fmt.forEach(t),Qlr=i(Jl),m(_6.$$.fragment,Jl),Jl.forEach(t),Hlr=i(Ul),vo=n(Ul,"DIV",{class:!0});var va=s(vo);m(u6.$$.fragment,va),Ulr=i(va),Epe=n(va,"P",{});var Cmt=s(Epe);Jlr=r(Cmt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Cmt.forEach(t),Ylr=i(va),Tn=n(va,"P",{});var L4=s(Tn);Klr=r(L4,"The model class to instantiate is selected based on the "),ype=n(L4,"CODE",{});var Mmt=s(ype);Zlr=r(Mmt,"model_type"),Mmt.forEach(t),eir=r(L4,` property of the config object (either
passed as an argument or loaded from `),wpe=n(L4,"CODE",{});var Emt=s(wpe);oir=r(Emt,"pretrained_model_name_or_path"),Emt.forEach(t),rir=r(L4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ape=n(L4,"CODE",{});var ymt=s(Ape);tir=r(ymt,"pretrained_model_name_or_path"),ymt.forEach(t),air=r(L4,":"),L4.forEach(t),nir=i(va),ue=n(va,"UL",{});var ye=s(ue);K0=n(ye,"LI",{});var ILe=s(K0);Lpe=n(ILe,"STRONG",{});var wmt=s(Lpe);sir=r(wmt,"bart"),wmt.forEach(t),lir=r(ILe," \u2014 "),HO=n(ILe,"A",{href:!0});var Amt=s(HO);iir=r(Amt,"TFBartForConditionalGeneration"),Amt.forEach(t),dir=r(ILe," (BART model)"),ILe.forEach(t),cir=i(ye),Z0=n(ye,"LI",{});var jLe=s(Z0);Bpe=n(jLe,"STRONG",{});var Lmt=s(Bpe);fir=r(Lmt,"blenderbot"),Lmt.forEach(t),mir=r(jLe," \u2014 "),UO=n(jLe,"A",{href:!0});var Bmt=s(UO);gir=r(Bmt,"TFBlenderbotForConditionalGeneration"),Bmt.forEach(t),hir=r(jLe," (Blenderbot model)"),jLe.forEach(t),pir=i(ye),eT=n(ye,"LI",{});var DLe=s(eT);xpe=n(DLe,"STRONG",{});var xmt=s(xpe);_ir=r(xmt,"blenderbot-small"),xmt.forEach(t),uir=r(DLe," \u2014 "),JO=n(DLe,"A",{href:!0});var kmt=s(JO);bir=r(kmt,"TFBlenderbotSmallForConditionalGeneration"),kmt.forEach(t),vir=r(DLe," (BlenderbotSmall model)"),DLe.forEach(t),Tir=i(ye),oT=n(ye,"LI",{});var NLe=s(oT);kpe=n(NLe,"STRONG",{});var Rmt=s(kpe);Fir=r(Rmt,"encoder-decoder"),Rmt.forEach(t),Cir=r(NLe," \u2014 "),YO=n(NLe,"A",{href:!0});var Smt=s(YO);Mir=r(Smt,"TFEncoderDecoderModel"),Smt.forEach(t),Eir=r(NLe," (Encoder decoder model)"),NLe.forEach(t),yir=i(ye),rT=n(ye,"LI",{});var qLe=s(rT);Rpe=n(qLe,"STRONG",{});var Pmt=s(Rpe);wir=r(Pmt,"led"),Pmt.forEach(t),Air=r(qLe," \u2014 "),KO=n(qLe,"A",{href:!0});var $mt=s(KO);Lir=r($mt,"TFLEDForConditionalGeneration"),$mt.forEach(t),Bir=r(qLe," (LED model)"),qLe.forEach(t),xir=i(ye),tT=n(ye,"LI",{});var OLe=s(tT);Spe=n(OLe,"STRONG",{});var Imt=s(Spe);kir=r(Imt,"marian"),Imt.forEach(t),Rir=r(OLe," \u2014 "),ZO=n(OLe,"A",{href:!0});var jmt=s(ZO);Sir=r(jmt,"TFMarianMTModel"),jmt.forEach(t),Pir=r(OLe," (Marian model)"),OLe.forEach(t),$ir=i(ye),aT=n(ye,"LI",{});var GLe=s(aT);Ppe=n(GLe,"STRONG",{});var Dmt=s(Ppe);Iir=r(Dmt,"mbart"),Dmt.forEach(t),jir=r(GLe," \u2014 "),eG=n(GLe,"A",{href:!0});var Nmt=s(eG);Dir=r(Nmt,"TFMBartForConditionalGeneration"),Nmt.forEach(t),Nir=r(GLe," (mBART model)"),GLe.forEach(t),qir=i(ye),nT=n(ye,"LI",{});var XLe=s(nT);$pe=n(XLe,"STRONG",{});var qmt=s($pe);Oir=r(qmt,"mt5"),qmt.forEach(t),Gir=r(XLe," \u2014 "),oG=n(XLe,"A",{href:!0});var Omt=s(oG);Xir=r(Omt,"TFMT5ForConditionalGeneration"),Omt.forEach(t),Vir=r(XLe," (mT5 model)"),XLe.forEach(t),zir=i(ye),sT=n(ye,"LI",{});var VLe=s(sT);Ipe=n(VLe,"STRONG",{});var Gmt=s(Ipe);Wir=r(Gmt,"pegasus"),Gmt.forEach(t),Qir=r(VLe," \u2014 "),rG=n(VLe,"A",{href:!0});var Xmt=s(rG);Hir=r(Xmt,"TFPegasusForConditionalGeneration"),Xmt.forEach(t),Uir=r(VLe," (Pegasus model)"),VLe.forEach(t),Jir=i(ye),lT=n(ye,"LI",{});var zLe=s(lT);jpe=n(zLe,"STRONG",{});var Vmt=s(jpe);Yir=r(Vmt,"t5"),Vmt.forEach(t),Kir=r(zLe," \u2014 "),tG=n(zLe,"A",{href:!0});var zmt=s(tG);Zir=r(zmt,"TFT5ForConditionalGeneration"),zmt.forEach(t),edr=r(zLe," (T5 model)"),zLe.forEach(t),ye.forEach(t),odr=i(va),Dpe=n(va,"P",{});var Wmt=s(Dpe);rdr=r(Wmt,"Examples:"),Wmt.forEach(t),tdr=i(va),m(b6.$$.fragment,va),va.forEach(t),Ul.forEach(t),kke=i(c),xc=n(c,"H2",{class:!0});var XSe=s(xc);iT=n(XSe,"A",{id:!0,class:!0,href:!0});var Qmt=s(iT);Npe=n(Qmt,"SPAN",{});var Hmt=s(Npe);m(v6.$$.fragment,Hmt),Hmt.forEach(t),Qmt.forEach(t),adr=i(XSe),qpe=n(XSe,"SPAN",{});var Umt=s(qpe);ndr=r(Umt,"TFAutoModelForSequenceClassification"),Umt.forEach(t),XSe.forEach(t),Rke=i(c),yr=n(c,"DIV",{class:!0});var Yl=s(yr);m(T6.$$.fragment,Yl),sdr=i(Yl),kc=n(Yl,"P",{});var PW=s(kc);ldr=r(PW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Ope=n(PW,"CODE",{});var Jmt=s(Ope);idr=r(Jmt,"from_pretrained()"),Jmt.forEach(t),ddr=r(PW,"class method or the "),Gpe=n(PW,"CODE",{});var Ymt=s(Gpe);cdr=r(Ymt,"from_config()"),Ymt.forEach(t),fdr=r(PW,`class
method.`),PW.forEach(t),mdr=i(Yl),F6=n(Yl,"P",{});var VSe=s(F6);gdr=r(VSe,"This class cannot be instantiated directly using "),Xpe=n(VSe,"CODE",{});var Kmt=s(Xpe);hdr=r(Kmt,"__init__()"),Kmt.forEach(t),pdr=r(VSe," (throws an error)."),VSe.forEach(t),_dr=i(Yl),vt=n(Yl,"DIV",{class:!0});var Kl=s(vt);m(C6.$$.fragment,Kl),udr=i(Kl),Vpe=n(Kl,"P",{});var Zmt=s(Vpe);bdr=r(Zmt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Zmt.forEach(t),vdr=i(Kl),Rc=n(Kl,"P",{});var $W=s(Rc);Tdr=r($W,`Note:
Loading a model from its configuration file does `),zpe=n($W,"STRONG",{});var egt=s(zpe);Fdr=r(egt,"not"),egt.forEach(t),Cdr=r($W,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wpe=n($W,"CODE",{});var ogt=s(Wpe);Mdr=r(ogt,"from_pretrained()"),ogt.forEach(t),Edr=r($W,"to load the model weights."),$W.forEach(t),ydr=i(Kl),Qpe=n(Kl,"P",{});var rgt=s(Qpe);wdr=r(rgt,"Examples:"),rgt.forEach(t),Adr=i(Kl),m(M6.$$.fragment,Kl),Kl.forEach(t),Ldr=i(Yl),To=n(Yl,"DIV",{class:!0});var Ta=s(To);m(E6.$$.fragment,Ta),Bdr=i(Ta),Hpe=n(Ta,"P",{});var tgt=s(Hpe);xdr=r(tgt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),tgt.forEach(t),kdr=i(Ta),Fn=n(Ta,"P",{});var B4=s(Fn);Rdr=r(B4,"The model class to instantiate is selected based on the "),Upe=n(B4,"CODE",{});var agt=s(Upe);Sdr=r(agt,"model_type"),agt.forEach(t),Pdr=r(B4,` property of the config object (either
passed as an argument or loaded from `),Jpe=n(B4,"CODE",{});var ngt=s(Jpe);$dr=r(ngt,"pretrained_model_name_or_path"),ngt.forEach(t),Idr=r(B4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ype=n(B4,"CODE",{});var sgt=s(Ype);jdr=r(sgt,"pretrained_model_name_or_path"),sgt.forEach(t),Ddr=r(B4,":"),B4.forEach(t),Ndr=i(Ta),V=n(Ta,"UL",{});var W=s(V);dT=n(W,"LI",{});var WLe=s(dT);Kpe=n(WLe,"STRONG",{});var lgt=s(Kpe);qdr=r(lgt,"albert"),lgt.forEach(t),Odr=r(WLe," \u2014 "),aG=n(WLe,"A",{href:!0});var igt=s(aG);Gdr=r(igt,"TFAlbertForSequenceClassification"),igt.forEach(t),Xdr=r(WLe," (ALBERT model)"),WLe.forEach(t),Vdr=i(W),cT=n(W,"LI",{});var QLe=s(cT);Zpe=n(QLe,"STRONG",{});var dgt=s(Zpe);zdr=r(dgt,"bert"),dgt.forEach(t),Wdr=r(QLe," \u2014 "),nG=n(QLe,"A",{href:!0});var cgt=s(nG);Qdr=r(cgt,"TFBertForSequenceClassification"),cgt.forEach(t),Hdr=r(QLe," (BERT model)"),QLe.forEach(t),Udr=i(W),fT=n(W,"LI",{});var HLe=s(fT);e_e=n(HLe,"STRONG",{});var fgt=s(e_e);Jdr=r(fgt,"camembert"),fgt.forEach(t),Ydr=r(HLe," \u2014 "),sG=n(HLe,"A",{href:!0});var mgt=s(sG);Kdr=r(mgt,"TFCamembertForSequenceClassification"),mgt.forEach(t),Zdr=r(HLe," (CamemBERT model)"),HLe.forEach(t),ecr=i(W),mT=n(W,"LI",{});var ULe=s(mT);o_e=n(ULe,"STRONG",{});var ggt=s(o_e);ocr=r(ggt,"convbert"),ggt.forEach(t),rcr=r(ULe," \u2014 "),lG=n(ULe,"A",{href:!0});var hgt=s(lG);tcr=r(hgt,"TFConvBertForSequenceClassification"),hgt.forEach(t),acr=r(ULe," (ConvBERT model)"),ULe.forEach(t),ncr=i(W),gT=n(W,"LI",{});var JLe=s(gT);r_e=n(JLe,"STRONG",{});var pgt=s(r_e);scr=r(pgt,"ctrl"),pgt.forEach(t),lcr=r(JLe," \u2014 "),iG=n(JLe,"A",{href:!0});var _gt=s(iG);icr=r(_gt,"TFCTRLForSequenceClassification"),_gt.forEach(t),dcr=r(JLe," (CTRL model)"),JLe.forEach(t),ccr=i(W),hT=n(W,"LI",{});var YLe=s(hT);t_e=n(YLe,"STRONG",{});var ugt=s(t_e);fcr=r(ugt,"deberta"),ugt.forEach(t),mcr=r(YLe," \u2014 "),dG=n(YLe,"A",{href:!0});var bgt=s(dG);gcr=r(bgt,"TFDebertaForSequenceClassification"),bgt.forEach(t),hcr=r(YLe," (DeBERTa model)"),YLe.forEach(t),pcr=i(W),pT=n(W,"LI",{});var KLe=s(pT);a_e=n(KLe,"STRONG",{});var vgt=s(a_e);_cr=r(vgt,"deberta-v2"),vgt.forEach(t),ucr=r(KLe," \u2014 "),cG=n(KLe,"A",{href:!0});var Tgt=s(cG);bcr=r(Tgt,"TFDebertaV2ForSequenceClassification"),Tgt.forEach(t),vcr=r(KLe," (DeBERTa-v2 model)"),KLe.forEach(t),Tcr=i(W),_T=n(W,"LI",{});var ZLe=s(_T);n_e=n(ZLe,"STRONG",{});var Fgt=s(n_e);Fcr=r(Fgt,"distilbert"),Fgt.forEach(t),Ccr=r(ZLe," \u2014 "),fG=n(ZLe,"A",{href:!0});var Cgt=s(fG);Mcr=r(Cgt,"TFDistilBertForSequenceClassification"),Cgt.forEach(t),Ecr=r(ZLe," (DistilBERT model)"),ZLe.forEach(t),ycr=i(W),uT=n(W,"LI",{});var e8e=s(uT);s_e=n(e8e,"STRONG",{});var Mgt=s(s_e);wcr=r(Mgt,"electra"),Mgt.forEach(t),Acr=r(e8e," \u2014 "),mG=n(e8e,"A",{href:!0});var Egt=s(mG);Lcr=r(Egt,"TFElectraForSequenceClassification"),Egt.forEach(t),Bcr=r(e8e," (ELECTRA model)"),e8e.forEach(t),xcr=i(W),bT=n(W,"LI",{});var o8e=s(bT);l_e=n(o8e,"STRONG",{});var ygt=s(l_e);kcr=r(ygt,"flaubert"),ygt.forEach(t),Rcr=r(o8e," \u2014 "),gG=n(o8e,"A",{href:!0});var wgt=s(gG);Scr=r(wgt,"TFFlaubertForSequenceClassification"),wgt.forEach(t),Pcr=r(o8e," (FlauBERT model)"),o8e.forEach(t),$cr=i(W),vT=n(W,"LI",{});var r8e=s(vT);i_e=n(r8e,"STRONG",{});var Agt=s(i_e);Icr=r(Agt,"funnel"),Agt.forEach(t),jcr=r(r8e," \u2014 "),hG=n(r8e,"A",{href:!0});var Lgt=s(hG);Dcr=r(Lgt,"TFFunnelForSequenceClassification"),Lgt.forEach(t),Ncr=r(r8e," (Funnel Transformer model)"),r8e.forEach(t),qcr=i(W),TT=n(W,"LI",{});var t8e=s(TT);d_e=n(t8e,"STRONG",{});var Bgt=s(d_e);Ocr=r(Bgt,"gpt2"),Bgt.forEach(t),Gcr=r(t8e," \u2014 "),pG=n(t8e,"A",{href:!0});var xgt=s(pG);Xcr=r(xgt,"TFGPT2ForSequenceClassification"),xgt.forEach(t),Vcr=r(t8e," (OpenAI GPT-2 model)"),t8e.forEach(t),zcr=i(W),FT=n(W,"LI",{});var a8e=s(FT);c_e=n(a8e,"STRONG",{});var kgt=s(c_e);Wcr=r(kgt,"layoutlm"),kgt.forEach(t),Qcr=r(a8e," \u2014 "),_G=n(a8e,"A",{href:!0});var Rgt=s(_G);Hcr=r(Rgt,"TFLayoutLMForSequenceClassification"),Rgt.forEach(t),Ucr=r(a8e," (LayoutLM model)"),a8e.forEach(t),Jcr=i(W),CT=n(W,"LI",{});var n8e=s(CT);f_e=n(n8e,"STRONG",{});var Sgt=s(f_e);Ycr=r(Sgt,"longformer"),Sgt.forEach(t),Kcr=r(n8e," \u2014 "),uG=n(n8e,"A",{href:!0});var Pgt=s(uG);Zcr=r(Pgt,"TFLongformerForSequenceClassification"),Pgt.forEach(t),efr=r(n8e," (Longformer model)"),n8e.forEach(t),ofr=i(W),MT=n(W,"LI",{});var s8e=s(MT);m_e=n(s8e,"STRONG",{});var $gt=s(m_e);rfr=r($gt,"mobilebert"),$gt.forEach(t),tfr=r(s8e," \u2014 "),bG=n(s8e,"A",{href:!0});var Igt=s(bG);afr=r(Igt,"TFMobileBertForSequenceClassification"),Igt.forEach(t),nfr=r(s8e," (MobileBERT model)"),s8e.forEach(t),sfr=i(W),ET=n(W,"LI",{});var l8e=s(ET);g_e=n(l8e,"STRONG",{});var jgt=s(g_e);lfr=r(jgt,"mpnet"),jgt.forEach(t),ifr=r(l8e," \u2014 "),vG=n(l8e,"A",{href:!0});var Dgt=s(vG);dfr=r(Dgt,"TFMPNetForSequenceClassification"),Dgt.forEach(t),cfr=r(l8e," (MPNet model)"),l8e.forEach(t),ffr=i(W),yT=n(W,"LI",{});var i8e=s(yT);h_e=n(i8e,"STRONG",{});var Ngt=s(h_e);mfr=r(Ngt,"openai-gpt"),Ngt.forEach(t),gfr=r(i8e," \u2014 "),TG=n(i8e,"A",{href:!0});var qgt=s(TG);hfr=r(qgt,"TFOpenAIGPTForSequenceClassification"),qgt.forEach(t),pfr=r(i8e," (OpenAI GPT model)"),i8e.forEach(t),_fr=i(W),wT=n(W,"LI",{});var d8e=s(wT);p_e=n(d8e,"STRONG",{});var Ogt=s(p_e);ufr=r(Ogt,"rembert"),Ogt.forEach(t),bfr=r(d8e," \u2014 "),FG=n(d8e,"A",{href:!0});var Ggt=s(FG);vfr=r(Ggt,"TFRemBertForSequenceClassification"),Ggt.forEach(t),Tfr=r(d8e," (RemBERT model)"),d8e.forEach(t),Ffr=i(W),AT=n(W,"LI",{});var c8e=s(AT);__e=n(c8e,"STRONG",{});var Xgt=s(__e);Cfr=r(Xgt,"roberta"),Xgt.forEach(t),Mfr=r(c8e," \u2014 "),CG=n(c8e,"A",{href:!0});var Vgt=s(CG);Efr=r(Vgt,"TFRobertaForSequenceClassification"),Vgt.forEach(t),yfr=r(c8e," (RoBERTa model)"),c8e.forEach(t),wfr=i(W),LT=n(W,"LI",{});var f8e=s(LT);u_e=n(f8e,"STRONG",{});var zgt=s(u_e);Afr=r(zgt,"roformer"),zgt.forEach(t),Lfr=r(f8e," \u2014 "),MG=n(f8e,"A",{href:!0});var Wgt=s(MG);Bfr=r(Wgt,"TFRoFormerForSequenceClassification"),Wgt.forEach(t),xfr=r(f8e," (RoFormer model)"),f8e.forEach(t),kfr=i(W),BT=n(W,"LI",{});var m8e=s(BT);b_e=n(m8e,"STRONG",{});var Qgt=s(b_e);Rfr=r(Qgt,"tapas"),Qgt.forEach(t),Sfr=r(m8e," \u2014 "),EG=n(m8e,"A",{href:!0});var Hgt=s(EG);Pfr=r(Hgt,"TFTapasForSequenceClassification"),Hgt.forEach(t),$fr=r(m8e," (TAPAS model)"),m8e.forEach(t),Ifr=i(W),xT=n(W,"LI",{});var g8e=s(xT);v_e=n(g8e,"STRONG",{});var Ugt=s(v_e);jfr=r(Ugt,"transfo-xl"),Ugt.forEach(t),Dfr=r(g8e," \u2014 "),yG=n(g8e,"A",{href:!0});var Jgt=s(yG);Nfr=r(Jgt,"TFTransfoXLForSequenceClassification"),Jgt.forEach(t),qfr=r(g8e," (Transformer-XL model)"),g8e.forEach(t),Ofr=i(W),kT=n(W,"LI",{});var h8e=s(kT);T_e=n(h8e,"STRONG",{});var Ygt=s(T_e);Gfr=r(Ygt,"xlm"),Ygt.forEach(t),Xfr=r(h8e," \u2014 "),wG=n(h8e,"A",{href:!0});var Kgt=s(wG);Vfr=r(Kgt,"TFXLMForSequenceClassification"),Kgt.forEach(t),zfr=r(h8e," (XLM model)"),h8e.forEach(t),Wfr=i(W),RT=n(W,"LI",{});var p8e=s(RT);F_e=n(p8e,"STRONG",{});var Zgt=s(F_e);Qfr=r(Zgt,"xlm-roberta"),Zgt.forEach(t),Hfr=r(p8e," \u2014 "),AG=n(p8e,"A",{href:!0});var eht=s(AG);Ufr=r(eht,"TFXLMRobertaForSequenceClassification"),eht.forEach(t),Jfr=r(p8e," (XLM-RoBERTa model)"),p8e.forEach(t),Yfr=i(W),ST=n(W,"LI",{});var _8e=s(ST);C_e=n(_8e,"STRONG",{});var oht=s(C_e);Kfr=r(oht,"xlnet"),oht.forEach(t),Zfr=r(_8e," \u2014 "),LG=n(_8e,"A",{href:!0});var rht=s(LG);emr=r(rht,"TFXLNetForSequenceClassification"),rht.forEach(t),omr=r(_8e," (XLNet model)"),_8e.forEach(t),W.forEach(t),rmr=i(Ta),M_e=n(Ta,"P",{});var tht=s(M_e);tmr=r(tht,"Examples:"),tht.forEach(t),amr=i(Ta),m(y6.$$.fragment,Ta),Ta.forEach(t),Yl.forEach(t),Ske=i(c),Sc=n(c,"H2",{class:!0});var zSe=s(Sc);PT=n(zSe,"A",{id:!0,class:!0,href:!0});var aht=s(PT);E_e=n(aht,"SPAN",{});var nht=s(E_e);m(w6.$$.fragment,nht),nht.forEach(t),aht.forEach(t),nmr=i(zSe),y_e=n(zSe,"SPAN",{});var sht=s(y_e);smr=r(sht,"TFAutoModelForMultipleChoice"),sht.forEach(t),zSe.forEach(t),Pke=i(c),wr=n(c,"DIV",{class:!0});var Zl=s(wr);m(A6.$$.fragment,Zl),lmr=i(Zl),Pc=n(Zl,"P",{});var IW=s(Pc);imr=r(IW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),w_e=n(IW,"CODE",{});var lht=s(w_e);dmr=r(lht,"from_pretrained()"),lht.forEach(t),cmr=r(IW,"class method or the "),A_e=n(IW,"CODE",{});var iht=s(A_e);fmr=r(iht,"from_config()"),iht.forEach(t),mmr=r(IW,`class
method.`),IW.forEach(t),gmr=i(Zl),L6=n(Zl,"P",{});var WSe=s(L6);hmr=r(WSe,"This class cannot be instantiated directly using "),L_e=n(WSe,"CODE",{});var dht=s(L_e);pmr=r(dht,"__init__()"),dht.forEach(t),_mr=r(WSe," (throws an error)."),WSe.forEach(t),umr=i(Zl),Tt=n(Zl,"DIV",{class:!0});var ei=s(Tt);m(B6.$$.fragment,ei),bmr=i(ei),B_e=n(ei,"P",{});var cht=s(B_e);vmr=r(cht,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),cht.forEach(t),Tmr=i(ei),$c=n(ei,"P",{});var jW=s($c);Fmr=r(jW,`Note:
Loading a model from its configuration file does `),x_e=n(jW,"STRONG",{});var fht=s(x_e);Cmr=r(fht,"not"),fht.forEach(t),Mmr=r(jW,` load the model weights. It only affects the
model\u2019s configuration. Use `),k_e=n(jW,"CODE",{});var mht=s(k_e);Emr=r(mht,"from_pretrained()"),mht.forEach(t),ymr=r(jW,"to load the model weights."),jW.forEach(t),wmr=i(ei),R_e=n(ei,"P",{});var ght=s(R_e);Amr=r(ght,"Examples:"),ght.forEach(t),Lmr=i(ei),m(x6.$$.fragment,ei),ei.forEach(t),Bmr=i(Zl),Fo=n(Zl,"DIV",{class:!0});var Fa=s(Fo);m(k6.$$.fragment,Fa),xmr=i(Fa),S_e=n(Fa,"P",{});var hht=s(S_e);kmr=r(hht,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),hht.forEach(t),Rmr=i(Fa),Cn=n(Fa,"P",{});var x4=s(Cn);Smr=r(x4,"The model class to instantiate is selected based on the "),P_e=n(x4,"CODE",{});var pht=s(P_e);Pmr=r(pht,"model_type"),pht.forEach(t),$mr=r(x4,` property of the config object (either
passed as an argument or loaded from `),$_e=n(x4,"CODE",{});var _ht=s($_e);Imr=r(_ht,"pretrained_model_name_or_path"),_ht.forEach(t),jmr=r(x4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I_e=n(x4,"CODE",{});var uht=s(I_e);Dmr=r(uht,"pretrained_model_name_or_path"),uht.forEach(t),Nmr=r(x4,":"),x4.forEach(t),qmr=i(Fa),ae=n(Fa,"UL",{});var le=s(ae);$T=n(le,"LI",{});var u8e=s($T);j_e=n(u8e,"STRONG",{});var bht=s(j_e);Omr=r(bht,"albert"),bht.forEach(t),Gmr=r(u8e," \u2014 "),BG=n(u8e,"A",{href:!0});var vht=s(BG);Xmr=r(vht,"TFAlbertForMultipleChoice"),vht.forEach(t),Vmr=r(u8e," (ALBERT model)"),u8e.forEach(t),zmr=i(le),IT=n(le,"LI",{});var b8e=s(IT);D_e=n(b8e,"STRONG",{});var Tht=s(D_e);Wmr=r(Tht,"bert"),Tht.forEach(t),Qmr=r(b8e," \u2014 "),xG=n(b8e,"A",{href:!0});var Fht=s(xG);Hmr=r(Fht,"TFBertForMultipleChoice"),Fht.forEach(t),Umr=r(b8e," (BERT model)"),b8e.forEach(t),Jmr=i(le),jT=n(le,"LI",{});var v8e=s(jT);N_e=n(v8e,"STRONG",{});var Cht=s(N_e);Ymr=r(Cht,"camembert"),Cht.forEach(t),Kmr=r(v8e," \u2014 "),kG=n(v8e,"A",{href:!0});var Mht=s(kG);Zmr=r(Mht,"TFCamembertForMultipleChoice"),Mht.forEach(t),egr=r(v8e," (CamemBERT model)"),v8e.forEach(t),ogr=i(le),DT=n(le,"LI",{});var T8e=s(DT);q_e=n(T8e,"STRONG",{});var Eht=s(q_e);rgr=r(Eht,"convbert"),Eht.forEach(t),tgr=r(T8e," \u2014 "),RG=n(T8e,"A",{href:!0});var yht=s(RG);agr=r(yht,"TFConvBertForMultipleChoice"),yht.forEach(t),ngr=r(T8e," (ConvBERT model)"),T8e.forEach(t),sgr=i(le),NT=n(le,"LI",{});var F8e=s(NT);O_e=n(F8e,"STRONG",{});var wht=s(O_e);lgr=r(wht,"distilbert"),wht.forEach(t),igr=r(F8e," \u2014 "),SG=n(F8e,"A",{href:!0});var Aht=s(SG);dgr=r(Aht,"TFDistilBertForMultipleChoice"),Aht.forEach(t),cgr=r(F8e," (DistilBERT model)"),F8e.forEach(t),fgr=i(le),qT=n(le,"LI",{});var C8e=s(qT);G_e=n(C8e,"STRONG",{});var Lht=s(G_e);mgr=r(Lht,"electra"),Lht.forEach(t),ggr=r(C8e," \u2014 "),PG=n(C8e,"A",{href:!0});var Bht=s(PG);hgr=r(Bht,"TFElectraForMultipleChoice"),Bht.forEach(t),pgr=r(C8e," (ELECTRA model)"),C8e.forEach(t),_gr=i(le),OT=n(le,"LI",{});var M8e=s(OT);X_e=n(M8e,"STRONG",{});var xht=s(X_e);ugr=r(xht,"flaubert"),xht.forEach(t),bgr=r(M8e," \u2014 "),$G=n(M8e,"A",{href:!0});var kht=s($G);vgr=r(kht,"TFFlaubertForMultipleChoice"),kht.forEach(t),Tgr=r(M8e," (FlauBERT model)"),M8e.forEach(t),Fgr=i(le),GT=n(le,"LI",{});var E8e=s(GT);V_e=n(E8e,"STRONG",{});var Rht=s(V_e);Cgr=r(Rht,"funnel"),Rht.forEach(t),Mgr=r(E8e," \u2014 "),IG=n(E8e,"A",{href:!0});var Sht=s(IG);Egr=r(Sht,"TFFunnelForMultipleChoice"),Sht.forEach(t),ygr=r(E8e," (Funnel Transformer model)"),E8e.forEach(t),wgr=i(le),XT=n(le,"LI",{});var y8e=s(XT);z_e=n(y8e,"STRONG",{});var Pht=s(z_e);Agr=r(Pht,"longformer"),Pht.forEach(t),Lgr=r(y8e," \u2014 "),jG=n(y8e,"A",{href:!0});var $ht=s(jG);Bgr=r($ht,"TFLongformerForMultipleChoice"),$ht.forEach(t),xgr=r(y8e," (Longformer model)"),y8e.forEach(t),kgr=i(le),VT=n(le,"LI",{});var w8e=s(VT);W_e=n(w8e,"STRONG",{});var Iht=s(W_e);Rgr=r(Iht,"mobilebert"),Iht.forEach(t),Sgr=r(w8e," \u2014 "),DG=n(w8e,"A",{href:!0});var jht=s(DG);Pgr=r(jht,"TFMobileBertForMultipleChoice"),jht.forEach(t),$gr=r(w8e," (MobileBERT model)"),w8e.forEach(t),Igr=i(le),zT=n(le,"LI",{});var A8e=s(zT);Q_e=n(A8e,"STRONG",{});var Dht=s(Q_e);jgr=r(Dht,"mpnet"),Dht.forEach(t),Dgr=r(A8e," \u2014 "),NG=n(A8e,"A",{href:!0});var Nht=s(NG);Ngr=r(Nht,"TFMPNetForMultipleChoice"),Nht.forEach(t),qgr=r(A8e," (MPNet model)"),A8e.forEach(t),Ogr=i(le),WT=n(le,"LI",{});var L8e=s(WT);H_e=n(L8e,"STRONG",{});var qht=s(H_e);Ggr=r(qht,"rembert"),qht.forEach(t),Xgr=r(L8e," \u2014 "),qG=n(L8e,"A",{href:!0});var Oht=s(qG);Vgr=r(Oht,"TFRemBertForMultipleChoice"),Oht.forEach(t),zgr=r(L8e," (RemBERT model)"),L8e.forEach(t),Wgr=i(le),QT=n(le,"LI",{});var B8e=s(QT);U_e=n(B8e,"STRONG",{});var Ght=s(U_e);Qgr=r(Ght,"roberta"),Ght.forEach(t),Hgr=r(B8e," \u2014 "),OG=n(B8e,"A",{href:!0});var Xht=s(OG);Ugr=r(Xht,"TFRobertaForMultipleChoice"),Xht.forEach(t),Jgr=r(B8e," (RoBERTa model)"),B8e.forEach(t),Ygr=i(le),HT=n(le,"LI",{});var x8e=s(HT);J_e=n(x8e,"STRONG",{});var Vht=s(J_e);Kgr=r(Vht,"roformer"),Vht.forEach(t),Zgr=r(x8e," \u2014 "),GG=n(x8e,"A",{href:!0});var zht=s(GG);ehr=r(zht,"TFRoFormerForMultipleChoice"),zht.forEach(t),ohr=r(x8e," (RoFormer model)"),x8e.forEach(t),rhr=i(le),UT=n(le,"LI",{});var k8e=s(UT);Y_e=n(k8e,"STRONG",{});var Wht=s(Y_e);thr=r(Wht,"xlm"),Wht.forEach(t),ahr=r(k8e," \u2014 "),XG=n(k8e,"A",{href:!0});var Qht=s(XG);nhr=r(Qht,"TFXLMForMultipleChoice"),Qht.forEach(t),shr=r(k8e," (XLM model)"),k8e.forEach(t),lhr=i(le),JT=n(le,"LI",{});var R8e=s(JT);K_e=n(R8e,"STRONG",{});var Hht=s(K_e);ihr=r(Hht,"xlm-roberta"),Hht.forEach(t),dhr=r(R8e," \u2014 "),VG=n(R8e,"A",{href:!0});var Uht=s(VG);chr=r(Uht,"TFXLMRobertaForMultipleChoice"),Uht.forEach(t),fhr=r(R8e," (XLM-RoBERTa model)"),R8e.forEach(t),mhr=i(le),YT=n(le,"LI",{});var S8e=s(YT);Z_e=n(S8e,"STRONG",{});var Jht=s(Z_e);ghr=r(Jht,"xlnet"),Jht.forEach(t),hhr=r(S8e," \u2014 "),zG=n(S8e,"A",{href:!0});var Yht=s(zG);phr=r(Yht,"TFXLNetForMultipleChoice"),Yht.forEach(t),_hr=r(S8e," (XLNet model)"),S8e.forEach(t),le.forEach(t),uhr=i(Fa),eue=n(Fa,"P",{});var Kht=s(eue);bhr=r(Kht,"Examples:"),Kht.forEach(t),vhr=i(Fa),m(R6.$$.fragment,Fa),Fa.forEach(t),Zl.forEach(t),$ke=i(c),Ic=n(c,"H2",{class:!0});var QSe=s(Ic);KT=n(QSe,"A",{id:!0,class:!0,href:!0});var Zht=s(KT);oue=n(Zht,"SPAN",{});var ept=s(oue);m(S6.$$.fragment,ept),ept.forEach(t),Zht.forEach(t),Thr=i(QSe),rue=n(QSe,"SPAN",{});var opt=s(rue);Fhr=r(opt,"TFAutoModelForTableQuestionAnswering"),opt.forEach(t),QSe.forEach(t),Ike=i(c),Ar=n(c,"DIV",{class:!0});var oi=s(Ar);m(P6.$$.fragment,oi),Chr=i(oi),jc=n(oi,"P",{});var DW=s(jc);Mhr=r(DW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),tue=n(DW,"CODE",{});var rpt=s(tue);Ehr=r(rpt,"from_pretrained()"),rpt.forEach(t),yhr=r(DW,"class method or the "),aue=n(DW,"CODE",{});var tpt=s(aue);whr=r(tpt,"from_config()"),tpt.forEach(t),Ahr=r(DW,`class
method.`),DW.forEach(t),Lhr=i(oi),$6=n(oi,"P",{});var HSe=s($6);Bhr=r(HSe,"This class cannot be instantiated directly using "),nue=n(HSe,"CODE",{});var apt=s(nue);xhr=r(apt,"__init__()"),apt.forEach(t),khr=r(HSe," (throws an error)."),HSe.forEach(t),Rhr=i(oi),Ft=n(oi,"DIV",{class:!0});var ri=s(Ft);m(I6.$$.fragment,ri),Shr=i(ri),sue=n(ri,"P",{});var npt=s(sue);Phr=r(npt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),npt.forEach(t),$hr=i(ri),Dc=n(ri,"P",{});var NW=s(Dc);Ihr=r(NW,`Note:
Loading a model from its configuration file does `),lue=n(NW,"STRONG",{});var spt=s(lue);jhr=r(spt,"not"),spt.forEach(t),Dhr=r(NW,` load the model weights. It only affects the
model\u2019s configuration. Use `),iue=n(NW,"CODE",{});var lpt=s(iue);Nhr=r(lpt,"from_pretrained()"),lpt.forEach(t),qhr=r(NW,"to load the model weights."),NW.forEach(t),Ohr=i(ri),due=n(ri,"P",{});var ipt=s(due);Ghr=r(ipt,"Examples:"),ipt.forEach(t),Xhr=i(ri),m(j6.$$.fragment,ri),ri.forEach(t),Vhr=i(oi),Co=n(oi,"DIV",{class:!0});var Ca=s(Co);m(D6.$$.fragment,Ca),zhr=i(Ca),cue=n(Ca,"P",{});var dpt=s(cue);Whr=r(dpt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),dpt.forEach(t),Qhr=i(Ca),Mn=n(Ca,"P",{});var k4=s(Mn);Hhr=r(k4,"The model class to instantiate is selected based on the "),fue=n(k4,"CODE",{});var cpt=s(fue);Uhr=r(cpt,"model_type"),cpt.forEach(t),Jhr=r(k4,` property of the config object (either
passed as an argument or loaded from `),mue=n(k4,"CODE",{});var fpt=s(mue);Yhr=r(fpt,"pretrained_model_name_or_path"),fpt.forEach(t),Khr=r(k4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gue=n(k4,"CODE",{});var mpt=s(gue);Zhr=r(mpt,"pretrained_model_name_or_path"),mpt.forEach(t),epr=r(k4,":"),k4.forEach(t),opr=i(Ca),hue=n(Ca,"UL",{});var gpt=s(hue);ZT=n(gpt,"LI",{});var P8e=s(ZT);pue=n(P8e,"STRONG",{});var hpt=s(pue);rpr=r(hpt,"tapas"),hpt.forEach(t),tpr=r(P8e," \u2014 "),WG=n(P8e,"A",{href:!0});var ppt=s(WG);apr=r(ppt,"TFTapasForQuestionAnswering"),ppt.forEach(t),npr=r(P8e," (TAPAS model)"),P8e.forEach(t),gpt.forEach(t),spr=i(Ca),_ue=n(Ca,"P",{});var _pt=s(_ue);lpr=r(_pt,"Examples:"),_pt.forEach(t),ipr=i(Ca),m(N6.$$.fragment,Ca),Ca.forEach(t),oi.forEach(t),jke=i(c),Nc=n(c,"H2",{class:!0});var USe=s(Nc);eF=n(USe,"A",{id:!0,class:!0,href:!0});var upt=s(eF);uue=n(upt,"SPAN",{});var bpt=s(uue);m(q6.$$.fragment,bpt),bpt.forEach(t),upt.forEach(t),dpr=i(USe),bue=n(USe,"SPAN",{});var vpt=s(bue);cpr=r(vpt,"TFAutoModelForTokenClassification"),vpt.forEach(t),USe.forEach(t),Dke=i(c),Lr=n(c,"DIV",{class:!0});var ti=s(Lr);m(O6.$$.fragment,ti),fpr=i(ti),qc=n(ti,"P",{});var qW=s(qc);mpr=r(qW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),vue=n(qW,"CODE",{});var Tpt=s(vue);gpr=r(Tpt,"from_pretrained()"),Tpt.forEach(t),hpr=r(qW,"class method or the "),Tue=n(qW,"CODE",{});var Fpt=s(Tue);ppr=r(Fpt,"from_config()"),Fpt.forEach(t),_pr=r(qW,`class
method.`),qW.forEach(t),upr=i(ti),G6=n(ti,"P",{});var JSe=s(G6);bpr=r(JSe,"This class cannot be instantiated directly using "),Fue=n(JSe,"CODE",{});var Cpt=s(Fue);vpr=r(Cpt,"__init__()"),Cpt.forEach(t),Tpr=r(JSe," (throws an error)."),JSe.forEach(t),Fpr=i(ti),Ct=n(ti,"DIV",{class:!0});var ai=s(Ct);m(X6.$$.fragment,ai),Cpr=i(ai),Cue=n(ai,"P",{});var Mpt=s(Cue);Mpr=r(Mpt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Mpt.forEach(t),Epr=i(ai),Oc=n(ai,"P",{});var OW=s(Oc);ypr=r(OW,`Note:
Loading a model from its configuration file does `),Mue=n(OW,"STRONG",{});var Ept=s(Mue);wpr=r(Ept,"not"),Ept.forEach(t),Apr=r(OW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eue=n(OW,"CODE",{});var ypt=s(Eue);Lpr=r(ypt,"from_pretrained()"),ypt.forEach(t),Bpr=r(OW,"to load the model weights."),OW.forEach(t),xpr=i(ai),yue=n(ai,"P",{});var wpt=s(yue);kpr=r(wpt,"Examples:"),wpt.forEach(t),Rpr=i(ai),m(V6.$$.fragment,ai),ai.forEach(t),Spr=i(ti),Mo=n(ti,"DIV",{class:!0});var Ma=s(Mo);m(z6.$$.fragment,Ma),Ppr=i(Ma),wue=n(Ma,"P",{});var Apt=s(wue);$pr=r(Apt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Apt.forEach(t),Ipr=i(Ma),En=n(Ma,"P",{});var R4=s(En);jpr=r(R4,"The model class to instantiate is selected based on the "),Aue=n(R4,"CODE",{});var Lpt=s(Aue);Dpr=r(Lpt,"model_type"),Lpt.forEach(t),Npr=r(R4,` property of the config object (either
passed as an argument or loaded from `),Lue=n(R4,"CODE",{});var Bpt=s(Lue);qpr=r(Bpt,"pretrained_model_name_or_path"),Bpt.forEach(t),Opr=r(R4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bue=n(R4,"CODE",{});var xpt=s(Bue);Gpr=r(xpt,"pretrained_model_name_or_path"),xpt.forEach(t),Xpr=r(R4,":"),R4.forEach(t),Vpr=i(Ma),K=n(Ma,"UL",{});var oe=s(K);oF=n(oe,"LI",{});var $8e=s(oF);xue=n($8e,"STRONG",{});var kpt=s(xue);zpr=r(kpt,"albert"),kpt.forEach(t),Wpr=r($8e," \u2014 "),QG=n($8e,"A",{href:!0});var Rpt=s(QG);Qpr=r(Rpt,"TFAlbertForTokenClassification"),Rpt.forEach(t),Hpr=r($8e," (ALBERT model)"),$8e.forEach(t),Upr=i(oe),rF=n(oe,"LI",{});var I8e=s(rF);kue=n(I8e,"STRONG",{});var Spt=s(kue);Jpr=r(Spt,"bert"),Spt.forEach(t),Ypr=r(I8e," \u2014 "),HG=n(I8e,"A",{href:!0});var Ppt=s(HG);Kpr=r(Ppt,"TFBertForTokenClassification"),Ppt.forEach(t),Zpr=r(I8e," (BERT model)"),I8e.forEach(t),e_r=i(oe),tF=n(oe,"LI",{});var j8e=s(tF);Rue=n(j8e,"STRONG",{});var $pt=s(Rue);o_r=r($pt,"camembert"),$pt.forEach(t),r_r=r(j8e," \u2014 "),UG=n(j8e,"A",{href:!0});var Ipt=s(UG);t_r=r(Ipt,"TFCamembertForTokenClassification"),Ipt.forEach(t),a_r=r(j8e," (CamemBERT model)"),j8e.forEach(t),n_r=i(oe),aF=n(oe,"LI",{});var D8e=s(aF);Sue=n(D8e,"STRONG",{});var jpt=s(Sue);s_r=r(jpt,"convbert"),jpt.forEach(t),l_r=r(D8e," \u2014 "),JG=n(D8e,"A",{href:!0});var Dpt=s(JG);i_r=r(Dpt,"TFConvBertForTokenClassification"),Dpt.forEach(t),d_r=r(D8e," (ConvBERT model)"),D8e.forEach(t),c_r=i(oe),nF=n(oe,"LI",{});var N8e=s(nF);Pue=n(N8e,"STRONG",{});var Npt=s(Pue);f_r=r(Npt,"deberta"),Npt.forEach(t),m_r=r(N8e," \u2014 "),YG=n(N8e,"A",{href:!0});var qpt=s(YG);g_r=r(qpt,"TFDebertaForTokenClassification"),qpt.forEach(t),h_r=r(N8e," (DeBERTa model)"),N8e.forEach(t),p_r=i(oe),sF=n(oe,"LI",{});var q8e=s(sF);$ue=n(q8e,"STRONG",{});var Opt=s($ue);__r=r(Opt,"deberta-v2"),Opt.forEach(t),u_r=r(q8e," \u2014 "),KG=n(q8e,"A",{href:!0});var Gpt=s(KG);b_r=r(Gpt,"TFDebertaV2ForTokenClassification"),Gpt.forEach(t),v_r=r(q8e," (DeBERTa-v2 model)"),q8e.forEach(t),T_r=i(oe),lF=n(oe,"LI",{});var O8e=s(lF);Iue=n(O8e,"STRONG",{});var Xpt=s(Iue);F_r=r(Xpt,"distilbert"),Xpt.forEach(t),C_r=r(O8e," \u2014 "),ZG=n(O8e,"A",{href:!0});var Vpt=s(ZG);M_r=r(Vpt,"TFDistilBertForTokenClassification"),Vpt.forEach(t),E_r=r(O8e," (DistilBERT model)"),O8e.forEach(t),y_r=i(oe),iF=n(oe,"LI",{});var G8e=s(iF);jue=n(G8e,"STRONG",{});var zpt=s(jue);w_r=r(zpt,"electra"),zpt.forEach(t),A_r=r(G8e," \u2014 "),eX=n(G8e,"A",{href:!0});var Wpt=s(eX);L_r=r(Wpt,"TFElectraForTokenClassification"),Wpt.forEach(t),B_r=r(G8e," (ELECTRA model)"),G8e.forEach(t),x_r=i(oe),dF=n(oe,"LI",{});var X8e=s(dF);Due=n(X8e,"STRONG",{});var Qpt=s(Due);k_r=r(Qpt,"flaubert"),Qpt.forEach(t),R_r=r(X8e," \u2014 "),oX=n(X8e,"A",{href:!0});var Hpt=s(oX);S_r=r(Hpt,"TFFlaubertForTokenClassification"),Hpt.forEach(t),P_r=r(X8e," (FlauBERT model)"),X8e.forEach(t),$_r=i(oe),cF=n(oe,"LI",{});var V8e=s(cF);Nue=n(V8e,"STRONG",{});var Upt=s(Nue);I_r=r(Upt,"funnel"),Upt.forEach(t),j_r=r(V8e," \u2014 "),rX=n(V8e,"A",{href:!0});var Jpt=s(rX);D_r=r(Jpt,"TFFunnelForTokenClassification"),Jpt.forEach(t),N_r=r(V8e," (Funnel Transformer model)"),V8e.forEach(t),q_r=i(oe),fF=n(oe,"LI",{});var z8e=s(fF);que=n(z8e,"STRONG",{});var Ypt=s(que);O_r=r(Ypt,"layoutlm"),Ypt.forEach(t),G_r=r(z8e," \u2014 "),tX=n(z8e,"A",{href:!0});var Kpt=s(tX);X_r=r(Kpt,"TFLayoutLMForTokenClassification"),Kpt.forEach(t),V_r=r(z8e," (LayoutLM model)"),z8e.forEach(t),z_r=i(oe),mF=n(oe,"LI",{});var W8e=s(mF);Oue=n(W8e,"STRONG",{});var Zpt=s(Oue);W_r=r(Zpt,"longformer"),Zpt.forEach(t),Q_r=r(W8e," \u2014 "),aX=n(W8e,"A",{href:!0});var e_t=s(aX);H_r=r(e_t,"TFLongformerForTokenClassification"),e_t.forEach(t),U_r=r(W8e," (Longformer model)"),W8e.forEach(t),J_r=i(oe),gF=n(oe,"LI",{});var Q8e=s(gF);Gue=n(Q8e,"STRONG",{});var o_t=s(Gue);Y_r=r(o_t,"mobilebert"),o_t.forEach(t),K_r=r(Q8e," \u2014 "),nX=n(Q8e,"A",{href:!0});var r_t=s(nX);Z_r=r(r_t,"TFMobileBertForTokenClassification"),r_t.forEach(t),eur=r(Q8e," (MobileBERT model)"),Q8e.forEach(t),our=i(oe),hF=n(oe,"LI",{});var H8e=s(hF);Xue=n(H8e,"STRONG",{});var t_t=s(Xue);rur=r(t_t,"mpnet"),t_t.forEach(t),tur=r(H8e," \u2014 "),sX=n(H8e,"A",{href:!0});var a_t=s(sX);aur=r(a_t,"TFMPNetForTokenClassification"),a_t.forEach(t),nur=r(H8e," (MPNet model)"),H8e.forEach(t),sur=i(oe),pF=n(oe,"LI",{});var U8e=s(pF);Vue=n(U8e,"STRONG",{});var n_t=s(Vue);lur=r(n_t,"rembert"),n_t.forEach(t),iur=r(U8e," \u2014 "),lX=n(U8e,"A",{href:!0});var s_t=s(lX);dur=r(s_t,"TFRemBertForTokenClassification"),s_t.forEach(t),cur=r(U8e," (RemBERT model)"),U8e.forEach(t),fur=i(oe),_F=n(oe,"LI",{});var J8e=s(_F);zue=n(J8e,"STRONG",{});var l_t=s(zue);mur=r(l_t,"roberta"),l_t.forEach(t),gur=r(J8e," \u2014 "),iX=n(J8e,"A",{href:!0});var i_t=s(iX);hur=r(i_t,"TFRobertaForTokenClassification"),i_t.forEach(t),pur=r(J8e," (RoBERTa model)"),J8e.forEach(t),_ur=i(oe),uF=n(oe,"LI",{});var Y8e=s(uF);Wue=n(Y8e,"STRONG",{});var d_t=s(Wue);uur=r(d_t,"roformer"),d_t.forEach(t),bur=r(Y8e," \u2014 "),dX=n(Y8e,"A",{href:!0});var c_t=s(dX);vur=r(c_t,"TFRoFormerForTokenClassification"),c_t.forEach(t),Tur=r(Y8e," (RoFormer model)"),Y8e.forEach(t),Fur=i(oe),bF=n(oe,"LI",{});var K8e=s(bF);Que=n(K8e,"STRONG",{});var f_t=s(Que);Cur=r(f_t,"xlm"),f_t.forEach(t),Mur=r(K8e," \u2014 "),cX=n(K8e,"A",{href:!0});var m_t=s(cX);Eur=r(m_t,"TFXLMForTokenClassification"),m_t.forEach(t),yur=r(K8e," (XLM model)"),K8e.forEach(t),wur=i(oe),vF=n(oe,"LI",{});var Z8e=s(vF);Hue=n(Z8e,"STRONG",{});var g_t=s(Hue);Aur=r(g_t,"xlm-roberta"),g_t.forEach(t),Lur=r(Z8e," \u2014 "),fX=n(Z8e,"A",{href:!0});var h_t=s(fX);Bur=r(h_t,"TFXLMRobertaForTokenClassification"),h_t.forEach(t),xur=r(Z8e," (XLM-RoBERTa model)"),Z8e.forEach(t),kur=i(oe),TF=n(oe,"LI",{});var e9e=s(TF);Uue=n(e9e,"STRONG",{});var p_t=s(Uue);Rur=r(p_t,"xlnet"),p_t.forEach(t),Sur=r(e9e," \u2014 "),mX=n(e9e,"A",{href:!0});var __t=s(mX);Pur=r(__t,"TFXLNetForTokenClassification"),__t.forEach(t),$ur=r(e9e," (XLNet model)"),e9e.forEach(t),oe.forEach(t),Iur=i(Ma),Jue=n(Ma,"P",{});var u_t=s(Jue);jur=r(u_t,"Examples:"),u_t.forEach(t),Dur=i(Ma),m(W6.$$.fragment,Ma),Ma.forEach(t),ti.forEach(t),Nke=i(c),Gc=n(c,"H2",{class:!0});var YSe=s(Gc);FF=n(YSe,"A",{id:!0,class:!0,href:!0});var b_t=s(FF);Yue=n(b_t,"SPAN",{});var v_t=s(Yue);m(Q6.$$.fragment,v_t),v_t.forEach(t),b_t.forEach(t),Nur=i(YSe),Kue=n(YSe,"SPAN",{});var T_t=s(Kue);qur=r(T_t,"TFAutoModelForQuestionAnswering"),T_t.forEach(t),YSe.forEach(t),qke=i(c),Br=n(c,"DIV",{class:!0});var ni=s(Br);m(H6.$$.fragment,ni),Our=i(ni),Xc=n(ni,"P",{});var GW=s(Xc);Gur=r(GW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Zue=n(GW,"CODE",{});var F_t=s(Zue);Xur=r(F_t,"from_pretrained()"),F_t.forEach(t),Vur=r(GW,"class method or the "),e1e=n(GW,"CODE",{});var C_t=s(e1e);zur=r(C_t,"from_config()"),C_t.forEach(t),Wur=r(GW,`class
method.`),GW.forEach(t),Qur=i(ni),U6=n(ni,"P",{});var KSe=s(U6);Hur=r(KSe,"This class cannot be instantiated directly using "),o1e=n(KSe,"CODE",{});var M_t=s(o1e);Uur=r(M_t,"__init__()"),M_t.forEach(t),Jur=r(KSe," (throws an error)."),KSe.forEach(t),Yur=i(ni),Mt=n(ni,"DIV",{class:!0});var si=s(Mt);m(J6.$$.fragment,si),Kur=i(si),r1e=n(si,"P",{});var E_t=s(r1e);Zur=r(E_t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),E_t.forEach(t),e1r=i(si),Vc=n(si,"P",{});var XW=s(Vc);o1r=r(XW,`Note:
Loading a model from its configuration file does `),t1e=n(XW,"STRONG",{});var y_t=s(t1e);r1r=r(y_t,"not"),y_t.forEach(t),t1r=r(XW,` load the model weights. It only affects the
model\u2019s configuration. Use `),a1e=n(XW,"CODE",{});var w_t=s(a1e);a1r=r(w_t,"from_pretrained()"),w_t.forEach(t),n1r=r(XW,"to load the model weights."),XW.forEach(t),s1r=i(si),n1e=n(si,"P",{});var A_t=s(n1e);l1r=r(A_t,"Examples:"),A_t.forEach(t),i1r=i(si),m(Y6.$$.fragment,si),si.forEach(t),d1r=i(ni),Eo=n(ni,"DIV",{class:!0});var Ea=s(Eo);m(K6.$$.fragment,Ea),c1r=i(Ea),s1e=n(Ea,"P",{});var L_t=s(s1e);f1r=r(L_t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),L_t.forEach(t),m1r=i(Ea),yn=n(Ea,"P",{});var S4=s(yn);g1r=r(S4,"The model class to instantiate is selected based on the "),l1e=n(S4,"CODE",{});var B_t=s(l1e);h1r=r(B_t,"model_type"),B_t.forEach(t),p1r=r(S4,` property of the config object (either
passed as an argument or loaded from `),i1e=n(S4,"CODE",{});var x_t=s(i1e);_1r=r(x_t,"pretrained_model_name_or_path"),x_t.forEach(t),u1r=r(S4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d1e=n(S4,"CODE",{});var k_t=s(d1e);b1r=r(k_t,"pretrained_model_name_or_path"),k_t.forEach(t),v1r=r(S4,":"),S4.forEach(t),T1r=i(Ea),Z=n(Ea,"UL",{});var re=s(Z);CF=n(re,"LI",{});var o9e=s(CF);c1e=n(o9e,"STRONG",{});var R_t=s(c1e);F1r=r(R_t,"albert"),R_t.forEach(t),C1r=r(o9e," \u2014 "),gX=n(o9e,"A",{href:!0});var S_t=s(gX);M1r=r(S_t,"TFAlbertForQuestionAnswering"),S_t.forEach(t),E1r=r(o9e," (ALBERT model)"),o9e.forEach(t),y1r=i(re),MF=n(re,"LI",{});var r9e=s(MF);f1e=n(r9e,"STRONG",{});var P_t=s(f1e);w1r=r(P_t,"bert"),P_t.forEach(t),A1r=r(r9e," \u2014 "),hX=n(r9e,"A",{href:!0});var $_t=s(hX);L1r=r($_t,"TFBertForQuestionAnswering"),$_t.forEach(t),B1r=r(r9e," (BERT model)"),r9e.forEach(t),x1r=i(re),EF=n(re,"LI",{});var t9e=s(EF);m1e=n(t9e,"STRONG",{});var I_t=s(m1e);k1r=r(I_t,"camembert"),I_t.forEach(t),R1r=r(t9e," \u2014 "),pX=n(t9e,"A",{href:!0});var j_t=s(pX);S1r=r(j_t,"TFCamembertForQuestionAnswering"),j_t.forEach(t),P1r=r(t9e," (CamemBERT model)"),t9e.forEach(t),$1r=i(re),yF=n(re,"LI",{});var a9e=s(yF);g1e=n(a9e,"STRONG",{});var D_t=s(g1e);I1r=r(D_t,"convbert"),D_t.forEach(t),j1r=r(a9e," \u2014 "),_X=n(a9e,"A",{href:!0});var N_t=s(_X);D1r=r(N_t,"TFConvBertForQuestionAnswering"),N_t.forEach(t),N1r=r(a9e," (ConvBERT model)"),a9e.forEach(t),q1r=i(re),wF=n(re,"LI",{});var n9e=s(wF);h1e=n(n9e,"STRONG",{});var q_t=s(h1e);O1r=r(q_t,"deberta"),q_t.forEach(t),G1r=r(n9e," \u2014 "),uX=n(n9e,"A",{href:!0});var O_t=s(uX);X1r=r(O_t,"TFDebertaForQuestionAnswering"),O_t.forEach(t),V1r=r(n9e," (DeBERTa model)"),n9e.forEach(t),z1r=i(re),AF=n(re,"LI",{});var s9e=s(AF);p1e=n(s9e,"STRONG",{});var G_t=s(p1e);W1r=r(G_t,"deberta-v2"),G_t.forEach(t),Q1r=r(s9e," \u2014 "),bX=n(s9e,"A",{href:!0});var X_t=s(bX);H1r=r(X_t,"TFDebertaV2ForQuestionAnswering"),X_t.forEach(t),U1r=r(s9e," (DeBERTa-v2 model)"),s9e.forEach(t),J1r=i(re),LF=n(re,"LI",{});var l9e=s(LF);_1e=n(l9e,"STRONG",{});var V_t=s(_1e);Y1r=r(V_t,"distilbert"),V_t.forEach(t),K1r=r(l9e," \u2014 "),vX=n(l9e,"A",{href:!0});var z_t=s(vX);Z1r=r(z_t,"TFDistilBertForQuestionAnswering"),z_t.forEach(t),e7r=r(l9e," (DistilBERT model)"),l9e.forEach(t),o7r=i(re),BF=n(re,"LI",{});var i9e=s(BF);u1e=n(i9e,"STRONG",{});var W_t=s(u1e);r7r=r(W_t,"electra"),W_t.forEach(t),t7r=r(i9e," \u2014 "),TX=n(i9e,"A",{href:!0});var Q_t=s(TX);a7r=r(Q_t,"TFElectraForQuestionAnswering"),Q_t.forEach(t),n7r=r(i9e," (ELECTRA model)"),i9e.forEach(t),s7r=i(re),xF=n(re,"LI",{});var d9e=s(xF);b1e=n(d9e,"STRONG",{});var H_t=s(b1e);l7r=r(H_t,"flaubert"),H_t.forEach(t),i7r=r(d9e," \u2014 "),FX=n(d9e,"A",{href:!0});var U_t=s(FX);d7r=r(U_t,"TFFlaubertForQuestionAnsweringSimple"),U_t.forEach(t),c7r=r(d9e," (FlauBERT model)"),d9e.forEach(t),f7r=i(re),kF=n(re,"LI",{});var c9e=s(kF);v1e=n(c9e,"STRONG",{});var J_t=s(v1e);m7r=r(J_t,"funnel"),J_t.forEach(t),g7r=r(c9e," \u2014 "),CX=n(c9e,"A",{href:!0});var Y_t=s(CX);h7r=r(Y_t,"TFFunnelForQuestionAnswering"),Y_t.forEach(t),p7r=r(c9e," (Funnel Transformer model)"),c9e.forEach(t),_7r=i(re),RF=n(re,"LI",{});var f9e=s(RF);T1e=n(f9e,"STRONG",{});var K_t=s(T1e);u7r=r(K_t,"longformer"),K_t.forEach(t),b7r=r(f9e," \u2014 "),MX=n(f9e,"A",{href:!0});var Z_t=s(MX);v7r=r(Z_t,"TFLongformerForQuestionAnswering"),Z_t.forEach(t),T7r=r(f9e," (Longformer model)"),f9e.forEach(t),F7r=i(re),SF=n(re,"LI",{});var m9e=s(SF);F1e=n(m9e,"STRONG",{});var eut=s(F1e);C7r=r(eut,"mobilebert"),eut.forEach(t),M7r=r(m9e," \u2014 "),EX=n(m9e,"A",{href:!0});var out=s(EX);E7r=r(out,"TFMobileBertForQuestionAnswering"),out.forEach(t),y7r=r(m9e," (MobileBERT model)"),m9e.forEach(t),w7r=i(re),PF=n(re,"LI",{});var g9e=s(PF);C1e=n(g9e,"STRONG",{});var rut=s(C1e);A7r=r(rut,"mpnet"),rut.forEach(t),L7r=r(g9e," \u2014 "),yX=n(g9e,"A",{href:!0});var tut=s(yX);B7r=r(tut,"TFMPNetForQuestionAnswering"),tut.forEach(t),x7r=r(g9e," (MPNet model)"),g9e.forEach(t),k7r=i(re),$F=n(re,"LI",{});var h9e=s($F);M1e=n(h9e,"STRONG",{});var aut=s(M1e);R7r=r(aut,"rembert"),aut.forEach(t),S7r=r(h9e," \u2014 "),wX=n(h9e,"A",{href:!0});var nut=s(wX);P7r=r(nut,"TFRemBertForQuestionAnswering"),nut.forEach(t),$7r=r(h9e," (RemBERT model)"),h9e.forEach(t),I7r=i(re),IF=n(re,"LI",{});var p9e=s(IF);E1e=n(p9e,"STRONG",{});var sut=s(E1e);j7r=r(sut,"roberta"),sut.forEach(t),D7r=r(p9e," \u2014 "),AX=n(p9e,"A",{href:!0});var lut=s(AX);N7r=r(lut,"TFRobertaForQuestionAnswering"),lut.forEach(t),q7r=r(p9e," (RoBERTa model)"),p9e.forEach(t),O7r=i(re),jF=n(re,"LI",{});var _9e=s(jF);y1e=n(_9e,"STRONG",{});var iut=s(y1e);G7r=r(iut,"roformer"),iut.forEach(t),X7r=r(_9e," \u2014 "),LX=n(_9e,"A",{href:!0});var dut=s(LX);V7r=r(dut,"TFRoFormerForQuestionAnswering"),dut.forEach(t),z7r=r(_9e," (RoFormer model)"),_9e.forEach(t),W7r=i(re),DF=n(re,"LI",{});var u9e=s(DF);w1e=n(u9e,"STRONG",{});var cut=s(w1e);Q7r=r(cut,"xlm"),cut.forEach(t),H7r=r(u9e," \u2014 "),BX=n(u9e,"A",{href:!0});var fut=s(BX);U7r=r(fut,"TFXLMForQuestionAnsweringSimple"),fut.forEach(t),J7r=r(u9e," (XLM model)"),u9e.forEach(t),Y7r=i(re),NF=n(re,"LI",{});var b9e=s(NF);A1e=n(b9e,"STRONG",{});var mut=s(A1e);K7r=r(mut,"xlm-roberta"),mut.forEach(t),Z7r=r(b9e," \u2014 "),xX=n(b9e,"A",{href:!0});var gut=s(xX);ebr=r(gut,"TFXLMRobertaForQuestionAnswering"),gut.forEach(t),obr=r(b9e," (XLM-RoBERTa model)"),b9e.forEach(t),rbr=i(re),qF=n(re,"LI",{});var v9e=s(qF);L1e=n(v9e,"STRONG",{});var hut=s(L1e);tbr=r(hut,"xlnet"),hut.forEach(t),abr=r(v9e," \u2014 "),kX=n(v9e,"A",{href:!0});var put=s(kX);nbr=r(put,"TFXLNetForQuestionAnsweringSimple"),put.forEach(t),sbr=r(v9e," (XLNet model)"),v9e.forEach(t),re.forEach(t),lbr=i(Ea),B1e=n(Ea,"P",{});var _ut=s(B1e);ibr=r(_ut,"Examples:"),_ut.forEach(t),dbr=i(Ea),m(Z6.$$.fragment,Ea),Ea.forEach(t),ni.forEach(t),Oke=i(c),zc=n(c,"H2",{class:!0});var ZSe=s(zc);OF=n(ZSe,"A",{id:!0,class:!0,href:!0});var uut=s(OF);x1e=n(uut,"SPAN",{});var but=s(x1e);m(eA.$$.fragment,but),but.forEach(t),uut.forEach(t),cbr=i(ZSe),k1e=n(ZSe,"SPAN",{});var vut=s(k1e);fbr=r(vut,"TFAutoModelForVision2Seq"),vut.forEach(t),ZSe.forEach(t),Gke=i(c),xr=n(c,"DIV",{class:!0});var li=s(xr);m(oA.$$.fragment,li),mbr=i(li),Wc=n(li,"P",{});var VW=s(Wc);gbr=r(VW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),R1e=n(VW,"CODE",{});var Tut=s(R1e);hbr=r(Tut,"from_pretrained()"),Tut.forEach(t),pbr=r(VW,"class method or the "),S1e=n(VW,"CODE",{});var Fut=s(S1e);_br=r(Fut,"from_config()"),Fut.forEach(t),ubr=r(VW,`class
method.`),VW.forEach(t),bbr=i(li),rA=n(li,"P",{});var ePe=s(rA);vbr=r(ePe,"This class cannot be instantiated directly using "),P1e=n(ePe,"CODE",{});var Cut=s(P1e);Tbr=r(Cut,"__init__()"),Cut.forEach(t),Fbr=r(ePe," (throws an error)."),ePe.forEach(t),Cbr=i(li),Et=n(li,"DIV",{class:!0});var ii=s(Et);m(tA.$$.fragment,ii),Mbr=i(ii),$1e=n(ii,"P",{});var Mut=s($1e);Ebr=r(Mut,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Mut.forEach(t),ybr=i(ii),Qc=n(ii,"P",{});var zW=s(Qc);wbr=r(zW,`Note:
Loading a model from its configuration file does `),I1e=n(zW,"STRONG",{});var Eut=s(I1e);Abr=r(Eut,"not"),Eut.forEach(t),Lbr=r(zW,` load the model weights. It only affects the
model\u2019s configuration. Use `),j1e=n(zW,"CODE",{});var yut=s(j1e);Bbr=r(yut,"from_pretrained()"),yut.forEach(t),xbr=r(zW,"to load the model weights."),zW.forEach(t),kbr=i(ii),D1e=n(ii,"P",{});var wut=s(D1e);Rbr=r(wut,"Examples:"),wut.forEach(t),Sbr=i(ii),m(aA.$$.fragment,ii),ii.forEach(t),Pbr=i(li),yo=n(li,"DIV",{class:!0});var ya=s(yo);m(nA.$$.fragment,ya),$br=i(ya),N1e=n(ya,"P",{});var Aut=s(N1e);Ibr=r(Aut,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Aut.forEach(t),jbr=i(ya),wn=n(ya,"P",{});var P4=s(wn);Dbr=r(P4,"The model class to instantiate is selected based on the "),q1e=n(P4,"CODE",{});var Lut=s(q1e);Nbr=r(Lut,"model_type"),Lut.forEach(t),qbr=r(P4,` property of the config object (either
passed as an argument or loaded from `),O1e=n(P4,"CODE",{});var But=s(O1e);Obr=r(But,"pretrained_model_name_or_path"),But.forEach(t),Gbr=r(P4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G1e=n(P4,"CODE",{});var xut=s(G1e);Xbr=r(xut,"pretrained_model_name_or_path"),xut.forEach(t),Vbr=r(P4,":"),P4.forEach(t),zbr=i(ya),X1e=n(ya,"UL",{});var kut=s(X1e);GF=n(kut,"LI",{});var T9e=s(GF);V1e=n(T9e,"STRONG",{});var Rut=s(V1e);Wbr=r(Rut,"vision-encoder-decoder"),Rut.forEach(t),Qbr=r(T9e," \u2014 "),RX=n(T9e,"A",{href:!0});var Sut=s(RX);Hbr=r(Sut,"TFVisionEncoderDecoderModel"),Sut.forEach(t),Ubr=r(T9e," (Vision Encoder decoder model)"),T9e.forEach(t),kut.forEach(t),Jbr=i(ya),z1e=n(ya,"P",{});var Put=s(z1e);Ybr=r(Put,"Examples:"),Put.forEach(t),Kbr=i(ya),m(sA.$$.fragment,ya),ya.forEach(t),li.forEach(t),Xke=i(c),Hc=n(c,"H2",{class:!0});var oPe=s(Hc);XF=n(oPe,"A",{id:!0,class:!0,href:!0});var $ut=s(XF);W1e=n($ut,"SPAN",{});var Iut=s(W1e);m(lA.$$.fragment,Iut),Iut.forEach(t),$ut.forEach(t),Zbr=i(oPe),Q1e=n(oPe,"SPAN",{});var jut=s(Q1e);e5r=r(jut,"TFAutoModelForSpeechSeq2Seq"),jut.forEach(t),oPe.forEach(t),Vke=i(c),kr=n(c,"DIV",{class:!0});var di=s(kr);m(iA.$$.fragment,di),o5r=i(di),Uc=n(di,"P",{});var WW=s(Uc);r5r=r(WW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),H1e=n(WW,"CODE",{});var Dut=s(H1e);t5r=r(Dut,"from_pretrained()"),Dut.forEach(t),a5r=r(WW,"class method or the "),U1e=n(WW,"CODE",{});var Nut=s(U1e);n5r=r(Nut,"from_config()"),Nut.forEach(t),s5r=r(WW,`class
method.`),WW.forEach(t),l5r=i(di),dA=n(di,"P",{});var rPe=s(dA);i5r=r(rPe,"This class cannot be instantiated directly using "),J1e=n(rPe,"CODE",{});var qut=s(J1e);d5r=r(qut,"__init__()"),qut.forEach(t),c5r=r(rPe," (throws an error)."),rPe.forEach(t),f5r=i(di),yt=n(di,"DIV",{class:!0});var ci=s(yt);m(cA.$$.fragment,ci),m5r=i(ci),Y1e=n(ci,"P",{});var Out=s(Y1e);g5r=r(Out,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Out.forEach(t),h5r=i(ci),Jc=n(ci,"P",{});var QW=s(Jc);p5r=r(QW,`Note:
Loading a model from its configuration file does `),K1e=n(QW,"STRONG",{});var Gut=s(K1e);_5r=r(Gut,"not"),Gut.forEach(t),u5r=r(QW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Z1e=n(QW,"CODE",{});var Xut=s(Z1e);b5r=r(Xut,"from_pretrained()"),Xut.forEach(t),v5r=r(QW,"to load the model weights."),QW.forEach(t),T5r=i(ci),e7e=n(ci,"P",{});var Vut=s(e7e);F5r=r(Vut,"Examples:"),Vut.forEach(t),C5r=i(ci),m(fA.$$.fragment,ci),ci.forEach(t),M5r=i(di),wo=n(di,"DIV",{class:!0});var wa=s(wo);m(mA.$$.fragment,wa),E5r=i(wa),o7e=n(wa,"P",{});var zut=s(o7e);y5r=r(zut,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),zut.forEach(t),w5r=i(wa),An=n(wa,"P",{});var $4=s(An);A5r=r($4,"The model class to instantiate is selected based on the "),r7e=n($4,"CODE",{});var Wut=s(r7e);L5r=r(Wut,"model_type"),Wut.forEach(t),B5r=r($4,` property of the config object (either
passed as an argument or loaded from `),t7e=n($4,"CODE",{});var Qut=s(t7e);x5r=r(Qut,"pretrained_model_name_or_path"),Qut.forEach(t),k5r=r($4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a7e=n($4,"CODE",{});var Hut=s(a7e);R5r=r(Hut,"pretrained_model_name_or_path"),Hut.forEach(t),S5r=r($4,":"),$4.forEach(t),P5r=i(wa),n7e=n(wa,"UL",{});var Uut=s(n7e);VF=n(Uut,"LI",{});var F9e=s(VF);s7e=n(F9e,"STRONG",{});var Jut=s(s7e);$5r=r(Jut,"speech_to_text"),Jut.forEach(t),I5r=r(F9e," \u2014 "),SX=n(F9e,"A",{href:!0});var Yut=s(SX);j5r=r(Yut,"TFSpeech2TextForConditionalGeneration"),Yut.forEach(t),D5r=r(F9e," (Speech2Text model)"),F9e.forEach(t),Uut.forEach(t),N5r=i(wa),l7e=n(wa,"P",{});var Kut=s(l7e);q5r=r(Kut,"Examples:"),Kut.forEach(t),O5r=i(wa),m(gA.$$.fragment,wa),wa.forEach(t),di.forEach(t),zke=i(c),Yc=n(c,"H2",{class:!0});var tPe=s(Yc);zF=n(tPe,"A",{id:!0,class:!0,href:!0});var Zut=s(zF);i7e=n(Zut,"SPAN",{});var e1t=s(i7e);m(hA.$$.fragment,e1t),e1t.forEach(t),Zut.forEach(t),G5r=i(tPe),d7e=n(tPe,"SPAN",{});var o1t=s(d7e);X5r=r(o1t,"FlaxAutoModel"),o1t.forEach(t),tPe.forEach(t),Wke=i(c),Rr=n(c,"DIV",{class:!0});var fi=s(Rr);m(pA.$$.fragment,fi),V5r=i(fi),Kc=n(fi,"P",{});var HW=s(Kc);z5r=r(HW,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),c7e=n(HW,"CODE",{});var r1t=s(c7e);W5r=r(r1t,"from_pretrained()"),r1t.forEach(t),Q5r=r(HW,"class method or the "),f7e=n(HW,"CODE",{});var t1t=s(f7e);H5r=r(t1t,"from_config()"),t1t.forEach(t),U5r=r(HW,`class
method.`),HW.forEach(t),J5r=i(fi),_A=n(fi,"P",{});var aPe=s(_A);Y5r=r(aPe,"This class cannot be instantiated directly using "),m7e=n(aPe,"CODE",{});var a1t=s(m7e);K5r=r(a1t,"__init__()"),a1t.forEach(t),Z5r=r(aPe," (throws an error)."),aPe.forEach(t),e2r=i(fi),wt=n(fi,"DIV",{class:!0});var mi=s(wt);m(uA.$$.fragment,mi),o2r=i(mi),g7e=n(mi,"P",{});var n1t=s(g7e);r2r=r(n1t,"Instantiates one of the base model classes of the library from a configuration."),n1t.forEach(t),t2r=i(mi),Zc=n(mi,"P",{});var UW=s(Zc);a2r=r(UW,`Note:
Loading a model from its configuration file does `),h7e=n(UW,"STRONG",{});var s1t=s(h7e);n2r=r(s1t,"not"),s1t.forEach(t),s2r=r(UW,` load the model weights. It only affects the
model\u2019s configuration. Use `),p7e=n(UW,"CODE",{});var l1t=s(p7e);l2r=r(l1t,"from_pretrained()"),l1t.forEach(t),i2r=r(UW,"to load the model weights."),UW.forEach(t),d2r=i(mi),_7e=n(mi,"P",{});var i1t=s(_7e);c2r=r(i1t,"Examples:"),i1t.forEach(t),f2r=i(mi),m(bA.$$.fragment,mi),mi.forEach(t),m2r=i(fi),Ao=n(fi,"DIV",{class:!0});var Aa=s(Ao);m(vA.$$.fragment,Aa),g2r=i(Aa),u7e=n(Aa,"P",{});var d1t=s(u7e);h2r=r(d1t,"Instantiate one of the base model classes of the library from a pretrained model."),d1t.forEach(t),p2r=i(Aa),Ln=n(Aa,"P",{});var I4=s(Ln);_2r=r(I4,"The model class to instantiate is selected based on the "),b7e=n(I4,"CODE",{});var c1t=s(b7e);u2r=r(c1t,"model_type"),c1t.forEach(t),b2r=r(I4,` property of the config object (either
passed as an argument or loaded from `),v7e=n(I4,"CODE",{});var f1t=s(v7e);v2r=r(f1t,"pretrained_model_name_or_path"),f1t.forEach(t),T2r=r(I4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T7e=n(I4,"CODE",{});var m1t=s(T7e);F2r=r(m1t,"pretrained_model_name_or_path"),m1t.forEach(t),C2r=r(I4,":"),I4.forEach(t),M2r=i(Aa),z=n(Aa,"UL",{});var Q=s(z);WF=n(Q,"LI",{});var C9e=s(WF);F7e=n(C9e,"STRONG",{});var g1t=s(F7e);E2r=r(g1t,"albert"),g1t.forEach(t),y2r=r(C9e," \u2014 "),PX=n(C9e,"A",{href:!0});var h1t=s(PX);w2r=r(h1t,"FlaxAlbertModel"),h1t.forEach(t),A2r=r(C9e," (ALBERT model)"),C9e.forEach(t),L2r=i(Q),QF=n(Q,"LI",{});var M9e=s(QF);C7e=n(M9e,"STRONG",{});var p1t=s(C7e);B2r=r(p1t,"bart"),p1t.forEach(t),x2r=r(M9e," \u2014 "),$X=n(M9e,"A",{href:!0});var _1t=s($X);k2r=r(_1t,"FlaxBartModel"),_1t.forEach(t),R2r=r(M9e," (BART model)"),M9e.forEach(t),S2r=i(Q),HF=n(Q,"LI",{});var E9e=s(HF);M7e=n(E9e,"STRONG",{});var u1t=s(M7e);P2r=r(u1t,"beit"),u1t.forEach(t),$2r=r(E9e," \u2014 "),IX=n(E9e,"A",{href:!0});var b1t=s(IX);I2r=r(b1t,"FlaxBeitModel"),b1t.forEach(t),j2r=r(E9e," (BEiT model)"),E9e.forEach(t),D2r=i(Q),UF=n(Q,"LI",{});var y9e=s(UF);E7e=n(y9e,"STRONG",{});var v1t=s(E7e);N2r=r(v1t,"bert"),v1t.forEach(t),q2r=r(y9e," \u2014 "),jX=n(y9e,"A",{href:!0});var T1t=s(jX);O2r=r(T1t,"FlaxBertModel"),T1t.forEach(t),G2r=r(y9e," (BERT model)"),y9e.forEach(t),X2r=i(Q),JF=n(Q,"LI",{});var w9e=s(JF);y7e=n(w9e,"STRONG",{});var F1t=s(y7e);V2r=r(F1t,"big_bird"),F1t.forEach(t),z2r=r(w9e," \u2014 "),DX=n(w9e,"A",{href:!0});var C1t=s(DX);W2r=r(C1t,"FlaxBigBirdModel"),C1t.forEach(t),Q2r=r(w9e," (BigBird model)"),w9e.forEach(t),H2r=i(Q),YF=n(Q,"LI",{});var A9e=s(YF);w7e=n(A9e,"STRONG",{});var M1t=s(w7e);U2r=r(M1t,"blenderbot"),M1t.forEach(t),J2r=r(A9e," \u2014 "),NX=n(A9e,"A",{href:!0});var E1t=s(NX);Y2r=r(E1t,"FlaxBlenderbotModel"),E1t.forEach(t),K2r=r(A9e," (Blenderbot model)"),A9e.forEach(t),Z2r=i(Q),KF=n(Q,"LI",{});var L9e=s(KF);A7e=n(L9e,"STRONG",{});var y1t=s(A7e);evr=r(y1t,"blenderbot-small"),y1t.forEach(t),ovr=r(L9e," \u2014 "),qX=n(L9e,"A",{href:!0});var w1t=s(qX);rvr=r(w1t,"FlaxBlenderbotSmallModel"),w1t.forEach(t),tvr=r(L9e," (BlenderbotSmall model)"),L9e.forEach(t),avr=i(Q),ZF=n(Q,"LI",{});var B9e=s(ZF);L7e=n(B9e,"STRONG",{});var A1t=s(L7e);nvr=r(A1t,"clip"),A1t.forEach(t),svr=r(B9e," \u2014 "),OX=n(B9e,"A",{href:!0});var L1t=s(OX);lvr=r(L1t,"FlaxCLIPModel"),L1t.forEach(t),ivr=r(B9e," (CLIP model)"),B9e.forEach(t),dvr=i(Q),eC=n(Q,"LI",{});var x9e=s(eC);B7e=n(x9e,"STRONG",{});var B1t=s(B7e);cvr=r(B1t,"distilbert"),B1t.forEach(t),fvr=r(x9e," \u2014 "),GX=n(x9e,"A",{href:!0});var x1t=s(GX);mvr=r(x1t,"FlaxDistilBertModel"),x1t.forEach(t),gvr=r(x9e," (DistilBERT model)"),x9e.forEach(t),hvr=i(Q),oC=n(Q,"LI",{});var k9e=s(oC);x7e=n(k9e,"STRONG",{});var k1t=s(x7e);pvr=r(k1t,"electra"),k1t.forEach(t),_vr=r(k9e," \u2014 "),XX=n(k9e,"A",{href:!0});var R1t=s(XX);uvr=r(R1t,"FlaxElectraModel"),R1t.forEach(t),bvr=r(k9e," (ELECTRA model)"),k9e.forEach(t),vvr=i(Q),rC=n(Q,"LI",{});var R9e=s(rC);k7e=n(R9e,"STRONG",{});var S1t=s(k7e);Tvr=r(S1t,"gpt2"),S1t.forEach(t),Fvr=r(R9e," \u2014 "),VX=n(R9e,"A",{href:!0});var P1t=s(VX);Cvr=r(P1t,"FlaxGPT2Model"),P1t.forEach(t),Mvr=r(R9e," (OpenAI GPT-2 model)"),R9e.forEach(t),Evr=i(Q),tC=n(Q,"LI",{});var S9e=s(tC);R7e=n(S9e,"STRONG",{});var $1t=s(R7e);yvr=r($1t,"gpt_neo"),$1t.forEach(t),wvr=r(S9e," \u2014 "),zX=n(S9e,"A",{href:!0});var I1t=s(zX);Avr=r(I1t,"FlaxGPTNeoModel"),I1t.forEach(t),Lvr=r(S9e," (GPT Neo model)"),S9e.forEach(t),Bvr=i(Q),aC=n(Q,"LI",{});var P9e=s(aC);S7e=n(P9e,"STRONG",{});var j1t=s(S7e);xvr=r(j1t,"gptj"),j1t.forEach(t),kvr=r(P9e," \u2014 "),WX=n(P9e,"A",{href:!0});var D1t=s(WX);Rvr=r(D1t,"FlaxGPTJModel"),D1t.forEach(t),Svr=r(P9e," (GPT-J model)"),P9e.forEach(t),Pvr=i(Q),nC=n(Q,"LI",{});var $9e=s(nC);P7e=n($9e,"STRONG",{});var N1t=s(P7e);$vr=r(N1t,"marian"),N1t.forEach(t),Ivr=r($9e," \u2014 "),QX=n($9e,"A",{href:!0});var q1t=s(QX);jvr=r(q1t,"FlaxMarianModel"),q1t.forEach(t),Dvr=r($9e," (Marian model)"),$9e.forEach(t),Nvr=i(Q),sC=n(Q,"LI",{});var I9e=s(sC);$7e=n(I9e,"STRONG",{});var O1t=s($7e);qvr=r(O1t,"mbart"),O1t.forEach(t),Ovr=r(I9e," \u2014 "),HX=n(I9e,"A",{href:!0});var G1t=s(HX);Gvr=r(G1t,"FlaxMBartModel"),G1t.forEach(t),Xvr=r(I9e," (mBART model)"),I9e.forEach(t),Vvr=i(Q),lC=n(Q,"LI",{});var j9e=s(lC);I7e=n(j9e,"STRONG",{});var X1t=s(I7e);zvr=r(X1t,"mt5"),X1t.forEach(t),Wvr=r(j9e," \u2014 "),UX=n(j9e,"A",{href:!0});var V1t=s(UX);Qvr=r(V1t,"FlaxMT5Model"),V1t.forEach(t),Hvr=r(j9e," (mT5 model)"),j9e.forEach(t),Uvr=i(Q),iC=n(Q,"LI",{});var D9e=s(iC);j7e=n(D9e,"STRONG",{});var z1t=s(j7e);Jvr=r(z1t,"pegasus"),z1t.forEach(t),Yvr=r(D9e," \u2014 "),JX=n(D9e,"A",{href:!0});var W1t=s(JX);Kvr=r(W1t,"FlaxPegasusModel"),W1t.forEach(t),Zvr=r(D9e," (Pegasus model)"),D9e.forEach(t),e0r=i(Q),dC=n(Q,"LI",{});var N9e=s(dC);D7e=n(N9e,"STRONG",{});var Q1t=s(D7e);o0r=r(Q1t,"roberta"),Q1t.forEach(t),r0r=r(N9e," \u2014 "),YX=n(N9e,"A",{href:!0});var H1t=s(YX);t0r=r(H1t,"FlaxRobertaModel"),H1t.forEach(t),a0r=r(N9e," (RoBERTa model)"),N9e.forEach(t),n0r=i(Q),cC=n(Q,"LI",{});var q9e=s(cC);N7e=n(q9e,"STRONG",{});var U1t=s(N7e);s0r=r(U1t,"roformer"),U1t.forEach(t),l0r=r(q9e," \u2014 "),KX=n(q9e,"A",{href:!0});var J1t=s(KX);i0r=r(J1t,"FlaxRoFormerModel"),J1t.forEach(t),d0r=r(q9e," (RoFormer model)"),q9e.forEach(t),c0r=i(Q),fC=n(Q,"LI",{});var O9e=s(fC);q7e=n(O9e,"STRONG",{});var Y1t=s(q7e);f0r=r(Y1t,"t5"),Y1t.forEach(t),m0r=r(O9e," \u2014 "),ZX=n(O9e,"A",{href:!0});var K1t=s(ZX);g0r=r(K1t,"FlaxT5Model"),K1t.forEach(t),h0r=r(O9e," (T5 model)"),O9e.forEach(t),p0r=i(Q),mC=n(Q,"LI",{});var G9e=s(mC);O7e=n(G9e,"STRONG",{});var Z1t=s(O7e);_0r=r(Z1t,"vision-text-dual-encoder"),Z1t.forEach(t),u0r=r(G9e," \u2014 "),eV=n(G9e,"A",{href:!0});var e7t=s(eV);b0r=r(e7t,"FlaxVisionTextDualEncoderModel"),e7t.forEach(t),v0r=r(G9e," (VisionTextDualEncoder model)"),G9e.forEach(t),T0r=i(Q),gC=n(Q,"LI",{});var X9e=s(gC);G7e=n(X9e,"STRONG",{});var o7t=s(G7e);F0r=r(o7t,"vit"),o7t.forEach(t),C0r=r(X9e," \u2014 "),oV=n(X9e,"A",{href:!0});var r7t=s(oV);M0r=r(r7t,"FlaxViTModel"),r7t.forEach(t),E0r=r(X9e," (ViT model)"),X9e.forEach(t),y0r=i(Q),hC=n(Q,"LI",{});var V9e=s(hC);X7e=n(V9e,"STRONG",{});var t7t=s(X7e);w0r=r(t7t,"wav2vec2"),t7t.forEach(t),A0r=r(V9e," \u2014 "),rV=n(V9e,"A",{href:!0});var a7t=s(rV);L0r=r(a7t,"FlaxWav2Vec2Model"),a7t.forEach(t),B0r=r(V9e," (Wav2Vec2 model)"),V9e.forEach(t),x0r=i(Q),pC=n(Q,"LI",{});var z9e=s(pC);V7e=n(z9e,"STRONG",{});var n7t=s(V7e);k0r=r(n7t,"xglm"),n7t.forEach(t),R0r=r(z9e," \u2014 "),tV=n(z9e,"A",{href:!0});var s7t=s(tV);S0r=r(s7t,"FlaxXGLMModel"),s7t.forEach(t),P0r=r(z9e," (XGLM model)"),z9e.forEach(t),$0r=i(Q),_C=n(Q,"LI",{});var W9e=s(_C);z7e=n(W9e,"STRONG",{});var l7t=s(z7e);I0r=r(l7t,"xlm-roberta"),l7t.forEach(t),j0r=r(W9e," \u2014 "),aV=n(W9e,"A",{href:!0});var i7t=s(aV);D0r=r(i7t,"FlaxXLMRobertaModel"),i7t.forEach(t),N0r=r(W9e," (XLM-RoBERTa model)"),W9e.forEach(t),Q.forEach(t),q0r=i(Aa),W7e=n(Aa,"P",{});var d7t=s(W7e);O0r=r(d7t,"Examples:"),d7t.forEach(t),G0r=i(Aa),m(TA.$$.fragment,Aa),Aa.forEach(t),fi.forEach(t),Qke=i(c),ef=n(c,"H2",{class:!0});var nPe=s(ef);uC=n(nPe,"A",{id:!0,class:!0,href:!0});var c7t=s(uC);Q7e=n(c7t,"SPAN",{});var f7t=s(Q7e);m(FA.$$.fragment,f7t),f7t.forEach(t),c7t.forEach(t),X0r=i(nPe),H7e=n(nPe,"SPAN",{});var m7t=s(H7e);V0r=r(m7t,"FlaxAutoModelForCausalLM"),m7t.forEach(t),nPe.forEach(t),Hke=i(c),Sr=n(c,"DIV",{class:!0});var gi=s(Sr);m(CA.$$.fragment,gi),z0r=i(gi),of=n(gi,"P",{});var JW=s(of);W0r=r(JW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),U7e=n(JW,"CODE",{});var g7t=s(U7e);Q0r=r(g7t,"from_pretrained()"),g7t.forEach(t),H0r=r(JW,"class method or the "),J7e=n(JW,"CODE",{});var h7t=s(J7e);U0r=r(h7t,"from_config()"),h7t.forEach(t),J0r=r(JW,`class
method.`),JW.forEach(t),Y0r=i(gi),MA=n(gi,"P",{});var sPe=s(MA);K0r=r(sPe,"This class cannot be instantiated directly using "),Y7e=n(sPe,"CODE",{});var p7t=s(Y7e);Z0r=r(p7t,"__init__()"),p7t.forEach(t),eTr=r(sPe," (throws an error)."),sPe.forEach(t),oTr=i(gi),At=n(gi,"DIV",{class:!0});var hi=s(At);m(EA.$$.fragment,hi),rTr=i(hi),K7e=n(hi,"P",{});var _7t=s(K7e);tTr=r(_7t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),_7t.forEach(t),aTr=i(hi),rf=n(hi,"P",{});var YW=s(rf);nTr=r(YW,`Note:
Loading a model from its configuration file does `),Z7e=n(YW,"STRONG",{});var u7t=s(Z7e);sTr=r(u7t,"not"),u7t.forEach(t),lTr=r(YW,` load the model weights. It only affects the
model\u2019s configuration. Use `),ebe=n(YW,"CODE",{});var b7t=s(ebe);iTr=r(b7t,"from_pretrained()"),b7t.forEach(t),dTr=r(YW,"to load the model weights."),YW.forEach(t),cTr=i(hi),obe=n(hi,"P",{});var v7t=s(obe);fTr=r(v7t,"Examples:"),v7t.forEach(t),mTr=i(hi),m(yA.$$.fragment,hi),hi.forEach(t),gTr=i(gi),Lo=n(gi,"DIV",{class:!0});var La=s(Lo);m(wA.$$.fragment,La),hTr=i(La),rbe=n(La,"P",{});var T7t=s(rbe);pTr=r(T7t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),T7t.forEach(t),_Tr=i(La),Bn=n(La,"P",{});var j4=s(Bn);uTr=r(j4,"The model class to instantiate is selected based on the "),tbe=n(j4,"CODE",{});var F7t=s(tbe);bTr=r(F7t,"model_type"),F7t.forEach(t),vTr=r(j4,` property of the config object (either
passed as an argument or loaded from `),abe=n(j4,"CODE",{});var C7t=s(abe);TTr=r(C7t,"pretrained_model_name_or_path"),C7t.forEach(t),FTr=r(j4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=n(j4,"CODE",{});var M7t=s(nbe);CTr=r(M7t,"pretrained_model_name_or_path"),M7t.forEach(t),MTr=r(j4,":"),j4.forEach(t),ETr=i(La),xn=n(La,"UL",{});var D4=s(xn);bC=n(D4,"LI",{});var Q9e=s(bC);sbe=n(Q9e,"STRONG",{});var E7t=s(sbe);yTr=r(E7t,"gpt2"),E7t.forEach(t),wTr=r(Q9e," \u2014 "),nV=n(Q9e,"A",{href:!0});var y7t=s(nV);ATr=r(y7t,"FlaxGPT2LMHeadModel"),y7t.forEach(t),LTr=r(Q9e," (OpenAI GPT-2 model)"),Q9e.forEach(t),BTr=i(D4),vC=n(D4,"LI",{});var H9e=s(vC);lbe=n(H9e,"STRONG",{});var w7t=s(lbe);xTr=r(w7t,"gpt_neo"),w7t.forEach(t),kTr=r(H9e," \u2014 "),sV=n(H9e,"A",{href:!0});var A7t=s(sV);RTr=r(A7t,"FlaxGPTNeoForCausalLM"),A7t.forEach(t),STr=r(H9e," (GPT Neo model)"),H9e.forEach(t),PTr=i(D4),TC=n(D4,"LI",{});var U9e=s(TC);ibe=n(U9e,"STRONG",{});var L7t=s(ibe);$Tr=r(L7t,"gptj"),L7t.forEach(t),ITr=r(U9e," \u2014 "),lV=n(U9e,"A",{href:!0});var B7t=s(lV);jTr=r(B7t,"FlaxGPTJForCausalLM"),B7t.forEach(t),DTr=r(U9e," (GPT-J model)"),U9e.forEach(t),NTr=i(D4),FC=n(D4,"LI",{});var J9e=s(FC);dbe=n(J9e,"STRONG",{});var x7t=s(dbe);qTr=r(x7t,"xglm"),x7t.forEach(t),OTr=r(J9e," \u2014 "),iV=n(J9e,"A",{href:!0});var k7t=s(iV);GTr=r(k7t,"FlaxXGLMForCausalLM"),k7t.forEach(t),XTr=r(J9e," (XGLM model)"),J9e.forEach(t),D4.forEach(t),VTr=i(La),cbe=n(La,"P",{});var R7t=s(cbe);zTr=r(R7t,"Examples:"),R7t.forEach(t),WTr=i(La),m(AA.$$.fragment,La),La.forEach(t),gi.forEach(t),Uke=i(c),tf=n(c,"H2",{class:!0});var lPe=s(tf);CC=n(lPe,"A",{id:!0,class:!0,href:!0});var S7t=s(CC);fbe=n(S7t,"SPAN",{});var P7t=s(fbe);m(LA.$$.fragment,P7t),P7t.forEach(t),S7t.forEach(t),QTr=i(lPe),mbe=n(lPe,"SPAN",{});var $7t=s(mbe);HTr=r($7t,"FlaxAutoModelForPreTraining"),$7t.forEach(t),lPe.forEach(t),Jke=i(c),Pr=n(c,"DIV",{class:!0});var pi=s(Pr);m(BA.$$.fragment,pi),UTr=i(pi),af=n(pi,"P",{});var KW=s(af);JTr=r(KW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gbe=n(KW,"CODE",{});var I7t=s(gbe);YTr=r(I7t,"from_pretrained()"),I7t.forEach(t),KTr=r(KW,"class method or the "),hbe=n(KW,"CODE",{});var j7t=s(hbe);ZTr=r(j7t,"from_config()"),j7t.forEach(t),eFr=r(KW,`class
method.`),KW.forEach(t),oFr=i(pi),xA=n(pi,"P",{});var iPe=s(xA);rFr=r(iPe,"This class cannot be instantiated directly using "),pbe=n(iPe,"CODE",{});var D7t=s(pbe);tFr=r(D7t,"__init__()"),D7t.forEach(t),aFr=r(iPe," (throws an error)."),iPe.forEach(t),nFr=i(pi),Lt=n(pi,"DIV",{class:!0});var _i=s(Lt);m(kA.$$.fragment,_i),sFr=i(_i),_be=n(_i,"P",{});var N7t=s(_be);lFr=r(N7t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),N7t.forEach(t),iFr=i(_i),nf=n(_i,"P",{});var ZW=s(nf);dFr=r(ZW,`Note:
Loading a model from its configuration file does `),ube=n(ZW,"STRONG",{});var q7t=s(ube);cFr=r(q7t,"not"),q7t.forEach(t),fFr=r(ZW,` load the model weights. It only affects the
model\u2019s configuration. Use `),bbe=n(ZW,"CODE",{});var O7t=s(bbe);mFr=r(O7t,"from_pretrained()"),O7t.forEach(t),gFr=r(ZW,"to load the model weights."),ZW.forEach(t),hFr=i(_i),vbe=n(_i,"P",{});var G7t=s(vbe);pFr=r(G7t,"Examples:"),G7t.forEach(t),_Fr=i(_i),m(RA.$$.fragment,_i),_i.forEach(t),uFr=i(pi),Bo=n(pi,"DIV",{class:!0});var Ba=s(Bo);m(SA.$$.fragment,Ba),bFr=i(Ba),Tbe=n(Ba,"P",{});var X7t=s(Tbe);vFr=r(X7t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),X7t.forEach(t),TFr=i(Ba),kn=n(Ba,"P",{});var N4=s(kn);FFr=r(N4,"The model class to instantiate is selected based on the "),Fbe=n(N4,"CODE",{});var V7t=s(Fbe);CFr=r(V7t,"model_type"),V7t.forEach(t),MFr=r(N4,` property of the config object (either
passed as an argument or loaded from `),Cbe=n(N4,"CODE",{});var z7t=s(Cbe);EFr=r(z7t,"pretrained_model_name_or_path"),z7t.forEach(t),yFr=r(N4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mbe=n(N4,"CODE",{});var W7t=s(Mbe);wFr=r(W7t,"pretrained_model_name_or_path"),W7t.forEach(t),AFr=r(N4,":"),N4.forEach(t),LFr=i(Ba),ce=n(Ba,"UL",{});var me=s(ce);MC=n(me,"LI",{});var Y9e=s(MC);Ebe=n(Y9e,"STRONG",{});var Q7t=s(Ebe);BFr=r(Q7t,"albert"),Q7t.forEach(t),xFr=r(Y9e," \u2014 "),dV=n(Y9e,"A",{href:!0});var H7t=s(dV);kFr=r(H7t,"FlaxAlbertForPreTraining"),H7t.forEach(t),RFr=r(Y9e," (ALBERT model)"),Y9e.forEach(t),SFr=i(me),EC=n(me,"LI",{});var K9e=s(EC);ybe=n(K9e,"STRONG",{});var U7t=s(ybe);PFr=r(U7t,"bart"),U7t.forEach(t),$Fr=r(K9e," \u2014 "),cV=n(K9e,"A",{href:!0});var J7t=s(cV);IFr=r(J7t,"FlaxBartForConditionalGeneration"),J7t.forEach(t),jFr=r(K9e," (BART model)"),K9e.forEach(t),DFr=i(me),yC=n(me,"LI",{});var Z9e=s(yC);wbe=n(Z9e,"STRONG",{});var Y7t=s(wbe);NFr=r(Y7t,"bert"),Y7t.forEach(t),qFr=r(Z9e," \u2014 "),fV=n(Z9e,"A",{href:!0});var K7t=s(fV);OFr=r(K7t,"FlaxBertForPreTraining"),K7t.forEach(t),GFr=r(Z9e," (BERT model)"),Z9e.forEach(t),XFr=i(me),wC=n(me,"LI",{});var eBe=s(wC);Abe=n(eBe,"STRONG",{});var Z7t=s(Abe);VFr=r(Z7t,"big_bird"),Z7t.forEach(t),zFr=r(eBe," \u2014 "),mV=n(eBe,"A",{href:!0});var ebt=s(mV);WFr=r(ebt,"FlaxBigBirdForPreTraining"),ebt.forEach(t),QFr=r(eBe," (BigBird model)"),eBe.forEach(t),HFr=i(me),AC=n(me,"LI",{});var oBe=s(AC);Lbe=n(oBe,"STRONG",{});var obt=s(Lbe);UFr=r(obt,"electra"),obt.forEach(t),JFr=r(oBe," \u2014 "),gV=n(oBe,"A",{href:!0});var rbt=s(gV);YFr=r(rbt,"FlaxElectraForPreTraining"),rbt.forEach(t),KFr=r(oBe," (ELECTRA model)"),oBe.forEach(t),ZFr=i(me),LC=n(me,"LI",{});var rBe=s(LC);Bbe=n(rBe,"STRONG",{});var tbt=s(Bbe);eCr=r(tbt,"mbart"),tbt.forEach(t),oCr=r(rBe," \u2014 "),hV=n(rBe,"A",{href:!0});var abt=s(hV);rCr=r(abt,"FlaxMBartForConditionalGeneration"),abt.forEach(t),tCr=r(rBe," (mBART model)"),rBe.forEach(t),aCr=i(me),BC=n(me,"LI",{});var tBe=s(BC);xbe=n(tBe,"STRONG",{});var nbt=s(xbe);nCr=r(nbt,"mt5"),nbt.forEach(t),sCr=r(tBe," \u2014 "),pV=n(tBe,"A",{href:!0});var sbt=s(pV);lCr=r(sbt,"FlaxMT5ForConditionalGeneration"),sbt.forEach(t),iCr=r(tBe," (mT5 model)"),tBe.forEach(t),dCr=i(me),xC=n(me,"LI",{});var aBe=s(xC);kbe=n(aBe,"STRONG",{});var lbt=s(kbe);cCr=r(lbt,"roberta"),lbt.forEach(t),fCr=r(aBe," \u2014 "),_V=n(aBe,"A",{href:!0});var ibt=s(_V);mCr=r(ibt,"FlaxRobertaForMaskedLM"),ibt.forEach(t),gCr=r(aBe," (RoBERTa model)"),aBe.forEach(t),hCr=i(me),kC=n(me,"LI",{});var nBe=s(kC);Rbe=n(nBe,"STRONG",{});var dbt=s(Rbe);pCr=r(dbt,"roformer"),dbt.forEach(t),_Cr=r(nBe," \u2014 "),uV=n(nBe,"A",{href:!0});var cbt=s(uV);uCr=r(cbt,"FlaxRoFormerForMaskedLM"),cbt.forEach(t),bCr=r(nBe," (RoFormer model)"),nBe.forEach(t),vCr=i(me),RC=n(me,"LI",{});var sBe=s(RC);Sbe=n(sBe,"STRONG",{});var fbt=s(Sbe);TCr=r(fbt,"t5"),fbt.forEach(t),FCr=r(sBe," \u2014 "),bV=n(sBe,"A",{href:!0});var mbt=s(bV);CCr=r(mbt,"FlaxT5ForConditionalGeneration"),mbt.forEach(t),MCr=r(sBe," (T5 model)"),sBe.forEach(t),ECr=i(me),SC=n(me,"LI",{});var lBe=s(SC);Pbe=n(lBe,"STRONG",{});var gbt=s(Pbe);yCr=r(gbt,"wav2vec2"),gbt.forEach(t),wCr=r(lBe," \u2014 "),vV=n(lBe,"A",{href:!0});var hbt=s(vV);ACr=r(hbt,"FlaxWav2Vec2ForPreTraining"),hbt.forEach(t),LCr=r(lBe," (Wav2Vec2 model)"),lBe.forEach(t),BCr=i(me),PC=n(me,"LI",{});var iBe=s(PC);$be=n(iBe,"STRONG",{});var pbt=s($be);xCr=r(pbt,"xlm-roberta"),pbt.forEach(t),kCr=r(iBe," \u2014 "),TV=n(iBe,"A",{href:!0});var _bt=s(TV);RCr=r(_bt,"FlaxXLMRobertaForMaskedLM"),_bt.forEach(t),SCr=r(iBe," (XLM-RoBERTa model)"),iBe.forEach(t),me.forEach(t),PCr=i(Ba),Ibe=n(Ba,"P",{});var ubt=s(Ibe);$Cr=r(ubt,"Examples:"),ubt.forEach(t),ICr=i(Ba),m(PA.$$.fragment,Ba),Ba.forEach(t),pi.forEach(t),Yke=i(c),sf=n(c,"H2",{class:!0});var dPe=s(sf);$C=n(dPe,"A",{id:!0,class:!0,href:!0});var bbt=s($C);jbe=n(bbt,"SPAN",{});var vbt=s(jbe);m($A.$$.fragment,vbt),vbt.forEach(t),bbt.forEach(t),jCr=i(dPe),Dbe=n(dPe,"SPAN",{});var Tbt=s(Dbe);DCr=r(Tbt,"FlaxAutoModelForMaskedLM"),Tbt.forEach(t),dPe.forEach(t),Kke=i(c),$r=n(c,"DIV",{class:!0});var ui=s($r);m(IA.$$.fragment,ui),NCr=i(ui),lf=n(ui,"P",{});var eQ=s(lf);qCr=r(eQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Nbe=n(eQ,"CODE",{});var Fbt=s(Nbe);OCr=r(Fbt,"from_pretrained()"),Fbt.forEach(t),GCr=r(eQ,"class method or the "),qbe=n(eQ,"CODE",{});var Cbt=s(qbe);XCr=r(Cbt,"from_config()"),Cbt.forEach(t),VCr=r(eQ,`class
method.`),eQ.forEach(t),zCr=i(ui),jA=n(ui,"P",{});var cPe=s(jA);WCr=r(cPe,"This class cannot be instantiated directly using "),Obe=n(cPe,"CODE",{});var Mbt=s(Obe);QCr=r(Mbt,"__init__()"),Mbt.forEach(t),HCr=r(cPe," (throws an error)."),cPe.forEach(t),UCr=i(ui),Bt=n(ui,"DIV",{class:!0});var bi=s(Bt);m(DA.$$.fragment,bi),JCr=i(bi),Gbe=n(bi,"P",{});var Ebt=s(Gbe);YCr=r(Ebt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ebt.forEach(t),KCr=i(bi),df=n(bi,"P",{});var oQ=s(df);ZCr=r(oQ,`Note:
Loading a model from its configuration file does `),Xbe=n(oQ,"STRONG",{});var ybt=s(Xbe);eMr=r(ybt,"not"),ybt.forEach(t),oMr=r(oQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vbe=n(oQ,"CODE",{});var wbt=s(Vbe);rMr=r(wbt,"from_pretrained()"),wbt.forEach(t),tMr=r(oQ,"to load the model weights."),oQ.forEach(t),aMr=i(bi),zbe=n(bi,"P",{});var Abt=s(zbe);nMr=r(Abt,"Examples:"),Abt.forEach(t),sMr=i(bi),m(NA.$$.fragment,bi),bi.forEach(t),lMr=i(ui),xo=n(ui,"DIV",{class:!0});var xa=s(xo);m(qA.$$.fragment,xa),iMr=i(xa),Wbe=n(xa,"P",{});var Lbt=s(Wbe);dMr=r(Lbt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Lbt.forEach(t),cMr=i(xa),Rn=n(xa,"P",{});var q4=s(Rn);fMr=r(q4,"The model class to instantiate is selected based on the "),Qbe=n(q4,"CODE",{});var Bbt=s(Qbe);mMr=r(Bbt,"model_type"),Bbt.forEach(t),gMr=r(q4,` property of the config object (either
passed as an argument or loaded from `),Hbe=n(q4,"CODE",{});var xbt=s(Hbe);hMr=r(xbt,"pretrained_model_name_or_path"),xbt.forEach(t),pMr=r(q4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ube=n(q4,"CODE",{});var kbt=s(Ube);_Mr=r(kbt,"pretrained_model_name_or_path"),kbt.forEach(t),uMr=r(q4,":"),q4.forEach(t),bMr=i(xa),be=n(xa,"UL",{});var we=s(be);IC=n(we,"LI",{});var dBe=s(IC);Jbe=n(dBe,"STRONG",{});var Rbt=s(Jbe);vMr=r(Rbt,"albert"),Rbt.forEach(t),TMr=r(dBe," \u2014 "),FV=n(dBe,"A",{href:!0});var Sbt=s(FV);FMr=r(Sbt,"FlaxAlbertForMaskedLM"),Sbt.forEach(t),CMr=r(dBe," (ALBERT model)"),dBe.forEach(t),MMr=i(we),jC=n(we,"LI",{});var cBe=s(jC);Ybe=n(cBe,"STRONG",{});var Pbt=s(Ybe);EMr=r(Pbt,"bart"),Pbt.forEach(t),yMr=r(cBe," \u2014 "),CV=n(cBe,"A",{href:!0});var $bt=s(CV);wMr=r($bt,"FlaxBartForConditionalGeneration"),$bt.forEach(t),AMr=r(cBe," (BART model)"),cBe.forEach(t),LMr=i(we),DC=n(we,"LI",{});var fBe=s(DC);Kbe=n(fBe,"STRONG",{});var Ibt=s(Kbe);BMr=r(Ibt,"bert"),Ibt.forEach(t),xMr=r(fBe," \u2014 "),MV=n(fBe,"A",{href:!0});var jbt=s(MV);kMr=r(jbt,"FlaxBertForMaskedLM"),jbt.forEach(t),RMr=r(fBe," (BERT model)"),fBe.forEach(t),SMr=i(we),NC=n(we,"LI",{});var mBe=s(NC);Zbe=n(mBe,"STRONG",{});var Dbt=s(Zbe);PMr=r(Dbt,"big_bird"),Dbt.forEach(t),$Mr=r(mBe," \u2014 "),EV=n(mBe,"A",{href:!0});var Nbt=s(EV);IMr=r(Nbt,"FlaxBigBirdForMaskedLM"),Nbt.forEach(t),jMr=r(mBe," (BigBird model)"),mBe.forEach(t),DMr=i(we),qC=n(we,"LI",{});var gBe=s(qC);e5e=n(gBe,"STRONG",{});var qbt=s(e5e);NMr=r(qbt,"distilbert"),qbt.forEach(t),qMr=r(gBe," \u2014 "),yV=n(gBe,"A",{href:!0});var Obt=s(yV);OMr=r(Obt,"FlaxDistilBertForMaskedLM"),Obt.forEach(t),GMr=r(gBe," (DistilBERT model)"),gBe.forEach(t),XMr=i(we),OC=n(we,"LI",{});var hBe=s(OC);o5e=n(hBe,"STRONG",{});var Gbt=s(o5e);VMr=r(Gbt,"electra"),Gbt.forEach(t),zMr=r(hBe," \u2014 "),wV=n(hBe,"A",{href:!0});var Xbt=s(wV);WMr=r(Xbt,"FlaxElectraForMaskedLM"),Xbt.forEach(t),QMr=r(hBe," (ELECTRA model)"),hBe.forEach(t),HMr=i(we),GC=n(we,"LI",{});var pBe=s(GC);r5e=n(pBe,"STRONG",{});var Vbt=s(r5e);UMr=r(Vbt,"mbart"),Vbt.forEach(t),JMr=r(pBe," \u2014 "),AV=n(pBe,"A",{href:!0});var zbt=s(AV);YMr=r(zbt,"FlaxMBartForConditionalGeneration"),zbt.forEach(t),KMr=r(pBe," (mBART model)"),pBe.forEach(t),ZMr=i(we),XC=n(we,"LI",{});var _Be=s(XC);t5e=n(_Be,"STRONG",{});var Wbt=s(t5e);e4r=r(Wbt,"roberta"),Wbt.forEach(t),o4r=r(_Be," \u2014 "),LV=n(_Be,"A",{href:!0});var Qbt=s(LV);r4r=r(Qbt,"FlaxRobertaForMaskedLM"),Qbt.forEach(t),t4r=r(_Be," (RoBERTa model)"),_Be.forEach(t),a4r=i(we),VC=n(we,"LI",{});var uBe=s(VC);a5e=n(uBe,"STRONG",{});var Hbt=s(a5e);n4r=r(Hbt,"roformer"),Hbt.forEach(t),s4r=r(uBe," \u2014 "),BV=n(uBe,"A",{href:!0});var Ubt=s(BV);l4r=r(Ubt,"FlaxRoFormerForMaskedLM"),Ubt.forEach(t),i4r=r(uBe," (RoFormer model)"),uBe.forEach(t),d4r=i(we),zC=n(we,"LI",{});var bBe=s(zC);n5e=n(bBe,"STRONG",{});var Jbt=s(n5e);c4r=r(Jbt,"xlm-roberta"),Jbt.forEach(t),f4r=r(bBe," \u2014 "),xV=n(bBe,"A",{href:!0});var Ybt=s(xV);m4r=r(Ybt,"FlaxXLMRobertaForMaskedLM"),Ybt.forEach(t),g4r=r(bBe," (XLM-RoBERTa model)"),bBe.forEach(t),we.forEach(t),h4r=i(xa),s5e=n(xa,"P",{});var Kbt=s(s5e);p4r=r(Kbt,"Examples:"),Kbt.forEach(t),_4r=i(xa),m(OA.$$.fragment,xa),xa.forEach(t),ui.forEach(t),Zke=i(c),cf=n(c,"H2",{class:!0});var fPe=s(cf);WC=n(fPe,"A",{id:!0,class:!0,href:!0});var Zbt=s(WC);l5e=n(Zbt,"SPAN",{});var e5t=s(l5e);m(GA.$$.fragment,e5t),e5t.forEach(t),Zbt.forEach(t),u4r=i(fPe),i5e=n(fPe,"SPAN",{});var o5t=s(i5e);b4r=r(o5t,"FlaxAutoModelForSeq2SeqLM"),o5t.forEach(t),fPe.forEach(t),eRe=i(c),Ir=n(c,"DIV",{class:!0});var vi=s(Ir);m(XA.$$.fragment,vi),v4r=i(vi),ff=n(vi,"P",{});var rQ=s(ff);T4r=r(rQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),d5e=n(rQ,"CODE",{});var r5t=s(d5e);F4r=r(r5t,"from_pretrained()"),r5t.forEach(t),C4r=r(rQ,"class method or the "),c5e=n(rQ,"CODE",{});var t5t=s(c5e);M4r=r(t5t,"from_config()"),t5t.forEach(t),E4r=r(rQ,`class
method.`),rQ.forEach(t),y4r=i(vi),VA=n(vi,"P",{});var mPe=s(VA);w4r=r(mPe,"This class cannot be instantiated directly using "),f5e=n(mPe,"CODE",{});var a5t=s(f5e);A4r=r(a5t,"__init__()"),a5t.forEach(t),L4r=r(mPe," (throws an error)."),mPe.forEach(t),B4r=i(vi),xt=n(vi,"DIV",{class:!0});var Ti=s(xt);m(zA.$$.fragment,Ti),x4r=i(Ti),m5e=n(Ti,"P",{});var n5t=s(m5e);k4r=r(n5t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),n5t.forEach(t),R4r=i(Ti),mf=n(Ti,"P",{});var tQ=s(mf);S4r=r(tQ,`Note:
Loading a model from its configuration file does `),g5e=n(tQ,"STRONG",{});var s5t=s(g5e);P4r=r(s5t,"not"),s5t.forEach(t),$4r=r(tQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),h5e=n(tQ,"CODE",{});var l5t=s(h5e);I4r=r(l5t,"from_pretrained()"),l5t.forEach(t),j4r=r(tQ,"to load the model weights."),tQ.forEach(t),D4r=i(Ti),p5e=n(Ti,"P",{});var i5t=s(p5e);N4r=r(i5t,"Examples:"),i5t.forEach(t),q4r=i(Ti),m(WA.$$.fragment,Ti),Ti.forEach(t),O4r=i(vi),ko=n(vi,"DIV",{class:!0});var ka=s(ko);m(QA.$$.fragment,ka),G4r=i(ka),_5e=n(ka,"P",{});var d5t=s(_5e);X4r=r(d5t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),d5t.forEach(t),V4r=i(ka),Sn=n(ka,"P",{});var O4=s(Sn);z4r=r(O4,"The model class to instantiate is selected based on the "),u5e=n(O4,"CODE",{});var c5t=s(u5e);W4r=r(c5t,"model_type"),c5t.forEach(t),Q4r=r(O4,` property of the config object (either
passed as an argument or loaded from `),b5e=n(O4,"CODE",{});var f5t=s(b5e);H4r=r(f5t,"pretrained_model_name_or_path"),f5t.forEach(t),U4r=r(O4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v5e=n(O4,"CODE",{});var m5t=s(v5e);J4r=r(m5t,"pretrained_model_name_or_path"),m5t.forEach(t),Y4r=r(O4,":"),O4.forEach(t),K4r=i(ka),Ce=n(ka,"UL",{});var lo=s(Ce);QC=n(lo,"LI",{});var vBe=s(QC);T5e=n(vBe,"STRONG",{});var g5t=s(T5e);Z4r=r(g5t,"bart"),g5t.forEach(t),eEr=r(vBe," \u2014 "),kV=n(vBe,"A",{href:!0});var h5t=s(kV);oEr=r(h5t,"FlaxBartForConditionalGeneration"),h5t.forEach(t),rEr=r(vBe," (BART model)"),vBe.forEach(t),tEr=i(lo),HC=n(lo,"LI",{});var TBe=s(HC);F5e=n(TBe,"STRONG",{});var p5t=s(F5e);aEr=r(p5t,"blenderbot"),p5t.forEach(t),nEr=r(TBe," \u2014 "),RV=n(TBe,"A",{href:!0});var _5t=s(RV);sEr=r(_5t,"FlaxBlenderbotForConditionalGeneration"),_5t.forEach(t),lEr=r(TBe," (Blenderbot model)"),TBe.forEach(t),iEr=i(lo),UC=n(lo,"LI",{});var FBe=s(UC);C5e=n(FBe,"STRONG",{});var u5t=s(C5e);dEr=r(u5t,"blenderbot-small"),u5t.forEach(t),cEr=r(FBe," \u2014 "),SV=n(FBe,"A",{href:!0});var b5t=s(SV);fEr=r(b5t,"FlaxBlenderbotSmallForConditionalGeneration"),b5t.forEach(t),mEr=r(FBe," (BlenderbotSmall model)"),FBe.forEach(t),gEr=i(lo),JC=n(lo,"LI",{});var CBe=s(JC);M5e=n(CBe,"STRONG",{});var v5t=s(M5e);hEr=r(v5t,"encoder-decoder"),v5t.forEach(t),pEr=r(CBe," \u2014 "),PV=n(CBe,"A",{href:!0});var T5t=s(PV);_Er=r(T5t,"FlaxEncoderDecoderModel"),T5t.forEach(t),uEr=r(CBe," (Encoder decoder model)"),CBe.forEach(t),bEr=i(lo),YC=n(lo,"LI",{});var MBe=s(YC);E5e=n(MBe,"STRONG",{});var F5t=s(E5e);vEr=r(F5t,"marian"),F5t.forEach(t),TEr=r(MBe," \u2014 "),$V=n(MBe,"A",{href:!0});var C5t=s($V);FEr=r(C5t,"FlaxMarianMTModel"),C5t.forEach(t),CEr=r(MBe," (Marian model)"),MBe.forEach(t),MEr=i(lo),KC=n(lo,"LI",{});var EBe=s(KC);y5e=n(EBe,"STRONG",{});var M5t=s(y5e);EEr=r(M5t,"mbart"),M5t.forEach(t),yEr=r(EBe," \u2014 "),IV=n(EBe,"A",{href:!0});var E5t=s(IV);wEr=r(E5t,"FlaxMBartForConditionalGeneration"),E5t.forEach(t),AEr=r(EBe," (mBART model)"),EBe.forEach(t),LEr=i(lo),ZC=n(lo,"LI",{});var yBe=s(ZC);w5e=n(yBe,"STRONG",{});var y5t=s(w5e);BEr=r(y5t,"mt5"),y5t.forEach(t),xEr=r(yBe," \u2014 "),jV=n(yBe,"A",{href:!0});var w5t=s(jV);kEr=r(w5t,"FlaxMT5ForConditionalGeneration"),w5t.forEach(t),REr=r(yBe," (mT5 model)"),yBe.forEach(t),SEr=i(lo),eM=n(lo,"LI",{});var wBe=s(eM);A5e=n(wBe,"STRONG",{});var A5t=s(A5e);PEr=r(A5t,"pegasus"),A5t.forEach(t),$Er=r(wBe," \u2014 "),DV=n(wBe,"A",{href:!0});var L5t=s(DV);IEr=r(L5t,"FlaxPegasusForConditionalGeneration"),L5t.forEach(t),jEr=r(wBe," (Pegasus model)"),wBe.forEach(t),DEr=i(lo),oM=n(lo,"LI",{});var ABe=s(oM);L5e=n(ABe,"STRONG",{});var B5t=s(L5e);NEr=r(B5t,"t5"),B5t.forEach(t),qEr=r(ABe," \u2014 "),NV=n(ABe,"A",{href:!0});var x5t=s(NV);OEr=r(x5t,"FlaxT5ForConditionalGeneration"),x5t.forEach(t),GEr=r(ABe," (T5 model)"),ABe.forEach(t),lo.forEach(t),XEr=i(ka),B5e=n(ka,"P",{});var k5t=s(B5e);VEr=r(k5t,"Examples:"),k5t.forEach(t),zEr=i(ka),m(HA.$$.fragment,ka),ka.forEach(t),vi.forEach(t),oRe=i(c),gf=n(c,"H2",{class:!0});var gPe=s(gf);rM=n(gPe,"A",{id:!0,class:!0,href:!0});var R5t=s(rM);x5e=n(R5t,"SPAN",{});var S5t=s(x5e);m(UA.$$.fragment,S5t),S5t.forEach(t),R5t.forEach(t),WEr=i(gPe),k5e=n(gPe,"SPAN",{});var P5t=s(k5e);QEr=r(P5t,"FlaxAutoModelForSequenceClassification"),P5t.forEach(t),gPe.forEach(t),rRe=i(c),jr=n(c,"DIV",{class:!0});var Fi=s(jr);m(JA.$$.fragment,Fi),HEr=i(Fi),hf=n(Fi,"P",{});var aQ=s(hf);UEr=r(aQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),R5e=n(aQ,"CODE",{});var $5t=s(R5e);JEr=r($5t,"from_pretrained()"),$5t.forEach(t),YEr=r(aQ,"class method or the "),S5e=n(aQ,"CODE",{});var I5t=s(S5e);KEr=r(I5t,"from_config()"),I5t.forEach(t),ZEr=r(aQ,`class
method.`),aQ.forEach(t),e3r=i(Fi),YA=n(Fi,"P",{});var hPe=s(YA);o3r=r(hPe,"This class cannot be instantiated directly using "),P5e=n(hPe,"CODE",{});var j5t=s(P5e);r3r=r(j5t,"__init__()"),j5t.forEach(t),t3r=r(hPe," (throws an error)."),hPe.forEach(t),a3r=i(Fi),kt=n(Fi,"DIV",{class:!0});var Ci=s(kt);m(KA.$$.fragment,Ci),n3r=i(Ci),$5e=n(Ci,"P",{});var D5t=s($5e);s3r=r(D5t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),D5t.forEach(t),l3r=i(Ci),pf=n(Ci,"P",{});var nQ=s(pf);i3r=r(nQ,`Note:
Loading a model from its configuration file does `),I5e=n(nQ,"STRONG",{});var N5t=s(I5e);d3r=r(N5t,"not"),N5t.forEach(t),c3r=r(nQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),j5e=n(nQ,"CODE",{});var q5t=s(j5e);f3r=r(q5t,"from_pretrained()"),q5t.forEach(t),m3r=r(nQ,"to load the model weights."),nQ.forEach(t),g3r=i(Ci),D5e=n(Ci,"P",{});var O5t=s(D5e);h3r=r(O5t,"Examples:"),O5t.forEach(t),p3r=i(Ci),m(ZA.$$.fragment,Ci),Ci.forEach(t),_3r=i(Fi),Ro=n(Fi,"DIV",{class:!0});var Ra=s(Ro);m(eL.$$.fragment,Ra),u3r=i(Ra),N5e=n(Ra,"P",{});var G5t=s(N5e);b3r=r(G5t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),G5t.forEach(t),v3r=i(Ra),Pn=n(Ra,"P",{});var G4=s(Pn);T3r=r(G4,"The model class to instantiate is selected based on the "),q5e=n(G4,"CODE",{});var X5t=s(q5e);F3r=r(X5t,"model_type"),X5t.forEach(t),C3r=r(G4,` property of the config object (either
passed as an argument or loaded from `),O5e=n(G4,"CODE",{});var V5t=s(O5e);M3r=r(V5t,"pretrained_model_name_or_path"),V5t.forEach(t),E3r=r(G4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G5e=n(G4,"CODE",{});var z5t=s(G5e);y3r=r(z5t,"pretrained_model_name_or_path"),z5t.forEach(t),w3r=r(G4,":"),G4.forEach(t),A3r=i(Ra),ve=n(Ra,"UL",{});var Ae=s(ve);tM=n(Ae,"LI",{});var LBe=s(tM);X5e=n(LBe,"STRONG",{});var W5t=s(X5e);L3r=r(W5t,"albert"),W5t.forEach(t),B3r=r(LBe," \u2014 "),qV=n(LBe,"A",{href:!0});var Q5t=s(qV);x3r=r(Q5t,"FlaxAlbertForSequenceClassification"),Q5t.forEach(t),k3r=r(LBe," (ALBERT model)"),LBe.forEach(t),R3r=i(Ae),aM=n(Ae,"LI",{});var BBe=s(aM);V5e=n(BBe,"STRONG",{});var H5t=s(V5e);S3r=r(H5t,"bart"),H5t.forEach(t),P3r=r(BBe," \u2014 "),OV=n(BBe,"A",{href:!0});var U5t=s(OV);$3r=r(U5t,"FlaxBartForSequenceClassification"),U5t.forEach(t),I3r=r(BBe," (BART model)"),BBe.forEach(t),j3r=i(Ae),nM=n(Ae,"LI",{});var xBe=s(nM);z5e=n(xBe,"STRONG",{});var J5t=s(z5e);D3r=r(J5t,"bert"),J5t.forEach(t),N3r=r(xBe," \u2014 "),GV=n(xBe,"A",{href:!0});var Y5t=s(GV);q3r=r(Y5t,"FlaxBertForSequenceClassification"),Y5t.forEach(t),O3r=r(xBe," (BERT model)"),xBe.forEach(t),G3r=i(Ae),sM=n(Ae,"LI",{});var kBe=s(sM);W5e=n(kBe,"STRONG",{});var K5t=s(W5e);X3r=r(K5t,"big_bird"),K5t.forEach(t),V3r=r(kBe," \u2014 "),XV=n(kBe,"A",{href:!0});var Z5t=s(XV);z3r=r(Z5t,"FlaxBigBirdForSequenceClassification"),Z5t.forEach(t),W3r=r(kBe," (BigBird model)"),kBe.forEach(t),Q3r=i(Ae),lM=n(Ae,"LI",{});var RBe=s(lM);Q5e=n(RBe,"STRONG",{});var e2t=s(Q5e);H3r=r(e2t,"distilbert"),e2t.forEach(t),U3r=r(RBe," \u2014 "),VV=n(RBe,"A",{href:!0});var o2t=s(VV);J3r=r(o2t,"FlaxDistilBertForSequenceClassification"),o2t.forEach(t),Y3r=r(RBe," (DistilBERT model)"),RBe.forEach(t),K3r=i(Ae),iM=n(Ae,"LI",{});var SBe=s(iM);H5e=n(SBe,"STRONG",{});var r2t=s(H5e);Z3r=r(r2t,"electra"),r2t.forEach(t),eyr=r(SBe," \u2014 "),zV=n(SBe,"A",{href:!0});var t2t=s(zV);oyr=r(t2t,"FlaxElectraForSequenceClassification"),t2t.forEach(t),ryr=r(SBe," (ELECTRA model)"),SBe.forEach(t),tyr=i(Ae),dM=n(Ae,"LI",{});var PBe=s(dM);U5e=n(PBe,"STRONG",{});var a2t=s(U5e);ayr=r(a2t,"mbart"),a2t.forEach(t),nyr=r(PBe," \u2014 "),WV=n(PBe,"A",{href:!0});var n2t=s(WV);syr=r(n2t,"FlaxMBartForSequenceClassification"),n2t.forEach(t),lyr=r(PBe," (mBART model)"),PBe.forEach(t),iyr=i(Ae),cM=n(Ae,"LI",{});var $Be=s(cM);J5e=n($Be,"STRONG",{});var s2t=s(J5e);dyr=r(s2t,"roberta"),s2t.forEach(t),cyr=r($Be," \u2014 "),QV=n($Be,"A",{href:!0});var l2t=s(QV);fyr=r(l2t,"FlaxRobertaForSequenceClassification"),l2t.forEach(t),myr=r($Be," (RoBERTa model)"),$Be.forEach(t),gyr=i(Ae),fM=n(Ae,"LI",{});var IBe=s(fM);Y5e=n(IBe,"STRONG",{});var i2t=s(Y5e);hyr=r(i2t,"roformer"),i2t.forEach(t),pyr=r(IBe," \u2014 "),HV=n(IBe,"A",{href:!0});var d2t=s(HV);_yr=r(d2t,"FlaxRoFormerForSequenceClassification"),d2t.forEach(t),uyr=r(IBe," (RoFormer model)"),IBe.forEach(t),byr=i(Ae),mM=n(Ae,"LI",{});var jBe=s(mM);K5e=n(jBe,"STRONG",{});var c2t=s(K5e);vyr=r(c2t,"xlm-roberta"),c2t.forEach(t),Tyr=r(jBe," \u2014 "),UV=n(jBe,"A",{href:!0});var f2t=s(UV);Fyr=r(f2t,"FlaxXLMRobertaForSequenceClassification"),f2t.forEach(t),Cyr=r(jBe," (XLM-RoBERTa model)"),jBe.forEach(t),Ae.forEach(t),Myr=i(Ra),Z5e=n(Ra,"P",{});var m2t=s(Z5e);Eyr=r(m2t,"Examples:"),m2t.forEach(t),yyr=i(Ra),m(oL.$$.fragment,Ra),Ra.forEach(t),Fi.forEach(t),tRe=i(c),_f=n(c,"H2",{class:!0});var pPe=s(_f);gM=n(pPe,"A",{id:!0,class:!0,href:!0});var g2t=s(gM);e2e=n(g2t,"SPAN",{});var h2t=s(e2e);m(rL.$$.fragment,h2t),h2t.forEach(t),g2t.forEach(t),wyr=i(pPe),o2e=n(pPe,"SPAN",{});var p2t=s(o2e);Ayr=r(p2t,"FlaxAutoModelForQuestionAnswering"),p2t.forEach(t),pPe.forEach(t),aRe=i(c),Dr=n(c,"DIV",{class:!0});var Mi=s(Dr);m(tL.$$.fragment,Mi),Lyr=i(Mi),uf=n(Mi,"P",{});var sQ=s(uf);Byr=r(sQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),r2e=n(sQ,"CODE",{});var _2t=s(r2e);xyr=r(_2t,"from_pretrained()"),_2t.forEach(t),kyr=r(sQ,"class method or the "),t2e=n(sQ,"CODE",{});var u2t=s(t2e);Ryr=r(u2t,"from_config()"),u2t.forEach(t),Syr=r(sQ,`class
method.`),sQ.forEach(t),Pyr=i(Mi),aL=n(Mi,"P",{});var _Pe=s(aL);$yr=r(_Pe,"This class cannot be instantiated directly using "),a2e=n(_Pe,"CODE",{});var b2t=s(a2e);Iyr=r(b2t,"__init__()"),b2t.forEach(t),jyr=r(_Pe," (throws an error)."),_Pe.forEach(t),Dyr=i(Mi),Rt=n(Mi,"DIV",{class:!0});var Ei=s(Rt);m(nL.$$.fragment,Ei),Nyr=i(Ei),n2e=n(Ei,"P",{});var v2t=s(n2e);qyr=r(v2t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),v2t.forEach(t),Oyr=i(Ei),bf=n(Ei,"P",{});var lQ=s(bf);Gyr=r(lQ,`Note:
Loading a model from its configuration file does `),s2e=n(lQ,"STRONG",{});var T2t=s(s2e);Xyr=r(T2t,"not"),T2t.forEach(t),Vyr=r(lQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),l2e=n(lQ,"CODE",{});var F2t=s(l2e);zyr=r(F2t,"from_pretrained()"),F2t.forEach(t),Wyr=r(lQ,"to load the model weights."),lQ.forEach(t),Qyr=i(Ei),i2e=n(Ei,"P",{});var C2t=s(i2e);Hyr=r(C2t,"Examples:"),C2t.forEach(t),Uyr=i(Ei),m(sL.$$.fragment,Ei),Ei.forEach(t),Jyr=i(Mi),So=n(Mi,"DIV",{class:!0});var Sa=s(So);m(lL.$$.fragment,Sa),Yyr=i(Sa),d2e=n(Sa,"P",{});var M2t=s(d2e);Kyr=r(M2t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),M2t.forEach(t),Zyr=i(Sa),$n=n(Sa,"P",{});var X4=s($n);ewr=r(X4,"The model class to instantiate is selected based on the "),c2e=n(X4,"CODE",{});var E2t=s(c2e);owr=r(E2t,"model_type"),E2t.forEach(t),rwr=r(X4,` property of the config object (either
passed as an argument or loaded from `),f2e=n(X4,"CODE",{});var y2t=s(f2e);twr=r(y2t,"pretrained_model_name_or_path"),y2t.forEach(t),awr=r(X4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m2e=n(X4,"CODE",{});var w2t=s(m2e);nwr=r(w2t,"pretrained_model_name_or_path"),w2t.forEach(t),swr=r(X4,":"),X4.forEach(t),lwr=i(Sa),Te=n(Sa,"UL",{});var Le=s(Te);hM=n(Le,"LI",{});var DBe=s(hM);g2e=n(DBe,"STRONG",{});var A2t=s(g2e);iwr=r(A2t,"albert"),A2t.forEach(t),dwr=r(DBe," \u2014 "),JV=n(DBe,"A",{href:!0});var L2t=s(JV);cwr=r(L2t,"FlaxAlbertForQuestionAnswering"),L2t.forEach(t),fwr=r(DBe," (ALBERT model)"),DBe.forEach(t),mwr=i(Le),pM=n(Le,"LI",{});var NBe=s(pM);h2e=n(NBe,"STRONG",{});var B2t=s(h2e);gwr=r(B2t,"bart"),B2t.forEach(t),hwr=r(NBe," \u2014 "),YV=n(NBe,"A",{href:!0});var x2t=s(YV);pwr=r(x2t,"FlaxBartForQuestionAnswering"),x2t.forEach(t),_wr=r(NBe," (BART model)"),NBe.forEach(t),uwr=i(Le),_M=n(Le,"LI",{});var qBe=s(_M);p2e=n(qBe,"STRONG",{});var k2t=s(p2e);bwr=r(k2t,"bert"),k2t.forEach(t),vwr=r(qBe," \u2014 "),KV=n(qBe,"A",{href:!0});var R2t=s(KV);Twr=r(R2t,"FlaxBertForQuestionAnswering"),R2t.forEach(t),Fwr=r(qBe," (BERT model)"),qBe.forEach(t),Cwr=i(Le),uM=n(Le,"LI",{});var OBe=s(uM);_2e=n(OBe,"STRONG",{});var S2t=s(_2e);Mwr=r(S2t,"big_bird"),S2t.forEach(t),Ewr=r(OBe," \u2014 "),ZV=n(OBe,"A",{href:!0});var P2t=s(ZV);ywr=r(P2t,"FlaxBigBirdForQuestionAnswering"),P2t.forEach(t),wwr=r(OBe," (BigBird model)"),OBe.forEach(t),Awr=i(Le),bM=n(Le,"LI",{});var GBe=s(bM);u2e=n(GBe,"STRONG",{});var $2t=s(u2e);Lwr=r($2t,"distilbert"),$2t.forEach(t),Bwr=r(GBe," \u2014 "),ez=n(GBe,"A",{href:!0});var I2t=s(ez);xwr=r(I2t,"FlaxDistilBertForQuestionAnswering"),I2t.forEach(t),kwr=r(GBe," (DistilBERT model)"),GBe.forEach(t),Rwr=i(Le),vM=n(Le,"LI",{});var XBe=s(vM);b2e=n(XBe,"STRONG",{});var j2t=s(b2e);Swr=r(j2t,"electra"),j2t.forEach(t),Pwr=r(XBe," \u2014 "),oz=n(XBe,"A",{href:!0});var D2t=s(oz);$wr=r(D2t,"FlaxElectraForQuestionAnswering"),D2t.forEach(t),Iwr=r(XBe," (ELECTRA model)"),XBe.forEach(t),jwr=i(Le),TM=n(Le,"LI",{});var VBe=s(TM);v2e=n(VBe,"STRONG",{});var N2t=s(v2e);Dwr=r(N2t,"mbart"),N2t.forEach(t),Nwr=r(VBe," \u2014 "),rz=n(VBe,"A",{href:!0});var q2t=s(rz);qwr=r(q2t,"FlaxMBartForQuestionAnswering"),q2t.forEach(t),Owr=r(VBe," (mBART model)"),VBe.forEach(t),Gwr=i(Le),FM=n(Le,"LI",{});var zBe=s(FM);T2e=n(zBe,"STRONG",{});var O2t=s(T2e);Xwr=r(O2t,"roberta"),O2t.forEach(t),Vwr=r(zBe," \u2014 "),tz=n(zBe,"A",{href:!0});var G2t=s(tz);zwr=r(G2t,"FlaxRobertaForQuestionAnswering"),G2t.forEach(t),Wwr=r(zBe," (RoBERTa model)"),zBe.forEach(t),Qwr=i(Le),CM=n(Le,"LI",{});var WBe=s(CM);F2e=n(WBe,"STRONG",{});var X2t=s(F2e);Hwr=r(X2t,"roformer"),X2t.forEach(t),Uwr=r(WBe," \u2014 "),az=n(WBe,"A",{href:!0});var V2t=s(az);Jwr=r(V2t,"FlaxRoFormerForQuestionAnswering"),V2t.forEach(t),Ywr=r(WBe," (RoFormer model)"),WBe.forEach(t),Kwr=i(Le),MM=n(Le,"LI",{});var QBe=s(MM);C2e=n(QBe,"STRONG",{});var z2t=s(C2e);Zwr=r(z2t,"xlm-roberta"),z2t.forEach(t),e6r=r(QBe," \u2014 "),nz=n(QBe,"A",{href:!0});var W2t=s(nz);o6r=r(W2t,"FlaxXLMRobertaForQuestionAnswering"),W2t.forEach(t),r6r=r(QBe," (XLM-RoBERTa model)"),QBe.forEach(t),Le.forEach(t),t6r=i(Sa),M2e=n(Sa,"P",{});var Q2t=s(M2e);a6r=r(Q2t,"Examples:"),Q2t.forEach(t),n6r=i(Sa),m(iL.$$.fragment,Sa),Sa.forEach(t),Mi.forEach(t),nRe=i(c),vf=n(c,"H2",{class:!0});var uPe=s(vf);EM=n(uPe,"A",{id:!0,class:!0,href:!0});var H2t=s(EM);E2e=n(H2t,"SPAN",{});var U2t=s(E2e);m(dL.$$.fragment,U2t),U2t.forEach(t),H2t.forEach(t),s6r=i(uPe),y2e=n(uPe,"SPAN",{});var J2t=s(y2e);l6r=r(J2t,"FlaxAutoModelForTokenClassification"),J2t.forEach(t),uPe.forEach(t),sRe=i(c),Nr=n(c,"DIV",{class:!0});var yi=s(Nr);m(cL.$$.fragment,yi),i6r=i(yi),Tf=n(yi,"P",{});var iQ=s(Tf);d6r=r(iQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),w2e=n(iQ,"CODE",{});var Y2t=s(w2e);c6r=r(Y2t,"from_pretrained()"),Y2t.forEach(t),f6r=r(iQ,"class method or the "),A2e=n(iQ,"CODE",{});var K2t=s(A2e);m6r=r(K2t,"from_config()"),K2t.forEach(t),g6r=r(iQ,`class
method.`),iQ.forEach(t),h6r=i(yi),fL=n(yi,"P",{});var bPe=s(fL);p6r=r(bPe,"This class cannot be instantiated directly using "),L2e=n(bPe,"CODE",{});var Z2t=s(L2e);_6r=r(Z2t,"__init__()"),Z2t.forEach(t),u6r=r(bPe," (throws an error)."),bPe.forEach(t),b6r=i(yi),St=n(yi,"DIV",{class:!0});var wi=s(St);m(mL.$$.fragment,wi),v6r=i(wi),B2e=n(wi,"P",{});var evt=s(B2e);T6r=r(evt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),evt.forEach(t),F6r=i(wi),Ff=n(wi,"P",{});var dQ=s(Ff);C6r=r(dQ,`Note:
Loading a model from its configuration file does `),x2e=n(dQ,"STRONG",{});var ovt=s(x2e);M6r=r(ovt,"not"),ovt.forEach(t),E6r=r(dQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),k2e=n(dQ,"CODE",{});var rvt=s(k2e);y6r=r(rvt,"from_pretrained()"),rvt.forEach(t),w6r=r(dQ,"to load the model weights."),dQ.forEach(t),A6r=i(wi),R2e=n(wi,"P",{});var tvt=s(R2e);L6r=r(tvt,"Examples:"),tvt.forEach(t),B6r=i(wi),m(gL.$$.fragment,wi),wi.forEach(t),x6r=i(yi),Po=n(yi,"DIV",{class:!0});var Pa=s(Po);m(hL.$$.fragment,Pa),k6r=i(Pa),S2e=n(Pa,"P",{});var avt=s(S2e);R6r=r(avt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),avt.forEach(t),S6r=i(Pa),In=n(Pa,"P",{});var V4=s(In);P6r=r(V4,"The model class to instantiate is selected based on the "),P2e=n(V4,"CODE",{});var nvt=s(P2e);$6r=r(nvt,"model_type"),nvt.forEach(t),I6r=r(V4,` property of the config object (either
passed as an argument or loaded from `),$2e=n(V4,"CODE",{});var svt=s($2e);j6r=r(svt,"pretrained_model_name_or_path"),svt.forEach(t),D6r=r(V4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=n(V4,"CODE",{});var lvt=s(I2e);N6r=r(lvt,"pretrained_model_name_or_path"),lvt.forEach(t),q6r=r(V4,":"),V4.forEach(t),O6r=i(Pa),Se=n(Pa,"UL",{});var Go=s(Se);yM=n(Go,"LI",{});var HBe=s(yM);j2e=n(HBe,"STRONG",{});var ivt=s(j2e);G6r=r(ivt,"albert"),ivt.forEach(t),X6r=r(HBe," \u2014 "),sz=n(HBe,"A",{href:!0});var dvt=s(sz);V6r=r(dvt,"FlaxAlbertForTokenClassification"),dvt.forEach(t),z6r=r(HBe," (ALBERT model)"),HBe.forEach(t),W6r=i(Go),wM=n(Go,"LI",{});var UBe=s(wM);D2e=n(UBe,"STRONG",{});var cvt=s(D2e);Q6r=r(cvt,"bert"),cvt.forEach(t),H6r=r(UBe," \u2014 "),lz=n(UBe,"A",{href:!0});var fvt=s(lz);U6r=r(fvt,"FlaxBertForTokenClassification"),fvt.forEach(t),J6r=r(UBe," (BERT model)"),UBe.forEach(t),Y6r=i(Go),AM=n(Go,"LI",{});var JBe=s(AM);N2e=n(JBe,"STRONG",{});var mvt=s(N2e);K6r=r(mvt,"big_bird"),mvt.forEach(t),Z6r=r(JBe," \u2014 "),iz=n(JBe,"A",{href:!0});var gvt=s(iz);eAr=r(gvt,"FlaxBigBirdForTokenClassification"),gvt.forEach(t),oAr=r(JBe," (BigBird model)"),JBe.forEach(t),rAr=i(Go),LM=n(Go,"LI",{});var YBe=s(LM);q2e=n(YBe,"STRONG",{});var hvt=s(q2e);tAr=r(hvt,"distilbert"),hvt.forEach(t),aAr=r(YBe," \u2014 "),dz=n(YBe,"A",{href:!0});var pvt=s(dz);nAr=r(pvt,"FlaxDistilBertForTokenClassification"),pvt.forEach(t),sAr=r(YBe," (DistilBERT model)"),YBe.forEach(t),lAr=i(Go),BM=n(Go,"LI",{});var KBe=s(BM);O2e=n(KBe,"STRONG",{});var _vt=s(O2e);iAr=r(_vt,"electra"),_vt.forEach(t),dAr=r(KBe," \u2014 "),cz=n(KBe,"A",{href:!0});var uvt=s(cz);cAr=r(uvt,"FlaxElectraForTokenClassification"),uvt.forEach(t),fAr=r(KBe," (ELECTRA model)"),KBe.forEach(t),mAr=i(Go),xM=n(Go,"LI",{});var ZBe=s(xM);G2e=n(ZBe,"STRONG",{});var bvt=s(G2e);gAr=r(bvt,"roberta"),bvt.forEach(t),hAr=r(ZBe," \u2014 "),fz=n(ZBe,"A",{href:!0});var vvt=s(fz);pAr=r(vvt,"FlaxRobertaForTokenClassification"),vvt.forEach(t),_Ar=r(ZBe," (RoBERTa model)"),ZBe.forEach(t),uAr=i(Go),kM=n(Go,"LI",{});var exe=s(kM);X2e=n(exe,"STRONG",{});var Tvt=s(X2e);bAr=r(Tvt,"roformer"),Tvt.forEach(t),vAr=r(exe," \u2014 "),mz=n(exe,"A",{href:!0});var Fvt=s(mz);TAr=r(Fvt,"FlaxRoFormerForTokenClassification"),Fvt.forEach(t),FAr=r(exe," (RoFormer model)"),exe.forEach(t),CAr=i(Go),RM=n(Go,"LI",{});var oxe=s(RM);V2e=n(oxe,"STRONG",{});var Cvt=s(V2e);MAr=r(Cvt,"xlm-roberta"),Cvt.forEach(t),EAr=r(oxe," \u2014 "),gz=n(oxe,"A",{href:!0});var Mvt=s(gz);yAr=r(Mvt,"FlaxXLMRobertaForTokenClassification"),Mvt.forEach(t),wAr=r(oxe," (XLM-RoBERTa model)"),oxe.forEach(t),Go.forEach(t),AAr=i(Pa),z2e=n(Pa,"P",{});var Evt=s(z2e);LAr=r(Evt,"Examples:"),Evt.forEach(t),BAr=i(Pa),m(pL.$$.fragment,Pa),Pa.forEach(t),yi.forEach(t),lRe=i(c),Cf=n(c,"H2",{class:!0});var vPe=s(Cf);SM=n(vPe,"A",{id:!0,class:!0,href:!0});var yvt=s(SM);W2e=n(yvt,"SPAN",{});var wvt=s(W2e);m(_L.$$.fragment,wvt),wvt.forEach(t),yvt.forEach(t),xAr=i(vPe),Q2e=n(vPe,"SPAN",{});var Avt=s(Q2e);kAr=r(Avt,"FlaxAutoModelForMultipleChoice"),Avt.forEach(t),vPe.forEach(t),iRe=i(c),qr=n(c,"DIV",{class:!0});var Ai=s(qr);m(uL.$$.fragment,Ai),RAr=i(Ai),Mf=n(Ai,"P",{});var cQ=s(Mf);SAr=r(cQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),H2e=n(cQ,"CODE",{});var Lvt=s(H2e);PAr=r(Lvt,"from_pretrained()"),Lvt.forEach(t),$Ar=r(cQ,"class method or the "),U2e=n(cQ,"CODE",{});var Bvt=s(U2e);IAr=r(Bvt,"from_config()"),Bvt.forEach(t),jAr=r(cQ,`class
method.`),cQ.forEach(t),DAr=i(Ai),bL=n(Ai,"P",{});var TPe=s(bL);NAr=r(TPe,"This class cannot be instantiated directly using "),J2e=n(TPe,"CODE",{});var xvt=s(J2e);qAr=r(xvt,"__init__()"),xvt.forEach(t),OAr=r(TPe," (throws an error)."),TPe.forEach(t),GAr=i(Ai),Pt=n(Ai,"DIV",{class:!0});var Li=s(Pt);m(vL.$$.fragment,Li),XAr=i(Li),Y2e=n(Li,"P",{});var kvt=s(Y2e);VAr=r(kvt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),kvt.forEach(t),zAr=i(Li),Ef=n(Li,"P",{});var fQ=s(Ef);WAr=r(fQ,`Note:
Loading a model from its configuration file does `),K2e=n(fQ,"STRONG",{});var Rvt=s(K2e);QAr=r(Rvt,"not"),Rvt.forEach(t),HAr=r(fQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Z2e=n(fQ,"CODE",{});var Svt=s(Z2e);UAr=r(Svt,"from_pretrained()"),Svt.forEach(t),JAr=r(fQ,"to load the model weights."),fQ.forEach(t),YAr=i(Li),eve=n(Li,"P",{});var Pvt=s(eve);KAr=r(Pvt,"Examples:"),Pvt.forEach(t),ZAr=i(Li),m(TL.$$.fragment,Li),Li.forEach(t),eLr=i(Ai),$o=n(Ai,"DIV",{class:!0});var $a=s($o);m(FL.$$.fragment,$a),oLr=i($a),ove=n($a,"P",{});var $vt=s(ove);rLr=r($vt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$vt.forEach(t),tLr=i($a),jn=n($a,"P",{});var z4=s(jn);aLr=r(z4,"The model class to instantiate is selected based on the "),rve=n(z4,"CODE",{});var Ivt=s(rve);nLr=r(Ivt,"model_type"),Ivt.forEach(t),sLr=r(z4,` property of the config object (either
passed as an argument or loaded from `),tve=n(z4,"CODE",{});var jvt=s(tve);lLr=r(jvt,"pretrained_model_name_or_path"),jvt.forEach(t),iLr=r(z4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=n(z4,"CODE",{});var Dvt=s(ave);dLr=r(Dvt,"pretrained_model_name_or_path"),Dvt.forEach(t),cLr=r(z4,":"),z4.forEach(t),fLr=i($a),Pe=n($a,"UL",{});var Xo=s(Pe);PM=n(Xo,"LI",{});var rxe=s(PM);nve=n(rxe,"STRONG",{});var Nvt=s(nve);mLr=r(Nvt,"albert"),Nvt.forEach(t),gLr=r(rxe," \u2014 "),hz=n(rxe,"A",{href:!0});var qvt=s(hz);hLr=r(qvt,"FlaxAlbertForMultipleChoice"),qvt.forEach(t),pLr=r(rxe," (ALBERT model)"),rxe.forEach(t),_Lr=i(Xo),$M=n(Xo,"LI",{});var txe=s($M);sve=n(txe,"STRONG",{});var Ovt=s(sve);uLr=r(Ovt,"bert"),Ovt.forEach(t),bLr=r(txe," \u2014 "),pz=n(txe,"A",{href:!0});var Gvt=s(pz);vLr=r(Gvt,"FlaxBertForMultipleChoice"),Gvt.forEach(t),TLr=r(txe," (BERT model)"),txe.forEach(t),FLr=i(Xo),IM=n(Xo,"LI",{});var axe=s(IM);lve=n(axe,"STRONG",{});var Xvt=s(lve);CLr=r(Xvt,"big_bird"),Xvt.forEach(t),MLr=r(axe," \u2014 "),_z=n(axe,"A",{href:!0});var Vvt=s(_z);ELr=r(Vvt,"FlaxBigBirdForMultipleChoice"),Vvt.forEach(t),yLr=r(axe," (BigBird model)"),axe.forEach(t),wLr=i(Xo),jM=n(Xo,"LI",{});var nxe=s(jM);ive=n(nxe,"STRONG",{});var zvt=s(ive);ALr=r(zvt,"distilbert"),zvt.forEach(t),LLr=r(nxe," \u2014 "),uz=n(nxe,"A",{href:!0});var Wvt=s(uz);BLr=r(Wvt,"FlaxDistilBertForMultipleChoice"),Wvt.forEach(t),xLr=r(nxe," (DistilBERT model)"),nxe.forEach(t),kLr=i(Xo),DM=n(Xo,"LI",{});var sxe=s(DM);dve=n(sxe,"STRONG",{});var Qvt=s(dve);RLr=r(Qvt,"electra"),Qvt.forEach(t),SLr=r(sxe," \u2014 "),bz=n(sxe,"A",{href:!0});var Hvt=s(bz);PLr=r(Hvt,"FlaxElectraForMultipleChoice"),Hvt.forEach(t),$Lr=r(sxe," (ELECTRA model)"),sxe.forEach(t),ILr=i(Xo),NM=n(Xo,"LI",{});var lxe=s(NM);cve=n(lxe,"STRONG",{});var Uvt=s(cve);jLr=r(Uvt,"roberta"),Uvt.forEach(t),DLr=r(lxe," \u2014 "),vz=n(lxe,"A",{href:!0});var Jvt=s(vz);NLr=r(Jvt,"FlaxRobertaForMultipleChoice"),Jvt.forEach(t),qLr=r(lxe," (RoBERTa model)"),lxe.forEach(t),OLr=i(Xo),qM=n(Xo,"LI",{});var ixe=s(qM);fve=n(ixe,"STRONG",{});var Yvt=s(fve);GLr=r(Yvt,"roformer"),Yvt.forEach(t),XLr=r(ixe," \u2014 "),Tz=n(ixe,"A",{href:!0});var Kvt=s(Tz);VLr=r(Kvt,"FlaxRoFormerForMultipleChoice"),Kvt.forEach(t),zLr=r(ixe," (RoFormer model)"),ixe.forEach(t),WLr=i(Xo),OM=n(Xo,"LI",{});var dxe=s(OM);mve=n(dxe,"STRONG",{});var Zvt=s(mve);QLr=r(Zvt,"xlm-roberta"),Zvt.forEach(t),HLr=r(dxe," \u2014 "),Fz=n(dxe,"A",{href:!0});var e0t=s(Fz);ULr=r(e0t,"FlaxXLMRobertaForMultipleChoice"),e0t.forEach(t),JLr=r(dxe," (XLM-RoBERTa model)"),dxe.forEach(t),Xo.forEach(t),YLr=i($a),gve=n($a,"P",{});var o0t=s(gve);KLr=r(o0t,"Examples:"),o0t.forEach(t),ZLr=i($a),m(CL.$$.fragment,$a),$a.forEach(t),Ai.forEach(t),dRe=i(c),yf=n(c,"H2",{class:!0});var FPe=s(yf);GM=n(FPe,"A",{id:!0,class:!0,href:!0});var r0t=s(GM);hve=n(r0t,"SPAN",{});var t0t=s(hve);m(ML.$$.fragment,t0t),t0t.forEach(t),r0t.forEach(t),e8r=i(FPe),pve=n(FPe,"SPAN",{});var a0t=s(pve);o8r=r(a0t,"FlaxAutoModelForNextSentencePrediction"),a0t.forEach(t),FPe.forEach(t),cRe=i(c),Or=n(c,"DIV",{class:!0});var Bi=s(Or);m(EL.$$.fragment,Bi),r8r=i(Bi),wf=n(Bi,"P",{});var mQ=s(wf);t8r=r(mQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),_ve=n(mQ,"CODE",{});var n0t=s(_ve);a8r=r(n0t,"from_pretrained()"),n0t.forEach(t),n8r=r(mQ,"class method or the "),uve=n(mQ,"CODE",{});var s0t=s(uve);s8r=r(s0t,"from_config()"),s0t.forEach(t),l8r=r(mQ,`class
method.`),mQ.forEach(t),i8r=i(Bi),yL=n(Bi,"P",{});var CPe=s(yL);d8r=r(CPe,"This class cannot be instantiated directly using "),bve=n(CPe,"CODE",{});var l0t=s(bve);c8r=r(l0t,"__init__()"),l0t.forEach(t),f8r=r(CPe," (throws an error)."),CPe.forEach(t),m8r=i(Bi),$t=n(Bi,"DIV",{class:!0});var xi=s($t);m(wL.$$.fragment,xi),g8r=i(xi),vve=n(xi,"P",{});var i0t=s(vve);h8r=r(i0t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),i0t.forEach(t),p8r=i(xi),Af=n(xi,"P",{});var gQ=s(Af);_8r=r(gQ,`Note:
Loading a model from its configuration file does `),Tve=n(gQ,"STRONG",{});var d0t=s(Tve);u8r=r(d0t,"not"),d0t.forEach(t),b8r=r(gQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fve=n(gQ,"CODE",{});var c0t=s(Fve);v8r=r(c0t,"from_pretrained()"),c0t.forEach(t),T8r=r(gQ,"to load the model weights."),gQ.forEach(t),F8r=i(xi),Cve=n(xi,"P",{});var f0t=s(Cve);C8r=r(f0t,"Examples:"),f0t.forEach(t),M8r=i(xi),m(AL.$$.fragment,xi),xi.forEach(t),E8r=i(Bi),Io=n(Bi,"DIV",{class:!0});var Ia=s(Io);m(LL.$$.fragment,Ia),y8r=i(Ia),Mve=n(Ia,"P",{});var m0t=s(Mve);w8r=r(m0t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),m0t.forEach(t),A8r=i(Ia),Dn=n(Ia,"P",{});var W4=s(Dn);L8r=r(W4,"The model class to instantiate is selected based on the "),Eve=n(W4,"CODE",{});var g0t=s(Eve);B8r=r(g0t,"model_type"),g0t.forEach(t),x8r=r(W4,` property of the config object (either
passed as an argument or loaded from `),yve=n(W4,"CODE",{});var h0t=s(yve);k8r=r(h0t,"pretrained_model_name_or_path"),h0t.forEach(t),R8r=r(W4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wve=n(W4,"CODE",{});var p0t=s(wve);S8r=r(p0t,"pretrained_model_name_or_path"),p0t.forEach(t),P8r=r(W4,":"),W4.forEach(t),$8r=i(Ia),Ave=n(Ia,"UL",{});var _0t=s(Ave);XM=n(_0t,"LI",{});var cxe=s(XM);Lve=n(cxe,"STRONG",{});var u0t=s(Lve);I8r=r(u0t,"bert"),u0t.forEach(t),j8r=r(cxe," \u2014 "),Cz=n(cxe,"A",{href:!0});var b0t=s(Cz);D8r=r(b0t,"FlaxBertForNextSentencePrediction"),b0t.forEach(t),N8r=r(cxe," (BERT model)"),cxe.forEach(t),_0t.forEach(t),q8r=i(Ia),Bve=n(Ia,"P",{});var v0t=s(Bve);O8r=r(v0t,"Examples:"),v0t.forEach(t),G8r=i(Ia),m(BL.$$.fragment,Ia),Ia.forEach(t),Bi.forEach(t),fRe=i(c),Lf=n(c,"H2",{class:!0});var MPe=s(Lf);VM=n(MPe,"A",{id:!0,class:!0,href:!0});var T0t=s(VM);xve=n(T0t,"SPAN",{});var F0t=s(xve);m(xL.$$.fragment,F0t),F0t.forEach(t),T0t.forEach(t),X8r=i(MPe),kve=n(MPe,"SPAN",{});var C0t=s(kve);V8r=r(C0t,"FlaxAutoModelForImageClassification"),C0t.forEach(t),MPe.forEach(t),mRe=i(c),Gr=n(c,"DIV",{class:!0});var ki=s(Gr);m(kL.$$.fragment,ki),z8r=i(ki),Bf=n(ki,"P",{});var hQ=s(Bf);W8r=r(hQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Rve=n(hQ,"CODE",{});var M0t=s(Rve);Q8r=r(M0t,"from_pretrained()"),M0t.forEach(t),H8r=r(hQ,"class method or the "),Sve=n(hQ,"CODE",{});var E0t=s(Sve);U8r=r(E0t,"from_config()"),E0t.forEach(t),J8r=r(hQ,`class
method.`),hQ.forEach(t),Y8r=i(ki),RL=n(ki,"P",{});var EPe=s(RL);K8r=r(EPe,"This class cannot be instantiated directly using "),Pve=n(EPe,"CODE",{});var y0t=s(Pve);Z8r=r(y0t,"__init__()"),y0t.forEach(t),e9r=r(EPe," (throws an error)."),EPe.forEach(t),o9r=i(ki),It=n(ki,"DIV",{class:!0});var Ri=s(It);m(SL.$$.fragment,Ri),r9r=i(Ri),$ve=n(Ri,"P",{});var w0t=s($ve);t9r=r(w0t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),w0t.forEach(t),a9r=i(Ri),xf=n(Ri,"P",{});var pQ=s(xf);n9r=r(pQ,`Note:
Loading a model from its configuration file does `),Ive=n(pQ,"STRONG",{});var A0t=s(Ive);s9r=r(A0t,"not"),A0t.forEach(t),l9r=r(pQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),jve=n(pQ,"CODE",{});var L0t=s(jve);i9r=r(L0t,"from_pretrained()"),L0t.forEach(t),d9r=r(pQ,"to load the model weights."),pQ.forEach(t),c9r=i(Ri),Dve=n(Ri,"P",{});var B0t=s(Dve);f9r=r(B0t,"Examples:"),B0t.forEach(t),m9r=i(Ri),m(PL.$$.fragment,Ri),Ri.forEach(t),g9r=i(ki),jo=n(ki,"DIV",{class:!0});var ja=s(jo);m($L.$$.fragment,ja),h9r=i(ja),Nve=n(ja,"P",{});var x0t=s(Nve);p9r=r(x0t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),x0t.forEach(t),_9r=i(ja),Nn=n(ja,"P",{});var Q4=s(Nn);u9r=r(Q4,"The model class to instantiate is selected based on the "),qve=n(Q4,"CODE",{});var k0t=s(qve);b9r=r(k0t,"model_type"),k0t.forEach(t),v9r=r(Q4,` property of the config object (either
passed as an argument or loaded from `),Ove=n(Q4,"CODE",{});var R0t=s(Ove);T9r=r(R0t,"pretrained_model_name_or_path"),R0t.forEach(t),F9r=r(Q4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gve=n(Q4,"CODE",{});var S0t=s(Gve);C9r=r(S0t,"pretrained_model_name_or_path"),S0t.forEach(t),M9r=r(Q4,":"),Q4.forEach(t),E9r=i(ja),IL=n(ja,"UL",{});var yPe=s(IL);zM=n(yPe,"LI",{});var fxe=s(zM);Xve=n(fxe,"STRONG",{});var P0t=s(Xve);y9r=r(P0t,"beit"),P0t.forEach(t),w9r=r(fxe," \u2014 "),Mz=n(fxe,"A",{href:!0});var $0t=s(Mz);A9r=r($0t,"FlaxBeitForImageClassification"),$0t.forEach(t),L9r=r(fxe," (BEiT model)"),fxe.forEach(t),B9r=i(yPe),WM=n(yPe,"LI",{});var mxe=s(WM);Vve=n(mxe,"STRONG",{});var I0t=s(Vve);x9r=r(I0t,"vit"),I0t.forEach(t),k9r=r(mxe," \u2014 "),Ez=n(mxe,"A",{href:!0});var j0t=s(Ez);R9r=r(j0t,"FlaxViTForImageClassification"),j0t.forEach(t),S9r=r(mxe," (ViT model)"),mxe.forEach(t),yPe.forEach(t),P9r=i(ja),zve=n(ja,"P",{});var D0t=s(zve);$9r=r(D0t,"Examples:"),D0t.forEach(t),I9r=i(ja),m(jL.$$.fragment,ja),ja.forEach(t),ki.forEach(t),gRe=i(c),kf=n(c,"H2",{class:!0});var wPe=s(kf);QM=n(wPe,"A",{id:!0,class:!0,href:!0});var N0t=s(QM);Wve=n(N0t,"SPAN",{});var q0t=s(Wve);m(DL.$$.fragment,q0t),q0t.forEach(t),N0t.forEach(t),j9r=i(wPe),Qve=n(wPe,"SPAN",{});var O0t=s(Qve);D9r=r(O0t,"FlaxAutoModelForVision2Seq"),O0t.forEach(t),wPe.forEach(t),hRe=i(c),Xr=n(c,"DIV",{class:!0});var Si=s(Xr);m(NL.$$.fragment,Si),N9r=i(Si),Rf=n(Si,"P",{});var _Q=s(Rf);q9r=r(_Q,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Hve=n(_Q,"CODE",{});var G0t=s(Hve);O9r=r(G0t,"from_pretrained()"),G0t.forEach(t),G9r=r(_Q,"class method or the "),Uve=n(_Q,"CODE",{});var X0t=s(Uve);X9r=r(X0t,"from_config()"),X0t.forEach(t),V9r=r(_Q,`class
method.`),_Q.forEach(t),z9r=i(Si),qL=n(Si,"P",{});var APe=s(qL);W9r=r(APe,"This class cannot be instantiated directly using "),Jve=n(APe,"CODE",{});var V0t=s(Jve);Q9r=r(V0t,"__init__()"),V0t.forEach(t),H9r=r(APe," (throws an error)."),APe.forEach(t),U9r=i(Si),jt=n(Si,"DIV",{class:!0});var Pi=s(jt);m(OL.$$.fragment,Pi),J9r=i(Pi),Yve=n(Pi,"P",{});var z0t=s(Yve);Y9r=r(z0t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),z0t.forEach(t),K9r=i(Pi),Sf=n(Pi,"P",{});var uQ=s(Sf);Z9r=r(uQ,`Note:
Loading a model from its configuration file does `),Kve=n(uQ,"STRONG",{});var W0t=s(Kve);eBr=r(W0t,"not"),W0t.forEach(t),oBr=r(uQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zve=n(uQ,"CODE",{});var Q0t=s(Zve);rBr=r(Q0t,"from_pretrained()"),Q0t.forEach(t),tBr=r(uQ,"to load the model weights."),uQ.forEach(t),aBr=i(Pi),e0e=n(Pi,"P",{});var H0t=s(e0e);nBr=r(H0t,"Examples:"),H0t.forEach(t),sBr=i(Pi),m(GL.$$.fragment,Pi),Pi.forEach(t),lBr=i(Si),Do=n(Si,"DIV",{class:!0});var Da=s(Do);m(XL.$$.fragment,Da),iBr=i(Da),o0e=n(Da,"P",{});var U0t=s(o0e);dBr=r(U0t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),U0t.forEach(t),cBr=i(Da),qn=n(Da,"P",{});var H4=s(qn);fBr=r(H4,"The model class to instantiate is selected based on the "),r0e=n(H4,"CODE",{});var J0t=s(r0e);mBr=r(J0t,"model_type"),J0t.forEach(t),gBr=r(H4,` property of the config object (either
passed as an argument or loaded from `),t0e=n(H4,"CODE",{});var Y0t=s(t0e);hBr=r(Y0t,"pretrained_model_name_or_path"),Y0t.forEach(t),pBr=r(H4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=n(H4,"CODE",{});var K0t=s(a0e);_Br=r(K0t,"pretrained_model_name_or_path"),K0t.forEach(t),uBr=r(H4,":"),H4.forEach(t),bBr=i(Da),n0e=n(Da,"UL",{});var Z0t=s(n0e);HM=n(Z0t,"LI",{});var gxe=s(HM);s0e=n(gxe,"STRONG",{});var eTt=s(s0e);vBr=r(eTt,"vision-encoder-decoder"),eTt.forEach(t),TBr=r(gxe," \u2014 "),yz=n(gxe,"A",{href:!0});var oTt=s(yz);FBr=r(oTt,"FlaxVisionEncoderDecoderModel"),oTt.forEach(t),CBr=r(gxe," (Vision Encoder decoder model)"),gxe.forEach(t),Z0t.forEach(t),MBr=i(Da),l0e=n(Da,"P",{});var rTt=s(l0e);EBr=r(rTt,"Examples:"),rTt.forEach(t),yBr=i(Da),m(VL.$$.fragment,Da),Da.forEach(t),Si.forEach(t),this.h()},h(){d(J,"name","hf:doc:metadata"),d(J,"content",JSON.stringify(fTt)),d(ge,"id","auto-classes"),d(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ge,"href","#auto-classes"),d(de,"class","relative group"),d(On,"href","/docs/transformers/pr_15770/en/model_doc/auto#transformers.AutoConfig"),d(Xn,"href","/docs/transformers/pr_15770/en/model_doc/auto#transformers.AutoModel"),d(Vn,"href","/docs/transformers/pr_15770/en/model_doc/auto#transformers.AutoTokenizer"),d(Gi,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertModel"),d(Nf,"id","extending-the-auto-classes"),d(Nf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Nf,"href","#extending-the-auto-classes"),d(Xi,"class","relative group"),d(Of,"id","transformers.AutoConfig"),d(Of,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Of,"href","#transformers.AutoConfig"),d(Vi,"class","relative group"),d(H8,"href","/docs/transformers/pr_15770/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(U8,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertConfig"),d(J8,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartConfig"),d(Y8,"href","/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitConfig"),d(K8,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertConfig"),d(Z8,"href","/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(e9,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdConfig"),d(o9,"href","/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(r9,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(t9,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(a9,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertConfig"),d(n9,"href","/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineConfig"),d(s9,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPConfig"),d(l9,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertConfig"),d(i9,"href","/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextConfig"),d(d9,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLConfig"),d(c9,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(f9,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(m9,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaConfig"),d(g9,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(h9,"href","/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTConfig"),d(p9,"href","/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrConfig"),d(_9,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertConfig"),d(u9,"href","/docs/transformers/pr_15770/en/model_doc/dpr#transformers.DPRConfig"),d(b9,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraConfig"),d(v9,"href","/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(T9,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertConfig"),d(F9,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetConfig"),d(C9,"href","/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTConfig"),d(M9,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelConfig"),d(E9,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Config"),d(y9,"href","/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(w9,"href","/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJConfig"),d(A9,"href","/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertConfig"),d(L9,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertConfig"),d(B9,"href","/docs/transformers/pr_15770/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(x9,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(k9,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(R9,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDConfig"),d(S9,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerConfig"),d(P9,"href","/docs/transformers/pr_15770/en/model_doc/luke#transformers.LukeConfig"),d($9,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertConfig"),d(I9,"href","/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100Config"),d(j9,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianConfig"),d(D9,"href","/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(N9,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartConfig"),d(q9,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(O9,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(G9,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetConfig"),d(X9,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Config"),d(V9,"href","/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(z9,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(W9,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusConfig"),d(Q9,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverConfig"),d(H9,"href","/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartConfig"),d(U9,"href","/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(J9,"href","/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(Y9,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(K9,"href","/docs/transformers/pr_15770/en/model_doc/rag#transformers.RagConfig"),d(Z9,"href","/docs/transformers/pr_15770/en/model_doc/realm#transformers.RealmConfig"),d(eB,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerConfig"),d(oB,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertConfig"),d(rB,"href","/docs/transformers/pr_15770/en/model_doc/resnet#transformers.ResNetConfig"),d(tB,"href","/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertConfig"),d(aB,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaConfig"),d(nB,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerConfig"),d(sB,"href","/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerConfig"),d(lB,"href","/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWConfig"),d(iB,"href","/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDConfig"),d(dB,"href","/docs/transformers/pr_15770/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(cB,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(fB,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(mB,"href","/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterConfig"),d(gB,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(hB,"href","/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinConfig"),d(pB,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Config"),d(_B,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasConfig"),d(uB,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(bB,"href","/docs/transformers/pr_15770/en/model_doc/trocr#transformers.TrOCRConfig"),d(vB,"href","/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(TB,"href","/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(FB,"href","/docs/transformers/pr_15770/en/model_doc/vilt#transformers.ViltConfig"),d(CB,"href","/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(MB,"href","/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(EB,"href","/docs/transformers/pr_15770/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(yB,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTConfig"),d(wB,"href","/docs/transformers/pr_15770/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(AB,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(LB,"href","/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMConfig"),d(BB,"href","/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMConfig"),d(xB,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMConfig"),d(kB,"href","/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(RB,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(SB,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(PB,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetConfig"),d($B,"href","/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoConfig"),d(mo,"class","docstring"),d(Bg,"class","docstring"),d(Wo,"class","docstring"),d(xg,"id","transformers.AutoTokenizer"),d(xg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xg,"href","#transformers.AutoTokenizer"),d(Wi,"class","relative group"),d(IB,"href","/docs/transformers/pr_15770/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(jB,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertTokenizer"),d(DB,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(NB,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartTokenizer"),d(qB,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartTokenizerFast"),d(OB,"href","/docs/transformers/pr_15770/en/model_doc/barthez#transformers.BarthezTokenizer"),d(GB,"href","/docs/transformers/pr_15770/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(XB,"href","/docs/transformers/pr_15770/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(VB,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertTokenizer"),d(zB,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertTokenizerFast"),d(WB,"href","/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(QB,"href","/docs/transformers/pr_15770/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(HB,"href","/docs/transformers/pr_15770/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(UB,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(JB,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(YB,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(KB,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(ZB,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(ex,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(ox,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(rx,"href","/docs/transformers/pr_15770/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(tx,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertTokenizer"),d(ax,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(nx,"href","/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineTokenizer"),d(sx,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPTokenizer"),d(lx,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(ix,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(dx,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(cx,"href","/docs/transformers/pr_15770/en/model_doc/cpm#transformers.CpmTokenizer"),d(fx,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(mx,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaTokenizer"),d(gx,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(hx,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(px,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(_x,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(ux,"href","/docs/transformers/pr_15770/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(bx,"href","/docs/transformers/pr_15770/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(vx,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraTokenizer"),d(Tx,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(Fx,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(Cx,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetTokenizer"),d(Mx,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(Ex,"href","/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(yx,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelTokenizer"),d(wx,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(Ax,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(Lx,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(Bx,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(xx,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(kx,"href","/docs/transformers/pr_15770/en/model_doc/herbert#transformers.HerbertTokenizer"),d(Rx,"href","/docs/transformers/pr_15770/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(Sx,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(Px,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaTokenizer"),d($x,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(Ix,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(jx,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(Dx,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(Nx,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(qx,"href","/docs/transformers/pr_15770/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(Ox,"href","/docs/transformers/pr_15770/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(Gx,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDTokenizer"),d(Xx,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDTokenizerFast"),d(Vx,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerTokenizer"),d(zx,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(Wx,"href","/docs/transformers/pr_15770/en/model_doc/luke#transformers.LukeTokenizer"),d(Qx,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(Hx,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(Ux,"href","/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(Jx,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianTokenizer"),d(Yx,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartTokenizer"),d(Kx,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(Zx,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(ek,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(ok,"href","/docs/transformers/pr_15770/en/model_doc/mluke#transformers.MLukeTokenizer"),d(rk,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(tk,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(ak,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(nk,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(sk,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.T5Tokenizer"),d(lk,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.T5TokenizerFast"),d(ik,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(dk,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(ck,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(fk,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(mk,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(gk,"href","/docs/transformers/pr_15770/en/model_doc/phobert#transformers.PhobertTokenizer"),d(hk,"href","/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartTokenizer"),d(pk,"href","/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(_k,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertTokenizer"),d(uk,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertTokenizerFast"),d(bk,"href","/docs/transformers/pr_15770/en/model_doc/rag#transformers.RagTokenizer"),d(vk,"href","/docs/transformers/pr_15770/en/model_doc/realm#transformers.RealmTokenizer"),d(Tk,"href","/docs/transformers/pr_15770/en/model_doc/realm#transformers.RealmTokenizerFast"),d(Fk,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerTokenizer"),d(Ck,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(Mk,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertTokenizer"),d(Ek,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(yk,"href","/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(wk,"href","/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(Ak,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaTokenizer"),d(Lk,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(Bk,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(xk,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(kk,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(Rk,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(Sk,"href","/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterTokenizer"),d(Pk,"href","/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d($k,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(Ik,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(jk,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.T5Tokenizer"),d(Dk,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.T5TokenizerFast"),d(Nk,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasTokenizer"),d(qk,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(Ok,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(Gk,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(Xk,"href","/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMTokenizer"),d(Vk,"href","/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(zk,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMTokenizer"),d(Wk,"href","/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(Qk,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(Hk,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(Uk,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(Jk,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(go,"class","docstring"),d(sh,"class","docstring"),d(Qo,"class","docstring"),d(lh,"id","transformers.AutoFeatureExtractor"),d(lh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(lh,"href","#transformers.AutoFeatureExtractor"),d(Qi,"class","relative group"),d(Yk,"href","/docs/transformers/pr_15770/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(Kk,"href","/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(Zk,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(eR,"href","/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(oR,"href","/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTFeatureExtractor"),d(rR,"href","/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(tR,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(aR,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),d(nR,"href","/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(sR,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),d(lR,"href","/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),d(iR,"href","/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(dR,"href","/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),d(cR,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(fR,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(mR,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(gR,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(hR,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(Ie,"class","docstring"),d(wh,"class","docstring"),d(Ho,"class","docstring"),d(Ah,"id","transformers.AutoProcessor"),d(Ah,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ah,"href","#transformers.AutoProcessor"),d(Hi,"class","relative group"),d(pR,"href","/docs/transformers/pr_15770/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(_R,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPProcessor"),d(uR,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(bR,"href","/docs/transformers/pr_15770/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(vR,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(TR,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(FR,"href","/docs/transformers/pr_15770/en/model_doc/trocr#transformers.TrOCRProcessor"),d(CR,"href","/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(MR,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(je,"class","docstring"),d(jh,"class","docstring"),d(Uo,"class","docstring"),d(Dh,"id","transformers.AutoModel"),d(Dh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Dh,"href","#transformers.AutoModel"),d(Ji,"class","relative group"),d(Vr,"class","docstring"),d(ER,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertModel"),d(yR,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartModel"),d(wR,"href","/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitModel"),d(AR,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertModel"),d(LR,"href","/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(BR,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdModel"),d(xR,"href","/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(kR,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(RR,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(SR,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertModel"),d(PR,"href","/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineModel"),d($R,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.CLIPModel"),d(IR,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertModel"),d(jR,"href","/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextModel"),d(DR,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLModel"),d(NR,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(qR,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(OR,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaModel"),d(GR,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(XR,"href","/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTModel"),d(VR,"href","/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrModel"),d(zR,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertModel"),d(WR,"href","/docs/transformers/pr_15770/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(QR,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraModel"),d(HR,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertModel"),d(UR,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetModel"),d(JR,"href","/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTModel"),d(YR,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelModel"),d(KR,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelBaseModel"),d(ZR,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2Model"),d(eS,"href","/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(oS,"href","/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJModel"),d(rS,"href","/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertModel"),d(tS,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertModel"),d(aS,"href","/docs/transformers/pr_15770/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(nS,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(sS,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(lS,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDModel"),d(iS,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerModel"),d(dS,"href","/docs/transformers/pr_15770/en/model_doc/luke#transformers.LukeModel"),d(cS,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertModel"),d(fS,"href","/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100Model"),d(mS,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianModel"),d(gS,"href","/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerModel"),d(hS,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartModel"),d(pS,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(_S,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertModel"),d(uS,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetModel"),d(bS,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5Model"),d(vS,"href","/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerModel"),d(TS,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(FS,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusModel"),d(CS,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverModel"),d(MS,"href","/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartModel"),d(ES,"href","/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerModel"),d(yS,"href","/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(wS,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertModel"),d(AS,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerModel"),d(LS,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertModel"),d(BS,"href","/docs/transformers/pr_15770/en/model_doc/resnet#transformers.ResNetModel"),d(xS,"href","/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertModel"),d(kS,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaModel"),d(RS,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerModel"),d(SS,"href","/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerModel"),d(PS,"href","/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWModel"),d($S,"href","/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDModel"),d(IS,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(jS,"href","/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterModel"),d(DS,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(NS,"href","/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinModel"),d(qS,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5Model"),d(OS,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasModel"),d(GS,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(XS,"href","/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechModel"),d(VS,"href","/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(zS,"href","/docs/transformers/pr_15770/en/model_doc/vilt#transformers.ViltModel"),d(WS,"href","/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(QS,"href","/docs/transformers/pr_15770/en/model_doc/visual_bert#transformers.VisualBertModel"),d(HS,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTModel"),d(US,"href","/docs/transformers/pr_15770/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(JS,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(YS,"href","/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMModel"),d(KS,"href","/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMModel"),d(ZS,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMModel"),d(eP,"href","/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(oP,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(rP,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(tP,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetModel"),d(aP,"href","/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoModel"),d(De,"class","docstring"),d(Jo,"class","docstring"),d(v_,"id","transformers.AutoModelForPreTraining"),d(v_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(v_,"href","#transformers.AutoModelForPreTraining"),d(Zi,"class","relative group"),d(zr,"class","docstring"),d(nP,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForPreTraining"),d(sP,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(lP,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForPreTraining"),d(iP,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(dP,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(cP,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(fP,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(mP,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(gP,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(hP,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(pP,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForPreTraining"),d(_P,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(uP,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForPreTraining"),d(bP,"href","/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(vP,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(TP,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(FP,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(CP,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(MP,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(EP,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(yP,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(wP,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(AP,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(LP,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(BP,"href","/docs/transformers/pr_15770/en/model_doc/retribert#transformers.RetriBertModel"),d(xP,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(kP,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(RP,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(SP,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(PP,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d($P,"href","/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(IP,"href","/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(jP,"href","/docs/transformers/pr_15770/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(DP,"href","/docs/transformers/pr_15770/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(NP,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(qP,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(OP,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(GP,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(XP,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(Ne,"class","docstring"),d(Yo,"class","docstring"),d(su,"id","transformers.AutoModelForCausalLM"),d(su,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(su,"href","#transformers.AutoModelForCausalLM"),d(rd,"class","relative group"),d(Wr,"class","docstring"),d(VP,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForCausalLM"),d(zP,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertLMHeadModel"),d(WP,"href","/docs/transformers/pr_15770/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(QP,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(HP,"href","/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(UP,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(JP,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(YP,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(KP,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(ZP,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(e$,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForCausalLM"),d(o$,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(r$,"href","/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(t$,"href","/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(a$,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianForCausalLM"),d(n$,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForCausalLM"),d(s$,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(l$,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(i$,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(d$,"href","/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(c$,"href","/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(f$,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(m$,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(g$,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(h$,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(p$,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(_$,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(u$,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(b$,"href","/docs/transformers/pr_15770/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(v$,"href","/docs/transformers/pr_15770/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(T$,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(F$,"href","/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(C$,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(M$,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(E$,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(qe,"class","docstring"),d(Ko,"class","docstring"),d(Xu,"id","transformers.AutoModelForMaskedLM"),d(Xu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Xu,"href","#transformers.AutoModelForMaskedLM"),d(nd,"class","relative group"),d(Qr,"class","docstring"),d(y$,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(w$,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(A$,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForMaskedLM"),d(L$,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(B$,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(x$,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(k$,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(R$,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(S$,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(P$,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d($$,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(I$,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(j$,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(D$,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(N$,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(q$,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(O$,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(G$,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(X$,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(V$,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(z$,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(W$,"href","/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(Q$,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(H$,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(U$,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(J$,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(Y$,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(K$,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(Z$,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(eI,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(oI,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(rI,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(tI,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(aI,"href","/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(Oe,"class","docstring"),d(Zo,"class","docstring"),d(w1,"id","transformers.AutoModelForSeq2SeqLM"),d(w1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w1,"href","#transformers.AutoModelForSeq2SeqLM"),d(id,"class","relative group"),d(Hr,"class","docstring"),d(nI,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(sI,"href","/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(lI,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(iI,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(dI,"href","/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(cI,"href","/docs/transformers/pr_15770/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(fI,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(mI,"href","/docs/transformers/pr_15770/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(gI,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.MarianMTModel"),d(hI,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(pI,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(_I,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(uI,"href","/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(bI,"href","/docs/transformers/pr_15770/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(vI,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(TI,"href","/docs/transformers/pr_15770/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(Ge,"class","docstring"),d(er,"class","docstring"),d(V1,"id","transformers.AutoModelForSequenceClassification"),d(V1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(V1,"href","#transformers.AutoModelForSequenceClassification"),d(fd,"class","relative group"),d(Ur,"class","docstring"),d(FI,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(CI,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForSequenceClassification"),d(MI,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForSequenceClassification"),d(EI,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(yI,"href","/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(wI,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(AI,"href","/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(LI,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(BI,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(xI,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(kI,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(RI,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(SI,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(PI,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d($I,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(II,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(jI,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(DI,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(NI,"href","/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(qI,"href","/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(OI,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(GI,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(XI,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(VI,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDForSequenceClassification"),d(zI,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(WI,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(QI,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(HI,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(UI,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(JI,"href","/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(YI,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(KI,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(ZI,"href","/docs/transformers/pr_15770/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(ej,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(oj,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(rj,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(tj,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(aj,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(nj,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(sj,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(lj,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(ij,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(dj,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(cj,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(fj,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(mj,"href","/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(Xe,"class","docstring"),d(or,"class","docstring"),d(D7,"id","transformers.AutoModelForMultipleChoice"),d(D7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D7,"href","#transformers.AutoModelForMultipleChoice"),d(hd,"class","relative group"),d(Jr,"class","docstring"),d(gj,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(hj,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForMultipleChoice"),d(pj,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(_j,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(uj,"href","/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(bj,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(vj,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(Tj,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(Fj,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(Cj,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(Mj,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(Ej,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(yj,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(wj,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(Aj,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(Lj,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(Bj,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(xj,"href","/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(kj,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(Rj,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(Sj,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(Pj,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d($j,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(Ij,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(jj,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(Dj,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(Nj,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(qj,"href","/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(Ve,"class","docstring"),d(rr,"class","docstring"),d(hb,"id","transformers.AutoModelForNextSentencePrediction"),d(hb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(hb,"href","#transformers.AutoModelForNextSentencePrediction"),d(ud,"class","relative group"),d(Yr,"class","docstring"),d(Oj,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(Gj,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(Xj,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(Vj,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(zj,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(ze,"class","docstring"),d(tr,"class","docstring"),d(Fb,"id","transformers.AutoModelForTokenClassification"),d(Fb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Fb,"href","#transformers.AutoModelForTokenClassification"),d(Td,"class","relative group"),d(Kr,"class","docstring"),d(Wj,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(Qj,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForTokenClassification"),d(Hj,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(Uj,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(Jj,"href","/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForTokenClassification"),d(Yj,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(Kj,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(Zj,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(eD,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(oD,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(rD,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(tD,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(aD,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(nD,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(sD,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(lD,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(iD,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(dD,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(cD,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(fD,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(mD,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(gD,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(hD,"href","/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(pD,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(_D,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(uD,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(bD,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(vD,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(TD,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(FD,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(CD,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(MD,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(ED,"href","/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(We,"class","docstring"),d(ar,"class","docstring"),d(r5,"id","transformers.AutoModelForQuestionAnswering"),d(r5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(r5,"href","#transformers.AutoModelForQuestionAnswering"),d(Md,"class","relative group"),d(Zr,"class","docstring"),d(yD,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(wD,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(AD,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(LD,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(BD,"href","/docs/transformers/pr_15770/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(xD,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(kD,"href","/docs/transformers/pr_15770/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(RD,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(SD,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(PD,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d($D,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(ID,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(jD,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(DD,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(ND,"href","/docs/transformers/pr_15770/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(qD,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(OD,"href","/docs/transformers/pr_15770/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(GD,"href","/docs/transformers/pr_15770/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(XD,"href","/docs/transformers/pr_15770/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(VD,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(zD,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(WD,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(QD,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(HD,"href","/docs/transformers/pr_15770/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(UD,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(JD,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(YD,"href","/docs/transformers/pr_15770/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(KD,"href","/docs/transformers/pr_15770/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(ZD,"href","/docs/transformers/pr_15770/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(eN,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(oN,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(rN,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(tN,"href","/docs/transformers/pr_15770/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(aN,"href","/docs/transformers/pr_15770/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(nN,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(sN,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(lN,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(iN,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(dN,"href","/docs/transformers/pr_15770/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(Qe,"class","docstring"),d(nr,"class","docstring"),d(X5,"id","transformers.AutoModelForTableQuestionAnswering"),d(X5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X5,"href","#transformers.AutoModelForTableQuestionAnswering"),d(wd,"class","relative group"),d(et,"class","docstring"),d(cN,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(He,"class","docstring"),d(sr,"class","docstring"),d(W5,"id","transformers.AutoModelForImageClassification"),d(W5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W5,"href","#transformers.AutoModelForImageClassification"),d(Bd,"class","relative group"),d(ot,"class","docstring"),d(fN,"href","/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitForImageClassification"),d(mN,"href","/docs/transformers/pr_15770/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(gN,"href","/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTForImageClassification"),d(hN,"href","/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(pN,"href","/docs/transformers/pr_15770/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(_N,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(uN,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(bN,"href","/docs/transformers/pr_15770/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(vN,"href","/docs/transformers/pr_15770/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(TN,"href","/docs/transformers/pr_15770/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(FN,"href","/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(CN,"href","/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinForImageClassification"),d(MN,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTForImageClassification"),d(Ue,"class","docstring"),d(lr,"class","docstring"),d(r2,"id","transformers.AutoModelForVision2Seq"),d(r2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(r2,"href","#transformers.AutoModelForVision2Seq"),d(Rd,"class","relative group"),d(rt,"class","docstring"),d(EN,"href","/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(Je,"class","docstring"),d(ir,"class","docstring"),d(n2,"id","transformers.AutoModelForAudioClassification"),d(n2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n2,"href","#transformers.AutoModelForAudioClassification"),d($d,"class","relative group"),d(tt,"class","docstring"),d(yN,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(wN,"href","/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(AN,"href","/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(LN,"href","/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(BN,"href","/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(xN,"href","/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(kN,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(RN,"href","/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(Ye,"class","docstring"),d(dr,"class","docstring"),d(p2,"id","transformers.AutoModelForAudioFrameClassification"),d(p2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p2,"href","#transformers.AutoModelForAudioFrameClassification"),d(Dd,"class","relative group"),d(at,"class","docstring"),d(SN,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(PN,"href","/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d($N,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(IN,"href","/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(Ke,"class","docstring"),d(cr,"class","docstring"),d(F2,"id","transformers.AutoModelForCTC"),d(F2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(F2,"href","#transformers.AutoModelForCTC"),d(Od,"class","relative group"),d(nt,"class","docstring"),d(jN,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(DN,"href","/docs/transformers/pr_15770/en/model_doc/hubert#transformers.HubertForCTC"),d(NN,"href","/docs/transformers/pr_15770/en/model_doc/sew#transformers.SEWForCTC"),d(qN,"href","/docs/transformers/pr_15770/en/model_doc/sew-d#transformers.SEWDForCTC"),d(ON,"href","/docs/transformers/pr_15770/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(GN,"href","/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(XN,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(VN,"href","/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForCTC"),d(Ze,"class","docstring"),d(fr,"class","docstring"),d(k2,"id","transformers.AutoModelForSpeechSeq2Seq"),d(k2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(k2,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Vd,"class","relative group"),d(st,"class","docstring"),d(zN,"href","/docs/transformers/pr_15770/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(WN,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(eo,"class","docstring"),d(mr,"class","docstring"),d($2,"id","transformers.AutoModelForAudioXVector"),d($2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($2,"href","#transformers.AutoModelForAudioXVector"),d(Qd,"class","relative group"),d(lt,"class","docstring"),d(QN,"href","/docs/transformers/pr_15770/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(HN,"href","/docs/transformers/pr_15770/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(UN,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(JN,"href","/docs/transformers/pr_15770/en/model_doc/wavlm#transformers.WavLMForXVector"),d(oo,"class","docstring"),d(gr,"class","docstring"),d(O2,"id","transformers.AutoModelForMaskedImageModeling"),d(O2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(O2,"href","#transformers.AutoModelForMaskedImageModeling"),d(Jd,"class","relative group"),d(it,"class","docstring"),d(YN,"href","/docs/transformers/pr_15770/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(KN,"href","/docs/transformers/pr_15770/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(ZN,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(ro,"class","docstring"),d(hr,"class","docstring"),d(W2,"id","transformers.AutoModelForObjectDetection"),d(W2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W2,"href","#transformers.AutoModelForObjectDetection"),d(ec,"class","relative group"),d(dt,"class","docstring"),d(eq,"href","/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrForObjectDetection"),d(to,"class","docstring"),d(pr,"class","docstring"),d(U2,"id","transformers.AutoModelForImageSegmentation"),d(U2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U2,"href","#transformers.AutoModelForImageSegmentation"),d(tc,"class","relative group"),d(ct,"class","docstring"),d(oq,"href","/docs/transformers/pr_15770/en/model_doc/detr#transformers.DetrForSegmentation"),d(ao,"class","docstring"),d(_r,"class","docstring"),d(K2,"id","transformers.AutoModelForSemanticSegmentation"),d(K2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K2,"href","#transformers.AutoModelForSemanticSegmentation"),d(sc,"class","relative group"),d(ft,"class","docstring"),d(rq,"href","/docs/transformers/pr_15770/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(tq,"href","/docs/transformers/pr_15770/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(no,"class","docstring"),d(ur,"class","docstring"),d(rv,"id","transformers.AutoModelForInstanceSegmentation"),d(rv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(rv,"href","#transformers.AutoModelForInstanceSegmentation"),d(dc,"class","relative group"),d(mt,"class","docstring"),d(aq,"href","/docs/transformers/pr_15770/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d(so,"class","docstring"),d(br,"class","docstring"),d(nv,"id","transformers.TFAutoModel"),d(nv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(nv,"href","#transformers.TFAutoModel"),d(mc,"class","relative group"),d(gt,"class","docstring"),d(nq,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertModel"),d(sq,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.TFBartModel"),d(lq,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertModel"),d(iq,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(dq,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(cq,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertModel"),d(fq,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.TFCLIPModel"),d(mq,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertModel"),d(gq,"href","/docs/transformers/pr_15770/en/model_doc/convnext#transformers.TFConvNextModel"),d(hq,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLModel"),d(pq,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaModel"),d(_q,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(uq,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(bq,"href","/docs/transformers/pr_15770/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(vq,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraModel"),d(Tq,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(Fq,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelModel"),d(Cq,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(Mq,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2Model"),d(Eq,"href","/docs/transformers/pr_15770/en/model_doc/hubert#transformers.TFHubertModel"),d(yq,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(wq,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.TFLEDModel"),d(Aq,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerModel"),d(Lq,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.TFLxmertModel"),d(Bq,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.TFMarianModel"),d(xq,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.TFMBartModel"),d(kq,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(Rq,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetModel"),d(Sq,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.TFMT5Model"),d(Pq,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d($q,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.TFPegasusModel"),d(Iq,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertModel"),d(jq,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaModel"),d(Dq,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerModel"),d(Nq,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(qq,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.TFT5Model"),d(Oq,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasModel"),d(Gq,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(Xq,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.TFViTModel"),d(Vq,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(zq,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMModel"),d(Wq,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(Qq,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetModel"),d(ho,"class","docstring"),d(vr,"class","docstring"),d(Qv,"id","transformers.TFAutoModelForPreTraining"),d(Qv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Qv,"href","#transformers.TFAutoModelForPreTraining"),d(pc,"class","relative group"),d(ht,"class","docstring"),d(Hq,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(Uq,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(Jq,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForPreTraining"),d(Yq,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Kq,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Zq,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(eO,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(oO,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(rO,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(tO,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(aO,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(nO,"href","/docs/transformers/pr_15770/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(sO,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(lO,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(iO,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(dO,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(cO,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(fO,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(mO,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(gO,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(hO,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(pO,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(po,"class","docstring"),d(Tr,"class","docstring"),d(_0,"id","transformers.TFAutoModelForCausalLM"),d(_0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_0,"href","#transformers.TFAutoModelForCausalLM"),d(bc,"class","relative group"),d(pt,"class","docstring"),d(_O,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(uO,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(bO,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(vO,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(TO,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(FO,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(CO,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(MO,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(EO,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(yO,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(_o,"class","docstring"),d(Fr,"class","docstring"),d(A0,"id","transformers.TFAutoModelForImageClassification"),d(A0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A0,"href","#transformers.TFAutoModelForImageClassification"),d(Fc,"class","relative group"),d(_t,"class","docstring"),d(wO,"href","/docs/transformers/pr_15770/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(AO,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.TFViTForImageClassification"),d(uo,"class","docstring"),d(Cr,"class","docstring"),d(x0,"id","transformers.TFAutoModelForMaskedLM"),d(x0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(x0,"href","#transformers.TFAutoModelForMaskedLM"),d(Ec,"class","relative group"),d(ut,"class","docstring"),d(LO,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(BO,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(xO,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(kO,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(RO,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(SO,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(PO,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d($O,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(IO,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(jO,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(DO,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(NO,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(qO,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(OO,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(GO,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(XO,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(VO,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(zO,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(WO,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(QO,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(bo,"class","docstring"),d(Mr,"class","docstring"),d(Y0,"id","transformers.TFAutoModelForSeq2SeqLM"),d(Y0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Y0,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(Ac,"class","relative group"),d(bt,"class","docstring"),d(HO,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(UO,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(JO,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(YO,"href","/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(KO,"href","/docs/transformers/pr_15770/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(ZO,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.TFMarianMTModel"),d(eG,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(oG,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(rG,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(tG,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(vo,"class","docstring"),d(Er,"class","docstring"),d(iT,"id","transformers.TFAutoModelForSequenceClassification"),d(iT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(iT,"href","#transformers.TFAutoModelForSequenceClassification"),d(xc,"class","relative group"),d(vt,"class","docstring"),d(aG,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(nG,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(sG,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(lG,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(iG,"href","/docs/transformers/pr_15770/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(dG,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(cG,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(fG,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(mG,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(gG,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(hG,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(pG,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(_G,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(uG,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(bG,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(vG,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(TG,"href","/docs/transformers/pr_15770/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(FG,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(CG,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(MG,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(EG,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(yG,"href","/docs/transformers/pr_15770/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(wG,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(AG,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(LG,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(To,"class","docstring"),d(yr,"class","docstring"),d(PT,"id","transformers.TFAutoModelForMultipleChoice"),d(PT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(PT,"href","#transformers.TFAutoModelForMultipleChoice"),d(Sc,"class","relative group"),d(Tt,"class","docstring"),d(BG,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(xG,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(kG,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(RG,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(SG,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(PG,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d($G,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(IG,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(jG,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(DG,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(NG,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(qG,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(OG,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(GG,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(XG,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(VG,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(zG,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Fo,"class","docstring"),d(wr,"class","docstring"),d(KT,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(KT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(KT,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Ic,"class","relative group"),d(Ft,"class","docstring"),d(WG,"href","/docs/transformers/pr_15770/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(Co,"class","docstring"),d(Ar,"class","docstring"),d(eF,"id","transformers.TFAutoModelForTokenClassification"),d(eF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(eF,"href","#transformers.TFAutoModelForTokenClassification"),d(Nc,"class","relative group"),d(Ct,"class","docstring"),d(QG,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(HG,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(UG,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(JG,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(YG,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(KG,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(ZG,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(eX,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(oX,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(rX,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(tX,"href","/docs/transformers/pr_15770/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(aX,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(nX,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(sX,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(lX,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(iX,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(dX,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(cX,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(fX,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(mX,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(Mo,"class","docstring"),d(Lr,"class","docstring"),d(FF,"id","transformers.TFAutoModelForQuestionAnswering"),d(FF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(FF,"href","#transformers.TFAutoModelForQuestionAnswering"),d(Gc,"class","relative group"),d(Mt,"class","docstring"),d(gX,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(hX,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(pX,"href","/docs/transformers/pr_15770/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(_X,"href","/docs/transformers/pr_15770/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(uX,"href","/docs/transformers/pr_15770/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(bX,"href","/docs/transformers/pr_15770/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(vX,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(TX,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(FX,"href","/docs/transformers/pr_15770/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(CX,"href","/docs/transformers/pr_15770/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(MX,"href","/docs/transformers/pr_15770/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(EX,"href","/docs/transformers/pr_15770/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(yX,"href","/docs/transformers/pr_15770/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(wX,"href","/docs/transformers/pr_15770/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(AX,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(LX,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(BX,"href","/docs/transformers/pr_15770/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(xX,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(kX,"href","/docs/transformers/pr_15770/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(Eo,"class","docstring"),d(Br,"class","docstring"),d(OF,"id","transformers.TFAutoModelForVision2Seq"),d(OF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(OF,"href","#transformers.TFAutoModelForVision2Seq"),d(zc,"class","relative group"),d(Et,"class","docstring"),d(RX,"href","/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(yo,"class","docstring"),d(xr,"class","docstring"),d(XF,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(XF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(XF,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(Hc,"class","relative group"),d(yt,"class","docstring"),d(SX,"href","/docs/transformers/pr_15770/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(wo,"class","docstring"),d(kr,"class","docstring"),d(zF,"id","transformers.FlaxAutoModel"),d(zF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(zF,"href","#transformers.FlaxAutoModel"),d(Yc,"class","relative group"),d(wt,"class","docstring"),d(PX,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertModel"),d($X,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartModel"),d(IX,"href","/docs/transformers/pr_15770/en/model_doc/beit#transformers.FlaxBeitModel"),d(jX,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertModel"),d(DX,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(NX,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(qX,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(OX,"href","/docs/transformers/pr_15770/en/model_doc/clip#transformers.FlaxCLIPModel"),d(GX,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(XX,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraModel"),d(VX,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(zX,"href","/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(WX,"href","/docs/transformers/pr_15770/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(QX,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.FlaxMarianModel"),d(HX,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartModel"),d(UX,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.FlaxMT5Model"),d(JX,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(YX,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(KX,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(ZX,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.FlaxT5Model"),d(eV,"href","/docs/transformers/pr_15770/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(oV,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.FlaxViTModel"),d(rV,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(tV,"href","/docs/transformers/pr_15770/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(aV,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(Ao,"class","docstring"),d(Rr,"class","docstring"),d(uC,"id","transformers.FlaxAutoModelForCausalLM"),d(uC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(uC,"href","#transformers.FlaxAutoModelForCausalLM"),d(ef,"class","relative group"),d(At,"class","docstring"),d(nV,"href","/docs/transformers/pr_15770/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(sV,"href","/docs/transformers/pr_15770/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(lV,"href","/docs/transformers/pr_15770/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(iV,"href","/docs/transformers/pr_15770/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(Lo,"class","docstring"),d(Sr,"class","docstring"),d(CC,"id","transformers.FlaxAutoModelForPreTraining"),d(CC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(CC,"href","#transformers.FlaxAutoModelForPreTraining"),d(tf,"class","relative group"),d(Lt,"class","docstring"),d(dV,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(cV,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(fV,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(mV,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(gV,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(hV,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(pV,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(_V,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(uV,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(bV,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(vV,"href","/docs/transformers/pr_15770/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(TV,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(Bo,"class","docstring"),d(Pr,"class","docstring"),d($C,"id","transformers.FlaxAutoModelForMaskedLM"),d($C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($C,"href","#transformers.FlaxAutoModelForMaskedLM"),d(sf,"class","relative group"),d(Bt,"class","docstring"),d(FV,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(CV,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(MV,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(EV,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(yV,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(wV,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(AV,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(LV,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(BV,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(xV,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(xo,"class","docstring"),d($r,"class","docstring"),d(WC,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(WC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(WC,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(cf,"class","relative group"),d(xt,"class","docstring"),d(kV,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(RV,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(SV,"href","/docs/transformers/pr_15770/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(PV,"href","/docs/transformers/pr_15770/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d($V,"href","/docs/transformers/pr_15770/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(IV,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(jV,"href","/docs/transformers/pr_15770/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(DV,"href","/docs/transformers/pr_15770/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(NV,"href","/docs/transformers/pr_15770/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(ko,"class","docstring"),d(Ir,"class","docstring"),d(rM,"id","transformers.FlaxAutoModelForSequenceClassification"),d(rM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(rM,"href","#transformers.FlaxAutoModelForSequenceClassification"),d(gf,"class","relative group"),d(kt,"class","docstring"),d(qV,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(OV,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(GV,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(XV,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(VV,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(zV,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(WV,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(QV,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(HV,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(UV,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(Ro,"class","docstring"),d(jr,"class","docstring"),d(gM,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(gM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(gM,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(_f,"class","relative group"),d(Rt,"class","docstring"),d(JV,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(YV,"href","/docs/transformers/pr_15770/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(KV,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(ZV,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(ez,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(oz,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(rz,"href","/docs/transformers/pr_15770/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(tz,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(az,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(nz,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(So,"class","docstring"),d(Dr,"class","docstring"),d(EM,"id","transformers.FlaxAutoModelForTokenClassification"),d(EM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(EM,"href","#transformers.FlaxAutoModelForTokenClassification"),d(vf,"class","relative group"),d(St,"class","docstring"),d(sz,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(lz,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(iz,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(dz,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(cz,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(fz,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(mz,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(gz,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(Po,"class","docstring"),d(Nr,"class","docstring"),d(SM,"id","transformers.FlaxAutoModelForMultipleChoice"),d(SM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(SM,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(Cf,"class","relative group"),d(Pt,"class","docstring"),d(hz,"href","/docs/transformers/pr_15770/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(pz,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(_z,"href","/docs/transformers/pr_15770/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(uz,"href","/docs/transformers/pr_15770/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(bz,"href","/docs/transformers/pr_15770/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(vz,"href","/docs/transformers/pr_15770/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(Tz,"href","/docs/transformers/pr_15770/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(Fz,"href","/docs/transformers/pr_15770/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d($o,"class","docstring"),d(qr,"class","docstring"),d(GM,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(GM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(GM,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(yf,"class","relative group"),d($t,"class","docstring"),d(Cz,"href","/docs/transformers/pr_15770/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(Io,"class","docstring"),d(Or,"class","docstring"),d(VM,"id","transformers.FlaxAutoModelForImageClassification"),d(VM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(VM,"href","#transformers.FlaxAutoModelForImageClassification"),d(Lf,"class","relative group"),d(It,"class","docstring"),d(Mz,"href","/docs/transformers/pr_15770/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(Ez,"href","/docs/transformers/pr_15770/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(jo,"class","docstring"),d(Gr,"class","docstring"),d(QM,"id","transformers.FlaxAutoModelForVision2Seq"),d(QM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(QM,"href","#transformers.FlaxAutoModelForVision2Seq"),d(kf,"class","relative group"),d(jt,"class","docstring"),d(yz,"href","/docs/transformers/pr_15770/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(Do,"class","docstring"),d(Xr,"class","docstring")},m(c,u){e(document.head,J),b(c,$e,u),b(c,de,u),e(de,ge),e(ge,io),g(fe,io,null),e(de,Fe),e(de,Vo),e(Vo,Ii),b(c,$f,u),b(c,ca,u),e(ca,ji),e(ca,Di),e(Di,U4),e(ca,If),b(c,Be,u),b(c,co,u),e(co,Ni),e(co,On),e(On,J4),e(co,Gn),e(co,Xn),e(Xn,Y4),e(co,qi),e(co,Vn),e(Vn,K4),e(co,Oi),b(c,jf,u),g(Na,c,u),b(c,fo,u),b(c,he,u),e(he,G8),e(he,Gi),e(Gi,X8),e(he,V8),b(c,zo,u),b(c,qa,u),e(qa,z8),e(qa,Df),e(Df,W8),e(qa,LPe),b(c,hxe,u),b(c,Xi,u),e(Xi,Nf),e(Nf,bQ),g(Z4,bQ,null),e(Xi,BPe),e(Xi,vQ),e(vQ,xPe),b(c,pxe,u),b(c,zn,u),e(zn,kPe),e(zn,TQ),e(TQ,RPe),e(zn,SPe),e(zn,FQ),e(FQ,PPe),e(zn,$Pe),b(c,_xe,u),g(eE,c,u),b(c,uxe,u),b(c,Q8,u),e(Q8,IPe),b(c,bxe,u),g(qf,c,u),b(c,vxe,u),b(c,Vi,u),e(Vi,Of),e(Of,CQ),g(oE,CQ,null),e(Vi,jPe),e(Vi,MQ),e(MQ,DPe),b(c,Txe,u),b(c,Wo,u),g(rE,Wo,null),e(Wo,NPe),e(Wo,tE),e(tE,qPe),e(tE,H8),e(H8,OPe),e(tE,GPe),e(Wo,XPe),e(Wo,aE),e(aE,VPe),e(aE,EQ),e(EQ,zPe),e(aE,WPe),e(Wo,QPe),e(Wo,mo),g(nE,mo,null),e(mo,HPe),e(mo,yQ),e(yQ,UPe),e(mo,JPe),e(mo,zi),e(zi,YPe),e(zi,wQ),e(wQ,KPe),e(zi,ZPe),e(zi,AQ),e(AQ,e$e),e(zi,o$e),e(mo,r$e),e(mo,v),e(v,Gf),e(Gf,LQ),e(LQ,t$e),e(Gf,a$e),e(Gf,U8),e(U8,n$e),e(Gf,s$e),e(v,l$e),e(v,Xf),e(Xf,BQ),e(BQ,i$e),e(Xf,d$e),e(Xf,J8),e(J8,c$e),e(Xf,f$e),e(v,m$e),e(v,Vf),e(Vf,xQ),e(xQ,g$e),e(Vf,h$e),e(Vf,Y8),e(Y8,p$e),e(Vf,_$e),e(v,u$e),e(v,zf),e(zf,kQ),e(kQ,b$e),e(zf,v$e),e(zf,K8),e(K8,T$e),e(zf,F$e),e(v,C$e),e(v,Wf),e(Wf,RQ),e(RQ,M$e),e(Wf,E$e),e(Wf,Z8),e(Z8,y$e),e(Wf,w$e),e(v,A$e),e(v,Qf),e(Qf,SQ),e(SQ,L$e),e(Qf,B$e),e(Qf,e9),e(e9,x$e),e(Qf,k$e),e(v,R$e),e(v,Hf),e(Hf,PQ),e(PQ,S$e),e(Hf,P$e),e(Hf,o9),e(o9,$$e),e(Hf,I$e),e(v,j$e),e(v,Uf),e(Uf,$Q),e($Q,D$e),e(Uf,N$e),e(Uf,r9),e(r9,q$e),e(Uf,O$e),e(v,G$e),e(v,Jf),e(Jf,IQ),e(IQ,X$e),e(Jf,V$e),e(Jf,t9),e(t9,z$e),e(Jf,W$e),e(v,Q$e),e(v,Yf),e(Yf,jQ),e(jQ,H$e),e(Yf,U$e),e(Yf,a9),e(a9,J$e),e(Yf,Y$e),e(v,K$e),e(v,Kf),e(Kf,DQ),e(DQ,Z$e),e(Kf,eIe),e(Kf,n9),e(n9,oIe),e(Kf,rIe),e(v,tIe),e(v,Zf),e(Zf,NQ),e(NQ,aIe),e(Zf,nIe),e(Zf,s9),e(s9,sIe),e(Zf,lIe),e(v,iIe),e(v,em),e(em,qQ),e(qQ,dIe),e(em,cIe),e(em,l9),e(l9,fIe),e(em,mIe),e(v,gIe),e(v,om),e(om,OQ),e(OQ,hIe),e(om,pIe),e(om,i9),e(i9,_Ie),e(om,uIe),e(v,bIe),e(v,rm),e(rm,GQ),e(GQ,vIe),e(rm,TIe),e(rm,d9),e(d9,FIe),e(rm,CIe),e(v,MIe),e(v,tm),e(tm,XQ),e(XQ,EIe),e(tm,yIe),e(tm,c9),e(c9,wIe),e(tm,AIe),e(v,LIe),e(v,am),e(am,VQ),e(VQ,BIe),e(am,xIe),e(am,f9),e(f9,kIe),e(am,RIe),e(v,SIe),e(v,nm),e(nm,zQ),e(zQ,PIe),e(nm,$Ie),e(nm,m9),e(m9,IIe),e(nm,jIe),e(v,DIe),e(v,sm),e(sm,WQ),e(WQ,NIe),e(sm,qIe),e(sm,g9),e(g9,OIe),e(sm,GIe),e(v,XIe),e(v,lm),e(lm,QQ),e(QQ,VIe),e(lm,zIe),e(lm,h9),e(h9,WIe),e(lm,QIe),e(v,HIe),e(v,im),e(im,HQ),e(HQ,UIe),e(im,JIe),e(im,p9),e(p9,YIe),e(im,KIe),e(v,ZIe),e(v,dm),e(dm,UQ),e(UQ,eje),e(dm,oje),e(dm,_9),e(_9,rje),e(dm,tje),e(v,aje),e(v,cm),e(cm,JQ),e(JQ,nje),e(cm,sje),e(cm,u9),e(u9,lje),e(cm,ije),e(v,dje),e(v,fm),e(fm,YQ),e(YQ,cje),e(fm,fje),e(fm,b9),e(b9,mje),e(fm,gje),e(v,hje),e(v,mm),e(mm,KQ),e(KQ,pje),e(mm,_je),e(mm,v9),e(v9,uje),e(mm,bje),e(v,vje),e(v,gm),e(gm,ZQ),e(ZQ,Tje),e(gm,Fje),e(gm,T9),e(T9,Cje),e(gm,Mje),e(v,Eje),e(v,hm),e(hm,eH),e(eH,yje),e(hm,wje),e(hm,F9),e(F9,Aje),e(hm,Lje),e(v,Bje),e(v,pm),e(pm,oH),e(oH,xje),e(pm,kje),e(pm,C9),e(C9,Rje),e(pm,Sje),e(v,Pje),e(v,_m),e(_m,rH),e(rH,$je),e(_m,Ije),e(_m,M9),e(M9,jje),e(_m,Dje),e(v,Nje),e(v,um),e(um,tH),e(tH,qje),e(um,Oje),e(um,E9),e(E9,Gje),e(um,Xje),e(v,Vje),e(v,bm),e(bm,aH),e(aH,zje),e(bm,Wje),e(bm,y9),e(y9,Qje),e(bm,Hje),e(v,Uje),e(v,vm),e(vm,nH),e(nH,Jje),e(vm,Yje),e(vm,w9),e(w9,Kje),e(vm,Zje),e(v,eDe),e(v,Tm),e(Tm,sH),e(sH,oDe),e(Tm,rDe),e(Tm,A9),e(A9,tDe),e(Tm,aDe),e(v,nDe),e(v,Fm),e(Fm,lH),e(lH,sDe),e(Fm,lDe),e(Fm,L9),e(L9,iDe),e(Fm,dDe),e(v,cDe),e(v,Cm),e(Cm,iH),e(iH,fDe),e(Cm,mDe),e(Cm,B9),e(B9,gDe),e(Cm,hDe),e(v,pDe),e(v,Mm),e(Mm,dH),e(dH,_De),e(Mm,uDe),e(Mm,x9),e(x9,bDe),e(Mm,vDe),e(v,TDe),e(v,Em),e(Em,cH),e(cH,FDe),e(Em,CDe),e(Em,k9),e(k9,MDe),e(Em,EDe),e(v,yDe),e(v,ym),e(ym,fH),e(fH,wDe),e(ym,ADe),e(ym,R9),e(R9,LDe),e(ym,BDe),e(v,xDe),e(v,wm),e(wm,mH),e(mH,kDe),e(wm,RDe),e(wm,S9),e(S9,SDe),e(wm,PDe),e(v,$De),e(v,Am),e(Am,gH),e(gH,IDe),e(Am,jDe),e(Am,P9),e(P9,DDe),e(Am,NDe),e(v,qDe),e(v,Lm),e(Lm,hH),e(hH,ODe),e(Lm,GDe),e(Lm,$9),e($9,XDe),e(Lm,VDe),e(v,zDe),e(v,Bm),e(Bm,pH),e(pH,WDe),e(Bm,QDe),e(Bm,I9),e(I9,HDe),e(Bm,UDe),e(v,JDe),e(v,xm),e(xm,_H),e(_H,YDe),e(xm,KDe),e(xm,j9),e(j9,ZDe),e(xm,eNe),e(v,oNe),e(v,km),e(km,uH),e(uH,rNe),e(km,tNe),e(km,D9),e(D9,aNe),e(km,nNe),e(v,sNe),e(v,Rm),e(Rm,bH),e(bH,lNe),e(Rm,iNe),e(Rm,N9),e(N9,dNe),e(Rm,cNe),e(v,fNe),e(v,Sm),e(Sm,vH),e(vH,mNe),e(Sm,gNe),e(Sm,q9),e(q9,hNe),e(Sm,pNe),e(v,_Ne),e(v,Pm),e(Pm,TH),e(TH,uNe),e(Pm,bNe),e(Pm,O9),e(O9,vNe),e(Pm,TNe),e(v,FNe),e(v,$m),e($m,FH),e(FH,CNe),e($m,MNe),e($m,G9),e(G9,ENe),e($m,yNe),e(v,wNe),e(v,Im),e(Im,CH),e(CH,ANe),e(Im,LNe),e(Im,X9),e(X9,BNe),e(Im,xNe),e(v,kNe),e(v,jm),e(jm,MH),e(MH,RNe),e(jm,SNe),e(jm,V9),e(V9,PNe),e(jm,$Ne),e(v,INe),e(v,Dm),e(Dm,EH),e(EH,jNe),e(Dm,DNe),e(Dm,z9),e(z9,NNe),e(Dm,qNe),e(v,ONe),e(v,Nm),e(Nm,yH),e(yH,GNe),e(Nm,XNe),e(Nm,W9),e(W9,VNe),e(Nm,zNe),e(v,WNe),e(v,qm),e(qm,wH),e(wH,QNe),e(qm,HNe),e(qm,Q9),e(Q9,UNe),e(qm,JNe),e(v,YNe),e(v,Om),e(Om,AH),e(AH,KNe),e(Om,ZNe),e(Om,H9),e(H9,eqe),e(Om,oqe),e(v,rqe),e(v,Gm),e(Gm,LH),e(LH,tqe),e(Gm,aqe),e(Gm,U9),e(U9,nqe),e(Gm,sqe),e(v,lqe),e(v,Xm),e(Xm,BH),e(BH,iqe),e(Xm,dqe),e(Xm,J9),e(J9,cqe),e(Xm,fqe),e(v,mqe),e(v,Vm),e(Vm,xH),e(xH,gqe),e(Vm,hqe),e(Vm,Y9),e(Y9,pqe),e(Vm,_qe),e(v,uqe),e(v,zm),e(zm,kH),e(kH,bqe),e(zm,vqe),e(zm,K9),e(K9,Tqe),e(zm,Fqe),e(v,Cqe),e(v,Wm),e(Wm,RH),e(RH,Mqe),e(Wm,Eqe),e(Wm,Z9),e(Z9,yqe),e(Wm,wqe),e(v,Aqe),e(v,Qm),e(Qm,SH),e(SH,Lqe),e(Qm,Bqe),e(Qm,eB),e(eB,xqe),e(Qm,kqe),e(v,Rqe),e(v,Hm),e(Hm,PH),e(PH,Sqe),e(Hm,Pqe),e(Hm,oB),e(oB,$qe),e(Hm,Iqe),e(v,jqe),e(v,Um),e(Um,$H),e($H,Dqe),e(Um,Nqe),e(Um,rB),e(rB,qqe),e(Um,Oqe),e(v,Gqe),e(v,Jm),e(Jm,IH),e(IH,Xqe),e(Jm,Vqe),e(Jm,tB),e(tB,zqe),e(Jm,Wqe),e(v,Qqe),e(v,Ym),e(Ym,jH),e(jH,Hqe),e(Ym,Uqe),e(Ym,aB),e(aB,Jqe),e(Ym,Yqe),e(v,Kqe),e(v,Km),e(Km,DH),e(DH,Zqe),e(Km,eOe),e(Km,nB),e(nB,oOe),e(Km,rOe),e(v,tOe),e(v,Zm),e(Zm,NH),e(NH,aOe),e(Zm,nOe),e(Zm,sB),e(sB,sOe),e(Zm,lOe),e(v,iOe),e(v,eg),e(eg,qH),e(qH,dOe),e(eg,cOe),e(eg,lB),e(lB,fOe),e(eg,mOe),e(v,gOe),e(v,og),e(og,OH),e(OH,hOe),e(og,pOe),e(og,iB),e(iB,_Oe),e(og,uOe),e(v,bOe),e(v,rg),e(rg,GH),e(GH,vOe),e(rg,TOe),e(rg,dB),e(dB,FOe),e(rg,COe),e(v,MOe),e(v,tg),e(tg,XH),e(XH,EOe),e(tg,yOe),e(tg,cB),e(cB,wOe),e(tg,AOe),e(v,LOe),e(v,ag),e(ag,VH),e(VH,BOe),e(ag,xOe),e(ag,fB),e(fB,kOe),e(ag,ROe),e(v,SOe),e(v,ng),e(ng,zH),e(zH,POe),e(ng,$Oe),e(ng,mB),e(mB,IOe),e(ng,jOe),e(v,DOe),e(v,sg),e(sg,WH),e(WH,NOe),e(sg,qOe),e(sg,gB),e(gB,OOe),e(sg,GOe),e(v,XOe),e(v,lg),e(lg,QH),e(QH,VOe),e(lg,zOe),e(lg,hB),e(hB,WOe),e(lg,QOe),e(v,HOe),e(v,ig),e(ig,HH),e(HH,UOe),e(ig,JOe),e(ig,pB),e(pB,YOe),e(ig,KOe),e(v,ZOe),e(v,dg),e(dg,UH),e(UH,eGe),e(dg,oGe),e(dg,_B),e(_B,rGe),e(dg,tGe),e(v,aGe),e(v,cg),e(cg,JH),e(JH,nGe),e(cg,sGe),e(cg,uB),e(uB,lGe),e(cg,iGe),e(v,dGe),e(v,fg),e(fg,YH),e(YH,cGe),e(fg,fGe),e(fg,bB),e(bB,mGe),e(fg,gGe),e(v,hGe),e(v,mg),e(mg,KH),e(KH,pGe),e(mg,_Ge),e(mg,vB),e(vB,uGe),e(mg,bGe),e(v,vGe),e(v,gg),e(gg,ZH),e(ZH,TGe),e(gg,FGe),e(gg,TB),e(TB,CGe),e(gg,MGe),e(v,EGe),e(v,hg),e(hg,eU),e(eU,yGe),e(hg,wGe),e(hg,FB),e(FB,AGe),e(hg,LGe),e(v,BGe),e(v,pg),e(pg,oU),e(oU,xGe),e(pg,kGe),e(pg,CB),e(CB,RGe),e(pg,SGe),e(v,PGe),e(v,_g),e(_g,rU),e(rU,$Ge),e(_g,IGe),e(_g,MB),e(MB,jGe),e(_g,DGe),e(v,NGe),e(v,ug),e(ug,tU),e(tU,qGe),e(ug,OGe),e(ug,EB),e(EB,GGe),e(ug,XGe),e(v,VGe),e(v,bg),e(bg,aU),e(aU,zGe),e(bg,WGe),e(bg,yB),e(yB,QGe),e(bg,HGe),e(v,UGe),e(v,vg),e(vg,nU),e(nU,JGe),e(vg,YGe),e(vg,wB),e(wB,KGe),e(vg,ZGe),e(v,eXe),e(v,Tg),e(Tg,sU),e(sU,oXe),e(Tg,rXe),e(Tg,AB),e(AB,tXe),e(Tg,aXe),e(v,nXe),e(v,Fg),e(Fg,lU),e(lU,sXe),e(Fg,lXe),e(Fg,LB),e(LB,iXe),e(Fg,dXe),e(v,cXe),e(v,Cg),e(Cg,iU),e(iU,fXe),e(Cg,mXe),e(Cg,BB),e(BB,gXe),e(Cg,hXe),e(v,pXe),e(v,Mg),e(Mg,dU),e(dU,_Xe),e(Mg,uXe),e(Mg,xB),e(xB,bXe),e(Mg,vXe),e(v,TXe),e(v,Eg),e(Eg,cU),e(cU,FXe),e(Eg,CXe),e(Eg,kB),e(kB,MXe),e(Eg,EXe),e(v,yXe),e(v,yg),e(yg,fU),e(fU,wXe),e(yg,AXe),e(yg,RB),e(RB,LXe),e(yg,BXe),e(v,xXe),e(v,wg),e(wg,mU),e(mU,kXe),e(wg,RXe),e(wg,SB),e(SB,SXe),e(wg,PXe),e(v,$Xe),e(v,Ag),e(Ag,gU),e(gU,IXe),e(Ag,jXe),e(Ag,PB),e(PB,DXe),e(Ag,NXe),e(v,qXe),e(v,Lg),e(Lg,hU),e(hU,OXe),e(Lg,GXe),e(Lg,$B),e($B,XXe),e(Lg,VXe),e(mo,zXe),e(mo,pU),e(pU,WXe),e(mo,QXe),g(sE,mo,null),e(Wo,HXe),e(Wo,Bg),g(lE,Bg,null),e(Bg,UXe),e(Bg,_U),e(_U,JXe),b(c,Fxe,u),b(c,Wi,u),e(Wi,xg),e(xg,uU),g(iE,uU,null),e(Wi,YXe),e(Wi,bU),e(bU,KXe),b(c,Cxe,u),b(c,Qo,u),g(dE,Qo,null),e(Qo,ZXe),e(Qo,cE),e(cE,eVe),e(cE,IB),e(IB,oVe),e(cE,rVe),e(Qo,tVe),e(Qo,fE),e(fE,aVe),e(fE,vU),e(vU,nVe),e(fE,sVe),e(Qo,lVe),e(Qo,go),g(mE,go,null),e(go,iVe),e(go,TU),e(TU,dVe),e(go,cVe),e(go,Oa),e(Oa,fVe),e(Oa,FU),e(FU,mVe),e(Oa,gVe),e(Oa,CU),e(CU,hVe),e(Oa,pVe),e(Oa,MU),e(MU,_Ve),e(Oa,uVe),e(go,bVe),e(go,E),e(E,Wn),e(Wn,EU),e(EU,vVe),e(Wn,TVe),e(Wn,jB),e(jB,FVe),e(Wn,CVe),e(Wn,DB),e(DB,MVe),e(Wn,EVe),e(E,yVe),e(E,Qn),e(Qn,yU),e(yU,wVe),e(Qn,AVe),e(Qn,NB),e(NB,LVe),e(Qn,BVe),e(Qn,qB),e(qB,xVe),e(Qn,kVe),e(E,RVe),e(E,Hn),e(Hn,wU),e(wU,SVe),e(Hn,PVe),e(Hn,OB),e(OB,$Ve),e(Hn,IVe),e(Hn,GB),e(GB,jVe),e(Hn,DVe),e(E,NVe),e(E,kg),e(kg,AU),e(AU,qVe),e(kg,OVe),e(kg,XB),e(XB,GVe),e(kg,XVe),e(E,VVe),e(E,Un),e(Un,LU),e(LU,zVe),e(Un,WVe),e(Un,VB),e(VB,QVe),e(Un,HVe),e(Un,zB),e(zB,UVe),e(Un,JVe),e(E,YVe),e(E,Rg),e(Rg,BU),e(BU,KVe),e(Rg,ZVe),e(Rg,WB),e(WB,eze),e(Rg,oze),e(E,rze),e(E,Sg),e(Sg,xU),e(xU,tze),e(Sg,aze),e(Sg,QB),e(QB,nze),e(Sg,sze),e(E,lze),e(E,Pg),e(Pg,kU),e(kU,ize),e(Pg,dze),e(Pg,HB),e(HB,cze),e(Pg,fze),e(E,mze),e(E,Jn),e(Jn,RU),e(RU,gze),e(Jn,hze),e(Jn,UB),e(UB,pze),e(Jn,_ze),e(Jn,JB),e(JB,uze),e(Jn,bze),e(E,vze),e(E,Yn),e(Yn,SU),e(SU,Tze),e(Yn,Fze),e(Yn,YB),e(YB,Cze),e(Yn,Mze),e(Yn,KB),e(KB,Eze),e(Yn,yze),e(E,wze),e(E,Kn),e(Kn,PU),e(PU,Aze),e(Kn,Lze),e(Kn,ZB),e(ZB,Bze),e(Kn,xze),e(Kn,ex),e(ex,kze),e(Kn,Rze),e(E,Sze),e(E,$g),e($g,$U),e($U,Pze),e($g,$ze),e($g,ox),e(ox,Ize),e($g,jze),e(E,Dze),e(E,Ig),e(Ig,IU),e(IU,Nze),e(Ig,qze),e(Ig,rx),e(rx,Oze),e(Ig,Gze),e(E,Xze),e(E,Zn),e(Zn,jU),e(jU,Vze),e(Zn,zze),e(Zn,tx),e(tx,Wze),e(Zn,Qze),e(Zn,ax),e(ax,Hze),e(Zn,Uze),e(E,Jze),e(E,jg),e(jg,DU),e(DU,Yze),e(jg,Kze),e(jg,nx),e(nx,Zze),e(jg,eWe),e(E,oWe),e(E,es),e(es,NU),e(NU,rWe),e(es,tWe),e(es,sx),e(sx,aWe),e(es,nWe),e(es,lx),e(lx,sWe),e(es,lWe),e(E,iWe),e(E,os),e(os,qU),e(qU,dWe),e(os,cWe),e(os,ix),e(ix,fWe),e(os,mWe),e(os,dx),e(dx,gWe),e(os,hWe),e(E,pWe),e(E,rs),e(rs,OU),e(OU,_We),e(rs,uWe),e(rs,cx),e(cx,bWe),e(rs,vWe),e(rs,GU),e(GU,TWe),e(rs,FWe),e(E,CWe),e(E,Dg),e(Dg,XU),e(XU,MWe),e(Dg,EWe),e(Dg,fx),e(fx,yWe),e(Dg,wWe),e(E,AWe),e(E,ts),e(ts,VU),e(VU,LWe),e(ts,BWe),e(ts,mx),e(mx,xWe),e(ts,kWe),e(ts,gx),e(gx,RWe),e(ts,SWe),e(E,PWe),e(E,Ng),e(Ng,zU),e(zU,$We),e(Ng,IWe),e(Ng,hx),e(hx,jWe),e(Ng,DWe),e(E,NWe),e(E,as),e(as,WU),e(WU,qWe),e(as,OWe),e(as,px),e(px,GWe),e(as,XWe),e(as,_x),e(_x,VWe),e(as,zWe),e(E,WWe),e(E,ns),e(ns,QU),e(QU,QWe),e(ns,HWe),e(ns,ux),e(ux,UWe),e(ns,JWe),e(ns,bx),e(bx,YWe),e(ns,KWe),e(E,ZWe),e(E,ss),e(ss,HU),e(HU,eQe),e(ss,oQe),e(ss,vx),e(vx,rQe),e(ss,tQe),e(ss,Tx),e(Tx,aQe),e(ss,nQe),e(E,sQe),e(E,qg),e(qg,UU),e(UU,lQe),e(qg,iQe),e(qg,Fx),e(Fx,dQe),e(qg,cQe),e(E,fQe),e(E,ls),e(ls,JU),e(JU,mQe),e(ls,gQe),e(ls,Cx),e(Cx,hQe),e(ls,pQe),e(ls,Mx),e(Mx,_Qe),e(ls,uQe),e(E,bQe),e(E,Og),e(Og,YU),e(YU,vQe),e(Og,TQe),e(Og,Ex),e(Ex,FQe),e(Og,CQe),e(E,MQe),e(E,is),e(is,KU),e(KU,EQe),e(is,yQe),e(is,yx),e(yx,wQe),e(is,AQe),e(is,wx),e(wx,LQe),e(is,BQe),e(E,xQe),e(E,ds),e(ds,ZU),e(ZU,kQe),e(ds,RQe),e(ds,Ax),e(Ax,SQe),e(ds,PQe),e(ds,Lx),e(Lx,$Qe),e(ds,IQe),e(E,jQe),e(E,cs),e(cs,eJ),e(eJ,DQe),e(cs,NQe),e(cs,Bx),e(Bx,qQe),e(cs,OQe),e(cs,xx),e(xx,GQe),e(cs,XQe),e(E,VQe),e(E,fs),e(fs,oJ),e(oJ,zQe),e(fs,WQe),e(fs,kx),e(kx,QQe),e(fs,HQe),e(fs,Rx),e(Rx,UQe),e(fs,JQe),e(E,YQe),e(E,Gg),e(Gg,rJ),e(rJ,KQe),e(Gg,ZQe),e(Gg,Sx),e(Sx,eHe),e(Gg,oHe),e(E,rHe),e(E,ms),e(ms,tJ),e(tJ,tHe),e(ms,aHe),e(ms,Px),e(Px,nHe),e(ms,sHe),e(ms,$x),e($x,lHe),e(ms,iHe),e(E,dHe),e(E,gs),e(gs,aJ),e(aJ,cHe),e(gs,fHe),e(gs,Ix),e(Ix,mHe),e(gs,gHe),e(gs,jx),e(jx,hHe),e(gs,pHe),e(E,_He),e(E,hs),e(hs,nJ),e(nJ,uHe),e(hs,bHe),e(hs,Dx),e(Dx,vHe),e(hs,THe),e(hs,Nx),e(Nx,FHe),e(hs,CHe),e(E,MHe),e(E,ps),e(ps,sJ),e(sJ,EHe),e(ps,yHe),e(ps,qx),e(qx,wHe),e(ps,AHe),e(ps,Ox),e(Ox,LHe),e(ps,BHe),e(E,xHe),e(E,_s),e(_s,lJ),e(lJ,kHe),e(_s,RHe),e(_s,Gx),e(Gx,SHe),e(_s,PHe),e(_s,Xx),e(Xx,$He),e(_s,IHe),e(E,jHe),e(E,us),e(us,iJ),e(iJ,DHe),e(us,NHe),e(us,Vx),e(Vx,qHe),e(us,OHe),e(us,zx),e(zx,GHe),e(us,XHe),e(E,VHe),e(E,Xg),e(Xg,dJ),e(dJ,zHe),e(Xg,WHe),e(Xg,Wx),e(Wx,QHe),e(Xg,HHe),e(E,UHe),e(E,bs),e(bs,cJ),e(cJ,JHe),e(bs,YHe),e(bs,Qx),e(Qx,KHe),e(bs,ZHe),e(bs,Hx),e(Hx,eUe),e(bs,oUe),e(E,rUe),e(E,Vg),e(Vg,fJ),e(fJ,tUe),e(Vg,aUe),e(Vg,Ux),e(Ux,nUe),e(Vg,sUe),e(E,lUe),e(E,zg),e(zg,mJ),e(mJ,iUe),e(zg,dUe),e(zg,Jx),e(Jx,cUe),e(zg,fUe),e(E,mUe),e(E,vs),e(vs,gJ),e(gJ,gUe),e(vs,hUe),e(vs,Yx),e(Yx,pUe),e(vs,_Ue),e(vs,Kx),e(Kx,uUe),e(vs,bUe),e(E,vUe),e(E,Ts),e(Ts,hJ),e(hJ,TUe),e(Ts,FUe),e(Ts,Zx),e(Zx,CUe),e(Ts,MUe),e(Ts,ek),e(ek,EUe),e(Ts,yUe),e(E,wUe),e(E,Wg),e(Wg,pJ),e(pJ,AUe),e(Wg,LUe),e(Wg,ok),e(ok,BUe),e(Wg,xUe),e(E,kUe),e(E,Fs),e(Fs,_J),e(_J,RUe),e(Fs,SUe),e(Fs,rk),e(rk,PUe),e(Fs,$Ue),e(Fs,tk),e(tk,IUe),e(Fs,jUe),e(E,DUe),e(E,Cs),e(Cs,uJ),e(uJ,NUe),e(Cs,qUe),e(Cs,ak),e(ak,OUe),e(Cs,GUe),e(Cs,nk),e(nk,XUe),e(Cs,VUe),e(E,zUe),e(E,Ms),e(Ms,bJ),e(bJ,WUe),e(Ms,QUe),e(Ms,sk),e(sk,HUe),e(Ms,UUe),e(Ms,lk),e(lk,JUe),e(Ms,YUe),e(E,KUe),e(E,Es),e(Es,vJ),e(vJ,ZUe),e(Es,eJe),e(Es,ik),e(ik,oJe),e(Es,rJe),e(Es,dk),e(dk,tJe),e(Es,aJe),e(E,nJe),e(E,ys),e(ys,TJ),e(TJ,sJe),e(ys,lJe),e(ys,ck),e(ck,iJe),e(ys,dJe),e(ys,fk),e(fk,cJe),e(ys,fJe),e(E,mJe),e(E,Qg),e(Qg,FJ),e(FJ,gJe),e(Qg,hJe),e(Qg,mk),e(mk,pJe),e(Qg,_Je),e(E,uJe),e(E,Hg),e(Hg,CJ),e(CJ,bJe),e(Hg,vJe),e(Hg,gk),e(gk,TJe),e(Hg,FJe),e(E,CJe),e(E,Ug),e(Ug,MJ),e(MJ,MJe),e(Ug,EJe),e(Ug,hk),e(hk,yJe),e(Ug,wJe),e(E,AJe),e(E,Jg),e(Jg,EJ),e(EJ,LJe),e(Jg,BJe),e(Jg,pk),e(pk,xJe),e(Jg,kJe),e(E,RJe),e(E,ws),e(ws,yJ),e(yJ,SJe),e(ws,PJe),e(ws,_k),e(_k,$Je),e(ws,IJe),e(ws,uk),e(uk,jJe),e(ws,DJe),e(E,NJe),e(E,Yg),e(Yg,wJ),e(wJ,qJe),e(Yg,OJe),e(Yg,bk),e(bk,GJe),e(Yg,XJe),e(E,VJe),e(E,As),e(As,AJ),e(AJ,zJe),e(As,WJe),e(As,vk),e(vk,QJe),e(As,HJe),e(As,Tk),e(Tk,UJe),e(As,JJe),e(E,YJe),e(E,Ls),e(Ls,LJ),e(LJ,KJe),e(Ls,ZJe),e(Ls,Fk),e(Fk,eYe),e(Ls,oYe),e(Ls,Ck),e(Ck,rYe),e(Ls,tYe),e(E,aYe),e(E,Bs),e(Bs,BJ),e(BJ,nYe),e(Bs,sYe),e(Bs,Mk),e(Mk,lYe),e(Bs,iYe),e(Bs,Ek),e(Ek,dYe),e(Bs,cYe),e(E,fYe),e(E,xs),e(xs,xJ),e(xJ,mYe),e(xs,gYe),e(xs,yk),e(yk,hYe),e(xs,pYe),e(xs,wk),e(wk,_Ye),e(xs,uYe),e(E,bYe),e(E,ks),e(ks,kJ),e(kJ,vYe),e(ks,TYe),e(ks,Ak),e(Ak,FYe),e(ks,CYe),e(ks,Lk),e(Lk,MYe),e(ks,EYe),e(E,yYe),e(E,Rs),e(Rs,RJ),e(RJ,wYe),e(Rs,AYe),e(Rs,Bk),e(Bk,LYe),e(Rs,BYe),e(Rs,xk),e(xk,xYe),e(Rs,kYe),e(E,RYe),e(E,Kg),e(Kg,SJ),e(SJ,SYe),e(Kg,PYe),e(Kg,kk),e(kk,$Ye),e(Kg,IYe),e(E,jYe),e(E,Zg),e(Zg,PJ),e(PJ,DYe),e(Zg,NYe),e(Zg,Rk),e(Rk,qYe),e(Zg,OYe),e(E,GYe),e(E,Ss),e(Ss,$J),e($J,XYe),e(Ss,VYe),e(Ss,Sk),e(Sk,zYe),e(Ss,WYe),e(Ss,Pk),e(Pk,QYe),e(Ss,HYe),e(E,UYe),e(E,Ps),e(Ps,IJ),e(IJ,JYe),e(Ps,YYe),e(Ps,$k),e($k,KYe),e(Ps,ZYe),e(Ps,Ik),e(Ik,eKe),e(Ps,oKe),e(E,rKe),e(E,$s),e($s,jJ),e(jJ,tKe),e($s,aKe),e($s,jk),e(jk,nKe),e($s,sKe),e($s,Dk),e(Dk,lKe),e($s,iKe),e(E,dKe),e(E,eh),e(eh,DJ),e(DJ,cKe),e(eh,fKe),e(eh,Nk),e(Nk,mKe),e(eh,gKe),e(E,hKe),e(E,oh),e(oh,NJ),e(NJ,pKe),e(oh,_Ke),e(oh,qk),e(qk,uKe),e(oh,bKe),e(E,vKe),e(E,rh),e(rh,qJ),e(qJ,TKe),e(rh,FKe),e(rh,Ok),e(Ok,CKe),e(rh,MKe),e(E,EKe),e(E,th),e(th,OJ),e(OJ,yKe),e(th,wKe),e(th,Gk),e(Gk,AKe),e(th,LKe),e(E,BKe),e(E,Is),e(Is,GJ),e(GJ,xKe),e(Is,kKe),e(Is,Xk),e(Xk,RKe),e(Is,SKe),e(Is,Vk),e(Vk,PKe),e(Is,$Ke),e(E,IKe),e(E,ah),e(ah,XJ),e(XJ,jKe),e(ah,DKe),e(ah,zk),e(zk,NKe),e(ah,qKe),e(E,OKe),e(E,nh),e(nh,VJ),e(VJ,GKe),e(nh,XKe),e(nh,Wk),e(Wk,VKe),e(nh,zKe),e(E,WKe),e(E,js),e(js,zJ),e(zJ,QKe),e(js,HKe),e(js,Qk),e(Qk,UKe),e(js,JKe),e(js,Hk),e(Hk,YKe),e(js,KKe),e(E,ZKe),e(E,Ds),e(Ds,WJ),e(WJ,eZe),e(Ds,oZe),e(Ds,Uk),e(Uk,rZe),e(Ds,tZe),e(Ds,Jk),e(Jk,aZe),e(Ds,nZe),e(go,sZe),e(go,QJ),e(QJ,lZe),e(go,iZe),g(gE,go,null),e(Qo,dZe),e(Qo,sh),g(hE,sh,null),e(sh,cZe),e(sh,HJ),e(HJ,fZe),b(c,Mxe,u),b(c,Qi,u),e(Qi,lh),e(lh,UJ),g(pE,UJ,null),e(Qi,mZe),e(Qi,JJ),e(JJ,gZe),b(c,Exe,u),b(c,Ho,u),g(_E,Ho,null),e(Ho,hZe),e(Ho,uE),e(uE,pZe),e(uE,Yk),e(Yk,_Ze),e(uE,uZe),e(Ho,bZe),e(Ho,bE),e(bE,vZe),e(bE,YJ),e(YJ,TZe),e(bE,FZe),e(Ho,CZe),e(Ho,Ie),g(vE,Ie,null),e(Ie,MZe),e(Ie,KJ),e(KJ,EZe),e(Ie,yZe),e(Ie,Ga),e(Ga,wZe),e(Ga,ZJ),e(ZJ,AZe),e(Ga,LZe),e(Ga,eY),e(eY,BZe),e(Ga,xZe),e(Ga,oY),e(oY,kZe),e(Ga,RZe),e(Ie,SZe),e(Ie,te),e(te,ih),e(ih,rY),e(rY,PZe),e(ih,$Ze),e(ih,Kk),e(Kk,IZe),e(ih,jZe),e(te,DZe),e(te,dh),e(dh,tY),e(tY,NZe),e(dh,qZe),e(dh,Zk),e(Zk,OZe),e(dh,GZe),e(te,XZe),e(te,ch),e(ch,aY),e(aY,VZe),e(ch,zZe),e(ch,eR),e(eR,WZe),e(ch,QZe),e(te,HZe),e(te,fh),e(fh,nY),e(nY,UZe),e(fh,JZe),e(fh,oR),e(oR,YZe),e(fh,KZe),e(te,ZZe),e(te,mh),e(mh,sY),e(sY,eeo),e(mh,oeo),e(mh,rR),e(rR,reo),e(mh,teo),e(te,aeo),e(te,gh),e(gh,lY),e(lY,neo),e(gh,seo),e(gh,tR),e(tR,leo),e(gh,ieo),e(te,deo),e(te,hh),e(hh,iY),e(iY,ceo),e(hh,feo),e(hh,aR),e(aR,meo),e(hh,geo),e(te,heo),e(te,ph),e(ph,dY),e(dY,peo),e(ph,_eo),e(ph,nR),e(nR,ueo),e(ph,beo),e(te,veo),e(te,_h),e(_h,cY),e(cY,Teo),e(_h,Feo),e(_h,sR),e(sR,Ceo),e(_h,Meo),e(te,Eeo),e(te,uh),e(uh,fY),e(fY,yeo),e(uh,weo),e(uh,lR),e(lR,Aeo),e(uh,Leo),e(te,Beo),e(te,bh),e(bh,mY),e(mY,xeo),e(bh,keo),e(bh,iR),e(iR,Reo),e(bh,Seo),e(te,Peo),e(te,vh),e(vh,gY),e(gY,$eo),e(vh,Ieo),e(vh,dR),e(dR,jeo),e(vh,Deo),e(te,Neo),e(te,Th),e(Th,hY),e(hY,qeo),e(Th,Oeo),e(Th,cR),e(cR,Geo),e(Th,Xeo),e(te,Veo),e(te,Fh),e(Fh,pY),e(pY,zeo),e(Fh,Weo),e(Fh,fR),e(fR,Qeo),e(Fh,Heo),e(te,Ueo),e(te,Ch),e(Ch,_Y),e(_Y,Jeo),e(Ch,Yeo),e(Ch,mR),e(mR,Keo),e(Ch,Zeo),e(te,eoo),e(te,Mh),e(Mh,uY),e(uY,ooo),e(Mh,roo),e(Mh,gR),e(gR,too),e(Mh,aoo),e(te,noo),e(te,Eh),e(Eh,bY),e(bY,soo),e(Eh,loo),e(Eh,hR),e(hR,ioo),e(Eh,doo),e(Ie,coo),g(yh,Ie,null),e(Ie,foo),e(Ie,vY),e(vY,moo),e(Ie,goo),g(TE,Ie,null),e(Ho,hoo),e(Ho,wh),g(FE,wh,null),e(wh,poo),e(wh,TY),e(TY,_oo),b(c,yxe,u),b(c,Hi,u),e(Hi,Ah),e(Ah,FY),g(CE,FY,null),e(Hi,uoo),e(Hi,CY),e(CY,boo),b(c,wxe,u),b(c,Uo,u),g(ME,Uo,null),e(Uo,voo),e(Uo,EE),e(EE,Too),e(EE,pR),e(pR,Foo),e(EE,Coo),e(Uo,Moo),e(Uo,yE),e(yE,Eoo),e(yE,MY),e(MY,yoo),e(yE,woo),e(Uo,Aoo),e(Uo,je),g(wE,je,null),e(je,Loo),e(je,EY),e(EY,Boo),e(je,xoo),e(je,Ui),e(Ui,koo),e(Ui,yY),e(yY,Roo),e(Ui,Soo),e(Ui,wY),e(wY,Poo),e(Ui,$oo),e(je,Ioo),e(je,xe),e(xe,Lh),e(Lh,AY),e(AY,joo),e(Lh,Doo),e(Lh,_R),e(_R,Noo),e(Lh,qoo),e(xe,Ooo),e(xe,Bh),e(Bh,LY),e(LY,Goo),e(Bh,Xoo),e(Bh,uR),e(uR,Voo),e(Bh,zoo),e(xe,Woo),e(xe,xh),e(xh,BY),e(BY,Qoo),e(xh,Hoo),e(xh,bR),e(bR,Uoo),e(xh,Joo),e(xe,Yoo),e(xe,kh),e(kh,xY),e(xY,Koo),e(kh,Zoo),e(kh,vR),e(vR,ero),e(kh,oro),e(xe,rro),e(xe,Rh),e(Rh,kY),e(kY,tro),e(Rh,aro),e(Rh,TR),e(TR,nro),e(Rh,sro),e(xe,lro),e(xe,Sh),e(Sh,RY),e(RY,iro),e(Sh,dro),e(Sh,FR),e(FR,cro),e(Sh,fro),e(xe,mro),e(xe,Ph),e(Ph,SY),e(SY,gro),e(Ph,hro),e(Ph,CR),e(CR,pro),e(Ph,_ro),e(xe,uro),e(xe,$h),e($h,PY),e(PY,bro),e($h,vro),e($h,MR),e(MR,Tro),e($h,Fro),e(je,Cro),g(Ih,je,null),e(je,Mro),e(je,$Y),e($Y,Ero),e(je,yro),g(AE,je,null),e(Uo,wro),e(Uo,jh),g(LE,jh,null),e(jh,Aro),e(jh,IY),e(IY,Lro),b(c,Axe,u),b(c,Ji,u),e(Ji,Dh),e(Dh,jY),g(BE,jY,null),e(Ji,Bro),e(Ji,DY),e(DY,xro),b(c,Lxe,u),b(c,Jo,u),g(xE,Jo,null),e(Jo,kro),e(Jo,Yi),e(Yi,Rro),e(Yi,NY),e(NY,Sro),e(Yi,Pro),e(Yi,qY),e(qY,$ro),e(Yi,Iro),e(Jo,jro),e(Jo,kE),e(kE,Dro),e(kE,OY),e(OY,Nro),e(kE,qro),e(Jo,Oro),e(Jo,Vr),g(RE,Vr,null),e(Vr,Gro),e(Vr,GY),e(GY,Xro),e(Vr,Vro),e(Vr,Ki),e(Ki,zro),e(Ki,XY),e(XY,Wro),e(Ki,Qro),e(Ki,VY),e(VY,Hro),e(Ki,Uro),e(Vr,Jro),e(Vr,zY),e(zY,Yro),e(Vr,Kro),g(SE,Vr,null),e(Jo,Zro),e(Jo,De),g(PE,De,null),e(De,eto),e(De,WY),e(WY,oto),e(De,rto),e(De,Xa),e(Xa,tto),e(Xa,QY),e(QY,ato),e(Xa,nto),e(Xa,HY),e(HY,sto),e(Xa,lto),e(Xa,UY),e(UY,ito),e(Xa,dto),e(De,cto),e(De,F),e(F,Nh),e(Nh,JY),e(JY,fto),e(Nh,mto),e(Nh,ER),e(ER,gto),e(Nh,hto),e(F,pto),e(F,qh),e(qh,YY),e(YY,_to),e(qh,uto),e(qh,yR),e(yR,bto),e(qh,vto),e(F,Tto),e(F,Oh),e(Oh,KY),e(KY,Fto),e(Oh,Cto),e(Oh,wR),e(wR,Mto),e(Oh,Eto),e(F,yto),e(F,Gh),e(Gh,ZY),e(ZY,wto),e(Gh,Ato),e(Gh,AR),e(AR,Lto),e(Gh,Bto),e(F,xto),e(F,Xh),e(Xh,eK),e(eK,kto),e(Xh,Rto),e(Xh,LR),e(LR,Sto),e(Xh,Pto),e(F,$to),e(F,Vh),e(Vh,oK),e(oK,Ito),e(Vh,jto),e(Vh,BR),e(BR,Dto),e(Vh,Nto),e(F,qto),e(F,zh),e(zh,rK),e(rK,Oto),e(zh,Gto),e(zh,xR),e(xR,Xto),e(zh,Vto),e(F,zto),e(F,Wh),e(Wh,tK),e(tK,Wto),e(Wh,Qto),e(Wh,kR),e(kR,Hto),e(Wh,Uto),e(F,Jto),e(F,Qh),e(Qh,aK),e(aK,Yto),e(Qh,Kto),e(Qh,RR),e(RR,Zto),e(Qh,eao),e(F,oao),e(F,Hh),e(Hh,nK),e(nK,rao),e(Hh,tao),e(Hh,SR),e(SR,aao),e(Hh,nao),e(F,sao),e(F,Uh),e(Uh,sK),e(sK,lao),e(Uh,iao),e(Uh,PR),e(PR,dao),e(Uh,cao),e(F,fao),e(F,Jh),e(Jh,lK),e(lK,mao),e(Jh,gao),e(Jh,$R),e($R,hao),e(Jh,pao),e(F,_ao),e(F,Yh),e(Yh,iK),e(iK,uao),e(Yh,bao),e(Yh,IR),e(IR,vao),e(Yh,Tao),e(F,Fao),e(F,Kh),e(Kh,dK),e(dK,Cao),e(Kh,Mao),e(Kh,jR),e(jR,Eao),e(Kh,yao),e(F,wao),e(F,Zh),e(Zh,cK),e(cK,Aao),e(Zh,Lao),e(Zh,DR),e(DR,Bao),e(Zh,xao),e(F,kao),e(F,ep),e(ep,fK),e(fK,Rao),e(ep,Sao),e(ep,NR),e(NR,Pao),e(ep,$ao),e(F,Iao),e(F,op),e(op,mK),e(mK,jao),e(op,Dao),e(op,qR),e(qR,Nao),e(op,qao),e(F,Oao),e(F,rp),e(rp,gK),e(gK,Gao),e(rp,Xao),e(rp,OR),e(OR,Vao),e(rp,zao),e(F,Wao),e(F,tp),e(tp,hK),e(hK,Qao),e(tp,Hao),e(tp,GR),e(GR,Uao),e(tp,Jao),e(F,Yao),e(F,ap),e(ap,pK),e(pK,Kao),e(ap,Zao),e(ap,XR),e(XR,eno),e(ap,ono),e(F,rno),e(F,np),e(np,_K),e(_K,tno),e(np,ano),e(np,VR),e(VR,nno),e(np,sno),e(F,lno),e(F,sp),e(sp,uK),e(uK,ino),e(sp,dno),e(sp,zR),e(zR,cno),e(sp,fno),e(F,mno),e(F,lp),e(lp,bK),e(bK,gno),e(lp,hno),e(lp,WR),e(WR,pno),e(lp,_no),e(F,uno),e(F,ip),e(ip,vK),e(vK,bno),e(ip,vno),e(ip,QR),e(QR,Tno),e(ip,Fno),e(F,Cno),e(F,dp),e(dp,TK),e(TK,Mno),e(dp,Eno),e(dp,HR),e(HR,yno),e(dp,wno),e(F,Ano),e(F,cp),e(cp,FK),e(FK,Lno),e(cp,Bno),e(cp,UR),e(UR,xno),e(cp,kno),e(F,Rno),e(F,fp),e(fp,CK),e(CK,Sno),e(fp,Pno),e(fp,JR),e(JR,$no),e(fp,Ino),e(F,jno),e(F,Ns),e(Ns,MK),e(MK,Dno),e(Ns,Nno),e(Ns,YR),e(YR,qno),e(Ns,Ono),e(Ns,KR),e(KR,Gno),e(Ns,Xno),e(F,Vno),e(F,mp),e(mp,EK),e(EK,zno),e(mp,Wno),e(mp,ZR),e(ZR,Qno),e(mp,Hno),e(F,Uno),e(F,gp),e(gp,yK),e(yK,Jno),e(gp,Yno),e(gp,eS),e(eS,Kno),e(gp,Zno),e(F,eso),e(F,hp),e(hp,wK),e(wK,oso),e(hp,rso),e(hp,oS),e(oS,tso),e(hp,aso),e(F,nso),e(F,pp),e(pp,AK),e(AK,sso),e(pp,lso),e(pp,rS),e(rS,iso),e(pp,dso),e(F,cso),e(F,_p),e(_p,LK),e(LK,fso),e(_p,mso),e(_p,tS),e(tS,gso),e(_p,hso),e(F,pso),e(F,up),e(up,BK),e(BK,_so),e(up,uso),e(up,aS),e(aS,bso),e(up,vso),e(F,Tso),e(F,bp),e(bp,xK),e(xK,Fso),e(bp,Cso),e(bp,nS),e(nS,Mso),e(bp,Eso),e(F,yso),e(F,vp),e(vp,kK),e(kK,wso),e(vp,Aso),e(vp,sS),e(sS,Lso),e(vp,Bso),e(F,xso),e(F,Tp),e(Tp,RK),e(RK,kso),e(Tp,Rso),e(Tp,lS),e(lS,Sso),e(Tp,Pso),e(F,$so),e(F,Fp),e(Fp,SK),e(SK,Iso),e(Fp,jso),e(Fp,iS),e(iS,Dso),e(Fp,Nso),e(F,qso),e(F,Cp),e(Cp,PK),e(PK,Oso),e(Cp,Gso),e(Cp,dS),e(dS,Xso),e(Cp,Vso),e(F,zso),e(F,Mp),e(Mp,$K),e($K,Wso),e(Mp,Qso),e(Mp,cS),e(cS,Hso),e(Mp,Uso),e(F,Jso),e(F,Ep),e(Ep,IK),e(IK,Yso),e(Ep,Kso),e(Ep,fS),e(fS,Zso),e(Ep,elo),e(F,olo),e(F,yp),e(yp,jK),e(jK,rlo),e(yp,tlo),e(yp,mS),e(mS,alo),e(yp,nlo),e(F,slo),e(F,wp),e(wp,DK),e(DK,llo),e(wp,ilo),e(wp,gS),e(gS,dlo),e(wp,clo),e(F,flo),e(F,Ap),e(Ap,NK),e(NK,mlo),e(Ap,glo),e(Ap,hS),e(hS,hlo),e(Ap,plo),e(F,_lo),e(F,Lp),e(Lp,qK),e(qK,ulo),e(Lp,blo),e(Lp,pS),e(pS,vlo),e(Lp,Tlo),e(F,Flo),e(F,Bp),e(Bp,OK),e(OK,Clo),e(Bp,Mlo),e(Bp,_S),e(_S,Elo),e(Bp,ylo),e(F,wlo),e(F,xp),e(xp,GK),e(GK,Alo),e(xp,Llo),e(xp,uS),e(uS,Blo),e(xp,xlo),e(F,klo),e(F,kp),e(kp,XK),e(XK,Rlo),e(kp,Slo),e(kp,bS),e(bS,Plo),e(kp,$lo),e(F,Ilo),e(F,Rp),e(Rp,VK),e(VK,jlo),e(Rp,Dlo),e(Rp,vS),e(vS,Nlo),e(Rp,qlo),e(F,Olo),e(F,Sp),e(Sp,zK),e(zK,Glo),e(Sp,Xlo),e(Sp,TS),e(TS,Vlo),e(Sp,zlo),e(F,Wlo),e(F,Pp),e(Pp,WK),e(WK,Qlo),e(Pp,Hlo),e(Pp,FS),e(FS,Ulo),e(Pp,Jlo),e(F,Ylo),e(F,$p),e($p,QK),e(QK,Klo),e($p,Zlo),e($p,CS),e(CS,eio),e($p,oio),e(F,rio),e(F,Ip),e(Ip,HK),e(HK,tio),e(Ip,aio),e(Ip,MS),e(MS,nio),e(Ip,sio),e(F,lio),e(F,jp),e(jp,UK),e(UK,iio),e(jp,dio),e(jp,ES),e(ES,cio),e(jp,fio),e(F,mio),e(F,Dp),e(Dp,JK),e(JK,gio),e(Dp,hio),e(Dp,yS),e(yS,pio),e(Dp,_io),e(F,uio),e(F,Np),e(Np,YK),e(YK,bio),e(Np,vio),e(Np,wS),e(wS,Tio),e(Np,Fio),e(F,Cio),e(F,qp),e(qp,KK),e(KK,Mio),e(qp,Eio),e(qp,AS),e(AS,yio),e(qp,wio),e(F,Aio),e(F,Op),e(Op,ZK),e(ZK,Lio),e(Op,Bio),e(Op,LS),e(LS,xio),e(Op,kio),e(F,Rio),e(F,Gp),e(Gp,eZ),e(eZ,Sio),e(Gp,Pio),e(Gp,BS),e(BS,$io),e(Gp,Iio),e(F,jio),e(F,Xp),e(Xp,oZ),e(oZ,Dio),e(Xp,Nio),e(Xp,xS),e(xS,qio),e(Xp,Oio),e(F,Gio),e(F,Vp),e(Vp,rZ),e(rZ,Xio),e(Vp,Vio),e(Vp,kS),e(kS,zio),e(Vp,Wio),e(F,Qio),e(F,zp),e(zp,tZ),e(tZ,Hio),e(zp,Uio),e(zp,RS),e(RS,Jio),e(zp,Yio),e(F,Kio),e(F,Wp),e(Wp,aZ),e(aZ,Zio),e(Wp,edo),e(Wp,SS),e(SS,odo),e(Wp,rdo),e(F,tdo),e(F,Qp),e(Qp,nZ),e(nZ,ado),e(Qp,ndo),e(Qp,PS),e(PS,sdo),e(Qp,ldo),e(F,ido),e(F,Hp),e(Hp,sZ),e(sZ,ddo),e(Hp,cdo),e(Hp,$S),e($S,fdo),e(Hp,mdo),e(F,gdo),e(F,Up),e(Up,lZ),e(lZ,hdo),e(Up,pdo),e(Up,IS),e(IS,_do),e(Up,udo),e(F,bdo),e(F,Jp),e(Jp,iZ),e(iZ,vdo),e(Jp,Tdo),e(Jp,jS),e(jS,Fdo),e(Jp,Cdo),e(F,Mdo),e(F,Yp),e(Yp,dZ),e(dZ,Edo),e(Yp,ydo),e(Yp,DS),e(DS,wdo),e(Yp,Ado),e(F,Ldo),e(F,Kp),e(Kp,cZ),e(cZ,Bdo),e(Kp,xdo),e(Kp,NS),e(NS,kdo),e(Kp,Rdo),e(F,Sdo),e(F,Zp),e(Zp,fZ),e(fZ,Pdo),e(Zp,$do),e(Zp,qS),e(qS,Ido),e(Zp,jdo),e(F,Ddo),e(F,e_),e(e_,mZ),e(mZ,Ndo),e(e_,qdo),e(e_,OS),e(OS,Odo),e(e_,Gdo),e(F,Xdo),e(F,o_),e(o_,gZ),e(gZ,Vdo),e(o_,zdo),e(o_,GS),e(GS,Wdo),e(o_,Qdo),e(F,Hdo),e(F,r_),e(r_,hZ),e(hZ,Udo),e(r_,Jdo),e(r_,XS),e(XS,Ydo),e(r_,Kdo),e(F,Zdo),e(F,t_),e(t_,pZ),e(pZ,eco),e(t_,oco),e(t_,VS),e(VS,rco),e(t_,tco),e(F,aco),e(F,a_),e(a_,_Z),e(_Z,nco),e(a_,sco),e(a_,zS),e(zS,lco),e(a_,ico),e(F,dco),e(F,n_),e(n_,uZ),e(uZ,cco),e(n_,fco),e(n_,WS),e(WS,mco),e(n_,gco),e(F,hco),e(F,s_),e(s_,bZ),e(bZ,pco),e(s_,_co),e(s_,QS),e(QS,uco),e(s_,bco),e(F,vco),e(F,l_),e(l_,vZ),e(vZ,Tco),e(l_,Fco),e(l_,HS),e(HS,Cco),e(l_,Mco),e(F,Eco),e(F,i_),e(i_,TZ),e(TZ,yco),e(i_,wco),e(i_,US),e(US,Aco),e(i_,Lco),e(F,Bco),e(F,d_),e(d_,FZ),e(FZ,xco),e(d_,kco),e(d_,JS),e(JS,Rco),e(d_,Sco),e(F,Pco),e(F,c_),e(c_,CZ),e(CZ,$co),e(c_,Ico),e(c_,YS),e(YS,jco),e(c_,Dco),e(F,Nco),e(F,f_),e(f_,MZ),e(MZ,qco),e(f_,Oco),e(f_,KS),e(KS,Gco),e(f_,Xco),e(F,Vco),e(F,m_),e(m_,EZ),e(EZ,zco),e(m_,Wco),e(m_,ZS),e(ZS,Qco),e(m_,Hco),e(F,Uco),e(F,g_),e(g_,yZ),e(yZ,Jco),e(g_,Yco),e(g_,eP),e(eP,Kco),e(g_,Zco),e(F,efo),e(F,h_),e(h_,wZ),e(wZ,ofo),e(h_,rfo),e(h_,oP),e(oP,tfo),e(h_,afo),e(F,nfo),e(F,p_),e(p_,AZ),e(AZ,sfo),e(p_,lfo),e(p_,rP),e(rP,ifo),e(p_,dfo),e(F,cfo),e(F,__),e(__,LZ),e(LZ,ffo),e(__,mfo),e(__,tP),e(tP,gfo),e(__,hfo),e(F,pfo),e(F,u_),e(u_,BZ),e(BZ,_fo),e(u_,ufo),e(u_,aP),e(aP,bfo),e(u_,vfo),e(De,Tfo),e(De,b_),e(b_,Ffo),e(b_,xZ),e(xZ,Cfo),e(b_,Mfo),e(b_,kZ),e(kZ,Efo),e(De,yfo),e(De,RZ),e(RZ,wfo),e(De,Afo),g($E,De,null),b(c,Bxe,u),b(c,Zi,u),e(Zi,v_),e(v_,SZ),g(IE,SZ,null),e(Zi,Lfo),e(Zi,PZ),e(PZ,Bfo),b(c,xxe,u),b(c,Yo,u),g(jE,Yo,null),e(Yo,xfo),e(Yo,ed),e(ed,kfo),e(ed,$Z),e($Z,Rfo),e(ed,Sfo),e(ed,IZ),e(IZ,Pfo),e(ed,$fo),e(Yo,Ifo),e(Yo,DE),e(DE,jfo),e(DE,jZ),e(jZ,Dfo),e(DE,Nfo),e(Yo,qfo),e(Yo,zr),g(NE,zr,null),e(zr,Ofo),e(zr,DZ),e(DZ,Gfo),e(zr,Xfo),e(zr,od),e(od,Vfo),e(od,NZ),e(NZ,zfo),e(od,Wfo),e(od,qZ),e(qZ,Qfo),e(od,Hfo),e(zr,Ufo),e(zr,OZ),e(OZ,Jfo),e(zr,Yfo),g(qE,zr,null),e(Yo,Kfo),e(Yo,Ne),g(OE,Ne,null),e(Ne,Zfo),e(Ne,GZ),e(GZ,emo),e(Ne,omo),e(Ne,Va),e(Va,rmo),e(Va,XZ),e(XZ,tmo),e(Va,amo),e(Va,VZ),e(VZ,nmo),e(Va,smo),e(Va,zZ),e(zZ,lmo),e(Va,imo),e(Ne,dmo),e(Ne,k),e(k,T_),e(T_,WZ),e(WZ,cmo),e(T_,fmo),e(T_,nP),e(nP,mmo),e(T_,gmo),e(k,hmo),e(k,F_),e(F_,QZ),e(QZ,pmo),e(F_,_mo),e(F_,sP),e(sP,umo),e(F_,bmo),e(k,vmo),e(k,C_),e(C_,HZ),e(HZ,Tmo),e(C_,Fmo),e(C_,lP),e(lP,Cmo),e(C_,Mmo),e(k,Emo),e(k,M_),e(M_,UZ),e(UZ,ymo),e(M_,wmo),e(M_,iP),e(iP,Amo),e(M_,Lmo),e(k,Bmo),e(k,E_),e(E_,JZ),e(JZ,xmo),e(E_,kmo),e(E_,dP),e(dP,Rmo),e(E_,Smo),e(k,Pmo),e(k,y_),e(y_,YZ),e(YZ,$mo),e(y_,Imo),e(y_,cP),e(cP,jmo),e(y_,Dmo),e(k,Nmo),e(k,w_),e(w_,KZ),e(KZ,qmo),e(w_,Omo),e(w_,fP),e(fP,Gmo),e(w_,Xmo),e(k,Vmo),e(k,A_),e(A_,ZZ),e(ZZ,zmo),e(A_,Wmo),e(A_,mP),e(mP,Qmo),e(A_,Hmo),e(k,Umo),e(k,L_),e(L_,eee),e(eee,Jmo),e(L_,Ymo),e(L_,gP),e(gP,Kmo),e(L_,Zmo),e(k,ego),e(k,B_),e(B_,oee),e(oee,ogo),e(B_,rgo),e(B_,hP),e(hP,tgo),e(B_,ago),e(k,ngo),e(k,x_),e(x_,ree),e(ree,sgo),e(x_,lgo),e(x_,pP),e(pP,igo),e(x_,dgo),e(k,cgo),e(k,k_),e(k_,tee),e(tee,fgo),e(k_,mgo),e(k_,_P),e(_P,ggo),e(k_,hgo),e(k,pgo),e(k,R_),e(R_,aee),e(aee,_go),e(R_,ugo),e(R_,uP),e(uP,bgo),e(R_,vgo),e(k,Tgo),e(k,S_),e(S_,nee),e(nee,Fgo),e(S_,Cgo),e(S_,bP),e(bP,Mgo),e(S_,Ego),e(k,ygo),e(k,P_),e(P_,see),e(see,wgo),e(P_,Ago),e(P_,vP),e(vP,Lgo),e(P_,Bgo),e(k,xgo),e(k,$_),e($_,lee),e(lee,kgo),e($_,Rgo),e($_,TP),e(TP,Sgo),e($_,Pgo),e(k,$go),e(k,I_),e(I_,iee),e(iee,Igo),e(I_,jgo),e(I_,FP),e(FP,Dgo),e(I_,Ngo),e(k,qgo),e(k,j_),e(j_,dee),e(dee,Ogo),e(j_,Ggo),e(j_,CP),e(CP,Xgo),e(j_,Vgo),e(k,zgo),e(k,D_),e(D_,cee),e(cee,Wgo),e(D_,Qgo),e(D_,MP),e(MP,Hgo),e(D_,Ugo),e(k,Jgo),e(k,N_),e(N_,fee),e(fee,Ygo),e(N_,Kgo),e(N_,EP),e(EP,Zgo),e(N_,eho),e(k,oho),e(k,q_),e(q_,mee),e(mee,rho),e(q_,tho),e(q_,yP),e(yP,aho),e(q_,nho),e(k,sho),e(k,O_),e(O_,gee),e(gee,lho),e(O_,iho),e(O_,wP),e(wP,dho),e(O_,cho),e(k,fho),e(k,G_),e(G_,hee),e(hee,mho),e(G_,gho),e(G_,AP),e(AP,hho),e(G_,pho),e(k,_ho),e(k,X_),e(X_,pee),e(pee,uho),e(X_,bho),e(X_,LP),e(LP,vho),e(X_,Tho),e(k,Fho),e(k,V_),e(V_,_ee),e(_ee,Cho),e(V_,Mho),e(V_,BP),e(BP,Eho),e(V_,yho),e(k,who),e(k,z_),e(z_,uee),e(uee,Aho),e(z_,Lho),e(z_,xP),e(xP,Bho),e(z_,xho),e(k,kho),e(k,W_),e(W_,bee),e(bee,Rho),e(W_,Sho),e(W_,kP),e(kP,Pho),e(W_,$ho),e(k,Iho),e(k,Q_),e(Q_,vee),e(vee,jho),e(Q_,Dho),e(Q_,RP),e(RP,Nho),e(Q_,qho),e(k,Oho),e(k,H_),e(H_,Tee),e(Tee,Gho),e(H_,Xho),e(H_,SP),e(SP,Vho),e(H_,zho),e(k,Who),e(k,U_),e(U_,Fee),e(Fee,Qho),e(U_,Hho),e(U_,PP),e(PP,Uho),e(U_,Jho),e(k,Yho),e(k,J_),e(J_,Cee),e(Cee,Kho),e(J_,Zho),e(J_,$P),e($P,epo),e(J_,opo),e(k,rpo),e(k,Y_),e(Y_,Mee),e(Mee,tpo),e(Y_,apo),e(Y_,IP),e(IP,npo),e(Y_,spo),e(k,lpo),e(k,K_),e(K_,Eee),e(Eee,ipo),e(K_,dpo),e(K_,jP),e(jP,cpo),e(K_,fpo),e(k,mpo),e(k,Z_),e(Z_,yee),e(yee,gpo),e(Z_,hpo),e(Z_,DP),e(DP,ppo),e(Z_,_po),e(k,upo),e(k,eu),e(eu,wee),e(wee,bpo),e(eu,vpo),e(eu,NP),e(NP,Tpo),e(eu,Fpo),e(k,Cpo),e(k,ou),e(ou,Aee),e(Aee,Mpo),e(ou,Epo),e(ou,qP),e(qP,ypo),e(ou,wpo),e(k,Apo),e(k,ru),e(ru,Lee),e(Lee,Lpo),e(ru,Bpo),e(ru,OP),e(OP,xpo),e(ru,kpo),e(k,Rpo),e(k,tu),e(tu,Bee),e(Bee,Spo),e(tu,Ppo),e(tu,GP),e(GP,$po),e(tu,Ipo),e(k,jpo),e(k,au),e(au,xee),e(xee,Dpo),e(au,Npo),e(au,XP),e(XP,qpo),e(au,Opo),e(Ne,Gpo),e(Ne,nu),e(nu,Xpo),e(nu,kee),e(kee,Vpo),e(nu,zpo),e(nu,Ree),e(Ree,Wpo),e(Ne,Qpo),e(Ne,See),e(See,Hpo),e(Ne,Upo),g(GE,Ne,null),b(c,kxe,u),b(c,rd,u),e(rd,su),e(su,Pee),g(XE,Pee,null),e(rd,Jpo),e(rd,$ee),e($ee,Ypo),b(c,Rxe,u),b(c,Ko,u),g(VE,Ko,null),e(Ko,Kpo),e(Ko,td),e(td,Zpo),e(td,Iee),e(Iee,e_o),e(td,o_o),e(td,jee),e(jee,r_o),e(td,t_o),e(Ko,a_o),e(Ko,zE),e(zE,n_o),e(zE,Dee),e(Dee,s_o),e(zE,l_o),e(Ko,i_o),e(Ko,Wr),g(WE,Wr,null),e(Wr,d_o),e(Wr,Nee),e(Nee,c_o),e(Wr,f_o),e(Wr,ad),e(ad,m_o),e(ad,qee),e(qee,g_o),e(ad,h_o),e(ad,Oee),e(Oee,p_o),e(ad,__o),e(Wr,u_o),e(Wr,Gee),e(Gee,b_o),e(Wr,v_o),g(QE,Wr,null),e(Ko,T_o),e(Ko,qe),g(HE,qe,null),e(qe,F_o),e(qe,Xee),e(Xee,C_o),e(qe,M_o),e(qe,za),e(za,E_o),e(za,Vee),e(Vee,y_o),e(za,w_o),e(za,zee),e(zee,A_o),e(za,L_o),e(za,Wee),e(Wee,B_o),e(za,x_o),e(qe,k_o),e(qe,$),e($,lu),e(lu,Qee),e(Qee,R_o),e(lu,S_o),e(lu,VP),e(VP,P_o),e(lu,$_o),e($,I_o),e($,iu),e(iu,Hee),e(Hee,j_o),e(iu,D_o),e(iu,zP),e(zP,N_o),e(iu,q_o),e($,O_o),e($,du),e(du,Uee),e(Uee,G_o),e(du,X_o),e(du,WP),e(WP,V_o),e(du,z_o),e($,W_o),e($,cu),e(cu,Jee),e(Jee,Q_o),e(cu,H_o),e(cu,QP),e(QP,U_o),e(cu,J_o),e($,Y_o),e($,fu),e(fu,Yee),e(Yee,K_o),e(fu,Z_o),e(fu,HP),e(HP,euo),e(fu,ouo),e($,ruo),e($,mu),e(mu,Kee),e(Kee,tuo),e(mu,auo),e(mu,UP),e(UP,nuo),e(mu,suo),e($,luo),e($,gu),e(gu,Zee),e(Zee,iuo),e(gu,duo),e(gu,JP),e(JP,cuo),e(gu,fuo),e($,muo),e($,hu),e(hu,eoe),e(eoe,guo),e(hu,huo),e(hu,YP),e(YP,puo),e(hu,_uo),e($,uuo),e($,pu),e(pu,ooe),e(ooe,buo),e(pu,vuo),e(pu,KP),e(KP,Tuo),e(pu,Fuo),e($,Cuo),e($,_u),e(_u,roe),e(roe,Muo),e(_u,Euo),e(_u,ZP),e(ZP,yuo),e(_u,wuo),e($,Auo),e($,uu),e(uu,toe),e(toe,Luo),e(uu,Buo),e(uu,e$),e(e$,xuo),e(uu,kuo),e($,Ruo),e($,bu),e(bu,aoe),e(aoe,Suo),e(bu,Puo),e(bu,o$),e(o$,$uo),e(bu,Iuo),e($,juo),e($,vu),e(vu,noe),e(noe,Duo),e(vu,Nuo),e(vu,r$),e(r$,quo),e(vu,Ouo),e($,Guo),e($,Tu),e(Tu,soe),e(soe,Xuo),e(Tu,Vuo),e(Tu,t$),e(t$,zuo),e(Tu,Wuo),e($,Quo),e($,Fu),e(Fu,loe),e(loe,Huo),e(Fu,Uuo),e(Fu,a$),e(a$,Juo),e(Fu,Yuo),e($,Kuo),e($,Cu),e(Cu,ioe),e(ioe,Zuo),e(Cu,e1o),e(Cu,n$),e(n$,o1o),e(Cu,r1o),e($,t1o),e($,Mu),e(Mu,doe),e(doe,a1o),e(Mu,n1o),e(Mu,s$),e(s$,s1o),e(Mu,l1o),e($,i1o),e($,Eu),e(Eu,coe),e(coe,d1o),e(Eu,c1o),e(Eu,l$),e(l$,f1o),e(Eu,m1o),e($,g1o),e($,yu),e(yu,foe),e(foe,h1o),e(yu,p1o),e(yu,i$),e(i$,_1o),e(yu,u1o),e($,b1o),e($,wu),e(wu,moe),e(moe,v1o),e(wu,T1o),e(wu,d$),e(d$,F1o),e(wu,C1o),e($,M1o),e($,Au),e(Au,goe),e(goe,E1o),e(Au,y1o),e(Au,c$),e(c$,w1o),e(Au,A1o),e($,L1o),e($,Lu),e(Lu,hoe),e(hoe,B1o),e(Lu,x1o),e(Lu,f$),e(f$,k1o),e(Lu,R1o),e($,S1o),e($,Bu),e(Bu,poe),e(poe,P1o),e(Bu,$1o),e(Bu,m$),e(m$,I1o),e(Bu,j1o),e($,D1o),e($,xu),e(xu,_oe),e(_oe,N1o),e(xu,q1o),e(xu,g$),e(g$,O1o),e(xu,G1o),e($,X1o),e($,ku),e(ku,uoe),e(uoe,V1o),e(ku,z1o),e(ku,h$),e(h$,W1o),e(ku,Q1o),e($,H1o),e($,Ru),e(Ru,boe),e(boe,U1o),e(Ru,J1o),e(Ru,p$),e(p$,Y1o),e(Ru,K1o),e($,Z1o),e($,Su),e(Su,voe),e(voe,e7o),e(Su,o7o),e(Su,_$),e(_$,r7o),e(Su,t7o),e($,a7o),e($,Pu),e(Pu,Toe),e(Toe,n7o),e(Pu,s7o),e(Pu,u$),e(u$,l7o),e(Pu,i7o),e($,d7o),e($,$u),e($u,Foe),e(Foe,c7o),e($u,f7o),e($u,b$),e(b$,m7o),e($u,g7o),e($,h7o),e($,Iu),e(Iu,Coe),e(Coe,p7o),e(Iu,_7o),e(Iu,v$),e(v$,u7o),e(Iu,b7o),e($,v7o),e($,ju),e(ju,Moe),e(Moe,T7o),e(ju,F7o),e(ju,T$),e(T$,C7o),e(ju,M7o),e($,E7o),e($,Du),e(Du,Eoe),e(Eoe,y7o),e(Du,w7o),e(Du,F$),e(F$,A7o),e(Du,L7o),e($,B7o),e($,Nu),e(Nu,yoe),e(yoe,x7o),e(Nu,k7o),e(Nu,C$),e(C$,R7o),e(Nu,S7o),e($,P7o),e($,qu),e(qu,woe),e(woe,$7o),e(qu,I7o),e(qu,M$),e(M$,j7o),e(qu,D7o),e($,N7o),e($,Ou),e(Ou,Aoe),e(Aoe,q7o),e(Ou,O7o),e(Ou,E$),e(E$,G7o),e(Ou,X7o),e(qe,V7o),e(qe,Gu),e(Gu,z7o),e(Gu,Loe),e(Loe,W7o),e(Gu,Q7o),e(Gu,Boe),e(Boe,H7o),e(qe,U7o),e(qe,xoe),e(xoe,J7o),e(qe,Y7o),g(UE,qe,null),b(c,Sxe,u),b(c,nd,u),e(nd,Xu),e(Xu,koe),g(JE,koe,null),e(nd,K7o),e(nd,Roe),e(Roe,Z7o),b(c,Pxe,u),b(c,Zo,u),g(YE,Zo,null),e(Zo,ebo),e(Zo,sd),e(sd,obo),e(sd,Soe),e(Soe,rbo),e(sd,tbo),e(sd,Poe),e(Poe,abo),e(sd,nbo),e(Zo,sbo),e(Zo,KE),e(KE,lbo),e(KE,$oe),e($oe,ibo),e(KE,dbo),e(Zo,cbo),e(Zo,Qr),g(ZE,Qr,null),e(Qr,fbo),e(Qr,Ioe),e(Ioe,mbo),e(Qr,gbo),e(Qr,ld),e(ld,hbo),e(ld,joe),e(joe,pbo),e(ld,_bo),e(ld,Doe),e(Doe,ubo),e(ld,bbo),e(Qr,vbo),e(Qr,Noe),e(Noe,Tbo),e(Qr,Fbo),g(e3,Qr,null),e(Zo,Cbo),e(Zo,Oe),g(o3,Oe,null),e(Oe,Mbo),e(Oe,qoe),e(qoe,Ebo),e(Oe,ybo),e(Oe,Wa),e(Wa,wbo),e(Wa,Ooe),e(Ooe,Abo),e(Wa,Lbo),e(Wa,Goe),e(Goe,Bbo),e(Wa,xbo),e(Wa,Xoe),e(Xoe,kbo),e(Wa,Rbo),e(Oe,Sbo),e(Oe,I),e(I,Vu),e(Vu,Voe),e(Voe,Pbo),e(Vu,$bo),e(Vu,y$),e(y$,Ibo),e(Vu,jbo),e(I,Dbo),e(I,zu),e(zu,zoe),e(zoe,Nbo),e(zu,qbo),e(zu,w$),e(w$,Obo),e(zu,Gbo),e(I,Xbo),e(I,Wu),e(Wu,Woe),e(Woe,Vbo),e(Wu,zbo),e(Wu,A$),e(A$,Wbo),e(Wu,Qbo),e(I,Hbo),e(I,Qu),e(Qu,Qoe),e(Qoe,Ubo),e(Qu,Jbo),e(Qu,L$),e(L$,Ybo),e(Qu,Kbo),e(I,Zbo),e(I,Hu),e(Hu,Hoe),e(Hoe,e5o),e(Hu,o5o),e(Hu,B$),e(B$,r5o),e(Hu,t5o),e(I,a5o),e(I,Uu),e(Uu,Uoe),e(Uoe,n5o),e(Uu,s5o),e(Uu,x$),e(x$,l5o),e(Uu,i5o),e(I,d5o),e(I,Ju),e(Ju,Joe),e(Joe,c5o),e(Ju,f5o),e(Ju,k$),e(k$,m5o),e(Ju,g5o),e(I,h5o),e(I,Yu),e(Yu,Yoe),e(Yoe,p5o),e(Yu,_5o),e(Yu,R$),e(R$,u5o),e(Yu,b5o),e(I,v5o),e(I,Ku),e(Ku,Koe),e(Koe,T5o),e(Ku,F5o),e(Ku,S$),e(S$,C5o),e(Ku,M5o),e(I,E5o),e(I,Zu),e(Zu,Zoe),e(Zoe,y5o),e(Zu,w5o),e(Zu,P$),e(P$,A5o),e(Zu,L5o),e(I,B5o),e(I,e1),e(e1,ere),e(ere,x5o),e(e1,k5o),e(e1,$$),e($$,R5o),e(e1,S5o),e(I,P5o),e(I,o1),e(o1,ore),e(ore,$5o),e(o1,I5o),e(o1,I$),e(I$,j5o),e(o1,D5o),e(I,N5o),e(I,r1),e(r1,rre),e(rre,q5o),e(r1,O5o),e(r1,j$),e(j$,G5o),e(r1,X5o),e(I,V5o),e(I,t1),e(t1,tre),e(tre,z5o),e(t1,W5o),e(t1,D$),e(D$,Q5o),e(t1,H5o),e(I,U5o),e(I,a1),e(a1,are),e(are,J5o),e(a1,Y5o),e(a1,N$),e(N$,K5o),e(a1,Z5o),e(I,e2o),e(I,n1),e(n1,nre),e(nre,o2o),e(n1,r2o),e(n1,q$),e(q$,t2o),e(n1,a2o),e(I,n2o),e(I,s1),e(s1,sre),e(sre,s2o),e(s1,l2o),e(s1,O$),e(O$,i2o),e(s1,d2o),e(I,c2o),e(I,l1),e(l1,lre),e(lre,f2o),e(l1,m2o),e(l1,G$),e(G$,g2o),e(l1,h2o),e(I,p2o),e(I,i1),e(i1,ire),e(ire,_2o),e(i1,u2o),e(i1,X$),e(X$,b2o),e(i1,v2o),e(I,T2o),e(I,d1),e(d1,dre),e(dre,F2o),e(d1,C2o),e(d1,V$),e(V$,M2o),e(d1,E2o),e(I,y2o),e(I,c1),e(c1,cre),e(cre,w2o),e(c1,A2o),e(c1,z$),e(z$,L2o),e(c1,B2o),e(I,x2o),e(I,f1),e(f1,fre),e(fre,k2o),e(f1,R2o),e(f1,W$),e(W$,S2o),e(f1,P2o),e(I,$2o),e(I,m1),e(m1,mre),e(mre,I2o),e(m1,j2o),e(m1,Q$),e(Q$,D2o),e(m1,N2o),e(I,q2o),e(I,g1),e(g1,gre),e(gre,O2o),e(g1,G2o),e(g1,H$),e(H$,X2o),e(g1,V2o),e(I,z2o),e(I,h1),e(h1,hre),e(hre,W2o),e(h1,Q2o),e(h1,U$),e(U$,H2o),e(h1,U2o),e(I,J2o),e(I,p1),e(p1,pre),e(pre,Y2o),e(p1,K2o),e(p1,J$),e(J$,Z2o),e(p1,evo),e(I,ovo),e(I,_1),e(_1,_re),e(_re,rvo),e(_1,tvo),e(_1,Y$),e(Y$,avo),e(_1,nvo),e(I,svo),e(I,u1),e(u1,ure),e(ure,lvo),e(u1,ivo),e(u1,K$),e(K$,dvo),e(u1,cvo),e(I,fvo),e(I,b1),e(b1,bre),e(bre,mvo),e(b1,gvo),e(b1,Z$),e(Z$,hvo),e(b1,pvo),e(I,_vo),e(I,v1),e(v1,vre),e(vre,uvo),e(v1,bvo),e(v1,eI),e(eI,vvo),e(v1,Tvo),e(I,Fvo),e(I,T1),e(T1,Tre),e(Tre,Cvo),e(T1,Mvo),e(T1,Fre),e(Fre,Evo),e(T1,yvo),e(I,wvo),e(I,F1),e(F1,Cre),e(Cre,Avo),e(F1,Lvo),e(F1,oI),e(oI,Bvo),e(F1,xvo),e(I,kvo),e(I,C1),e(C1,Mre),e(Mre,Rvo),e(C1,Svo),e(C1,rI),e(rI,Pvo),e(C1,$vo),e(I,Ivo),e(I,M1),e(M1,Ere),e(Ere,jvo),e(M1,Dvo),e(M1,tI),e(tI,Nvo),e(M1,qvo),e(I,Ovo),e(I,E1),e(E1,yre),e(yre,Gvo),e(E1,Xvo),e(E1,aI),e(aI,Vvo),e(E1,zvo),e(Oe,Wvo),e(Oe,y1),e(y1,Qvo),e(y1,wre),e(wre,Hvo),e(y1,Uvo),e(y1,Are),e(Are,Jvo),e(Oe,Yvo),e(Oe,Lre),e(Lre,Kvo),e(Oe,Zvo),g(r3,Oe,null),b(c,$xe,u),b(c,id,u),e(id,w1),e(w1,Bre),g(t3,Bre,null),e(id,e0o),e(id,xre),e(xre,o0o),b(c,Ixe,u),b(c,er,u),g(a3,er,null),e(er,r0o),e(er,dd),e(dd,t0o),e(dd,kre),e(kre,a0o),e(dd,n0o),e(dd,Rre),e(Rre,s0o),e(dd,l0o),e(er,i0o),e(er,n3),e(n3,d0o),e(n3,Sre),e(Sre,c0o),e(n3,f0o),e(er,m0o),e(er,Hr),g(s3,Hr,null),e(Hr,g0o),e(Hr,Pre),e(Pre,h0o),e(Hr,p0o),e(Hr,cd),e(cd,_0o),e(cd,$re),e($re,u0o),e(cd,b0o),e(cd,Ire),e(Ire,v0o),e(cd,T0o),e(Hr,F0o),e(Hr,jre),e(jre,C0o),e(Hr,M0o),g(l3,Hr,null),e(er,E0o),e(er,Ge),g(i3,Ge,null),e(Ge,y0o),e(Ge,Dre),e(Dre,w0o),e(Ge,A0o),e(Ge,Qa),e(Qa,L0o),e(Qa,Nre),e(Nre,B0o),e(Qa,x0o),e(Qa,qre),e(qre,k0o),e(Qa,R0o),e(Qa,Ore),e(Ore,S0o),e(Qa,P0o),e(Ge,$0o),e(Ge,ne),e(ne,A1),e(A1,Gre),e(Gre,I0o),e(A1,j0o),e(A1,nI),e(nI,D0o),e(A1,N0o),e(ne,q0o),e(ne,L1),e(L1,Xre),e(Xre,O0o),e(L1,G0o),e(L1,sI),e(sI,X0o),e(L1,V0o),e(ne,z0o),e(ne,B1),e(B1,Vre),e(Vre,W0o),e(B1,Q0o),e(B1,lI),e(lI,H0o),e(B1,U0o),e(ne,J0o),e(ne,x1),e(x1,zre),e(zre,Y0o),e(x1,K0o),e(x1,iI),e(iI,Z0o),e(x1,eTo),e(ne,oTo),e(ne,k1),e(k1,Wre),e(Wre,rTo),e(k1,tTo),e(k1,dI),e(dI,aTo),e(k1,nTo),e(ne,sTo),e(ne,R1),e(R1,Qre),e(Qre,lTo),e(R1,iTo),e(R1,cI),e(cI,dTo),e(R1,cTo),e(ne,fTo),e(ne,S1),e(S1,Hre),e(Hre,mTo),e(S1,gTo),e(S1,fI),e(fI,hTo),e(S1,pTo),e(ne,_To),e(ne,P1),e(P1,Ure),e(Ure,uTo),e(P1,bTo),e(P1,mI),e(mI,vTo),e(P1,TTo),e(ne,FTo),e(ne,$1),e($1,Jre),e(Jre,CTo),e($1,MTo),e($1,gI),e(gI,ETo),e($1,yTo),e(ne,wTo),e(ne,I1),e(I1,Yre),e(Yre,ATo),e(I1,LTo),e(I1,hI),e(hI,BTo),e(I1,xTo),e(ne,kTo),e(ne,j1),e(j1,Kre),e(Kre,RTo),e(j1,STo),e(j1,pI),e(pI,PTo),e(j1,$To),e(ne,ITo),e(ne,D1),e(D1,Zre),e(Zre,jTo),e(D1,DTo),e(D1,_I),e(_I,NTo),e(D1,qTo),e(ne,OTo),e(ne,N1),e(N1,ete),e(ete,GTo),e(N1,XTo),e(N1,uI),e(uI,VTo),e(N1,zTo),e(ne,WTo),e(ne,q1),e(q1,ote),e(ote,QTo),e(q1,HTo),e(q1,bI),e(bI,UTo),e(q1,JTo),e(ne,YTo),e(ne,O1),e(O1,rte),e(rte,KTo),e(O1,ZTo),e(O1,vI),e(vI,eFo),e(O1,oFo),e(ne,rFo),e(ne,G1),e(G1,tte),e(tte,tFo),e(G1,aFo),e(G1,TI),e(TI,nFo),e(G1,sFo),e(Ge,lFo),e(Ge,X1),e(X1,iFo),e(X1,ate),e(ate,dFo),e(X1,cFo),e(X1,nte),e(nte,fFo),e(Ge,mFo),e(Ge,ste),e(ste,gFo),e(Ge,hFo),g(d3,Ge,null),b(c,jxe,u),b(c,fd,u),e(fd,V1),e(V1,lte),g(c3,lte,null),e(fd,pFo),e(fd,ite),e(ite,_Fo),b(c,Dxe,u),b(c,or,u),g(f3,or,null),e(or,uFo),e(or,md),e(md,bFo),e(md,dte),e(dte,vFo),e(md,TFo),e(md,cte),e(cte,FFo),e(md,CFo),e(or,MFo),e(or,m3),e(m3,EFo),e(m3,fte),e(fte,yFo),e(m3,wFo),e(or,AFo),e(or,Ur),g(g3,Ur,null),e(Ur,LFo),e(Ur,mte),e(mte,BFo),e(Ur,xFo),e(Ur,gd),e(gd,kFo),e(gd,gte),e(gte,RFo),e(gd,SFo),e(gd,hte),e(hte,PFo),e(gd,$Fo),e(Ur,IFo),e(Ur,pte),e(pte,jFo),e(Ur,DFo),g(h3,Ur,null),e(or,NFo),e(or,Xe),g(p3,Xe,null),e(Xe,qFo),e(Xe,_te),e(_te,OFo),e(Xe,GFo),e(Xe,Ha),e(Ha,XFo),e(Ha,ute),e(ute,VFo),e(Ha,zFo),e(Ha,bte),e(bte,WFo),e(Ha,QFo),e(Ha,vte),e(vte,HFo),e(Ha,UFo),e(Xe,JFo),e(Xe,A),e(A,z1),e(z1,Tte),e(Tte,YFo),e(z1,KFo),e(z1,FI),e(FI,ZFo),e(z1,eCo),e(A,oCo),e(A,W1),e(W1,Fte),e(Fte,rCo),e(W1,tCo),e(W1,CI),e(CI,aCo),e(W1,nCo),e(A,sCo),e(A,Q1),e(Q1,Cte),e(Cte,lCo),e(Q1,iCo),e(Q1,MI),e(MI,dCo),e(Q1,cCo),e(A,fCo),e(A,H1),e(H1,Mte),e(Mte,mCo),e(H1,gCo),e(H1,EI),e(EI,hCo),e(H1,pCo),e(A,_Co),e(A,U1),e(U1,Ete),e(Ete,uCo),e(U1,bCo),e(U1,yI),e(yI,vCo),e(U1,TCo),e(A,FCo),e(A,J1),e(J1,yte),e(yte,CCo),e(J1,MCo),e(J1,wI),e(wI,ECo),e(J1,yCo),e(A,wCo),e(A,Y1),e(Y1,wte),e(wte,ACo),e(Y1,LCo),e(Y1,AI),e(AI,BCo),e(Y1,xCo),e(A,kCo),e(A,K1),e(K1,Ate),e(Ate,RCo),e(K1,SCo),e(K1,LI),e(LI,PCo),e(K1,$Co),e(A,ICo),e(A,Z1),e(Z1,Lte),e(Lte,jCo),e(Z1,DCo),e(Z1,BI),e(BI,NCo),e(Z1,qCo),e(A,OCo),e(A,e7),e(e7,Bte),e(Bte,GCo),e(e7,XCo),e(e7,xI),e(xI,VCo),e(e7,zCo),e(A,WCo),e(A,o7),e(o7,xte),e(xte,QCo),e(o7,HCo),e(o7,kI),e(kI,UCo),e(o7,JCo),e(A,YCo),e(A,r7),e(r7,kte),e(kte,KCo),e(r7,ZCo),e(r7,RI),e(RI,eMo),e(r7,oMo),e(A,rMo),e(A,t7),e(t7,Rte),e(Rte,tMo),e(t7,aMo),e(t7,SI),e(SI,nMo),e(t7,sMo),e(A,lMo),e(A,a7),e(a7,Ste),e(Ste,iMo),e(a7,dMo),e(a7,PI),e(PI,cMo),e(a7,fMo),e(A,mMo),e(A,n7),e(n7,Pte),e(Pte,gMo),e(n7,hMo),e(n7,$I),e($I,pMo),e(n7,_Mo),e(A,uMo),e(A,s7),e(s7,$te),e($te,bMo),e(s7,vMo),e(s7,II),e(II,TMo),e(s7,FMo),e(A,CMo),e(A,l7),e(l7,Ite),e(Ite,MMo),e(l7,EMo),e(l7,jI),e(jI,yMo),e(l7,wMo),e(A,AMo),e(A,i7),e(i7,jte),e(jte,LMo),e(i7,BMo),e(i7,DI),e(DI,xMo),e(i7,kMo),e(A,RMo),e(A,d7),e(d7,Dte),e(Dte,SMo),e(d7,PMo),e(d7,NI),e(NI,$Mo),e(d7,IMo),e(A,jMo),e(A,c7),e(c7,Nte),e(Nte,DMo),e(c7,NMo),e(c7,qI),e(qI,qMo),e(c7,OMo),e(A,GMo),e(A,f7),e(f7,qte),e(qte,XMo),e(f7,VMo),e(f7,OI),e(OI,zMo),e(f7,WMo),e(A,QMo),e(A,m7),e(m7,Ote),e(Ote,HMo),e(m7,UMo),e(m7,GI),e(GI,JMo),e(m7,YMo),e(A,KMo),e(A,g7),e(g7,Gte),e(Gte,ZMo),e(g7,e4o),e(g7,XI),e(XI,o4o),e(g7,r4o),e(A,t4o),e(A,h7),e(h7,Xte),e(Xte,a4o),e(h7,n4o),e(h7,VI),e(VI,s4o),e(h7,l4o),e(A,i4o),e(A,p7),e(p7,Vte),e(Vte,d4o),e(p7,c4o),e(p7,zI),e(zI,f4o),e(p7,m4o),e(A,g4o),e(A,_7),e(_7,zte),e(zte,h4o),e(_7,p4o),e(_7,WI),e(WI,_4o),e(_7,u4o),e(A,b4o),e(A,u7),e(u7,Wte),e(Wte,v4o),e(u7,T4o),e(u7,QI),e(QI,F4o),e(u7,C4o),e(A,M4o),e(A,b7),e(b7,Qte),e(Qte,E4o),e(b7,y4o),e(b7,HI),e(HI,w4o),e(b7,A4o),e(A,L4o),e(A,v7),e(v7,Hte),e(Hte,B4o),e(v7,x4o),e(v7,UI),e(UI,k4o),e(v7,R4o),e(A,S4o),e(A,T7),e(T7,Ute),e(Ute,P4o),e(T7,$4o),e(T7,JI),e(JI,I4o),e(T7,j4o),e(A,D4o),e(A,F7),e(F7,Jte),e(Jte,N4o),e(F7,q4o),e(F7,YI),e(YI,O4o),e(F7,G4o),e(A,X4o),e(A,C7),e(C7,Yte),e(Yte,V4o),e(C7,z4o),e(C7,KI),e(KI,W4o),e(C7,Q4o),e(A,H4o),e(A,M7),e(M7,Kte),e(Kte,U4o),e(M7,J4o),e(M7,ZI),e(ZI,Y4o),e(M7,K4o),e(A,Z4o),e(A,E7),e(E7,Zte),e(Zte,eEo),e(E7,oEo),e(E7,ej),e(ej,rEo),e(E7,tEo),e(A,aEo),e(A,y7),e(y7,eae),e(eae,nEo),e(y7,sEo),e(y7,oj),e(oj,lEo),e(y7,iEo),e(A,dEo),e(A,w7),e(w7,oae),e(oae,cEo),e(w7,fEo),e(w7,rj),e(rj,mEo),e(w7,gEo),e(A,hEo),e(A,A7),e(A7,rae),e(rae,pEo),e(A7,_Eo),e(A7,tj),e(tj,uEo),e(A7,bEo),e(A,vEo),e(A,L7),e(L7,tae),e(tae,TEo),e(L7,FEo),e(L7,aj),e(aj,CEo),e(L7,MEo),e(A,EEo),e(A,B7),e(B7,aae),e(aae,yEo),e(B7,wEo),e(B7,nj),e(nj,AEo),e(B7,LEo),e(A,BEo),e(A,x7),e(x7,nae),e(nae,xEo),e(x7,kEo),e(x7,sj),e(sj,REo),e(x7,SEo),e(A,PEo),e(A,k7),e(k7,sae),e(sae,$Eo),e(k7,IEo),e(k7,lj),e(lj,jEo),e(k7,DEo),e(A,NEo),e(A,R7),e(R7,lae),e(lae,qEo),e(R7,OEo),e(R7,ij),e(ij,GEo),e(R7,XEo),e(A,VEo),e(A,S7),e(S7,iae),e(iae,zEo),e(S7,WEo),e(S7,dj),e(dj,QEo),e(S7,HEo),e(A,UEo),e(A,P7),e(P7,dae),e(dae,JEo),e(P7,YEo),e(P7,cj),e(cj,KEo),e(P7,ZEo),e(A,e3o),e(A,$7),e($7,cae),e(cae,o3o),e($7,r3o),e($7,fj),e(fj,t3o),e($7,a3o),e(A,n3o),e(A,I7),e(I7,fae),e(fae,s3o),e(I7,l3o),e(I7,mj),e(mj,i3o),e(I7,d3o),e(Xe,c3o),e(Xe,j7),e(j7,f3o),e(j7,mae),e(mae,m3o),e(j7,g3o),e(j7,gae),e(gae,h3o),e(Xe,p3o),e(Xe,hae),e(hae,_3o),e(Xe,u3o),g(_3,Xe,null),b(c,Nxe,u),b(c,hd,u),e(hd,D7),e(D7,pae),g(u3,pae,null),e(hd,b3o),e(hd,_ae),e(_ae,v3o),b(c,qxe,u),b(c,rr,u),g(b3,rr,null),e(rr,T3o),e(rr,pd),e(pd,F3o),e(pd,uae),e(uae,C3o),e(pd,M3o),e(pd,bae),e(bae,E3o),e(pd,y3o),e(rr,w3o),e(rr,v3),e(v3,A3o),e(v3,vae),e(vae,L3o),e(v3,B3o),e(rr,x3o),e(rr,Jr),g(T3,Jr,null),e(Jr,k3o),e(Jr,Tae),e(Tae,R3o),e(Jr,S3o),e(Jr,_d),e(_d,P3o),e(_d,Fae),e(Fae,$3o),e(_d,I3o),e(_d,Cae),e(Cae,j3o),e(_d,D3o),e(Jr,N3o),e(Jr,Mae),e(Mae,q3o),e(Jr,O3o),g(F3,Jr,null),e(rr,G3o),e(rr,Ve),g(C3,Ve,null),e(Ve,X3o),e(Ve,Eae),e(Eae,V3o),e(Ve,z3o),e(Ve,Ua),e(Ua,W3o),e(Ua,yae),e(yae,Q3o),e(Ua,H3o),e(Ua,wae),e(wae,U3o),e(Ua,J3o),e(Ua,Aae),e(Aae,Y3o),e(Ua,K3o),e(Ve,Z3o),e(Ve,O),e(O,N7),e(N7,Lae),e(Lae,eyo),e(N7,oyo),e(N7,gj),e(gj,ryo),e(N7,tyo),e(O,ayo),e(O,q7),e(q7,Bae),e(Bae,nyo),e(q7,syo),e(q7,hj),e(hj,lyo),e(q7,iyo),e(O,dyo),e(O,O7),e(O7,xae),e(xae,cyo),e(O7,fyo),e(O7,pj),e(pj,myo),e(O7,gyo),e(O,hyo),e(O,G7),e(G7,kae),e(kae,pyo),e(G7,_yo),e(G7,_j),e(_j,uyo),e(G7,byo),e(O,vyo),e(O,X7),e(X7,Rae),e(Rae,Tyo),e(X7,Fyo),e(X7,uj),e(uj,Cyo),e(X7,Myo),e(O,Eyo),e(O,V7),e(V7,Sae),e(Sae,yyo),e(V7,wyo),e(V7,bj),e(bj,Ayo),e(V7,Lyo),e(O,Byo),e(O,z7),e(z7,Pae),e(Pae,xyo),e(z7,kyo),e(z7,vj),e(vj,Ryo),e(z7,Syo),e(O,Pyo),e(O,W7),e(W7,$ae),e($ae,$yo),e(W7,Iyo),e(W7,Tj),e(Tj,jyo),e(W7,Dyo),e(O,Nyo),e(O,Q7),e(Q7,Iae),e(Iae,qyo),e(Q7,Oyo),e(Q7,Fj),e(Fj,Gyo),e(Q7,Xyo),e(O,Vyo),e(O,H7),e(H7,jae),e(jae,zyo),e(H7,Wyo),e(H7,Cj),e(Cj,Qyo),e(H7,Hyo),e(O,Uyo),e(O,U7),e(U7,Dae),e(Dae,Jyo),e(U7,Yyo),e(U7,Mj),e(Mj,Kyo),e(U7,Zyo),e(O,ewo),e(O,J7),e(J7,Nae),e(Nae,owo),e(J7,rwo),e(J7,Ej),e(Ej,two),e(J7,awo),e(O,nwo),e(O,Y7),e(Y7,qae),e(qae,swo),e(Y7,lwo),e(Y7,yj),e(yj,iwo),e(Y7,dwo),e(O,cwo),e(O,K7),e(K7,Oae),e(Oae,fwo),e(K7,mwo),e(K7,wj),e(wj,gwo),e(K7,hwo),e(O,pwo),e(O,Z7),e(Z7,Gae),e(Gae,_wo),e(Z7,uwo),e(Z7,Aj),e(Aj,bwo),e(Z7,vwo),e(O,Two),e(O,eb),e(eb,Xae),e(Xae,Fwo),e(eb,Cwo),e(eb,Lj),e(Lj,Mwo),e(eb,Ewo),e(O,ywo),e(O,ob),e(ob,Vae),e(Vae,wwo),e(ob,Awo),e(ob,Bj),e(Bj,Lwo),e(ob,Bwo),e(O,xwo),e(O,rb),e(rb,zae),e(zae,kwo),e(rb,Rwo),e(rb,xj),e(xj,Swo),e(rb,Pwo),e(O,$wo),e(O,tb),e(tb,Wae),e(Wae,Iwo),e(tb,jwo),e(tb,kj),e(kj,Dwo),e(tb,Nwo),e(O,qwo),e(O,ab),e(ab,Qae),e(Qae,Owo),e(ab,Gwo),e(ab,Rj),e(Rj,Xwo),e(ab,Vwo),e(O,zwo),e(O,nb),e(nb,Hae),e(Hae,Wwo),e(nb,Qwo),e(nb,Sj),e(Sj,Hwo),e(nb,Uwo),e(O,Jwo),e(O,sb),e(sb,Uae),e(Uae,Ywo),e(sb,Kwo),e(sb,Pj),e(Pj,Zwo),e(sb,e6o),e(O,o6o),e(O,lb),e(lb,Jae),e(Jae,r6o),e(lb,t6o),e(lb,$j),e($j,a6o),e(lb,n6o),e(O,s6o),e(O,ib),e(ib,Yae),e(Yae,l6o),e(ib,i6o),e(ib,Ij),e(Ij,d6o),e(ib,c6o),e(O,f6o),e(O,db),e(db,Kae),e(Kae,m6o),e(db,g6o),e(db,jj),e(jj,h6o),e(db,p6o),e(O,_6o),e(O,cb),e(cb,Zae),e(Zae,u6o),e(cb,b6o),e(cb,Dj),e(Dj,v6o),e(cb,T6o),e(O,F6o),e(O,fb),e(fb,ene),e(ene,C6o),e(fb,M6o),e(fb,Nj),e(Nj,E6o),e(fb,y6o),e(O,w6o),e(O,mb),e(mb,one),e(one,A6o),e(mb,L6o),e(mb,qj),e(qj,B6o),e(mb,x6o),e(Ve,k6o),e(Ve,gb),e(gb,R6o),e(gb,rne),e(rne,S6o),e(gb,P6o),e(gb,tne),e(tne,$6o),e(Ve,I6o),e(Ve,ane),e(ane,j6o),e(Ve,D6o),g(M3,Ve,null),b(c,Oxe,u),b(c,ud,u),e(ud,hb),e(hb,nne),g(E3,nne,null),e(ud,N6o),e(ud,sne),e(sne,q6o),b(c,Gxe,u),b(c,tr,u),g(y3,tr,null),e(tr,O6o),e(tr,bd),e(bd,G6o),e(bd,lne),e(lne,X6o),e(bd,V6o),e(bd,ine),e(ine,z6o),e(bd,W6o),e(tr,Q6o),e(tr,w3),e(w3,H6o),e(w3,dne),e(dne,U6o),e(w3,J6o),e(tr,Y6o),e(tr,Yr),g(A3,Yr,null),e(Yr,K6o),e(Yr,cne),e(cne,Z6o),e(Yr,eAo),e(Yr,vd),e(vd,oAo),e(vd,fne),e(fne,rAo),e(vd,tAo),e(vd,mne),e(mne,aAo),e(vd,nAo),e(Yr,sAo),e(Yr,gne),e(gne,lAo),e(Yr,iAo),g(L3,Yr,null),e(tr,dAo),e(tr,ze),g(B3,ze,null),e(ze,cAo),e(ze,hne),e(hne,fAo),e(ze,mAo),e(ze,Ja),e(Ja,gAo),e(Ja,pne),e(pne,hAo),e(Ja,pAo),e(Ja,_ne),e(_ne,_Ao),e(Ja,uAo),e(Ja,une),e(une,bAo),e(Ja,vAo),e(ze,TAo),e(ze,da),e(da,pb),e(pb,bne),e(bne,FAo),e(pb,CAo),e(pb,Oj),e(Oj,MAo),e(pb,EAo),e(da,yAo),e(da,_b),e(_b,vne),e(vne,wAo),e(_b,AAo),e(_b,Gj),e(Gj,LAo),e(_b,BAo),e(da,xAo),e(da,ub),e(ub,Tne),e(Tne,kAo),e(ub,RAo),e(ub,Xj),e(Xj,SAo),e(ub,PAo),e(da,$Ao),e(da,bb),e(bb,Fne),e(Fne,IAo),e(bb,jAo),e(bb,Vj),e(Vj,DAo),e(bb,NAo),e(da,qAo),e(da,vb),e(vb,Cne),e(Cne,OAo),e(vb,GAo),e(vb,zj),e(zj,XAo),e(vb,VAo),e(ze,zAo),e(ze,Tb),e(Tb,WAo),e(Tb,Mne),e(Mne,QAo),e(Tb,HAo),e(Tb,Ene),e(Ene,UAo),e(ze,JAo),e(ze,yne),e(yne,YAo),e(ze,KAo),g(x3,ze,null),b(c,Xxe,u),b(c,Td,u),e(Td,Fb),e(Fb,wne),g(k3,wne,null),e(Td,ZAo),e(Td,Ane),e(Ane,eLo),b(c,Vxe,u),b(c,ar,u),g(R3,ar,null),e(ar,oLo),e(ar,Fd),e(Fd,rLo),e(Fd,Lne),e(Lne,tLo),e(Fd,aLo),e(Fd,Bne),e(Bne,nLo),e(Fd,sLo),e(ar,lLo),e(ar,S3),e(S3,iLo),e(S3,xne),e(xne,dLo),e(S3,cLo),e(ar,fLo),e(ar,Kr),g(P3,Kr,null),e(Kr,mLo),e(Kr,kne),e(kne,gLo),e(Kr,hLo),e(Kr,Cd),e(Cd,pLo),e(Cd,Rne),e(Rne,_Lo),e(Cd,uLo),e(Cd,Sne),e(Sne,bLo),e(Cd,vLo),e(Kr,TLo),e(Kr,Pne),e(Pne,FLo),e(Kr,CLo),g($3,Kr,null),e(ar,MLo),e(ar,We),g(I3,We,null),e(We,ELo),e(We,$ne),e($ne,yLo),e(We,wLo),e(We,Ya),e(Ya,ALo),e(Ya,Ine),e(Ine,LLo),e(Ya,BLo),e(Ya,jne),e(jne,xLo),e(Ya,kLo),e(Ya,Dne),e(Dne,RLo),e(Ya,SLo),e(We,PLo),e(We,N),e(N,Cb),e(Cb,Nne),e(Nne,$Lo),e(Cb,ILo),e(Cb,Wj),e(Wj,jLo),e(Cb,DLo),e(N,NLo),e(N,Mb),e(Mb,qne),e(qne,qLo),e(Mb,OLo),e(Mb,Qj),e(Qj,GLo),e(Mb,XLo),e(N,VLo),e(N,Eb),e(Eb,One),e(One,zLo),e(Eb,WLo),e(Eb,Hj),e(Hj,QLo),e(Eb,HLo),e(N,ULo),e(N,yb),e(yb,Gne),e(Gne,JLo),e(yb,YLo),e(yb,Uj),e(Uj,KLo),e(yb,ZLo),e(N,e8o),e(N,wb),e(wb,Xne),e(Xne,o8o),e(wb,r8o),e(wb,Jj),e(Jj,t8o),e(wb,a8o),e(N,n8o),e(N,Ab),e(Ab,Vne),e(Vne,s8o),e(Ab,l8o),e(Ab,Yj),e(Yj,i8o),e(Ab,d8o),e(N,c8o),e(N,Lb),e(Lb,zne),e(zne,f8o),e(Lb,m8o),e(Lb,Kj),e(Kj,g8o),e(Lb,h8o),e(N,p8o),e(N,Bb),e(Bb,Wne),e(Wne,_8o),e(Bb,u8o),e(Bb,Zj),e(Zj,b8o),e(Bb,v8o),e(N,T8o),e(N,xb),e(xb,Qne),e(Qne,F8o),e(xb,C8o),e(xb,eD),e(eD,M8o),e(xb,E8o),e(N,y8o),e(N,kb),e(kb,Hne),e(Hne,w8o),e(kb,A8o),e(kb,oD),e(oD,L8o),e(kb,B8o),e(N,x8o),e(N,Rb),e(Rb,Une),e(Une,k8o),e(Rb,R8o),e(Rb,rD),e(rD,S8o),e(Rb,P8o),e(N,$8o),e(N,Sb),e(Sb,Jne),e(Jne,I8o),e(Sb,j8o),e(Sb,tD),e(tD,D8o),e(Sb,N8o),e(N,q8o),e(N,Pb),e(Pb,Yne),e(Yne,O8o),e(Pb,G8o),e(Pb,aD),e(aD,X8o),e(Pb,V8o),e(N,z8o),e(N,$b),e($b,Kne),e(Kne,W8o),e($b,Q8o),e($b,nD),e(nD,H8o),e($b,U8o),e(N,J8o),e(N,Ib),e(Ib,Zne),e(Zne,Y8o),e(Ib,K8o),e(Ib,sD),e(sD,Z8o),e(Ib,e9o),e(N,o9o),e(N,jb),e(jb,ese),e(ese,r9o),e(jb,t9o),e(jb,lD),e(lD,a9o),e(jb,n9o),e(N,s9o),e(N,Db),e(Db,ose),e(ose,l9o),e(Db,i9o),e(Db,iD),e(iD,d9o),e(Db,c9o),e(N,f9o),e(N,Nb),e(Nb,rse),e(rse,m9o),e(Nb,g9o),e(Nb,dD),e(dD,h9o),e(Nb,p9o),e(N,_9o),e(N,qb),e(qb,tse),e(tse,u9o),e(qb,b9o),e(qb,cD),e(cD,v9o),e(qb,T9o),e(N,F9o),e(N,Ob),e(Ob,ase),e(ase,C9o),e(Ob,M9o),e(Ob,fD),e(fD,E9o),e(Ob,y9o),e(N,w9o),e(N,Gb),e(Gb,nse),e(nse,A9o),e(Gb,L9o),e(Gb,mD),e(mD,B9o),e(Gb,x9o),e(N,k9o),e(N,Xb),e(Xb,sse),e(sse,R9o),e(Xb,S9o),e(Xb,gD),e(gD,P9o),e(Xb,$9o),e(N,I9o),e(N,Vb),e(Vb,lse),e(lse,j9o),e(Vb,D9o),e(Vb,hD),e(hD,N9o),e(Vb,q9o),e(N,O9o),e(N,zb),e(zb,ise),e(ise,G9o),e(zb,X9o),e(zb,pD),e(pD,V9o),e(zb,z9o),e(N,W9o),e(N,Wb),e(Wb,dse),e(dse,Q9o),e(Wb,H9o),e(Wb,_D),e(_D,U9o),e(Wb,J9o),e(N,Y9o),e(N,Qb),e(Qb,cse),e(cse,K9o),e(Qb,Z9o),e(Qb,uD),e(uD,eBo),e(Qb,oBo),e(N,rBo),e(N,Hb),e(Hb,fse),e(fse,tBo),e(Hb,aBo),e(Hb,bD),e(bD,nBo),e(Hb,sBo),e(N,lBo),e(N,Ub),e(Ub,mse),e(mse,iBo),e(Ub,dBo),e(Ub,vD),e(vD,cBo),e(Ub,fBo),e(N,mBo),e(N,Jb),e(Jb,gse),e(gse,gBo),e(Jb,hBo),e(Jb,TD),e(TD,pBo),e(Jb,_Bo),e(N,uBo),e(N,Yb),e(Yb,hse),e(hse,bBo),e(Yb,vBo),e(Yb,FD),e(FD,TBo),e(Yb,FBo),e(N,CBo),e(N,Kb),e(Kb,pse),e(pse,MBo),e(Kb,EBo),e(Kb,CD),e(CD,yBo),e(Kb,wBo),e(N,ABo),e(N,Zb),e(Zb,_se),e(_se,LBo),e(Zb,BBo),e(Zb,MD),e(MD,xBo),e(Zb,kBo),e(N,RBo),e(N,e5),e(e5,use),e(use,SBo),e(e5,PBo),e(e5,ED),e(ED,$Bo),e(e5,IBo),e(We,jBo),e(We,o5),e(o5,DBo),e(o5,bse),e(bse,NBo),e(o5,qBo),e(o5,vse),e(vse,OBo),e(We,GBo),e(We,Tse),e(Tse,XBo),e(We,VBo),g(j3,We,null),b(c,zxe,u),b(c,Md,u),e(Md,r5),e(r5,Fse),g(D3,Fse,null),e(Md,zBo),e(Md,Cse),e(Cse,WBo),b(c,Wxe,u),b(c,nr,u),g(N3,nr,null),e(nr,QBo),e(nr,Ed),e(Ed,HBo),e(Ed,Mse),e(Mse,UBo),e(Ed,JBo),e(Ed,Ese),e(Ese,YBo),e(Ed,KBo),e(nr,ZBo),e(nr,q3),e(q3,exo),e(q3,yse),e(yse,oxo),e(q3,rxo),e(nr,txo),e(nr,Zr),g(O3,Zr,null),e(Zr,axo),e(Zr,wse),e(wse,nxo),e(Zr,sxo),e(Zr,yd),e(yd,lxo),e(yd,Ase),e(Ase,ixo),e(yd,dxo),e(yd,Lse),e(Lse,cxo),e(yd,fxo),e(Zr,mxo),e(Zr,Bse),e(Bse,gxo),e(Zr,hxo),g(G3,Zr,null),e(nr,pxo),e(nr,Qe),g(X3,Qe,null),e(Qe,_xo),e(Qe,xse),e(xse,uxo),e(Qe,bxo),e(Qe,Ka),e(Ka,vxo),e(Ka,kse),e(kse,Txo),e(Ka,Fxo),e(Ka,Rse),e(Rse,Cxo),e(Ka,Mxo),e(Ka,Sse),e(Sse,Exo),e(Ka,yxo),e(Qe,wxo),e(Qe,R),e(R,t5),e(t5,Pse),e(Pse,Axo),e(t5,Lxo),e(t5,yD),e(yD,Bxo),e(t5,xxo),e(R,kxo),e(R,a5),e(a5,$se),e($se,Rxo),e(a5,Sxo),e(a5,wD),e(wD,Pxo),e(a5,$xo),e(R,Ixo),e(R,n5),e(n5,Ise),e(Ise,jxo),e(n5,Dxo),e(n5,AD),e(AD,Nxo),e(n5,qxo),e(R,Oxo),e(R,s5),e(s5,jse),e(jse,Gxo),e(s5,Xxo),e(s5,LD),e(LD,Vxo),e(s5,zxo),e(R,Wxo),e(R,l5),e(l5,Dse),e(Dse,Qxo),e(l5,Hxo),e(l5,BD),e(BD,Uxo),e(l5,Jxo),e(R,Yxo),e(R,i5),e(i5,Nse),e(Nse,Kxo),e(i5,Zxo),e(i5,xD),e(xD,eko),e(i5,oko),e(R,rko),e(R,d5),e(d5,qse),e(qse,tko),e(d5,ako),e(d5,kD),e(kD,nko),e(d5,sko),e(R,lko),e(R,c5),e(c5,Ose),e(Ose,iko),e(c5,dko),e(c5,RD),e(RD,cko),e(c5,fko),e(R,mko),e(R,f5),e(f5,Gse),e(Gse,gko),e(f5,hko),e(f5,SD),e(SD,pko),e(f5,_ko),e(R,uko),e(R,m5),e(m5,Xse),e(Xse,bko),e(m5,vko),e(m5,PD),e(PD,Tko),e(m5,Fko),e(R,Cko),e(R,g5),e(g5,Vse),e(Vse,Mko),e(g5,Eko),e(g5,$D),e($D,yko),e(g5,wko),e(R,Ako),e(R,h5),e(h5,zse),e(zse,Lko),e(h5,Bko),e(h5,ID),e(ID,xko),e(h5,kko),e(R,Rko),e(R,p5),e(p5,Wse),e(Wse,Sko),e(p5,Pko),e(p5,jD),e(jD,$ko),e(p5,Iko),e(R,jko),e(R,_5),e(_5,Qse),e(Qse,Dko),e(_5,Nko),e(_5,DD),e(DD,qko),e(_5,Oko),e(R,Gko),e(R,u5),e(u5,Hse),e(Hse,Xko),e(u5,Vko),e(u5,ND),e(ND,zko),e(u5,Wko),e(R,Qko),e(R,b5),e(b5,Use),e(Use,Hko),e(b5,Uko),e(b5,qD),e(qD,Jko),e(b5,Yko),e(R,Kko),e(R,v5),e(v5,Jse),e(Jse,Zko),e(v5,eRo),e(v5,OD),e(OD,oRo),e(v5,rRo),e(R,tRo),e(R,T5),e(T5,Yse),e(Yse,aRo),e(T5,nRo),e(T5,GD),e(GD,sRo),e(T5,lRo),e(R,iRo),e(R,F5),e(F5,Kse),e(Kse,dRo),e(F5,cRo),e(F5,XD),e(XD,fRo),e(F5,mRo),e(R,gRo),e(R,C5),e(C5,Zse),e(Zse,hRo),e(C5,pRo),e(C5,VD),e(VD,_Ro),e(C5,uRo),e(R,bRo),e(R,M5),e(M5,ele),e(ele,vRo),e(M5,TRo),e(M5,zD),e(zD,FRo),e(M5,CRo),e(R,MRo),e(R,E5),e(E5,ole),e(ole,ERo),e(E5,yRo),e(E5,WD),e(WD,wRo),e(E5,ARo),e(R,LRo),e(R,y5),e(y5,rle),e(rle,BRo),e(y5,xRo),e(y5,QD),e(QD,kRo),e(y5,RRo),e(R,SRo),e(R,w5),e(w5,tle),e(tle,PRo),e(w5,$Ro),e(w5,HD),e(HD,IRo),e(w5,jRo),e(R,DRo),e(R,A5),e(A5,ale),e(ale,NRo),e(A5,qRo),e(A5,UD),e(UD,ORo),e(A5,GRo),e(R,XRo),e(R,L5),e(L5,nle),e(nle,VRo),e(L5,zRo),e(L5,JD),e(JD,WRo),e(L5,QRo),e(R,HRo),e(R,B5),e(B5,sle),e(sle,URo),e(B5,JRo),e(B5,YD),e(YD,YRo),e(B5,KRo),e(R,ZRo),e(R,x5),e(x5,lle),e(lle,eSo),e(x5,oSo),e(x5,KD),e(KD,rSo),e(x5,tSo),e(R,aSo),e(R,k5),e(k5,ile),e(ile,nSo),e(k5,sSo),e(k5,ZD),e(ZD,lSo),e(k5,iSo),e(R,dSo),e(R,R5),e(R5,dle),e(dle,cSo),e(R5,fSo),e(R5,eN),e(eN,mSo),e(R5,gSo),e(R,hSo),e(R,S5),e(S5,cle),e(cle,pSo),e(S5,_So),e(S5,oN),e(oN,uSo),e(S5,bSo),e(R,vSo),e(R,P5),e(P5,fle),e(fle,TSo),e(P5,FSo),e(P5,rN),e(rN,CSo),e(P5,MSo),e(R,ESo),e(R,$5),e($5,mle),e(mle,ySo),e($5,wSo),e($5,tN),e(tN,ASo),e($5,LSo),e(R,BSo),e(R,I5),e(I5,gle),e(gle,xSo),e(I5,kSo),e(I5,aN),e(aN,RSo),e(I5,SSo),e(R,PSo),e(R,j5),e(j5,hle),e(hle,$So),e(j5,ISo),e(j5,nN),e(nN,jSo),e(j5,DSo),e(R,NSo),e(R,D5),e(D5,ple),e(ple,qSo),e(D5,OSo),e(D5,sN),e(sN,GSo),e(D5,XSo),e(R,VSo),e(R,N5),e(N5,_le),e(_le,zSo),e(N5,WSo),e(N5,lN),e(lN,QSo),e(N5,HSo),e(R,USo),e(R,q5),e(q5,ule),e(ule,JSo),e(q5,YSo),e(q5,iN),e(iN,KSo),e(q5,ZSo),e(R,ePo),e(R,O5),e(O5,ble),e(ble,oPo),e(O5,rPo),e(O5,dN),e(dN,tPo),e(O5,aPo),e(Qe,nPo),e(Qe,G5),e(G5,sPo),e(G5,vle),e(vle,lPo),e(G5,iPo),e(G5,Tle),e(Tle,dPo),e(Qe,cPo),e(Qe,Fle),e(Fle,fPo),e(Qe,mPo),g(V3,Qe,null),b(c,Qxe,u),b(c,wd,u),e(wd,X5),e(X5,Cle),g(z3,Cle,null),e(wd,gPo),e(wd,Mle),e(Mle,hPo),b(c,Hxe,u),b(c,sr,u),g(W3,sr,null),e(sr,pPo),e(sr,Ad),e(Ad,_Po),e(Ad,Ele),e(Ele,uPo),e(Ad,bPo),e(Ad,yle),e(yle,vPo),e(Ad,TPo),e(sr,FPo),e(sr,Q3),e(Q3,CPo),e(Q3,wle),e(wle,MPo),e(Q3,EPo),e(sr,yPo),e(sr,et),g(H3,et,null),e(et,wPo),e(et,Ale),e(Ale,APo),e(et,LPo),e(et,Ld),e(Ld,BPo),e(Ld,Lle),e(Lle,xPo),e(Ld,kPo),e(Ld,Ble),e(Ble,RPo),e(Ld,SPo),e(et,PPo),e(et,xle),e(xle,$Po),e(et,IPo),g(U3,et,null),e(sr,jPo),e(sr,He),g(J3,He,null),e(He,DPo),e(He,kle),e(kle,NPo),e(He,qPo),e(He,Za),e(Za,OPo),e(Za,Rle),e(Rle,GPo),e(Za,XPo),e(Za,Sle),e(Sle,VPo),e(Za,zPo),e(Za,Ple),e(Ple,WPo),e(Za,QPo),e(He,HPo),e(He,$le),e($le,V5),e(V5,Ile),e(Ile,UPo),e(V5,JPo),e(V5,cN),e(cN,YPo),e(V5,KPo),e(He,ZPo),e(He,z5),e(z5,e$o),e(z5,jle),e(jle,o$o),e(z5,r$o),e(z5,Dle),e(Dle,t$o),e(He,a$o),e(He,Nle),e(Nle,n$o),e(He,s$o),g(Y3,He,null),b(c,Uxe,u),b(c,Bd,u),e(Bd,W5),e(W5,qle),g(K3,qle,null),e(Bd,l$o),e(Bd,Ole),e(Ole,i$o),b(c,Jxe,u),b(c,lr,u),g(Z3,lr,null),e(lr,d$o),e(lr,xd),e(xd,c$o),e(xd,Gle),e(Gle,f$o),e(xd,m$o),e(xd,Xle),e(Xle,g$o),e(xd,h$o),e(lr,p$o),e(lr,ey),e(ey,_$o),e(ey,Vle),e(Vle,u$o),e(ey,b$o),e(lr,v$o),e(lr,ot),g(oy,ot,null),e(ot,T$o),e(ot,zle),e(zle,F$o),e(ot,C$o),e(ot,kd),e(kd,M$o),e(kd,Wle),e(Wle,E$o),e(kd,y$o),e(kd,Qle),e(Qle,w$o),e(kd,A$o),e(ot,L$o),e(ot,Hle),e(Hle,B$o),e(ot,x$o),g(ry,ot,null),e(lr,k$o),e(lr,Ue),g(ty,Ue,null),e(Ue,R$o),e(Ue,Ule),e(Ule,S$o),e(Ue,P$o),e(Ue,en),e(en,$$o),e(en,Jle),e(Jle,I$o),e(en,j$o),e(en,Yle),e(Yle,D$o),e(en,N$o),e(en,Kle),e(Kle,q$o),e(en,O$o),e(Ue,G$o),e(Ue,pe),e(pe,Q5),e(Q5,Zle),e(Zle,X$o),e(Q5,V$o),e(Q5,fN),e(fN,z$o),e(Q5,W$o),e(pe,Q$o),e(pe,H5),e(H5,eie),e(eie,H$o),e(H5,U$o),e(H5,mN),e(mN,J$o),e(H5,Y$o),e(pe,K$o),e(pe,qs),e(qs,oie),e(oie,Z$o),e(qs,eIo),e(qs,gN),e(gN,oIo),e(qs,rIo),e(qs,hN),e(hN,tIo),e(qs,aIo),e(pe,nIo),e(pe,U5),e(U5,rie),e(rie,sIo),e(U5,lIo),e(U5,pN),e(pN,iIo),e(U5,dIo),e(pe,cIo),e(pe,fa),e(fa,tie),e(tie,fIo),e(fa,mIo),e(fa,_N),e(_N,gIo),e(fa,hIo),e(fa,uN),e(uN,pIo),e(fa,_Io),e(fa,bN),e(bN,uIo),e(fa,bIo),e(pe,vIo),e(pe,J5),e(J5,aie),e(aie,TIo),e(J5,FIo),e(J5,vN),e(vN,CIo),e(J5,MIo),e(pe,EIo),e(pe,Y5),e(Y5,nie),e(nie,yIo),e(Y5,wIo),e(Y5,TN),e(TN,AIo),e(Y5,LIo),e(pe,BIo),e(pe,K5),e(K5,sie),e(sie,xIo),e(K5,kIo),e(K5,FN),e(FN,RIo),e(K5,SIo),e(pe,PIo),e(pe,Z5),e(Z5,lie),e(lie,$Io),e(Z5,IIo),e(Z5,CN),e(CN,jIo),e(Z5,DIo),e(pe,NIo),e(pe,e2),e(e2,iie),e(iie,qIo),e(e2,OIo),e(e2,MN),e(MN,GIo),e(e2,XIo),e(Ue,VIo),e(Ue,o2),e(o2,zIo),e(o2,die),e(die,WIo),e(o2,QIo),e(o2,cie),e(cie,HIo),e(Ue,UIo),e(Ue,fie),e(fie,JIo),e(Ue,YIo),g(ay,Ue,null),b(c,Yxe,u),b(c,Rd,u),e(Rd,r2),e(r2,mie),g(ny,mie,null),e(Rd,KIo),e(Rd,gie),e(gie,ZIo),b(c,Kxe,u),b(c,ir,u),g(sy,ir,null),e(ir,ejo),e(ir,Sd),e(Sd,ojo),e(Sd,hie),e(hie,rjo),e(Sd,tjo),e(Sd,pie),e(pie,ajo),e(Sd,njo),e(ir,sjo),e(ir,ly),e(ly,ljo),e(ly,_ie),e(_ie,ijo),e(ly,djo),e(ir,cjo),e(ir,rt),g(iy,rt,null),e(rt,fjo),e(rt,uie),e(uie,mjo),e(rt,gjo),e(rt,Pd),e(Pd,hjo),e(Pd,bie),e(bie,pjo),e(Pd,_jo),e(Pd,vie),e(vie,ujo),e(Pd,bjo),e(rt,vjo),e(rt,Tie),e(Tie,Tjo),e(rt,Fjo),g(dy,rt,null),e(ir,Cjo),e(ir,Je),g(cy,Je,null),e(Je,Mjo),e(Je,Fie),e(Fie,Ejo),e(Je,yjo),e(Je,on),e(on,wjo),e(on,Cie),e(Cie,Ajo),e(on,Ljo),e(on,Mie),e(Mie,Bjo),e(on,xjo),e(on,Eie),e(Eie,kjo),e(on,Rjo),e(Je,Sjo),e(Je,yie),e(yie,t2),e(t2,wie),e(wie,Pjo),e(t2,$jo),e(t2,EN),e(EN,Ijo),e(t2,jjo),e(Je,Djo),e(Je,a2),e(a2,Njo),e(a2,Aie),e(Aie,qjo),e(a2,Ojo),e(a2,Lie),e(Lie,Gjo),e(Je,Xjo),e(Je,Bie),e(Bie,Vjo),e(Je,zjo),g(fy,Je,null),b(c,Zxe,u),b(c,$d,u),e($d,n2),e(n2,xie),g(my,xie,null),e($d,Wjo),e($d,kie),e(kie,Qjo),b(c,eke,u),b(c,dr,u),g(gy,dr,null),e(dr,Hjo),e(dr,Id),e(Id,Ujo),e(Id,Rie),e(Rie,Jjo),e(Id,Yjo),e(Id,Sie),e(Sie,Kjo),e(Id,Zjo),e(dr,eDo),e(dr,hy),e(hy,oDo),e(hy,Pie),e(Pie,rDo),e(hy,tDo),e(dr,aDo),e(dr,tt),g(py,tt,null),e(tt,nDo),e(tt,$ie),e($ie,sDo),e(tt,lDo),e(tt,jd),e(jd,iDo),e(jd,Iie),e(Iie,dDo),e(jd,cDo),e(jd,jie),e(jie,fDo),e(jd,mDo),e(tt,gDo),e(tt,Die),e(Die,hDo),e(tt,pDo),g(_y,tt,null),e(dr,_Do),e(dr,Ye),g(uy,Ye,null),e(Ye,uDo),e(Ye,Nie),e(Nie,bDo),e(Ye,vDo),e(Ye,rn),e(rn,TDo),e(rn,qie),e(qie,FDo),e(rn,CDo),e(rn,Oie),e(Oie,MDo),e(rn,EDo),e(rn,Gie),e(Gie,yDo),e(rn,wDo),e(Ye,ADo),e(Ye,ke),e(ke,s2),e(s2,Xie),e(Xie,LDo),e(s2,BDo),e(s2,yN),e(yN,xDo),e(s2,kDo),e(ke,RDo),e(ke,l2),e(l2,Vie),e(Vie,SDo),e(l2,PDo),e(l2,wN),e(wN,$Do),e(l2,IDo),e(ke,jDo),e(ke,i2),e(i2,zie),e(zie,DDo),e(i2,NDo),e(i2,AN),e(AN,qDo),e(i2,ODo),e(ke,GDo),e(ke,d2),e(d2,Wie),e(Wie,XDo),e(d2,VDo),e(d2,LN),e(LN,zDo),e(d2,WDo),e(ke,QDo),e(ke,c2),e(c2,Qie),e(Qie,HDo),e(c2,UDo),e(c2,BN),e(BN,JDo),e(c2,YDo),e(ke,KDo),e(ke,f2),e(f2,Hie),e(Hie,ZDo),e(f2,eNo),e(f2,xN),e(xN,oNo),e(f2,rNo),e(ke,tNo),e(ke,m2),e(m2,Uie),e(Uie,aNo),e(m2,nNo),e(m2,kN),e(kN,sNo),e(m2,lNo),e(ke,iNo),e(ke,g2),e(g2,Jie),e(Jie,dNo),e(g2,cNo),e(g2,RN),e(RN,fNo),e(g2,mNo),e(Ye,gNo),e(Ye,h2),e(h2,hNo),e(h2,Yie),e(Yie,pNo),e(h2,_No),e(h2,Kie),e(Kie,uNo),e(Ye,bNo),e(Ye,Zie),e(Zie,vNo),e(Ye,TNo),g(by,Ye,null),b(c,oke,u),b(c,Dd,u),e(Dd,p2),e(p2,ede),g(vy,ede,null),e(Dd,FNo),e(Dd,ode),e(ode,CNo),b(c,rke,u),b(c,cr,u),g(Ty,cr,null),e(cr,MNo),e(cr,Nd),e(Nd,ENo),e(Nd,rde),e(rde,yNo),e(Nd,wNo),e(Nd,tde),e(tde,ANo),e(Nd,LNo),e(cr,BNo),e(cr,Fy),e(Fy,xNo),e(Fy,ade),e(ade,kNo),e(Fy,RNo),e(cr,SNo),e(cr,at),g(Cy,at,null),e(at,PNo),e(at,nde),e(nde,$No),e(at,INo),e(at,qd),e(qd,jNo),e(qd,sde),e(sde,DNo),e(qd,NNo),e(qd,lde),e(lde,qNo),e(qd,ONo),e(at,GNo),e(at,ide),e(ide,XNo),e(at,VNo),g(My,at,null),e(cr,zNo),e(cr,Ke),g(Ey,Ke,null),e(Ke,WNo),e(Ke,dde),e(dde,QNo),e(Ke,HNo),e(Ke,tn),e(tn,UNo),e(tn,cde),e(cde,JNo),e(tn,YNo),e(tn,fde),e(fde,KNo),e(tn,ZNo),e(tn,mde),e(mde,eqo),e(tn,oqo),e(Ke,rqo),e(Ke,an),e(an,_2),e(_2,gde),e(gde,tqo),e(_2,aqo),e(_2,SN),e(SN,nqo),e(_2,sqo),e(an,lqo),e(an,u2),e(u2,hde),e(hde,iqo),e(u2,dqo),e(u2,PN),e(PN,cqo),e(u2,fqo),e(an,mqo),e(an,b2),e(b2,pde),e(pde,gqo),e(b2,hqo),e(b2,$N),e($N,pqo),e(b2,_qo),e(an,uqo),e(an,v2),e(v2,_de),e(_de,bqo),e(v2,vqo),e(v2,IN),e(IN,Tqo),e(v2,Fqo),e(Ke,Cqo),e(Ke,T2),e(T2,Mqo),e(T2,ude),e(ude,Eqo),e(T2,yqo),e(T2,bde),e(bde,wqo),e(Ke,Aqo),e(Ke,vde),e(vde,Lqo),e(Ke,Bqo),g(yy,Ke,null),b(c,tke,u),b(c,Od,u),e(Od,F2),e(F2,Tde),g(wy,Tde,null),e(Od,xqo),e(Od,Fde),e(Fde,kqo),b(c,ake,u),b(c,fr,u),g(Ay,fr,null),e(fr,Rqo),e(fr,Gd),e(Gd,Sqo),e(Gd,Cde),e(Cde,Pqo),e(Gd,$qo),e(Gd,Mde),e(Mde,Iqo),e(Gd,jqo),e(fr,Dqo),e(fr,Ly),e(Ly,Nqo),e(Ly,Ede),e(Ede,qqo),e(Ly,Oqo),e(fr,Gqo),e(fr,nt),g(By,nt,null),e(nt,Xqo),e(nt,yde),e(yde,Vqo),e(nt,zqo),e(nt,Xd),e(Xd,Wqo),e(Xd,wde),e(wde,Qqo),e(Xd,Hqo),e(Xd,Ade),e(Ade,Uqo),e(Xd,Jqo),e(nt,Yqo),e(nt,Lde),e(Lde,Kqo),e(nt,Zqo),g(xy,nt,null),e(fr,eOo),e(fr,Ze),g(ky,Ze,null),e(Ze,oOo),e(Ze,Bde),e(Bde,rOo),e(Ze,tOo),e(Ze,nn),e(nn,aOo),e(nn,xde),e(xde,nOo),e(nn,sOo),e(nn,kde),e(kde,lOo),e(nn,iOo),e(nn,Rde),e(Rde,dOo),e(nn,cOo),e(Ze,fOo),e(Ze,Re),e(Re,C2),e(C2,Sde),e(Sde,mOo),e(C2,gOo),e(C2,jN),e(jN,hOo),e(C2,pOo),e(Re,_Oo),e(Re,M2),e(M2,Pde),e(Pde,uOo),e(M2,bOo),e(M2,DN),e(DN,vOo),e(M2,TOo),e(Re,FOo),e(Re,E2),e(E2,$de),e($de,COo),e(E2,MOo),e(E2,NN),e(NN,EOo),e(E2,yOo),e(Re,wOo),e(Re,y2),e(y2,Ide),e(Ide,AOo),e(y2,LOo),e(y2,qN),e(qN,BOo),e(y2,xOo),e(Re,kOo),e(Re,w2),e(w2,jde),e(jde,ROo),e(w2,SOo),e(w2,ON),e(ON,POo),e(w2,$Oo),e(Re,IOo),e(Re,A2),e(A2,Dde),e(Dde,jOo),e(A2,DOo),e(A2,GN),e(GN,NOo),e(A2,qOo),e(Re,OOo),e(Re,L2),e(L2,Nde),e(Nde,GOo),e(L2,XOo),e(L2,XN),e(XN,VOo),e(L2,zOo),e(Re,WOo),e(Re,B2),e(B2,qde),e(qde,QOo),e(B2,HOo),e(B2,VN),e(VN,UOo),e(B2,JOo),e(Ze,YOo),e(Ze,x2),e(x2,KOo),e(x2,Ode),e(Ode,ZOo),e(x2,eGo),e(x2,Gde),e(Gde,oGo),e(Ze,rGo),e(Ze,Xde),e(Xde,tGo),e(Ze,aGo),g(Ry,Ze,null),b(c,nke,u),b(c,Vd,u),e(Vd,k2),e(k2,Vde),g(Sy,Vde,null),e(Vd,nGo),e(Vd,zde),e(zde,sGo),b(c,ske,u),b(c,mr,u),g(Py,mr,null),e(mr,lGo),e(mr,zd),e(zd,iGo),e(zd,Wde),e(Wde,dGo),e(zd,cGo),e(zd,Qde),e(Qde,fGo),e(zd,mGo),e(mr,gGo),e(mr,$y),e($y,hGo),e($y,Hde),e(Hde,pGo),e($y,_Go),e(mr,uGo),e(mr,st),g(Iy,st,null),e(st,bGo),e(st,Ude),e(Ude,vGo),e(st,TGo),e(st,Wd),e(Wd,FGo),e(Wd,Jde),e(Jde,CGo),e(Wd,MGo),e(Wd,Yde),e(Yde,EGo),e(Wd,yGo),e(st,wGo),e(st,Kde),e(Kde,AGo),e(st,LGo),g(jy,st,null),e(mr,BGo),e(mr,eo),g(Dy,eo,null),e(eo,xGo),e(eo,Zde),e(Zde,kGo),e(eo,RGo),e(eo,sn),e(sn,SGo),e(sn,ece),e(ece,PGo),e(sn,$Go),e(sn,oce),e(oce,IGo),e(sn,jGo),e(sn,rce),e(rce,DGo),e(sn,NGo),e(eo,qGo),e(eo,Ny),e(Ny,R2),e(R2,tce),e(tce,OGo),e(R2,GGo),e(R2,zN),e(zN,XGo),e(R2,VGo),e(Ny,zGo),e(Ny,S2),e(S2,ace),e(ace,WGo),e(S2,QGo),e(S2,WN),e(WN,HGo),e(S2,UGo),e(eo,JGo),e(eo,P2),e(P2,YGo),e(P2,nce),e(nce,KGo),e(P2,ZGo),e(P2,sce),e(sce,eXo),e(eo,oXo),e(eo,lce),e(lce,rXo),e(eo,tXo),g(qy,eo,null),b(c,lke,u),b(c,Qd,u),e(Qd,$2),e($2,ice),g(Oy,ice,null),e(Qd,aXo),e(Qd,dce),e(dce,nXo),b(c,ike,u),b(c,gr,u),g(Gy,gr,null),e(gr,sXo),e(gr,Hd),e(Hd,lXo),e(Hd,cce),e(cce,iXo),e(Hd,dXo),e(Hd,fce),e(fce,cXo),e(Hd,fXo),e(gr,mXo),e(gr,Xy),e(Xy,gXo),e(Xy,mce),e(mce,hXo),e(Xy,pXo),e(gr,_Xo),e(gr,lt),g(Vy,lt,null),e(lt,uXo),e(lt,gce),e(gce,bXo),e(lt,vXo),e(lt,Ud),e(Ud,TXo),e(Ud,hce),e(hce,FXo),e(Ud,CXo),e(Ud,pce),e(pce,MXo),e(Ud,EXo),e(lt,yXo),e(lt,_ce),e(_ce,wXo),e(lt,AXo),g(zy,lt,null),e(gr,LXo),e(gr,oo),g(Wy,oo,null),e(oo,BXo),e(oo,uce),e(uce,xXo),e(oo,kXo),e(oo,ln),e(ln,RXo),e(ln,bce),e(bce,SXo),e(ln,PXo),e(ln,vce),e(vce,$Xo),e(ln,IXo),e(ln,Tce),e(Tce,jXo),e(ln,DXo),e(oo,NXo),e(oo,dn),e(dn,I2),e(I2,Fce),e(Fce,qXo),e(I2,OXo),e(I2,QN),e(QN,GXo),e(I2,XXo),e(dn,VXo),e(dn,j2),e(j2,Cce),e(Cce,zXo),e(j2,WXo),e(j2,HN),e(HN,QXo),e(j2,HXo),e(dn,UXo),e(dn,D2),e(D2,Mce),e(Mce,JXo),e(D2,YXo),e(D2,UN),e(UN,KXo),e(D2,ZXo),e(dn,eVo),e(dn,N2),e(N2,Ece),e(Ece,oVo),e(N2,rVo),e(N2,JN),e(JN,tVo),e(N2,aVo),e(oo,nVo),e(oo,q2),e(q2,sVo),e(q2,yce),e(yce,lVo),e(q2,iVo),e(q2,wce),e(wce,dVo),e(oo,cVo),e(oo,Ace),e(Ace,fVo),e(oo,mVo),g(Qy,oo,null),b(c,dke,u),b(c,Jd,u),e(Jd,O2),e(O2,Lce),g(Hy,Lce,null),e(Jd,gVo),e(Jd,Bce),e(Bce,hVo),b(c,cke,u),b(c,hr,u),g(Uy,hr,null),e(hr,pVo),e(hr,Yd),e(Yd,_Vo),e(Yd,xce),e(xce,uVo),e(Yd,bVo),e(Yd,kce),e(kce,vVo),e(Yd,TVo),e(hr,FVo),e(hr,Jy),e(Jy,CVo),e(Jy,Rce),e(Rce,MVo),e(Jy,EVo),e(hr,yVo),e(hr,it),g(Yy,it,null),e(it,wVo),e(it,Sce),e(Sce,AVo),e(it,LVo),e(it,Kd),e(Kd,BVo),e(Kd,Pce),e(Pce,xVo),e(Kd,kVo),e(Kd,$ce),e($ce,RVo),e(Kd,SVo),e(it,PVo),e(it,Ice),e(Ice,$Vo),e(it,IVo),g(Ky,it,null),e(hr,jVo),e(hr,ro),g(Zy,ro,null),e(ro,DVo),e(ro,jce),e(jce,NVo),e(ro,qVo),e(ro,cn),e(cn,OVo),e(cn,Dce),e(Dce,GVo),e(cn,XVo),e(cn,Nce),e(Nce,VVo),e(cn,zVo),e(cn,qce),e(qce,WVo),e(cn,QVo),e(ro,HVo),e(ro,Zd),e(Zd,G2),e(G2,Oce),e(Oce,UVo),e(G2,JVo),e(G2,YN),e(YN,YVo),e(G2,KVo),e(Zd,ZVo),e(Zd,X2),e(X2,Gce),e(Gce,ezo),e(X2,ozo),e(X2,KN),e(KN,rzo),e(X2,tzo),e(Zd,azo),e(Zd,V2),e(V2,Xce),e(Xce,nzo),e(V2,szo),e(V2,ZN),e(ZN,lzo),e(V2,izo),e(ro,dzo),e(ro,z2),e(z2,czo),e(z2,Vce),e(Vce,fzo),e(z2,mzo),e(z2,zce),e(zce,gzo),e(ro,hzo),e(ro,Wce),e(Wce,pzo),e(ro,_zo),g(ew,ro,null),b(c,fke,u),b(c,ec,u),e(ec,W2),e(W2,Qce),g(ow,Qce,null),e(ec,uzo),e(ec,Hce),e(Hce,bzo),b(c,mke,u),b(c,pr,u),g(rw,pr,null),e(pr,vzo),e(pr,oc),e(oc,Tzo),e(oc,Uce),e(Uce,Fzo),e(oc,Czo),e(oc,Jce),e(Jce,Mzo),e(oc,Ezo),e(pr,yzo),e(pr,tw),e(tw,wzo),e(tw,Yce),e(Yce,Azo),e(tw,Lzo),e(pr,Bzo),e(pr,dt),g(aw,dt,null),e(dt,xzo),e(dt,Kce),e(Kce,kzo),e(dt,Rzo),e(dt,rc),e(rc,Szo),e(rc,Zce),e(Zce,Pzo),e(rc,$zo),e(rc,efe),e(efe,Izo),e(rc,jzo),e(dt,Dzo),e(dt,ofe),e(ofe,Nzo),e(dt,qzo),g(nw,dt,null),e(pr,Ozo),e(pr,to),g(sw,to,null),e(to,Gzo),e(to,rfe),e(rfe,Xzo),e(to,Vzo),e(to,fn),e(fn,zzo),e(fn,tfe),e(tfe,Wzo),e(fn,Qzo),e(fn,afe),e(afe,Hzo),e(fn,Uzo),e(fn,nfe),e(nfe,Jzo),e(fn,Yzo),e(to,Kzo),e(to,sfe),e(sfe,Q2),e(Q2,lfe),e(lfe,Zzo),e(Q2,eWo),e(Q2,eq),e(eq,oWo),e(Q2,rWo),e(to,tWo),e(to,H2),e(H2,aWo),e(H2,ife),e(ife,nWo),e(H2,sWo),e(H2,dfe),e(dfe,lWo),e(to,iWo),e(to,cfe),e(cfe,dWo),e(to,cWo),g(lw,to,null),b(c,gke,u),b(c,tc,u),e(tc,U2),e(U2,ffe),g(iw,ffe,null),e(tc,fWo),e(tc,mfe),e(mfe,mWo),b(c,hke,u),b(c,_r,u),g(dw,_r,null),e(_r,gWo),e(_r,ac),e(ac,hWo),e(ac,gfe),e(gfe,pWo),e(ac,_Wo),e(ac,hfe),e(hfe,uWo),e(ac,bWo),e(_r,vWo),e(_r,cw),e(cw,TWo),e(cw,pfe),e(pfe,FWo),e(cw,CWo),e(_r,MWo),e(_r,ct),g(fw,ct,null),e(ct,EWo),e(ct,_fe),e(_fe,yWo),e(ct,wWo),e(ct,nc),e(nc,AWo),e(nc,ufe),e(ufe,LWo),e(nc,BWo),e(nc,bfe),e(bfe,xWo),e(nc,kWo),e(ct,RWo),e(ct,vfe),e(vfe,SWo),e(ct,PWo),g(mw,ct,null),e(_r,$Wo),e(_r,ao),g(gw,ao,null),e(ao,IWo),e(ao,Tfe),e(Tfe,jWo),e(ao,DWo),e(ao,mn),e(mn,NWo),e(mn,Ffe),e(Ffe,qWo),e(mn,OWo),e(mn,Cfe),e(Cfe,GWo),e(mn,XWo),e(mn,Mfe),e(Mfe,VWo),e(mn,zWo),e(ao,WWo),e(ao,Efe),e(Efe,J2),e(J2,yfe),e(yfe,QWo),e(J2,HWo),e(J2,oq),e(oq,UWo),e(J2,JWo),e(ao,YWo),e(ao,Y2),e(Y2,KWo),e(Y2,wfe),e(wfe,ZWo),e(Y2,eQo),e(Y2,Afe),e(Afe,oQo),e(ao,rQo),e(ao,Lfe),e(Lfe,tQo),e(ao,aQo),g(hw,ao,null),b(c,pke,u),b(c,sc,u),e(sc,K2),e(K2,Bfe),g(pw,Bfe,null),e(sc,nQo),e(sc,xfe),e(xfe,sQo),b(c,_ke,u),b(c,ur,u),g(_w,ur,null),e(ur,lQo),e(ur,lc),e(lc,iQo),e(lc,kfe),e(kfe,dQo),e(lc,cQo),e(lc,Rfe),e(Rfe,fQo),e(lc,mQo),e(ur,gQo),e(ur,uw),e(uw,hQo),e(uw,Sfe),e(Sfe,pQo),e(uw,_Qo),e(ur,uQo),e(ur,ft),g(bw,ft,null),e(ft,bQo),e(ft,Pfe),e(Pfe,vQo),e(ft,TQo),e(ft,ic),e(ic,FQo),e(ic,$fe),e($fe,CQo),e(ic,MQo),e(ic,Ife),e(Ife,EQo),e(ic,yQo),e(ft,wQo),e(ft,jfe),e(jfe,AQo),e(ft,LQo),g(vw,ft,null),e(ur,BQo),e(ur,no),g(Tw,no,null),e(no,xQo),e(no,Dfe),e(Dfe,kQo),e(no,RQo),e(no,gn),e(gn,SQo),e(gn,Nfe),e(Nfe,PQo),e(gn,$Qo),e(gn,qfe),e(qfe,IQo),e(gn,jQo),e(gn,Ofe),e(Ofe,DQo),e(gn,NQo),e(no,qQo),e(no,Fw),e(Fw,Z2),e(Z2,Gfe),e(Gfe,OQo),e(Z2,GQo),e(Z2,rq),e(rq,XQo),e(Z2,VQo),e(Fw,zQo),e(Fw,ev),e(ev,Xfe),e(Xfe,WQo),e(ev,QQo),e(ev,tq),e(tq,HQo),e(ev,UQo),e(no,JQo),e(no,ov),e(ov,YQo),e(ov,Vfe),e(Vfe,KQo),e(ov,ZQo),e(ov,zfe),e(zfe,eHo),e(no,oHo),e(no,Wfe),e(Wfe,rHo),e(no,tHo),g(Cw,no,null),b(c,uke,u),b(c,dc,u),e(dc,rv),e(rv,Qfe),g(Mw,Qfe,null),e(dc,aHo),e(dc,Hfe),e(Hfe,nHo),b(c,bke,u),b(c,br,u),g(Ew,br,null),e(br,sHo),e(br,cc),e(cc,lHo),e(cc,Ufe),e(Ufe,iHo),e(cc,dHo),e(cc,Jfe),e(Jfe,cHo),e(cc,fHo),e(br,mHo),e(br,yw),e(yw,gHo),e(yw,Yfe),e(Yfe,hHo),e(yw,pHo),e(br,_Ho),e(br,mt),g(ww,mt,null),e(mt,uHo),e(mt,Kfe),e(Kfe,bHo),e(mt,vHo),e(mt,fc),e(fc,THo),e(fc,Zfe),e(Zfe,FHo),e(fc,CHo),e(fc,eme),e(eme,MHo),e(fc,EHo),e(mt,yHo),e(mt,ome),e(ome,wHo),e(mt,AHo),g(Aw,mt,null),e(br,LHo),e(br,so),g(Lw,so,null),e(so,BHo),e(so,rme),e(rme,xHo),e(so,kHo),e(so,hn),e(hn,RHo),e(hn,tme),e(tme,SHo),e(hn,PHo),e(hn,ame),e(ame,$Ho),e(hn,IHo),e(hn,nme),e(nme,jHo),e(hn,DHo),e(so,NHo),e(so,sme),e(sme,tv),e(tv,lme),e(lme,qHo),e(tv,OHo),e(tv,aq),e(aq,GHo),e(tv,XHo),e(so,VHo),e(so,av),e(av,zHo),e(av,ime),e(ime,WHo),e(av,QHo),e(av,dme),e(dme,HHo),e(so,UHo),e(so,cme),e(cme,JHo),e(so,YHo),g(Bw,so,null),b(c,vke,u),b(c,mc,u),e(mc,nv),e(nv,fme),g(xw,fme,null),e(mc,KHo),e(mc,mme),e(mme,ZHo),b(c,Tke,u),b(c,vr,u),g(kw,vr,null),e(vr,eUo),e(vr,gc),e(gc,oUo),e(gc,gme),e(gme,rUo),e(gc,tUo),e(gc,hme),e(hme,aUo),e(gc,nUo),e(vr,sUo),e(vr,Rw),e(Rw,lUo),e(Rw,pme),e(pme,iUo),e(Rw,dUo),e(vr,cUo),e(vr,gt),g(Sw,gt,null),e(gt,fUo),e(gt,_me),e(_me,mUo),e(gt,gUo),e(gt,hc),e(hc,hUo),e(hc,ume),e(ume,pUo),e(hc,_Uo),e(hc,bme),e(bme,uUo),e(hc,bUo),e(gt,vUo),e(gt,vme),e(vme,TUo),e(gt,FUo),g(Pw,gt,null),e(vr,CUo),e(vr,ho),g($w,ho,null),e(ho,MUo),e(ho,Tme),e(Tme,EUo),e(ho,yUo),e(ho,pn),e(pn,wUo),e(pn,Fme),e(Fme,AUo),e(pn,LUo),e(pn,Cme),e(Cme,BUo),e(pn,xUo),e(pn,Mme),e(Mme,kUo),e(pn,RUo),e(ho,SUo),e(ho,B),e(B,sv),e(sv,Eme),e(Eme,PUo),e(sv,$Uo),e(sv,nq),e(nq,IUo),e(sv,jUo),e(B,DUo),e(B,lv),e(lv,yme),e(yme,NUo),e(lv,qUo),e(lv,sq),e(sq,OUo),e(lv,GUo),e(B,XUo),e(B,iv),e(iv,wme),e(wme,VUo),e(iv,zUo),e(iv,lq),e(lq,WUo),e(iv,QUo),e(B,HUo),e(B,dv),e(dv,Ame),e(Ame,UUo),e(dv,JUo),e(dv,iq),e(iq,YUo),e(dv,KUo),e(B,ZUo),e(B,cv),e(cv,Lme),e(Lme,eJo),e(cv,oJo),e(cv,dq),e(dq,rJo),e(cv,tJo),e(B,aJo),e(B,fv),e(fv,Bme),e(Bme,nJo),e(fv,sJo),e(fv,cq),e(cq,lJo),e(fv,iJo),e(B,dJo),e(B,mv),e(mv,xme),e(xme,cJo),e(mv,fJo),e(mv,fq),e(fq,mJo),e(mv,gJo),e(B,hJo),e(B,gv),e(gv,kme),e(kme,pJo),e(gv,_Jo),e(gv,mq),e(mq,uJo),e(gv,bJo),e(B,vJo),e(B,hv),e(hv,Rme),e(Rme,TJo),e(hv,FJo),e(hv,gq),e(gq,CJo),e(hv,MJo),e(B,EJo),e(B,pv),e(pv,Sme),e(Sme,yJo),e(pv,wJo),e(pv,hq),e(hq,AJo),e(pv,LJo),e(B,BJo),e(B,_v),e(_v,Pme),e(Pme,xJo),e(_v,kJo),e(_v,pq),e(pq,RJo),e(_v,SJo),e(B,PJo),e(B,uv),e(uv,$me),e($me,$Jo),e(uv,IJo),e(uv,_q),e(_q,jJo),e(uv,DJo),e(B,NJo),e(B,bv),e(bv,Ime),e(Ime,qJo),e(bv,OJo),e(bv,uq),e(uq,GJo),e(bv,XJo),e(B,VJo),e(B,vv),e(vv,jme),e(jme,zJo),e(vv,WJo),e(vv,bq),e(bq,QJo),e(vv,HJo),e(B,UJo),e(B,Tv),e(Tv,Dme),e(Dme,JJo),e(Tv,YJo),e(Tv,vq),e(vq,KJo),e(Tv,ZJo),e(B,eYo),e(B,Fv),e(Fv,Nme),e(Nme,oYo),e(Fv,rYo),e(Fv,Tq),e(Tq,tYo),e(Fv,aYo),e(B,nYo),e(B,Os),e(Os,qme),e(qme,sYo),e(Os,lYo),e(Os,Fq),e(Fq,iYo),e(Os,dYo),e(Os,Cq),e(Cq,cYo),e(Os,fYo),e(B,mYo),e(B,Cv),e(Cv,Ome),e(Ome,gYo),e(Cv,hYo),e(Cv,Mq),e(Mq,pYo),e(Cv,_Yo),e(B,uYo),e(B,Mv),e(Mv,Gme),e(Gme,bYo),e(Mv,vYo),e(Mv,Eq),e(Eq,TYo),e(Mv,FYo),e(B,CYo),e(B,Ev),e(Ev,Xme),e(Xme,MYo),e(Ev,EYo),e(Ev,yq),e(yq,yYo),e(Ev,wYo),e(B,AYo),e(B,yv),e(yv,Vme),e(Vme,LYo),e(yv,BYo),e(yv,wq),e(wq,xYo),e(yv,kYo),e(B,RYo),e(B,wv),e(wv,zme),e(zme,SYo),e(wv,PYo),e(wv,Aq),e(Aq,$Yo),e(wv,IYo),e(B,jYo),e(B,Av),e(Av,Wme),e(Wme,DYo),e(Av,NYo),e(Av,Lq),e(Lq,qYo),e(Av,OYo),e(B,GYo),e(B,Lv),e(Lv,Qme),e(Qme,XYo),e(Lv,VYo),e(Lv,Bq),e(Bq,zYo),e(Lv,WYo),e(B,QYo),e(B,Bv),e(Bv,Hme),e(Hme,HYo),e(Bv,UYo),e(Bv,xq),e(xq,JYo),e(Bv,YYo),e(B,KYo),e(B,xv),e(xv,Ume),e(Ume,ZYo),e(xv,eKo),e(xv,kq),e(kq,oKo),e(xv,rKo),e(B,tKo),e(B,kv),e(kv,Jme),e(Jme,aKo),e(kv,nKo),e(kv,Rq),e(Rq,sKo),e(kv,lKo),e(B,iKo),e(B,Rv),e(Rv,Yme),e(Yme,dKo),e(Rv,cKo),e(Rv,Sq),e(Sq,fKo),e(Rv,mKo),e(B,gKo),e(B,Sv),e(Sv,Kme),e(Kme,hKo),e(Sv,pKo),e(Sv,Pq),e(Pq,_Ko),e(Sv,uKo),e(B,bKo),e(B,Pv),e(Pv,Zme),e(Zme,vKo),e(Pv,TKo),e(Pv,$q),e($q,FKo),e(Pv,CKo),e(B,MKo),e(B,$v),e($v,ege),e(ege,EKo),e($v,yKo),e($v,Iq),e(Iq,wKo),e($v,AKo),e(B,LKo),e(B,Iv),e(Iv,oge),e(oge,BKo),e(Iv,xKo),e(Iv,jq),e(jq,kKo),e(Iv,RKo),e(B,SKo),e(B,jv),e(jv,rge),e(rge,PKo),e(jv,$Ko),e(jv,Dq),e(Dq,IKo),e(jv,jKo),e(B,DKo),e(B,Dv),e(Dv,tge),e(tge,NKo),e(Dv,qKo),e(Dv,Nq),e(Nq,OKo),e(Dv,GKo),e(B,XKo),e(B,Nv),e(Nv,age),e(age,VKo),e(Nv,zKo),e(Nv,qq),e(qq,WKo),e(Nv,QKo),e(B,HKo),e(B,qv),e(qv,nge),e(nge,UKo),e(qv,JKo),e(qv,Oq),e(Oq,YKo),e(qv,KKo),e(B,ZKo),e(B,Ov),e(Ov,sge),e(sge,eZo),e(Ov,oZo),e(Ov,Gq),e(Gq,rZo),e(Ov,tZo),e(B,aZo),e(B,Gv),e(Gv,lge),e(lge,nZo),e(Gv,sZo),e(Gv,Xq),e(Xq,lZo),e(Gv,iZo),e(B,dZo),e(B,Xv),e(Xv,ige),e(ige,cZo),e(Xv,fZo),e(Xv,Vq),e(Vq,mZo),e(Xv,gZo),e(B,hZo),e(B,Vv),e(Vv,dge),e(dge,pZo),e(Vv,_Zo),e(Vv,zq),e(zq,uZo),e(Vv,bZo),e(B,vZo),e(B,zv),e(zv,cge),e(cge,TZo),e(zv,FZo),e(zv,Wq),e(Wq,CZo),e(zv,MZo),e(B,EZo),e(B,Wv),e(Wv,fge),e(fge,yZo),e(Wv,wZo),e(Wv,Qq),e(Qq,AZo),e(Wv,LZo),e(ho,BZo),e(ho,mge),e(mge,xZo),e(ho,kZo),g(Iw,ho,null),b(c,Fke,u),b(c,pc,u),e(pc,Qv),e(Qv,gge),g(jw,gge,null),e(pc,RZo),e(pc,hge),e(hge,SZo),b(c,Cke,u),b(c,Tr,u),g(Dw,Tr,null),e(Tr,PZo),e(Tr,_c),e(_c,$Zo),e(_c,pge),e(pge,IZo),e(_c,jZo),e(_c,_ge),e(_ge,DZo),e(_c,NZo),e(Tr,qZo),e(Tr,Nw),e(Nw,OZo),e(Nw,uge),e(uge,GZo),e(Nw,XZo),e(Tr,VZo),e(Tr,ht),g(qw,ht,null),e(ht,zZo),e(ht,bge),e(bge,WZo),e(ht,QZo),e(ht,uc),e(uc,HZo),e(uc,vge),e(vge,UZo),e(uc,JZo),e(uc,Tge),e(Tge,YZo),e(uc,KZo),e(ht,ZZo),e(ht,Fge),e(Fge,eer),e(ht,oer),g(Ow,ht,null),e(Tr,rer),e(Tr,po),g(Gw,po,null),e(po,ter),e(po,Cge),e(Cge,aer),e(po,ner),e(po,_n),e(_n,ser),e(_n,Mge),e(Mge,ler),e(_n,ier),e(_n,Ege),e(Ege,der),e(_n,cer),e(_n,yge),e(yge,fer),e(_n,mer),e(po,ger),e(po,H),e(H,Hv),e(Hv,wge),e(wge,her),e(Hv,per),e(Hv,Hq),e(Hq,_er),e(Hv,uer),e(H,ber),e(H,Uv),e(Uv,Age),e(Age,ver),e(Uv,Ter),e(Uv,Uq),e(Uq,Fer),e(Uv,Cer),e(H,Mer),e(H,Jv),e(Jv,Lge),e(Lge,Eer),e(Jv,yer),e(Jv,Jq),e(Jq,wer),e(Jv,Aer),e(H,Ler),e(H,Yv),e(Yv,Bge),e(Bge,Ber),e(Yv,xer),e(Yv,Yq),e(Yq,ker),e(Yv,Rer),e(H,Ser),e(H,Kv),e(Kv,xge),e(xge,Per),e(Kv,$er),e(Kv,Kq),e(Kq,Ier),e(Kv,jer),e(H,Der),e(H,Zv),e(Zv,kge),e(kge,Ner),e(Zv,qer),e(Zv,Zq),e(Zq,Oer),e(Zv,Ger),e(H,Xer),e(H,e0),e(e0,Rge),e(Rge,Ver),e(e0,zer),e(e0,eO),e(eO,Wer),e(e0,Qer),e(H,Her),e(H,o0),e(o0,Sge),e(Sge,Uer),e(o0,Jer),e(o0,oO),e(oO,Yer),e(o0,Ker),e(H,Zer),e(H,r0),e(r0,Pge),e(Pge,eor),e(r0,oor),e(r0,rO),e(rO,ror),e(r0,tor),e(H,aor),e(H,t0),e(t0,$ge),e($ge,nor),e(t0,sor),e(t0,tO),e(tO,lor),e(t0,ior),e(H,dor),e(H,a0),e(a0,Ige),e(Ige,cor),e(a0,mor),e(a0,aO),e(aO,gor),e(a0,hor),e(H,por),e(H,n0),e(n0,jge),e(jge,_or),e(n0,uor),e(n0,nO),e(nO,bor),e(n0,vor),e(H,Tor),e(H,s0),e(s0,Dge),e(Dge,For),e(s0,Cor),e(s0,sO),e(sO,Mor),e(s0,Eor),e(H,yor),e(H,l0),e(l0,Nge),e(Nge,wor),e(l0,Aor),e(l0,lO),e(lO,Lor),e(l0,Bor),e(H,xor),e(H,i0),e(i0,qge),e(qge,kor),e(i0,Ror),e(i0,iO),e(iO,Sor),e(i0,Por),e(H,$or),e(H,d0),e(d0,Oge),e(Oge,Ior),e(d0,jor),e(d0,dO),e(dO,Dor),e(d0,Nor),e(H,qor),e(H,c0),e(c0,Gge),e(Gge,Oor),e(c0,Gor),e(c0,cO),e(cO,Xor),e(c0,Vor),e(H,zor),e(H,f0),e(f0,Xge),e(Xge,Wor),e(f0,Qor),e(f0,fO),e(fO,Hor),e(f0,Uor),e(H,Jor),e(H,m0),e(m0,Vge),e(Vge,Yor),e(m0,Kor),e(m0,mO),e(mO,Zor),e(m0,err),e(H,orr),e(H,g0),e(g0,zge),e(zge,rrr),e(g0,trr),e(g0,gO),e(gO,arr),e(g0,nrr),e(H,srr),e(H,h0),e(h0,Wge),e(Wge,lrr),e(h0,irr),e(h0,hO),e(hO,drr),e(h0,crr),e(H,frr),e(H,p0),e(p0,Qge),e(Qge,mrr),e(p0,grr),e(p0,pO),e(pO,hrr),e(p0,prr),e(po,_rr),e(po,Hge),e(Hge,urr),e(po,brr),g(Xw,po,null),b(c,Mke,u),b(c,bc,u),e(bc,_0),e(_0,Uge),g(Vw,Uge,null),e(bc,vrr),e(bc,Jge),e(Jge,Trr),b(c,Eke,u),b(c,Fr,u),g(zw,Fr,null),e(Fr,Frr),e(Fr,vc),e(vc,Crr),e(vc,Yge),e(Yge,Mrr),e(vc,Err),e(vc,Kge),e(Kge,yrr),e(vc,wrr),e(Fr,Arr),e(Fr,Ww),e(Ww,Lrr),e(Ww,Zge),e(Zge,Brr),e(Ww,xrr),e(Fr,krr),e(Fr,pt),g(Qw,pt,null),e(pt,Rrr),e(pt,ehe),e(ehe,Srr),e(pt,Prr),e(pt,Tc),e(Tc,$rr),e(Tc,ohe),e(ohe,Irr),e(Tc,jrr),e(Tc,rhe),e(rhe,Drr),e(Tc,Nrr),e(pt,qrr),e(pt,the),e(the,Orr),e(pt,Grr),g(Hw,pt,null),e(Fr,Xrr),e(Fr,_o),g(Uw,_o,null),e(_o,Vrr),e(_o,ahe),e(ahe,zrr),e(_o,Wrr),e(_o,un),e(un,Qrr),e(un,nhe),e(nhe,Hrr),e(un,Urr),e(un,she),e(she,Jrr),e(un,Yrr),e(un,lhe),e(lhe,Krr),e(un,Zrr),e(_o,etr),e(_o,_e),e(_e,u0),e(u0,ihe),e(ihe,otr),e(u0,rtr),e(u0,_O),e(_O,ttr),e(u0,atr),e(_e,ntr),e(_e,b0),e(b0,dhe),e(dhe,str),e(b0,ltr),e(b0,uO),e(uO,itr),e(b0,dtr),e(_e,ctr),e(_e,v0),e(v0,che),e(che,ftr),e(v0,mtr),e(v0,bO),e(bO,gtr),e(v0,htr),e(_e,ptr),e(_e,T0),e(T0,fhe),e(fhe,_tr),e(T0,utr),e(T0,vO),e(vO,btr),e(T0,vtr),e(_e,Ttr),e(_e,F0),e(F0,mhe),e(mhe,Ftr),e(F0,Ctr),e(F0,TO),e(TO,Mtr),e(F0,Etr),e(_e,ytr),e(_e,C0),e(C0,ghe),e(ghe,wtr),e(C0,Atr),e(C0,FO),e(FO,Ltr),e(C0,Btr),e(_e,xtr),e(_e,M0),e(M0,hhe),e(hhe,ktr),e(M0,Rtr),e(M0,CO),e(CO,Str),e(M0,Ptr),e(_e,$tr),e(_e,E0),e(E0,phe),e(phe,Itr),e(E0,jtr),e(E0,MO),e(MO,Dtr),e(E0,Ntr),e(_e,qtr),e(_e,y0),e(y0,_he),e(_he,Otr),e(y0,Gtr),e(y0,EO),e(EO,Xtr),e(y0,Vtr),e(_e,ztr),e(_e,w0),e(w0,uhe),e(uhe,Wtr),e(w0,Qtr),e(w0,yO),e(yO,Htr),e(w0,Utr),e(_o,Jtr),e(_o,bhe),e(bhe,Ytr),e(_o,Ktr),g(Jw,_o,null),b(c,yke,u),b(c,Fc,u),e(Fc,A0),e(A0,vhe),g(Yw,vhe,null),e(Fc,Ztr),e(Fc,The),e(The,ear),b(c,wke,u),b(c,Cr,u),g(Kw,Cr,null),e(Cr,oar),e(Cr,Cc),e(Cc,rar),e(Cc,Fhe),e(Fhe,tar),e(Cc,aar),e(Cc,Che),e(Che,nar),e(Cc,sar),e(Cr,lar),e(Cr,Zw),e(Zw,iar),e(Zw,Mhe),e(Mhe,dar),e(Zw,car),e(Cr,far),e(Cr,_t),g(e6,_t,null),e(_t,mar),e(_t,Ehe),e(Ehe,gar),e(_t,har),e(_t,Mc),e(Mc,par),e(Mc,yhe),e(yhe,_ar),e(Mc,uar),e(Mc,whe),e(whe,bar),e(Mc,Tar),e(_t,Far),e(_t,Ahe),e(Ahe,Car),e(_t,Mar),g(o6,_t,null),e(Cr,Ear),e(Cr,uo),g(r6,uo,null),e(uo,yar),e(uo,Lhe),e(Lhe,war),e(uo,Aar),e(uo,bn),e(bn,Lar),e(bn,Bhe),e(Bhe,Bar),e(bn,xar),e(bn,xhe),e(xhe,kar),e(bn,Rar),e(bn,khe),e(khe,Sar),e(bn,Par),e(uo,$ar),e(uo,t6),e(t6,L0),e(L0,Rhe),e(Rhe,Iar),e(L0,jar),e(L0,wO),e(wO,Dar),e(L0,Nar),e(t6,qar),e(t6,B0),e(B0,She),e(She,Oar),e(B0,Gar),e(B0,AO),e(AO,Xar),e(B0,Var),e(uo,zar),e(uo,Phe),e(Phe,War),e(uo,Qar),g(a6,uo,null),b(c,Ake,u),b(c,Ec,u),e(Ec,x0),e(x0,$he),g(n6,$he,null),e(Ec,Har),e(Ec,Ihe),e(Ihe,Uar),b(c,Lke,u),b(c,Mr,u),g(s6,Mr,null),e(Mr,Jar),e(Mr,yc),e(yc,Yar),e(yc,jhe),e(jhe,Kar),e(yc,Zar),e(yc,Dhe),e(Dhe,enr),e(yc,onr),e(Mr,rnr),e(Mr,l6),e(l6,tnr),e(l6,Nhe),e(Nhe,anr),e(l6,nnr),e(Mr,snr),e(Mr,ut),g(i6,ut,null),e(ut,lnr),e(ut,qhe),e(qhe,inr),e(ut,dnr),e(ut,wc),e(wc,cnr),e(wc,Ohe),e(Ohe,fnr),e(wc,mnr),e(wc,Ghe),e(Ghe,gnr),e(wc,hnr),e(ut,pnr),e(ut,Xhe),e(Xhe,_nr),e(ut,unr),g(d6,ut,null),e(Mr,bnr),e(Mr,bo),g(c6,bo,null),e(bo,vnr),e(bo,Vhe),e(Vhe,Tnr),e(bo,Fnr),e(bo,vn),e(vn,Cnr),e(vn,zhe),e(zhe,Mnr),e(vn,Enr),e(vn,Whe),e(Whe,ynr),e(vn,wnr),e(vn,Qhe),e(Qhe,Anr),e(vn,Lnr),e(bo,Bnr),e(bo,Y),e(Y,k0),e(k0,Hhe),e(Hhe,xnr),e(k0,knr),e(k0,LO),e(LO,Rnr),e(k0,Snr),e(Y,Pnr),e(Y,R0),e(R0,Uhe),e(Uhe,$nr),e(R0,Inr),e(R0,BO),e(BO,jnr),e(R0,Dnr),e(Y,Nnr),e(Y,S0),e(S0,Jhe),e(Jhe,qnr),e(S0,Onr),e(S0,xO),e(xO,Gnr),e(S0,Xnr),e(Y,Vnr),e(Y,P0),e(P0,Yhe),e(Yhe,znr),e(P0,Wnr),e(P0,kO),e(kO,Qnr),e(P0,Hnr),e(Y,Unr),e(Y,$0),e($0,Khe),e(Khe,Jnr),e($0,Ynr),e($0,RO),e(RO,Knr),e($0,Znr),e(Y,esr),e(Y,I0),e(I0,Zhe),e(Zhe,osr),e(I0,rsr),e(I0,SO),e(SO,tsr),e(I0,asr),e(Y,nsr),e(Y,j0),e(j0,epe),e(epe,ssr),e(j0,lsr),e(j0,PO),e(PO,isr),e(j0,dsr),e(Y,csr),e(Y,D0),e(D0,ope),e(ope,fsr),e(D0,msr),e(D0,$O),e($O,gsr),e(D0,hsr),e(Y,psr),e(Y,N0),e(N0,rpe),e(rpe,_sr),e(N0,usr),e(N0,IO),e(IO,bsr),e(N0,vsr),e(Y,Tsr),e(Y,q0),e(q0,tpe),e(tpe,Fsr),e(q0,Csr),e(q0,jO),e(jO,Msr),e(q0,Esr),e(Y,ysr),e(Y,O0),e(O0,ape),e(ape,wsr),e(O0,Asr),e(O0,DO),e(DO,Lsr),e(O0,Bsr),e(Y,xsr),e(Y,G0),e(G0,npe),e(npe,ksr),e(G0,Rsr),e(G0,NO),e(NO,Ssr),e(G0,Psr),e(Y,$sr),e(Y,X0),e(X0,spe),e(spe,Isr),e(X0,jsr),e(X0,qO),e(qO,Dsr),e(X0,Nsr),e(Y,qsr),e(Y,V0),e(V0,lpe),e(lpe,Osr),e(V0,Gsr),e(V0,OO),e(OO,Xsr),e(V0,Vsr),e(Y,zsr),e(Y,z0),e(z0,ipe),e(ipe,Wsr),e(z0,Qsr),e(z0,GO),e(GO,Hsr),e(z0,Usr),e(Y,Jsr),e(Y,W0),e(W0,dpe),e(dpe,Ysr),e(W0,Ksr),e(W0,XO),e(XO,Zsr),e(W0,elr),e(Y,olr),e(Y,Q0),e(Q0,cpe),e(cpe,rlr),e(Q0,tlr),e(Q0,VO),e(VO,alr),e(Q0,nlr),e(Y,slr),e(Y,H0),e(H0,fpe),e(fpe,llr),e(H0,ilr),e(H0,zO),e(zO,dlr),e(H0,clr),e(Y,flr),e(Y,U0),e(U0,mpe),e(mpe,mlr),e(U0,glr),e(U0,WO),e(WO,hlr),e(U0,plr),e(Y,_lr),e(Y,J0),e(J0,gpe),e(gpe,ulr),e(J0,blr),e(J0,QO),e(QO,vlr),e(J0,Tlr),e(bo,Flr),e(bo,hpe),e(hpe,Clr),e(bo,Mlr),g(f6,bo,null),b(c,Bke,u),b(c,Ac,u),e(Ac,Y0),e(Y0,ppe),g(m6,ppe,null),e(Ac,Elr),e(Ac,_pe),e(_pe,ylr),b(c,xke,u),b(c,Er,u),g(g6,Er,null),e(Er,wlr),e(Er,Lc),e(Lc,Alr),e(Lc,upe),e(upe,Llr),e(Lc,Blr),e(Lc,bpe),e(bpe,xlr),e(Lc,klr),e(Er,Rlr),e(Er,h6),e(h6,Slr),e(h6,vpe),e(vpe,Plr),e(h6,$lr),e(Er,Ilr),e(Er,bt),g(p6,bt,null),e(bt,jlr),e(bt,Tpe),e(Tpe,Dlr),e(bt,Nlr),e(bt,Bc),e(Bc,qlr),e(Bc,Fpe),e(Fpe,Olr),e(Bc,Glr),e(Bc,Cpe),e(Cpe,Xlr),e(Bc,Vlr),e(bt,zlr),e(bt,Mpe),e(Mpe,Wlr),e(bt,Qlr),g(_6,bt,null),e(Er,Hlr),e(Er,vo),g(u6,vo,null),e(vo,Ulr),e(vo,Epe),e(Epe,Jlr),e(vo,Ylr),e(vo,Tn),e(Tn,Klr),e(Tn,ype),e(ype,Zlr),e(Tn,eir),e(Tn,wpe),e(wpe,oir),e(Tn,rir),e(Tn,Ape),e(Ape,tir),e(Tn,air),e(vo,nir),e(vo,ue),e(ue,K0),e(K0,Lpe),e(Lpe,sir),e(K0,lir),e(K0,HO),e(HO,iir),e(K0,dir),e(ue,cir),e(ue,Z0),e(Z0,Bpe),e(Bpe,fir),e(Z0,mir),e(Z0,UO),e(UO,gir),e(Z0,hir),e(ue,pir),e(ue,eT),e(eT,xpe),e(xpe,_ir),e(eT,uir),e(eT,JO),e(JO,bir),e(eT,vir),e(ue,Tir),e(ue,oT),e(oT,kpe),e(kpe,Fir),e(oT,Cir),e(oT,YO),e(YO,Mir),e(oT,Eir),e(ue,yir),e(ue,rT),e(rT,Rpe),e(Rpe,wir),e(rT,Air),e(rT,KO),e(KO,Lir),e(rT,Bir),e(ue,xir),e(ue,tT),e(tT,Spe),e(Spe,kir),e(tT,Rir),e(tT,ZO),e(ZO,Sir),e(tT,Pir),e(ue,$ir),e(ue,aT),e(aT,Ppe),e(Ppe,Iir),e(aT,jir),e(aT,eG),e(eG,Dir),e(aT,Nir),e(ue,qir),e(ue,nT),e(nT,$pe),e($pe,Oir),e(nT,Gir),e(nT,oG),e(oG,Xir),e(nT,Vir),e(ue,zir),e(ue,sT),e(sT,Ipe),e(Ipe,Wir),e(sT,Qir),e(sT,rG),e(rG,Hir),e(sT,Uir),e(ue,Jir),e(ue,lT),e(lT,jpe),e(jpe,Yir),e(lT,Kir),e(lT,tG),e(tG,Zir),e(lT,edr),e(vo,odr),e(vo,Dpe),e(Dpe,rdr),e(vo,tdr),g(b6,vo,null),b(c,kke,u),b(c,xc,u),e(xc,iT),e(iT,Npe),g(v6,Npe,null),e(xc,adr),e(xc,qpe),e(qpe,ndr),b(c,Rke,u),b(c,yr,u),g(T6,yr,null),e(yr,sdr),e(yr,kc),e(kc,ldr),e(kc,Ope),e(Ope,idr),e(kc,ddr),e(kc,Gpe),e(Gpe,cdr),e(kc,fdr),e(yr,mdr),e(yr,F6),e(F6,gdr),e(F6,Xpe),e(Xpe,hdr),e(F6,pdr),e(yr,_dr),e(yr,vt),g(C6,vt,null),e(vt,udr),e(vt,Vpe),e(Vpe,bdr),e(vt,vdr),e(vt,Rc),e(Rc,Tdr),e(Rc,zpe),e(zpe,Fdr),e(Rc,Cdr),e(Rc,Wpe),e(Wpe,Mdr),e(Rc,Edr),e(vt,ydr),e(vt,Qpe),e(Qpe,wdr),e(vt,Adr),g(M6,vt,null),e(yr,Ldr),e(yr,To),g(E6,To,null),e(To,Bdr),e(To,Hpe),e(Hpe,xdr),e(To,kdr),e(To,Fn),e(Fn,Rdr),e(Fn,Upe),e(Upe,Sdr),e(Fn,Pdr),e(Fn,Jpe),e(Jpe,$dr),e(Fn,Idr),e(Fn,Ype),e(Ype,jdr),e(Fn,Ddr),e(To,Ndr),e(To,V),e(V,dT),e(dT,Kpe),e(Kpe,qdr),e(dT,Odr),e(dT,aG),e(aG,Gdr),e(dT,Xdr),e(V,Vdr),e(V,cT),e(cT,Zpe),e(Zpe,zdr),e(cT,Wdr),e(cT,nG),e(nG,Qdr),e(cT,Hdr),e(V,Udr),e(V,fT),e(fT,e_e),e(e_e,Jdr),e(fT,Ydr),e(fT,sG),e(sG,Kdr),e(fT,Zdr),e(V,ecr),e(V,mT),e(mT,o_e),e(o_e,ocr),e(mT,rcr),e(mT,lG),e(lG,tcr),e(mT,acr),e(V,ncr),e(V,gT),e(gT,r_e),e(r_e,scr),e(gT,lcr),e(gT,iG),e(iG,icr),e(gT,dcr),e(V,ccr),e(V,hT),e(hT,t_e),e(t_e,fcr),e(hT,mcr),e(hT,dG),e(dG,gcr),e(hT,hcr),e(V,pcr),e(V,pT),e(pT,a_e),e(a_e,_cr),e(pT,ucr),e(pT,cG),e(cG,bcr),e(pT,vcr),e(V,Tcr),e(V,_T),e(_T,n_e),e(n_e,Fcr),e(_T,Ccr),e(_T,fG),e(fG,Mcr),e(_T,Ecr),e(V,ycr),e(V,uT),e(uT,s_e),e(s_e,wcr),e(uT,Acr),e(uT,mG),e(mG,Lcr),e(uT,Bcr),e(V,xcr),e(V,bT),e(bT,l_e),e(l_e,kcr),e(bT,Rcr),e(bT,gG),e(gG,Scr),e(bT,Pcr),e(V,$cr),e(V,vT),e(vT,i_e),e(i_e,Icr),e(vT,jcr),e(vT,hG),e(hG,Dcr),e(vT,Ncr),e(V,qcr),e(V,TT),e(TT,d_e),e(d_e,Ocr),e(TT,Gcr),e(TT,pG),e(pG,Xcr),e(TT,Vcr),e(V,zcr),e(V,FT),e(FT,c_e),e(c_e,Wcr),e(FT,Qcr),e(FT,_G),e(_G,Hcr),e(FT,Ucr),e(V,Jcr),e(V,CT),e(CT,f_e),e(f_e,Ycr),e(CT,Kcr),e(CT,uG),e(uG,Zcr),e(CT,efr),e(V,ofr),e(V,MT),e(MT,m_e),e(m_e,rfr),e(MT,tfr),e(MT,bG),e(bG,afr),e(MT,nfr),e(V,sfr),e(V,ET),e(ET,g_e),e(g_e,lfr),e(ET,ifr),e(ET,vG),e(vG,dfr),e(ET,cfr),e(V,ffr),e(V,yT),e(yT,h_e),e(h_e,mfr),e(yT,gfr),e(yT,TG),e(TG,hfr),e(yT,pfr),e(V,_fr),e(V,wT),e(wT,p_e),e(p_e,ufr),e(wT,bfr),e(wT,FG),e(FG,vfr),e(wT,Tfr),e(V,Ffr),e(V,AT),e(AT,__e),e(__e,Cfr),e(AT,Mfr),e(AT,CG),e(CG,Efr),e(AT,yfr),e(V,wfr),e(V,LT),e(LT,u_e),e(u_e,Afr),e(LT,Lfr),e(LT,MG),e(MG,Bfr),e(LT,xfr),e(V,kfr),e(V,BT),e(BT,b_e),e(b_e,Rfr),e(BT,Sfr),e(BT,EG),e(EG,Pfr),e(BT,$fr),e(V,Ifr),e(V,xT),e(xT,v_e),e(v_e,jfr),e(xT,Dfr),e(xT,yG),e(yG,Nfr),e(xT,qfr),e(V,Ofr),e(V,kT),e(kT,T_e),e(T_e,Gfr),e(kT,Xfr),e(kT,wG),e(wG,Vfr),e(kT,zfr),e(V,Wfr),e(V,RT),e(RT,F_e),e(F_e,Qfr),e(RT,Hfr),e(RT,AG),e(AG,Ufr),e(RT,Jfr),e(V,Yfr),e(V,ST),e(ST,C_e),e(C_e,Kfr),e(ST,Zfr),e(ST,LG),e(LG,emr),e(ST,omr),e(To,rmr),e(To,M_e),e(M_e,tmr),e(To,amr),g(y6,To,null),b(c,Ske,u),b(c,Sc,u),e(Sc,PT),e(PT,E_e),g(w6,E_e,null),e(Sc,nmr),e(Sc,y_e),e(y_e,smr),b(c,Pke,u),b(c,wr,u),g(A6,wr,null),e(wr,lmr),e(wr,Pc),e(Pc,imr),e(Pc,w_e),e(w_e,dmr),e(Pc,cmr),e(Pc,A_e),e(A_e,fmr),e(Pc,mmr),e(wr,gmr),e(wr,L6),e(L6,hmr),e(L6,L_e),e(L_e,pmr),e(L6,_mr),e(wr,umr),e(wr,Tt),g(B6,Tt,null),e(Tt,bmr),e(Tt,B_e),e(B_e,vmr),e(Tt,Tmr),e(Tt,$c),e($c,Fmr),e($c,x_e),e(x_e,Cmr),e($c,Mmr),e($c,k_e),e(k_e,Emr),e($c,ymr),e(Tt,wmr),e(Tt,R_e),e(R_e,Amr),e(Tt,Lmr),g(x6,Tt,null),e(wr,Bmr),e(wr,Fo),g(k6,Fo,null),e(Fo,xmr),e(Fo,S_e),e(S_e,kmr),e(Fo,Rmr),e(Fo,Cn),e(Cn,Smr),e(Cn,P_e),e(P_e,Pmr),e(Cn,$mr),e(Cn,$_e),e($_e,Imr),e(Cn,jmr),e(Cn,I_e),e(I_e,Dmr),e(Cn,Nmr),e(Fo,qmr),e(Fo,ae),e(ae,$T),e($T,j_e),e(j_e,Omr),e($T,Gmr),e($T,BG),e(BG,Xmr),e($T,Vmr),e(ae,zmr),e(ae,IT),e(IT,D_e),e(D_e,Wmr),e(IT,Qmr),e(IT,xG),e(xG,Hmr),e(IT,Umr),e(ae,Jmr),e(ae,jT),e(jT,N_e),e(N_e,Ymr),e(jT,Kmr),e(jT,kG),e(kG,Zmr),e(jT,egr),e(ae,ogr),e(ae,DT),e(DT,q_e),e(q_e,rgr),e(DT,tgr),e(DT,RG),e(RG,agr),e(DT,ngr),e(ae,sgr),e(ae,NT),e(NT,O_e),e(O_e,lgr),e(NT,igr),e(NT,SG),e(SG,dgr),e(NT,cgr),e(ae,fgr),e(ae,qT),e(qT,G_e),e(G_e,mgr),e(qT,ggr),e(qT,PG),e(PG,hgr),e(qT,pgr),e(ae,_gr),e(ae,OT),e(OT,X_e),e(X_e,ugr),e(OT,bgr),e(OT,$G),e($G,vgr),e(OT,Tgr),e(ae,Fgr),e(ae,GT),e(GT,V_e),e(V_e,Cgr),e(GT,Mgr),e(GT,IG),e(IG,Egr),e(GT,ygr),e(ae,wgr),e(ae,XT),e(XT,z_e),e(z_e,Agr),e(XT,Lgr),e(XT,jG),e(jG,Bgr),e(XT,xgr),e(ae,kgr),e(ae,VT),e(VT,W_e),e(W_e,Rgr),e(VT,Sgr),e(VT,DG),e(DG,Pgr),e(VT,$gr),e(ae,Igr),e(ae,zT),e(zT,Q_e),e(Q_e,jgr),e(zT,Dgr),e(zT,NG),e(NG,Ngr),e(zT,qgr),e(ae,Ogr),e(ae,WT),e(WT,H_e),e(H_e,Ggr),e(WT,Xgr),e(WT,qG),e(qG,Vgr),e(WT,zgr),e(ae,Wgr),e(ae,QT),e(QT,U_e),e(U_e,Qgr),e(QT,Hgr),e(QT,OG),e(OG,Ugr),e(QT,Jgr),e(ae,Ygr),e(ae,HT),e(HT,J_e),e(J_e,Kgr),e(HT,Zgr),e(HT,GG),e(GG,ehr),e(HT,ohr),e(ae,rhr),e(ae,UT),e(UT,Y_e),e(Y_e,thr),e(UT,ahr),e(UT,XG),e(XG,nhr),e(UT,shr),e(ae,lhr),e(ae,JT),e(JT,K_e),e(K_e,ihr),e(JT,dhr),e(JT,VG),e(VG,chr),e(JT,fhr),e(ae,mhr),e(ae,YT),e(YT,Z_e),e(Z_e,ghr),e(YT,hhr),e(YT,zG),e(zG,phr),e(YT,_hr),e(Fo,uhr),e(Fo,eue),e(eue,bhr),e(Fo,vhr),g(R6,Fo,null),b(c,$ke,u),b(c,Ic,u),e(Ic,KT),e(KT,oue),g(S6,oue,null),e(Ic,Thr),e(Ic,rue),e(rue,Fhr),b(c,Ike,u),b(c,Ar,u),g(P6,Ar,null),e(Ar,Chr),e(Ar,jc),e(jc,Mhr),e(jc,tue),e(tue,Ehr),e(jc,yhr),e(jc,aue),e(aue,whr),e(jc,Ahr),e(Ar,Lhr),e(Ar,$6),e($6,Bhr),e($6,nue),e(nue,xhr),e($6,khr),e(Ar,Rhr),e(Ar,Ft),g(I6,Ft,null),e(Ft,Shr),e(Ft,sue),e(sue,Phr),e(Ft,$hr),e(Ft,Dc),e(Dc,Ihr),e(Dc,lue),e(lue,jhr),e(Dc,Dhr),e(Dc,iue),e(iue,Nhr),e(Dc,qhr),e(Ft,Ohr),e(Ft,due),e(due,Ghr),e(Ft,Xhr),g(j6,Ft,null),e(Ar,Vhr),e(Ar,Co),g(D6,Co,null),e(Co,zhr),e(Co,cue),e(cue,Whr),e(Co,Qhr),e(Co,Mn),e(Mn,Hhr),e(Mn,fue),e(fue,Uhr),e(Mn,Jhr),e(Mn,mue),e(mue,Yhr),e(Mn,Khr),e(Mn,gue),e(gue,Zhr),e(Mn,epr),e(Co,opr),e(Co,hue),e(hue,ZT),e(ZT,pue),e(pue,rpr),e(ZT,tpr),e(ZT,WG),e(WG,apr),e(ZT,npr),e(Co,spr),e(Co,_ue),e(_ue,lpr),e(Co,ipr),g(N6,Co,null),b(c,jke,u),b(c,Nc,u),e(Nc,eF),e(eF,uue),g(q6,uue,null),e(Nc,dpr),e(Nc,bue),e(bue,cpr),b(c,Dke,u),b(c,Lr,u),g(O6,Lr,null),e(Lr,fpr),e(Lr,qc),e(qc,mpr),e(qc,vue),e(vue,gpr),e(qc,hpr),e(qc,Tue),e(Tue,ppr),e(qc,_pr),e(Lr,upr),e(Lr,G6),e(G6,bpr),e(G6,Fue),e(Fue,vpr),e(G6,Tpr),e(Lr,Fpr),e(Lr,Ct),g(X6,Ct,null),e(Ct,Cpr),e(Ct,Cue),e(Cue,Mpr),e(Ct,Epr),e(Ct,Oc),e(Oc,ypr),e(Oc,Mue),e(Mue,wpr),e(Oc,Apr),e(Oc,Eue),e(Eue,Lpr),e(Oc,Bpr),e(Ct,xpr),e(Ct,yue),e(yue,kpr),e(Ct,Rpr),g(V6,Ct,null),e(Lr,Spr),e(Lr,Mo),g(z6,Mo,null),e(Mo,Ppr),e(Mo,wue),e(wue,$pr),e(Mo,Ipr),e(Mo,En),e(En,jpr),e(En,Aue),e(Aue,Dpr),e(En,Npr),e(En,Lue),e(Lue,qpr),e(En,Opr),e(En,Bue),e(Bue,Gpr),e(En,Xpr),e(Mo,Vpr),e(Mo,K),e(K,oF),e(oF,xue),e(xue,zpr),e(oF,Wpr),e(oF,QG),e(QG,Qpr),e(oF,Hpr),e(K,Upr),e(K,rF),e(rF,kue),e(kue,Jpr),e(rF,Ypr),e(rF,HG),e(HG,Kpr),e(rF,Zpr),e(K,e_r),e(K,tF),e(tF,Rue),e(Rue,o_r),e(tF,r_r),e(tF,UG),e(UG,t_r),e(tF,a_r),e(K,n_r),e(K,aF),e(aF,Sue),e(Sue,s_r),e(aF,l_r),e(aF,JG),e(JG,i_r),e(aF,d_r),e(K,c_r),e(K,nF),e(nF,Pue),e(Pue,f_r),e(nF,m_r),e(nF,YG),e(YG,g_r),e(nF,h_r),e(K,p_r),e(K,sF),e(sF,$ue),e($ue,__r),e(sF,u_r),e(sF,KG),e(KG,b_r),e(sF,v_r),e(K,T_r),e(K,lF),e(lF,Iue),e(Iue,F_r),e(lF,C_r),e(lF,ZG),e(ZG,M_r),e(lF,E_r),e(K,y_r),e(K,iF),e(iF,jue),e(jue,w_r),e(iF,A_r),e(iF,eX),e(eX,L_r),e(iF,B_r),e(K,x_r),e(K,dF),e(dF,Due),e(Due,k_r),e(dF,R_r),e(dF,oX),e(oX,S_r),e(dF,P_r),e(K,$_r),e(K,cF),e(cF,Nue),e(Nue,I_r),e(cF,j_r),e(cF,rX),e(rX,D_r),e(cF,N_r),e(K,q_r),e(K,fF),e(fF,que),e(que,O_r),e(fF,G_r),e(fF,tX),e(tX,X_r),e(fF,V_r),e(K,z_r),e(K,mF),e(mF,Oue),e(Oue,W_r),e(mF,Q_r),e(mF,aX),e(aX,H_r),e(mF,U_r),e(K,J_r),e(K,gF),e(gF,Gue),e(Gue,Y_r),e(gF,K_r),e(gF,nX),e(nX,Z_r),e(gF,eur),e(K,our),e(K,hF),e(hF,Xue),e(Xue,rur),e(hF,tur),e(hF,sX),e(sX,aur),e(hF,nur),e(K,sur),e(K,pF),e(pF,Vue),e(Vue,lur),e(pF,iur),e(pF,lX),e(lX,dur),e(pF,cur),e(K,fur),e(K,_F),e(_F,zue),e(zue,mur),e(_F,gur),e(_F,iX),e(iX,hur),e(_F,pur),e(K,_ur),e(K,uF),e(uF,Wue),e(Wue,uur),e(uF,bur),e(uF,dX),e(dX,vur),e(uF,Tur),e(K,Fur),e(K,bF),e(bF,Que),e(Que,Cur),e(bF,Mur),e(bF,cX),e(cX,Eur),e(bF,yur),e(K,wur),e(K,vF),e(vF,Hue),e(Hue,Aur),e(vF,Lur),e(vF,fX),e(fX,Bur),e(vF,xur),e(K,kur),e(K,TF),e(TF,Uue),e(Uue,Rur),e(TF,Sur),e(TF,mX),e(mX,Pur),e(TF,$ur),e(Mo,Iur),e(Mo,Jue),e(Jue,jur),e(Mo,Dur),g(W6,Mo,null),b(c,Nke,u),b(c,Gc,u),e(Gc,FF),e(FF,Yue),g(Q6,Yue,null),e(Gc,Nur),e(Gc,Kue),e(Kue,qur),b(c,qke,u),b(c,Br,u),g(H6,Br,null),e(Br,Our),e(Br,Xc),e(Xc,Gur),e(Xc,Zue),e(Zue,Xur),e(Xc,Vur),e(Xc,e1e),e(e1e,zur),e(Xc,Wur),e(Br,Qur),e(Br,U6),e(U6,Hur),e(U6,o1e),e(o1e,Uur),e(U6,Jur),e(Br,Yur),e(Br,Mt),g(J6,Mt,null),e(Mt,Kur),e(Mt,r1e),e(r1e,Zur),e(Mt,e1r),e(Mt,Vc),e(Vc,o1r),e(Vc,t1e),e(t1e,r1r),e(Vc,t1r),e(Vc,a1e),e(a1e,a1r),e(Vc,n1r),e(Mt,s1r),e(Mt,n1e),e(n1e,l1r),e(Mt,i1r),g(Y6,Mt,null),e(Br,d1r),e(Br,Eo),g(K6,Eo,null),e(Eo,c1r),e(Eo,s1e),e(s1e,f1r),e(Eo,m1r),e(Eo,yn),e(yn,g1r),e(yn,l1e),e(l1e,h1r),e(yn,p1r),e(yn,i1e),e(i1e,_1r),e(yn,u1r),e(yn,d1e),e(d1e,b1r),e(yn,v1r),e(Eo,T1r),e(Eo,Z),e(Z,CF),e(CF,c1e),e(c1e,F1r),e(CF,C1r),e(CF,gX),e(gX,M1r),e(CF,E1r),e(Z,y1r),e(Z,MF),e(MF,f1e),e(f1e,w1r),e(MF,A1r),e(MF,hX),e(hX,L1r),e(MF,B1r),e(Z,x1r),e(Z,EF),e(EF,m1e),e(m1e,k1r),e(EF,R1r),e(EF,pX),e(pX,S1r),e(EF,P1r),e(Z,$1r),e(Z,yF),e(yF,g1e),e(g1e,I1r),e(yF,j1r),e(yF,_X),e(_X,D1r),e(yF,N1r),e(Z,q1r),e(Z,wF),e(wF,h1e),e(h1e,O1r),e(wF,G1r),e(wF,uX),e(uX,X1r),e(wF,V1r),e(Z,z1r),e(Z,AF),e(AF,p1e),e(p1e,W1r),e(AF,Q1r),e(AF,bX),e(bX,H1r),e(AF,U1r),e(Z,J1r),e(Z,LF),e(LF,_1e),e(_1e,Y1r),e(LF,K1r),e(LF,vX),e(vX,Z1r),e(LF,e7r),e(Z,o7r),e(Z,BF),e(BF,u1e),e(u1e,r7r),e(BF,t7r),e(BF,TX),e(TX,a7r),e(BF,n7r),e(Z,s7r),e(Z,xF),e(xF,b1e),e(b1e,l7r),e(xF,i7r),e(xF,FX),e(FX,d7r),e(xF,c7r),e(Z,f7r),e(Z,kF),e(kF,v1e),e(v1e,m7r),e(kF,g7r),e(kF,CX),e(CX,h7r),e(kF,p7r),e(Z,_7r),e(Z,RF),e(RF,T1e),e(T1e,u7r),e(RF,b7r),e(RF,MX),e(MX,v7r),e(RF,T7r),e(Z,F7r),e(Z,SF),e(SF,F1e),e(F1e,C7r),e(SF,M7r),e(SF,EX),e(EX,E7r),e(SF,y7r),e(Z,w7r),e(Z,PF),e(PF,C1e),e(C1e,A7r),e(PF,L7r),e(PF,yX),e(yX,B7r),e(PF,x7r),e(Z,k7r),e(Z,$F),e($F,M1e),e(M1e,R7r),e($F,S7r),e($F,wX),e(wX,P7r),e($F,$7r),e(Z,I7r),e(Z,IF),e(IF,E1e),e(E1e,j7r),e(IF,D7r),e(IF,AX),e(AX,N7r),e(IF,q7r),e(Z,O7r),e(Z,jF),e(jF,y1e),e(y1e,G7r),e(jF,X7r),e(jF,LX),e(LX,V7r),e(jF,z7r),e(Z,W7r),e(Z,DF),e(DF,w1e),e(w1e,Q7r),e(DF,H7r),e(DF,BX),e(BX,U7r),e(DF,J7r),e(Z,Y7r),e(Z,NF),e(NF,A1e),e(A1e,K7r),e(NF,Z7r),e(NF,xX),e(xX,ebr),e(NF,obr),e(Z,rbr),e(Z,qF),e(qF,L1e),e(L1e,tbr),e(qF,abr),e(qF,kX),e(kX,nbr),e(qF,sbr),e(Eo,lbr),e(Eo,B1e),e(B1e,ibr),e(Eo,dbr),g(Z6,Eo,null),b(c,Oke,u),b(c,zc,u),e(zc,OF),e(OF,x1e),g(eA,x1e,null),e(zc,cbr),e(zc,k1e),e(k1e,fbr),b(c,Gke,u),b(c,xr,u),g(oA,xr,null),e(xr,mbr),e(xr,Wc),e(Wc,gbr),e(Wc,R1e),e(R1e,hbr),e(Wc,pbr),e(Wc,S1e),e(S1e,_br),e(Wc,ubr),e(xr,bbr),e(xr,rA),e(rA,vbr),e(rA,P1e),e(P1e,Tbr),e(rA,Fbr),e(xr,Cbr),e(xr,Et),g(tA,Et,null),e(Et,Mbr),e(Et,$1e),e($1e,Ebr),e(Et,ybr),e(Et,Qc),e(Qc,wbr),e(Qc,I1e),e(I1e,Abr),e(Qc,Lbr),e(Qc,j1e),e(j1e,Bbr),e(Qc,xbr),e(Et,kbr),e(Et,D1e),e(D1e,Rbr),e(Et,Sbr),g(aA,Et,null),e(xr,Pbr),e(xr,yo),g(nA,yo,null),e(yo,$br),e(yo,N1e),e(N1e,Ibr),e(yo,jbr),e(yo,wn),e(wn,Dbr),e(wn,q1e),e(q1e,Nbr),e(wn,qbr),e(wn,O1e),e(O1e,Obr),e(wn,Gbr),e(wn,G1e),e(G1e,Xbr),e(wn,Vbr),e(yo,zbr),e(yo,X1e),e(X1e,GF),e(GF,V1e),e(V1e,Wbr),e(GF,Qbr),e(GF,RX),e(RX,Hbr),e(GF,Ubr),e(yo,Jbr),e(yo,z1e),e(z1e,Ybr),e(yo,Kbr),g(sA,yo,null),b(c,Xke,u),b(c,Hc,u),e(Hc,XF),e(XF,W1e),g(lA,W1e,null),e(Hc,Zbr),e(Hc,Q1e),e(Q1e,e5r),b(c,Vke,u),b(c,kr,u),g(iA,kr,null),e(kr,o5r),e(kr,Uc),e(Uc,r5r),e(Uc,H1e),e(H1e,t5r),e(Uc,a5r),e(Uc,U1e),e(U1e,n5r),e(Uc,s5r),e(kr,l5r),e(kr,dA),e(dA,i5r),e(dA,J1e),e(J1e,d5r),e(dA,c5r),e(kr,f5r),e(kr,yt),g(cA,yt,null),e(yt,m5r),e(yt,Y1e),e(Y1e,g5r),e(yt,h5r),e(yt,Jc),e(Jc,p5r),e(Jc,K1e),e(K1e,_5r),e(Jc,u5r),e(Jc,Z1e),e(Z1e,b5r),e(Jc,v5r),e(yt,T5r),e(yt,e7e),e(e7e,F5r),e(yt,C5r),g(fA,yt,null),e(kr,M5r),e(kr,wo),g(mA,wo,null),e(wo,E5r),e(wo,o7e),e(o7e,y5r),e(wo,w5r),e(wo,An),e(An,A5r),e(An,r7e),e(r7e,L5r),e(An,B5r),e(An,t7e),e(t7e,x5r),e(An,k5r),e(An,a7e),e(a7e,R5r),e(An,S5r),e(wo,P5r),e(wo,n7e),e(n7e,VF),e(VF,s7e),e(s7e,$5r),e(VF,I5r),e(VF,SX),e(SX,j5r),e(VF,D5r),e(wo,N5r),e(wo,l7e),e(l7e,q5r),e(wo,O5r),g(gA,wo,null),b(c,zke,u),b(c,Yc,u),e(Yc,zF),e(zF,i7e),g(hA,i7e,null),e(Yc,G5r),e(Yc,d7e),e(d7e,X5r),b(c,Wke,u),b(c,Rr,u),g(pA,Rr,null),e(Rr,V5r),e(Rr,Kc),e(Kc,z5r),e(Kc,c7e),e(c7e,W5r),e(Kc,Q5r),e(Kc,f7e),e(f7e,H5r),e(Kc,U5r),e(Rr,J5r),e(Rr,_A),e(_A,Y5r),e(_A,m7e),e(m7e,K5r),e(_A,Z5r),e(Rr,e2r),e(Rr,wt),g(uA,wt,null),e(wt,o2r),e(wt,g7e),e(g7e,r2r),e(wt,t2r),e(wt,Zc),e(Zc,a2r),e(Zc,h7e),e(h7e,n2r),e(Zc,s2r),e(Zc,p7e),e(p7e,l2r),e(Zc,i2r),e(wt,d2r),e(wt,_7e),e(_7e,c2r),e(wt,f2r),g(bA,wt,null),e(Rr,m2r),e(Rr,Ao),g(vA,Ao,null),e(Ao,g2r),e(Ao,u7e),e(u7e,h2r),e(Ao,p2r),e(Ao,Ln),e(Ln,_2r),e(Ln,b7e),e(b7e,u2r),e(Ln,b2r),e(Ln,v7e),e(v7e,v2r),e(Ln,T2r),e(Ln,T7e),e(T7e,F2r),e(Ln,C2r),e(Ao,M2r),e(Ao,z),e(z,WF),e(WF,F7e),e(F7e,E2r),e(WF,y2r),e(WF,PX),e(PX,w2r),e(WF,A2r),e(z,L2r),e(z,QF),e(QF,C7e),e(C7e,B2r),e(QF,x2r),e(QF,$X),e($X,k2r),e(QF,R2r),e(z,S2r),e(z,HF),e(HF,M7e),e(M7e,P2r),e(HF,$2r),e(HF,IX),e(IX,I2r),e(HF,j2r),e(z,D2r),e(z,UF),e(UF,E7e),e(E7e,N2r),e(UF,q2r),e(UF,jX),e(jX,O2r),e(UF,G2r),e(z,X2r),e(z,JF),e(JF,y7e),e(y7e,V2r),e(JF,z2r),e(JF,DX),e(DX,W2r),e(JF,Q2r),e(z,H2r),e(z,YF),e(YF,w7e),e(w7e,U2r),e(YF,J2r),e(YF,NX),e(NX,Y2r),e(YF,K2r),e(z,Z2r),e(z,KF),e(KF,A7e),e(A7e,evr),e(KF,ovr),e(KF,qX),e(qX,rvr),e(KF,tvr),e(z,avr),e(z,ZF),e(ZF,L7e),e(L7e,nvr),e(ZF,svr),e(ZF,OX),e(OX,lvr),e(ZF,ivr),e(z,dvr),e(z,eC),e(eC,B7e),e(B7e,cvr),e(eC,fvr),e(eC,GX),e(GX,mvr),e(eC,gvr),e(z,hvr),e(z,oC),e(oC,x7e),e(x7e,pvr),e(oC,_vr),e(oC,XX),e(XX,uvr),e(oC,bvr),e(z,vvr),e(z,rC),e(rC,k7e),e(k7e,Tvr),e(rC,Fvr),e(rC,VX),e(VX,Cvr),e(rC,Mvr),e(z,Evr),e(z,tC),e(tC,R7e),e(R7e,yvr),e(tC,wvr),e(tC,zX),e(zX,Avr),e(tC,Lvr),e(z,Bvr),e(z,aC),e(aC,S7e),e(S7e,xvr),e(aC,kvr),e(aC,WX),e(WX,Rvr),e(aC,Svr),e(z,Pvr),e(z,nC),e(nC,P7e),e(P7e,$vr),e(nC,Ivr),e(nC,QX),e(QX,jvr),e(nC,Dvr),e(z,Nvr),e(z,sC),e(sC,$7e),e($7e,qvr),e(sC,Ovr),e(sC,HX),e(HX,Gvr),e(sC,Xvr),e(z,Vvr),e(z,lC),e(lC,I7e),e(I7e,zvr),e(lC,Wvr),e(lC,UX),e(UX,Qvr),e(lC,Hvr),e(z,Uvr),e(z,iC),e(iC,j7e),e(j7e,Jvr),e(iC,Yvr),e(iC,JX),e(JX,Kvr),e(iC,Zvr),e(z,e0r),e(z,dC),e(dC,D7e),e(D7e,o0r),e(dC,r0r),e(dC,YX),e(YX,t0r),e(dC,a0r),e(z,n0r),e(z,cC),e(cC,N7e),e(N7e,s0r),e(cC,l0r),e(cC,KX),e(KX,i0r),e(cC,d0r),e(z,c0r),e(z,fC),e(fC,q7e),e(q7e,f0r),e(fC,m0r),e(fC,ZX),e(ZX,g0r),e(fC,h0r),e(z,p0r),e(z,mC),e(mC,O7e),e(O7e,_0r),e(mC,u0r),e(mC,eV),e(eV,b0r),e(mC,v0r),e(z,T0r),e(z,gC),e(gC,G7e),e(G7e,F0r),e(gC,C0r),e(gC,oV),e(oV,M0r),e(gC,E0r),e(z,y0r),e(z,hC),e(hC,X7e),e(X7e,w0r),e(hC,A0r),e(hC,rV),e(rV,L0r),e(hC,B0r),e(z,x0r),e(z,pC),e(pC,V7e),e(V7e,k0r),e(pC,R0r),e(pC,tV),e(tV,S0r),e(pC,P0r),e(z,$0r),e(z,_C),e(_C,z7e),e(z7e,I0r),e(_C,j0r),e(_C,aV),e(aV,D0r),e(_C,N0r),e(Ao,q0r),e(Ao,W7e),e(W7e,O0r),e(Ao,G0r),g(TA,Ao,null),b(c,Qke,u),b(c,ef,u),e(ef,uC),e(uC,Q7e),g(FA,Q7e,null),e(ef,X0r),e(ef,H7e),e(H7e,V0r),b(c,Hke,u),b(c,Sr,u),g(CA,Sr,null),e(Sr,z0r),e(Sr,of),e(of,W0r),e(of,U7e),e(U7e,Q0r),e(of,H0r),e(of,J7e),e(J7e,U0r),e(of,J0r),e(Sr,Y0r),e(Sr,MA),e(MA,K0r),e(MA,Y7e),e(Y7e,Z0r),e(MA,eTr),e(Sr,oTr),e(Sr,At),g(EA,At,null),e(At,rTr),e(At,K7e),e(K7e,tTr),e(At,aTr),e(At,rf),e(rf,nTr),e(rf,Z7e),e(Z7e,sTr),e(rf,lTr),e(rf,ebe),e(ebe,iTr),e(rf,dTr),e(At,cTr),e(At,obe),e(obe,fTr),e(At,mTr),g(yA,At,null),e(Sr,gTr),e(Sr,Lo),g(wA,Lo,null),e(Lo,hTr),e(Lo,rbe),e(rbe,pTr),e(Lo,_Tr),e(Lo,Bn),e(Bn,uTr),e(Bn,tbe),e(tbe,bTr),e(Bn,vTr),e(Bn,abe),e(abe,TTr),e(Bn,FTr),e(Bn,nbe),e(nbe,CTr),e(Bn,MTr),e(Lo,ETr),e(Lo,xn),e(xn,bC),e(bC,sbe),e(sbe,yTr),e(bC,wTr),e(bC,nV),e(nV,ATr),e(bC,LTr),e(xn,BTr),e(xn,vC),e(vC,lbe),e(lbe,xTr),e(vC,kTr),e(vC,sV),e(sV,RTr),e(vC,STr),e(xn,PTr),e(xn,TC),e(TC,ibe),e(ibe,$Tr),e(TC,ITr),e(TC,lV),e(lV,jTr),e(TC,DTr),e(xn,NTr),e(xn,FC),e(FC,dbe),e(dbe,qTr),e(FC,OTr),e(FC,iV),e(iV,GTr),e(FC,XTr),e(Lo,VTr),e(Lo,cbe),e(cbe,zTr),e(Lo,WTr),g(AA,Lo,null),b(c,Uke,u),b(c,tf,u),e(tf,CC),e(CC,fbe),g(LA,fbe,null),e(tf,QTr),e(tf,mbe),e(mbe,HTr),b(c,Jke,u),b(c,Pr,u),g(BA,Pr,null),e(Pr,UTr),e(Pr,af),e(af,JTr),e(af,gbe),e(gbe,YTr),e(af,KTr),e(af,hbe),e(hbe,ZTr),e(af,eFr),e(Pr,oFr),e(Pr,xA),e(xA,rFr),e(xA,pbe),e(pbe,tFr),e(xA,aFr),e(Pr,nFr),e(Pr,Lt),g(kA,Lt,null),e(Lt,sFr),e(Lt,_be),e(_be,lFr),e(Lt,iFr),e(Lt,nf),e(nf,dFr),e(nf,ube),e(ube,cFr),e(nf,fFr),e(nf,bbe),e(bbe,mFr),e(nf,gFr),e(Lt,hFr),e(Lt,vbe),e(vbe,pFr),e(Lt,_Fr),g(RA,Lt,null),e(Pr,uFr),e(Pr,Bo),g(SA,Bo,null),e(Bo,bFr),e(Bo,Tbe),e(Tbe,vFr),e(Bo,TFr),e(Bo,kn),e(kn,FFr),e(kn,Fbe),e(Fbe,CFr),e(kn,MFr),e(kn,Cbe),e(Cbe,EFr),e(kn,yFr),e(kn,Mbe),e(Mbe,wFr),e(kn,AFr),e(Bo,LFr),e(Bo,ce),e(ce,MC),e(MC,Ebe),e(Ebe,BFr),e(MC,xFr),e(MC,dV),e(dV,kFr),e(MC,RFr),e(ce,SFr),e(ce,EC),e(EC,ybe),e(ybe,PFr),e(EC,$Fr),e(EC,cV),e(cV,IFr),e(EC,jFr),e(ce,DFr),e(ce,yC),e(yC,wbe),e(wbe,NFr),e(yC,qFr),e(yC,fV),e(fV,OFr),e(yC,GFr),e(ce,XFr),e(ce,wC),e(wC,Abe),e(Abe,VFr),e(wC,zFr),e(wC,mV),e(mV,WFr),e(wC,QFr),e(ce,HFr),e(ce,AC),e(AC,Lbe),e(Lbe,UFr),e(AC,JFr),e(AC,gV),e(gV,YFr),e(AC,KFr),e(ce,ZFr),e(ce,LC),e(LC,Bbe),e(Bbe,eCr),e(LC,oCr),e(LC,hV),e(hV,rCr),e(LC,tCr),e(ce,aCr),e(ce,BC),e(BC,xbe),e(xbe,nCr),e(BC,sCr),e(BC,pV),e(pV,lCr),e(BC,iCr),e(ce,dCr),e(ce,xC),e(xC,kbe),e(kbe,cCr),e(xC,fCr),e(xC,_V),e(_V,mCr),e(xC,gCr),e(ce,hCr),e(ce,kC),e(kC,Rbe),e(Rbe,pCr),e(kC,_Cr),e(kC,uV),e(uV,uCr),e(kC,bCr),e(ce,vCr),e(ce,RC),e(RC,Sbe),e(Sbe,TCr),e(RC,FCr),e(RC,bV),e(bV,CCr),e(RC,MCr),e(ce,ECr),e(ce,SC),e(SC,Pbe),e(Pbe,yCr),e(SC,wCr),e(SC,vV),e(vV,ACr),e(SC,LCr),e(ce,BCr),e(ce,PC),e(PC,$be),e($be,xCr),e(PC,kCr),e(PC,TV),e(TV,RCr),e(PC,SCr),e(Bo,PCr),e(Bo,Ibe),e(Ibe,$Cr),e(Bo,ICr),g(PA,Bo,null),b(c,Yke,u),b(c,sf,u),e(sf,$C),e($C,jbe),g($A,jbe,null),e(sf,jCr),e(sf,Dbe),e(Dbe,DCr),b(c,Kke,u),b(c,$r,u),g(IA,$r,null),e($r,NCr),e($r,lf),e(lf,qCr),e(lf,Nbe),e(Nbe,OCr),e(lf,GCr),e(lf,qbe),e(qbe,XCr),e(lf,VCr),e($r,zCr),e($r,jA),e(jA,WCr),e(jA,Obe),e(Obe,QCr),e(jA,HCr),e($r,UCr),e($r,Bt),g(DA,Bt,null),e(Bt,JCr),e(Bt,Gbe),e(Gbe,YCr),e(Bt,KCr),e(Bt,df),e(df,ZCr),e(df,Xbe),e(Xbe,eMr),e(df,oMr),e(df,Vbe),e(Vbe,rMr),e(df,tMr),e(Bt,aMr),e(Bt,zbe),e(zbe,nMr),e(Bt,sMr),g(NA,Bt,null),e($r,lMr),e($r,xo),g(qA,xo,null),e(xo,iMr),e(xo,Wbe),e(Wbe,dMr),e(xo,cMr),e(xo,Rn),e(Rn,fMr),e(Rn,Qbe),e(Qbe,mMr),e(Rn,gMr),e(Rn,Hbe),e(Hbe,hMr),e(Rn,pMr),e(Rn,Ube),e(Ube,_Mr),e(Rn,uMr),e(xo,bMr),e(xo,be),e(be,IC),e(IC,Jbe),e(Jbe,vMr),e(IC,TMr),e(IC,FV),e(FV,FMr),e(IC,CMr),e(be,MMr),e(be,jC),e(jC,Ybe),e(Ybe,EMr),e(jC,yMr),e(jC,CV),e(CV,wMr),e(jC,AMr),e(be,LMr),e(be,DC),e(DC,Kbe),e(Kbe,BMr),e(DC,xMr),e(DC,MV),e(MV,kMr),e(DC,RMr),e(be,SMr),e(be,NC),e(NC,Zbe),e(Zbe,PMr),e(NC,$Mr),e(NC,EV),e(EV,IMr),e(NC,jMr),e(be,DMr),e(be,qC),e(qC,e5e),e(e5e,NMr),e(qC,qMr),e(qC,yV),e(yV,OMr),e(qC,GMr),e(be,XMr),e(be,OC),e(OC,o5e),e(o5e,VMr),e(OC,zMr),e(OC,wV),e(wV,WMr),e(OC,QMr),e(be,HMr),e(be,GC),e(GC,r5e),e(r5e,UMr),e(GC,JMr),e(GC,AV),e(AV,YMr),e(GC,KMr),e(be,ZMr),e(be,XC),e(XC,t5e),e(t5e,e4r),e(XC,o4r),e(XC,LV),e(LV,r4r),e(XC,t4r),e(be,a4r),e(be,VC),e(VC,a5e),e(a5e,n4r),e(VC,s4r),e(VC,BV),e(BV,l4r),e(VC,i4r),e(be,d4r),e(be,zC),e(zC,n5e),e(n5e,c4r),e(zC,f4r),e(zC,xV),e(xV,m4r),e(zC,g4r),e(xo,h4r),e(xo,s5e),e(s5e,p4r),e(xo,_4r),g(OA,xo,null),b(c,Zke,u),b(c,cf,u),e(cf,WC),e(WC,l5e),g(GA,l5e,null),e(cf,u4r),e(cf,i5e),e(i5e,b4r),b(c,eRe,u),b(c,Ir,u),g(XA,Ir,null),e(Ir,v4r),e(Ir,ff),e(ff,T4r),e(ff,d5e),e(d5e,F4r),e(ff,C4r),e(ff,c5e),e(c5e,M4r),e(ff,E4r),e(Ir,y4r),e(Ir,VA),e(VA,w4r),e(VA,f5e),e(f5e,A4r),e(VA,L4r),e(Ir,B4r),e(Ir,xt),g(zA,xt,null),e(xt,x4r),e(xt,m5e),e(m5e,k4r),e(xt,R4r),e(xt,mf),e(mf,S4r),e(mf,g5e),e(g5e,P4r),e(mf,$4r),e(mf,h5e),e(h5e,I4r),e(mf,j4r),e(xt,D4r),e(xt,p5e),e(p5e,N4r),e(xt,q4r),g(WA,xt,null),e(Ir,O4r),e(Ir,ko),g(QA,ko,null),e(ko,G4r),e(ko,_5e),e(_5e,X4r),e(ko,V4r),e(ko,Sn),e(Sn,z4r),e(Sn,u5e),e(u5e,W4r),e(Sn,Q4r),e(Sn,b5e),e(b5e,H4r),e(Sn,U4r),e(Sn,v5e),e(v5e,J4r),e(Sn,Y4r),e(ko,K4r),e(ko,Ce),e(Ce,QC),e(QC,T5e),e(T5e,Z4r),e(QC,eEr),e(QC,kV),e(kV,oEr),e(QC,rEr),e(Ce,tEr),e(Ce,HC),e(HC,F5e),e(F5e,aEr),e(HC,nEr),e(HC,RV),e(RV,sEr),e(HC,lEr),e(Ce,iEr),e(Ce,UC),e(UC,C5e),e(C5e,dEr),e(UC,cEr),e(UC,SV),e(SV,fEr),e(UC,mEr),e(Ce,gEr),e(Ce,JC),e(JC,M5e),e(M5e,hEr),e(JC,pEr),e(JC,PV),e(PV,_Er),e(JC,uEr),e(Ce,bEr),e(Ce,YC),e(YC,E5e),e(E5e,vEr),e(YC,TEr),e(YC,$V),e($V,FEr),e(YC,CEr),e(Ce,MEr),e(Ce,KC),e(KC,y5e),e(y5e,EEr),e(KC,yEr),e(KC,IV),e(IV,wEr),e(KC,AEr),e(Ce,LEr),e(Ce,ZC),e(ZC,w5e),e(w5e,BEr),e(ZC,xEr),e(ZC,jV),e(jV,kEr),e(ZC,REr),e(Ce,SEr),e(Ce,eM),e(eM,A5e),e(A5e,PEr),e(eM,$Er),e(eM,DV),e(DV,IEr),e(eM,jEr),e(Ce,DEr),e(Ce,oM),e(oM,L5e),e(L5e,NEr),e(oM,qEr),e(oM,NV),e(NV,OEr),e(oM,GEr),e(ko,XEr),e(ko,B5e),e(B5e,VEr),e(ko,zEr),g(HA,ko,null),b(c,oRe,u),b(c,gf,u),e(gf,rM),e(rM,x5e),g(UA,x5e,null),e(gf,WEr),e(gf,k5e),e(k5e,QEr),b(c,rRe,u),b(c,jr,u),g(JA,jr,null),e(jr,HEr),e(jr,hf),e(hf,UEr),e(hf,R5e),e(R5e,JEr),e(hf,YEr),e(hf,S5e),e(S5e,KEr),e(hf,ZEr),e(jr,e3r),e(jr,YA),e(YA,o3r),e(YA,P5e),e(P5e,r3r),e(YA,t3r),e(jr,a3r),e(jr,kt),g(KA,kt,null),e(kt,n3r),e(kt,$5e),e($5e,s3r),e(kt,l3r),e(kt,pf),e(pf,i3r),e(pf,I5e),e(I5e,d3r),e(pf,c3r),e(pf,j5e),e(j5e,f3r),e(pf,m3r),e(kt,g3r),e(kt,D5e),e(D5e,h3r),e(kt,p3r),g(ZA,kt,null),e(jr,_3r),e(jr,Ro),g(eL,Ro,null),e(Ro,u3r),e(Ro,N5e),e(N5e,b3r),e(Ro,v3r),e(Ro,Pn),e(Pn,T3r),e(Pn,q5e),e(q5e,F3r),e(Pn,C3r),e(Pn,O5e),e(O5e,M3r),e(Pn,E3r),e(Pn,G5e),e(G5e,y3r),e(Pn,w3r),e(Ro,A3r),e(Ro,ve),e(ve,tM),e(tM,X5e),e(X5e,L3r),e(tM,B3r),e(tM,qV),e(qV,x3r),e(tM,k3r),e(ve,R3r),e(ve,aM),e(aM,V5e),e(V5e,S3r),e(aM,P3r),e(aM,OV),e(OV,$3r),e(aM,I3r),e(ve,j3r),e(ve,nM),e(nM,z5e),e(z5e,D3r),e(nM,N3r),e(nM,GV),e(GV,q3r),e(nM,O3r),e(ve,G3r),e(ve,sM),e(sM,W5e),e(W5e,X3r),e(sM,V3r),e(sM,XV),e(XV,z3r),e(sM,W3r),e(ve,Q3r),e(ve,lM),e(lM,Q5e),e(Q5e,H3r),e(lM,U3r),e(lM,VV),e(VV,J3r),e(lM,Y3r),e(ve,K3r),e(ve,iM),e(iM,H5e),e(H5e,Z3r),e(iM,eyr),e(iM,zV),e(zV,oyr),e(iM,ryr),e(ve,tyr),e(ve,dM),e(dM,U5e),e(U5e,ayr),e(dM,nyr),e(dM,WV),e(WV,syr),e(dM,lyr),e(ve,iyr),e(ve,cM),e(cM,J5e),e(J5e,dyr),e(cM,cyr),e(cM,QV),e(QV,fyr),e(cM,myr),e(ve,gyr),e(ve,fM),e(fM,Y5e),e(Y5e,hyr),e(fM,pyr),e(fM,HV),e(HV,_yr),e(fM,uyr),e(ve,byr),e(ve,mM),e(mM,K5e),e(K5e,vyr),e(mM,Tyr),e(mM,UV),e(UV,Fyr),e(mM,Cyr),e(Ro,Myr),e(Ro,Z5e),e(Z5e,Eyr),e(Ro,yyr),g(oL,Ro,null),b(c,tRe,u),b(c,_f,u),e(_f,gM),e(gM,e2e),g(rL,e2e,null),e(_f,wyr),e(_f,o2e),e(o2e,Ayr),b(c,aRe,u),b(c,Dr,u),g(tL,Dr,null),e(Dr,Lyr),e(Dr,uf),e(uf,Byr),e(uf,r2e),e(r2e,xyr),e(uf,kyr),e(uf,t2e),e(t2e,Ryr),e(uf,Syr),e(Dr,Pyr),e(Dr,aL),e(aL,$yr),e(aL,a2e),e(a2e,Iyr),e(aL,jyr),e(Dr,Dyr),e(Dr,Rt),g(nL,Rt,null),e(Rt,Nyr),e(Rt,n2e),e(n2e,qyr),e(Rt,Oyr),e(Rt,bf),e(bf,Gyr),e(bf,s2e),e(s2e,Xyr),e(bf,Vyr),e(bf,l2e),e(l2e,zyr),e(bf,Wyr),e(Rt,Qyr),e(Rt,i2e),e(i2e,Hyr),e(Rt,Uyr),g(sL,Rt,null),e(Dr,Jyr),e(Dr,So),g(lL,So,null),e(So,Yyr),e(So,d2e),e(d2e,Kyr),e(So,Zyr),e(So,$n),e($n,ewr),e($n,c2e),e(c2e,owr),e($n,rwr),e($n,f2e),e(f2e,twr),e($n,awr),e($n,m2e),e(m2e,nwr),e($n,swr),e(So,lwr),e(So,Te),e(Te,hM),e(hM,g2e),e(g2e,iwr),e(hM,dwr),e(hM,JV),e(JV,cwr),e(hM,fwr),e(Te,mwr),e(Te,pM),e(pM,h2e),e(h2e,gwr),e(pM,hwr),e(pM,YV),e(YV,pwr),e(pM,_wr),e(Te,uwr),e(Te,_M),e(_M,p2e),e(p2e,bwr),e(_M,vwr),e(_M,KV),e(KV,Twr),e(_M,Fwr),e(Te,Cwr),e(Te,uM),e(uM,_2e),e(_2e,Mwr),e(uM,Ewr),e(uM,ZV),e(ZV,ywr),e(uM,wwr),e(Te,Awr),e(Te,bM),e(bM,u2e),e(u2e,Lwr),e(bM,Bwr),e(bM,ez),e(ez,xwr),e(bM,kwr),e(Te,Rwr),e(Te,vM),e(vM,b2e),e(b2e,Swr),e(vM,Pwr),e(vM,oz),e(oz,$wr),e(vM,Iwr),e(Te,jwr),e(Te,TM),e(TM,v2e),e(v2e,Dwr),e(TM,Nwr),e(TM,rz),e(rz,qwr),e(TM,Owr),e(Te,Gwr),e(Te,FM),e(FM,T2e),e(T2e,Xwr),e(FM,Vwr),e(FM,tz),e(tz,zwr),e(FM,Wwr),e(Te,Qwr),e(Te,CM),e(CM,F2e),e(F2e,Hwr),e(CM,Uwr),e(CM,az),e(az,Jwr),e(CM,Ywr),e(Te,Kwr),e(Te,MM),e(MM,C2e),e(C2e,Zwr),e(MM,e6r),e(MM,nz),e(nz,o6r),e(MM,r6r),e(So,t6r),e(So,M2e),e(M2e,a6r),e(So,n6r),g(iL,So,null),b(c,nRe,u),b(c,vf,u),e(vf,EM),e(EM,E2e),g(dL,E2e,null),e(vf,s6r),e(vf,y2e),e(y2e,l6r),b(c,sRe,u),b(c,Nr,u),g(cL,Nr,null),e(Nr,i6r),e(Nr,Tf),e(Tf,d6r),e(Tf,w2e),e(w2e,c6r),e(Tf,f6r),e(Tf,A2e),e(A2e,m6r),e(Tf,g6r),e(Nr,h6r),e(Nr,fL),e(fL,p6r),e(fL,L2e),e(L2e,_6r),e(fL,u6r),e(Nr,b6r),e(Nr,St),g(mL,St,null),e(St,v6r),e(St,B2e),e(B2e,T6r),e(St,F6r),e(St,Ff),e(Ff,C6r),e(Ff,x2e),e(x2e,M6r),e(Ff,E6r),e(Ff,k2e),e(k2e,y6r),e(Ff,w6r),e(St,A6r),e(St,R2e),e(R2e,L6r),e(St,B6r),g(gL,St,null),e(Nr,x6r),e(Nr,Po),g(hL,Po,null),e(Po,k6r),e(Po,S2e),e(S2e,R6r),e(Po,S6r),e(Po,In),e(In,P6r),e(In,P2e),e(P2e,$6r),e(In,I6r),e(In,$2e),e($2e,j6r),e(In,D6r),e(In,I2e),e(I2e,N6r),e(In,q6r),e(Po,O6r),e(Po,Se),e(Se,yM),e(yM,j2e),e(j2e,G6r),e(yM,X6r),e(yM,sz),e(sz,V6r),e(yM,z6r),e(Se,W6r),e(Se,wM),e(wM,D2e),e(D2e,Q6r),e(wM,H6r),e(wM,lz),e(lz,U6r),e(wM,J6r),e(Se,Y6r),e(Se,AM),e(AM,N2e),e(N2e,K6r),e(AM,Z6r),e(AM,iz),e(iz,eAr),e(AM,oAr),e(Se,rAr),e(Se,LM),e(LM,q2e),e(q2e,tAr),e(LM,aAr),e(LM,dz),e(dz,nAr),e(LM,sAr),e(Se,lAr),e(Se,BM),e(BM,O2e),e(O2e,iAr),e(BM,dAr),e(BM,cz),e(cz,cAr),e(BM,fAr),e(Se,mAr),e(Se,xM),e(xM,G2e),e(G2e,gAr),e(xM,hAr),e(xM,fz),e(fz,pAr),e(xM,_Ar),e(Se,uAr),e(Se,kM),e(kM,X2e),e(X2e,bAr),e(kM,vAr),e(kM,mz),e(mz,TAr),e(kM,FAr),e(Se,CAr),e(Se,RM),e(RM,V2e),e(V2e,MAr),e(RM,EAr),e(RM,gz),e(gz,yAr),e(RM,wAr),e(Po,AAr),e(Po,z2e),e(z2e,LAr),e(Po,BAr),g(pL,Po,null),b(c,lRe,u),b(c,Cf,u),e(Cf,SM),e(SM,W2e),g(_L,W2e,null),e(Cf,xAr),e(Cf,Q2e),e(Q2e,kAr),b(c,iRe,u),b(c,qr,u),g(uL,qr,null),e(qr,RAr),e(qr,Mf),e(Mf,SAr),e(Mf,H2e),e(H2e,PAr),e(Mf,$Ar),e(Mf,U2e),e(U2e,IAr),e(Mf,jAr),e(qr,DAr),e(qr,bL),e(bL,NAr),e(bL,J2e),e(J2e,qAr),e(bL,OAr),e(qr,GAr),e(qr,Pt),g(vL,Pt,null),e(Pt,XAr),e(Pt,Y2e),e(Y2e,VAr),e(Pt,zAr),e(Pt,Ef),e(Ef,WAr),e(Ef,K2e),e(K2e,QAr),e(Ef,HAr),e(Ef,Z2e),e(Z2e,UAr),e(Ef,JAr),e(Pt,YAr),e(Pt,eve),e(eve,KAr),e(Pt,ZAr),g(TL,Pt,null),e(qr,eLr),e(qr,$o),g(FL,$o,null),e($o,oLr),e($o,ove),e(ove,rLr),e($o,tLr),e($o,jn),e(jn,aLr),e(jn,rve),e(rve,nLr),e(jn,sLr),e(jn,tve),e(tve,lLr),e(jn,iLr),e(jn,ave),e(ave,dLr),e(jn,cLr),e($o,fLr),e($o,Pe),e(Pe,PM),e(PM,nve),e(nve,mLr),e(PM,gLr),e(PM,hz),e(hz,hLr),e(PM,pLr),e(Pe,_Lr),e(Pe,$M),e($M,sve),e(sve,uLr),e($M,bLr),e($M,pz),e(pz,vLr),e($M,TLr),e(Pe,FLr),e(Pe,IM),e(IM,lve),e(lve,CLr),e(IM,MLr),e(IM,_z),e(_z,ELr),e(IM,yLr),e(Pe,wLr),e(Pe,jM),e(jM,ive),e(ive,ALr),e(jM,LLr),e(jM,uz),e(uz,BLr),e(jM,xLr),e(Pe,kLr),e(Pe,DM),e(DM,dve),e(dve,RLr),e(DM,SLr),e(DM,bz),e(bz,PLr),e(DM,$Lr),e(Pe,ILr),e(Pe,NM),e(NM,cve),e(cve,jLr),e(NM,DLr),e(NM,vz),e(vz,NLr),e(NM,qLr),e(Pe,OLr),e(Pe,qM),e(qM,fve),e(fve,GLr),e(qM,XLr),e(qM,Tz),e(Tz,VLr),e(qM,zLr),e(Pe,WLr),e(Pe,OM),e(OM,mve),e(mve,QLr),e(OM,HLr),e(OM,Fz),e(Fz,ULr),e(OM,JLr),e($o,YLr),e($o,gve),e(gve,KLr),e($o,ZLr),g(CL,$o,null),b(c,dRe,u),b(c,yf,u),e(yf,GM),e(GM,hve),g(ML,hve,null),e(yf,e8r),e(yf,pve),e(pve,o8r),b(c,cRe,u),b(c,Or,u),g(EL,Or,null),e(Or,r8r),e(Or,wf),e(wf,t8r),e(wf,_ve),e(_ve,a8r),e(wf,n8r),e(wf,uve),e(uve,s8r),e(wf,l8r),e(Or,i8r),e(Or,yL),e(yL,d8r),e(yL,bve),e(bve,c8r),e(yL,f8r),e(Or,m8r),e(Or,$t),g(wL,$t,null),e($t,g8r),e($t,vve),e(vve,h8r),e($t,p8r),e($t,Af),e(Af,_8r),e(Af,Tve),e(Tve,u8r),e(Af,b8r),e(Af,Fve),e(Fve,v8r),e(Af,T8r),e($t,F8r),e($t,Cve),e(Cve,C8r),e($t,M8r),g(AL,$t,null),e(Or,E8r),e(Or,Io),g(LL,Io,null),e(Io,y8r),e(Io,Mve),e(Mve,w8r),e(Io,A8r),e(Io,Dn),e(Dn,L8r),e(Dn,Eve),e(Eve,B8r),e(Dn,x8r),e(Dn,yve),e(yve,k8r),e(Dn,R8r),e(Dn,wve),e(wve,S8r),e(Dn,P8r),e(Io,$8r),e(Io,Ave),e(Ave,XM),e(XM,Lve),e(Lve,I8r),e(XM,j8r),e(XM,Cz),e(Cz,D8r),e(XM,N8r),e(Io,q8r),e(Io,Bve),e(Bve,O8r),e(Io,G8r),g(BL,Io,null),b(c,fRe,u),b(c,Lf,u),e(Lf,VM),e(VM,xve),g(xL,xve,null),e(Lf,X8r),e(Lf,kve),e(kve,V8r),b(c,mRe,u),b(c,Gr,u),g(kL,Gr,null),e(Gr,z8r),e(Gr,Bf),e(Bf,W8r),e(Bf,Rve),e(Rve,Q8r),e(Bf,H8r),e(Bf,Sve),e(Sve,U8r),e(Bf,J8r),e(Gr,Y8r),e(Gr,RL),e(RL,K8r),e(RL,Pve),e(Pve,Z8r),e(RL,e9r),e(Gr,o9r),e(Gr,It),g(SL,It,null),e(It,r9r),e(It,$ve),e($ve,t9r),e(It,a9r),e(It,xf),e(xf,n9r),e(xf,Ive),e(Ive,s9r),e(xf,l9r),e(xf,jve),e(jve,i9r),e(xf,d9r),e(It,c9r),e(It,Dve),e(Dve,f9r),e(It,m9r),g(PL,It,null),e(Gr,g9r),e(Gr,jo),g($L,jo,null),e(jo,h9r),e(jo,Nve),e(Nve,p9r),e(jo,_9r),e(jo,Nn),e(Nn,u9r),e(Nn,qve),e(qve,b9r),e(Nn,v9r),e(Nn,Ove),e(Ove,T9r),e(Nn,F9r),e(Nn,Gve),e(Gve,C9r),e(Nn,M9r),e(jo,E9r),e(jo,IL),e(IL,zM),e(zM,Xve),e(Xve,y9r),e(zM,w9r),e(zM,Mz),e(Mz,A9r),e(zM,L9r),e(IL,B9r),e(IL,WM),e(WM,Vve),e(Vve,x9r),e(WM,k9r),e(WM,Ez),e(Ez,R9r),e(WM,S9r),e(jo,P9r),e(jo,zve),e(zve,$9r),e(jo,I9r),g(jL,jo,null),b(c,gRe,u),b(c,kf,u),e(kf,QM),e(QM,Wve),g(DL,Wve,null),e(kf,j9r),e(kf,Qve),e(Qve,D9r),b(c,hRe,u),b(c,Xr,u),g(NL,Xr,null),e(Xr,N9r),e(Xr,Rf),e(Rf,q9r),e(Rf,Hve),e(Hve,O9r),e(Rf,G9r),e(Rf,Uve),e(Uve,X9r),e(Rf,V9r),e(Xr,z9r),e(Xr,qL),e(qL,W9r),e(qL,Jve),e(Jve,Q9r),e(qL,H9r),e(Xr,U9r),e(Xr,jt),g(OL,jt,null),e(jt,J9r),e(jt,Yve),e(Yve,Y9r),e(jt,K9r),e(jt,Sf),e(Sf,Z9r),e(Sf,Kve),e(Kve,eBr),e(Sf,oBr),e(Sf,Zve),e(Zve,rBr),e(Sf,tBr),e(jt,aBr),e(jt,e0e),e(e0e,nBr),e(jt,sBr),g(GL,jt,null),e(Xr,lBr),e(Xr,Do),g(XL,Do,null),e(Do,iBr),e(Do,o0e),e(o0e,dBr),e(Do,cBr),e(Do,qn),e(qn,fBr),e(qn,r0e),e(r0e,mBr),e(qn,gBr),e(qn,t0e),e(t0e,hBr),e(qn,pBr),e(qn,a0e),e(a0e,_Br),e(qn,uBr),e(Do,bBr),e(Do,n0e),e(n0e,HM),e(HM,s0e),e(s0e,vBr),e(HM,TBr),e(HM,yz),e(yz,FBr),e(HM,CBr),e(Do,MBr),e(Do,l0e),e(l0e,EBr),e(Do,yBr),g(VL,Do,null),pRe=!0},p(c,[u]){const zL={};u&2&&(zL.$$scope={dirty:u,ctx:c}),qf.$set(zL);const i0e={};u&2&&(i0e.$$scope={dirty:u,ctx:c}),yh.$set(i0e);const d0e={};u&2&&(d0e.$$scope={dirty:u,ctx:c}),Ih.$set(d0e)},i(c){pRe||(h(fe.$$.fragment,c),h(Na.$$.fragment,c),h(Z4.$$.fragment,c),h(eE.$$.fragment,c),h(qf.$$.fragment,c),h(oE.$$.fragment,c),h(rE.$$.fragment,c),h(nE.$$.fragment,c),h(sE.$$.fragment,c),h(lE.$$.fragment,c),h(iE.$$.fragment,c),h(dE.$$.fragment,c),h(mE.$$.fragment,c),h(gE.$$.fragment,c),h(hE.$$.fragment,c),h(pE.$$.fragment,c),h(_E.$$.fragment,c),h(vE.$$.fragment,c),h(yh.$$.fragment,c),h(TE.$$.fragment,c),h(FE.$$.fragment,c),h(CE.$$.fragment,c),h(ME.$$.fragment,c),h(wE.$$.fragment,c),h(Ih.$$.fragment,c),h(AE.$$.fragment,c),h(LE.$$.fragment,c),h(BE.$$.fragment,c),h(xE.$$.fragment,c),h(RE.$$.fragment,c),h(SE.$$.fragment,c),h(PE.$$.fragment,c),h($E.$$.fragment,c),h(IE.$$.fragment,c),h(jE.$$.fragment,c),h(NE.$$.fragment,c),h(qE.$$.fragment,c),h(OE.$$.fragment,c),h(GE.$$.fragment,c),h(XE.$$.fragment,c),h(VE.$$.fragment,c),h(WE.$$.fragment,c),h(QE.$$.fragment,c),h(HE.$$.fragment,c),h(UE.$$.fragment,c),h(JE.$$.fragment,c),h(YE.$$.fragment,c),h(ZE.$$.fragment,c),h(e3.$$.fragment,c),h(o3.$$.fragment,c),h(r3.$$.fragment,c),h(t3.$$.fragment,c),h(a3.$$.fragment,c),h(s3.$$.fragment,c),h(l3.$$.fragment,c),h(i3.$$.fragment,c),h(d3.$$.fragment,c),h(c3.$$.fragment,c),h(f3.$$.fragment,c),h(g3.$$.fragment,c),h(h3.$$.fragment,c),h(p3.$$.fragment,c),h(_3.$$.fragment,c),h(u3.$$.fragment,c),h(b3.$$.fragment,c),h(T3.$$.fragment,c),h(F3.$$.fragment,c),h(C3.$$.fragment,c),h(M3.$$.fragment,c),h(E3.$$.fragment,c),h(y3.$$.fragment,c),h(A3.$$.fragment,c),h(L3.$$.fragment,c),h(B3.$$.fragment,c),h(x3.$$.fragment,c),h(k3.$$.fragment,c),h(R3.$$.fragment,c),h(P3.$$.fragment,c),h($3.$$.fragment,c),h(I3.$$.fragment,c),h(j3.$$.fragment,c),h(D3.$$.fragment,c),h(N3.$$.fragment,c),h(O3.$$.fragment,c),h(G3.$$.fragment,c),h(X3.$$.fragment,c),h(V3.$$.fragment,c),h(z3.$$.fragment,c),h(W3.$$.fragment,c),h(H3.$$.fragment,c),h(U3.$$.fragment,c),h(J3.$$.fragment,c),h(Y3.$$.fragment,c),h(K3.$$.fragment,c),h(Z3.$$.fragment,c),h(oy.$$.fragment,c),h(ry.$$.fragment,c),h(ty.$$.fragment,c),h(ay.$$.fragment,c),h(ny.$$.fragment,c),h(sy.$$.fragment,c),h(iy.$$.fragment,c),h(dy.$$.fragment,c),h(cy.$$.fragment,c),h(fy.$$.fragment,c),h(my.$$.fragment,c),h(gy.$$.fragment,c),h(py.$$.fragment,c),h(_y.$$.fragment,c),h(uy.$$.fragment,c),h(by.$$.fragment,c),h(vy.$$.fragment,c),h(Ty.$$.fragment,c),h(Cy.$$.fragment,c),h(My.$$.fragment,c),h(Ey.$$.fragment,c),h(yy.$$.fragment,c),h(wy.$$.fragment,c),h(Ay.$$.fragment,c),h(By.$$.fragment,c),h(xy.$$.fragment,c),h(ky.$$.fragment,c),h(Ry.$$.fragment,c),h(Sy.$$.fragment,c),h(Py.$$.fragment,c),h(Iy.$$.fragment,c),h(jy.$$.fragment,c),h(Dy.$$.fragment,c),h(qy.$$.fragment,c),h(Oy.$$.fragment,c),h(Gy.$$.fragment,c),h(Vy.$$.fragment,c),h(zy.$$.fragment,c),h(Wy.$$.fragment,c),h(Qy.$$.fragment,c),h(Hy.$$.fragment,c),h(Uy.$$.fragment,c),h(Yy.$$.fragment,c),h(Ky.$$.fragment,c),h(Zy.$$.fragment,c),h(ew.$$.fragment,c),h(ow.$$.fragment,c),h(rw.$$.fragment,c),h(aw.$$.fragment,c),h(nw.$$.fragment,c),h(sw.$$.fragment,c),h(lw.$$.fragment,c),h(iw.$$.fragment,c),h(dw.$$.fragment,c),h(fw.$$.fragment,c),h(mw.$$.fragment,c),h(gw.$$.fragment,c),h(hw.$$.fragment,c),h(pw.$$.fragment,c),h(_w.$$.fragment,c),h(bw.$$.fragment,c),h(vw.$$.fragment,c),h(Tw.$$.fragment,c),h(Cw.$$.fragment,c),h(Mw.$$.fragment,c),h(Ew.$$.fragment,c),h(ww.$$.fragment,c),h(Aw.$$.fragment,c),h(Lw.$$.fragment,c),h(Bw.$$.fragment,c),h(xw.$$.fragment,c),h(kw.$$.fragment,c),h(Sw.$$.fragment,c),h(Pw.$$.fragment,c),h($w.$$.fragment,c),h(Iw.$$.fragment,c),h(jw.$$.fragment,c),h(Dw.$$.fragment,c),h(qw.$$.fragment,c),h(Ow.$$.fragment,c),h(Gw.$$.fragment,c),h(Xw.$$.fragment,c),h(Vw.$$.fragment,c),h(zw.$$.fragment,c),h(Qw.$$.fragment,c),h(Hw.$$.fragment,c),h(Uw.$$.fragment,c),h(Jw.$$.fragment,c),h(Yw.$$.fragment,c),h(Kw.$$.fragment,c),h(e6.$$.fragment,c),h(o6.$$.fragment,c),h(r6.$$.fragment,c),h(a6.$$.fragment,c),h(n6.$$.fragment,c),h(s6.$$.fragment,c),h(i6.$$.fragment,c),h(d6.$$.fragment,c),h(c6.$$.fragment,c),h(f6.$$.fragment,c),h(m6.$$.fragment,c),h(g6.$$.fragment,c),h(p6.$$.fragment,c),h(_6.$$.fragment,c),h(u6.$$.fragment,c),h(b6.$$.fragment,c),h(v6.$$.fragment,c),h(T6.$$.fragment,c),h(C6.$$.fragment,c),h(M6.$$.fragment,c),h(E6.$$.fragment,c),h(y6.$$.fragment,c),h(w6.$$.fragment,c),h(A6.$$.fragment,c),h(B6.$$.fragment,c),h(x6.$$.fragment,c),h(k6.$$.fragment,c),h(R6.$$.fragment,c),h(S6.$$.fragment,c),h(P6.$$.fragment,c),h(I6.$$.fragment,c),h(j6.$$.fragment,c),h(D6.$$.fragment,c),h(N6.$$.fragment,c),h(q6.$$.fragment,c),h(O6.$$.fragment,c),h(X6.$$.fragment,c),h(V6.$$.fragment,c),h(z6.$$.fragment,c),h(W6.$$.fragment,c),h(Q6.$$.fragment,c),h(H6.$$.fragment,c),h(J6.$$.fragment,c),h(Y6.$$.fragment,c),h(K6.$$.fragment,c),h(Z6.$$.fragment,c),h(eA.$$.fragment,c),h(oA.$$.fragment,c),h(tA.$$.fragment,c),h(aA.$$.fragment,c),h(nA.$$.fragment,c),h(sA.$$.fragment,c),h(lA.$$.fragment,c),h(iA.$$.fragment,c),h(cA.$$.fragment,c),h(fA.$$.fragment,c),h(mA.$$.fragment,c),h(gA.$$.fragment,c),h(hA.$$.fragment,c),h(pA.$$.fragment,c),h(uA.$$.fragment,c),h(bA.$$.fragment,c),h(vA.$$.fragment,c),h(TA.$$.fragment,c),h(FA.$$.fragment,c),h(CA.$$.fragment,c),h(EA.$$.fragment,c),h(yA.$$.fragment,c),h(wA.$$.fragment,c),h(AA.$$.fragment,c),h(LA.$$.fragment,c),h(BA.$$.fragment,c),h(kA.$$.fragment,c),h(RA.$$.fragment,c),h(SA.$$.fragment,c),h(PA.$$.fragment,c),h($A.$$.fragment,c),h(IA.$$.fragment,c),h(DA.$$.fragment,c),h(NA.$$.fragment,c),h(qA.$$.fragment,c),h(OA.$$.fragment,c),h(GA.$$.fragment,c),h(XA.$$.fragment,c),h(zA.$$.fragment,c),h(WA.$$.fragment,c),h(QA.$$.fragment,c),h(HA.$$.fragment,c),h(UA.$$.fragment,c),h(JA.$$.fragment,c),h(KA.$$.fragment,c),h(ZA.$$.fragment,c),h(eL.$$.fragment,c),h(oL.$$.fragment,c),h(rL.$$.fragment,c),h(tL.$$.fragment,c),h(nL.$$.fragment,c),h(sL.$$.fragment,c),h(lL.$$.fragment,c),h(iL.$$.fragment,c),h(dL.$$.fragment,c),h(cL.$$.fragment,c),h(mL.$$.fragment,c),h(gL.$$.fragment,c),h(hL.$$.fragment,c),h(pL.$$.fragment,c),h(_L.$$.fragment,c),h(uL.$$.fragment,c),h(vL.$$.fragment,c),h(TL.$$.fragment,c),h(FL.$$.fragment,c),h(CL.$$.fragment,c),h(ML.$$.fragment,c),h(EL.$$.fragment,c),h(wL.$$.fragment,c),h(AL.$$.fragment,c),h(LL.$$.fragment,c),h(BL.$$.fragment,c),h(xL.$$.fragment,c),h(kL.$$.fragment,c),h(SL.$$.fragment,c),h(PL.$$.fragment,c),h($L.$$.fragment,c),h(jL.$$.fragment,c),h(DL.$$.fragment,c),h(NL.$$.fragment,c),h(OL.$$.fragment,c),h(GL.$$.fragment,c),h(XL.$$.fragment,c),h(VL.$$.fragment,c),pRe=!0)},o(c){p(fe.$$.fragment,c),p(Na.$$.fragment,c),p(Z4.$$.fragment,c),p(eE.$$.fragment,c),p(qf.$$.fragment,c),p(oE.$$.fragment,c),p(rE.$$.fragment,c),p(nE.$$.fragment,c),p(sE.$$.fragment,c),p(lE.$$.fragment,c),p(iE.$$.fragment,c),p(dE.$$.fragment,c),p(mE.$$.fragment,c),p(gE.$$.fragment,c),p(hE.$$.fragment,c),p(pE.$$.fragment,c),p(_E.$$.fragment,c),p(vE.$$.fragment,c),p(yh.$$.fragment,c),p(TE.$$.fragment,c),p(FE.$$.fragment,c),p(CE.$$.fragment,c),p(ME.$$.fragment,c),p(wE.$$.fragment,c),p(Ih.$$.fragment,c),p(AE.$$.fragment,c),p(LE.$$.fragment,c),p(BE.$$.fragment,c),p(xE.$$.fragment,c),p(RE.$$.fragment,c),p(SE.$$.fragment,c),p(PE.$$.fragment,c),p($E.$$.fragment,c),p(IE.$$.fragment,c),p(jE.$$.fragment,c),p(NE.$$.fragment,c),p(qE.$$.fragment,c),p(OE.$$.fragment,c),p(GE.$$.fragment,c),p(XE.$$.fragment,c),p(VE.$$.fragment,c),p(WE.$$.fragment,c),p(QE.$$.fragment,c),p(HE.$$.fragment,c),p(UE.$$.fragment,c),p(JE.$$.fragment,c),p(YE.$$.fragment,c),p(ZE.$$.fragment,c),p(e3.$$.fragment,c),p(o3.$$.fragment,c),p(r3.$$.fragment,c),p(t3.$$.fragment,c),p(a3.$$.fragment,c),p(s3.$$.fragment,c),p(l3.$$.fragment,c),p(i3.$$.fragment,c),p(d3.$$.fragment,c),p(c3.$$.fragment,c),p(f3.$$.fragment,c),p(g3.$$.fragment,c),p(h3.$$.fragment,c),p(p3.$$.fragment,c),p(_3.$$.fragment,c),p(u3.$$.fragment,c),p(b3.$$.fragment,c),p(T3.$$.fragment,c),p(F3.$$.fragment,c),p(C3.$$.fragment,c),p(M3.$$.fragment,c),p(E3.$$.fragment,c),p(y3.$$.fragment,c),p(A3.$$.fragment,c),p(L3.$$.fragment,c),p(B3.$$.fragment,c),p(x3.$$.fragment,c),p(k3.$$.fragment,c),p(R3.$$.fragment,c),p(P3.$$.fragment,c),p($3.$$.fragment,c),p(I3.$$.fragment,c),p(j3.$$.fragment,c),p(D3.$$.fragment,c),p(N3.$$.fragment,c),p(O3.$$.fragment,c),p(G3.$$.fragment,c),p(X3.$$.fragment,c),p(V3.$$.fragment,c),p(z3.$$.fragment,c),p(W3.$$.fragment,c),p(H3.$$.fragment,c),p(U3.$$.fragment,c),p(J3.$$.fragment,c),p(Y3.$$.fragment,c),p(K3.$$.fragment,c),p(Z3.$$.fragment,c),p(oy.$$.fragment,c),p(ry.$$.fragment,c),p(ty.$$.fragment,c),p(ay.$$.fragment,c),p(ny.$$.fragment,c),p(sy.$$.fragment,c),p(iy.$$.fragment,c),p(dy.$$.fragment,c),p(cy.$$.fragment,c),p(fy.$$.fragment,c),p(my.$$.fragment,c),p(gy.$$.fragment,c),p(py.$$.fragment,c),p(_y.$$.fragment,c),p(uy.$$.fragment,c),p(by.$$.fragment,c),p(vy.$$.fragment,c),p(Ty.$$.fragment,c),p(Cy.$$.fragment,c),p(My.$$.fragment,c),p(Ey.$$.fragment,c),p(yy.$$.fragment,c),p(wy.$$.fragment,c),p(Ay.$$.fragment,c),p(By.$$.fragment,c),p(xy.$$.fragment,c),p(ky.$$.fragment,c),p(Ry.$$.fragment,c),p(Sy.$$.fragment,c),p(Py.$$.fragment,c),p(Iy.$$.fragment,c),p(jy.$$.fragment,c),p(Dy.$$.fragment,c),p(qy.$$.fragment,c),p(Oy.$$.fragment,c),p(Gy.$$.fragment,c),p(Vy.$$.fragment,c),p(zy.$$.fragment,c),p(Wy.$$.fragment,c),p(Qy.$$.fragment,c),p(Hy.$$.fragment,c),p(Uy.$$.fragment,c),p(Yy.$$.fragment,c),p(Ky.$$.fragment,c),p(Zy.$$.fragment,c),p(ew.$$.fragment,c),p(ow.$$.fragment,c),p(rw.$$.fragment,c),p(aw.$$.fragment,c),p(nw.$$.fragment,c),p(sw.$$.fragment,c),p(lw.$$.fragment,c),p(iw.$$.fragment,c),p(dw.$$.fragment,c),p(fw.$$.fragment,c),p(mw.$$.fragment,c),p(gw.$$.fragment,c),p(hw.$$.fragment,c),p(pw.$$.fragment,c),p(_w.$$.fragment,c),p(bw.$$.fragment,c),p(vw.$$.fragment,c),p(Tw.$$.fragment,c),p(Cw.$$.fragment,c),p(Mw.$$.fragment,c),p(Ew.$$.fragment,c),p(ww.$$.fragment,c),p(Aw.$$.fragment,c),p(Lw.$$.fragment,c),p(Bw.$$.fragment,c),p(xw.$$.fragment,c),p(kw.$$.fragment,c),p(Sw.$$.fragment,c),p(Pw.$$.fragment,c),p($w.$$.fragment,c),p(Iw.$$.fragment,c),p(jw.$$.fragment,c),p(Dw.$$.fragment,c),p(qw.$$.fragment,c),p(Ow.$$.fragment,c),p(Gw.$$.fragment,c),p(Xw.$$.fragment,c),p(Vw.$$.fragment,c),p(zw.$$.fragment,c),p(Qw.$$.fragment,c),p(Hw.$$.fragment,c),p(Uw.$$.fragment,c),p(Jw.$$.fragment,c),p(Yw.$$.fragment,c),p(Kw.$$.fragment,c),p(e6.$$.fragment,c),p(o6.$$.fragment,c),p(r6.$$.fragment,c),p(a6.$$.fragment,c),p(n6.$$.fragment,c),p(s6.$$.fragment,c),p(i6.$$.fragment,c),p(d6.$$.fragment,c),p(c6.$$.fragment,c),p(f6.$$.fragment,c),p(m6.$$.fragment,c),p(g6.$$.fragment,c),p(p6.$$.fragment,c),p(_6.$$.fragment,c),p(u6.$$.fragment,c),p(b6.$$.fragment,c),p(v6.$$.fragment,c),p(T6.$$.fragment,c),p(C6.$$.fragment,c),p(M6.$$.fragment,c),p(E6.$$.fragment,c),p(y6.$$.fragment,c),p(w6.$$.fragment,c),p(A6.$$.fragment,c),p(B6.$$.fragment,c),p(x6.$$.fragment,c),p(k6.$$.fragment,c),p(R6.$$.fragment,c),p(S6.$$.fragment,c),p(P6.$$.fragment,c),p(I6.$$.fragment,c),p(j6.$$.fragment,c),p(D6.$$.fragment,c),p(N6.$$.fragment,c),p(q6.$$.fragment,c),p(O6.$$.fragment,c),p(X6.$$.fragment,c),p(V6.$$.fragment,c),p(z6.$$.fragment,c),p(W6.$$.fragment,c),p(Q6.$$.fragment,c),p(H6.$$.fragment,c),p(J6.$$.fragment,c),p(Y6.$$.fragment,c),p(K6.$$.fragment,c),p(Z6.$$.fragment,c),p(eA.$$.fragment,c),p(oA.$$.fragment,c),p(tA.$$.fragment,c),p(aA.$$.fragment,c),p(nA.$$.fragment,c),p(sA.$$.fragment,c),p(lA.$$.fragment,c),p(iA.$$.fragment,c),p(cA.$$.fragment,c),p(fA.$$.fragment,c),p(mA.$$.fragment,c),p(gA.$$.fragment,c),p(hA.$$.fragment,c),p(pA.$$.fragment,c),p(uA.$$.fragment,c),p(bA.$$.fragment,c),p(vA.$$.fragment,c),p(TA.$$.fragment,c),p(FA.$$.fragment,c),p(CA.$$.fragment,c),p(EA.$$.fragment,c),p(yA.$$.fragment,c),p(wA.$$.fragment,c),p(AA.$$.fragment,c),p(LA.$$.fragment,c),p(BA.$$.fragment,c),p(kA.$$.fragment,c),p(RA.$$.fragment,c),p(SA.$$.fragment,c),p(PA.$$.fragment,c),p($A.$$.fragment,c),p(IA.$$.fragment,c),p(DA.$$.fragment,c),p(NA.$$.fragment,c),p(qA.$$.fragment,c),p(OA.$$.fragment,c),p(GA.$$.fragment,c),p(XA.$$.fragment,c),p(zA.$$.fragment,c),p(WA.$$.fragment,c),p(QA.$$.fragment,c),p(HA.$$.fragment,c),p(UA.$$.fragment,c),p(JA.$$.fragment,c),p(KA.$$.fragment,c),p(ZA.$$.fragment,c),p(eL.$$.fragment,c),p(oL.$$.fragment,c),p(rL.$$.fragment,c),p(tL.$$.fragment,c),p(nL.$$.fragment,c),p(sL.$$.fragment,c),p(lL.$$.fragment,c),p(iL.$$.fragment,c),p(dL.$$.fragment,c),p(cL.$$.fragment,c),p(mL.$$.fragment,c),p(gL.$$.fragment,c),p(hL.$$.fragment,c),p(pL.$$.fragment,c),p(_L.$$.fragment,c),p(uL.$$.fragment,c),p(vL.$$.fragment,c),p(TL.$$.fragment,c),p(FL.$$.fragment,c),p(CL.$$.fragment,c),p(ML.$$.fragment,c),p(EL.$$.fragment,c),p(wL.$$.fragment,c),p(AL.$$.fragment,c),p(LL.$$.fragment,c),p(BL.$$.fragment,c),p(xL.$$.fragment,c),p(kL.$$.fragment,c),p(SL.$$.fragment,c),p(PL.$$.fragment,c),p($L.$$.fragment,c),p(jL.$$.fragment,c),p(DL.$$.fragment,c),p(NL.$$.fragment,c),p(OL.$$.fragment,c),p(GL.$$.fragment,c),p(XL.$$.fragment,c),p(VL.$$.fragment,c),pRe=!1},d(c){t(J),c&&t($e),c&&t(de),_(fe),c&&t($f),c&&t(ca),c&&t(Be),c&&t(co),c&&t(jf),_(Na,c),c&&t(fo),c&&t(he),c&&t(zo),c&&t(qa),c&&t(hxe),c&&t(Xi),_(Z4),c&&t(pxe),c&&t(zn),c&&t(_xe),_(eE,c),c&&t(uxe),c&&t(Q8),c&&t(bxe),_(qf,c),c&&t(vxe),c&&t(Vi),_(oE),c&&t(Txe),c&&t(Wo),_(rE),_(nE),_(sE),_(lE),c&&t(Fxe),c&&t(Wi),_(iE),c&&t(Cxe),c&&t(Qo),_(dE),_(mE),_(gE),_(hE),c&&t(Mxe),c&&t(Qi),_(pE),c&&t(Exe),c&&t(Ho),_(_E),_(vE),_(yh),_(TE),_(FE),c&&t(yxe),c&&t(Hi),_(CE),c&&t(wxe),c&&t(Uo),_(ME),_(wE),_(Ih),_(AE),_(LE),c&&t(Axe),c&&t(Ji),_(BE),c&&t(Lxe),c&&t(Jo),_(xE),_(RE),_(SE),_(PE),_($E),c&&t(Bxe),c&&t(Zi),_(IE),c&&t(xxe),c&&t(Yo),_(jE),_(NE),_(qE),_(OE),_(GE),c&&t(kxe),c&&t(rd),_(XE),c&&t(Rxe),c&&t(Ko),_(VE),_(WE),_(QE),_(HE),_(UE),c&&t(Sxe),c&&t(nd),_(JE),c&&t(Pxe),c&&t(Zo),_(YE),_(ZE),_(e3),_(o3),_(r3),c&&t($xe),c&&t(id),_(t3),c&&t(Ixe),c&&t(er),_(a3),_(s3),_(l3),_(i3),_(d3),c&&t(jxe),c&&t(fd),_(c3),c&&t(Dxe),c&&t(or),_(f3),_(g3),_(h3),_(p3),_(_3),c&&t(Nxe),c&&t(hd),_(u3),c&&t(qxe),c&&t(rr),_(b3),_(T3),_(F3),_(C3),_(M3),c&&t(Oxe),c&&t(ud),_(E3),c&&t(Gxe),c&&t(tr),_(y3),_(A3),_(L3),_(B3),_(x3),c&&t(Xxe),c&&t(Td),_(k3),c&&t(Vxe),c&&t(ar),_(R3),_(P3),_($3),_(I3),_(j3),c&&t(zxe),c&&t(Md),_(D3),c&&t(Wxe),c&&t(nr),_(N3),_(O3),_(G3),_(X3),_(V3),c&&t(Qxe),c&&t(wd),_(z3),c&&t(Hxe),c&&t(sr),_(W3),_(H3),_(U3),_(J3),_(Y3),c&&t(Uxe),c&&t(Bd),_(K3),c&&t(Jxe),c&&t(lr),_(Z3),_(oy),_(ry),_(ty),_(ay),c&&t(Yxe),c&&t(Rd),_(ny),c&&t(Kxe),c&&t(ir),_(sy),_(iy),_(dy),_(cy),_(fy),c&&t(Zxe),c&&t($d),_(my),c&&t(eke),c&&t(dr),_(gy),_(py),_(_y),_(uy),_(by),c&&t(oke),c&&t(Dd),_(vy),c&&t(rke),c&&t(cr),_(Ty),_(Cy),_(My),_(Ey),_(yy),c&&t(tke),c&&t(Od),_(wy),c&&t(ake),c&&t(fr),_(Ay),_(By),_(xy),_(ky),_(Ry),c&&t(nke),c&&t(Vd),_(Sy),c&&t(ske),c&&t(mr),_(Py),_(Iy),_(jy),_(Dy),_(qy),c&&t(lke),c&&t(Qd),_(Oy),c&&t(ike),c&&t(gr),_(Gy),_(Vy),_(zy),_(Wy),_(Qy),c&&t(dke),c&&t(Jd),_(Hy),c&&t(cke),c&&t(hr),_(Uy),_(Yy),_(Ky),_(Zy),_(ew),c&&t(fke),c&&t(ec),_(ow),c&&t(mke),c&&t(pr),_(rw),_(aw),_(nw),_(sw),_(lw),c&&t(gke),c&&t(tc),_(iw),c&&t(hke),c&&t(_r),_(dw),_(fw),_(mw),_(gw),_(hw),c&&t(pke),c&&t(sc),_(pw),c&&t(_ke),c&&t(ur),_(_w),_(bw),_(vw),_(Tw),_(Cw),c&&t(uke),c&&t(dc),_(Mw),c&&t(bke),c&&t(br),_(Ew),_(ww),_(Aw),_(Lw),_(Bw),c&&t(vke),c&&t(mc),_(xw),c&&t(Tke),c&&t(vr),_(kw),_(Sw),_(Pw),_($w),_(Iw),c&&t(Fke),c&&t(pc),_(jw),c&&t(Cke),c&&t(Tr),_(Dw),_(qw),_(Ow),_(Gw),_(Xw),c&&t(Mke),c&&t(bc),_(Vw),c&&t(Eke),c&&t(Fr),_(zw),_(Qw),_(Hw),_(Uw),_(Jw),c&&t(yke),c&&t(Fc),_(Yw),c&&t(wke),c&&t(Cr),_(Kw),_(e6),_(o6),_(r6),_(a6),c&&t(Ake),c&&t(Ec),_(n6),c&&t(Lke),c&&t(Mr),_(s6),_(i6),_(d6),_(c6),_(f6),c&&t(Bke),c&&t(Ac),_(m6),c&&t(xke),c&&t(Er),_(g6),_(p6),_(_6),_(u6),_(b6),c&&t(kke),c&&t(xc),_(v6),c&&t(Rke),c&&t(yr),_(T6),_(C6),_(M6),_(E6),_(y6),c&&t(Ske),c&&t(Sc),_(w6),c&&t(Pke),c&&t(wr),_(A6),_(B6),_(x6),_(k6),_(R6),c&&t($ke),c&&t(Ic),_(S6),c&&t(Ike),c&&t(Ar),_(P6),_(I6),_(j6),_(D6),_(N6),c&&t(jke),c&&t(Nc),_(q6),c&&t(Dke),c&&t(Lr),_(O6),_(X6),_(V6),_(z6),_(W6),c&&t(Nke),c&&t(Gc),_(Q6),c&&t(qke),c&&t(Br),_(H6),_(J6),_(Y6),_(K6),_(Z6),c&&t(Oke),c&&t(zc),_(eA),c&&t(Gke),c&&t(xr),_(oA),_(tA),_(aA),_(nA),_(sA),c&&t(Xke),c&&t(Hc),_(lA),c&&t(Vke),c&&t(kr),_(iA),_(cA),_(fA),_(mA),_(gA),c&&t(zke),c&&t(Yc),_(hA),c&&t(Wke),c&&t(Rr),_(pA),_(uA),_(bA),_(vA),_(TA),c&&t(Qke),c&&t(ef),_(FA),c&&t(Hke),c&&t(Sr),_(CA),_(EA),_(yA),_(wA),_(AA),c&&t(Uke),c&&t(tf),_(LA),c&&t(Jke),c&&t(Pr),_(BA),_(kA),_(RA),_(SA),_(PA),c&&t(Yke),c&&t(sf),_($A),c&&t(Kke),c&&t($r),_(IA),_(DA),_(NA),_(qA),_(OA),c&&t(Zke),c&&t(cf),_(GA),c&&t(eRe),c&&t(Ir),_(XA),_(zA),_(WA),_(QA),_(HA),c&&t(oRe),c&&t(gf),_(UA),c&&t(rRe),c&&t(jr),_(JA),_(KA),_(ZA),_(eL),_(oL),c&&t(tRe),c&&t(_f),_(rL),c&&t(aRe),c&&t(Dr),_(tL),_(nL),_(sL),_(lL),_(iL),c&&t(nRe),c&&t(vf),_(dL),c&&t(sRe),c&&t(Nr),_(cL),_(mL),_(gL),_(hL),_(pL),c&&t(lRe),c&&t(Cf),_(_L),c&&t(iRe),c&&t(qr),_(uL),_(vL),_(TL),_(FL),_(CL),c&&t(dRe),c&&t(yf),_(ML),c&&t(cRe),c&&t(Or),_(EL),_(wL),_(AL),_(LL),_(BL),c&&t(fRe),c&&t(Lf),_(xL),c&&t(mRe),c&&t(Gr),_(kL),_(SL),_(PL),_($L),_(jL),c&&t(gRe),c&&t(kf),_(DL),c&&t(hRe),c&&t(Xr),_(NL),_(OL),_(GL),_(XL),_(VL)}}}const fTt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function mTt($i,J,$e){let{fw:de}=J;return $i.$$set=ge=>{"fw"in ge&&$e(0,de=ge.fw)},[de]}class vTt extends tTt{constructor(J){super();aTt(this,J,mTt,cTt,nTt,{fw:0})}}export{vTt as default,fTt as metadata};
