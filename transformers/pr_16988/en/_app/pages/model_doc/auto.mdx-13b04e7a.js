import{S as N3t,i as j3t,s as D3t,e as a,k as l,w as F,t as o,M as G3t,c as n,d as t,m as i,a as s,x as T,h as r,b as c,F as e,g as b,y as M,q as E,o as C,B as w,v as O3t,L as I}from"../../chunks/vendor-6b77c823.js";import{T as yqr}from"../../chunks/Tip-39098574.js";import{D as R}from"../../chunks/Docstring-1088f2fb.js";import{C as B}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as ee}from"../../chunks/IconCopyLink-7a11ce68.js";import{E as P}from"../../chunks/ExampleCodeBlock-5212b321.js";function V3t(A){let g,v,p,m,u,d,h,Mo,ii,mf,et,di,ci,Gw,gf,qe,Xe,fi,yn,Ow,Ln,xn,Vw,mi,$n,Xw,gi,hf,Ma;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),ii=a("code"),mf=o("model_type"),et=o(" attribute is set to the same key you use when registering the config (here "),di=a("code"),ci=o('"new-model"'),Gw=o(")."),gf=l(),qe=a("p"),Xe=o("Likewise, if your "),fi=a("code"),yn=o("NewModel"),Ow=o(" is a subclass of "),Ln=a("a"),xn=o("PreTrainedModel"),Vw=o(`, make sure its
`),mi=a("code"),$n=o("config_class"),Xw=o(` attribute is set to the same class you use when registering the model (here
`),gi=a("code"),hf=o("NewModelConfig"),Ma=o(")."),this.h()},l(ze){g=n(ze,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var i$=s(p);m=r(i$,"NewModelConfig"),i$.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var hi=s(d);h=r(hi,"PretrainedConfig"),hi.forEach(t),Mo=r(Ae,`, make sure its
`),ii=n(Ae,"CODE",{});var d$=s(ii);mf=r(d$,"model_type"),d$.forEach(t),et=r(Ae," attribute is set to the same key you use when registering the config (here "),di=n(Ae,"CODE",{});var c$=s(di);ci=r(c$,'"new-model"'),c$.forEach(t),Gw=r(Ae,")."),Ae.forEach(t),gf=i(ze),qe=n(ze,"P",{});var Eo=s(qe);Xe=r(Eo,"Likewise, if your "),fi=n(Eo,"CODE",{});var Ea=s(fi);yn=r(Ea,"NewModel"),Ea.forEach(t),Ow=r(Eo," is a subclass of "),Ln=n(Eo,"A",{href:!0});var f$=s(Ln);xn=r(f$,"PreTrainedModel"),f$.forEach(t),Vw=r(Eo,`, make sure its
`),mi=n(Eo,"CODE",{});var pf=s(mi);$n=r(pf,"config_class"),pf.forEach(t),Xw=r(Eo,` attribute is set to the same class you use when registering the model (here
`),gi=n(Eo,"CODE",{});var m$=s(gi);hf=r(m$,"NewModelConfig"),m$.forEach(t),Ma=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(Ln,"href","/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel")},m(ze,Ae){b(ze,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Mo),e(g,ii),e(ii,mf),e(g,et),e(g,di),e(di,ci),e(g,Gw),b(ze,gf,Ae),b(ze,qe,Ae),e(qe,Xe),e(qe,fi),e(fi,yn),e(qe,Ow),e(qe,Ln),e(Ln,xn),e(qe,Vw),e(qe,mi),e(mi,$n),e(qe,Xw),e(qe,gi),e(gi,hf),e(qe,Ma)},d(ze){ze&&t(g),ze&&t(gf),ze&&t(qe)}}}function X3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function z3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Q3t(A){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function W3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function H3t(A){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function U3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function J3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Y3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function K3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Z3t(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ewt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function owt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function twt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function awt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function swt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _wt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Twt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ewt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Awt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ywt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $wt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Swt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Iwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Owt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ywt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zwt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _At(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $At(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jAt(A){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DAt(A){let g,v,p,m,u,d,h,Mo,ii,mf,et,di,ci,Gw,gf,qe,Xe,fi,yn,Ow,Ln,xn,Vw,mi,$n,Xw,gi,hf,Ma,ze,Ae,i$,hi,d$,c$,Eo,Ea,f$,pf,m$,Aje,pPe,pi,uf,GZ,zw,yje,OZ,Lje,uPe,kn,xje,VZ,$je,kje,XZ,Sje,Rje,_Pe,Qw,bPe,g$,Bje,vPe,_f,FPe,ui,bf,zZ,Ww,Pje,QZ,Ije,TPe,Co,Hw,qje,Uw,Nje,h$,jje,Dje,Gje,Jw,Oje,WZ,Vje,Xje,zje,Er,Yw,Qje,HZ,Wje,Hje,_i,Uje,UZ,Jje,Yje,JZ,Kje,Zje,eDe,y,vf,YZ,oDe,rDe,p$,tDe,aDe,nDe,Ff,KZ,sDe,lDe,u$,iDe,dDe,cDe,Tf,ZZ,fDe,mDe,_$,gDe,hDe,pDe,Mf,eee,uDe,_De,b$,bDe,vDe,FDe,Ef,oee,TDe,MDe,v$,EDe,CDe,wDe,Cf,ree,ADe,yDe,F$,LDe,xDe,$De,wf,tee,kDe,SDe,T$,RDe,BDe,PDe,Af,aee,IDe,qDe,M$,NDe,jDe,DDe,yf,nee,GDe,ODe,E$,VDe,XDe,zDe,Lf,see,QDe,WDe,C$,HDe,UDe,JDe,xf,lee,YDe,KDe,w$,ZDe,eGe,oGe,$f,iee,rGe,tGe,A$,aGe,nGe,sGe,kf,dee,lGe,iGe,y$,dGe,cGe,fGe,Sf,cee,mGe,gGe,L$,hGe,pGe,uGe,Rf,fee,_Ge,bGe,x$,vGe,FGe,TGe,Bf,mee,MGe,EGe,$$,CGe,wGe,AGe,Pf,gee,yGe,LGe,k$,xGe,$Ge,kGe,If,hee,SGe,RGe,S$,BGe,PGe,IGe,qf,pee,qGe,NGe,R$,jGe,DGe,GGe,Nf,uee,OGe,VGe,B$,XGe,zGe,QGe,jf,_ee,WGe,HGe,P$,UGe,JGe,YGe,Df,bee,KGe,ZGe,I$,eOe,oOe,rOe,Gf,vee,tOe,aOe,q$,nOe,sOe,lOe,Of,Fee,iOe,dOe,N$,cOe,fOe,mOe,Vf,Tee,gOe,hOe,j$,pOe,uOe,_Oe,Xf,Mee,bOe,vOe,D$,FOe,TOe,MOe,zf,Eee,EOe,COe,G$,wOe,AOe,yOe,Qf,Cee,LOe,xOe,O$,$Oe,kOe,SOe,Wf,wee,ROe,BOe,V$,POe,IOe,qOe,Hf,Aee,NOe,jOe,X$,DOe,GOe,OOe,Uf,yee,VOe,XOe,z$,zOe,QOe,WOe,Jf,Lee,HOe,UOe,Q$,JOe,YOe,KOe,Yf,xee,ZOe,eVe,W$,oVe,rVe,tVe,Kf,$ee,aVe,nVe,H$,sVe,lVe,iVe,Zf,kee,dVe,cVe,U$,fVe,mVe,gVe,em,See,hVe,pVe,J$,uVe,_Ve,bVe,om,Ree,vVe,FVe,Y$,TVe,MVe,EVe,rm,Bee,CVe,wVe,K$,AVe,yVe,LVe,tm,Pee,xVe,$Ve,Z$,kVe,SVe,RVe,am,Iee,BVe,PVe,ek,IVe,qVe,NVe,nm,qee,jVe,DVe,ok,GVe,OVe,VVe,sm,Nee,XVe,zVe,rk,QVe,WVe,HVe,lm,jee,UVe,JVe,tk,YVe,KVe,ZVe,im,Dee,eXe,oXe,ak,rXe,tXe,aXe,dm,Gee,nXe,sXe,nk,lXe,iXe,dXe,cm,Oee,cXe,fXe,sk,mXe,gXe,hXe,fm,Vee,pXe,uXe,lk,_Xe,bXe,vXe,mm,Xee,FXe,TXe,ik,MXe,EXe,CXe,gm,zee,wXe,AXe,dk,yXe,LXe,xXe,hm,Qee,$Xe,kXe,ck,SXe,RXe,BXe,pm,Wee,PXe,IXe,fk,qXe,NXe,jXe,um,Hee,DXe,GXe,mk,OXe,VXe,XXe,_m,Uee,zXe,QXe,gk,WXe,HXe,UXe,bm,Jee,JXe,YXe,hk,KXe,ZXe,eze,vm,Yee,oze,rze,pk,tze,aze,nze,Fm,Kee,sze,lze,uk,ize,dze,cze,Tm,Zee,fze,mze,_k,gze,hze,pze,Mm,eoe,uze,_ze,bk,bze,vze,Fze,Em,ooe,Tze,Mze,vk,Eze,Cze,wze,Cm,roe,Aze,yze,Fk,Lze,xze,$ze,wm,toe,kze,Sze,Tk,Rze,Bze,Pze,Am,aoe,Ize,qze,Mk,Nze,jze,Dze,ym,noe,Gze,Oze,Ek,Vze,Xze,zze,Lm,soe,Qze,Wze,Ck,Hze,Uze,Jze,xm,loe,Yze,Kze,wk,Zze,eQe,oQe,$m,ioe,rQe,tQe,Ak,aQe,nQe,sQe,km,doe,lQe,iQe,yk,dQe,cQe,fQe,Sm,coe,mQe,gQe,Lk,hQe,pQe,uQe,Rm,foe,_Qe,bQe,xk,vQe,FQe,TQe,Bm,moe,MQe,EQe,$k,CQe,wQe,AQe,Pm,goe,yQe,LQe,kk,xQe,$Qe,kQe,Im,hoe,SQe,RQe,Sk,BQe,PQe,IQe,qm,poe,qQe,NQe,Rk,jQe,DQe,GQe,Nm,uoe,OQe,VQe,Bk,XQe,zQe,QQe,jm,_oe,WQe,HQe,Pk,UQe,JQe,YQe,Dm,boe,KQe,ZQe,Ik,eWe,oWe,rWe,Gm,voe,tWe,aWe,qk,nWe,sWe,lWe,Om,Foe,iWe,dWe,Nk,cWe,fWe,mWe,Vm,Toe,gWe,hWe,jk,pWe,uWe,_We,Xm,Moe,bWe,vWe,Dk,FWe,TWe,MWe,zm,Eoe,EWe,CWe,Gk,wWe,AWe,yWe,Qm,Coe,LWe,xWe,Ok,$We,kWe,SWe,Wm,woe,RWe,BWe,Vk,PWe,IWe,qWe,Hm,Aoe,NWe,jWe,Xk,DWe,GWe,OWe,Um,yoe,VWe,XWe,zk,zWe,QWe,WWe,Jm,Loe,HWe,UWe,Qk,JWe,YWe,KWe,Ym,xoe,ZWe,eHe,Wk,oHe,rHe,tHe,Km,$oe,aHe,nHe,Hk,sHe,lHe,iHe,Zm,koe,dHe,cHe,Uk,fHe,mHe,gHe,eg,Soe,hHe,pHe,Jk,uHe,_He,bHe,og,Roe,vHe,FHe,Yk,THe,MHe,EHe,rg,Boe,CHe,wHe,Kk,AHe,yHe,LHe,tg,Poe,xHe,$He,Zk,kHe,SHe,RHe,ag,Ioe,BHe,PHe,eS,IHe,qHe,NHe,ng,qoe,jHe,DHe,oS,GHe,OHe,VHe,sg,Noe,XHe,zHe,rS,QHe,WHe,HHe,lg,joe,UHe,JHe,tS,YHe,KHe,ZHe,ig,Doe,eUe,oUe,aS,rUe,tUe,aUe,dg,Goe,nUe,sUe,nS,lUe,iUe,dUe,cg,Ooe,cUe,fUe,sS,mUe,gUe,hUe,fg,Voe,pUe,uUe,lS,_Ue,bUe,vUe,mg,Xoe,FUe,TUe,iS,MUe,EUe,CUe,gg,zoe,wUe,AUe,dS,yUe,LUe,xUe,hg,$Ue,pg,Kw,kUe,Qoe,SUe,MPe,bi,ug,Woe,Zw,RUe,Hoe,BUe,EPe,wo,eA,PUe,oA,IUe,cS,qUe,NUe,jUe,rA,DUe,Uoe,GUe,OUe,VUe,Cr,tA,XUe,Joe,zUe,QUe,Ca,WUe,Yoe,HUe,UUe,Koe,JUe,YUe,Zoe,KUe,ZUe,eJe,k,Sn,ere,oJe,rJe,fS,tJe,aJe,mS,nJe,sJe,lJe,Rn,ore,iJe,dJe,gS,cJe,fJe,hS,mJe,gJe,hJe,Bn,rre,pJe,uJe,pS,_Je,bJe,uS,vJe,FJe,TJe,_g,tre,MJe,EJe,_S,CJe,wJe,AJe,Pn,are,yJe,LJe,bS,xJe,$Je,vS,kJe,SJe,RJe,bg,nre,BJe,PJe,FS,IJe,qJe,NJe,vg,sre,jJe,DJe,TS,GJe,OJe,VJe,Fg,lre,XJe,zJe,MS,QJe,WJe,HJe,In,ire,UJe,JJe,ES,YJe,KJe,CS,ZJe,eYe,oYe,qn,dre,rYe,tYe,wS,aYe,nYe,AS,sYe,lYe,iYe,Nn,cre,dYe,cYe,yS,fYe,mYe,LS,gYe,hYe,pYe,Tg,fre,uYe,_Ye,xS,bYe,vYe,FYe,Mg,mre,TYe,MYe,$S,EYe,CYe,wYe,jn,gre,AYe,yYe,kS,LYe,xYe,SS,$Ye,kYe,SYe,Eg,hre,RYe,BYe,RS,PYe,IYe,qYe,Dn,pre,NYe,jYe,BS,DYe,GYe,PS,OYe,VYe,XYe,Gn,ure,zYe,QYe,IS,WYe,HYe,qS,UYe,JYe,YYe,On,_re,KYe,ZYe,NS,eKe,oKe,jS,rKe,tKe,aKe,Cg,bre,nKe,sKe,DS,lKe,iKe,dKe,Vn,vre,cKe,fKe,GS,mKe,gKe,OS,hKe,pKe,uKe,Xn,Fre,_Ke,bKe,VS,vKe,FKe,XS,TKe,MKe,EKe,zn,Tre,CKe,wKe,zS,AKe,yKe,QS,LKe,xKe,$Ke,Qn,Mre,kKe,SKe,WS,RKe,BKe,HS,PKe,IKe,qKe,Wn,Ere,NKe,jKe,US,DKe,GKe,JS,OKe,VKe,XKe,Hn,Cre,zKe,QKe,YS,WKe,HKe,KS,UKe,JKe,YKe,wg,wre,KKe,ZKe,ZS,eZe,oZe,rZe,Un,Are,tZe,aZe,eR,nZe,sZe,oR,lZe,iZe,dZe,Ag,yre,cZe,fZe,rR,mZe,gZe,hZe,Jn,Lre,pZe,uZe,tR,_Ze,bZe,aR,vZe,FZe,TZe,Yn,xre,MZe,EZe,nR,CZe,wZe,sR,AZe,yZe,LZe,Kn,$re,xZe,$Ze,lR,kZe,SZe,iR,RZe,BZe,PZe,Zn,kre,IZe,qZe,dR,NZe,jZe,cR,DZe,GZe,OZe,es,Sre,VZe,XZe,fR,zZe,QZe,mR,WZe,HZe,UZe,yg,Rre,JZe,YZe,gR,KZe,ZZe,eeo,os,Bre,oeo,reo,hR,teo,aeo,pR,neo,seo,leo,rs,Pre,ieo,deo,uR,ceo,feo,_R,meo,geo,heo,ts,Ire,peo,ueo,bR,_eo,beo,vR,veo,Feo,Teo,as,qre,Meo,Eeo,FR,Ceo,weo,TR,Aeo,yeo,Leo,ns,Nre,xeo,$eo,MR,keo,Seo,ER,Reo,Beo,Peo,ss,jre,Ieo,qeo,CR,Neo,jeo,wR,Deo,Geo,Oeo,Lg,Dre,Veo,Xeo,AR,zeo,Qeo,Weo,ls,Gre,Heo,Ueo,yR,Jeo,Yeo,LR,Keo,Zeo,eoo,xg,Ore,ooo,roo,xR,too,aoo,noo,$g,Vre,soo,loo,$R,ioo,doo,coo,is,Xre,foo,moo,kR,goo,hoo,SR,poo,uoo,_oo,ds,zre,boo,voo,RR,Foo,Too,BR,Moo,Eoo,Coo,cs,Qre,woo,Aoo,PR,yoo,Loo,IR,xoo,$oo,koo,kg,Wre,Soo,Roo,qR,Boo,Poo,Ioo,fs,Hre,qoo,Noo,NR,joo,Doo,jR,Goo,Ooo,Voo,ms,Ure,Xoo,zoo,DR,Qoo,Woo,GR,Hoo,Uoo,Joo,gs,Jre,Yoo,Koo,OR,Zoo,ero,VR,oro,rro,tro,hs,Yre,aro,nro,XR,sro,lro,zR,iro,dro,cro,ps,Kre,fro,mro,QR,gro,hro,WR,pro,uro,_ro,us,Zre,bro,vro,HR,Fro,Tro,UR,Mro,Ero,Cro,Sg,ete,wro,Aro,JR,yro,Lro,xro,Rg,ote,$ro,kro,YR,Sro,Rro,Bro,Bg,rte,Pro,Iro,KR,qro,Nro,jro,Pg,tte,Dro,Gro,ZR,Oro,Vro,Xro,_s,ate,zro,Qro,eB,Wro,Hro,oB,Uro,Jro,Yro,Ig,nte,Kro,Zro,rB,eto,oto,rto,bs,ste,tto,ato,tB,nto,sto,aB,lto,ito,dto,vs,lte,cto,fto,nB,mto,gto,sB,hto,pto,uto,Fs,ite,_to,bto,lB,vto,Fto,iB,Tto,Mto,Eto,Ts,dte,Cto,wto,dB,Ato,yto,cB,Lto,xto,$to,Ms,cte,kto,Sto,fB,Rto,Bto,mB,Pto,Ito,qto,Es,fte,Nto,jto,gB,Dto,Gto,hB,Oto,Vto,Xto,qg,mte,zto,Qto,pB,Wto,Hto,Uto,Ng,gte,Jto,Yto,uB,Kto,Zto,eao,Cs,hte,oao,rao,_B,tao,aao,bB,nao,sao,lao,ws,pte,iao,dao,vB,cao,fao,FB,mao,gao,hao,As,ute,pao,uao,TB,_ao,bao,MB,vao,Fao,Tao,jg,_te,Mao,Eao,EB,Cao,wao,Aao,Dg,bte,yao,Lao,CB,xao,$ao,kao,Gg,vte,Sao,Rao,wB,Bao,Pao,Iao,ys,Fte,qao,Nao,AB,jao,Dao,yB,Gao,Oao,Vao,Og,Tte,Xao,zao,LB,Qao,Wao,Hao,Vg,Mte,Uao,Jao,xB,Yao,Kao,Zao,Ls,Ete,eno,ono,$B,rno,tno,kB,ano,nno,sno,Xg,Cte,lno,ino,SB,dno,cno,fno,zg,wte,mno,gno,RB,hno,pno,uno,xs,Ate,_no,bno,BB,vno,Fno,PB,Tno,Mno,Eno,$s,yte,Cno,wno,IB,Ano,yno,qB,Lno,xno,$no,ks,Lte,kno,Sno,NB,Rno,Bno,jB,Pno,Ino,qno,Ss,xte,Nno,jno,DB,Dno,Gno,GB,Ono,Vno,Xno,Qg,zno,Wg,aA,Qno,$te,Wno,CPe,vi,Hg,kte,nA,Hno,Ste,Uno,wPe,Ao,sA,Jno,lA,Yno,OB,Kno,Zno,eso,iA,oso,Rte,rso,tso,aso,Qe,dA,nso,Bte,sso,lso,wa,iso,Pte,dso,cso,Ite,fso,mso,qte,gso,hso,pso,te,Ug,Nte,uso,_so,VB,bso,vso,Fso,Jg,jte,Tso,Mso,XB,Eso,Cso,wso,Yg,Dte,Aso,yso,zB,Lso,xso,$so,Kg,Gte,kso,Sso,QB,Rso,Bso,Pso,Zg,Ote,Iso,qso,WB,Nso,jso,Dso,eh,Vte,Gso,Oso,HB,Vso,Xso,zso,oh,Xte,Qso,Wso,UB,Hso,Uso,Jso,rh,zte,Yso,Kso,JB,Zso,elo,olo,th,Qte,rlo,tlo,YB,alo,nlo,slo,ah,Wte,llo,ilo,KB,dlo,clo,flo,nh,Hte,mlo,glo,ZB,hlo,plo,ulo,sh,Ute,_lo,blo,eP,vlo,Flo,Tlo,lh,Jte,Mlo,Elo,oP,Clo,wlo,Alo,ih,Yte,ylo,Llo,rP,xlo,$lo,klo,dh,Kte,Slo,Rlo,tP,Blo,Plo,Ilo,ch,Zte,qlo,Nlo,aP,jlo,Dlo,Glo,fh,eae,Olo,Vlo,nP,Xlo,zlo,Qlo,mh,oae,Wlo,Hlo,sP,Ulo,Jlo,Ylo,gh,rae,Klo,Zlo,lP,eio,oio,rio,hh,tae,tio,aio,iP,nio,sio,lio,ph,aae,iio,dio,dP,cio,fio,mio,uh,nae,gio,hio,cP,pio,uio,_io,_h,sae,bio,vio,fP,Fio,Tio,Mio,bh,lae,Eio,Cio,mP,wio,Aio,yio,vh,Lio,Fh,xio,Th,cA,$io,iae,kio,APe,Fi,Mh,dae,fA,Sio,cae,Rio,yPe,yo,mA,Bio,gA,Pio,gP,Iio,qio,Nio,hA,jio,fae,Dio,Gio,Oio,We,pA,Vio,mae,Xio,zio,Ti,Qio,gae,Wio,Hio,hae,Uio,Jio,Yio,be,Eh,pae,Kio,Zio,hP,edo,odo,rdo,Ch,uae,tdo,ado,pP,ndo,sdo,ldo,wh,_ae,ido,ddo,uP,cdo,fdo,mdo,Ah,bae,gdo,hdo,_P,pdo,udo,_do,yh,vae,bdo,vdo,bP,Fdo,Tdo,Mdo,Lh,Fae,Edo,Cdo,vP,wdo,Ado,ydo,xh,Tae,Ldo,xdo,FP,$do,kdo,Sdo,$h,Mae,Rdo,Bdo,TP,Pdo,Ido,qdo,kh,Eae,Ndo,jdo,MP,Ddo,Gdo,Odo,Sh,Cae,Vdo,Xdo,EP,zdo,Qdo,Wdo,Rh,wae,Hdo,Udo,CP,Jdo,Ydo,Kdo,Bh,Aae,Zdo,eco,wP,oco,rco,tco,Ph,yae,aco,nco,AP,sco,lco,ico,Ih,Lae,dco,cco,yP,fco,mco,gco,qh,hco,Nh,pco,jh,uA,uco,xae,_co,LPe,Mi,Dh,$ae,_A,bco,kae,vco,xPe,Lo,bA,Fco,Ei,Tco,LP,Mco,Eco,xP,Cco,wco,Aco,vA,yco,Sae,Lco,xco,$co,ot,FA,kco,Rae,Sco,Rco,Ci,Bco,Bae,Pco,Ico,$P,qco,Nco,jco,Gh,Dco,He,TA,Gco,Pae,Oco,Vco,Aa,Xco,Iae,zco,Qco,qae,Wco,Hco,Nae,Uco,Jco,Yco,x,Oh,jae,Kco,Zco,kP,efo,ofo,rfo,Vh,Dae,tfo,afo,SP,nfo,sfo,lfo,Xh,Gae,ifo,dfo,RP,cfo,ffo,mfo,zh,Oae,gfo,hfo,BP,pfo,ufo,_fo,Qh,Vae,bfo,vfo,PP,Ffo,Tfo,Mfo,Wh,Xae,Efo,Cfo,IP,wfo,Afo,yfo,Hh,zae,Lfo,xfo,qP,$fo,kfo,Sfo,Uh,Qae,Rfo,Bfo,NP,Pfo,Ifo,qfo,Jh,Wae,Nfo,jfo,jP,Dfo,Gfo,Ofo,Yh,Hae,Vfo,Xfo,DP,zfo,Qfo,Wfo,Kh,Uae,Hfo,Ufo,GP,Jfo,Yfo,Kfo,Zh,Jae,Zfo,emo,OP,omo,rmo,tmo,ep,Yae,amo,nmo,VP,smo,lmo,imo,op,Kae,dmo,cmo,XP,fmo,mmo,gmo,rp,Zae,hmo,pmo,zP,umo,_mo,bmo,tp,ene,vmo,Fmo,QP,Tmo,Mmo,Emo,ap,one,Cmo,wmo,WP,Amo,ymo,Lmo,np,rne,xmo,$mo,HP,kmo,Smo,Rmo,sp,tne,Bmo,Pmo,UP,Imo,qmo,Nmo,lp,ane,jmo,Dmo,JP,Gmo,Omo,Vmo,ip,nne,Xmo,zmo,YP,Qmo,Wmo,Hmo,dp,sne,Umo,Jmo,KP,Ymo,Kmo,Zmo,cp,lne,ego,ogo,ZP,rgo,tgo,ago,fp,ine,ngo,sgo,eI,lgo,igo,dgo,mp,dne,cgo,fgo,oI,mgo,ggo,hgo,gp,cne,pgo,ugo,rI,_go,bgo,vgo,hp,fne,Fgo,Tgo,tI,Mgo,Ego,Cgo,pp,mne,wgo,Ago,aI,ygo,Lgo,xgo,up,gne,$go,kgo,nI,Sgo,Rgo,Bgo,_p,hne,Pgo,Igo,sI,qgo,Ngo,jgo,Rs,pne,Dgo,Ggo,lI,Ogo,Vgo,iI,Xgo,zgo,Qgo,bp,une,Wgo,Hgo,dI,Ugo,Jgo,Ygo,vp,_ne,Kgo,Zgo,cI,eho,oho,rho,Fp,bne,tho,aho,fI,nho,sho,lho,Tp,vne,iho,dho,mI,cho,fho,mho,Mp,Fne,gho,hho,gI,pho,uho,_ho,Ep,Tne,bho,vho,hI,Fho,Tho,Mho,Cp,Mne,Eho,Cho,pI,who,Aho,yho,wp,Ene,Lho,xho,uI,$ho,kho,Sho,Ap,Cne,Rho,Bho,_I,Pho,Iho,qho,yp,wne,Nho,jho,bI,Dho,Gho,Oho,Lp,Ane,Vho,Xho,vI,zho,Qho,Who,xp,yne,Hho,Uho,FI,Jho,Yho,Kho,$p,Lne,Zho,epo,TI,opo,rpo,tpo,kp,xne,apo,npo,MI,spo,lpo,ipo,Sp,$ne,dpo,cpo,EI,fpo,mpo,gpo,Rp,kne,hpo,ppo,CI,upo,_po,bpo,Bp,Sne,vpo,Fpo,wI,Tpo,Mpo,Epo,Pp,Rne,Cpo,wpo,AI,Apo,ypo,Lpo,Ip,Bne,xpo,$po,yI,kpo,Spo,Rpo,qp,Pne,Bpo,Ppo,LI,Ipo,qpo,Npo,Np,Ine,jpo,Dpo,xI,Gpo,Opo,Vpo,jp,qne,Xpo,zpo,$I,Qpo,Wpo,Hpo,Dp,Nne,Upo,Jpo,kI,Ypo,Kpo,Zpo,Gp,jne,euo,ouo,SI,ruo,tuo,auo,Op,Dne,nuo,suo,RI,luo,iuo,duo,Vp,Gne,cuo,fuo,BI,muo,guo,huo,Xp,One,puo,uuo,PI,_uo,buo,vuo,zp,Vne,Fuo,Tuo,II,Muo,Euo,Cuo,Qp,Xne,wuo,Auo,qI,yuo,Luo,xuo,Wp,zne,$uo,kuo,NI,Suo,Ruo,Buo,Hp,Qne,Puo,Iuo,jI,quo,Nuo,juo,Up,Wne,Duo,Guo,DI,Ouo,Vuo,Xuo,Jp,Hne,zuo,Quo,GI,Wuo,Huo,Uuo,Yp,Une,Juo,Yuo,OI,Kuo,Zuo,e_o,Kp,Jne,o_o,r_o,VI,t_o,a_o,n_o,Zp,Yne,s_o,l_o,XI,i_o,d_o,c_o,eu,Kne,f_o,m_o,zI,g_o,h_o,p_o,ou,Zne,u_o,__o,QI,b_o,v_o,F_o,ru,ese,T_o,M_o,WI,E_o,C_o,w_o,tu,ose,A_o,y_o,HI,L_o,x_o,$_o,au,rse,k_o,S_o,UI,R_o,B_o,P_o,nu,tse,I_o,q_o,JI,N_o,j_o,D_o,su,ase,G_o,O_o,YI,V_o,X_o,z_o,lu,nse,Q_o,W_o,KI,H_o,U_o,J_o,iu,sse,Y_o,K_o,ZI,Z_o,e1o,o1o,du,lse,r1o,t1o,eq,a1o,n1o,s1o,cu,ise,l1o,i1o,oq,d1o,c1o,f1o,fu,dse,m1o,g1o,rq,h1o,p1o,u1o,mu,cse,_1o,b1o,tq,v1o,F1o,T1o,gu,fse,M1o,E1o,aq,C1o,w1o,A1o,hu,mse,y1o,L1o,nq,x1o,$1o,k1o,pu,gse,S1o,R1o,sq,B1o,P1o,I1o,uu,hse,q1o,N1o,lq,j1o,D1o,G1o,_u,pse,O1o,V1o,iq,X1o,z1o,Q1o,bu,use,W1o,H1o,dq,U1o,J1o,Y1o,vu,_se,K1o,Z1o,cq,e8o,o8o,r8o,Fu,bse,t8o,a8o,fq,n8o,s8o,l8o,Tu,vse,i8o,d8o,mq,c8o,f8o,m8o,Mu,Fse,g8o,h8o,gq,p8o,u8o,_8o,Eu,Tse,b8o,v8o,hq,F8o,T8o,M8o,Cu,Mse,E8o,C8o,pq,w8o,A8o,y8o,wu,Ese,L8o,x8o,uq,$8o,k8o,S8o,Au,Cse,R8o,B8o,_q,P8o,I8o,q8o,yu,wse,N8o,j8o,bq,D8o,G8o,O8o,Lu,V8o,Ase,X8o,z8o,yse,Q8o,W8o,xu,$Pe,wi,$u,Lse,MA,H8o,xse,U8o,kPe,xo,EA,J8o,Ai,Y8o,vq,K8o,Z8o,Fq,ebo,obo,rbo,CA,tbo,$se,abo,nbo,sbo,rt,wA,lbo,kse,ibo,dbo,yi,cbo,Sse,fbo,mbo,Tq,gbo,hbo,pbo,ku,ubo,Ue,AA,_bo,Rse,bbo,vbo,ya,Fbo,Bse,Tbo,Mbo,Pse,Ebo,Cbo,Ise,wbo,Abo,ybo,G,Su,qse,Lbo,xbo,Mq,$bo,kbo,Sbo,Ru,Nse,Rbo,Bbo,Eq,Pbo,Ibo,qbo,Bu,jse,Nbo,jbo,Cq,Dbo,Gbo,Obo,Pu,Dse,Vbo,Xbo,wq,zbo,Qbo,Wbo,Iu,Gse,Hbo,Ubo,Aq,Jbo,Ybo,Kbo,qu,Ose,Zbo,e2o,yq,o2o,r2o,t2o,Nu,Vse,a2o,n2o,Lq,s2o,l2o,i2o,ju,Xse,d2o,c2o,xq,f2o,m2o,g2o,Du,zse,h2o,p2o,$q,u2o,_2o,b2o,Gu,Qse,v2o,F2o,kq,T2o,M2o,E2o,Ou,Wse,C2o,w2o,Sq,A2o,y2o,L2o,Vu,Hse,x2o,$2o,Rq,k2o,S2o,R2o,Xu,Use,B2o,P2o,Bq,I2o,q2o,N2o,zu,Jse,j2o,D2o,Pq,G2o,O2o,V2o,Qu,Yse,X2o,z2o,Iq,Q2o,W2o,H2o,Wu,Kse,U2o,J2o,qq,Y2o,K2o,Z2o,Hu,Zse,evo,ovo,Nq,rvo,tvo,avo,Uu,ele,nvo,svo,jq,lvo,ivo,dvo,Ju,ole,cvo,fvo,Dq,mvo,gvo,hvo,Yu,rle,pvo,uvo,Gq,_vo,bvo,vvo,Ku,tle,Fvo,Tvo,Oq,Mvo,Evo,Cvo,Zu,ale,wvo,Avo,Vq,yvo,Lvo,xvo,e_,nle,$vo,kvo,Xq,Svo,Rvo,Bvo,o_,sle,Pvo,Ivo,zq,qvo,Nvo,jvo,r_,lle,Dvo,Gvo,Qq,Ovo,Vvo,Xvo,t_,ile,zvo,Qvo,Wq,Wvo,Hvo,Uvo,a_,dle,Jvo,Yvo,Hq,Kvo,Zvo,eFo,n_,cle,oFo,rFo,Uq,tFo,aFo,nFo,s_,fle,sFo,lFo,Jq,iFo,dFo,cFo,l_,mle,fFo,mFo,Yq,gFo,hFo,pFo,i_,gle,uFo,_Fo,Kq,bFo,vFo,FFo,d_,hle,TFo,MFo,Zq,EFo,CFo,wFo,c_,ple,AFo,yFo,eN,LFo,xFo,$Fo,f_,ule,kFo,SFo,oN,RFo,BFo,PFo,m_,_le,IFo,qFo,rN,NFo,jFo,DFo,g_,ble,GFo,OFo,tN,VFo,XFo,zFo,h_,vle,QFo,WFo,aN,HFo,UFo,JFo,p_,Fle,YFo,KFo,nN,ZFo,e6o,o6o,u_,Tle,r6o,t6o,sN,a6o,n6o,s6o,__,l6o,Mle,i6o,d6o,Ele,c6o,f6o,b_,SPe,Li,v_,Cle,yA,m6o,wle,g6o,RPe,$o,LA,h6o,xi,p6o,lN,u6o,_6o,iN,b6o,v6o,F6o,xA,T6o,Ale,M6o,E6o,C6o,tt,$A,w6o,yle,A6o,y6o,$i,L6o,Lle,x6o,$6o,dN,k6o,S6o,R6o,F_,B6o,Je,kA,P6o,xle,I6o,q6o,La,N6o,$le,j6o,D6o,kle,G6o,O6o,Sle,V6o,X6o,z6o,z,T_,Rle,Q6o,W6o,cN,H6o,U6o,J6o,M_,Ble,Y6o,K6o,fN,Z6o,eTo,oTo,E_,Ple,rTo,tTo,mN,aTo,nTo,sTo,C_,Ile,lTo,iTo,gN,dTo,cTo,fTo,w_,qle,mTo,gTo,hN,hTo,pTo,uTo,A_,Nle,_To,bTo,pN,vTo,FTo,TTo,y_,jle,MTo,ETo,uN,CTo,wTo,ATo,L_,Dle,yTo,LTo,_N,xTo,$To,kTo,x_,Gle,STo,RTo,bN,BTo,PTo,ITo,$_,Ole,qTo,NTo,vN,jTo,DTo,GTo,k_,Vle,OTo,VTo,FN,XTo,zTo,QTo,S_,Xle,WTo,HTo,TN,UTo,JTo,YTo,R_,zle,KTo,ZTo,MN,e9o,o9o,r9o,B_,Qle,t9o,a9o,EN,n9o,s9o,l9o,P_,Wle,i9o,d9o,CN,c9o,f9o,m9o,I_,Hle,g9o,h9o,wN,p9o,u9o,_9o,q_,Ule,b9o,v9o,AN,F9o,T9o,M9o,N_,Jle,E9o,C9o,yN,w9o,A9o,y9o,j_,Yle,L9o,x9o,LN,$9o,k9o,S9o,D_,Kle,R9o,B9o,xN,P9o,I9o,q9o,G_,Zle,N9o,j9o,$N,D9o,G9o,O9o,O_,eie,V9o,X9o,kN,z9o,Q9o,W9o,V_,oie,H9o,U9o,SN,J9o,Y9o,K9o,X_,rie,Z9o,eMo,RN,oMo,rMo,tMo,z_,tie,aMo,nMo,BN,sMo,lMo,iMo,Q_,aie,dMo,cMo,PN,fMo,mMo,gMo,W_,nie,hMo,pMo,IN,uMo,_Mo,bMo,H_,sie,vMo,FMo,qN,TMo,MMo,EMo,U_,lie,CMo,wMo,NN,AMo,yMo,LMo,J_,iie,xMo,$Mo,jN,kMo,SMo,RMo,Y_,die,BMo,PMo,DN,IMo,qMo,NMo,K_,cie,jMo,DMo,GN,GMo,OMo,VMo,Z_,fie,XMo,zMo,ON,QMo,WMo,HMo,e1,mie,UMo,JMo,VN,YMo,KMo,ZMo,o1,gie,e4o,o4o,XN,r4o,t4o,a4o,r1,n4o,hie,s4o,l4o,pie,i4o,d4o,t1,BPe,ki,a1,uie,SA,c4o,_ie,f4o,PPe,ko,RA,m4o,Si,g4o,zN,h4o,p4o,QN,u4o,_4o,b4o,BA,v4o,bie,F4o,T4o,M4o,at,PA,E4o,vie,C4o,w4o,Ri,A4o,Fie,y4o,L4o,WN,x4o,$4o,k4o,n1,S4o,Ye,IA,R4o,Tie,B4o,P4o,xa,I4o,Mie,q4o,N4o,Eie,j4o,D4o,Cie,G4o,O4o,V4o,Q,s1,wie,X4o,z4o,HN,Q4o,W4o,H4o,l1,Aie,U4o,J4o,UN,Y4o,K4o,Z4o,i1,yie,eEo,oEo,JN,rEo,tEo,aEo,d1,Lie,nEo,sEo,YN,lEo,iEo,dEo,c1,xie,cEo,fEo,KN,mEo,gEo,hEo,f1,$ie,pEo,uEo,ZN,_Eo,bEo,vEo,m1,kie,FEo,TEo,ej,MEo,EEo,CEo,g1,Sie,wEo,AEo,oj,yEo,LEo,xEo,h1,Rie,$Eo,kEo,rj,SEo,REo,BEo,p1,Bie,PEo,IEo,tj,qEo,NEo,jEo,u1,Pie,DEo,GEo,aj,OEo,VEo,XEo,_1,Iie,zEo,QEo,nj,WEo,HEo,UEo,b1,qie,JEo,YEo,sj,KEo,ZEo,e5o,v1,Nie,o5o,r5o,lj,t5o,a5o,n5o,F1,jie,s5o,l5o,ij,i5o,d5o,c5o,T1,Die,f5o,m5o,dj,g5o,h5o,p5o,M1,Gie,u5o,_5o,cj,b5o,v5o,F5o,E1,Oie,T5o,M5o,fj,E5o,C5o,w5o,C1,Vie,A5o,y5o,mj,L5o,x5o,$5o,w1,Xie,k5o,S5o,gj,R5o,B5o,P5o,A1,zie,I5o,q5o,hj,N5o,j5o,D5o,y1,Qie,G5o,O5o,pj,V5o,X5o,z5o,L1,Wie,Q5o,W5o,uj,H5o,U5o,J5o,x1,Hie,Y5o,K5o,_j,Z5o,eCo,oCo,$1,Uie,rCo,tCo,bj,aCo,nCo,sCo,k1,Jie,lCo,iCo,vj,dCo,cCo,fCo,S1,Yie,mCo,gCo,Fj,hCo,pCo,uCo,R1,Kie,_Co,bCo,Tj,vCo,FCo,TCo,B1,Zie,MCo,ECo,Mj,CCo,wCo,ACo,P1,ede,yCo,LCo,Ej,xCo,$Co,kCo,I1,ode,SCo,RCo,rde,BCo,PCo,ICo,q1,tde,qCo,NCo,Cj,jCo,DCo,GCo,N1,ade,OCo,VCo,wj,XCo,zCo,QCo,j1,nde,WCo,HCo,Aj,UCo,JCo,YCo,D1,sde,KCo,ZCo,yj,e3o,o3o,r3o,G1,t3o,lde,a3o,n3o,ide,s3o,l3o,O1,IPe,Bi,V1,dde,qA,i3o,cde,d3o,qPe,So,NA,c3o,Pi,f3o,Lj,m3o,g3o,xj,h3o,p3o,u3o,jA,_3o,fde,b3o,v3o,F3o,nt,DA,T3o,mde,M3o,E3o,Ii,C3o,gde,w3o,A3o,$j,y3o,L3o,x3o,X1,$3o,Ke,GA,k3o,hde,S3o,R3o,$a,B3o,pde,P3o,I3o,ude,q3o,N3o,_de,j3o,D3o,G3o,he,z1,bde,O3o,V3o,kj,X3o,z3o,Q3o,Q1,vde,W3o,H3o,Sj,U3o,J3o,Y3o,W1,Fde,K3o,Z3o,Rj,ewo,owo,rwo,H1,Tde,two,awo,Bj,nwo,swo,lwo,U1,Mde,iwo,dwo,Pj,cwo,fwo,mwo,J1,Ede,gwo,hwo,Ij,pwo,uwo,_wo,Y1,Cde,bwo,vwo,qj,Fwo,Two,Mwo,K1,wde,Ewo,Cwo,Nj,wwo,Awo,ywo,Z1,Ade,Lwo,xwo,jj,$wo,kwo,Swo,e8,yde,Rwo,Bwo,Dj,Pwo,Iwo,qwo,o8,Lde,Nwo,jwo,Gj,Dwo,Gwo,Owo,r8,xde,Vwo,Xwo,Oj,zwo,Qwo,Wwo,t8,$de,Hwo,Uwo,Vj,Jwo,Ywo,Kwo,a8,kde,Zwo,eAo,Xj,oAo,rAo,tAo,n8,Sde,aAo,nAo,zj,sAo,lAo,iAo,s8,Rde,dAo,cAo,Qj,fAo,mAo,gAo,l8,Bde,hAo,pAo,Wj,uAo,_Ao,bAo,i8,vAo,Pde,FAo,TAo,Ide,MAo,EAo,d8,NPe,qi,c8,qde,OA,CAo,Nde,wAo,jPe,Ro,VA,AAo,Ni,yAo,Hj,LAo,xAo,Uj,$Ao,kAo,SAo,XA,RAo,jde,BAo,PAo,IAo,st,zA,qAo,Dde,NAo,jAo,ji,DAo,Gde,GAo,OAo,Jj,VAo,XAo,zAo,f8,QAo,Ze,QA,WAo,Ode,HAo,UAo,ka,JAo,Vde,YAo,KAo,Xde,ZAo,e0o,zde,o0o,r0o,t0o,q,m8,Qde,a0o,n0o,Yj,s0o,l0o,i0o,g8,Wde,d0o,c0o,Kj,f0o,m0o,g0o,h8,Hde,h0o,p0o,Zj,u0o,_0o,b0o,p8,Ude,v0o,F0o,eD,T0o,M0o,E0o,u8,Jde,C0o,w0o,oD,A0o,y0o,L0o,_8,Yde,x0o,$0o,rD,k0o,S0o,R0o,b8,Kde,B0o,P0o,tD,I0o,q0o,N0o,v8,Zde,j0o,D0o,aD,G0o,O0o,V0o,F8,ece,X0o,z0o,nD,Q0o,W0o,H0o,T8,oce,U0o,J0o,sD,Y0o,K0o,Z0o,M8,rce,eyo,oyo,lD,ryo,tyo,ayo,E8,tce,nyo,syo,iD,lyo,iyo,dyo,C8,ace,cyo,fyo,dD,myo,gyo,hyo,w8,nce,pyo,uyo,cD,_yo,byo,vyo,A8,sce,Fyo,Tyo,fD,Myo,Eyo,Cyo,y8,lce,wyo,Ayo,mD,yyo,Lyo,xyo,L8,ice,$yo,kyo,gD,Syo,Ryo,Byo,x8,dce,Pyo,Iyo,hD,qyo,Nyo,jyo,$8,cce,Dyo,Gyo,pD,Oyo,Vyo,Xyo,k8,fce,zyo,Qyo,uD,Wyo,Hyo,Uyo,S8,mce,Jyo,Yyo,_D,Kyo,Zyo,eLo,R8,gce,oLo,rLo,bD,tLo,aLo,nLo,B8,hce,sLo,lLo,vD,iLo,dLo,cLo,P8,pce,fLo,mLo,FD,gLo,hLo,pLo,I8,uce,uLo,_Lo,TD,bLo,vLo,FLo,q8,_ce,TLo,MLo,MD,ELo,CLo,wLo,N8,bce,ALo,yLo,ED,LLo,xLo,$Lo,j8,vce,kLo,SLo,CD,RLo,BLo,PLo,D8,Fce,ILo,qLo,wD,NLo,jLo,DLo,G8,Tce,GLo,OLo,AD,VLo,XLo,zLo,O8,Mce,QLo,WLo,yD,HLo,ULo,JLo,V8,Ece,YLo,KLo,LD,ZLo,exo,oxo,X8,Cce,rxo,txo,xD,axo,nxo,sxo,z8,wce,lxo,ixo,$D,dxo,cxo,fxo,Q8,Ace,mxo,gxo,kD,hxo,pxo,uxo,W8,yce,_xo,bxo,SD,vxo,Fxo,Txo,H8,Lce,Mxo,Exo,RD,Cxo,wxo,Axo,U8,xce,yxo,Lxo,BD,xxo,$xo,kxo,J8,$ce,Sxo,Rxo,PD,Bxo,Pxo,Ixo,Y8,kce,qxo,Nxo,ID,jxo,Dxo,Gxo,K8,Sce,Oxo,Vxo,qD,Xxo,zxo,Qxo,Z8,Rce,Wxo,Hxo,ND,Uxo,Jxo,Yxo,eb,Bce,Kxo,Zxo,jD,e7o,o7o,r7o,ob,Pce,t7o,a7o,DD,n7o,s7o,l7o,rb,Ice,i7o,d7o,GD,c7o,f7o,m7o,tb,qce,g7o,h7o,OD,p7o,u7o,_7o,ab,Nce,b7o,v7o,VD,F7o,T7o,M7o,nb,E7o,jce,C7o,w7o,Dce,A7o,y7o,sb,DPe,Di,lb,Gce,WA,L7o,Oce,x7o,GPe,Bo,HA,$7o,Gi,k7o,XD,S7o,R7o,zD,B7o,P7o,I7o,UA,q7o,Vce,N7o,j7o,D7o,lt,JA,G7o,Xce,O7o,V7o,Oi,X7o,zce,z7o,Q7o,QD,W7o,H7o,U7o,ib,J7o,eo,YA,Y7o,Qce,K7o,Z7o,Sa,e$o,Wce,o$o,r$o,Hce,t$o,a$o,Uce,n$o,s$o,l$o,Y,db,Jce,i$o,d$o,WD,c$o,f$o,m$o,cb,Yce,g$o,h$o,HD,p$o,u$o,_$o,fb,Kce,b$o,v$o,UD,F$o,T$o,M$o,mb,Zce,E$o,C$o,JD,w$o,A$o,y$o,gb,efe,L$o,x$o,YD,$$o,k$o,S$o,hb,ofe,R$o,B$o,KD,P$o,I$o,q$o,pb,rfe,N$o,j$o,ZD,D$o,G$o,O$o,ub,tfe,V$o,X$o,eG,z$o,Q$o,W$o,_b,afe,H$o,U$o,oG,J$o,Y$o,K$o,bb,nfe,Z$o,eko,rG,oko,rko,tko,vb,sfe,ako,nko,tG,sko,lko,iko,Fb,lfe,dko,cko,aG,fko,mko,gko,Tb,ife,hko,pko,nG,uko,_ko,bko,Mb,dfe,vko,Fko,sG,Tko,Mko,Eko,Eb,cfe,Cko,wko,lG,Ako,yko,Lko,Cb,ffe,xko,$ko,iG,kko,Sko,Rko,wb,mfe,Bko,Pko,dG,Iko,qko,Nko,Ab,gfe,jko,Dko,cG,Gko,Oko,Vko,yb,hfe,Xko,zko,fG,Qko,Wko,Hko,Lb,pfe,Uko,Jko,mG,Yko,Kko,Zko,xb,ufe,eSo,oSo,gG,rSo,tSo,aSo,$b,_fe,nSo,sSo,hG,lSo,iSo,dSo,kb,bfe,cSo,fSo,pG,mSo,gSo,hSo,Sb,vfe,pSo,uSo,uG,_So,bSo,vSo,Rb,Ffe,FSo,TSo,_G,MSo,ESo,CSo,Bb,Tfe,wSo,ASo,bG,ySo,LSo,xSo,Pb,Mfe,$So,kSo,vG,SSo,RSo,BSo,Ib,Efe,PSo,ISo,FG,qSo,NSo,jSo,qb,Cfe,DSo,GSo,TG,OSo,VSo,XSo,Nb,zSo,wfe,QSo,WSo,Afe,HSo,USo,jb,OPe,Vi,Db,yfe,KA,JSo,Lfe,YSo,VPe,Po,ZA,KSo,Xi,ZSo,MG,eRo,oRo,EG,rRo,tRo,aRo,e0,nRo,xfe,sRo,lRo,iRo,it,o0,dRo,$fe,cRo,fRo,zi,mRo,kfe,gRo,hRo,CG,pRo,uRo,_Ro,Gb,bRo,oo,r0,vRo,Sfe,FRo,TRo,Ra,MRo,Rfe,ERo,CRo,Bfe,wRo,ARo,Pfe,yRo,LRo,xRo,Yr,Ob,Ife,$Ro,kRo,wG,SRo,RRo,BRo,Vb,qfe,PRo,IRo,AG,qRo,NRo,jRo,Xb,Nfe,DRo,GRo,yG,ORo,VRo,XRo,zb,jfe,zRo,QRo,LG,WRo,HRo,URo,Qb,Dfe,JRo,YRo,xG,KRo,ZRo,eBo,Wb,oBo,Gfe,rBo,tBo,Ofe,aBo,nBo,Hb,XPe,Qi,Ub,Vfe,t0,sBo,Xfe,lBo,zPe,Io,a0,iBo,Wi,dBo,$G,cBo,fBo,kG,mBo,gBo,hBo,n0,pBo,zfe,uBo,_Bo,bBo,dt,s0,vBo,Qfe,FBo,TBo,Hi,MBo,Wfe,EBo,CBo,SG,wBo,ABo,yBo,Jb,LBo,ro,l0,xBo,Hfe,$Bo,kBo,Ba,SBo,Ufe,RBo,BBo,Jfe,PBo,IBo,Yfe,qBo,NBo,jBo,U,Yb,Kfe,DBo,GBo,RG,OBo,VBo,XBo,Kb,Zfe,zBo,QBo,BG,WBo,HBo,UBo,Zb,eme,JBo,YBo,PG,KBo,ZBo,ePo,e2,ome,oPo,rPo,IG,tPo,aPo,nPo,o2,rme,sPo,lPo,qG,iPo,dPo,cPo,r2,tme,fPo,mPo,NG,gPo,hPo,pPo,t2,ame,uPo,_Po,jG,bPo,vPo,FPo,a2,nme,TPo,MPo,DG,EPo,CPo,wPo,n2,sme,APo,yPo,GG,LPo,xPo,$Po,s2,lme,kPo,SPo,OG,RPo,BPo,PPo,l2,ime,IPo,qPo,VG,NPo,jPo,DPo,i2,dme,GPo,OPo,XG,VPo,XPo,zPo,d2,cme,QPo,WPo,zG,HPo,UPo,JPo,c2,fme,YPo,KPo,QG,ZPo,eIo,oIo,f2,mme,rIo,tIo,WG,aIo,nIo,sIo,m2,gme,lIo,iIo,HG,dIo,cIo,fIo,g2,hme,mIo,gIo,UG,hIo,pIo,uIo,h2,pme,_Io,bIo,JG,vIo,FIo,TIo,p2,ume,MIo,EIo,YG,CIo,wIo,AIo,u2,_me,yIo,LIo,KG,xIo,$Io,kIo,_2,bme,SIo,RIo,ZG,BIo,PIo,IIo,b2,vme,qIo,NIo,eO,jIo,DIo,GIo,v2,Fme,OIo,VIo,oO,XIo,zIo,QIo,F2,Tme,WIo,HIo,rO,UIo,JIo,YIo,T2,Mme,KIo,ZIo,tO,eqo,oqo,rqo,M2,Eme,tqo,aqo,aO,nqo,sqo,lqo,E2,Cme,iqo,dqo,nO,cqo,fqo,mqo,C2,wme,gqo,hqo,sO,pqo,uqo,_qo,w2,Ame,bqo,vqo,lO,Fqo,Tqo,Mqo,A2,yme,Eqo,Cqo,iO,wqo,Aqo,yqo,y2,Lme,Lqo,xqo,dO,$qo,kqo,Sqo,L2,xme,Rqo,Bqo,cO,Pqo,Iqo,qqo,x2,$me,Nqo,jqo,fO,Dqo,Gqo,Oqo,$2,Vqo,kme,Xqo,zqo,Sme,Qqo,Wqo,k2,QPe,Ui,S2,Rme,i0,Hqo,Bme,Uqo,WPe,qo,d0,Jqo,Ji,Yqo,mO,Kqo,Zqo,gO,eNo,oNo,rNo,c0,tNo,Pme,aNo,nNo,sNo,ct,f0,lNo,Ime,iNo,dNo,Yi,cNo,qme,fNo,mNo,hO,gNo,hNo,pNo,R2,uNo,to,m0,_No,Nme,bNo,vNo,Pa,FNo,jme,TNo,MNo,Dme,ENo,CNo,Gme,wNo,ANo,yNo,O,B2,Ome,LNo,xNo,pO,$No,kNo,SNo,P2,Vme,RNo,BNo,uO,PNo,INo,qNo,I2,Xme,NNo,jNo,_O,DNo,GNo,ONo,q2,zme,VNo,XNo,bO,zNo,QNo,WNo,N2,Qme,HNo,UNo,vO,JNo,YNo,KNo,j2,Wme,ZNo,ejo,FO,ojo,rjo,tjo,D2,Hme,ajo,njo,TO,sjo,ljo,ijo,G2,Ume,djo,cjo,MO,fjo,mjo,gjo,O2,Jme,hjo,pjo,EO,ujo,_jo,bjo,V2,Yme,vjo,Fjo,CO,Tjo,Mjo,Ejo,X2,Kme,Cjo,wjo,wO,Ajo,yjo,Ljo,z2,Zme,xjo,$jo,AO,kjo,Sjo,Rjo,Q2,ege,Bjo,Pjo,yO,Ijo,qjo,Njo,W2,oge,jjo,Djo,LO,Gjo,Ojo,Vjo,H2,rge,Xjo,zjo,xO,Qjo,Wjo,Hjo,U2,tge,Ujo,Jjo,$O,Yjo,Kjo,Zjo,J2,age,eDo,oDo,kO,rDo,tDo,aDo,Y2,nge,nDo,sDo,SO,lDo,iDo,dDo,K2,sge,cDo,fDo,RO,mDo,gDo,hDo,Z2,lge,pDo,uDo,BO,_Do,bDo,vDo,ev,ige,FDo,TDo,PO,MDo,EDo,CDo,ov,dge,wDo,ADo,IO,yDo,LDo,xDo,rv,cge,$Do,kDo,qO,SDo,RDo,BDo,tv,fge,PDo,IDo,NO,qDo,NDo,jDo,av,mge,DDo,GDo,jO,ODo,VDo,XDo,nv,gge,zDo,QDo,DO,WDo,HDo,UDo,sv,hge,JDo,YDo,GO,KDo,ZDo,eGo,lv,pge,oGo,rGo,OO,tGo,aGo,nGo,iv,uge,sGo,lGo,VO,iGo,dGo,cGo,dv,_ge,fGo,mGo,XO,gGo,hGo,pGo,cv,bge,uGo,_Go,zO,bGo,vGo,FGo,fv,vge,TGo,MGo,QO,EGo,CGo,wGo,mv,Fge,AGo,yGo,WO,LGo,xGo,$Go,gv,Tge,kGo,SGo,HO,RGo,BGo,PGo,hv,Mge,IGo,qGo,UO,NGo,jGo,DGo,pv,Ege,GGo,OGo,JO,VGo,XGo,zGo,uv,Cge,QGo,WGo,YO,HGo,UGo,JGo,_v,wge,YGo,KGo,KO,ZGo,eOo,oOo,bv,Age,rOo,tOo,ZO,aOo,nOo,sOo,vv,lOo,yge,iOo,dOo,Lge,cOo,fOo,Fv,HPe,Ki,Tv,xge,g0,mOo,$ge,gOo,UPe,No,h0,hOo,Zi,pOo,eV,uOo,_Oo,oV,bOo,vOo,FOo,p0,TOo,kge,MOo,EOo,COo,ft,u0,wOo,Sge,AOo,yOo,ed,LOo,Rge,xOo,$Oo,rV,kOo,SOo,ROo,Mv,BOo,ao,_0,POo,Bge,IOo,qOo,Ia,NOo,Pge,jOo,DOo,Ige,GOo,OOo,qge,VOo,XOo,zOo,Nge,Ev,jge,QOo,WOo,tV,HOo,UOo,JOo,Cv,YOo,Dge,KOo,ZOo,Gge,eVo,oVo,wv,JPe,od,Av,Oge,b0,rVo,Vge,tVo,YPe,jo,v0,aVo,rd,nVo,aV,sVo,lVo,nV,iVo,dVo,cVo,F0,fVo,Xge,mVo,gVo,hVo,mt,T0,pVo,zge,uVo,_Vo,td,bVo,Qge,vVo,FVo,sV,TVo,MVo,EVo,yv,CVo,no,M0,wVo,Wge,AVo,yVo,qa,LVo,Hge,xVo,$Vo,Uge,kVo,SVo,Jge,RVo,BVo,PVo,ve,Lv,Yge,IVo,qVo,lV,NVo,jVo,DVo,xv,Kge,GVo,OVo,iV,VVo,XVo,zVo,$v,Zge,QVo,WVo,dV,HVo,UVo,JVo,Bs,ehe,YVo,KVo,cV,ZVo,eXo,fV,oXo,rXo,tXo,kv,ohe,aXo,nXo,mV,sXo,lXo,iXo,gt,rhe,dXo,cXo,gV,fXo,mXo,hV,gXo,hXo,pV,pXo,uXo,_Xo,Sv,the,bXo,vXo,uV,FXo,TXo,MXo,Rv,ahe,EXo,CXo,_V,wXo,AXo,yXo,Bv,nhe,LXo,xXo,bV,$Xo,kXo,SXo,Pv,she,RXo,BXo,vV,PXo,IXo,qXo,Iv,lhe,NXo,jXo,FV,DXo,GXo,OXo,qv,ihe,VXo,XXo,TV,zXo,QXo,WXo,Nv,dhe,HXo,UXo,MV,JXo,YXo,KXo,jv,ZXo,che,ezo,ozo,fhe,rzo,tzo,Dv,KPe,ad,Gv,mhe,E0,azo,ghe,nzo,ZPe,Do,C0,szo,nd,lzo,EV,izo,dzo,CV,czo,fzo,mzo,w0,gzo,hhe,hzo,pzo,uzo,ht,A0,_zo,phe,bzo,vzo,sd,Fzo,uhe,Tzo,Mzo,wV,Ezo,Czo,wzo,Ov,Azo,so,y0,yzo,_he,Lzo,xzo,Na,$zo,bhe,kzo,Szo,vhe,Rzo,Bzo,Fhe,Pzo,Izo,qzo,The,Vv,Mhe,Nzo,jzo,AV,Dzo,Gzo,Ozo,Xv,Vzo,Ehe,Xzo,zzo,Che,Qzo,Wzo,zv,eIe,ld,Qv,whe,L0,Hzo,Ahe,Uzo,oIe,Go,x0,Jzo,id,Yzo,yV,Kzo,Zzo,LV,eQo,oQo,rQo,$0,tQo,yhe,aQo,nQo,sQo,pt,k0,lQo,Lhe,iQo,dQo,dd,cQo,xhe,fQo,mQo,xV,gQo,hQo,pQo,Wv,uQo,lo,S0,_Qo,$he,bQo,vQo,ja,FQo,khe,TQo,MQo,She,EQo,CQo,Rhe,wQo,AQo,yQo,Ne,Hv,Bhe,LQo,xQo,$V,$Qo,kQo,SQo,Uv,Phe,RQo,BQo,kV,PQo,IQo,qQo,Jv,Ihe,NQo,jQo,SV,DQo,GQo,OQo,Yv,qhe,VQo,XQo,RV,zQo,QQo,WQo,Kv,Nhe,HQo,UQo,BV,JQo,YQo,KQo,Zv,jhe,ZQo,eWo,PV,oWo,rWo,tWo,eF,Dhe,aWo,nWo,IV,sWo,lWo,iWo,oF,Ghe,dWo,cWo,qV,fWo,mWo,gWo,rF,hWo,Ohe,pWo,uWo,Vhe,_Wo,bWo,tF,rIe,cd,aF,Xhe,R0,vWo,zhe,FWo,tIe,Oo,B0,TWo,fd,MWo,NV,EWo,CWo,jV,wWo,AWo,yWo,P0,LWo,Qhe,xWo,$Wo,kWo,ut,I0,SWo,Whe,RWo,BWo,md,PWo,Hhe,IWo,qWo,DV,NWo,jWo,DWo,nF,GWo,io,q0,OWo,Uhe,VWo,XWo,Da,zWo,Jhe,QWo,WWo,Yhe,HWo,UWo,Khe,JWo,YWo,KWo,Ga,sF,Zhe,ZWo,eHo,GV,oHo,rHo,tHo,lF,epe,aHo,nHo,OV,sHo,lHo,iHo,iF,ope,dHo,cHo,VV,fHo,mHo,gHo,dF,rpe,hHo,pHo,XV,uHo,_Ho,bHo,cF,vHo,tpe,FHo,THo,ape,MHo,EHo,fF,aIe,gd,mF,npe,N0,CHo,spe,wHo,nIe,Vo,j0,AHo,hd,yHo,zV,LHo,xHo,QV,$Ho,kHo,SHo,D0,RHo,lpe,BHo,PHo,IHo,_t,G0,qHo,ipe,NHo,jHo,pd,DHo,dpe,GHo,OHo,WV,VHo,XHo,zHo,gF,QHo,co,O0,WHo,cpe,HHo,UHo,Oa,JHo,fpe,YHo,KHo,mpe,ZHo,eUo,gpe,oUo,rUo,tUo,je,hF,hpe,aUo,nUo,HV,sUo,lUo,iUo,pF,ppe,dUo,cUo,UV,fUo,mUo,gUo,uF,upe,hUo,pUo,JV,uUo,_Uo,bUo,_F,_pe,vUo,FUo,YV,TUo,MUo,EUo,bF,bpe,CUo,wUo,KV,AUo,yUo,LUo,vF,vpe,xUo,$Uo,ZV,kUo,SUo,RUo,FF,Fpe,BUo,PUo,eX,IUo,qUo,NUo,TF,Tpe,jUo,DUo,oX,GUo,OUo,VUo,MF,XUo,Mpe,zUo,QUo,Epe,WUo,HUo,EF,sIe,ud,CF,Cpe,V0,UUo,wpe,JUo,lIe,Xo,X0,YUo,_d,KUo,rX,ZUo,eJo,tX,oJo,rJo,tJo,z0,aJo,Ape,nJo,sJo,lJo,bt,Q0,iJo,ype,dJo,cJo,bd,fJo,Lpe,mJo,gJo,aX,hJo,pJo,uJo,wF,_Jo,fo,W0,bJo,xpe,vJo,FJo,Va,TJo,$pe,MJo,EJo,kpe,CJo,wJo,Spe,AJo,yJo,LJo,H0,AF,Rpe,xJo,$Jo,nX,kJo,SJo,RJo,yF,Bpe,BJo,PJo,sX,IJo,qJo,NJo,LF,jJo,Ppe,DJo,GJo,Ipe,OJo,VJo,xF,iIe,vd,$F,qpe,U0,XJo,Npe,zJo,dIe,zo,J0,QJo,Fd,WJo,lX,HJo,UJo,iX,JJo,YJo,KJo,Y0,ZJo,jpe,eYo,oYo,rYo,vt,K0,tYo,Dpe,aYo,nYo,Td,sYo,Gpe,lYo,iYo,dX,dYo,cYo,fYo,kF,mYo,mo,Z0,gYo,Ope,hYo,pYo,Xa,uYo,Vpe,_Yo,bYo,Xpe,vYo,FYo,zpe,TYo,MYo,EYo,za,SF,Qpe,CYo,wYo,cX,AYo,yYo,LYo,RF,Wpe,xYo,$Yo,fX,kYo,SYo,RYo,BF,Hpe,BYo,PYo,mX,IYo,qYo,NYo,PF,Upe,jYo,DYo,gX,GYo,OYo,VYo,IF,XYo,Jpe,zYo,QYo,Ype,WYo,HYo,qF,cIe,Md,NF,Kpe,ey,UYo,Zpe,JYo,fIe,Qo,oy,YYo,Ed,KYo,hX,ZYo,eKo,pX,oKo,rKo,tKo,ry,aKo,eue,nKo,sKo,lKo,Ft,ty,iKo,oue,dKo,cKo,Cd,fKo,rue,mKo,gKo,uX,hKo,pKo,uKo,jF,_Ko,go,ay,bKo,tue,vKo,FKo,Qa,TKo,aue,MKo,EKo,nue,CKo,wKo,sue,AKo,yKo,LKo,wd,DF,lue,xKo,$Ko,_X,kKo,SKo,RKo,GF,iue,BKo,PKo,bX,IKo,qKo,NKo,OF,due,jKo,DKo,vX,GKo,OKo,VKo,VF,XKo,cue,zKo,QKo,fue,WKo,HKo,XF,mIe,Ad,zF,mue,ny,UKo,gue,JKo,gIe,Wo,sy,YKo,yd,KKo,FX,ZKo,eZo,TX,oZo,rZo,tZo,ly,aZo,hue,nZo,sZo,lZo,Tt,iy,iZo,pue,dZo,cZo,Ld,fZo,uue,mZo,gZo,MX,hZo,pZo,uZo,QF,_Zo,ho,dy,bZo,_ue,vZo,FZo,Wa,TZo,bue,MZo,EZo,vue,CZo,wZo,Fue,AZo,yZo,LZo,cy,WF,Tue,xZo,$Zo,EX,kZo,SZo,RZo,HF,Mue,BZo,PZo,CX,IZo,qZo,NZo,UF,jZo,Eue,DZo,GZo,Cue,OZo,VZo,JF,hIe,xd,YF,wue,fy,XZo,Aue,zZo,pIe,Ho,my,QZo,$d,WZo,wX,HZo,UZo,AX,JZo,YZo,KZo,gy,ZZo,yue,eer,oer,rer,Mt,hy,ter,Lue,aer,ner,kd,ser,xue,ler,ier,yX,der,cer,fer,KF,mer,po,py,ger,$ue,her,per,Ha,uer,kue,_er,ber,Sue,ver,Fer,Rue,Ter,Mer,Eer,Bue,ZF,Pue,Cer,wer,LX,Aer,yer,Ler,e6,xer,Iue,$er,ker,que,Ser,Rer,o6,uIe,Sd,r6,Nue,uy,Ber,jue,Per,_Ie,Uo,_y,Ier,Rd,qer,xX,Ner,jer,$X,Der,Ger,Oer,by,Ver,Due,Xer,zer,Qer,Et,vy,Wer,Gue,Her,Uer,Bd,Jer,Oue,Yer,Ker,kX,Zer,eor,oor,t6,ror,uo,Fy,tor,Vue,aor,nor,Ua,sor,Xue,lor,ior,zue,dor,cor,Que,mor,gor,hor,Ja,a6,Wue,por,uor,SX,_or,bor,vor,n6,Hue,For,Tor,RX,Mor,Eor,Cor,s6,Uue,wor,Aor,BX,yor,Lor,xor,l6,Jue,$or,kor,PX,Sor,Ror,Bor,i6,Por,Yue,Ior,qor,Kue,Nor,jor,d6,bIe,Pd,c6,Zue,Ty,Dor,e_e,Gor,vIe,Jo,My,Oor,Id,Vor,IX,Xor,zor,qX,Qor,Wor,Hor,Ey,Uor,o_e,Jor,Yor,Kor,Ct,Cy,Zor,r_e,err,orr,qd,rrr,t_e,trr,arr,NX,nrr,srr,lrr,f6,irr,_o,wy,drr,a_e,crr,frr,Ya,mrr,n_e,grr,hrr,s_e,prr,urr,l_e,_rr,brr,vrr,i_e,m6,d_e,Frr,Trr,jX,Mrr,Err,Crr,g6,wrr,c_e,Arr,yrr,f_e,Lrr,xrr,h6,FIe,Nd,p6,m_e,Ay,$rr,g_e,krr,TIe,Yo,yy,Srr,jd,Rrr,DX,Brr,Prr,GX,Irr,qrr,Nrr,Ly,jrr,h_e,Drr,Grr,Orr,wt,xy,Vrr,p_e,Xrr,zrr,Dd,Qrr,u_e,Wrr,Hrr,OX,Urr,Jrr,Yrr,u6,Krr,wr,$y,Zrr,__e,etr,otr,Ka,rtr,b_e,ttr,atr,v_e,ntr,str,F_e,ltr,itr,dtr,N,_6,T_e,ctr,ftr,VX,mtr,gtr,htr,b6,M_e,ptr,utr,XX,_tr,btr,vtr,v6,E_e,Ftr,Ttr,zX,Mtr,Etr,Ctr,F6,C_e,wtr,Atr,QX,ytr,Ltr,xtr,T6,w_e,$tr,ktr,WX,Str,Rtr,Btr,M6,A_e,Ptr,Itr,HX,qtr,Ntr,jtr,E6,y_e,Dtr,Gtr,UX,Otr,Vtr,Xtr,C6,L_e,ztr,Qtr,JX,Wtr,Htr,Utr,w6,x_e,Jtr,Ytr,YX,Ktr,Ztr,ear,A6,$_e,oar,rar,KX,tar,aar,nar,y6,k_e,sar,lar,ZX,iar,dar,car,L6,S_e,far,mar,ez,gar,har,par,x6,R_e,uar,_ar,oz,bar,Far,Tar,$6,B_e,Mar,Ear,rz,Car,war,Aar,k6,P_e,yar,Lar,tz,xar,$ar,kar,S6,I_e,Sar,Rar,az,Bar,Par,Iar,R6,q_e,qar,Nar,nz,jar,Dar,Gar,Ps,N_e,Oar,Var,sz,Xar,zar,lz,Qar,War,Har,B6,j_e,Uar,Jar,iz,Yar,Kar,Zar,P6,D_e,enr,onr,dz,rnr,tnr,anr,I6,G_e,nnr,snr,cz,lnr,inr,dnr,q6,O_e,cnr,fnr,fz,mnr,gnr,hnr,N6,V_e,pnr,unr,mz,_nr,bnr,vnr,j6,X_e,Fnr,Tnr,gz,Mnr,Enr,Cnr,D6,z_e,wnr,Anr,hz,ynr,Lnr,xnr,G6,Q_e,$nr,knr,pz,Snr,Rnr,Bnr,O6,W_e,Pnr,Inr,uz,qnr,Nnr,jnr,V6,H_e,Dnr,Gnr,_z,Onr,Vnr,Xnr,X6,U_e,znr,Qnr,bz,Wnr,Hnr,Unr,z6,J_e,Jnr,Ynr,vz,Knr,Znr,esr,Q6,Y_e,osr,rsr,Fz,tsr,asr,nsr,W6,K_e,ssr,lsr,Tz,isr,dsr,csr,H6,Z_e,fsr,msr,Mz,gsr,hsr,psr,U6,e1e,usr,_sr,Ez,bsr,vsr,Fsr,J6,o1e,Tsr,Msr,Cz,Esr,Csr,wsr,Y6,r1e,Asr,ysr,wz,Lsr,xsr,$sr,K6,t1e,ksr,Ssr,Az,Rsr,Bsr,Psr,Z6,a1e,Isr,qsr,yz,Nsr,jsr,Dsr,eT,n1e,Gsr,Osr,Lz,Vsr,Xsr,zsr,oT,s1e,Qsr,Wsr,xz,Hsr,Usr,Jsr,rT,l1e,Ysr,Ksr,$z,Zsr,elr,olr,tT,i1e,rlr,tlr,kz,alr,nlr,slr,aT,d1e,llr,ilr,Sz,dlr,clr,flr,nT,c1e,mlr,glr,Rz,hlr,plr,ulr,sT,f1e,_lr,blr,Bz,vlr,Flr,Tlr,lT,m1e,Mlr,Elr,Pz,Clr,wlr,Alr,iT,MIe,Gd,dT,g1e,ky,ylr,h1e,Llr,EIe,Ko,Sy,xlr,Od,$lr,Iz,klr,Slr,qz,Rlr,Blr,Plr,Ry,Ilr,p1e,qlr,Nlr,jlr,At,By,Dlr,u1e,Glr,Olr,Vd,Vlr,_1e,Xlr,zlr,Nz,Qlr,Wlr,Hlr,cT,Ulr,Ar,Py,Jlr,b1e,Ylr,Klr,Za,Zlr,v1e,eir,oir,F1e,rir,tir,T1e,air,nir,sir,ne,fT,M1e,lir,iir,jz,dir,cir,fir,mT,E1e,mir,gir,Dz,hir,pir,uir,gT,C1e,_ir,bir,Gz,vir,Fir,Tir,hT,w1e,Mir,Eir,Oz,Cir,wir,Air,pT,A1e,yir,Lir,Vz,xir,$ir,kir,uT,y1e,Sir,Rir,Xz,Bir,Pir,Iir,_T,L1e,qir,Nir,zz,jir,Dir,Gir,bT,x1e,Oir,Vir,Qz,Xir,zir,Qir,vT,$1e,Wir,Hir,Wz,Uir,Jir,Yir,FT,k1e,Kir,Zir,Hz,edr,odr,rdr,TT,S1e,tdr,adr,Uz,ndr,sdr,ldr,MT,R1e,idr,ddr,Jz,cdr,fdr,mdr,ET,B1e,gdr,hdr,Yz,pdr,udr,_dr,CT,P1e,bdr,vdr,Kz,Fdr,Tdr,Mdr,wT,I1e,Edr,Cdr,Zz,wdr,Adr,ydr,AT,q1e,Ldr,xdr,eQ,$dr,kdr,Sdr,yT,N1e,Rdr,Bdr,oQ,Pdr,Idr,qdr,LT,j1e,Ndr,jdr,rQ,Ddr,Gdr,Odr,xT,D1e,Vdr,Xdr,tQ,zdr,Qdr,Wdr,$T,G1e,Hdr,Udr,aQ,Jdr,Ydr,Kdr,kT,O1e,Zdr,ecr,nQ,ocr,rcr,tcr,ST,V1e,acr,ncr,sQ,scr,lcr,icr,RT,X1e,dcr,ccr,lQ,fcr,mcr,gcr,BT,CIe,Xd,PT,z1e,Iy,hcr,Q1e,pcr,wIe,Zo,qy,ucr,zd,_cr,iQ,bcr,vcr,dQ,Fcr,Tcr,Mcr,Ny,Ecr,W1e,Ccr,wcr,Acr,yt,jy,ycr,H1e,Lcr,xcr,Qd,$cr,U1e,kcr,Scr,cQ,Rcr,Bcr,Pcr,IT,Icr,yr,Dy,qcr,J1e,Ncr,jcr,en,Dcr,Y1e,Gcr,Ocr,K1e,Vcr,Xcr,Z1e,zcr,Qcr,Wcr,Te,qT,e8e,Hcr,Ucr,fQ,Jcr,Ycr,Kcr,NT,o8e,Zcr,efr,mQ,ofr,rfr,tfr,jT,r8e,afr,nfr,gQ,sfr,lfr,ifr,DT,t8e,dfr,cfr,hQ,ffr,mfr,gfr,GT,a8e,hfr,pfr,pQ,ufr,_fr,bfr,OT,n8e,vfr,Ffr,uQ,Tfr,Mfr,Efr,VT,s8e,Cfr,wfr,_Q,Afr,yfr,Lfr,XT,l8e,xfr,$fr,bQ,kfr,Sfr,Rfr,zT,i8e,Bfr,Pfr,vQ,Ifr,qfr,Nfr,QT,d8e,jfr,Dfr,FQ,Gfr,Ofr,Vfr,WT,c8e,Xfr,zfr,TQ,Qfr,Wfr,Hfr,HT,f8e,Ufr,Jfr,MQ,Yfr,Kfr,Zfr,UT,AIe,Wd,JT,m8e,Gy,emr,g8e,omr,yIe,er,Oy,rmr,Hd,tmr,EQ,amr,nmr,CQ,smr,lmr,imr,Vy,dmr,h8e,cmr,fmr,mmr,Lt,Xy,gmr,p8e,hmr,pmr,Ud,umr,u8e,_mr,bmr,wQ,vmr,Fmr,Tmr,YT,Mmr,Lr,zy,Emr,_8e,Cmr,wmr,on,Amr,b8e,ymr,Lmr,v8e,xmr,$mr,F8e,kmr,Smr,Rmr,rn,KT,T8e,Bmr,Pmr,AQ,Imr,qmr,Nmr,ZT,M8e,jmr,Dmr,yQ,Gmr,Omr,Vmr,e9,E8e,Xmr,zmr,LQ,Qmr,Wmr,Hmr,o9,C8e,Umr,Jmr,xQ,Ymr,Kmr,Zmr,r9,LIe,Jd,t9,w8e,Qy,egr,A8e,ogr,xIe,or,Wy,rgr,Yd,tgr,$Q,agr,ngr,kQ,sgr,lgr,igr,Hy,dgr,y8e,cgr,fgr,mgr,xt,Uy,ggr,L8e,hgr,pgr,Kd,ugr,x8e,_gr,bgr,SQ,vgr,Fgr,Tgr,a9,Mgr,xr,Jy,Egr,$8e,Cgr,wgr,tn,Agr,k8e,ygr,Lgr,S8e,xgr,$gr,R8e,kgr,Sgr,Rgr,ie,n9,B8e,Bgr,Pgr,RQ,Igr,qgr,Ngr,s9,P8e,jgr,Dgr,BQ,Ggr,Ogr,Vgr,l9,I8e,Xgr,zgr,PQ,Qgr,Wgr,Hgr,i9,q8e,Ugr,Jgr,IQ,Ygr,Kgr,Zgr,d9,N8e,ehr,ohr,qQ,rhr,thr,ahr,c9,j8e,nhr,shr,NQ,lhr,ihr,dhr,f9,D8e,chr,fhr,jQ,mhr,ghr,hhr,m9,G8e,phr,uhr,DQ,_hr,bhr,vhr,g9,O8e,Fhr,Thr,GQ,Mhr,Ehr,Chr,h9,V8e,whr,Ahr,OQ,yhr,Lhr,xhr,p9,X8e,$hr,khr,VQ,Shr,Rhr,Bhr,u9,z8e,Phr,Ihr,XQ,qhr,Nhr,jhr,_9,Q8e,Dhr,Ghr,zQ,Ohr,Vhr,Xhr,b9,W8e,zhr,Qhr,QQ,Whr,Hhr,Uhr,v9,H8e,Jhr,Yhr,WQ,Khr,Zhr,epr,F9,U8e,opr,rpr,HQ,tpr,apr,npr,T9,J8e,spr,lpr,UQ,ipr,dpr,cpr,M9,Y8e,fpr,mpr,JQ,gpr,hpr,ppr,E9,K8e,upr,_pr,YQ,bpr,vpr,Fpr,C9,Z8e,Tpr,Mpr,KQ,Epr,Cpr,wpr,w9,$Ie,Zd,A9,ebe,Yy,Apr,obe,ypr,kIe,rr,Ky,Lpr,ec,xpr,ZQ,$pr,kpr,eW,Spr,Rpr,Bpr,Zy,Ppr,rbe,Ipr,qpr,Npr,$t,eL,jpr,tbe,Dpr,Gpr,oc,Opr,abe,Vpr,Xpr,oW,zpr,Qpr,Wpr,y9,Hpr,$r,oL,Upr,nbe,Jpr,Ypr,an,Kpr,sbe,Zpr,eur,lbe,our,rur,ibe,tur,aur,nur,ye,L9,dbe,sur,lur,rW,iur,dur,cur,x9,cbe,fur,mur,tW,gur,hur,pur,$9,fbe,uur,_ur,aW,bur,vur,Fur,k9,mbe,Tur,Mur,nW,Eur,Cur,wur,S9,gbe,Aur,yur,sW,Lur,xur,$ur,R9,hbe,kur,Sur,lW,Rur,Bur,Pur,B9,pbe,Iur,qur,iW,Nur,jur,Dur,P9,ube,Gur,Our,dW,Vur,Xur,zur,I9,_be,Qur,Wur,cW,Hur,Uur,Jur,q9,bbe,Yur,Kur,fW,Zur,e_r,o_r,N9,SIe,rc,j9,vbe,rL,r_r,Fbe,t_r,RIe,tr,tL,a_r,tc,n_r,mW,s_r,l_r,gW,i_r,d_r,c_r,aL,f_r,Tbe,m_r,g_r,h_r,kt,nL,p_r,Mbe,u_r,__r,ac,b_r,Ebe,v_r,F_r,hW,T_r,M_r,E_r,D9,C_r,kr,sL,w_r,Cbe,A_r,y_r,nn,L_r,wbe,x_r,$_r,Abe,k_r,S_r,ybe,R_r,B_r,P_r,Z,G9,Lbe,I_r,q_r,pW,N_r,j_r,D_r,O9,xbe,G_r,O_r,uW,V_r,X_r,z_r,V9,$be,Q_r,W_r,_W,H_r,U_r,J_r,X9,kbe,Y_r,K_r,bW,Z_r,e1r,o1r,z9,Sbe,r1r,t1r,vW,a1r,n1r,s1r,Q9,Rbe,l1r,i1r,FW,d1r,c1r,f1r,W9,Bbe,m1r,g1r,TW,h1r,p1r,u1r,H9,Pbe,_1r,b1r,MW,v1r,F1r,T1r,U9,Ibe,M1r,E1r,EW,C1r,w1r,A1r,J9,qbe,y1r,L1r,CW,x1r,$1r,k1r,Y9,Nbe,S1r,R1r,wW,B1r,P1r,I1r,K9,jbe,q1r,N1r,AW,j1r,D1r,G1r,Z9,Dbe,O1r,V1r,yW,X1r,z1r,Q1r,eM,Gbe,W1r,H1r,LW,U1r,J1r,Y1r,oM,Obe,K1r,Z1r,xW,e8r,o8r,r8r,rM,Vbe,t8r,a8r,$W,n8r,s8r,l8r,tM,Xbe,i8r,d8r,kW,c8r,f8r,m8r,aM,zbe,g8r,h8r,SW,p8r,u8r,_8r,nM,Qbe,b8r,v8r,RW,F8r,T8r,M8r,sM,Wbe,E8r,C8r,BW,w8r,A8r,y8r,lM,Hbe,L8r,x8r,PW,$8r,k8r,S8r,iM,Ube,R8r,B8r,IW,P8r,I8r,q8r,dM,Jbe,N8r,j8r,qW,D8r,G8r,O8r,cM,Ybe,V8r,X8r,NW,z8r,Q8r,W8r,fM,Kbe,H8r,U8r,jW,J8r,Y8r,K8r,mM,Zbe,Z8r,ebr,DW,obr,rbr,tbr,gM,BIe,nc,hM,e2e,lL,abr,o2e,nbr,PIe,ar,iL,sbr,sc,lbr,GW,ibr,dbr,OW,cbr,fbr,mbr,dL,gbr,r2e,hbr,pbr,ubr,St,cL,_br,t2e,bbr,vbr,lc,Fbr,a2e,Tbr,Mbr,VW,Ebr,Cbr,wbr,pM,Abr,Sr,fL,ybr,n2e,Lbr,xbr,sn,$br,s2e,kbr,Sbr,l2e,Rbr,Bbr,i2e,Pbr,Ibr,qbr,pe,uM,d2e,Nbr,jbr,XW,Dbr,Gbr,Obr,_M,c2e,Vbr,Xbr,zW,zbr,Qbr,Wbr,bM,f2e,Hbr,Ubr,QW,Jbr,Ybr,Kbr,vM,m2e,Zbr,e2r,WW,o2r,r2r,t2r,FM,g2e,a2r,n2r,HW,s2r,l2r,i2r,TM,h2e,d2r,c2r,UW,f2r,m2r,g2r,MM,p2e,h2r,p2r,JW,u2r,_2r,b2r,EM,u2e,v2r,F2r,YW,T2r,M2r,E2r,CM,_2e,C2r,w2r,KW,A2r,y2r,L2r,wM,b2e,x2r,$2r,ZW,k2r,S2r,R2r,AM,v2e,B2r,P2r,eH,I2r,q2r,N2r,yM,F2e,j2r,D2r,oH,G2r,O2r,V2r,LM,T2e,X2r,z2r,rH,Q2r,W2r,H2r,xM,M2e,U2r,J2r,tH,Y2r,K2r,Z2r,$M,E2e,evr,ovr,aH,rvr,tvr,avr,kM,C2e,nvr,svr,nH,lvr,ivr,dvr,SM,w2e,cvr,fvr,sH,mvr,gvr,hvr,RM,IIe,ic,BM,A2e,mL,pvr,y2e,uvr,qIe,nr,gL,_vr,dc,bvr,lH,vvr,Fvr,iH,Tvr,Mvr,Evr,hL,Cvr,L2e,wvr,Avr,yvr,Rt,pL,Lvr,x2e,xvr,$vr,cc,kvr,$2e,Svr,Rvr,dH,Bvr,Pvr,Ivr,PM,qvr,Rr,uL,Nvr,k2e,jvr,Dvr,ln,Gvr,S2e,Ovr,Vvr,R2e,Xvr,zvr,B2e,Qvr,Wvr,Hvr,_L,IM,P2e,Uvr,Jvr,cH,Yvr,Kvr,Zvr,qM,I2e,eFr,oFr,fH,rFr,tFr,aFr,NM,NIe,fc,jM,q2e,bL,nFr,N2e,sFr,jIe,sr,vL,lFr,mc,iFr,mH,dFr,cFr,gH,fFr,mFr,gFr,FL,hFr,j2e,pFr,uFr,_Fr,Bt,TL,bFr,D2e,vFr,FFr,gc,TFr,G2e,MFr,EFr,hH,CFr,wFr,AFr,DM,yFr,Br,ML,LFr,O2e,xFr,$Fr,dn,kFr,V2e,SFr,RFr,X2e,BFr,PFr,z2e,IFr,qFr,NFr,Q2e,GM,W2e,jFr,DFr,pH,GFr,OFr,VFr,OM,DIe,hc,VM,H2e,EL,XFr,U2e,zFr,GIe,lr,CL,QFr,pc,WFr,uH,HFr,UFr,_H,JFr,YFr,KFr,wL,ZFr,J2e,e6r,o6r,r6r,Pt,AL,t6r,Y2e,a6r,n6r,uc,s6r,K2e,l6r,i6r,bH,d6r,c6r,f6r,XM,m6r,Pr,yL,g6r,Z2e,h6r,p6r,cn,u6r,eve,_6r,b6r,ove,v6r,F6r,rve,T6r,M6r,E6r,de,zM,tve,C6r,w6r,vH,A6r,y6r,L6r,QM,ave,x6r,$6r,FH,k6r,S6r,R6r,WM,nve,B6r,P6r,TH,I6r,q6r,N6r,HM,sve,j6r,D6r,MH,G6r,O6r,V6r,UM,lve,X6r,z6r,EH,Q6r,W6r,H6r,JM,ive,U6r,J6r,CH,Y6r,K6r,Z6r,YM,dve,eTr,oTr,wH,rTr,tTr,aTr,KM,cve,nTr,sTr,AH,lTr,iTr,dTr,ZM,fve,cTr,fTr,yH,mTr,gTr,hTr,e4,mve,pTr,uTr,LH,_Tr,bTr,vTr,o4,gve,FTr,TTr,xH,MTr,ETr,CTr,r4,hve,wTr,ATr,$H,yTr,LTr,xTr,t4,pve,$Tr,kTr,kH,STr,RTr,BTr,a4,uve,PTr,ITr,SH,qTr,NTr,jTr,n4,_ve,DTr,GTr,RH,OTr,VTr,XTr,s4,bve,zTr,QTr,BH,WTr,HTr,UTr,l4,vve,JTr,YTr,PH,KTr,ZTr,e9r,i4,Fve,o9r,r9r,IH,t9r,a9r,n9r,d4,Tve,s9r,l9r,qH,i9r,d9r,c9r,c4,Mve,f9r,m9r,NH,g9r,h9r,p9r,f4,OIe,_c,m4,Eve,LL,u9r,Cve,_9r,VIe,ir,xL,b9r,bc,v9r,jH,F9r,T9r,DH,M9r,E9r,C9r,$L,w9r,wve,A9r,y9r,L9r,It,kL,x9r,Ave,$9r,k9r,vc,S9r,yve,R9r,B9r,GH,P9r,I9r,q9r,g4,N9r,Ir,SL,j9r,Lve,D9r,G9r,fn,O9r,xve,V9r,X9r,$ve,z9r,Q9r,kve,W9r,H9r,U9r,ce,h4,Sve,J9r,Y9r,OH,K9r,Z9r,eMr,p4,Rve,oMr,rMr,VH,tMr,aMr,nMr,u4,Bve,sMr,lMr,XH,iMr,dMr,cMr,_4,Pve,fMr,mMr,zH,gMr,hMr,pMr,b4,Ive,uMr,_Mr,QH,bMr,vMr,FMr,v4,qve,TMr,MMr,WH,EMr,CMr,wMr,F4,Nve,AMr,yMr,HH,LMr,xMr,$Mr,T4,jve,kMr,SMr,UH,RMr,BMr,PMr,M4,Dve,IMr,qMr,JH,NMr,jMr,DMr,E4,Gve,GMr,OMr,YH,VMr,XMr,zMr,C4,Ove,QMr,WMr,KH,HMr,UMr,JMr,w4,Vve,YMr,KMr,ZH,ZMr,e4r,o4r,A4,Xve,r4r,t4r,eU,a4r,n4r,s4r,y4,zve,l4r,i4r,oU,d4r,c4r,f4r,L4,Qve,m4r,g4r,rU,h4r,p4r,u4r,x4,Wve,_4r,b4r,tU,v4r,F4r,T4r,$4,Hve,M4r,E4r,aU,C4r,w4r,A4r,k4,Uve,y4r,L4r,nU,x4r,$4r,k4r,S4,Jve,S4r,R4r,sU,B4r,P4r,I4r,R4,Yve,q4r,N4r,lU,j4r,D4r,G4r,B4,XIe,Fc,P4,Kve,RL,O4r,Zve,V4r,zIe,dr,BL,X4r,Tc,z4r,iU,Q4r,W4r,dU,H4r,U4r,J4r,PL,Y4r,eFe,K4r,Z4r,eEr,qt,IL,oEr,oFe,rEr,tEr,Mc,aEr,rFe,nEr,sEr,cU,lEr,iEr,dEr,I4,cEr,qr,qL,fEr,tFe,mEr,gEr,mn,hEr,aFe,pEr,uEr,nFe,_Er,bEr,sFe,vEr,FEr,TEr,lFe,q4,iFe,MEr,EEr,fU,CEr,wEr,AEr,N4,QIe,Ec,j4,dFe,NL,yEr,cFe,LEr,WIe,cr,jL,xEr,Cc,$Er,mU,kEr,SEr,gU,REr,BEr,PEr,DL,IEr,fFe,qEr,NEr,jEr,Nt,GL,DEr,mFe,GEr,OEr,wc,VEr,gFe,XEr,zEr,hU,QEr,WEr,HEr,D4,UEr,Nr,OL,JEr,hFe,YEr,KEr,gn,ZEr,pFe,e5r,o5r,uFe,r5r,t5r,_Fe,a5r,n5r,s5r,bFe,G4,vFe,l5r,i5r,pU,d5r,c5r,f5r,O4,HIe,Ac,V4,FFe,VL,m5r,TFe,g5r,UIe,fr,XL,h5r,yc,p5r,uU,u5r,_5r,_U,b5r,v5r,F5r,zL,T5r,MFe,M5r,E5r,C5r,jt,QL,w5r,EFe,A5r,y5r,Lc,L5r,CFe,x5r,$5r,bU,k5r,S5r,R5r,X4,B5r,jr,WL,P5r,wFe,I5r,q5r,hn,N5r,AFe,j5r,D5r,yFe,G5r,O5r,LFe,V5r,X5r,z5r,oe,z4,xFe,Q5r,W5r,vU,H5r,U5r,J5r,Q4,$Fe,Y5r,K5r,FU,Z5r,eCr,oCr,W4,kFe,rCr,tCr,TU,aCr,nCr,sCr,H4,SFe,lCr,iCr,MU,dCr,cCr,fCr,U4,RFe,mCr,gCr,EU,hCr,pCr,uCr,J4,BFe,_Cr,bCr,CU,vCr,FCr,TCr,Y4,PFe,MCr,ECr,wU,CCr,wCr,ACr,K4,IFe,yCr,LCr,AU,xCr,$Cr,kCr,Z4,qFe,SCr,RCr,yU,BCr,PCr,ICr,eE,NFe,qCr,NCr,LU,jCr,DCr,GCr,oE,jFe,OCr,VCr,xU,XCr,zCr,QCr,rE,DFe,WCr,HCr,$U,UCr,JCr,YCr,tE,GFe,KCr,ZCr,kU,e3r,o3r,r3r,aE,OFe,t3r,a3r,SU,n3r,s3r,l3r,nE,VFe,i3r,d3r,RU,c3r,f3r,m3r,sE,XFe,g3r,h3r,BU,p3r,u3r,_3r,lE,zFe,b3r,v3r,PU,F3r,T3r,M3r,iE,QFe,E3r,C3r,IU,w3r,A3r,y3r,dE,WFe,L3r,x3r,qU,$3r,k3r,S3r,cE,HFe,R3r,B3r,NU,P3r,I3r,q3r,fE,UFe,N3r,j3r,jU,D3r,G3r,O3r,mE,JFe,V3r,X3r,DU,z3r,Q3r,W3r,gE,YFe,H3r,U3r,GU,J3r,Y3r,K3r,hE,KFe,Z3r,ewr,OU,owr,rwr,twr,pE,ZFe,awr,nwr,VU,swr,lwr,iwr,uE,JIe,xc,_E,e6e,HL,dwr,o6e,cwr,YIe,mr,UL,fwr,$c,mwr,XU,gwr,hwr,zU,pwr,uwr,_wr,JL,bwr,r6e,vwr,Fwr,Twr,Dt,YL,Mwr,t6e,Ewr,Cwr,kc,wwr,a6e,Awr,ywr,QU,Lwr,xwr,$wr,bE,kwr,Dr,KL,Swr,n6e,Rwr,Bwr,pn,Pwr,s6e,Iwr,qwr,l6e,Nwr,jwr,i6e,Dwr,Gwr,Owr,ke,vE,d6e,Vwr,Xwr,WU,zwr,Qwr,Wwr,FE,c6e,Hwr,Uwr,HU,Jwr,Ywr,Kwr,TE,f6e,Zwr,eAr,UU,oAr,rAr,tAr,ME,m6e,aAr,nAr,JU,sAr,lAr,iAr,EE,g6e,dAr,cAr,YU,fAr,mAr,gAr,CE,h6e,hAr,pAr,KU,uAr,_Ar,bAr,wE,p6e,vAr,FAr,ZU,TAr,MAr,EAr,AE,u6e,CAr,wAr,eJ,AAr,yAr,LAr,yE,_6e,xAr,$Ar,oJ,kAr,SAr,RAr,LE,KIe,Sc,xE,b6e,ZL,BAr,v6e,PAr,ZIe,gr,ex,IAr,Rc,qAr,rJ,NAr,jAr,tJ,DAr,GAr,OAr,ox,VAr,F6e,XAr,zAr,QAr,Gt,rx,WAr,T6e,HAr,UAr,Bc,JAr,M6e,YAr,KAr,aJ,ZAr,e0r,o0r,$E,r0r,Gr,tx,t0r,E6e,a0r,n0r,un,s0r,C6e,l0r,i0r,w6e,d0r,c0r,A6e,f0r,m0r,g0r,Me,kE,y6e,h0r,p0r,nJ,u0r,_0r,b0r,SE,L6e,v0r,F0r,sJ,T0r,M0r,E0r,RE,x6e,C0r,w0r,lJ,A0r,y0r,L0r,BE,$6e,x0r,$0r,iJ,k0r,S0r,R0r,PE,k6e,B0r,P0r,dJ,I0r,q0r,N0r,IE,S6e,j0r,D0r,cJ,G0r,O0r,V0r,qE,R6e,X0r,z0r,fJ,Q0r,W0r,H0r,NE,B6e,U0r,J0r,mJ,Y0r,K0r,Z0r,jE,P6e,eyr,oyr,gJ,ryr,tyr,ayr,DE,I6e,nyr,syr,hJ,lyr,iyr,dyr,GE,q6e,cyr,fyr,pJ,myr,gyr,hyr,OE,N6e,pyr,uyr,uJ,_yr,byr,vyr,VE,eqe,Pc,XE,j6e,ax,Fyr,D6e,Tyr,oqe,hr,nx,Myr,Ic,Eyr,_J,Cyr,wyr,bJ,Ayr,yyr,Lyr,sx,xyr,G6e,$yr,kyr,Syr,Ot,lx,Ryr,O6e,Byr,Pyr,qc,Iyr,V6e,qyr,Nyr,vJ,jyr,Dyr,Gyr,zE,Oyr,Or,ix,Vyr,X6e,Xyr,zyr,_n,Qyr,z6e,Wyr,Hyr,Q6e,Uyr,Jyr,W6e,Yyr,Kyr,Zyr,Le,QE,H6e,eLr,oLr,FJ,rLr,tLr,aLr,WE,U6e,nLr,sLr,TJ,lLr,iLr,dLr,HE,J6e,cLr,fLr,MJ,mLr,gLr,hLr,UE,Y6e,pLr,uLr,EJ,_Lr,bLr,vLr,JE,K6e,FLr,TLr,CJ,MLr,ELr,CLr,YE,Z6e,wLr,ALr,wJ,yLr,LLr,xLr,KE,eTe,$Lr,kLr,AJ,SLr,RLr,BLr,ZE,oTe,PLr,ILr,yJ,qLr,NLr,jLr,e5,rTe,DLr,GLr,LJ,OLr,VLr,XLr,o5,tTe,zLr,QLr,xJ,WLr,HLr,ULr,r5,rqe,Nc,t5,aTe,dx,JLr,nTe,YLr,tqe,pr,cx,KLr,jc,ZLr,$J,exr,oxr,kJ,rxr,txr,axr,fx,nxr,sTe,sxr,lxr,ixr,Vt,mx,dxr,lTe,cxr,fxr,Dc,mxr,iTe,gxr,hxr,SJ,pxr,uxr,_xr,a5,bxr,Vr,gx,vxr,dTe,Fxr,Txr,bn,Mxr,cTe,Exr,Cxr,fTe,wxr,Axr,mTe,yxr,Lxr,xxr,Se,n5,gTe,$xr,kxr,RJ,Sxr,Rxr,Bxr,s5,hTe,Pxr,Ixr,BJ,qxr,Nxr,jxr,l5,pTe,Dxr,Gxr,PJ,Oxr,Vxr,Xxr,i5,uTe,zxr,Qxr,IJ,Wxr,Hxr,Uxr,d5,_Te,Jxr,Yxr,qJ,Kxr,Zxr,e7r,c5,bTe,o7r,r7r,NJ,t7r,a7r,n7r,f5,vTe,s7r,l7r,jJ,i7r,d7r,c7r,m5,FTe,f7r,m7r,DJ,g7r,h7r,p7r,g5,TTe,u7r,_7r,GJ,b7r,v7r,F7r,h5,aqe,Gc,p5,MTe,hx,T7r,ETe,M7r,nqe,ur,px,E7r,Oc,C7r,OJ,w7r,A7r,VJ,y7r,L7r,x7r,ux,$7r,CTe,k7r,S7r,R7r,Xt,_x,B7r,wTe,P7r,I7r,Vc,q7r,ATe,N7r,j7r,XJ,D7r,G7r,O7r,u5,V7r,Xr,bx,X7r,yTe,z7r,Q7r,vn,W7r,LTe,H7r,U7r,xTe,J7r,Y7r,$Te,K7r,Z7r,e$r,xe,_5,kTe,o$r,r$r,zJ,t$r,a$r,n$r,b5,STe,s$r,l$r,QJ,i$r,d$r,c$r,v5,RTe,f$r,m$r,WJ,g$r,h$r,p$r,F5,BTe,u$r,_$r,HJ,b$r,v$r,F$r,T5,PTe,T$r,M$r,UJ,E$r,C$r,w$r,M5,ITe,A$r,y$r,JJ,L$r,x$r,$$r,E5,qTe,k$r,S$r,YJ,R$r,B$r,P$r,C5,NTe,I$r,q$r,KJ,N$r,j$r,D$r,w5,jTe,G$r,O$r,ZJ,V$r,X$r,z$r,A5,DTe,Q$r,W$r,eY,H$r,U$r,J$r,y5,sqe,Xc,L5,GTe,vx,Y$r,OTe,K$r,lqe,_r,Fx,Z$r,zc,ekr,oY,okr,rkr,rY,tkr,akr,nkr,Tx,skr,VTe,lkr,ikr,dkr,zt,Mx,ckr,XTe,fkr,mkr,Qc,gkr,zTe,hkr,pkr,tY,ukr,_kr,bkr,x5,vkr,zr,Ex,Fkr,QTe,Tkr,Mkr,Fn,Ekr,WTe,Ckr,wkr,HTe,Akr,ykr,UTe,Lkr,xkr,$kr,$e,$5,JTe,kkr,Skr,aY,Rkr,Bkr,Pkr,k5,YTe,Ikr,qkr,nY,Nkr,jkr,Dkr,S5,KTe,Gkr,Okr,sY,Vkr,Xkr,zkr,R5,ZTe,Qkr,Wkr,lY,Hkr,Ukr,Jkr,B5,e9e,Ykr,Kkr,iY,Zkr,eSr,oSr,P5,o9e,rSr,tSr,dY,aSr,nSr,sSr,I5,r9e,lSr,iSr,cY,dSr,cSr,fSr,q5,t9e,mSr,gSr,fY,hSr,pSr,uSr,N5,a9e,_Sr,bSr,mY,vSr,FSr,TSr,j5,n9e,MSr,ESr,gY,CSr,wSr,ASr,D5,iqe,Wc,G5,s9e,Cx,ySr,l9e,LSr,dqe,br,wx,xSr,Hc,$Sr,hY,kSr,SSr,pY,RSr,BSr,PSr,Ax,ISr,i9e,qSr,NSr,jSr,Qt,yx,DSr,d9e,GSr,OSr,Uc,VSr,c9e,XSr,zSr,uY,QSr,WSr,HSr,O5,USr,Qr,Lx,JSr,f9e,YSr,KSr,Tn,ZSr,m9e,eRr,oRr,g9e,rRr,tRr,h9e,aRr,nRr,sRr,De,V5,p9e,lRr,iRr,_Y,dRr,cRr,fRr,X5,u9e,mRr,gRr,bY,hRr,pRr,uRr,z5,_9e,_Rr,bRr,vY,vRr,FRr,TRr,Q5,b9e,MRr,ERr,FY,CRr,wRr,ARr,W5,v9e,yRr,LRr,TY,xRr,$Rr,kRr,H5,F9e,SRr,RRr,MY,BRr,PRr,IRr,U5,T9e,qRr,NRr,EY,jRr,DRr,GRr,J5,M9e,ORr,VRr,CY,XRr,zRr,QRr,Y5,cqe,Jc,K5,E9e,xx,WRr,C9e,HRr,fqe,vr,$x,URr,Yc,JRr,wY,YRr,KRr,AY,ZRr,eBr,oBr,kx,rBr,w9e,tBr,aBr,nBr,Wt,Sx,sBr,A9e,lBr,iBr,Kc,dBr,y9e,cBr,fBr,yY,mBr,gBr,hBr,Z5,pBr,Wr,Rx,uBr,L9e,_Br,bBr,Mn,vBr,x9e,FBr,TBr,$9e,MBr,EBr,k9e,CBr,wBr,ABr,Ge,eC,S9e,yBr,LBr,LY,xBr,$Br,kBr,oC,R9e,SBr,RBr,xY,BBr,PBr,IBr,rC,B9e,qBr,NBr,$Y,jBr,DBr,GBr,tC,P9e,OBr,VBr,kY,XBr,zBr,QBr,aC,I9e,WBr,HBr,SY,UBr,JBr,YBr,nC,q9e,KBr,ZBr,RY,ePr,oPr,rPr,sC,N9e,tPr,aPr,BY,nPr,sPr,lPr,lC,j9e,iPr,dPr,PY,cPr,fPr,mPr,iC,mqe,Zc,dC,D9e,Bx,gPr,G9e,hPr,gqe,Fr,Px,pPr,ef,uPr,IY,_Pr,bPr,qY,vPr,FPr,TPr,Ix,MPr,O9e,EPr,CPr,wPr,Ht,qx,APr,V9e,yPr,LPr,of,xPr,X9e,$Pr,kPr,NY,SPr,RPr,BPr,cC,PPr,Hr,Nx,IPr,z9e,qPr,NPr,En,jPr,Q9e,DPr,GPr,W9e,OPr,VPr,H9e,XPr,zPr,QPr,U9e,fC,J9e,WPr,HPr,jY,UPr,JPr,YPr,mC,hqe,rf,gC,Y9e,jx,KPr,K9e,ZPr,pqe,Tr,Dx,eIr,tf,oIr,DY,rIr,tIr,GY,aIr,nIr,sIr,Gx,lIr,Z9e,iIr,dIr,cIr,Ut,Ox,fIr,eMe,mIr,gIr,af,hIr,oMe,pIr,uIr,OY,_Ir,bIr,vIr,hC,FIr,Ur,Vx,TIr,rMe,MIr,EIr,Cn,CIr,tMe,wIr,AIr,aMe,yIr,LIr,nMe,xIr,$Ir,kIr,Xx,pC,sMe,SIr,RIr,VY,BIr,PIr,IIr,uC,lMe,qIr,NIr,XY,jIr,DIr,GIr,_C,uqe,nf,bC,iMe,zx,OIr,dMe,VIr,_qe,Mr,Qx,XIr,sf,zIr,zY,QIr,WIr,QY,HIr,UIr,JIr,Wx,YIr,cMe,KIr,ZIr,eqr,Jt,Hx,oqr,fMe,rqr,tqr,lf,aqr,mMe,nqr,sqr,WY,lqr,iqr,dqr,vC,cqr,Jr,Ux,fqr,gMe,mqr,gqr,wn,hqr,hMe,pqr,uqr,pMe,_qr,bqr,uMe,vqr,Fqr,Tqr,_Me,FC,bMe,Mqr,Eqr,HY,Cqr,wqr,Aqr,TC,bqe;return d=new ee({}),Ma=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),zw=new ee({}),Qw=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),_f=new yqr({props:{warning:!0,$$slots:{default:[V3t]},$$scope:{ctx:A}}}),Ww=new ee({}),Hw=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/configuration_auto.py#L563"}}),Yw=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/configuration_auto.py#L586"}}),hg=new P({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[X3t]},$$scope:{ctx:A}}}),Kw=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/configuration_auto.py#L708"}}),Zw=new ee({}),eA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/tokenization_auto.py#L377"}}),tA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_16988/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/tokenization_auto.py#L391"}}),Qg=new P({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[z3t]},$$scope:{ctx:A}}}),aA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/tokenization_auto.py#L587"}}),nA=new ee({}),sA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/feature_extraction_auto.py#L177"}}),dA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_16988/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/feature_extraction_auto.py#L191"}}),vh=new yqr({props:{$$slots:{default:[Q3t]},$$scope:{ctx:A}}}),Fh=new P({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[W3t]},$$scope:{ctx:A}}}),cA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/feature_extraction_auto.py#L318"}}),fA=new ee({}),mA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/processing_auto.py#L76"}}),pA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/processing_auto.py#L90"}}),qh=new yqr({props:{$$slots:{default:[H3t]},$$scope:{ctx:A}}}),Nh=new P({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[U3t]},$$scope:{ctx:A}}}),uA=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/processing_auto.py#L243"}}),_A=new ee({}),bA=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L717"}}),FA=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),Gh=new P({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[J3t]},$$scope:{ctx:A}}}),TA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),xu=new P({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Y3t]},$$scope:{ctx:A}}}),MA=new ee({}),EA=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L724"}}),wA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),ku=new P({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[K3t]},$$scope:{ctx:A}}}),AA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),b_=new P({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Z3t]},$$scope:{ctx:A}}}),yA=new ee({}),LA=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L739"}}),$A=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),F_=new P({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[ewt]},$$scope:{ctx:A}}}),kA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),t1=new P({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[owt]},$$scope:{ctx:A}}}),SA=new ee({}),RA=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L746"}}),PA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),n1=new P({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[rwt]},$$scope:{ctx:A}}}),IA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),O1=new P({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[twt]},$$scope:{ctx:A}}}),qA=new ee({}),NA=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L753"}}),DA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),X1=new P({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[awt]},$$scope:{ctx:A}}}),GA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),d8=new P({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[nwt]},$$scope:{ctx:A}}}),OA=new ee({}),VA=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L762"}}),zA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),f8=new P({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[swt]},$$scope:{ctx:A}}}),QA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),sb=new P({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[lwt]},$$scope:{ctx:A}}}),WA=new ee({}),HA=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L796"}}),JA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),ib=new P({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[iwt]},$$scope:{ctx:A}}}),YA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),jb=new P({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[dwt]},$$scope:{ctx:A}}}),KA=new ee({}),ZA=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L803"}}),o0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),Gb=new P({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[cwt]},$$scope:{ctx:A}}}),r0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),Hb=new P({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[fwt]},$$scope:{ctx:A}}}),t0=new ee({}),a0=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L789"}}),s0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),Jb=new P({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[mwt]},$$scope:{ctx:A}}}),l0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),k2=new P({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[gwt]},$$scope:{ctx:A}}}),i0=new ee({}),d0=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L771"}}),f0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),R2=new P({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[hwt]},$$scope:{ctx:A}}}),m0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),Fv=new P({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[pwt]},$$scope:{ctx:A}}}),g0=new ee({}),h0=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L778"}}),u0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),Mv=new P({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[uwt]},$$scope:{ctx:A}}}),_0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),wv=new P({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[_wt]},$$scope:{ctx:A}}}),b0=new ee({}),v0=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L812"}}),T0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),yv=new P({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[bwt]},$$scope:{ctx:A}}}),M0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),Dv=new P({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[vwt]},$$scope:{ctx:A}}}),E0=new ee({}),C0=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L851"}}),A0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),Ov=new P({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Fwt]},$$scope:{ctx:A}}}),y0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),zv=new P({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Twt]},$$scope:{ctx:A}}}),L0=new ee({}),x0=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L858"}}),k0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),Wv=new P({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Mwt]},$$scope:{ctx:A}}}),S0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),tF=new P({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Ewt]},$$scope:{ctx:A}}}),R0=new ee({}),B0=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L881"}}),I0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),nF=new P({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Cwt]},$$scope:{ctx:A}}}),q0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),fF=new P({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[wwt]},$$scope:{ctx:A}}}),N0=new ee({}),j0=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L865"}}),G0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),gF=new P({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Awt]},$$scope:{ctx:A}}}),O0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),EF=new P({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[ywt]},$$scope:{ctx:A}}}),V0=new ee({}),X0=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L872"}}),Q0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),wF=new P({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Lwt]},$$scope:{ctx:A}}}),W0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),xF=new P({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[xwt]},$$scope:{ctx:A}}}),U0=new ee({}),J0=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L890"}}),K0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),kF=new P({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[$wt]},$$scope:{ctx:A}}}),Z0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),qF=new P({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[kwt]},$$scope:{ctx:A}}}),ey=new ee({}),oy=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L897"}}),ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),jF=new P({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Swt]},$$scope:{ctx:A}}}),ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),XF=new P({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Rwt]},$$scope:{ctx:A}}}),ny=new ee({}),sy=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L844"}}),iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),QF=new P({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[Bwt]},$$scope:{ctx:A}}}),dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),JF=new P({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[Pwt]},$$scope:{ctx:A}}}),fy=new ee({}),my=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L819"}}),hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),KF=new P({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Iwt]},$$scope:{ctx:A}}}),py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),o6=new P({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[qwt]},$$scope:{ctx:A}}}),uy=new ee({}),_y=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L826"}}),vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),t6=new P({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Nwt]},$$scope:{ctx:A}}}),Fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),d6=new P({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[jwt]},$$scope:{ctx:A}}}),Ty=new ee({}),My=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_auto.py#L835"}}),Cy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),f6=new P({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Dwt]},$$scope:{ctx:A}}}),wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),h6=new P({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[Gwt]},$$scope:{ctx:A}}}),Ay=new ee({}),yy=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L394"}}),xy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),u6=new P({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Owt]},$$scope:{ctx:A}}}),$y=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),iT=new P({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Vwt]},$$scope:{ctx:A}}}),ky=new ee({}),Sy=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L401"}}),By=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),cT=new P({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Xwt]},$$scope:{ctx:A}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),BT=new P({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[zwt]},$$scope:{ctx:A}}}),Iy=new ee({}),qy=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),jy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),IT=new P({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Qwt]},$$scope:{ctx:A}}}),Dy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),UT=new P({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Wwt]},$$scope:{ctx:A}}}),Gy=new ee({}),Oy=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),Xy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),YT=new P({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Hwt]},$$scope:{ctx:A}}}),zy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),r9=new P({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Uwt]},$$scope:{ctx:A}}}),Qy=new ee({}),Wy=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L448"}}),Uy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),a9=new P({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Jwt]},$$scope:{ctx:A}}}),Jy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),w9=new P({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Ywt]},$$scope:{ctx:A}}}),Yy=new ee({}),Ky=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),eL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),y9=new P({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Kwt]},$$scope:{ctx:A}}}),oL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),N9=new P({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Zwt]},$$scope:{ctx:A}}}),rL=new ee({}),tL=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L464"}}),nL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),D9=new P({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[eAt]},$$scope:{ctx:A}}}),sL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),gM=new P({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[oAt]},$$scope:{ctx:A}}}),lL=new ee({}),iL=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),cL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),pM=new P({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[rAt]},$$scope:{ctx:A}}}),fL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),RM=new P({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[tAt]},$$scope:{ctx:A}}}),mL=new ee({}),gL=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),pL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),PM=new P({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[aAt]},$$scope:{ctx:A}}}),uL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),NM=new P({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[nAt]},$$scope:{ctx:A}}}),bL=new ee({}),vL=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),TL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),DM=new P({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[sAt]},$$scope:{ctx:A}}}),ML=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),OM=new P({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[lAt]},$$scope:{ctx:A}}}),EL=new ee({}),CL=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),AL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),XM=new P({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[iAt]},$$scope:{ctx:A}}}),yL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),f4=new P({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[dAt]},$$scope:{ctx:A}}}),LL=new ee({}),xL=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L473"}}),kL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),g4=new P({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[cAt]},$$scope:{ctx:A}}}),SL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),B4=new P({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[fAt]},$$scope:{ctx:A}}}),RL=new ee({}),BL=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),IL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),I4=new P({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[mAt]},$$scope:{ctx:A}}}),qL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),N4=new P({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[gAt]},$$scope:{ctx:A}}}),NL=new ee({}),jL=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_tf_auto.py#L516"}}),GL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),D4=new P({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[hAt]},$$scope:{ctx:A}}}),OL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),O4=new P({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[pAt]},$$scope:{ctx:A}}}),VL=new ee({}),XL=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L241"}}),QL=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),X4=new P({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[uAt]},$$scope:{ctx:A}}}),WL=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),uE=new P({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[_At]},$$scope:{ctx:A}}}),HL=new ee({}),UL=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),YL=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),bE=new P({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[bAt]},$$scope:{ctx:A}}}),KL=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),LE=new P({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[vAt]},$$scope:{ctx:A}}}),ZL=new ee({}),ex=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),rx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),$E=new P({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[FAt]},$$scope:{ctx:A}}}),tx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),VE=new P({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[TAt]},$$scope:{ctx:A}}}),ax=new ee({}),nx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L262"}}),lx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),zE=new P({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[MAt]},$$scope:{ctx:A}}}),ix=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),r5=new P({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[EAt]},$$scope:{ctx:A}}}),dx=new ee({}),cx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L269"}}),mx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),a5=new P({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[CAt]},$$scope:{ctx:A}}}),gx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),h5=new P({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[wAt]},$$scope:{ctx:A}}}),hx=new ee({}),px=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L278"}}),_x=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),u5=new P({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[AAt]},$$scope:{ctx:A}}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),y5=new P({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[yAt]},$$scope:{ctx:A}}}),vx=new ee({}),Fx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L287"}}),Mx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),x5=new P({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[LAt]},$$scope:{ctx:A}}}),Ex=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),D5=new P({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[xAt]},$$scope:{ctx:A}}}),Cx=new ee({}),wx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L294"}}),yx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),O5=new P({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[$At]},$$scope:{ctx:A}}}),Lx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),Y5=new P({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[kAt]},$$scope:{ctx:A}}}),xx=new ee({}),$x=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L303"}}),Sx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),Z5=new P({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[SAt]},$$scope:{ctx:A}}}),Rx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new P({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[RAt]},$$scope:{ctx:A}}}),Bx=new ee({}),Px=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),qx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),cC=new P({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[BAt]},$$scope:{ctx:A}}}),Nx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new P({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[PAt]},$$scope:{ctx:A}}}),jx=new ee({}),Dx=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L319"}}),Ox=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),hC=new P({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[IAt]},$$scope:{ctx:A}}}),Vx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),_C=new P({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[qAt]},$$scope:{ctx:A}}}),zx=new ee({}),Qx=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/modeling_flax_auto.py#L328"}}),Hx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L389"}}),vC=new P({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[NAt]},$$scope:{ctx:A}}}),Ux=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16988/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16988/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_16988/src/transformers/models/auto/auto_factory.py#L417"}}),TC=new P({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[jAt]},$$scope:{ctx:A}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),ii=o("Auto Classes"),mf=l(),et=a("p"),di=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ci=a("code"),Gw=o("from_pretrained()"),gf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),qe=l(),Xe=a("p"),fi=o("Instantiating one of "),yn=a("a"),Ow=o("AutoConfig"),Ln=o(", "),xn=a("a"),Vw=o("AutoModel"),mi=o(`, and
`),$n=a("a"),Xw=o("AutoTokenizer"),gi=o(" will directly create a class of the relevant architecture. For instance"),hf=l(),F(Ma.$$.fragment),ze=l(),Ae=a("p"),i$=o("will create a model that is an instance of "),hi=a("a"),d$=o("BertModel"),c$=o("."),Eo=l(),Ea=a("p"),f$=o("There is one class of "),pf=a("code"),m$=o("AutoModel"),Aje=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),pPe=l(),pi=a("h2"),uf=a("a"),GZ=a("span"),F(zw.$$.fragment),yje=l(),OZ=a("span"),Lje=o("Extending the Auto Classes"),uPe=l(),kn=a("p"),xje=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),VZ=a("code"),$je=o("NewModel"),kje=o(", make sure you have a "),XZ=a("code"),Sje=o("NewModelConfig"),Rje=o(` then you can add those to the auto
classes like this:`),_Pe=l(),F(Qw.$$.fragment),bPe=l(),g$=a("p"),Bje=o("You will then be able to use the auto classes like you would usually do!"),vPe=l(),F(_f.$$.fragment),FPe=l(),ui=a("h2"),bf=a("a"),zZ=a("span"),F(Ww.$$.fragment),Pje=l(),QZ=a("span"),Ije=o("AutoConfig"),TPe=l(),Co=a("div"),F(Hw.$$.fragment),qje=l(),Uw=a("p"),Nje=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),h$=a("a"),jje=o("from_pretrained()"),Dje=o(" class method."),Gje=l(),Jw=a("p"),Oje=o("This class cannot be instantiated directly using "),WZ=a("code"),Vje=o("__init__()"),Xje=o(" (throws an error)."),zje=l(),Er=a("div"),F(Yw.$$.fragment),Qje=l(),HZ=a("p"),Wje=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Hje=l(),_i=a("p"),Uje=o("The configuration class to instantiate is selected based on the "),UZ=a("code"),Jje=o("model_type"),Yje=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),JZ=a("code"),Kje=o("pretrained_model_name_or_path"),Zje=o(":"),eDe=l(),y=a("ul"),vf=a("li"),YZ=a("strong"),oDe=o("albert"),rDe=o(" \u2014 "),p$=a("a"),tDe=o("AlbertConfig"),aDe=o(" (ALBERT model)"),nDe=l(),Ff=a("li"),KZ=a("strong"),sDe=o("bart"),lDe=o(" \u2014 "),u$=a("a"),iDe=o("BartConfig"),dDe=o(" (BART model)"),cDe=l(),Tf=a("li"),ZZ=a("strong"),fDe=o("beit"),mDe=o(" \u2014 "),_$=a("a"),gDe=o("BeitConfig"),hDe=o(" (BEiT model)"),pDe=l(),Mf=a("li"),eee=a("strong"),uDe=o("bert"),_De=o(" \u2014 "),b$=a("a"),bDe=o("BertConfig"),vDe=o(" (BERT model)"),FDe=l(),Ef=a("li"),oee=a("strong"),TDe=o("bert-generation"),MDe=o(" \u2014 "),v$=a("a"),EDe=o("BertGenerationConfig"),CDe=o(" (Bert Generation model)"),wDe=l(),Cf=a("li"),ree=a("strong"),ADe=o("big_bird"),yDe=o(" \u2014 "),F$=a("a"),LDe=o("BigBirdConfig"),xDe=o(" (BigBird model)"),$De=l(),wf=a("li"),tee=a("strong"),kDe=o("bigbird_pegasus"),SDe=o(" \u2014 "),T$=a("a"),RDe=o("BigBirdPegasusConfig"),BDe=o(" (BigBirdPegasus model)"),PDe=l(),Af=a("li"),aee=a("strong"),IDe=o("blenderbot"),qDe=o(" \u2014 "),M$=a("a"),NDe=o("BlenderbotConfig"),jDe=o(" (Blenderbot model)"),DDe=l(),yf=a("li"),nee=a("strong"),GDe=o("blenderbot-small"),ODe=o(" \u2014 "),E$=a("a"),VDe=o("BlenderbotSmallConfig"),XDe=o(" (BlenderbotSmall model)"),zDe=l(),Lf=a("li"),see=a("strong"),QDe=o("camembert"),WDe=o(" \u2014 "),C$=a("a"),HDe=o("CamembertConfig"),UDe=o(" (CamemBERT model)"),JDe=l(),xf=a("li"),lee=a("strong"),YDe=o("canine"),KDe=o(" \u2014 "),w$=a("a"),ZDe=o("CanineConfig"),eGe=o(" (Canine model)"),oGe=l(),$f=a("li"),iee=a("strong"),rGe=o("clip"),tGe=o(" \u2014 "),A$=a("a"),aGe=o("CLIPConfig"),nGe=o(" (CLIP model)"),sGe=l(),kf=a("li"),dee=a("strong"),lGe=o("convbert"),iGe=o(" \u2014 "),y$=a("a"),dGe=o("ConvBertConfig"),cGe=o(" (ConvBERT model)"),fGe=l(),Sf=a("li"),cee=a("strong"),mGe=o("convnext"),gGe=o(" \u2014 "),L$=a("a"),hGe=o("ConvNextConfig"),pGe=o(" (ConvNext model)"),uGe=l(),Rf=a("li"),fee=a("strong"),_Ge=o("ctrl"),bGe=o(" \u2014 "),x$=a("a"),vGe=o("CTRLConfig"),FGe=o(" (CTRL model)"),TGe=l(),Bf=a("li"),mee=a("strong"),MGe=o("data2vec-audio"),EGe=o(" \u2014 "),$$=a("a"),CGe=o("Data2VecAudioConfig"),wGe=o(" (Data2VecAudio model)"),AGe=l(),Pf=a("li"),gee=a("strong"),yGe=o("data2vec-text"),LGe=o(" \u2014 "),k$=a("a"),xGe=o("Data2VecTextConfig"),$Ge=o(" (Data2VecText model)"),kGe=l(),If=a("li"),hee=a("strong"),SGe=o("data2vec-vision"),RGe=o(" \u2014 "),S$=a("a"),BGe=o("Data2VecVisionConfig"),PGe=o(" (Data2VecVision model)"),IGe=l(),qf=a("li"),pee=a("strong"),qGe=o("deberta"),NGe=o(" \u2014 "),R$=a("a"),jGe=o("DebertaConfig"),DGe=o(" (DeBERTa model)"),GGe=l(),Nf=a("li"),uee=a("strong"),OGe=o("deberta-v2"),VGe=o(" \u2014 "),B$=a("a"),XGe=o("DebertaV2Config"),zGe=o(" (DeBERTa-v2 model)"),QGe=l(),jf=a("li"),_ee=a("strong"),WGe=o("decision_transformer"),HGe=o(" \u2014 "),P$=a("a"),UGe=o("DecisionTransformerConfig"),JGe=o(" (Decision Transformer model)"),YGe=l(),Df=a("li"),bee=a("strong"),KGe=o("deit"),ZGe=o(" \u2014 "),I$=a("a"),eOe=o("DeiTConfig"),oOe=o(" (DeiT model)"),rOe=l(),Gf=a("li"),vee=a("strong"),tOe=o("detr"),aOe=o(" \u2014 "),q$=a("a"),nOe=o("DetrConfig"),sOe=o(" (DETR model)"),lOe=l(),Of=a("li"),Fee=a("strong"),iOe=o("distilbert"),dOe=o(" \u2014 "),N$=a("a"),cOe=o("DistilBertConfig"),fOe=o(" (DistilBERT model)"),mOe=l(),Vf=a("li"),Tee=a("strong"),gOe=o("dpr"),hOe=o(" \u2014 "),j$=a("a"),pOe=o("DPRConfig"),uOe=o(" (DPR model)"),_Oe=l(),Xf=a("li"),Mee=a("strong"),bOe=o("dpt"),vOe=o(" \u2014 "),D$=a("a"),FOe=o("DPTConfig"),TOe=o(" (DPT model)"),MOe=l(),zf=a("li"),Eee=a("strong"),EOe=o("electra"),COe=o(" \u2014 "),G$=a("a"),wOe=o("ElectraConfig"),AOe=o(" (ELECTRA model)"),yOe=l(),Qf=a("li"),Cee=a("strong"),LOe=o("encoder-decoder"),xOe=o(" \u2014 "),O$=a("a"),$Oe=o("EncoderDecoderConfig"),kOe=o(" (Encoder decoder model)"),SOe=l(),Wf=a("li"),wee=a("strong"),ROe=o("flaubert"),BOe=o(" \u2014 "),V$=a("a"),POe=o("FlaubertConfig"),IOe=o(" (FlauBERT model)"),qOe=l(),Hf=a("li"),Aee=a("strong"),NOe=o("fnet"),jOe=o(" \u2014 "),X$=a("a"),DOe=o("FNetConfig"),GOe=o(" (FNet model)"),OOe=l(),Uf=a("li"),yee=a("strong"),VOe=o("fsmt"),XOe=o(" \u2014 "),z$=a("a"),zOe=o("FSMTConfig"),QOe=o(" (FairSeq Machine-Translation model)"),WOe=l(),Jf=a("li"),Lee=a("strong"),HOe=o("funnel"),UOe=o(" \u2014 "),Q$=a("a"),JOe=o("FunnelConfig"),YOe=o(" (Funnel Transformer model)"),KOe=l(),Yf=a("li"),xee=a("strong"),ZOe=o("glpn"),eVe=o(" \u2014 "),W$=a("a"),oVe=o("GLPNConfig"),rVe=o(" (GLPN model)"),tVe=l(),Kf=a("li"),$ee=a("strong"),aVe=o("gpt2"),nVe=o(" \u2014 "),H$=a("a"),sVe=o("GPT2Config"),lVe=o(" (OpenAI GPT-2 model)"),iVe=l(),Zf=a("li"),kee=a("strong"),dVe=o("gpt_neo"),cVe=o(" \u2014 "),U$=a("a"),fVe=o("GPTNeoConfig"),mVe=o(" (GPT Neo model)"),gVe=l(),em=a("li"),See=a("strong"),hVe=o("gptj"),pVe=o(" \u2014 "),J$=a("a"),uVe=o("GPTJConfig"),_Ve=o(" (GPT-J model)"),bVe=l(),om=a("li"),Ree=a("strong"),vVe=o("hubert"),FVe=o(" \u2014 "),Y$=a("a"),TVe=o("HubertConfig"),MVe=o(" (Hubert model)"),EVe=l(),rm=a("li"),Bee=a("strong"),CVe=o("ibert"),wVe=o(" \u2014 "),K$=a("a"),AVe=o("IBertConfig"),yVe=o(" (I-BERT model)"),LVe=l(),tm=a("li"),Pee=a("strong"),xVe=o("imagegpt"),$Ve=o(" \u2014 "),Z$=a("a"),kVe=o("ImageGPTConfig"),SVe=o(" (ImageGPT model)"),RVe=l(),am=a("li"),Iee=a("strong"),BVe=o("layoutlm"),PVe=o(" \u2014 "),ek=a("a"),IVe=o("LayoutLMConfig"),qVe=o(" (LayoutLM model)"),NVe=l(),nm=a("li"),qee=a("strong"),jVe=o("layoutlmv2"),DVe=o(" \u2014 "),ok=a("a"),GVe=o("LayoutLMv2Config"),OVe=o(" (LayoutLMv2 model)"),VVe=l(),sm=a("li"),Nee=a("strong"),XVe=o("led"),zVe=o(" \u2014 "),rk=a("a"),QVe=o("LEDConfig"),WVe=o(" (LED model)"),HVe=l(),lm=a("li"),jee=a("strong"),UVe=o("longformer"),JVe=o(" \u2014 "),tk=a("a"),YVe=o("LongformerConfig"),KVe=o(" (Longformer model)"),ZVe=l(),im=a("li"),Dee=a("strong"),eXe=o("luke"),oXe=o(" \u2014 "),ak=a("a"),rXe=o("LukeConfig"),tXe=o(" (LUKE model)"),aXe=l(),dm=a("li"),Gee=a("strong"),nXe=o("lxmert"),sXe=o(" \u2014 "),nk=a("a"),lXe=o("LxmertConfig"),iXe=o(" (LXMERT model)"),dXe=l(),cm=a("li"),Oee=a("strong"),cXe=o("m2m_100"),fXe=o(" \u2014 "),sk=a("a"),mXe=o("M2M100Config"),gXe=o(" (M2M100 model)"),hXe=l(),fm=a("li"),Vee=a("strong"),pXe=o("marian"),uXe=o(" \u2014 "),lk=a("a"),_Xe=o("MarianConfig"),bXe=o(" (Marian model)"),vXe=l(),mm=a("li"),Xee=a("strong"),FXe=o("maskformer"),TXe=o(" \u2014 "),ik=a("a"),MXe=o("MaskFormerConfig"),EXe=o(" (MaskFormer model)"),CXe=l(),gm=a("li"),zee=a("strong"),wXe=o("mbart"),AXe=o(" \u2014 "),dk=a("a"),yXe=o("MBartConfig"),LXe=o(" (mBART model)"),xXe=l(),hm=a("li"),Qee=a("strong"),$Xe=o("megatron-bert"),kXe=o(" \u2014 "),ck=a("a"),SXe=o("MegatronBertConfig"),RXe=o(" (MegatronBert model)"),BXe=l(),pm=a("li"),Wee=a("strong"),PXe=o("mobilebert"),IXe=o(" \u2014 "),fk=a("a"),qXe=o("MobileBertConfig"),NXe=o(" (MobileBERT model)"),jXe=l(),um=a("li"),Hee=a("strong"),DXe=o("mpnet"),GXe=o(" \u2014 "),mk=a("a"),OXe=o("MPNetConfig"),VXe=o(" (MPNet model)"),XXe=l(),_m=a("li"),Uee=a("strong"),zXe=o("mt5"),QXe=o(" \u2014 "),gk=a("a"),WXe=o("MT5Config"),HXe=o(" (mT5 model)"),UXe=l(),bm=a("li"),Jee=a("strong"),JXe=o("nystromformer"),YXe=o(" \u2014 "),hk=a("a"),KXe=o("NystromformerConfig"),ZXe=o(" (Nystromformer model)"),eze=l(),vm=a("li"),Yee=a("strong"),oze=o("openai-gpt"),rze=o(" \u2014 "),pk=a("a"),tze=o("OpenAIGPTConfig"),aze=o(" (OpenAI GPT model)"),nze=l(),Fm=a("li"),Kee=a("strong"),sze=o("pegasus"),lze=o(" \u2014 "),uk=a("a"),ize=o("PegasusConfig"),dze=o(" (Pegasus model)"),cze=l(),Tm=a("li"),Zee=a("strong"),fze=o("perceiver"),mze=o(" \u2014 "),_k=a("a"),gze=o("PerceiverConfig"),hze=o(" (Perceiver model)"),pze=l(),Mm=a("li"),eoe=a("strong"),uze=o("plbart"),_ze=o(" \u2014 "),bk=a("a"),bze=o("PLBartConfig"),vze=o(" (PLBart model)"),Fze=l(),Em=a("li"),ooe=a("strong"),Tze=o("poolformer"),Mze=o(" \u2014 "),vk=a("a"),Eze=o("PoolFormerConfig"),Cze=o(" (PoolFormer model)"),wze=l(),Cm=a("li"),roe=a("strong"),Aze=o("prophetnet"),yze=o(" \u2014 "),Fk=a("a"),Lze=o("ProphetNetConfig"),xze=o(" (ProphetNet model)"),$ze=l(),wm=a("li"),toe=a("strong"),kze=o("qdqbert"),Sze=o(" \u2014 "),Tk=a("a"),Rze=o("QDQBertConfig"),Bze=o(" (QDQBert model)"),Pze=l(),Am=a("li"),aoe=a("strong"),Ize=o("rag"),qze=o(" \u2014 "),Mk=a("a"),Nze=o("RagConfig"),jze=o(" (RAG model)"),Dze=l(),ym=a("li"),noe=a("strong"),Gze=o("realm"),Oze=o(" \u2014 "),Ek=a("a"),Vze=o("RealmConfig"),Xze=o(" (Realm model)"),zze=l(),Lm=a("li"),soe=a("strong"),Qze=o("reformer"),Wze=o(" \u2014 "),Ck=a("a"),Hze=o("ReformerConfig"),Uze=o(" (Reformer model)"),Jze=l(),xm=a("li"),loe=a("strong"),Yze=o("regnet"),Kze=o(" \u2014 "),wk=a("a"),Zze=o("RegNetConfig"),eQe=o(" (RegNet model)"),oQe=l(),$m=a("li"),ioe=a("strong"),rQe=o("rembert"),tQe=o(" \u2014 "),Ak=a("a"),aQe=o("RemBertConfig"),nQe=o(" (RemBERT model)"),sQe=l(),km=a("li"),doe=a("strong"),lQe=o("resnet"),iQe=o(" \u2014 "),yk=a("a"),dQe=o("ResNetConfig"),cQe=o(" (ResNet model)"),fQe=l(),Sm=a("li"),coe=a("strong"),mQe=o("retribert"),gQe=o(" \u2014 "),Lk=a("a"),hQe=o("RetriBertConfig"),pQe=o(" (RetriBERT model)"),uQe=l(),Rm=a("li"),foe=a("strong"),_Qe=o("roberta"),bQe=o(" \u2014 "),xk=a("a"),vQe=o("RobertaConfig"),FQe=o(" (RoBERTa model)"),TQe=l(),Bm=a("li"),moe=a("strong"),MQe=o("roformer"),EQe=o(" \u2014 "),$k=a("a"),CQe=o("RoFormerConfig"),wQe=o(" (RoFormer model)"),AQe=l(),Pm=a("li"),goe=a("strong"),yQe=o("segformer"),LQe=o(" \u2014 "),kk=a("a"),xQe=o("SegformerConfig"),$Qe=o(" (SegFormer model)"),kQe=l(),Im=a("li"),hoe=a("strong"),SQe=o("sew"),RQe=o(" \u2014 "),Sk=a("a"),BQe=o("SEWConfig"),PQe=o(" (SEW model)"),IQe=l(),qm=a("li"),poe=a("strong"),qQe=o("sew-d"),NQe=o(" \u2014 "),Rk=a("a"),jQe=o("SEWDConfig"),DQe=o(" (SEW-D model)"),GQe=l(),Nm=a("li"),uoe=a("strong"),OQe=o("speech-encoder-decoder"),VQe=o(" \u2014 "),Bk=a("a"),XQe=o("SpeechEncoderDecoderConfig"),zQe=o(" (Speech Encoder decoder model)"),QQe=l(),jm=a("li"),_oe=a("strong"),WQe=o("speech_to_text"),HQe=o(" \u2014 "),Pk=a("a"),UQe=o("Speech2TextConfig"),JQe=o(" (Speech2Text model)"),YQe=l(),Dm=a("li"),boe=a("strong"),KQe=o("speech_to_text_2"),ZQe=o(" \u2014 "),Ik=a("a"),eWe=o("Speech2Text2Config"),oWe=o(" (Speech2Text2 model)"),rWe=l(),Gm=a("li"),voe=a("strong"),tWe=o("splinter"),aWe=o(" \u2014 "),qk=a("a"),nWe=o("SplinterConfig"),sWe=o(" (Splinter model)"),lWe=l(),Om=a("li"),Foe=a("strong"),iWe=o("squeezebert"),dWe=o(" \u2014 "),Nk=a("a"),cWe=o("SqueezeBertConfig"),fWe=o(" (SqueezeBERT model)"),mWe=l(),Vm=a("li"),Toe=a("strong"),gWe=o("swin"),hWe=o(" \u2014 "),jk=a("a"),pWe=o("SwinConfig"),uWe=o(" (Swin model)"),_We=l(),Xm=a("li"),Moe=a("strong"),bWe=o("t5"),vWe=o(" \u2014 "),Dk=a("a"),FWe=o("T5Config"),TWe=o(" (T5 model)"),MWe=l(),zm=a("li"),Eoe=a("strong"),EWe=o("tapas"),CWe=o(" \u2014 "),Gk=a("a"),wWe=o("TapasConfig"),AWe=o(" (TAPAS model)"),yWe=l(),Qm=a("li"),Coe=a("strong"),LWe=o("tapex"),xWe=o(" \u2014 "),Ok=a("a"),$We=o("BartConfig"),kWe=o(" (TAPEX model)"),SWe=l(),Wm=a("li"),woe=a("strong"),RWe=o("transfo-xl"),BWe=o(" \u2014 "),Vk=a("a"),PWe=o("TransfoXLConfig"),IWe=o(" (Transformer-XL model)"),qWe=l(),Hm=a("li"),Aoe=a("strong"),NWe=o("trocr"),jWe=o(" \u2014 "),Xk=a("a"),DWe=o("TrOCRConfig"),GWe=o(" (TrOCR model)"),OWe=l(),Um=a("li"),yoe=a("strong"),VWe=o("unispeech"),XWe=o(" \u2014 "),zk=a("a"),zWe=o("UniSpeechConfig"),QWe=o(" (UniSpeech model)"),WWe=l(),Jm=a("li"),Loe=a("strong"),HWe=o("unispeech-sat"),UWe=o(" \u2014 "),Qk=a("a"),JWe=o("UniSpeechSatConfig"),YWe=o(" (UniSpeechSat model)"),KWe=l(),Ym=a("li"),xoe=a("strong"),ZWe=o("van"),eHe=o(" \u2014 "),Wk=a("a"),oHe=o("VanConfig"),rHe=o(" (VAN model)"),tHe=l(),Km=a("li"),$oe=a("strong"),aHe=o("vilt"),nHe=o(" \u2014 "),Hk=a("a"),sHe=o("ViltConfig"),lHe=o(" (ViLT model)"),iHe=l(),Zm=a("li"),koe=a("strong"),dHe=o("vision-encoder-decoder"),cHe=o(" \u2014 "),Uk=a("a"),fHe=o("VisionEncoderDecoderConfig"),mHe=o(" (Vision Encoder decoder model)"),gHe=l(),eg=a("li"),Soe=a("strong"),hHe=o("vision-text-dual-encoder"),pHe=o(" \u2014 "),Jk=a("a"),uHe=o("VisionTextDualEncoderConfig"),_He=o(" (VisionTextDualEncoder model)"),bHe=l(),og=a("li"),Roe=a("strong"),vHe=o("visual_bert"),FHe=o(" \u2014 "),Yk=a("a"),THe=o("VisualBertConfig"),MHe=o(" (VisualBert model)"),EHe=l(),rg=a("li"),Boe=a("strong"),CHe=o("vit"),wHe=o(" \u2014 "),Kk=a("a"),AHe=o("ViTConfig"),yHe=o(" (ViT model)"),LHe=l(),tg=a("li"),Poe=a("strong"),xHe=o("vit_mae"),$He=o(" \u2014 "),Zk=a("a"),kHe=o("ViTMAEConfig"),SHe=o(" (ViTMAE model)"),RHe=l(),ag=a("li"),Ioe=a("strong"),BHe=o("wav2vec2"),PHe=o(" \u2014 "),eS=a("a"),IHe=o("Wav2Vec2Config"),qHe=o(" (Wav2Vec2 model)"),NHe=l(),ng=a("li"),qoe=a("strong"),jHe=o("wavlm"),DHe=o(" \u2014 "),oS=a("a"),GHe=o("WavLMConfig"),OHe=o(" (WavLM model)"),VHe=l(),sg=a("li"),Noe=a("strong"),XHe=o("xglm"),zHe=o(" \u2014 "),rS=a("a"),QHe=o("XGLMConfig"),WHe=o(" (XGLM model)"),HHe=l(),lg=a("li"),joe=a("strong"),UHe=o("xlm"),JHe=o(" \u2014 "),tS=a("a"),YHe=o("XLMConfig"),KHe=o(" (XLM model)"),ZHe=l(),ig=a("li"),Doe=a("strong"),eUe=o("xlm-prophetnet"),oUe=o(" \u2014 "),aS=a("a"),rUe=o("XLMProphetNetConfig"),tUe=o(" (XLMProphetNet model)"),aUe=l(),dg=a("li"),Goe=a("strong"),nUe=o("xlm-roberta"),sUe=o(" \u2014 "),nS=a("a"),lUe=o("XLMRobertaConfig"),iUe=o(" (XLM-RoBERTa model)"),dUe=l(),cg=a("li"),Ooe=a("strong"),cUe=o("xlm-roberta-xl"),fUe=o(" \u2014 "),sS=a("a"),mUe=o("XLMRobertaXLConfig"),gUe=o(" (XLM-RoBERTa-XL model)"),hUe=l(),fg=a("li"),Voe=a("strong"),pUe=o("xlnet"),uUe=o(" \u2014 "),lS=a("a"),_Ue=o("XLNetConfig"),bUe=o(" (XLNet model)"),vUe=l(),mg=a("li"),Xoe=a("strong"),FUe=o("yolos"),TUe=o(" \u2014 "),iS=a("a"),MUe=o("YolosConfig"),EUe=o(" (YOLOS model)"),CUe=l(),gg=a("li"),zoe=a("strong"),wUe=o("yoso"),AUe=o(" \u2014 "),dS=a("a"),yUe=o("YosoConfig"),LUe=o(" (YOSO model)"),xUe=l(),F(hg.$$.fragment),$Ue=l(),pg=a("div"),F(Kw.$$.fragment),kUe=l(),Qoe=a("p"),SUe=o("Register a new configuration for this class."),MPe=l(),bi=a("h2"),ug=a("a"),Woe=a("span"),F(Zw.$$.fragment),RUe=l(),Hoe=a("span"),BUe=o("AutoTokenizer"),EPe=l(),wo=a("div"),F(eA.$$.fragment),PUe=l(),oA=a("p"),IUe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),cS=a("a"),qUe=o("AutoTokenizer.from_pretrained()"),NUe=o(" class method."),jUe=l(),rA=a("p"),DUe=o("This class cannot be instantiated directly using "),Uoe=a("code"),GUe=o("__init__()"),OUe=o(" (throws an error)."),VUe=l(),Cr=a("div"),F(tA.$$.fragment),XUe=l(),Joe=a("p"),zUe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),QUe=l(),Ca=a("p"),WUe=o("The tokenizer class to instantiate is selected based on the "),Yoe=a("code"),HUe=o("model_type"),UUe=o(` property of the config object (either
passed as an argument or loaded from `),Koe=a("code"),JUe=o("pretrained_model_name_or_path"),YUe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zoe=a("code"),KUe=o("pretrained_model_name_or_path"),ZUe=o(":"),eJe=l(),k=a("ul"),Sn=a("li"),ere=a("strong"),oJe=o("albert"),rJe=o(" \u2014 "),fS=a("a"),tJe=o("AlbertTokenizer"),aJe=o(" or "),mS=a("a"),nJe=o("AlbertTokenizerFast"),sJe=o(" (ALBERT model)"),lJe=l(),Rn=a("li"),ore=a("strong"),iJe=o("bart"),dJe=o(" \u2014 "),gS=a("a"),cJe=o("BartTokenizer"),fJe=o(" or "),hS=a("a"),mJe=o("BartTokenizerFast"),gJe=o(" (BART model)"),hJe=l(),Bn=a("li"),rre=a("strong"),pJe=o("barthez"),uJe=o(" \u2014 "),pS=a("a"),_Je=o("BarthezTokenizer"),bJe=o(" or "),uS=a("a"),vJe=o("BarthezTokenizerFast"),FJe=o(" (BARThez model)"),TJe=l(),_g=a("li"),tre=a("strong"),MJe=o("bartpho"),EJe=o(" \u2014 "),_S=a("a"),CJe=o("BartphoTokenizer"),wJe=o(" (BARTpho model)"),AJe=l(),Pn=a("li"),are=a("strong"),yJe=o("bert"),LJe=o(" \u2014 "),bS=a("a"),xJe=o("BertTokenizer"),$Je=o(" or "),vS=a("a"),kJe=o("BertTokenizerFast"),SJe=o(" (BERT model)"),RJe=l(),bg=a("li"),nre=a("strong"),BJe=o("bert-generation"),PJe=o(" \u2014 "),FS=a("a"),IJe=o("BertGenerationTokenizer"),qJe=o(" (Bert Generation model)"),NJe=l(),vg=a("li"),sre=a("strong"),jJe=o("bert-japanese"),DJe=o(" \u2014 "),TS=a("a"),GJe=o("BertJapaneseTokenizer"),OJe=o(" (BertJapanese model)"),VJe=l(),Fg=a("li"),lre=a("strong"),XJe=o("bertweet"),zJe=o(" \u2014 "),MS=a("a"),QJe=o("BertweetTokenizer"),WJe=o(" (Bertweet model)"),HJe=l(),In=a("li"),ire=a("strong"),UJe=o("big_bird"),JJe=o(" \u2014 "),ES=a("a"),YJe=o("BigBirdTokenizer"),KJe=o(" or "),CS=a("a"),ZJe=o("BigBirdTokenizerFast"),eYe=o(" (BigBird model)"),oYe=l(),qn=a("li"),dre=a("strong"),rYe=o("bigbird_pegasus"),tYe=o(" \u2014 "),wS=a("a"),aYe=o("PegasusTokenizer"),nYe=o(" or "),AS=a("a"),sYe=o("PegasusTokenizerFast"),lYe=o(" (BigBirdPegasus model)"),iYe=l(),Nn=a("li"),cre=a("strong"),dYe=o("blenderbot"),cYe=o(" \u2014 "),yS=a("a"),fYe=o("BlenderbotTokenizer"),mYe=o(" or "),LS=a("a"),gYe=o("BlenderbotTokenizerFast"),hYe=o(" (Blenderbot model)"),pYe=l(),Tg=a("li"),fre=a("strong"),uYe=o("blenderbot-small"),_Ye=o(" \u2014 "),xS=a("a"),bYe=o("BlenderbotSmallTokenizer"),vYe=o(" (BlenderbotSmall model)"),FYe=l(),Mg=a("li"),mre=a("strong"),TYe=o("byt5"),MYe=o(" \u2014 "),$S=a("a"),EYe=o("ByT5Tokenizer"),CYe=o(" (ByT5 model)"),wYe=l(),jn=a("li"),gre=a("strong"),AYe=o("camembert"),yYe=o(" \u2014 "),kS=a("a"),LYe=o("CamembertTokenizer"),xYe=o(" or "),SS=a("a"),$Ye=o("CamembertTokenizerFast"),kYe=o(" (CamemBERT model)"),SYe=l(),Eg=a("li"),hre=a("strong"),RYe=o("canine"),BYe=o(" \u2014 "),RS=a("a"),PYe=o("CanineTokenizer"),IYe=o(" (Canine model)"),qYe=l(),Dn=a("li"),pre=a("strong"),NYe=o("clip"),jYe=o(" \u2014 "),BS=a("a"),DYe=o("CLIPTokenizer"),GYe=o(" or "),PS=a("a"),OYe=o("CLIPTokenizerFast"),VYe=o(" (CLIP model)"),XYe=l(),Gn=a("li"),ure=a("strong"),zYe=o("convbert"),QYe=o(" \u2014 "),IS=a("a"),WYe=o("ConvBertTokenizer"),HYe=o(" or "),qS=a("a"),UYe=o("ConvBertTokenizerFast"),JYe=o(" (ConvBERT model)"),YYe=l(),On=a("li"),_re=a("strong"),KYe=o("cpm"),ZYe=o(" \u2014 "),NS=a("a"),eKe=o("CpmTokenizer"),oKe=o(" or "),jS=a("a"),rKe=o("CpmTokenizerFast"),tKe=o(" (CPM model)"),aKe=l(),Cg=a("li"),bre=a("strong"),nKe=o("ctrl"),sKe=o(" \u2014 "),DS=a("a"),lKe=o("CTRLTokenizer"),iKe=o(" (CTRL model)"),dKe=l(),Vn=a("li"),vre=a("strong"),cKe=o("data2vec-text"),fKe=o(" \u2014 "),GS=a("a"),mKe=o("RobertaTokenizer"),gKe=o(" or "),OS=a("a"),hKe=o("RobertaTokenizerFast"),pKe=o(" (Data2VecText model)"),uKe=l(),Xn=a("li"),Fre=a("strong"),_Ke=o("deberta"),bKe=o(" \u2014 "),VS=a("a"),vKe=o("DebertaTokenizer"),FKe=o(" or "),XS=a("a"),TKe=o("DebertaTokenizerFast"),MKe=o(" (DeBERTa model)"),EKe=l(),zn=a("li"),Tre=a("strong"),CKe=o("deberta-v2"),wKe=o(" \u2014 "),zS=a("a"),AKe=o("DebertaV2Tokenizer"),yKe=o(" or "),QS=a("a"),LKe=o("DebertaV2TokenizerFast"),xKe=o(" (DeBERTa-v2 model)"),$Ke=l(),Qn=a("li"),Mre=a("strong"),kKe=o("distilbert"),SKe=o(" \u2014 "),WS=a("a"),RKe=o("DistilBertTokenizer"),BKe=o(" or "),HS=a("a"),PKe=o("DistilBertTokenizerFast"),IKe=o(" (DistilBERT model)"),qKe=l(),Wn=a("li"),Ere=a("strong"),NKe=o("dpr"),jKe=o(" \u2014 "),US=a("a"),DKe=o("DPRQuestionEncoderTokenizer"),GKe=o(" or "),JS=a("a"),OKe=o("DPRQuestionEncoderTokenizerFast"),VKe=o(" (DPR model)"),XKe=l(),Hn=a("li"),Cre=a("strong"),zKe=o("electra"),QKe=o(" \u2014 "),YS=a("a"),WKe=o("ElectraTokenizer"),HKe=o(" or "),KS=a("a"),UKe=o("ElectraTokenizerFast"),JKe=o(" (ELECTRA model)"),YKe=l(),wg=a("li"),wre=a("strong"),KKe=o("flaubert"),ZKe=o(" \u2014 "),ZS=a("a"),eZe=o("FlaubertTokenizer"),oZe=o(" (FlauBERT model)"),rZe=l(),Un=a("li"),Are=a("strong"),tZe=o("fnet"),aZe=o(" \u2014 "),eR=a("a"),nZe=o("FNetTokenizer"),sZe=o(" or "),oR=a("a"),lZe=o("FNetTokenizerFast"),iZe=o(" (FNet model)"),dZe=l(),Ag=a("li"),yre=a("strong"),cZe=o("fsmt"),fZe=o(" \u2014 "),rR=a("a"),mZe=o("FSMTTokenizer"),gZe=o(" (FairSeq Machine-Translation model)"),hZe=l(),Jn=a("li"),Lre=a("strong"),pZe=o("funnel"),uZe=o(" \u2014 "),tR=a("a"),_Ze=o("FunnelTokenizer"),bZe=o(" or "),aR=a("a"),vZe=o("FunnelTokenizerFast"),FZe=o(" (Funnel Transformer model)"),TZe=l(),Yn=a("li"),xre=a("strong"),MZe=o("gpt2"),EZe=o(" \u2014 "),nR=a("a"),CZe=o("GPT2Tokenizer"),wZe=o(" or "),sR=a("a"),AZe=o("GPT2TokenizerFast"),yZe=o(" (OpenAI GPT-2 model)"),LZe=l(),Kn=a("li"),$re=a("strong"),xZe=o("gpt_neo"),$Ze=o(" \u2014 "),lR=a("a"),kZe=o("GPT2Tokenizer"),SZe=o(" or "),iR=a("a"),RZe=o("GPT2TokenizerFast"),BZe=o(" (GPT Neo model)"),PZe=l(),Zn=a("li"),kre=a("strong"),IZe=o("gptj"),qZe=o(" \u2014 "),dR=a("a"),NZe=o("GPT2Tokenizer"),jZe=o(" or "),cR=a("a"),DZe=o("GPT2TokenizerFast"),GZe=o(" (GPT-J model)"),OZe=l(),es=a("li"),Sre=a("strong"),VZe=o("herbert"),XZe=o(" \u2014 "),fR=a("a"),zZe=o("HerbertTokenizer"),QZe=o(" or "),mR=a("a"),WZe=o("HerbertTokenizerFast"),HZe=o(" (HerBERT model)"),UZe=l(),yg=a("li"),Rre=a("strong"),JZe=o("hubert"),YZe=o(" \u2014 "),gR=a("a"),KZe=o("Wav2Vec2CTCTokenizer"),ZZe=o(" (Hubert model)"),eeo=l(),os=a("li"),Bre=a("strong"),oeo=o("ibert"),reo=o(" \u2014 "),hR=a("a"),teo=o("RobertaTokenizer"),aeo=o(" or "),pR=a("a"),neo=o("RobertaTokenizerFast"),seo=o(" (I-BERT model)"),leo=l(),rs=a("li"),Pre=a("strong"),ieo=o("layoutlm"),deo=o(" \u2014 "),uR=a("a"),ceo=o("LayoutLMTokenizer"),feo=o(" or "),_R=a("a"),meo=o("LayoutLMTokenizerFast"),geo=o(" (LayoutLM model)"),heo=l(),ts=a("li"),Ire=a("strong"),peo=o("layoutlmv2"),ueo=o(" \u2014 "),bR=a("a"),_eo=o("LayoutLMv2Tokenizer"),beo=o(" or "),vR=a("a"),veo=o("LayoutLMv2TokenizerFast"),Feo=o(" (LayoutLMv2 model)"),Teo=l(),as=a("li"),qre=a("strong"),Meo=o("layoutxlm"),Eeo=o(" \u2014 "),FR=a("a"),Ceo=o("LayoutXLMTokenizer"),weo=o(" or "),TR=a("a"),Aeo=o("LayoutXLMTokenizerFast"),yeo=o(" (LayoutXLM model)"),Leo=l(),ns=a("li"),Nre=a("strong"),xeo=o("led"),$eo=o(" \u2014 "),MR=a("a"),keo=o("LEDTokenizer"),Seo=o(" or "),ER=a("a"),Reo=o("LEDTokenizerFast"),Beo=o(" (LED model)"),Peo=l(),ss=a("li"),jre=a("strong"),Ieo=o("longformer"),qeo=o(" \u2014 "),CR=a("a"),Neo=o("LongformerTokenizer"),jeo=o(" or "),wR=a("a"),Deo=o("LongformerTokenizerFast"),Geo=o(" (Longformer model)"),Oeo=l(),Lg=a("li"),Dre=a("strong"),Veo=o("luke"),Xeo=o(" \u2014 "),AR=a("a"),zeo=o("LukeTokenizer"),Qeo=o(" (LUKE model)"),Weo=l(),ls=a("li"),Gre=a("strong"),Heo=o("lxmert"),Ueo=o(" \u2014 "),yR=a("a"),Jeo=o("LxmertTokenizer"),Yeo=o(" or "),LR=a("a"),Keo=o("LxmertTokenizerFast"),Zeo=o(" (LXMERT model)"),eoo=l(),xg=a("li"),Ore=a("strong"),ooo=o("m2m_100"),roo=o(" \u2014 "),xR=a("a"),too=o("M2M100Tokenizer"),aoo=o(" (M2M100 model)"),noo=l(),$g=a("li"),Vre=a("strong"),soo=o("marian"),loo=o(" \u2014 "),$R=a("a"),ioo=o("MarianTokenizer"),doo=o(" (Marian model)"),coo=l(),is=a("li"),Xre=a("strong"),foo=o("mbart"),moo=o(" \u2014 "),kR=a("a"),goo=o("MBartTokenizer"),hoo=o(" or "),SR=a("a"),poo=o("MBartTokenizerFast"),uoo=o(" (mBART model)"),_oo=l(),ds=a("li"),zre=a("strong"),boo=o("mbart50"),voo=o(" \u2014 "),RR=a("a"),Foo=o("MBart50Tokenizer"),Too=o(" or "),BR=a("a"),Moo=o("MBart50TokenizerFast"),Eoo=o(" (mBART-50 model)"),Coo=l(),cs=a("li"),Qre=a("strong"),woo=o("megatron-bert"),Aoo=o(" \u2014 "),PR=a("a"),yoo=o("BertTokenizer"),Loo=o(" or "),IR=a("a"),xoo=o("BertTokenizerFast"),$oo=o(" (MegatronBert model)"),koo=l(),kg=a("li"),Wre=a("strong"),Soo=o("mluke"),Roo=o(" \u2014 "),qR=a("a"),Boo=o("MLukeTokenizer"),Poo=o(" (mLUKE model)"),Ioo=l(),fs=a("li"),Hre=a("strong"),qoo=o("mobilebert"),Noo=o(" \u2014 "),NR=a("a"),joo=o("MobileBertTokenizer"),Doo=o(" or "),jR=a("a"),Goo=o("MobileBertTokenizerFast"),Ooo=o(" (MobileBERT model)"),Voo=l(),ms=a("li"),Ure=a("strong"),Xoo=o("mpnet"),zoo=o(" \u2014 "),DR=a("a"),Qoo=o("MPNetTokenizer"),Woo=o(" or "),GR=a("a"),Hoo=o("MPNetTokenizerFast"),Uoo=o(" (MPNet model)"),Joo=l(),gs=a("li"),Jre=a("strong"),Yoo=o("mt5"),Koo=o(" \u2014 "),OR=a("a"),Zoo=o("MT5Tokenizer"),ero=o(" or "),VR=a("a"),oro=o("MT5TokenizerFast"),rro=o(" (mT5 model)"),tro=l(),hs=a("li"),Yre=a("strong"),aro=o("nystromformer"),nro=o(" \u2014 "),XR=a("a"),sro=o("AlbertTokenizer"),lro=o(" or "),zR=a("a"),iro=o("AlbertTokenizerFast"),dro=o(" (Nystromformer model)"),cro=l(),ps=a("li"),Kre=a("strong"),fro=o("openai-gpt"),mro=o(" \u2014 "),QR=a("a"),gro=o("OpenAIGPTTokenizer"),hro=o(" or "),WR=a("a"),pro=o("OpenAIGPTTokenizerFast"),uro=o(" (OpenAI GPT model)"),_ro=l(),us=a("li"),Zre=a("strong"),bro=o("pegasus"),vro=o(" \u2014 "),HR=a("a"),Fro=o("PegasusTokenizer"),Tro=o(" or "),UR=a("a"),Mro=o("PegasusTokenizerFast"),Ero=o(" (Pegasus model)"),Cro=l(),Sg=a("li"),ete=a("strong"),wro=o("perceiver"),Aro=o(" \u2014 "),JR=a("a"),yro=o("PerceiverTokenizer"),Lro=o(" (Perceiver model)"),xro=l(),Rg=a("li"),ote=a("strong"),$ro=o("phobert"),kro=o(" \u2014 "),YR=a("a"),Sro=o("PhobertTokenizer"),Rro=o(" (PhoBERT model)"),Bro=l(),Bg=a("li"),rte=a("strong"),Pro=o("plbart"),Iro=o(" \u2014 "),KR=a("a"),qro=o("PLBartTokenizer"),Nro=o(" (PLBart model)"),jro=l(),Pg=a("li"),tte=a("strong"),Dro=o("prophetnet"),Gro=o(" \u2014 "),ZR=a("a"),Oro=o("ProphetNetTokenizer"),Vro=o(" (ProphetNet model)"),Xro=l(),_s=a("li"),ate=a("strong"),zro=o("qdqbert"),Qro=o(" \u2014 "),eB=a("a"),Wro=o("BertTokenizer"),Hro=o(" or "),oB=a("a"),Uro=o("BertTokenizerFast"),Jro=o(" (QDQBert model)"),Yro=l(),Ig=a("li"),nte=a("strong"),Kro=o("rag"),Zro=o(" \u2014 "),rB=a("a"),eto=o("RagTokenizer"),oto=o(" (RAG model)"),rto=l(),bs=a("li"),ste=a("strong"),tto=o("realm"),ato=o(" \u2014 "),tB=a("a"),nto=o("RealmTokenizer"),sto=o(" or "),aB=a("a"),lto=o("RealmTokenizerFast"),ito=o(" (Realm model)"),dto=l(),vs=a("li"),lte=a("strong"),cto=o("reformer"),fto=o(" \u2014 "),nB=a("a"),mto=o("ReformerTokenizer"),gto=o(" or "),sB=a("a"),hto=o("ReformerTokenizerFast"),pto=o(" (Reformer model)"),uto=l(),Fs=a("li"),ite=a("strong"),_to=o("rembert"),bto=o(" \u2014 "),lB=a("a"),vto=o("RemBertTokenizer"),Fto=o(" or "),iB=a("a"),Tto=o("RemBertTokenizerFast"),Mto=o(" (RemBERT model)"),Eto=l(),Ts=a("li"),dte=a("strong"),Cto=o("retribert"),wto=o(" \u2014 "),dB=a("a"),Ato=o("RetriBertTokenizer"),yto=o(" or "),cB=a("a"),Lto=o("RetriBertTokenizerFast"),xto=o(" (RetriBERT model)"),$to=l(),Ms=a("li"),cte=a("strong"),kto=o("roberta"),Sto=o(" \u2014 "),fB=a("a"),Rto=o("RobertaTokenizer"),Bto=o(" or "),mB=a("a"),Pto=o("RobertaTokenizerFast"),Ito=o(" (RoBERTa model)"),qto=l(),Es=a("li"),fte=a("strong"),Nto=o("roformer"),jto=o(" \u2014 "),gB=a("a"),Dto=o("RoFormerTokenizer"),Gto=o(" or "),hB=a("a"),Oto=o("RoFormerTokenizerFast"),Vto=o(" (RoFormer model)"),Xto=l(),qg=a("li"),mte=a("strong"),zto=o("speech_to_text"),Qto=o(" \u2014 "),pB=a("a"),Wto=o("Speech2TextTokenizer"),Hto=o(" (Speech2Text model)"),Uto=l(),Ng=a("li"),gte=a("strong"),Jto=o("speech_to_text_2"),Yto=o(" \u2014 "),uB=a("a"),Kto=o("Speech2Text2Tokenizer"),Zto=o(" (Speech2Text2 model)"),eao=l(),Cs=a("li"),hte=a("strong"),oao=o("splinter"),rao=o(" \u2014 "),_B=a("a"),tao=o("SplinterTokenizer"),aao=o(" or "),bB=a("a"),nao=o("SplinterTokenizerFast"),sao=o(" (Splinter model)"),lao=l(),ws=a("li"),pte=a("strong"),iao=o("squeezebert"),dao=o(" \u2014 "),vB=a("a"),cao=o("SqueezeBertTokenizer"),fao=o(" or "),FB=a("a"),mao=o("SqueezeBertTokenizerFast"),gao=o(" (SqueezeBERT model)"),hao=l(),As=a("li"),ute=a("strong"),pao=o("t5"),uao=o(" \u2014 "),TB=a("a"),_ao=o("T5Tokenizer"),bao=o(" or "),MB=a("a"),vao=o("T5TokenizerFast"),Fao=o(" (T5 model)"),Tao=l(),jg=a("li"),_te=a("strong"),Mao=o("tapas"),Eao=o(" \u2014 "),EB=a("a"),Cao=o("TapasTokenizer"),wao=o(" (TAPAS model)"),Aao=l(),Dg=a("li"),bte=a("strong"),yao=o("tapex"),Lao=o(" \u2014 "),CB=a("a"),xao=o("TapexTokenizer"),$ao=o(" (TAPEX model)"),kao=l(),Gg=a("li"),vte=a("strong"),Sao=o("transfo-xl"),Rao=o(" \u2014 "),wB=a("a"),Bao=o("TransfoXLTokenizer"),Pao=o(" (Transformer-XL model)"),Iao=l(),ys=a("li"),Fte=a("strong"),qao=o("visual_bert"),Nao=o(" \u2014 "),AB=a("a"),jao=o("BertTokenizer"),Dao=o(" or "),yB=a("a"),Gao=o("BertTokenizerFast"),Oao=o(" (VisualBert model)"),Vao=l(),Og=a("li"),Tte=a("strong"),Xao=o("wav2vec2"),zao=o(" \u2014 "),LB=a("a"),Qao=o("Wav2Vec2CTCTokenizer"),Wao=o(" (Wav2Vec2 model)"),Hao=l(),Vg=a("li"),Mte=a("strong"),Uao=o("wav2vec2_phoneme"),Jao=o(" \u2014 "),xB=a("a"),Yao=o("Wav2Vec2PhonemeCTCTokenizer"),Kao=o(" (Wav2Vec2Phoneme model)"),Zao=l(),Ls=a("li"),Ete=a("strong"),eno=o("xglm"),ono=o(" \u2014 "),$B=a("a"),rno=o("XGLMTokenizer"),tno=o(" or "),kB=a("a"),ano=o("XGLMTokenizerFast"),nno=o(" (XGLM model)"),sno=l(),Xg=a("li"),Cte=a("strong"),lno=o("xlm"),ino=o(" \u2014 "),SB=a("a"),dno=o("XLMTokenizer"),cno=o(" (XLM model)"),fno=l(),zg=a("li"),wte=a("strong"),mno=o("xlm-prophetnet"),gno=o(" \u2014 "),RB=a("a"),hno=o("XLMProphetNetTokenizer"),pno=o(" (XLMProphetNet model)"),uno=l(),xs=a("li"),Ate=a("strong"),_no=o("xlm-roberta"),bno=o(" \u2014 "),BB=a("a"),vno=o("XLMRobertaTokenizer"),Fno=o(" or "),PB=a("a"),Tno=o("XLMRobertaTokenizerFast"),Mno=o(" (XLM-RoBERTa model)"),Eno=l(),$s=a("li"),yte=a("strong"),Cno=o("xlm-roberta-xl"),wno=o(" \u2014 "),IB=a("a"),Ano=o("RobertaTokenizer"),yno=o(" or "),qB=a("a"),Lno=o("RobertaTokenizerFast"),xno=o(" (XLM-RoBERTa-XL model)"),$no=l(),ks=a("li"),Lte=a("strong"),kno=o("xlnet"),Sno=o(" \u2014 "),NB=a("a"),Rno=o("XLNetTokenizer"),Bno=o(" or "),jB=a("a"),Pno=o("XLNetTokenizerFast"),Ino=o(" (XLNet model)"),qno=l(),Ss=a("li"),xte=a("strong"),Nno=o("yoso"),jno=o(" \u2014 "),DB=a("a"),Dno=o("AlbertTokenizer"),Gno=o(" or "),GB=a("a"),Ono=o("AlbertTokenizerFast"),Vno=o(" (YOSO model)"),Xno=l(),F(Qg.$$.fragment),zno=l(),Wg=a("div"),F(aA.$$.fragment),Qno=l(),$te=a("p"),Wno=o("Register a new tokenizer in this mapping."),CPe=l(),vi=a("h2"),Hg=a("a"),kte=a("span"),F(nA.$$.fragment),Hno=l(),Ste=a("span"),Uno=o("AutoFeatureExtractor"),wPe=l(),Ao=a("div"),F(sA.$$.fragment),Jno=l(),lA=a("p"),Yno=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),OB=a("a"),Kno=o("AutoFeatureExtractor.from_pretrained()"),Zno=o(" class method."),eso=l(),iA=a("p"),oso=o("This class cannot be instantiated directly using "),Rte=a("code"),rso=o("__init__()"),tso=o(" (throws an error)."),aso=l(),Qe=a("div"),F(dA.$$.fragment),nso=l(),Bte=a("p"),sso=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),lso=l(),wa=a("p"),iso=o("The feature extractor class to instantiate is selected based on the "),Pte=a("code"),dso=o("model_type"),cso=o(` property of the config object
(either passed as an argument or loaded from `),Ite=a("code"),fso=o("pretrained_model_name_or_path"),mso=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),qte=a("code"),gso=o("pretrained_model_name_or_path"),hso=o(":"),pso=l(),te=a("ul"),Ug=a("li"),Nte=a("strong"),uso=o("beit"),_so=o(" \u2014 "),VB=a("a"),bso=o("BeitFeatureExtractor"),vso=o(" (BEiT model)"),Fso=l(),Jg=a("li"),jte=a("strong"),Tso=o("clip"),Mso=o(" \u2014 "),XB=a("a"),Eso=o("CLIPFeatureExtractor"),Cso=o(" (CLIP model)"),wso=l(),Yg=a("li"),Dte=a("strong"),Aso=o("convnext"),yso=o(" \u2014 "),zB=a("a"),Lso=o("ConvNextFeatureExtractor"),xso=o(" (ConvNext model)"),$so=l(),Kg=a("li"),Gte=a("strong"),kso=o("data2vec-audio"),Sso=o(" \u2014 "),QB=a("a"),Rso=o("Wav2Vec2FeatureExtractor"),Bso=o(" (Data2VecAudio model)"),Pso=l(),Zg=a("li"),Ote=a("strong"),Iso=o("data2vec-vision"),qso=o(" \u2014 "),WB=a("a"),Nso=o("BeitFeatureExtractor"),jso=o(" (Data2VecVision model)"),Dso=l(),eh=a("li"),Vte=a("strong"),Gso=o("deit"),Oso=o(" \u2014 "),HB=a("a"),Vso=o("DeiTFeatureExtractor"),Xso=o(" (DeiT model)"),zso=l(),oh=a("li"),Xte=a("strong"),Qso=o("detr"),Wso=o(" \u2014 "),UB=a("a"),Hso=o("DetrFeatureExtractor"),Uso=o(" (DETR model)"),Jso=l(),rh=a("li"),zte=a("strong"),Yso=o("dpt"),Kso=o(" \u2014 "),JB=a("a"),Zso=o("DPTFeatureExtractor"),elo=o(" (DPT model)"),olo=l(),th=a("li"),Qte=a("strong"),rlo=o("glpn"),tlo=o(" \u2014 "),YB=a("a"),alo=o("GLPNFeatureExtractor"),nlo=o(" (GLPN model)"),slo=l(),ah=a("li"),Wte=a("strong"),llo=o("hubert"),ilo=o(" \u2014 "),KB=a("a"),dlo=o("Wav2Vec2FeatureExtractor"),clo=o(" (Hubert model)"),flo=l(),nh=a("li"),Hte=a("strong"),mlo=o("layoutlmv2"),glo=o(" \u2014 "),ZB=a("a"),hlo=o("LayoutLMv2FeatureExtractor"),plo=o(" (LayoutLMv2 model)"),ulo=l(),sh=a("li"),Ute=a("strong"),_lo=o("maskformer"),blo=o(" \u2014 "),eP=a("a"),vlo=o("MaskFormerFeatureExtractor"),Flo=o(" (MaskFormer model)"),Tlo=l(),lh=a("li"),Jte=a("strong"),Mlo=o("perceiver"),Elo=o(" \u2014 "),oP=a("a"),Clo=o("PerceiverFeatureExtractor"),wlo=o(" (Perceiver model)"),Alo=l(),ih=a("li"),Yte=a("strong"),ylo=o("poolformer"),Llo=o(" \u2014 "),rP=a("a"),xlo=o("PoolFormerFeatureExtractor"),$lo=o(" (PoolFormer model)"),klo=l(),dh=a("li"),Kte=a("strong"),Slo=o("regnet"),Rlo=o(" \u2014 "),tP=a("a"),Blo=o("ConvNextFeatureExtractor"),Plo=o(" (RegNet model)"),Ilo=l(),ch=a("li"),Zte=a("strong"),qlo=o("resnet"),Nlo=o(" \u2014 "),aP=a("a"),jlo=o("ConvNextFeatureExtractor"),Dlo=o(" (ResNet model)"),Glo=l(),fh=a("li"),eae=a("strong"),Olo=o("segformer"),Vlo=o(" \u2014 "),nP=a("a"),Xlo=o("SegformerFeatureExtractor"),zlo=o(" (SegFormer model)"),Qlo=l(),mh=a("li"),oae=a("strong"),Wlo=o("speech_to_text"),Hlo=o(" \u2014 "),sP=a("a"),Ulo=o("Speech2TextFeatureExtractor"),Jlo=o(" (Speech2Text model)"),Ylo=l(),gh=a("li"),rae=a("strong"),Klo=o("swin"),Zlo=o(" \u2014 "),lP=a("a"),eio=o("ViTFeatureExtractor"),oio=o(" (Swin model)"),rio=l(),hh=a("li"),tae=a("strong"),tio=o("van"),aio=o(" \u2014 "),iP=a("a"),nio=o("ConvNextFeatureExtractor"),sio=o(" (VAN model)"),lio=l(),ph=a("li"),aae=a("strong"),iio=o("vit"),dio=o(" \u2014 "),dP=a("a"),cio=o("ViTFeatureExtractor"),fio=o(" (ViT model)"),mio=l(),uh=a("li"),nae=a("strong"),gio=o("vit_mae"),hio=o(" \u2014 "),cP=a("a"),pio=o("ViTFeatureExtractor"),uio=o(" (ViTMAE model)"),_io=l(),_h=a("li"),sae=a("strong"),bio=o("wav2vec2"),vio=o(" \u2014 "),fP=a("a"),Fio=o("Wav2Vec2FeatureExtractor"),Tio=o(" (Wav2Vec2 model)"),Mio=l(),bh=a("li"),lae=a("strong"),Eio=o("yolos"),Cio=o(" \u2014 "),mP=a("a"),wio=o("YolosFeatureExtractor"),Aio=o(" (YOLOS model)"),yio=l(),F(vh.$$.fragment),Lio=l(),F(Fh.$$.fragment),xio=l(),Th=a("div"),F(cA.$$.fragment),$io=l(),iae=a("p"),kio=o("Register a new feature extractor for this class."),APe=l(),Fi=a("h2"),Mh=a("a"),dae=a("span"),F(fA.$$.fragment),Sio=l(),cae=a("span"),Rio=o("AutoProcessor"),yPe=l(),yo=a("div"),F(mA.$$.fragment),Bio=l(),gA=a("p"),Pio=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),gP=a("a"),Iio=o("AutoProcessor.from_pretrained()"),qio=o(" class method."),Nio=l(),hA=a("p"),jio=o("This class cannot be instantiated directly using "),fae=a("code"),Dio=o("__init__()"),Gio=o(" (throws an error)."),Oio=l(),We=a("div"),F(pA.$$.fragment),Vio=l(),mae=a("p"),Xio=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),zio=l(),Ti=a("p"),Qio=o("The processor class to instantiate is selected based on the "),gae=a("code"),Wio=o("model_type"),Hio=o(` property of the config object (either
passed as an argument or loaded from `),hae=a("code"),Uio=o("pretrained_model_name_or_path"),Jio=o(" if possible):"),Yio=l(),be=a("ul"),Eh=a("li"),pae=a("strong"),Kio=o("clip"),Zio=o(" \u2014 "),hP=a("a"),edo=o("CLIPProcessor"),odo=o(" (CLIP model)"),rdo=l(),Ch=a("li"),uae=a("strong"),tdo=o("layoutlmv2"),ado=o(" \u2014 "),pP=a("a"),ndo=o("LayoutLMv2Processor"),sdo=o(" (LayoutLMv2 model)"),ldo=l(),wh=a("li"),_ae=a("strong"),ido=o("layoutxlm"),ddo=o(" \u2014 "),uP=a("a"),cdo=o("LayoutXLMProcessor"),fdo=o(" (LayoutXLM model)"),mdo=l(),Ah=a("li"),bae=a("strong"),gdo=o("sew"),hdo=o(" \u2014 "),_P=a("a"),pdo=o("Wav2Vec2Processor"),udo=o(" (SEW model)"),_do=l(),yh=a("li"),vae=a("strong"),bdo=o("sew-d"),vdo=o(" \u2014 "),bP=a("a"),Fdo=o("Wav2Vec2Processor"),Tdo=o(" (SEW-D model)"),Mdo=l(),Lh=a("li"),Fae=a("strong"),Edo=o("speech_to_text"),Cdo=o(" \u2014 "),vP=a("a"),wdo=o("Speech2TextProcessor"),Ado=o(" (Speech2Text model)"),ydo=l(),xh=a("li"),Tae=a("strong"),Ldo=o("speech_to_text_2"),xdo=o(" \u2014 "),FP=a("a"),$do=o("Speech2Text2Processor"),kdo=o(" (Speech2Text2 model)"),Sdo=l(),$h=a("li"),Mae=a("strong"),Rdo=o("trocr"),Bdo=o(" \u2014 "),TP=a("a"),Pdo=o("TrOCRProcessor"),Ido=o(" (TrOCR model)"),qdo=l(),kh=a("li"),Eae=a("strong"),Ndo=o("unispeech"),jdo=o(" \u2014 "),MP=a("a"),Ddo=o("Wav2Vec2Processor"),Gdo=o(" (UniSpeech model)"),Odo=l(),Sh=a("li"),Cae=a("strong"),Vdo=o("unispeech-sat"),Xdo=o(" \u2014 "),EP=a("a"),zdo=o("Wav2Vec2Processor"),Qdo=o(" (UniSpeechSat model)"),Wdo=l(),Rh=a("li"),wae=a("strong"),Hdo=o("vilt"),Udo=o(" \u2014 "),CP=a("a"),Jdo=o("ViltProcessor"),Ydo=o(" (ViLT model)"),Kdo=l(),Bh=a("li"),Aae=a("strong"),Zdo=o("vision-text-dual-encoder"),eco=o(" \u2014 "),wP=a("a"),oco=o("VisionTextDualEncoderProcessor"),rco=o(" (VisionTextDualEncoder model)"),tco=l(),Ph=a("li"),yae=a("strong"),aco=o("wav2vec2"),nco=o(" \u2014 "),AP=a("a"),sco=o("Wav2Vec2Processor"),lco=o(" (Wav2Vec2 model)"),ico=l(),Ih=a("li"),Lae=a("strong"),dco=o("wavlm"),cco=o(" \u2014 "),yP=a("a"),fco=o("Wav2Vec2Processor"),mco=o(" (WavLM model)"),gco=l(),F(qh.$$.fragment),hco=l(),F(Nh.$$.fragment),pco=l(),jh=a("div"),F(uA.$$.fragment),uco=l(),xae=a("p"),_co=o("Register a new processor for this class."),LPe=l(),Mi=a("h2"),Dh=a("a"),$ae=a("span"),F(_A.$$.fragment),bco=l(),kae=a("span"),vco=o("AutoModel"),xPe=l(),Lo=a("div"),F(bA.$$.fragment),Fco=l(),Ei=a("p"),Tco=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),LP=a("a"),Mco=o("from_pretrained()"),Eco=o(" class method or the "),xP=a("a"),Cco=o("from_config()"),wco=o(` class
method.`),Aco=l(),vA=a("p"),yco=o("This class cannot be instantiated directly using "),Sae=a("code"),Lco=o("__init__()"),xco=o(" (throws an error)."),$co=l(),ot=a("div"),F(FA.$$.fragment),kco=l(),Rae=a("p"),Sco=o("Instantiates one of the base model classes of the library from a configuration."),Rco=l(),Ci=a("p"),Bco=o(`Note:
Loading a model from its configuration file does `),Bae=a("strong"),Pco=o("not"),Ico=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$P=a("a"),qco=o("from_pretrained()"),Nco=o(" to load the model weights."),jco=l(),F(Gh.$$.fragment),Dco=l(),He=a("div"),F(TA.$$.fragment),Gco=l(),Pae=a("p"),Oco=o("Instantiate one of the base model classes of the library from a pretrained model."),Vco=l(),Aa=a("p"),Xco=o("The model class to instantiate is selected based on the "),Iae=a("code"),zco=o("model_type"),Qco=o(` property of the config object (either
passed as an argument or loaded from `),qae=a("code"),Wco=o("pretrained_model_name_or_path"),Hco=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nae=a("code"),Uco=o("pretrained_model_name_or_path"),Jco=o(":"),Yco=l(),x=a("ul"),Oh=a("li"),jae=a("strong"),Kco=o("albert"),Zco=o(" \u2014 "),kP=a("a"),efo=o("AlbertModel"),ofo=o(" (ALBERT model)"),rfo=l(),Vh=a("li"),Dae=a("strong"),tfo=o("bart"),afo=o(" \u2014 "),SP=a("a"),nfo=o("BartModel"),sfo=o(" (BART model)"),lfo=l(),Xh=a("li"),Gae=a("strong"),ifo=o("beit"),dfo=o(" \u2014 "),RP=a("a"),cfo=o("BeitModel"),ffo=o(" (BEiT model)"),mfo=l(),zh=a("li"),Oae=a("strong"),gfo=o("bert"),hfo=o(" \u2014 "),BP=a("a"),pfo=o("BertModel"),ufo=o(" (BERT model)"),_fo=l(),Qh=a("li"),Vae=a("strong"),bfo=o("bert-generation"),vfo=o(" \u2014 "),PP=a("a"),Ffo=o("BertGenerationEncoder"),Tfo=o(" (Bert Generation model)"),Mfo=l(),Wh=a("li"),Xae=a("strong"),Efo=o("big_bird"),Cfo=o(" \u2014 "),IP=a("a"),wfo=o("BigBirdModel"),Afo=o(" (BigBird model)"),yfo=l(),Hh=a("li"),zae=a("strong"),Lfo=o("bigbird_pegasus"),xfo=o(" \u2014 "),qP=a("a"),$fo=o("BigBirdPegasusModel"),kfo=o(" (BigBirdPegasus model)"),Sfo=l(),Uh=a("li"),Qae=a("strong"),Rfo=o("blenderbot"),Bfo=o(" \u2014 "),NP=a("a"),Pfo=o("BlenderbotModel"),Ifo=o(" (Blenderbot model)"),qfo=l(),Jh=a("li"),Wae=a("strong"),Nfo=o("blenderbot-small"),jfo=o(" \u2014 "),jP=a("a"),Dfo=o("BlenderbotSmallModel"),Gfo=o(" (BlenderbotSmall model)"),Ofo=l(),Yh=a("li"),Hae=a("strong"),Vfo=o("camembert"),Xfo=o(" \u2014 "),DP=a("a"),zfo=o("CamembertModel"),Qfo=o(" (CamemBERT model)"),Wfo=l(),Kh=a("li"),Uae=a("strong"),Hfo=o("canine"),Ufo=o(" \u2014 "),GP=a("a"),Jfo=o("CanineModel"),Yfo=o(" (Canine model)"),Kfo=l(),Zh=a("li"),Jae=a("strong"),Zfo=o("clip"),emo=o(" \u2014 "),OP=a("a"),omo=o("CLIPModel"),rmo=o(" (CLIP model)"),tmo=l(),ep=a("li"),Yae=a("strong"),amo=o("convbert"),nmo=o(" \u2014 "),VP=a("a"),smo=o("ConvBertModel"),lmo=o(" (ConvBERT model)"),imo=l(),op=a("li"),Kae=a("strong"),dmo=o("convnext"),cmo=o(" \u2014 "),XP=a("a"),fmo=o("ConvNextModel"),mmo=o(" (ConvNext model)"),gmo=l(),rp=a("li"),Zae=a("strong"),hmo=o("ctrl"),pmo=o(" \u2014 "),zP=a("a"),umo=o("CTRLModel"),_mo=o(" (CTRL model)"),bmo=l(),tp=a("li"),ene=a("strong"),vmo=o("data2vec-audio"),Fmo=o(" \u2014 "),QP=a("a"),Tmo=o("Data2VecAudioModel"),Mmo=o(" (Data2VecAudio model)"),Emo=l(),ap=a("li"),one=a("strong"),Cmo=o("data2vec-text"),wmo=o(" \u2014 "),WP=a("a"),Amo=o("Data2VecTextModel"),ymo=o(" (Data2VecText model)"),Lmo=l(),np=a("li"),rne=a("strong"),xmo=o("data2vec-vision"),$mo=o(" \u2014 "),HP=a("a"),kmo=o("Data2VecVisionModel"),Smo=o(" (Data2VecVision model)"),Rmo=l(),sp=a("li"),tne=a("strong"),Bmo=o("deberta"),Pmo=o(" \u2014 "),UP=a("a"),Imo=o("DebertaModel"),qmo=o(" (DeBERTa model)"),Nmo=l(),lp=a("li"),ane=a("strong"),jmo=o("deberta-v2"),Dmo=o(" \u2014 "),JP=a("a"),Gmo=o("DebertaV2Model"),Omo=o(" (DeBERTa-v2 model)"),Vmo=l(),ip=a("li"),nne=a("strong"),Xmo=o("decision_transformer"),zmo=o(" \u2014 "),YP=a("a"),Qmo=o("DecisionTransformerModel"),Wmo=o(" (Decision Transformer model)"),Hmo=l(),dp=a("li"),sne=a("strong"),Umo=o("deit"),Jmo=o(" \u2014 "),KP=a("a"),Ymo=o("DeiTModel"),Kmo=o(" (DeiT model)"),Zmo=l(),cp=a("li"),lne=a("strong"),ego=o("detr"),ogo=o(" \u2014 "),ZP=a("a"),rgo=o("DetrModel"),tgo=o(" (DETR model)"),ago=l(),fp=a("li"),ine=a("strong"),ngo=o("distilbert"),sgo=o(" \u2014 "),eI=a("a"),lgo=o("DistilBertModel"),igo=o(" (DistilBERT model)"),dgo=l(),mp=a("li"),dne=a("strong"),cgo=o("dpr"),fgo=o(" \u2014 "),oI=a("a"),mgo=o("DPRQuestionEncoder"),ggo=o(" (DPR model)"),hgo=l(),gp=a("li"),cne=a("strong"),pgo=o("dpt"),ugo=o(" \u2014 "),rI=a("a"),_go=o("DPTModel"),bgo=o(" (DPT model)"),vgo=l(),hp=a("li"),fne=a("strong"),Fgo=o("electra"),Tgo=o(" \u2014 "),tI=a("a"),Mgo=o("ElectraModel"),Ego=o(" (ELECTRA model)"),Cgo=l(),pp=a("li"),mne=a("strong"),wgo=o("flaubert"),Ago=o(" \u2014 "),aI=a("a"),ygo=o("FlaubertModel"),Lgo=o(" (FlauBERT model)"),xgo=l(),up=a("li"),gne=a("strong"),$go=o("fnet"),kgo=o(" \u2014 "),nI=a("a"),Sgo=o("FNetModel"),Rgo=o(" (FNet model)"),Bgo=l(),_p=a("li"),hne=a("strong"),Pgo=o("fsmt"),Igo=o(" \u2014 "),sI=a("a"),qgo=o("FSMTModel"),Ngo=o(" (FairSeq Machine-Translation model)"),jgo=l(),Rs=a("li"),pne=a("strong"),Dgo=o("funnel"),Ggo=o(" \u2014 "),lI=a("a"),Ogo=o("FunnelModel"),Vgo=o(" or "),iI=a("a"),Xgo=o("FunnelBaseModel"),zgo=o(" (Funnel Transformer model)"),Qgo=l(),bp=a("li"),une=a("strong"),Wgo=o("glpn"),Hgo=o(" \u2014 "),dI=a("a"),Ugo=o("GLPNModel"),Jgo=o(" (GLPN model)"),Ygo=l(),vp=a("li"),_ne=a("strong"),Kgo=o("gpt2"),Zgo=o(" \u2014 "),cI=a("a"),eho=o("GPT2Model"),oho=o(" (OpenAI GPT-2 model)"),rho=l(),Fp=a("li"),bne=a("strong"),tho=o("gpt_neo"),aho=o(" \u2014 "),fI=a("a"),nho=o("GPTNeoModel"),sho=o(" (GPT Neo model)"),lho=l(),Tp=a("li"),vne=a("strong"),iho=o("gptj"),dho=o(" \u2014 "),mI=a("a"),cho=o("GPTJModel"),fho=o(" (GPT-J model)"),mho=l(),Mp=a("li"),Fne=a("strong"),gho=o("hubert"),hho=o(" \u2014 "),gI=a("a"),pho=o("HubertModel"),uho=o(" (Hubert model)"),_ho=l(),Ep=a("li"),Tne=a("strong"),bho=o("ibert"),vho=o(" \u2014 "),hI=a("a"),Fho=o("IBertModel"),Tho=o(" (I-BERT model)"),Mho=l(),Cp=a("li"),Mne=a("strong"),Eho=o("imagegpt"),Cho=o(" \u2014 "),pI=a("a"),who=o("ImageGPTModel"),Aho=o(" (ImageGPT model)"),yho=l(),wp=a("li"),Ene=a("strong"),Lho=o("layoutlm"),xho=o(" \u2014 "),uI=a("a"),$ho=o("LayoutLMModel"),kho=o(" (LayoutLM model)"),Sho=l(),Ap=a("li"),Cne=a("strong"),Rho=o("layoutlmv2"),Bho=o(" \u2014 "),_I=a("a"),Pho=o("LayoutLMv2Model"),Iho=o(" (LayoutLMv2 model)"),qho=l(),yp=a("li"),wne=a("strong"),Nho=o("led"),jho=o(" \u2014 "),bI=a("a"),Dho=o("LEDModel"),Gho=o(" (LED model)"),Oho=l(),Lp=a("li"),Ane=a("strong"),Vho=o("longformer"),Xho=o(" \u2014 "),vI=a("a"),zho=o("LongformerModel"),Qho=o(" (Longformer model)"),Who=l(),xp=a("li"),yne=a("strong"),Hho=o("luke"),Uho=o(" \u2014 "),FI=a("a"),Jho=o("LukeModel"),Yho=o(" (LUKE model)"),Kho=l(),$p=a("li"),Lne=a("strong"),Zho=o("lxmert"),epo=o(" \u2014 "),TI=a("a"),opo=o("LxmertModel"),rpo=o(" (LXMERT model)"),tpo=l(),kp=a("li"),xne=a("strong"),apo=o("m2m_100"),npo=o(" \u2014 "),MI=a("a"),spo=o("M2M100Model"),lpo=o(" (M2M100 model)"),ipo=l(),Sp=a("li"),$ne=a("strong"),dpo=o("marian"),cpo=o(" \u2014 "),EI=a("a"),fpo=o("MarianModel"),mpo=o(" (Marian model)"),gpo=l(),Rp=a("li"),kne=a("strong"),hpo=o("maskformer"),ppo=o(" \u2014 "),CI=a("a"),upo=o("MaskFormerModel"),_po=o(" (MaskFormer model)"),bpo=l(),Bp=a("li"),Sne=a("strong"),vpo=o("mbart"),Fpo=o(" \u2014 "),wI=a("a"),Tpo=o("MBartModel"),Mpo=o(" (mBART model)"),Epo=l(),Pp=a("li"),Rne=a("strong"),Cpo=o("megatron-bert"),wpo=o(" \u2014 "),AI=a("a"),Apo=o("MegatronBertModel"),ypo=o(" (MegatronBert model)"),Lpo=l(),Ip=a("li"),Bne=a("strong"),xpo=o("mobilebert"),$po=o(" \u2014 "),yI=a("a"),kpo=o("MobileBertModel"),Spo=o(" (MobileBERT model)"),Rpo=l(),qp=a("li"),Pne=a("strong"),Bpo=o("mpnet"),Ppo=o(" \u2014 "),LI=a("a"),Ipo=o("MPNetModel"),qpo=o(" (MPNet model)"),Npo=l(),Np=a("li"),Ine=a("strong"),jpo=o("mt5"),Dpo=o(" \u2014 "),xI=a("a"),Gpo=o("MT5Model"),Opo=o(" (mT5 model)"),Vpo=l(),jp=a("li"),qne=a("strong"),Xpo=o("nystromformer"),zpo=o(" \u2014 "),$I=a("a"),Qpo=o("NystromformerModel"),Wpo=o(" (Nystromformer model)"),Hpo=l(),Dp=a("li"),Nne=a("strong"),Upo=o("openai-gpt"),Jpo=o(" \u2014 "),kI=a("a"),Ypo=o("OpenAIGPTModel"),Kpo=o(" (OpenAI GPT model)"),Zpo=l(),Gp=a("li"),jne=a("strong"),euo=o("pegasus"),ouo=o(" \u2014 "),SI=a("a"),ruo=o("PegasusModel"),tuo=o(" (Pegasus model)"),auo=l(),Op=a("li"),Dne=a("strong"),nuo=o("perceiver"),suo=o(" \u2014 "),RI=a("a"),luo=o("PerceiverModel"),iuo=o(" (Perceiver model)"),duo=l(),Vp=a("li"),Gne=a("strong"),cuo=o("plbart"),fuo=o(" \u2014 "),BI=a("a"),muo=o("PLBartModel"),guo=o(" (PLBart model)"),huo=l(),Xp=a("li"),One=a("strong"),puo=o("poolformer"),uuo=o(" \u2014 "),PI=a("a"),_uo=o("PoolFormerModel"),buo=o(" (PoolFormer model)"),vuo=l(),zp=a("li"),Vne=a("strong"),Fuo=o("prophetnet"),Tuo=o(" \u2014 "),II=a("a"),Muo=o("ProphetNetModel"),Euo=o(" (ProphetNet model)"),Cuo=l(),Qp=a("li"),Xne=a("strong"),wuo=o("qdqbert"),Auo=o(" \u2014 "),qI=a("a"),yuo=o("QDQBertModel"),Luo=o(" (QDQBert model)"),xuo=l(),Wp=a("li"),zne=a("strong"),$uo=o("reformer"),kuo=o(" \u2014 "),NI=a("a"),Suo=o("ReformerModel"),Ruo=o(" (Reformer model)"),Buo=l(),Hp=a("li"),Qne=a("strong"),Puo=o("regnet"),Iuo=o(" \u2014 "),jI=a("a"),quo=o("RegNetModel"),Nuo=o(" (RegNet model)"),juo=l(),Up=a("li"),Wne=a("strong"),Duo=o("rembert"),Guo=o(" \u2014 "),DI=a("a"),Ouo=o("RemBertModel"),Vuo=o(" (RemBERT model)"),Xuo=l(),Jp=a("li"),Hne=a("strong"),zuo=o("resnet"),Quo=o(" \u2014 "),GI=a("a"),Wuo=o("ResNetModel"),Huo=o(" (ResNet model)"),Uuo=l(),Yp=a("li"),Une=a("strong"),Juo=o("retribert"),Yuo=o(" \u2014 "),OI=a("a"),Kuo=o("RetriBertModel"),Zuo=o(" (RetriBERT model)"),e_o=l(),Kp=a("li"),Jne=a("strong"),o_o=o("roberta"),r_o=o(" \u2014 "),VI=a("a"),t_o=o("RobertaModel"),a_o=o(" (RoBERTa model)"),n_o=l(),Zp=a("li"),Yne=a("strong"),s_o=o("roformer"),l_o=o(" \u2014 "),XI=a("a"),i_o=o("RoFormerModel"),d_o=o(" (RoFormer model)"),c_o=l(),eu=a("li"),Kne=a("strong"),f_o=o("segformer"),m_o=o(" \u2014 "),zI=a("a"),g_o=o("SegformerModel"),h_o=o(" (SegFormer model)"),p_o=l(),ou=a("li"),Zne=a("strong"),u_o=o("sew"),__o=o(" \u2014 "),QI=a("a"),b_o=o("SEWModel"),v_o=o(" (SEW model)"),F_o=l(),ru=a("li"),ese=a("strong"),T_o=o("sew-d"),M_o=o(" \u2014 "),WI=a("a"),E_o=o("SEWDModel"),C_o=o(" (SEW-D model)"),w_o=l(),tu=a("li"),ose=a("strong"),A_o=o("speech_to_text"),y_o=o(" \u2014 "),HI=a("a"),L_o=o("Speech2TextModel"),x_o=o(" (Speech2Text model)"),$_o=l(),au=a("li"),rse=a("strong"),k_o=o("splinter"),S_o=o(" \u2014 "),UI=a("a"),R_o=o("SplinterModel"),B_o=o(" (Splinter model)"),P_o=l(),nu=a("li"),tse=a("strong"),I_o=o("squeezebert"),q_o=o(" \u2014 "),JI=a("a"),N_o=o("SqueezeBertModel"),j_o=o(" (SqueezeBERT model)"),D_o=l(),su=a("li"),ase=a("strong"),G_o=o("swin"),O_o=o(" \u2014 "),YI=a("a"),V_o=o("SwinModel"),X_o=o(" (Swin model)"),z_o=l(),lu=a("li"),nse=a("strong"),Q_o=o("t5"),W_o=o(" \u2014 "),KI=a("a"),H_o=o("T5Model"),U_o=o(" (T5 model)"),J_o=l(),iu=a("li"),sse=a("strong"),Y_o=o("tapas"),K_o=o(" \u2014 "),ZI=a("a"),Z_o=o("TapasModel"),e1o=o(" (TAPAS model)"),o1o=l(),du=a("li"),lse=a("strong"),r1o=o("transfo-xl"),t1o=o(" \u2014 "),eq=a("a"),a1o=o("TransfoXLModel"),n1o=o(" (Transformer-XL model)"),s1o=l(),cu=a("li"),ise=a("strong"),l1o=o("unispeech"),i1o=o(" \u2014 "),oq=a("a"),d1o=o("UniSpeechModel"),c1o=o(" (UniSpeech model)"),f1o=l(),fu=a("li"),dse=a("strong"),m1o=o("unispeech-sat"),g1o=o(" \u2014 "),rq=a("a"),h1o=o("UniSpeechSatModel"),p1o=o(" (UniSpeechSat model)"),u1o=l(),mu=a("li"),cse=a("strong"),_1o=o("van"),b1o=o(" \u2014 "),tq=a("a"),v1o=o("VanModel"),F1o=o(" (VAN model)"),T1o=l(),gu=a("li"),fse=a("strong"),M1o=o("vilt"),E1o=o(" \u2014 "),aq=a("a"),C1o=o("ViltModel"),w1o=o(" (ViLT model)"),A1o=l(),hu=a("li"),mse=a("strong"),y1o=o("vision-text-dual-encoder"),L1o=o(" \u2014 "),nq=a("a"),x1o=o("VisionTextDualEncoderModel"),$1o=o(" (VisionTextDualEncoder model)"),k1o=l(),pu=a("li"),gse=a("strong"),S1o=o("visual_bert"),R1o=o(" \u2014 "),sq=a("a"),B1o=o("VisualBertModel"),P1o=o(" (VisualBert model)"),I1o=l(),uu=a("li"),hse=a("strong"),q1o=o("vit"),N1o=o(" \u2014 "),lq=a("a"),j1o=o("ViTModel"),D1o=o(" (ViT model)"),G1o=l(),_u=a("li"),pse=a("strong"),O1o=o("vit_mae"),V1o=o(" \u2014 "),iq=a("a"),X1o=o("ViTMAEModel"),z1o=o(" (ViTMAE model)"),Q1o=l(),bu=a("li"),use=a("strong"),W1o=o("wav2vec2"),H1o=o(" \u2014 "),dq=a("a"),U1o=o("Wav2Vec2Model"),J1o=o(" (Wav2Vec2 model)"),Y1o=l(),vu=a("li"),_se=a("strong"),K1o=o("wavlm"),Z1o=o(" \u2014 "),cq=a("a"),e8o=o("WavLMModel"),o8o=o(" (WavLM model)"),r8o=l(),Fu=a("li"),bse=a("strong"),t8o=o("xglm"),a8o=o(" \u2014 "),fq=a("a"),n8o=o("XGLMModel"),s8o=o(" (XGLM model)"),l8o=l(),Tu=a("li"),vse=a("strong"),i8o=o("xlm"),d8o=o(" \u2014 "),mq=a("a"),c8o=o("XLMModel"),f8o=o(" (XLM model)"),m8o=l(),Mu=a("li"),Fse=a("strong"),g8o=o("xlm-prophetnet"),h8o=o(" \u2014 "),gq=a("a"),p8o=o("XLMProphetNetModel"),u8o=o(" (XLMProphetNet model)"),_8o=l(),Eu=a("li"),Tse=a("strong"),b8o=o("xlm-roberta"),v8o=o(" \u2014 "),hq=a("a"),F8o=o("XLMRobertaModel"),T8o=o(" (XLM-RoBERTa model)"),M8o=l(),Cu=a("li"),Mse=a("strong"),E8o=o("xlm-roberta-xl"),C8o=o(" \u2014 "),pq=a("a"),w8o=o("XLMRobertaXLModel"),A8o=o(" (XLM-RoBERTa-XL model)"),y8o=l(),wu=a("li"),Ese=a("strong"),L8o=o("xlnet"),x8o=o(" \u2014 "),uq=a("a"),$8o=o("XLNetModel"),k8o=o(" (XLNet model)"),S8o=l(),Au=a("li"),Cse=a("strong"),R8o=o("yolos"),B8o=o(" \u2014 "),_q=a("a"),P8o=o("YolosModel"),I8o=o(" (YOLOS model)"),q8o=l(),yu=a("li"),wse=a("strong"),N8o=o("yoso"),j8o=o(" \u2014 "),bq=a("a"),D8o=o("YosoModel"),G8o=o(" (YOSO model)"),O8o=l(),Lu=a("p"),V8o=o("The model is set in evaluation mode by default using "),Ase=a("code"),X8o=o("model.eval()"),z8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yse=a("code"),Q8o=o("model.train()"),W8o=l(),F(xu.$$.fragment),$Pe=l(),wi=a("h2"),$u=a("a"),Lse=a("span"),F(MA.$$.fragment),H8o=l(),xse=a("span"),U8o=o("AutoModelForPreTraining"),kPe=l(),xo=a("div"),F(EA.$$.fragment),J8o=l(),Ai=a("p"),Y8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),vq=a("a"),K8o=o("from_pretrained()"),Z8o=o(" class method or the "),Fq=a("a"),ebo=o("from_config()"),obo=o(` class
method.`),rbo=l(),CA=a("p"),tbo=o("This class cannot be instantiated directly using "),$se=a("code"),abo=o("__init__()"),nbo=o(" (throws an error)."),sbo=l(),rt=a("div"),F(wA.$$.fragment),lbo=l(),kse=a("p"),ibo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),dbo=l(),yi=a("p"),cbo=o(`Note:
Loading a model from its configuration file does `),Sse=a("strong"),fbo=o("not"),mbo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tq=a("a"),gbo=o("from_pretrained()"),hbo=o(" to load the model weights."),pbo=l(),F(ku.$$.fragment),ubo=l(),Ue=a("div"),F(AA.$$.fragment),_bo=l(),Rse=a("p"),bbo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),vbo=l(),ya=a("p"),Fbo=o("The model class to instantiate is selected based on the "),Bse=a("code"),Tbo=o("model_type"),Mbo=o(` property of the config object (either
passed as an argument or loaded from `),Pse=a("code"),Ebo=o("pretrained_model_name_or_path"),Cbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ise=a("code"),wbo=o("pretrained_model_name_or_path"),Abo=o(":"),ybo=l(),G=a("ul"),Su=a("li"),qse=a("strong"),Lbo=o("albert"),xbo=o(" \u2014 "),Mq=a("a"),$bo=o("AlbertForPreTraining"),kbo=o(" (ALBERT model)"),Sbo=l(),Ru=a("li"),Nse=a("strong"),Rbo=o("bart"),Bbo=o(" \u2014 "),Eq=a("a"),Pbo=o("BartForConditionalGeneration"),Ibo=o(" (BART model)"),qbo=l(),Bu=a("li"),jse=a("strong"),Nbo=o("bert"),jbo=o(" \u2014 "),Cq=a("a"),Dbo=o("BertForPreTraining"),Gbo=o(" (BERT model)"),Obo=l(),Pu=a("li"),Dse=a("strong"),Vbo=o("big_bird"),Xbo=o(" \u2014 "),wq=a("a"),zbo=o("BigBirdForPreTraining"),Qbo=o(" (BigBird model)"),Wbo=l(),Iu=a("li"),Gse=a("strong"),Hbo=o("camembert"),Ubo=o(" \u2014 "),Aq=a("a"),Jbo=o("CamembertForMaskedLM"),Ybo=o(" (CamemBERT model)"),Kbo=l(),qu=a("li"),Ose=a("strong"),Zbo=o("ctrl"),e2o=o(" \u2014 "),yq=a("a"),o2o=o("CTRLLMHeadModel"),r2o=o(" (CTRL model)"),t2o=l(),Nu=a("li"),Vse=a("strong"),a2o=o("data2vec-text"),n2o=o(" \u2014 "),Lq=a("a"),s2o=o("Data2VecTextForMaskedLM"),l2o=o(" (Data2VecText model)"),i2o=l(),ju=a("li"),Xse=a("strong"),d2o=o("deberta"),c2o=o(" \u2014 "),xq=a("a"),f2o=o("DebertaForMaskedLM"),m2o=o(" (DeBERTa model)"),g2o=l(),Du=a("li"),zse=a("strong"),h2o=o("deberta-v2"),p2o=o(" \u2014 "),$q=a("a"),u2o=o("DebertaV2ForMaskedLM"),_2o=o(" (DeBERTa-v2 model)"),b2o=l(),Gu=a("li"),Qse=a("strong"),v2o=o("distilbert"),F2o=o(" \u2014 "),kq=a("a"),T2o=o("DistilBertForMaskedLM"),M2o=o(" (DistilBERT model)"),E2o=l(),Ou=a("li"),Wse=a("strong"),C2o=o("electra"),w2o=o(" \u2014 "),Sq=a("a"),A2o=o("ElectraForPreTraining"),y2o=o(" (ELECTRA model)"),L2o=l(),Vu=a("li"),Hse=a("strong"),x2o=o("flaubert"),$2o=o(" \u2014 "),Rq=a("a"),k2o=o("FlaubertWithLMHeadModel"),S2o=o(" (FlauBERT model)"),R2o=l(),Xu=a("li"),Use=a("strong"),B2o=o("fnet"),P2o=o(" \u2014 "),Bq=a("a"),I2o=o("FNetForPreTraining"),q2o=o(" (FNet model)"),N2o=l(),zu=a("li"),Jse=a("strong"),j2o=o("fsmt"),D2o=o(" \u2014 "),Pq=a("a"),G2o=o("FSMTForConditionalGeneration"),O2o=o(" (FairSeq Machine-Translation model)"),V2o=l(),Qu=a("li"),Yse=a("strong"),X2o=o("funnel"),z2o=o(" \u2014 "),Iq=a("a"),Q2o=o("FunnelForPreTraining"),W2o=o(" (Funnel Transformer model)"),H2o=l(),Wu=a("li"),Kse=a("strong"),U2o=o("gpt2"),J2o=o(" \u2014 "),qq=a("a"),Y2o=o("GPT2LMHeadModel"),K2o=o(" (OpenAI GPT-2 model)"),Z2o=l(),Hu=a("li"),Zse=a("strong"),evo=o("ibert"),ovo=o(" \u2014 "),Nq=a("a"),rvo=o("IBertForMaskedLM"),tvo=o(" (I-BERT model)"),avo=l(),Uu=a("li"),ele=a("strong"),nvo=o("layoutlm"),svo=o(" \u2014 "),jq=a("a"),lvo=o("LayoutLMForMaskedLM"),ivo=o(" (LayoutLM model)"),dvo=l(),Ju=a("li"),ole=a("strong"),cvo=o("longformer"),fvo=o(" \u2014 "),Dq=a("a"),mvo=o("LongformerForMaskedLM"),gvo=o(" (Longformer model)"),hvo=l(),Yu=a("li"),rle=a("strong"),pvo=o("lxmert"),uvo=o(" \u2014 "),Gq=a("a"),_vo=o("LxmertForPreTraining"),bvo=o(" (LXMERT model)"),vvo=l(),Ku=a("li"),tle=a("strong"),Fvo=o("megatron-bert"),Tvo=o(" \u2014 "),Oq=a("a"),Mvo=o("MegatronBertForPreTraining"),Evo=o(" (MegatronBert model)"),Cvo=l(),Zu=a("li"),ale=a("strong"),wvo=o("mobilebert"),Avo=o(" \u2014 "),Vq=a("a"),yvo=o("MobileBertForPreTraining"),Lvo=o(" (MobileBERT model)"),xvo=l(),e_=a("li"),nle=a("strong"),$vo=o("mpnet"),kvo=o(" \u2014 "),Xq=a("a"),Svo=o("MPNetForMaskedLM"),Rvo=o(" (MPNet model)"),Bvo=l(),o_=a("li"),sle=a("strong"),Pvo=o("openai-gpt"),Ivo=o(" \u2014 "),zq=a("a"),qvo=o("OpenAIGPTLMHeadModel"),Nvo=o(" (OpenAI GPT model)"),jvo=l(),r_=a("li"),lle=a("strong"),Dvo=o("retribert"),Gvo=o(" \u2014 "),Qq=a("a"),Ovo=o("RetriBertModel"),Vvo=o(" (RetriBERT model)"),Xvo=l(),t_=a("li"),ile=a("strong"),zvo=o("roberta"),Qvo=o(" \u2014 "),Wq=a("a"),Wvo=o("RobertaForMaskedLM"),Hvo=o(" (RoBERTa model)"),Uvo=l(),a_=a("li"),dle=a("strong"),Jvo=o("squeezebert"),Yvo=o(" \u2014 "),Hq=a("a"),Kvo=o("SqueezeBertForMaskedLM"),Zvo=o(" (SqueezeBERT model)"),eFo=l(),n_=a("li"),cle=a("strong"),oFo=o("t5"),rFo=o(" \u2014 "),Uq=a("a"),tFo=o("T5ForConditionalGeneration"),aFo=o(" (T5 model)"),nFo=l(),s_=a("li"),fle=a("strong"),sFo=o("tapas"),lFo=o(" \u2014 "),Jq=a("a"),iFo=o("TapasForMaskedLM"),dFo=o(" (TAPAS model)"),cFo=l(),l_=a("li"),mle=a("strong"),fFo=o("transfo-xl"),mFo=o(" \u2014 "),Yq=a("a"),gFo=o("TransfoXLLMHeadModel"),hFo=o(" (Transformer-XL model)"),pFo=l(),i_=a("li"),gle=a("strong"),uFo=o("unispeech"),_Fo=o(" \u2014 "),Kq=a("a"),bFo=o("UniSpeechForPreTraining"),vFo=o(" (UniSpeech model)"),FFo=l(),d_=a("li"),hle=a("strong"),TFo=o("unispeech-sat"),MFo=o(" \u2014 "),Zq=a("a"),EFo=o("UniSpeechSatForPreTraining"),CFo=o(" (UniSpeechSat model)"),wFo=l(),c_=a("li"),ple=a("strong"),AFo=o("visual_bert"),yFo=o(" \u2014 "),eN=a("a"),LFo=o("VisualBertForPreTraining"),xFo=o(" (VisualBert model)"),$Fo=l(),f_=a("li"),ule=a("strong"),kFo=o("vit_mae"),SFo=o(" \u2014 "),oN=a("a"),RFo=o("ViTMAEForPreTraining"),BFo=o(" (ViTMAE model)"),PFo=l(),m_=a("li"),_le=a("strong"),IFo=o("wav2vec2"),qFo=o(" \u2014 "),rN=a("a"),NFo=o("Wav2Vec2ForPreTraining"),jFo=o(" (Wav2Vec2 model)"),DFo=l(),g_=a("li"),ble=a("strong"),GFo=o("xlm"),OFo=o(" \u2014 "),tN=a("a"),VFo=o("XLMWithLMHeadModel"),XFo=o(" (XLM model)"),zFo=l(),h_=a("li"),vle=a("strong"),QFo=o("xlm-roberta"),WFo=o(" \u2014 "),aN=a("a"),HFo=o("XLMRobertaForMaskedLM"),UFo=o(" (XLM-RoBERTa model)"),JFo=l(),p_=a("li"),Fle=a("strong"),YFo=o("xlm-roberta-xl"),KFo=o(" \u2014 "),nN=a("a"),ZFo=o("XLMRobertaXLForMaskedLM"),e6o=o(" (XLM-RoBERTa-XL model)"),o6o=l(),u_=a("li"),Tle=a("strong"),r6o=o("xlnet"),t6o=o(" \u2014 "),sN=a("a"),a6o=o("XLNetLMHeadModel"),n6o=o(" (XLNet model)"),s6o=l(),__=a("p"),l6o=o("The model is set in evaluation mode by default using "),Mle=a("code"),i6o=o("model.eval()"),d6o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ele=a("code"),c6o=o("model.train()"),f6o=l(),F(b_.$$.fragment),SPe=l(),Li=a("h2"),v_=a("a"),Cle=a("span"),F(yA.$$.fragment),m6o=l(),wle=a("span"),g6o=o("AutoModelForCausalLM"),RPe=l(),$o=a("div"),F(LA.$$.fragment),h6o=l(),xi=a("p"),p6o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lN=a("a"),u6o=o("from_pretrained()"),_6o=o(" class method or the "),iN=a("a"),b6o=o("from_config()"),v6o=o(` class
method.`),F6o=l(),xA=a("p"),T6o=o("This class cannot be instantiated directly using "),Ale=a("code"),M6o=o("__init__()"),E6o=o(" (throws an error)."),C6o=l(),tt=a("div"),F($A.$$.fragment),w6o=l(),yle=a("p"),A6o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),y6o=l(),$i=a("p"),L6o=o(`Note:
Loading a model from its configuration file does `),Lle=a("strong"),x6o=o("not"),$6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dN=a("a"),k6o=o("from_pretrained()"),S6o=o(" to load the model weights."),R6o=l(),F(F_.$$.fragment),B6o=l(),Je=a("div"),F(kA.$$.fragment),P6o=l(),xle=a("p"),I6o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),q6o=l(),La=a("p"),N6o=o("The model class to instantiate is selected based on the "),$le=a("code"),j6o=o("model_type"),D6o=o(` property of the config object (either
passed as an argument or loaded from `),kle=a("code"),G6o=o("pretrained_model_name_or_path"),O6o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sle=a("code"),V6o=o("pretrained_model_name_or_path"),X6o=o(":"),z6o=l(),z=a("ul"),T_=a("li"),Rle=a("strong"),Q6o=o("bart"),W6o=o(" \u2014 "),cN=a("a"),H6o=o("BartForCausalLM"),U6o=o(" (BART model)"),J6o=l(),M_=a("li"),Ble=a("strong"),Y6o=o("bert"),K6o=o(" \u2014 "),fN=a("a"),Z6o=o("BertLMHeadModel"),eTo=o(" (BERT model)"),oTo=l(),E_=a("li"),Ple=a("strong"),rTo=o("bert-generation"),tTo=o(" \u2014 "),mN=a("a"),aTo=o("BertGenerationDecoder"),nTo=o(" (Bert Generation model)"),sTo=l(),C_=a("li"),Ile=a("strong"),lTo=o("big_bird"),iTo=o(" \u2014 "),gN=a("a"),dTo=o("BigBirdForCausalLM"),cTo=o(" (BigBird model)"),fTo=l(),w_=a("li"),qle=a("strong"),mTo=o("bigbird_pegasus"),gTo=o(" \u2014 "),hN=a("a"),hTo=o("BigBirdPegasusForCausalLM"),pTo=o(" (BigBirdPegasus model)"),uTo=l(),A_=a("li"),Nle=a("strong"),_To=o("blenderbot"),bTo=o(" \u2014 "),pN=a("a"),vTo=o("BlenderbotForCausalLM"),FTo=o(" (Blenderbot model)"),TTo=l(),y_=a("li"),jle=a("strong"),MTo=o("blenderbot-small"),ETo=o(" \u2014 "),uN=a("a"),CTo=o("BlenderbotSmallForCausalLM"),wTo=o(" (BlenderbotSmall model)"),ATo=l(),L_=a("li"),Dle=a("strong"),yTo=o("camembert"),LTo=o(" \u2014 "),_N=a("a"),xTo=o("CamembertForCausalLM"),$To=o(" (CamemBERT model)"),kTo=l(),x_=a("li"),Gle=a("strong"),STo=o("ctrl"),RTo=o(" \u2014 "),bN=a("a"),BTo=o("CTRLLMHeadModel"),PTo=o(" (CTRL model)"),ITo=l(),$_=a("li"),Ole=a("strong"),qTo=o("data2vec-text"),NTo=o(" \u2014 "),vN=a("a"),jTo=o("Data2VecTextForCausalLM"),DTo=o(" (Data2VecText model)"),GTo=l(),k_=a("li"),Vle=a("strong"),OTo=o("electra"),VTo=o(" \u2014 "),FN=a("a"),XTo=o("ElectraForCausalLM"),zTo=o(" (ELECTRA model)"),QTo=l(),S_=a("li"),Xle=a("strong"),WTo=o("gpt2"),HTo=o(" \u2014 "),TN=a("a"),UTo=o("GPT2LMHeadModel"),JTo=o(" (OpenAI GPT-2 model)"),YTo=l(),R_=a("li"),zle=a("strong"),KTo=o("gpt_neo"),ZTo=o(" \u2014 "),MN=a("a"),e9o=o("GPTNeoForCausalLM"),o9o=o(" (GPT Neo model)"),r9o=l(),B_=a("li"),Qle=a("strong"),t9o=o("gptj"),a9o=o(" \u2014 "),EN=a("a"),n9o=o("GPTJForCausalLM"),s9o=o(" (GPT-J model)"),l9o=l(),P_=a("li"),Wle=a("strong"),i9o=o("marian"),d9o=o(" \u2014 "),CN=a("a"),c9o=o("MarianForCausalLM"),f9o=o(" (Marian model)"),m9o=l(),I_=a("li"),Hle=a("strong"),g9o=o("mbart"),h9o=o(" \u2014 "),wN=a("a"),p9o=o("MBartForCausalLM"),u9o=o(" (mBART model)"),_9o=l(),q_=a("li"),Ule=a("strong"),b9o=o("megatron-bert"),v9o=o(" \u2014 "),AN=a("a"),F9o=o("MegatronBertForCausalLM"),T9o=o(" (MegatronBert model)"),M9o=l(),N_=a("li"),Jle=a("strong"),E9o=o("openai-gpt"),C9o=o(" \u2014 "),yN=a("a"),w9o=o("OpenAIGPTLMHeadModel"),A9o=o(" (OpenAI GPT model)"),y9o=l(),j_=a("li"),Yle=a("strong"),L9o=o("pegasus"),x9o=o(" \u2014 "),LN=a("a"),$9o=o("PegasusForCausalLM"),k9o=o(" (Pegasus model)"),S9o=l(),D_=a("li"),Kle=a("strong"),R9o=o("plbart"),B9o=o(" \u2014 "),xN=a("a"),P9o=o("PLBartForCausalLM"),I9o=o(" (PLBart model)"),q9o=l(),G_=a("li"),Zle=a("strong"),N9o=o("prophetnet"),j9o=o(" \u2014 "),$N=a("a"),D9o=o("ProphetNetForCausalLM"),G9o=o(" (ProphetNet model)"),O9o=l(),O_=a("li"),eie=a("strong"),V9o=o("qdqbert"),X9o=o(" \u2014 "),kN=a("a"),z9o=o("QDQBertLMHeadModel"),Q9o=o(" (QDQBert model)"),W9o=l(),V_=a("li"),oie=a("strong"),H9o=o("reformer"),U9o=o(" \u2014 "),SN=a("a"),J9o=o("ReformerModelWithLMHead"),Y9o=o(" (Reformer model)"),K9o=l(),X_=a("li"),rie=a("strong"),Z9o=o("rembert"),eMo=o(" \u2014 "),RN=a("a"),oMo=o("RemBertForCausalLM"),rMo=o(" (RemBERT model)"),tMo=l(),z_=a("li"),tie=a("strong"),aMo=o("roberta"),nMo=o(" \u2014 "),BN=a("a"),sMo=o("RobertaForCausalLM"),lMo=o(" (RoBERTa model)"),iMo=l(),Q_=a("li"),aie=a("strong"),dMo=o("roformer"),cMo=o(" \u2014 "),PN=a("a"),fMo=o("RoFormerForCausalLM"),mMo=o(" (RoFormer model)"),gMo=l(),W_=a("li"),nie=a("strong"),hMo=o("speech_to_text_2"),pMo=o(" \u2014 "),IN=a("a"),uMo=o("Speech2Text2ForCausalLM"),_Mo=o(" (Speech2Text2 model)"),bMo=l(),H_=a("li"),sie=a("strong"),vMo=o("transfo-xl"),FMo=o(" \u2014 "),qN=a("a"),TMo=o("TransfoXLLMHeadModel"),MMo=o(" (Transformer-XL model)"),EMo=l(),U_=a("li"),lie=a("strong"),CMo=o("trocr"),wMo=o(" \u2014 "),NN=a("a"),AMo=o("TrOCRForCausalLM"),yMo=o(" (TrOCR model)"),LMo=l(),J_=a("li"),iie=a("strong"),xMo=o("xglm"),$Mo=o(" \u2014 "),jN=a("a"),kMo=o("XGLMForCausalLM"),SMo=o(" (XGLM model)"),RMo=l(),Y_=a("li"),die=a("strong"),BMo=o("xlm"),PMo=o(" \u2014 "),DN=a("a"),IMo=o("XLMWithLMHeadModel"),qMo=o(" (XLM model)"),NMo=l(),K_=a("li"),cie=a("strong"),jMo=o("xlm-prophetnet"),DMo=o(" \u2014 "),GN=a("a"),GMo=o("XLMProphetNetForCausalLM"),OMo=o(" (XLMProphetNet model)"),VMo=l(),Z_=a("li"),fie=a("strong"),XMo=o("xlm-roberta"),zMo=o(" \u2014 "),ON=a("a"),QMo=o("XLMRobertaForCausalLM"),WMo=o(" (XLM-RoBERTa model)"),HMo=l(),e1=a("li"),mie=a("strong"),UMo=o("xlm-roberta-xl"),JMo=o(" \u2014 "),VN=a("a"),YMo=o("XLMRobertaXLForCausalLM"),KMo=o(" (XLM-RoBERTa-XL model)"),ZMo=l(),o1=a("li"),gie=a("strong"),e4o=o("xlnet"),o4o=o(" \u2014 "),XN=a("a"),r4o=o("XLNetLMHeadModel"),t4o=o(" (XLNet model)"),a4o=l(),r1=a("p"),n4o=o("The model is set in evaluation mode by default using "),hie=a("code"),s4o=o("model.eval()"),l4o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pie=a("code"),i4o=o("model.train()"),d4o=l(),F(t1.$$.fragment),BPe=l(),ki=a("h2"),a1=a("a"),uie=a("span"),F(SA.$$.fragment),c4o=l(),_ie=a("span"),f4o=o("AutoModelForMaskedLM"),PPe=l(),ko=a("div"),F(RA.$$.fragment),m4o=l(),Si=a("p"),g4o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),zN=a("a"),h4o=o("from_pretrained()"),p4o=o(" class method or the "),QN=a("a"),u4o=o("from_config()"),_4o=o(` class
method.`),b4o=l(),BA=a("p"),v4o=o("This class cannot be instantiated directly using "),bie=a("code"),F4o=o("__init__()"),T4o=o(" (throws an error)."),M4o=l(),at=a("div"),F(PA.$$.fragment),E4o=l(),vie=a("p"),C4o=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),w4o=l(),Ri=a("p"),A4o=o(`Note:
Loading a model from its configuration file does `),Fie=a("strong"),y4o=o("not"),L4o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WN=a("a"),x4o=o("from_pretrained()"),$4o=o(" to load the model weights."),k4o=l(),F(n1.$$.fragment),S4o=l(),Ye=a("div"),F(IA.$$.fragment),R4o=l(),Tie=a("p"),B4o=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),P4o=l(),xa=a("p"),I4o=o("The model class to instantiate is selected based on the "),Mie=a("code"),q4o=o("model_type"),N4o=o(` property of the config object (either
passed as an argument or loaded from `),Eie=a("code"),j4o=o("pretrained_model_name_or_path"),D4o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cie=a("code"),G4o=o("pretrained_model_name_or_path"),O4o=o(":"),V4o=l(),Q=a("ul"),s1=a("li"),wie=a("strong"),X4o=o("albert"),z4o=o(" \u2014 "),HN=a("a"),Q4o=o("AlbertForMaskedLM"),W4o=o(" (ALBERT model)"),H4o=l(),l1=a("li"),Aie=a("strong"),U4o=o("bart"),J4o=o(" \u2014 "),UN=a("a"),Y4o=o("BartForConditionalGeneration"),K4o=o(" (BART model)"),Z4o=l(),i1=a("li"),yie=a("strong"),eEo=o("bert"),oEo=o(" \u2014 "),JN=a("a"),rEo=o("BertForMaskedLM"),tEo=o(" (BERT model)"),aEo=l(),d1=a("li"),Lie=a("strong"),nEo=o("big_bird"),sEo=o(" \u2014 "),YN=a("a"),lEo=o("BigBirdForMaskedLM"),iEo=o(" (BigBird model)"),dEo=l(),c1=a("li"),xie=a("strong"),cEo=o("camembert"),fEo=o(" \u2014 "),KN=a("a"),mEo=o("CamembertForMaskedLM"),gEo=o(" (CamemBERT model)"),hEo=l(),f1=a("li"),$ie=a("strong"),pEo=o("convbert"),uEo=o(" \u2014 "),ZN=a("a"),_Eo=o("ConvBertForMaskedLM"),bEo=o(" (ConvBERT model)"),vEo=l(),m1=a("li"),kie=a("strong"),FEo=o("data2vec-text"),TEo=o(" \u2014 "),ej=a("a"),MEo=o("Data2VecTextForMaskedLM"),EEo=o(" (Data2VecText model)"),CEo=l(),g1=a("li"),Sie=a("strong"),wEo=o("deberta"),AEo=o(" \u2014 "),oj=a("a"),yEo=o("DebertaForMaskedLM"),LEo=o(" (DeBERTa model)"),xEo=l(),h1=a("li"),Rie=a("strong"),$Eo=o("deberta-v2"),kEo=o(" \u2014 "),rj=a("a"),SEo=o("DebertaV2ForMaskedLM"),REo=o(" (DeBERTa-v2 model)"),BEo=l(),p1=a("li"),Bie=a("strong"),PEo=o("distilbert"),IEo=o(" \u2014 "),tj=a("a"),qEo=o("DistilBertForMaskedLM"),NEo=o(" (DistilBERT model)"),jEo=l(),u1=a("li"),Pie=a("strong"),DEo=o("electra"),GEo=o(" \u2014 "),aj=a("a"),OEo=o("ElectraForMaskedLM"),VEo=o(" (ELECTRA model)"),XEo=l(),_1=a("li"),Iie=a("strong"),zEo=o("flaubert"),QEo=o(" \u2014 "),nj=a("a"),WEo=o("FlaubertWithLMHeadModel"),HEo=o(" (FlauBERT model)"),UEo=l(),b1=a("li"),qie=a("strong"),JEo=o("fnet"),YEo=o(" \u2014 "),sj=a("a"),KEo=o("FNetForMaskedLM"),ZEo=o(" (FNet model)"),e5o=l(),v1=a("li"),Nie=a("strong"),o5o=o("funnel"),r5o=o(" \u2014 "),lj=a("a"),t5o=o("FunnelForMaskedLM"),a5o=o(" (Funnel Transformer model)"),n5o=l(),F1=a("li"),jie=a("strong"),s5o=o("ibert"),l5o=o(" \u2014 "),ij=a("a"),i5o=o("IBertForMaskedLM"),d5o=o(" (I-BERT model)"),c5o=l(),T1=a("li"),Die=a("strong"),f5o=o("layoutlm"),m5o=o(" \u2014 "),dj=a("a"),g5o=o("LayoutLMForMaskedLM"),h5o=o(" (LayoutLM model)"),p5o=l(),M1=a("li"),Gie=a("strong"),u5o=o("longformer"),_5o=o(" \u2014 "),cj=a("a"),b5o=o("LongformerForMaskedLM"),v5o=o(" (Longformer model)"),F5o=l(),E1=a("li"),Oie=a("strong"),T5o=o("mbart"),M5o=o(" \u2014 "),fj=a("a"),E5o=o("MBartForConditionalGeneration"),C5o=o(" (mBART model)"),w5o=l(),C1=a("li"),Vie=a("strong"),A5o=o("megatron-bert"),y5o=o(" \u2014 "),mj=a("a"),L5o=o("MegatronBertForMaskedLM"),x5o=o(" (MegatronBert model)"),$5o=l(),w1=a("li"),Xie=a("strong"),k5o=o("mobilebert"),S5o=o(" \u2014 "),gj=a("a"),R5o=o("MobileBertForMaskedLM"),B5o=o(" (MobileBERT model)"),P5o=l(),A1=a("li"),zie=a("strong"),I5o=o("mpnet"),q5o=o(" \u2014 "),hj=a("a"),N5o=o("MPNetForMaskedLM"),j5o=o(" (MPNet model)"),D5o=l(),y1=a("li"),Qie=a("strong"),G5o=o("nystromformer"),O5o=o(" \u2014 "),pj=a("a"),V5o=o("NystromformerForMaskedLM"),X5o=o(" (Nystromformer model)"),z5o=l(),L1=a("li"),Wie=a("strong"),Q5o=o("perceiver"),W5o=o(" \u2014 "),uj=a("a"),H5o=o("PerceiverForMaskedLM"),U5o=o(" (Perceiver model)"),J5o=l(),x1=a("li"),Hie=a("strong"),Y5o=o("qdqbert"),K5o=o(" \u2014 "),_j=a("a"),Z5o=o("QDQBertForMaskedLM"),eCo=o(" (QDQBert model)"),oCo=l(),$1=a("li"),Uie=a("strong"),rCo=o("reformer"),tCo=o(" \u2014 "),bj=a("a"),aCo=o("ReformerForMaskedLM"),nCo=o(" (Reformer model)"),sCo=l(),k1=a("li"),Jie=a("strong"),lCo=o("rembert"),iCo=o(" \u2014 "),vj=a("a"),dCo=o("RemBertForMaskedLM"),cCo=o(" (RemBERT model)"),fCo=l(),S1=a("li"),Yie=a("strong"),mCo=o("roberta"),gCo=o(" \u2014 "),Fj=a("a"),hCo=o("RobertaForMaskedLM"),pCo=o(" (RoBERTa model)"),uCo=l(),R1=a("li"),Kie=a("strong"),_Co=o("roformer"),bCo=o(" \u2014 "),Tj=a("a"),vCo=o("RoFormerForMaskedLM"),FCo=o(" (RoFormer model)"),TCo=l(),B1=a("li"),Zie=a("strong"),MCo=o("squeezebert"),ECo=o(" \u2014 "),Mj=a("a"),CCo=o("SqueezeBertForMaskedLM"),wCo=o(" (SqueezeBERT model)"),ACo=l(),P1=a("li"),ede=a("strong"),yCo=o("tapas"),LCo=o(" \u2014 "),Ej=a("a"),xCo=o("TapasForMaskedLM"),$Co=o(" (TAPAS model)"),kCo=l(),I1=a("li"),ode=a("strong"),SCo=o("wav2vec2"),RCo=o(" \u2014 "),rde=a("code"),BCo=o("Wav2Vec2ForMaskedLM"),PCo=o(" (Wav2Vec2 model)"),ICo=l(),q1=a("li"),tde=a("strong"),qCo=o("xlm"),NCo=o(" \u2014 "),Cj=a("a"),jCo=o("XLMWithLMHeadModel"),DCo=o(" (XLM model)"),GCo=l(),N1=a("li"),ade=a("strong"),OCo=o("xlm-roberta"),VCo=o(" \u2014 "),wj=a("a"),XCo=o("XLMRobertaForMaskedLM"),zCo=o(" (XLM-RoBERTa model)"),QCo=l(),j1=a("li"),nde=a("strong"),WCo=o("xlm-roberta-xl"),HCo=o(" \u2014 "),Aj=a("a"),UCo=o("XLMRobertaXLForMaskedLM"),JCo=o(" (XLM-RoBERTa-XL model)"),YCo=l(),D1=a("li"),sde=a("strong"),KCo=o("yoso"),ZCo=o(" \u2014 "),yj=a("a"),e3o=o("YosoForMaskedLM"),o3o=o(" (YOSO model)"),r3o=l(),G1=a("p"),t3o=o("The model is set in evaluation mode by default using "),lde=a("code"),a3o=o("model.eval()"),n3o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ide=a("code"),s3o=o("model.train()"),l3o=l(),F(O1.$$.fragment),IPe=l(),Bi=a("h2"),V1=a("a"),dde=a("span"),F(qA.$$.fragment),i3o=l(),cde=a("span"),d3o=o("AutoModelForSeq2SeqLM"),qPe=l(),So=a("div"),F(NA.$$.fragment),c3o=l(),Pi=a("p"),f3o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Lj=a("a"),m3o=o("from_pretrained()"),g3o=o(" class method or the "),xj=a("a"),h3o=o("from_config()"),p3o=o(` class
method.`),u3o=l(),jA=a("p"),_3o=o("This class cannot be instantiated directly using "),fde=a("code"),b3o=o("__init__()"),v3o=o(" (throws an error)."),F3o=l(),nt=a("div"),F(DA.$$.fragment),T3o=l(),mde=a("p"),M3o=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),E3o=l(),Ii=a("p"),C3o=o(`Note:
Loading a model from its configuration file does `),gde=a("strong"),w3o=o("not"),A3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$j=a("a"),y3o=o("from_pretrained()"),L3o=o(" to load the model weights."),x3o=l(),F(X1.$$.fragment),$3o=l(),Ke=a("div"),F(GA.$$.fragment),k3o=l(),hde=a("p"),S3o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),R3o=l(),$a=a("p"),B3o=o("The model class to instantiate is selected based on the "),pde=a("code"),P3o=o("model_type"),I3o=o(` property of the config object (either
passed as an argument or loaded from `),ude=a("code"),q3o=o("pretrained_model_name_or_path"),N3o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_de=a("code"),j3o=o("pretrained_model_name_or_path"),D3o=o(":"),G3o=l(),he=a("ul"),z1=a("li"),bde=a("strong"),O3o=o("bart"),V3o=o(" \u2014 "),kj=a("a"),X3o=o("BartForConditionalGeneration"),z3o=o(" (BART model)"),Q3o=l(),Q1=a("li"),vde=a("strong"),W3o=o("bigbird_pegasus"),H3o=o(" \u2014 "),Sj=a("a"),U3o=o("BigBirdPegasusForConditionalGeneration"),J3o=o(" (BigBirdPegasus model)"),Y3o=l(),W1=a("li"),Fde=a("strong"),K3o=o("blenderbot"),Z3o=o(" \u2014 "),Rj=a("a"),ewo=o("BlenderbotForConditionalGeneration"),owo=o(" (Blenderbot model)"),rwo=l(),H1=a("li"),Tde=a("strong"),two=o("blenderbot-small"),awo=o(" \u2014 "),Bj=a("a"),nwo=o("BlenderbotSmallForConditionalGeneration"),swo=o(" (BlenderbotSmall model)"),lwo=l(),U1=a("li"),Mde=a("strong"),iwo=o("encoder-decoder"),dwo=o(" \u2014 "),Pj=a("a"),cwo=o("EncoderDecoderModel"),fwo=o(" (Encoder decoder model)"),mwo=l(),J1=a("li"),Ede=a("strong"),gwo=o("fsmt"),hwo=o(" \u2014 "),Ij=a("a"),pwo=o("FSMTForConditionalGeneration"),uwo=o(" (FairSeq Machine-Translation model)"),_wo=l(),Y1=a("li"),Cde=a("strong"),bwo=o("led"),vwo=o(" \u2014 "),qj=a("a"),Fwo=o("LEDForConditionalGeneration"),Two=o(" (LED model)"),Mwo=l(),K1=a("li"),wde=a("strong"),Ewo=o("m2m_100"),Cwo=o(" \u2014 "),Nj=a("a"),wwo=o("M2M100ForConditionalGeneration"),Awo=o(" (M2M100 model)"),ywo=l(),Z1=a("li"),Ade=a("strong"),Lwo=o("marian"),xwo=o(" \u2014 "),jj=a("a"),$wo=o("MarianMTModel"),kwo=o(" (Marian model)"),Swo=l(),e8=a("li"),yde=a("strong"),Rwo=o("mbart"),Bwo=o(" \u2014 "),Dj=a("a"),Pwo=o("MBartForConditionalGeneration"),Iwo=o(" (mBART model)"),qwo=l(),o8=a("li"),Lde=a("strong"),Nwo=o("mt5"),jwo=o(" \u2014 "),Gj=a("a"),Dwo=o("MT5ForConditionalGeneration"),Gwo=o(" (mT5 model)"),Owo=l(),r8=a("li"),xde=a("strong"),Vwo=o("pegasus"),Xwo=o(" \u2014 "),Oj=a("a"),zwo=o("PegasusForConditionalGeneration"),Qwo=o(" (Pegasus model)"),Wwo=l(),t8=a("li"),$de=a("strong"),Hwo=o("plbart"),Uwo=o(" \u2014 "),Vj=a("a"),Jwo=o("PLBartForConditionalGeneration"),Ywo=o(" (PLBart model)"),Kwo=l(),a8=a("li"),kde=a("strong"),Zwo=o("prophetnet"),eAo=o(" \u2014 "),Xj=a("a"),oAo=o("ProphetNetForConditionalGeneration"),rAo=o(" (ProphetNet model)"),tAo=l(),n8=a("li"),Sde=a("strong"),aAo=o("t5"),nAo=o(" \u2014 "),zj=a("a"),sAo=o("T5ForConditionalGeneration"),lAo=o(" (T5 model)"),iAo=l(),s8=a("li"),Rde=a("strong"),dAo=o("tapex"),cAo=o(" \u2014 "),Qj=a("a"),fAo=o("BartForConditionalGeneration"),mAo=o(" (TAPEX model)"),gAo=l(),l8=a("li"),Bde=a("strong"),hAo=o("xlm-prophetnet"),pAo=o(" \u2014 "),Wj=a("a"),uAo=o("XLMProphetNetForConditionalGeneration"),_Ao=o(" (XLMProphetNet model)"),bAo=l(),i8=a("p"),vAo=o("The model is set in evaluation mode by default using "),Pde=a("code"),FAo=o("model.eval()"),TAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ide=a("code"),MAo=o("model.train()"),EAo=l(),F(d8.$$.fragment),NPe=l(),qi=a("h2"),c8=a("a"),qde=a("span"),F(OA.$$.fragment),CAo=l(),Nde=a("span"),wAo=o("AutoModelForSequenceClassification"),jPe=l(),Ro=a("div"),F(VA.$$.fragment),AAo=l(),Ni=a("p"),yAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Hj=a("a"),LAo=o("from_pretrained()"),xAo=o(" class method or the "),Uj=a("a"),$Ao=o("from_config()"),kAo=o(` class
method.`),SAo=l(),XA=a("p"),RAo=o("This class cannot be instantiated directly using "),jde=a("code"),BAo=o("__init__()"),PAo=o(" (throws an error)."),IAo=l(),st=a("div"),F(zA.$$.fragment),qAo=l(),Dde=a("p"),NAo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),jAo=l(),ji=a("p"),DAo=o(`Note:
Loading a model from its configuration file does `),Gde=a("strong"),GAo=o("not"),OAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jj=a("a"),VAo=o("from_pretrained()"),XAo=o(" to load the model weights."),zAo=l(),F(f8.$$.fragment),QAo=l(),Ze=a("div"),F(QA.$$.fragment),WAo=l(),Ode=a("p"),HAo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),UAo=l(),ka=a("p"),JAo=o("The model class to instantiate is selected based on the "),Vde=a("code"),YAo=o("model_type"),KAo=o(` property of the config object (either
passed as an argument or loaded from `),Xde=a("code"),ZAo=o("pretrained_model_name_or_path"),e0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zde=a("code"),o0o=o("pretrained_model_name_or_path"),r0o=o(":"),t0o=l(),q=a("ul"),m8=a("li"),Qde=a("strong"),a0o=o("albert"),n0o=o(" \u2014 "),Yj=a("a"),s0o=o("AlbertForSequenceClassification"),l0o=o(" (ALBERT model)"),i0o=l(),g8=a("li"),Wde=a("strong"),d0o=o("bart"),c0o=o(" \u2014 "),Kj=a("a"),f0o=o("BartForSequenceClassification"),m0o=o(" (BART model)"),g0o=l(),h8=a("li"),Hde=a("strong"),h0o=o("bert"),p0o=o(" \u2014 "),Zj=a("a"),u0o=o("BertForSequenceClassification"),_0o=o(" (BERT model)"),b0o=l(),p8=a("li"),Ude=a("strong"),v0o=o("big_bird"),F0o=o(" \u2014 "),eD=a("a"),T0o=o("BigBirdForSequenceClassification"),M0o=o(" (BigBird model)"),E0o=l(),u8=a("li"),Jde=a("strong"),C0o=o("bigbird_pegasus"),w0o=o(" \u2014 "),oD=a("a"),A0o=o("BigBirdPegasusForSequenceClassification"),y0o=o(" (BigBirdPegasus model)"),L0o=l(),_8=a("li"),Yde=a("strong"),x0o=o("camembert"),$0o=o(" \u2014 "),rD=a("a"),k0o=o("CamembertForSequenceClassification"),S0o=o(" (CamemBERT model)"),R0o=l(),b8=a("li"),Kde=a("strong"),B0o=o("canine"),P0o=o(" \u2014 "),tD=a("a"),I0o=o("CanineForSequenceClassification"),q0o=o(" (Canine model)"),N0o=l(),v8=a("li"),Zde=a("strong"),j0o=o("convbert"),D0o=o(" \u2014 "),aD=a("a"),G0o=o("ConvBertForSequenceClassification"),O0o=o(" (ConvBERT model)"),V0o=l(),F8=a("li"),ece=a("strong"),X0o=o("ctrl"),z0o=o(" \u2014 "),nD=a("a"),Q0o=o("CTRLForSequenceClassification"),W0o=o(" (CTRL model)"),H0o=l(),T8=a("li"),oce=a("strong"),U0o=o("data2vec-text"),J0o=o(" \u2014 "),sD=a("a"),Y0o=o("Data2VecTextForSequenceClassification"),K0o=o(" (Data2VecText model)"),Z0o=l(),M8=a("li"),rce=a("strong"),eyo=o("deberta"),oyo=o(" \u2014 "),lD=a("a"),ryo=o("DebertaForSequenceClassification"),tyo=o(" (DeBERTa model)"),ayo=l(),E8=a("li"),tce=a("strong"),nyo=o("deberta-v2"),syo=o(" \u2014 "),iD=a("a"),lyo=o("DebertaV2ForSequenceClassification"),iyo=o(" (DeBERTa-v2 model)"),dyo=l(),C8=a("li"),ace=a("strong"),cyo=o("distilbert"),fyo=o(" \u2014 "),dD=a("a"),myo=o("DistilBertForSequenceClassification"),gyo=o(" (DistilBERT model)"),hyo=l(),w8=a("li"),nce=a("strong"),pyo=o("electra"),uyo=o(" \u2014 "),cD=a("a"),_yo=o("ElectraForSequenceClassification"),byo=o(" (ELECTRA model)"),vyo=l(),A8=a("li"),sce=a("strong"),Fyo=o("flaubert"),Tyo=o(" \u2014 "),fD=a("a"),Myo=o("FlaubertForSequenceClassification"),Eyo=o(" (FlauBERT model)"),Cyo=l(),y8=a("li"),lce=a("strong"),wyo=o("fnet"),Ayo=o(" \u2014 "),mD=a("a"),yyo=o("FNetForSequenceClassification"),Lyo=o(" (FNet model)"),xyo=l(),L8=a("li"),ice=a("strong"),$yo=o("funnel"),kyo=o(" \u2014 "),gD=a("a"),Syo=o("FunnelForSequenceClassification"),Ryo=o(" (Funnel Transformer model)"),Byo=l(),x8=a("li"),dce=a("strong"),Pyo=o("gpt2"),Iyo=o(" \u2014 "),hD=a("a"),qyo=o("GPT2ForSequenceClassification"),Nyo=o(" (OpenAI GPT-2 model)"),jyo=l(),$8=a("li"),cce=a("strong"),Dyo=o("gpt_neo"),Gyo=o(" \u2014 "),pD=a("a"),Oyo=o("GPTNeoForSequenceClassification"),Vyo=o(" (GPT Neo model)"),Xyo=l(),k8=a("li"),fce=a("strong"),zyo=o("gptj"),Qyo=o(" \u2014 "),uD=a("a"),Wyo=o("GPTJForSequenceClassification"),Hyo=o(" (GPT-J model)"),Uyo=l(),S8=a("li"),mce=a("strong"),Jyo=o("ibert"),Yyo=o(" \u2014 "),_D=a("a"),Kyo=o("IBertForSequenceClassification"),Zyo=o(" (I-BERT model)"),eLo=l(),R8=a("li"),gce=a("strong"),oLo=o("layoutlm"),rLo=o(" \u2014 "),bD=a("a"),tLo=o("LayoutLMForSequenceClassification"),aLo=o(" (LayoutLM model)"),nLo=l(),B8=a("li"),hce=a("strong"),sLo=o("layoutlmv2"),lLo=o(" \u2014 "),vD=a("a"),iLo=o("LayoutLMv2ForSequenceClassification"),dLo=o(" (LayoutLMv2 model)"),cLo=l(),P8=a("li"),pce=a("strong"),fLo=o("led"),mLo=o(" \u2014 "),FD=a("a"),gLo=o("LEDForSequenceClassification"),hLo=o(" (LED model)"),pLo=l(),I8=a("li"),uce=a("strong"),uLo=o("longformer"),_Lo=o(" \u2014 "),TD=a("a"),bLo=o("LongformerForSequenceClassification"),vLo=o(" (Longformer model)"),FLo=l(),q8=a("li"),_ce=a("strong"),TLo=o("mbart"),MLo=o(" \u2014 "),MD=a("a"),ELo=o("MBartForSequenceClassification"),CLo=o(" (mBART model)"),wLo=l(),N8=a("li"),bce=a("strong"),ALo=o("megatron-bert"),yLo=o(" \u2014 "),ED=a("a"),LLo=o("MegatronBertForSequenceClassification"),xLo=o(" (MegatronBert model)"),$Lo=l(),j8=a("li"),vce=a("strong"),kLo=o("mobilebert"),SLo=o(" \u2014 "),CD=a("a"),RLo=o("MobileBertForSequenceClassification"),BLo=o(" (MobileBERT model)"),PLo=l(),D8=a("li"),Fce=a("strong"),ILo=o("mpnet"),qLo=o(" \u2014 "),wD=a("a"),NLo=o("MPNetForSequenceClassification"),jLo=o(" (MPNet model)"),DLo=l(),G8=a("li"),Tce=a("strong"),GLo=o("nystromformer"),OLo=o(" \u2014 "),AD=a("a"),VLo=o("NystromformerForSequenceClassification"),XLo=o(" (Nystromformer model)"),zLo=l(),O8=a("li"),Mce=a("strong"),QLo=o("openai-gpt"),WLo=o(" \u2014 "),yD=a("a"),HLo=o("OpenAIGPTForSequenceClassification"),ULo=o(" (OpenAI GPT model)"),JLo=l(),V8=a("li"),Ece=a("strong"),YLo=o("perceiver"),KLo=o(" \u2014 "),LD=a("a"),ZLo=o("PerceiverForSequenceClassification"),exo=o(" (Perceiver model)"),oxo=l(),X8=a("li"),Cce=a("strong"),rxo=o("plbart"),txo=o(" \u2014 "),xD=a("a"),axo=o("PLBartForSequenceClassification"),nxo=o(" (PLBart model)"),sxo=l(),z8=a("li"),wce=a("strong"),lxo=o("qdqbert"),ixo=o(" \u2014 "),$D=a("a"),dxo=o("QDQBertForSequenceClassification"),cxo=o(" (QDQBert model)"),fxo=l(),Q8=a("li"),Ace=a("strong"),mxo=o("reformer"),gxo=o(" \u2014 "),kD=a("a"),hxo=o("ReformerForSequenceClassification"),pxo=o(" (Reformer model)"),uxo=l(),W8=a("li"),yce=a("strong"),_xo=o("rembert"),bxo=o(" \u2014 "),SD=a("a"),vxo=o("RemBertForSequenceClassification"),Fxo=o(" (RemBERT model)"),Txo=l(),H8=a("li"),Lce=a("strong"),Mxo=o("roberta"),Exo=o(" \u2014 "),RD=a("a"),Cxo=o("RobertaForSequenceClassification"),wxo=o(" (RoBERTa model)"),Axo=l(),U8=a("li"),xce=a("strong"),yxo=o("roformer"),Lxo=o(" \u2014 "),BD=a("a"),xxo=o("RoFormerForSequenceClassification"),$xo=o(" (RoFormer model)"),kxo=l(),J8=a("li"),$ce=a("strong"),Sxo=o("squeezebert"),Rxo=o(" \u2014 "),PD=a("a"),Bxo=o("SqueezeBertForSequenceClassification"),Pxo=o(" (SqueezeBERT model)"),Ixo=l(),Y8=a("li"),kce=a("strong"),qxo=o("tapas"),Nxo=o(" \u2014 "),ID=a("a"),jxo=o("TapasForSequenceClassification"),Dxo=o(" (TAPAS model)"),Gxo=l(),K8=a("li"),Sce=a("strong"),Oxo=o("tapex"),Vxo=o(" \u2014 "),qD=a("a"),Xxo=o("BartForSequenceClassification"),zxo=o(" (TAPEX model)"),Qxo=l(),Z8=a("li"),Rce=a("strong"),Wxo=o("transfo-xl"),Hxo=o(" \u2014 "),ND=a("a"),Uxo=o("TransfoXLForSequenceClassification"),Jxo=o(" (Transformer-XL model)"),Yxo=l(),eb=a("li"),Bce=a("strong"),Kxo=o("xlm"),Zxo=o(" \u2014 "),jD=a("a"),e7o=o("XLMForSequenceClassification"),o7o=o(" (XLM model)"),r7o=l(),ob=a("li"),Pce=a("strong"),t7o=o("xlm-roberta"),a7o=o(" \u2014 "),DD=a("a"),n7o=o("XLMRobertaForSequenceClassification"),s7o=o(" (XLM-RoBERTa model)"),l7o=l(),rb=a("li"),Ice=a("strong"),i7o=o("xlm-roberta-xl"),d7o=o(" \u2014 "),GD=a("a"),c7o=o("XLMRobertaXLForSequenceClassification"),f7o=o(" (XLM-RoBERTa-XL model)"),m7o=l(),tb=a("li"),qce=a("strong"),g7o=o("xlnet"),h7o=o(" \u2014 "),OD=a("a"),p7o=o("XLNetForSequenceClassification"),u7o=o(" (XLNet model)"),_7o=l(),ab=a("li"),Nce=a("strong"),b7o=o("yoso"),v7o=o(" \u2014 "),VD=a("a"),F7o=o("YosoForSequenceClassification"),T7o=o(" (YOSO model)"),M7o=l(),nb=a("p"),E7o=o("The model is set in evaluation mode by default using "),jce=a("code"),C7o=o("model.eval()"),w7o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dce=a("code"),A7o=o("model.train()"),y7o=l(),F(sb.$$.fragment),DPe=l(),Di=a("h2"),lb=a("a"),Gce=a("span"),F(WA.$$.fragment),L7o=l(),Oce=a("span"),x7o=o("AutoModelForMultipleChoice"),GPe=l(),Bo=a("div"),F(HA.$$.fragment),$7o=l(),Gi=a("p"),k7o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),XD=a("a"),S7o=o("from_pretrained()"),R7o=o(" class method or the "),zD=a("a"),B7o=o("from_config()"),P7o=o(` class
method.`),I7o=l(),UA=a("p"),q7o=o("This class cannot be instantiated directly using "),Vce=a("code"),N7o=o("__init__()"),j7o=o(" (throws an error)."),D7o=l(),lt=a("div"),F(JA.$$.fragment),G7o=l(),Xce=a("p"),O7o=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),V7o=l(),Oi=a("p"),X7o=o(`Note:
Loading a model from its configuration file does `),zce=a("strong"),z7o=o("not"),Q7o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QD=a("a"),W7o=o("from_pretrained()"),H7o=o(" to load the model weights."),U7o=l(),F(ib.$$.fragment),J7o=l(),eo=a("div"),F(YA.$$.fragment),Y7o=l(),Qce=a("p"),K7o=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Z7o=l(),Sa=a("p"),e$o=o("The model class to instantiate is selected based on the "),Wce=a("code"),o$o=o("model_type"),r$o=o(` property of the config object (either
passed as an argument or loaded from `),Hce=a("code"),t$o=o("pretrained_model_name_or_path"),a$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uce=a("code"),n$o=o("pretrained_model_name_or_path"),s$o=o(":"),l$o=l(),Y=a("ul"),db=a("li"),Jce=a("strong"),i$o=o("albert"),d$o=o(" \u2014 "),WD=a("a"),c$o=o("AlbertForMultipleChoice"),f$o=o(" (ALBERT model)"),m$o=l(),cb=a("li"),Yce=a("strong"),g$o=o("bert"),h$o=o(" \u2014 "),HD=a("a"),p$o=o("BertForMultipleChoice"),u$o=o(" (BERT model)"),_$o=l(),fb=a("li"),Kce=a("strong"),b$o=o("big_bird"),v$o=o(" \u2014 "),UD=a("a"),F$o=o("BigBirdForMultipleChoice"),T$o=o(" (BigBird model)"),M$o=l(),mb=a("li"),Zce=a("strong"),E$o=o("camembert"),C$o=o(" \u2014 "),JD=a("a"),w$o=o("CamembertForMultipleChoice"),A$o=o(" (CamemBERT model)"),y$o=l(),gb=a("li"),efe=a("strong"),L$o=o("canine"),x$o=o(" \u2014 "),YD=a("a"),$$o=o("CanineForMultipleChoice"),k$o=o(" (Canine model)"),S$o=l(),hb=a("li"),ofe=a("strong"),R$o=o("convbert"),B$o=o(" \u2014 "),KD=a("a"),P$o=o("ConvBertForMultipleChoice"),I$o=o(" (ConvBERT model)"),q$o=l(),pb=a("li"),rfe=a("strong"),N$o=o("data2vec-text"),j$o=o(" \u2014 "),ZD=a("a"),D$o=o("Data2VecTextForMultipleChoice"),G$o=o(" (Data2VecText model)"),O$o=l(),ub=a("li"),tfe=a("strong"),V$o=o("deberta-v2"),X$o=o(" \u2014 "),eG=a("a"),z$o=o("DebertaV2ForMultipleChoice"),Q$o=o(" (DeBERTa-v2 model)"),W$o=l(),_b=a("li"),afe=a("strong"),H$o=o("distilbert"),U$o=o(" \u2014 "),oG=a("a"),J$o=o("DistilBertForMultipleChoice"),Y$o=o(" (DistilBERT model)"),K$o=l(),bb=a("li"),nfe=a("strong"),Z$o=o("electra"),eko=o(" \u2014 "),rG=a("a"),oko=o("ElectraForMultipleChoice"),rko=o(" (ELECTRA model)"),tko=l(),vb=a("li"),sfe=a("strong"),ako=o("flaubert"),nko=o(" \u2014 "),tG=a("a"),sko=o("FlaubertForMultipleChoice"),lko=o(" (FlauBERT model)"),iko=l(),Fb=a("li"),lfe=a("strong"),dko=o("fnet"),cko=o(" \u2014 "),aG=a("a"),fko=o("FNetForMultipleChoice"),mko=o(" (FNet model)"),gko=l(),Tb=a("li"),ife=a("strong"),hko=o("funnel"),pko=o(" \u2014 "),nG=a("a"),uko=o("FunnelForMultipleChoice"),_ko=o(" (Funnel Transformer model)"),bko=l(),Mb=a("li"),dfe=a("strong"),vko=o("ibert"),Fko=o(" \u2014 "),sG=a("a"),Tko=o("IBertForMultipleChoice"),Mko=o(" (I-BERT model)"),Eko=l(),Eb=a("li"),cfe=a("strong"),Cko=o("longformer"),wko=o(" \u2014 "),lG=a("a"),Ako=o("LongformerForMultipleChoice"),yko=o(" (Longformer model)"),Lko=l(),Cb=a("li"),ffe=a("strong"),xko=o("megatron-bert"),$ko=o(" \u2014 "),iG=a("a"),kko=o("MegatronBertForMultipleChoice"),Sko=o(" (MegatronBert model)"),Rko=l(),wb=a("li"),mfe=a("strong"),Bko=o("mobilebert"),Pko=o(" \u2014 "),dG=a("a"),Iko=o("MobileBertForMultipleChoice"),qko=o(" (MobileBERT model)"),Nko=l(),Ab=a("li"),gfe=a("strong"),jko=o("mpnet"),Dko=o(" \u2014 "),cG=a("a"),Gko=o("MPNetForMultipleChoice"),Oko=o(" (MPNet model)"),Vko=l(),yb=a("li"),hfe=a("strong"),Xko=o("nystromformer"),zko=o(" \u2014 "),fG=a("a"),Qko=o("NystromformerForMultipleChoice"),Wko=o(" (Nystromformer model)"),Hko=l(),Lb=a("li"),pfe=a("strong"),Uko=o("qdqbert"),Jko=o(" \u2014 "),mG=a("a"),Yko=o("QDQBertForMultipleChoice"),Kko=o(" (QDQBert model)"),Zko=l(),xb=a("li"),ufe=a("strong"),eSo=o("rembert"),oSo=o(" \u2014 "),gG=a("a"),rSo=o("RemBertForMultipleChoice"),tSo=o(" (RemBERT model)"),aSo=l(),$b=a("li"),_fe=a("strong"),nSo=o("roberta"),sSo=o(" \u2014 "),hG=a("a"),lSo=o("RobertaForMultipleChoice"),iSo=o(" (RoBERTa model)"),dSo=l(),kb=a("li"),bfe=a("strong"),cSo=o("roformer"),fSo=o(" \u2014 "),pG=a("a"),mSo=o("RoFormerForMultipleChoice"),gSo=o(" (RoFormer model)"),hSo=l(),Sb=a("li"),vfe=a("strong"),pSo=o("squeezebert"),uSo=o(" \u2014 "),uG=a("a"),_So=o("SqueezeBertForMultipleChoice"),bSo=o(" (SqueezeBERT model)"),vSo=l(),Rb=a("li"),Ffe=a("strong"),FSo=o("xlm"),TSo=o(" \u2014 "),_G=a("a"),MSo=o("XLMForMultipleChoice"),ESo=o(" (XLM model)"),CSo=l(),Bb=a("li"),Tfe=a("strong"),wSo=o("xlm-roberta"),ASo=o(" \u2014 "),bG=a("a"),ySo=o("XLMRobertaForMultipleChoice"),LSo=o(" (XLM-RoBERTa model)"),xSo=l(),Pb=a("li"),Mfe=a("strong"),$So=o("xlm-roberta-xl"),kSo=o(" \u2014 "),vG=a("a"),SSo=o("XLMRobertaXLForMultipleChoice"),RSo=o(" (XLM-RoBERTa-XL model)"),BSo=l(),Ib=a("li"),Efe=a("strong"),PSo=o("xlnet"),ISo=o(" \u2014 "),FG=a("a"),qSo=o("XLNetForMultipleChoice"),NSo=o(" (XLNet model)"),jSo=l(),qb=a("li"),Cfe=a("strong"),DSo=o("yoso"),GSo=o(" \u2014 "),TG=a("a"),OSo=o("YosoForMultipleChoice"),VSo=o(" (YOSO model)"),XSo=l(),Nb=a("p"),zSo=o("The model is set in evaluation mode by default using "),wfe=a("code"),QSo=o("model.eval()"),WSo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Afe=a("code"),HSo=o("model.train()"),USo=l(),F(jb.$$.fragment),OPe=l(),Vi=a("h2"),Db=a("a"),yfe=a("span"),F(KA.$$.fragment),JSo=l(),Lfe=a("span"),YSo=o("AutoModelForNextSentencePrediction"),VPe=l(),Po=a("div"),F(ZA.$$.fragment),KSo=l(),Xi=a("p"),ZSo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),MG=a("a"),eRo=o("from_pretrained()"),oRo=o(" class method or the "),EG=a("a"),rRo=o("from_config()"),tRo=o(` class
method.`),aRo=l(),e0=a("p"),nRo=o("This class cannot be instantiated directly using "),xfe=a("code"),sRo=o("__init__()"),lRo=o(" (throws an error)."),iRo=l(),it=a("div"),F(o0.$$.fragment),dRo=l(),$fe=a("p"),cRo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),fRo=l(),zi=a("p"),mRo=o(`Note:
Loading a model from its configuration file does `),kfe=a("strong"),gRo=o("not"),hRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CG=a("a"),pRo=o("from_pretrained()"),uRo=o(" to load the model weights."),_Ro=l(),F(Gb.$$.fragment),bRo=l(),oo=a("div"),F(r0.$$.fragment),vRo=l(),Sfe=a("p"),FRo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),TRo=l(),Ra=a("p"),MRo=o("The model class to instantiate is selected based on the "),Rfe=a("code"),ERo=o("model_type"),CRo=o(` property of the config object (either
passed as an argument or loaded from `),Bfe=a("code"),wRo=o("pretrained_model_name_or_path"),ARo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pfe=a("code"),yRo=o("pretrained_model_name_or_path"),LRo=o(":"),xRo=l(),Yr=a("ul"),Ob=a("li"),Ife=a("strong"),$Ro=o("bert"),kRo=o(" \u2014 "),wG=a("a"),SRo=o("BertForNextSentencePrediction"),RRo=o(" (BERT model)"),BRo=l(),Vb=a("li"),qfe=a("strong"),PRo=o("fnet"),IRo=o(" \u2014 "),AG=a("a"),qRo=o("FNetForNextSentencePrediction"),NRo=o(" (FNet model)"),jRo=l(),Xb=a("li"),Nfe=a("strong"),DRo=o("megatron-bert"),GRo=o(" \u2014 "),yG=a("a"),ORo=o("MegatronBertForNextSentencePrediction"),VRo=o(" (MegatronBert model)"),XRo=l(),zb=a("li"),jfe=a("strong"),zRo=o("mobilebert"),QRo=o(" \u2014 "),LG=a("a"),WRo=o("MobileBertForNextSentencePrediction"),HRo=o(" (MobileBERT model)"),URo=l(),Qb=a("li"),Dfe=a("strong"),JRo=o("qdqbert"),YRo=o(" \u2014 "),xG=a("a"),KRo=o("QDQBertForNextSentencePrediction"),ZRo=o(" (QDQBert model)"),eBo=l(),Wb=a("p"),oBo=o("The model is set in evaluation mode by default using "),Gfe=a("code"),rBo=o("model.eval()"),tBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=a("code"),aBo=o("model.train()"),nBo=l(),F(Hb.$$.fragment),XPe=l(),Qi=a("h2"),Ub=a("a"),Vfe=a("span"),F(t0.$$.fragment),sBo=l(),Xfe=a("span"),lBo=o("AutoModelForTokenClassification"),zPe=l(),Io=a("div"),F(a0.$$.fragment),iBo=l(),Wi=a("p"),dBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$G=a("a"),cBo=o("from_pretrained()"),fBo=o(" class method or the "),kG=a("a"),mBo=o("from_config()"),gBo=o(` class
method.`),hBo=l(),n0=a("p"),pBo=o("This class cannot be instantiated directly using "),zfe=a("code"),uBo=o("__init__()"),_Bo=o(" (throws an error)."),bBo=l(),dt=a("div"),F(s0.$$.fragment),vBo=l(),Qfe=a("p"),FBo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),TBo=l(),Hi=a("p"),MBo=o(`Note:
Loading a model from its configuration file does `),Wfe=a("strong"),EBo=o("not"),CBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SG=a("a"),wBo=o("from_pretrained()"),ABo=o(" to load the model weights."),yBo=l(),F(Jb.$$.fragment),LBo=l(),ro=a("div"),F(l0.$$.fragment),xBo=l(),Hfe=a("p"),$Bo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),kBo=l(),Ba=a("p"),SBo=o("The model class to instantiate is selected based on the "),Ufe=a("code"),RBo=o("model_type"),BBo=o(` property of the config object (either
passed as an argument or loaded from `),Jfe=a("code"),PBo=o("pretrained_model_name_or_path"),IBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=a("code"),qBo=o("pretrained_model_name_or_path"),NBo=o(":"),jBo=l(),U=a("ul"),Yb=a("li"),Kfe=a("strong"),DBo=o("albert"),GBo=o(" \u2014 "),RG=a("a"),OBo=o("AlbertForTokenClassification"),VBo=o(" (ALBERT model)"),XBo=l(),Kb=a("li"),Zfe=a("strong"),zBo=o("bert"),QBo=o(" \u2014 "),BG=a("a"),WBo=o("BertForTokenClassification"),HBo=o(" (BERT model)"),UBo=l(),Zb=a("li"),eme=a("strong"),JBo=o("big_bird"),YBo=o(" \u2014 "),PG=a("a"),KBo=o("BigBirdForTokenClassification"),ZBo=o(" (BigBird model)"),ePo=l(),e2=a("li"),ome=a("strong"),oPo=o("camembert"),rPo=o(" \u2014 "),IG=a("a"),tPo=o("CamembertForTokenClassification"),aPo=o(" (CamemBERT model)"),nPo=l(),o2=a("li"),rme=a("strong"),sPo=o("canine"),lPo=o(" \u2014 "),qG=a("a"),iPo=o("CanineForTokenClassification"),dPo=o(" (Canine model)"),cPo=l(),r2=a("li"),tme=a("strong"),fPo=o("convbert"),mPo=o(" \u2014 "),NG=a("a"),gPo=o("ConvBertForTokenClassification"),hPo=o(" (ConvBERT model)"),pPo=l(),t2=a("li"),ame=a("strong"),uPo=o("data2vec-text"),_Po=o(" \u2014 "),jG=a("a"),bPo=o("Data2VecTextForTokenClassification"),vPo=o(" (Data2VecText model)"),FPo=l(),a2=a("li"),nme=a("strong"),TPo=o("deberta"),MPo=o(" \u2014 "),DG=a("a"),EPo=o("DebertaForTokenClassification"),CPo=o(" (DeBERTa model)"),wPo=l(),n2=a("li"),sme=a("strong"),APo=o("deberta-v2"),yPo=o(" \u2014 "),GG=a("a"),LPo=o("DebertaV2ForTokenClassification"),xPo=o(" (DeBERTa-v2 model)"),$Po=l(),s2=a("li"),lme=a("strong"),kPo=o("distilbert"),SPo=o(" \u2014 "),OG=a("a"),RPo=o("DistilBertForTokenClassification"),BPo=o(" (DistilBERT model)"),PPo=l(),l2=a("li"),ime=a("strong"),IPo=o("electra"),qPo=o(" \u2014 "),VG=a("a"),NPo=o("ElectraForTokenClassification"),jPo=o(" (ELECTRA model)"),DPo=l(),i2=a("li"),dme=a("strong"),GPo=o("flaubert"),OPo=o(" \u2014 "),XG=a("a"),VPo=o("FlaubertForTokenClassification"),XPo=o(" (FlauBERT model)"),zPo=l(),d2=a("li"),cme=a("strong"),QPo=o("fnet"),WPo=o(" \u2014 "),zG=a("a"),HPo=o("FNetForTokenClassification"),UPo=o(" (FNet model)"),JPo=l(),c2=a("li"),fme=a("strong"),YPo=o("funnel"),KPo=o(" \u2014 "),QG=a("a"),ZPo=o("FunnelForTokenClassification"),eIo=o(" (Funnel Transformer model)"),oIo=l(),f2=a("li"),mme=a("strong"),rIo=o("gpt2"),tIo=o(" \u2014 "),WG=a("a"),aIo=o("GPT2ForTokenClassification"),nIo=o(" (OpenAI GPT-2 model)"),sIo=l(),m2=a("li"),gme=a("strong"),lIo=o("ibert"),iIo=o(" \u2014 "),HG=a("a"),dIo=o("IBertForTokenClassification"),cIo=o(" (I-BERT model)"),fIo=l(),g2=a("li"),hme=a("strong"),mIo=o("layoutlm"),gIo=o(" \u2014 "),UG=a("a"),hIo=o("LayoutLMForTokenClassification"),pIo=o(" (LayoutLM model)"),uIo=l(),h2=a("li"),pme=a("strong"),_Io=o("layoutlmv2"),bIo=o(" \u2014 "),JG=a("a"),vIo=o("LayoutLMv2ForTokenClassification"),FIo=o(" (LayoutLMv2 model)"),TIo=l(),p2=a("li"),ume=a("strong"),MIo=o("longformer"),EIo=o(" \u2014 "),YG=a("a"),CIo=o("LongformerForTokenClassification"),wIo=o(" (Longformer model)"),AIo=l(),u2=a("li"),_me=a("strong"),yIo=o("megatron-bert"),LIo=o(" \u2014 "),KG=a("a"),xIo=o("MegatronBertForTokenClassification"),$Io=o(" (MegatronBert model)"),kIo=l(),_2=a("li"),bme=a("strong"),SIo=o("mobilebert"),RIo=o(" \u2014 "),ZG=a("a"),BIo=o("MobileBertForTokenClassification"),PIo=o(" (MobileBERT model)"),IIo=l(),b2=a("li"),vme=a("strong"),qIo=o("mpnet"),NIo=o(" \u2014 "),eO=a("a"),jIo=o("MPNetForTokenClassification"),DIo=o(" (MPNet model)"),GIo=l(),v2=a("li"),Fme=a("strong"),OIo=o("nystromformer"),VIo=o(" \u2014 "),oO=a("a"),XIo=o("NystromformerForTokenClassification"),zIo=o(" (Nystromformer model)"),QIo=l(),F2=a("li"),Tme=a("strong"),WIo=o("qdqbert"),HIo=o(" \u2014 "),rO=a("a"),UIo=o("QDQBertForTokenClassification"),JIo=o(" (QDQBert model)"),YIo=l(),T2=a("li"),Mme=a("strong"),KIo=o("rembert"),ZIo=o(" \u2014 "),tO=a("a"),eqo=o("RemBertForTokenClassification"),oqo=o(" (RemBERT model)"),rqo=l(),M2=a("li"),Eme=a("strong"),tqo=o("roberta"),aqo=o(" \u2014 "),aO=a("a"),nqo=o("RobertaForTokenClassification"),sqo=o(" (RoBERTa model)"),lqo=l(),E2=a("li"),Cme=a("strong"),iqo=o("roformer"),dqo=o(" \u2014 "),nO=a("a"),cqo=o("RoFormerForTokenClassification"),fqo=o(" (RoFormer model)"),mqo=l(),C2=a("li"),wme=a("strong"),gqo=o("squeezebert"),hqo=o(" \u2014 "),sO=a("a"),pqo=o("SqueezeBertForTokenClassification"),uqo=o(" (SqueezeBERT model)"),_qo=l(),w2=a("li"),Ame=a("strong"),bqo=o("xlm"),vqo=o(" \u2014 "),lO=a("a"),Fqo=o("XLMForTokenClassification"),Tqo=o(" (XLM model)"),Mqo=l(),A2=a("li"),yme=a("strong"),Eqo=o("xlm-roberta"),Cqo=o(" \u2014 "),iO=a("a"),wqo=o("XLMRobertaForTokenClassification"),Aqo=o(" (XLM-RoBERTa model)"),yqo=l(),y2=a("li"),Lme=a("strong"),Lqo=o("xlm-roberta-xl"),xqo=o(" \u2014 "),dO=a("a"),$qo=o("XLMRobertaXLForTokenClassification"),kqo=o(" (XLM-RoBERTa-XL model)"),Sqo=l(),L2=a("li"),xme=a("strong"),Rqo=o("xlnet"),Bqo=o(" \u2014 "),cO=a("a"),Pqo=o("XLNetForTokenClassification"),Iqo=o(" (XLNet model)"),qqo=l(),x2=a("li"),$me=a("strong"),Nqo=o("yoso"),jqo=o(" \u2014 "),fO=a("a"),Dqo=o("YosoForTokenClassification"),Gqo=o(" (YOSO model)"),Oqo=l(),$2=a("p"),Vqo=o("The model is set in evaluation mode by default using "),kme=a("code"),Xqo=o("model.eval()"),zqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sme=a("code"),Qqo=o("model.train()"),Wqo=l(),F(k2.$$.fragment),QPe=l(),Ui=a("h2"),S2=a("a"),Rme=a("span"),F(i0.$$.fragment),Hqo=l(),Bme=a("span"),Uqo=o("AutoModelForQuestionAnswering"),WPe=l(),qo=a("div"),F(d0.$$.fragment),Jqo=l(),Ji=a("p"),Yqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),mO=a("a"),Kqo=o("from_pretrained()"),Zqo=o(" class method or the "),gO=a("a"),eNo=o("from_config()"),oNo=o(` class
method.`),rNo=l(),c0=a("p"),tNo=o("This class cannot be instantiated directly using "),Pme=a("code"),aNo=o("__init__()"),nNo=o(" (throws an error)."),sNo=l(),ct=a("div"),F(f0.$$.fragment),lNo=l(),Ime=a("p"),iNo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),dNo=l(),Yi=a("p"),cNo=o(`Note:
Loading a model from its configuration file does `),qme=a("strong"),fNo=o("not"),mNo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=a("a"),gNo=o("from_pretrained()"),hNo=o(" to load the model weights."),pNo=l(),F(R2.$$.fragment),uNo=l(),to=a("div"),F(m0.$$.fragment),_No=l(),Nme=a("p"),bNo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),vNo=l(),Pa=a("p"),FNo=o("The model class to instantiate is selected based on the "),jme=a("code"),TNo=o("model_type"),MNo=o(` property of the config object (either
passed as an argument or loaded from `),Dme=a("code"),ENo=o("pretrained_model_name_or_path"),CNo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gme=a("code"),wNo=o("pretrained_model_name_or_path"),ANo=o(":"),yNo=l(),O=a("ul"),B2=a("li"),Ome=a("strong"),LNo=o("albert"),xNo=o(" \u2014 "),pO=a("a"),$No=o("AlbertForQuestionAnswering"),kNo=o(" (ALBERT model)"),SNo=l(),P2=a("li"),Vme=a("strong"),RNo=o("bart"),BNo=o(" \u2014 "),uO=a("a"),PNo=o("BartForQuestionAnswering"),INo=o(" (BART model)"),qNo=l(),I2=a("li"),Xme=a("strong"),NNo=o("bert"),jNo=o(" \u2014 "),_O=a("a"),DNo=o("BertForQuestionAnswering"),GNo=o(" (BERT model)"),ONo=l(),q2=a("li"),zme=a("strong"),VNo=o("big_bird"),XNo=o(" \u2014 "),bO=a("a"),zNo=o("BigBirdForQuestionAnswering"),QNo=o(" (BigBird model)"),WNo=l(),N2=a("li"),Qme=a("strong"),HNo=o("bigbird_pegasus"),UNo=o(" \u2014 "),vO=a("a"),JNo=o("BigBirdPegasusForQuestionAnswering"),YNo=o(" (BigBirdPegasus model)"),KNo=l(),j2=a("li"),Wme=a("strong"),ZNo=o("camembert"),ejo=o(" \u2014 "),FO=a("a"),ojo=o("CamembertForQuestionAnswering"),rjo=o(" (CamemBERT model)"),tjo=l(),D2=a("li"),Hme=a("strong"),ajo=o("canine"),njo=o(" \u2014 "),TO=a("a"),sjo=o("CanineForQuestionAnswering"),ljo=o(" (Canine model)"),ijo=l(),G2=a("li"),Ume=a("strong"),djo=o("convbert"),cjo=o(" \u2014 "),MO=a("a"),fjo=o("ConvBertForQuestionAnswering"),mjo=o(" (ConvBERT model)"),gjo=l(),O2=a("li"),Jme=a("strong"),hjo=o("data2vec-text"),pjo=o(" \u2014 "),EO=a("a"),ujo=o("Data2VecTextForQuestionAnswering"),_jo=o(" (Data2VecText model)"),bjo=l(),V2=a("li"),Yme=a("strong"),vjo=o("deberta"),Fjo=o(" \u2014 "),CO=a("a"),Tjo=o("DebertaForQuestionAnswering"),Mjo=o(" (DeBERTa model)"),Ejo=l(),X2=a("li"),Kme=a("strong"),Cjo=o("deberta-v2"),wjo=o(" \u2014 "),wO=a("a"),Ajo=o("DebertaV2ForQuestionAnswering"),yjo=o(" (DeBERTa-v2 model)"),Ljo=l(),z2=a("li"),Zme=a("strong"),xjo=o("distilbert"),$jo=o(" \u2014 "),AO=a("a"),kjo=o("DistilBertForQuestionAnswering"),Sjo=o(" (DistilBERT model)"),Rjo=l(),Q2=a("li"),ege=a("strong"),Bjo=o("electra"),Pjo=o(" \u2014 "),yO=a("a"),Ijo=o("ElectraForQuestionAnswering"),qjo=o(" (ELECTRA model)"),Njo=l(),W2=a("li"),oge=a("strong"),jjo=o("flaubert"),Djo=o(" \u2014 "),LO=a("a"),Gjo=o("FlaubertForQuestionAnsweringSimple"),Ojo=o(" (FlauBERT model)"),Vjo=l(),H2=a("li"),rge=a("strong"),Xjo=o("fnet"),zjo=o(" \u2014 "),xO=a("a"),Qjo=o("FNetForQuestionAnswering"),Wjo=o(" (FNet model)"),Hjo=l(),U2=a("li"),tge=a("strong"),Ujo=o("funnel"),Jjo=o(" \u2014 "),$O=a("a"),Yjo=o("FunnelForQuestionAnswering"),Kjo=o(" (Funnel Transformer model)"),Zjo=l(),J2=a("li"),age=a("strong"),eDo=o("gptj"),oDo=o(" \u2014 "),kO=a("a"),rDo=o("GPTJForQuestionAnswering"),tDo=o(" (GPT-J model)"),aDo=l(),Y2=a("li"),nge=a("strong"),nDo=o("ibert"),sDo=o(" \u2014 "),SO=a("a"),lDo=o("IBertForQuestionAnswering"),iDo=o(" (I-BERT model)"),dDo=l(),K2=a("li"),sge=a("strong"),cDo=o("layoutlmv2"),fDo=o(" \u2014 "),RO=a("a"),mDo=o("LayoutLMv2ForQuestionAnswering"),gDo=o(" (LayoutLMv2 model)"),hDo=l(),Z2=a("li"),lge=a("strong"),pDo=o("led"),uDo=o(" \u2014 "),BO=a("a"),_Do=o("LEDForQuestionAnswering"),bDo=o(" (LED model)"),vDo=l(),ev=a("li"),ige=a("strong"),FDo=o("longformer"),TDo=o(" \u2014 "),PO=a("a"),MDo=o("LongformerForQuestionAnswering"),EDo=o(" (Longformer model)"),CDo=l(),ov=a("li"),dge=a("strong"),wDo=o("lxmert"),ADo=o(" \u2014 "),IO=a("a"),yDo=o("LxmertForQuestionAnswering"),LDo=o(" (LXMERT model)"),xDo=l(),rv=a("li"),cge=a("strong"),$Do=o("mbart"),kDo=o(" \u2014 "),qO=a("a"),SDo=o("MBartForQuestionAnswering"),RDo=o(" (mBART model)"),BDo=l(),tv=a("li"),fge=a("strong"),PDo=o("megatron-bert"),IDo=o(" \u2014 "),NO=a("a"),qDo=o("MegatronBertForQuestionAnswering"),NDo=o(" (MegatronBert model)"),jDo=l(),av=a("li"),mge=a("strong"),DDo=o("mobilebert"),GDo=o(" \u2014 "),jO=a("a"),ODo=o("MobileBertForQuestionAnswering"),VDo=o(" (MobileBERT model)"),XDo=l(),nv=a("li"),gge=a("strong"),zDo=o("mpnet"),QDo=o(" \u2014 "),DO=a("a"),WDo=o("MPNetForQuestionAnswering"),HDo=o(" (MPNet model)"),UDo=l(),sv=a("li"),hge=a("strong"),JDo=o("nystromformer"),YDo=o(" \u2014 "),GO=a("a"),KDo=o("NystromformerForQuestionAnswering"),ZDo=o(" (Nystromformer model)"),eGo=l(),lv=a("li"),pge=a("strong"),oGo=o("qdqbert"),rGo=o(" \u2014 "),OO=a("a"),tGo=o("QDQBertForQuestionAnswering"),aGo=o(" (QDQBert model)"),nGo=l(),iv=a("li"),uge=a("strong"),sGo=o("reformer"),lGo=o(" \u2014 "),VO=a("a"),iGo=o("ReformerForQuestionAnswering"),dGo=o(" (Reformer model)"),cGo=l(),dv=a("li"),_ge=a("strong"),fGo=o("rembert"),mGo=o(" \u2014 "),XO=a("a"),gGo=o("RemBertForQuestionAnswering"),hGo=o(" (RemBERT model)"),pGo=l(),cv=a("li"),bge=a("strong"),uGo=o("roberta"),_Go=o(" \u2014 "),zO=a("a"),bGo=o("RobertaForQuestionAnswering"),vGo=o(" (RoBERTa model)"),FGo=l(),fv=a("li"),vge=a("strong"),TGo=o("roformer"),MGo=o(" \u2014 "),QO=a("a"),EGo=o("RoFormerForQuestionAnswering"),CGo=o(" (RoFormer model)"),wGo=l(),mv=a("li"),Fge=a("strong"),AGo=o("splinter"),yGo=o(" \u2014 "),WO=a("a"),LGo=o("SplinterForQuestionAnswering"),xGo=o(" (Splinter model)"),$Go=l(),gv=a("li"),Tge=a("strong"),kGo=o("squeezebert"),SGo=o(" \u2014 "),HO=a("a"),RGo=o("SqueezeBertForQuestionAnswering"),BGo=o(" (SqueezeBERT model)"),PGo=l(),hv=a("li"),Mge=a("strong"),IGo=o("xlm"),qGo=o(" \u2014 "),UO=a("a"),NGo=o("XLMForQuestionAnsweringSimple"),jGo=o(" (XLM model)"),DGo=l(),pv=a("li"),Ege=a("strong"),GGo=o("xlm-roberta"),OGo=o(" \u2014 "),JO=a("a"),VGo=o("XLMRobertaForQuestionAnswering"),XGo=o(" (XLM-RoBERTa model)"),zGo=l(),uv=a("li"),Cge=a("strong"),QGo=o("xlm-roberta-xl"),WGo=o(" \u2014 "),YO=a("a"),HGo=o("XLMRobertaXLForQuestionAnswering"),UGo=o(" (XLM-RoBERTa-XL model)"),JGo=l(),_v=a("li"),wge=a("strong"),YGo=o("xlnet"),KGo=o(" \u2014 "),KO=a("a"),ZGo=o("XLNetForQuestionAnsweringSimple"),eOo=o(" (XLNet model)"),oOo=l(),bv=a("li"),Age=a("strong"),rOo=o("yoso"),tOo=o(" \u2014 "),ZO=a("a"),aOo=o("YosoForQuestionAnswering"),nOo=o(" (YOSO model)"),sOo=l(),vv=a("p"),lOo=o("The model is set in evaluation mode by default using "),yge=a("code"),iOo=o("model.eval()"),dOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lge=a("code"),cOo=o("model.train()"),fOo=l(),F(Fv.$$.fragment),HPe=l(),Ki=a("h2"),Tv=a("a"),xge=a("span"),F(g0.$$.fragment),mOo=l(),$ge=a("span"),gOo=o("AutoModelForTableQuestionAnswering"),UPe=l(),No=a("div"),F(h0.$$.fragment),hOo=l(),Zi=a("p"),pOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),eV=a("a"),uOo=o("from_pretrained()"),_Oo=o(" class method or the "),oV=a("a"),bOo=o("from_config()"),vOo=o(` class
method.`),FOo=l(),p0=a("p"),TOo=o("This class cannot be instantiated directly using "),kge=a("code"),MOo=o("__init__()"),EOo=o(" (throws an error)."),COo=l(),ft=a("div"),F(u0.$$.fragment),wOo=l(),Sge=a("p"),AOo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),yOo=l(),ed=a("p"),LOo=o(`Note:
Loading a model from its configuration file does `),Rge=a("strong"),xOo=o("not"),$Oo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rV=a("a"),kOo=o("from_pretrained()"),SOo=o(" to load the model weights."),ROo=l(),F(Mv.$$.fragment),BOo=l(),ao=a("div"),F(_0.$$.fragment),POo=l(),Bge=a("p"),IOo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),qOo=l(),Ia=a("p"),NOo=o("The model class to instantiate is selected based on the "),Pge=a("code"),jOo=o("model_type"),DOo=o(` property of the config object (either
passed as an argument or loaded from `),Ige=a("code"),GOo=o("pretrained_model_name_or_path"),OOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qge=a("code"),VOo=o("pretrained_model_name_or_path"),XOo=o(":"),zOo=l(),Nge=a("ul"),Ev=a("li"),jge=a("strong"),QOo=o("tapas"),WOo=o(" \u2014 "),tV=a("a"),HOo=o("TapasForQuestionAnswering"),UOo=o(" (TAPAS model)"),JOo=l(),Cv=a("p"),YOo=o("The model is set in evaluation mode by default using "),Dge=a("code"),KOo=o("model.eval()"),ZOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gge=a("code"),eVo=o("model.train()"),oVo=l(),F(wv.$$.fragment),JPe=l(),od=a("h2"),Av=a("a"),Oge=a("span"),F(b0.$$.fragment),rVo=l(),Vge=a("span"),tVo=o("AutoModelForImageClassification"),YPe=l(),jo=a("div"),F(v0.$$.fragment),aVo=l(),rd=a("p"),nVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aV=a("a"),sVo=o("from_pretrained()"),lVo=o(" class method or the "),nV=a("a"),iVo=o("from_config()"),dVo=o(` class
method.`),cVo=l(),F0=a("p"),fVo=o("This class cannot be instantiated directly using "),Xge=a("code"),mVo=o("__init__()"),gVo=o(" (throws an error)."),hVo=l(),mt=a("div"),F(T0.$$.fragment),pVo=l(),zge=a("p"),uVo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_Vo=l(),td=a("p"),bVo=o(`Note:
Loading a model from its configuration file does `),Qge=a("strong"),vVo=o("not"),FVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sV=a("a"),TVo=o("from_pretrained()"),MVo=o(" to load the model weights."),EVo=l(),F(yv.$$.fragment),CVo=l(),no=a("div"),F(M0.$$.fragment),wVo=l(),Wge=a("p"),AVo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),yVo=l(),qa=a("p"),LVo=o("The model class to instantiate is selected based on the "),Hge=a("code"),xVo=o("model_type"),$Vo=o(` property of the config object (either
passed as an argument or loaded from `),Uge=a("code"),kVo=o("pretrained_model_name_or_path"),SVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jge=a("code"),RVo=o("pretrained_model_name_or_path"),BVo=o(":"),PVo=l(),ve=a("ul"),Lv=a("li"),Yge=a("strong"),IVo=o("beit"),qVo=o(" \u2014 "),lV=a("a"),NVo=o("BeitForImageClassification"),jVo=o(" (BEiT model)"),DVo=l(),xv=a("li"),Kge=a("strong"),GVo=o("convnext"),OVo=o(" \u2014 "),iV=a("a"),VVo=o("ConvNextForImageClassification"),XVo=o(" (ConvNext model)"),zVo=l(),$v=a("li"),Zge=a("strong"),QVo=o("data2vec-vision"),WVo=o(" \u2014 "),dV=a("a"),HVo=o("Data2VecVisionForImageClassification"),UVo=o(" (Data2VecVision model)"),JVo=l(),Bs=a("li"),ehe=a("strong"),YVo=o("deit"),KVo=o(" \u2014 "),cV=a("a"),ZVo=o("DeiTForImageClassification"),eXo=o(" or "),fV=a("a"),oXo=o("DeiTForImageClassificationWithTeacher"),rXo=o(" (DeiT model)"),tXo=l(),kv=a("li"),ohe=a("strong"),aXo=o("imagegpt"),nXo=o(" \u2014 "),mV=a("a"),sXo=o("ImageGPTForImageClassification"),lXo=o(" (ImageGPT model)"),iXo=l(),gt=a("li"),rhe=a("strong"),dXo=o("perceiver"),cXo=o(" \u2014 "),gV=a("a"),fXo=o("PerceiverForImageClassificationLearned"),mXo=o(" or "),hV=a("a"),gXo=o("PerceiverForImageClassificationFourier"),hXo=o(" or "),pV=a("a"),pXo=o("PerceiverForImageClassificationConvProcessing"),uXo=o(" (Perceiver model)"),_Xo=l(),Sv=a("li"),the=a("strong"),bXo=o("poolformer"),vXo=o(" \u2014 "),uV=a("a"),FXo=o("PoolFormerForImageClassification"),TXo=o(" (PoolFormer model)"),MXo=l(),Rv=a("li"),ahe=a("strong"),EXo=o("regnet"),CXo=o(" \u2014 "),_V=a("a"),wXo=o("RegNetForImageClassification"),AXo=o(" (RegNet model)"),yXo=l(),Bv=a("li"),nhe=a("strong"),LXo=o("resnet"),xXo=o(" \u2014 "),bV=a("a"),$Xo=o("ResNetForImageClassification"),kXo=o(" (ResNet model)"),SXo=l(),Pv=a("li"),she=a("strong"),RXo=o("segformer"),BXo=o(" \u2014 "),vV=a("a"),PXo=o("SegformerForImageClassification"),IXo=o(" (SegFormer model)"),qXo=l(),Iv=a("li"),lhe=a("strong"),NXo=o("swin"),jXo=o(" \u2014 "),FV=a("a"),DXo=o("SwinForImageClassification"),GXo=o(" (Swin model)"),OXo=l(),qv=a("li"),ihe=a("strong"),VXo=o("van"),XXo=o(" \u2014 "),TV=a("a"),zXo=o("VanForImageClassification"),QXo=o(" (VAN model)"),WXo=l(),Nv=a("li"),dhe=a("strong"),HXo=o("vit"),UXo=o(" \u2014 "),MV=a("a"),JXo=o("ViTForImageClassification"),YXo=o(" (ViT model)"),KXo=l(),jv=a("p"),ZXo=o("The model is set in evaluation mode by default using "),che=a("code"),ezo=o("model.eval()"),ozo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fhe=a("code"),rzo=o("model.train()"),tzo=l(),F(Dv.$$.fragment),KPe=l(),ad=a("h2"),Gv=a("a"),mhe=a("span"),F(E0.$$.fragment),azo=l(),ghe=a("span"),nzo=o("AutoModelForVision2Seq"),ZPe=l(),Do=a("div"),F(C0.$$.fragment),szo=l(),nd=a("p"),lzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),EV=a("a"),izo=o("from_pretrained()"),dzo=o(" class method or the "),CV=a("a"),czo=o("from_config()"),fzo=o(` class
method.`),mzo=l(),w0=a("p"),gzo=o("This class cannot be instantiated directly using "),hhe=a("code"),hzo=o("__init__()"),pzo=o(" (throws an error)."),uzo=l(),ht=a("div"),F(A0.$$.fragment),_zo=l(),phe=a("p"),bzo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),vzo=l(),sd=a("p"),Fzo=o(`Note:
Loading a model from its configuration file does `),uhe=a("strong"),Tzo=o("not"),Mzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wV=a("a"),Ezo=o("from_pretrained()"),Czo=o(" to load the model weights."),wzo=l(),F(Ov.$$.fragment),Azo=l(),so=a("div"),F(y0.$$.fragment),yzo=l(),_he=a("p"),Lzo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xzo=l(),Na=a("p"),$zo=o("The model class to instantiate is selected based on the "),bhe=a("code"),kzo=o("model_type"),Szo=o(` property of the config object (either
passed as an argument or loaded from `),vhe=a("code"),Rzo=o("pretrained_model_name_or_path"),Bzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fhe=a("code"),Pzo=o("pretrained_model_name_or_path"),Izo=o(":"),qzo=l(),The=a("ul"),Vv=a("li"),Mhe=a("strong"),Nzo=o("vision-encoder-decoder"),jzo=o(" \u2014 "),AV=a("a"),Dzo=o("VisionEncoderDecoderModel"),Gzo=o(" (Vision Encoder decoder model)"),Ozo=l(),Xv=a("p"),Vzo=o("The model is set in evaluation mode by default using "),Ehe=a("code"),Xzo=o("model.eval()"),zzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Che=a("code"),Qzo=o("model.train()"),Wzo=l(),F(zv.$$.fragment),eIe=l(),ld=a("h2"),Qv=a("a"),whe=a("span"),F(L0.$$.fragment),Hzo=l(),Ahe=a("span"),Uzo=o("AutoModelForAudioClassification"),oIe=l(),Go=a("div"),F(x0.$$.fragment),Jzo=l(),id=a("p"),Yzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),yV=a("a"),Kzo=o("from_pretrained()"),Zzo=o(" class method or the "),LV=a("a"),eQo=o("from_config()"),oQo=o(` class
method.`),rQo=l(),$0=a("p"),tQo=o("This class cannot be instantiated directly using "),yhe=a("code"),aQo=o("__init__()"),nQo=o(" (throws an error)."),sQo=l(),pt=a("div"),F(k0.$$.fragment),lQo=l(),Lhe=a("p"),iQo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),dQo=l(),dd=a("p"),cQo=o(`Note:
Loading a model from its configuration file does `),xhe=a("strong"),fQo=o("not"),mQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xV=a("a"),gQo=o("from_pretrained()"),hQo=o(" to load the model weights."),pQo=l(),F(Wv.$$.fragment),uQo=l(),lo=a("div"),F(S0.$$.fragment),_Qo=l(),$he=a("p"),bQo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),vQo=l(),ja=a("p"),FQo=o("The model class to instantiate is selected based on the "),khe=a("code"),TQo=o("model_type"),MQo=o(` property of the config object (either
passed as an argument or loaded from `),She=a("code"),EQo=o("pretrained_model_name_or_path"),CQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rhe=a("code"),wQo=o("pretrained_model_name_or_path"),AQo=o(":"),yQo=l(),Ne=a("ul"),Hv=a("li"),Bhe=a("strong"),LQo=o("data2vec-audio"),xQo=o(" \u2014 "),$V=a("a"),$Qo=o("Data2VecAudioForSequenceClassification"),kQo=o(" (Data2VecAudio model)"),SQo=l(),Uv=a("li"),Phe=a("strong"),RQo=o("hubert"),BQo=o(" \u2014 "),kV=a("a"),PQo=o("HubertForSequenceClassification"),IQo=o(" (Hubert model)"),qQo=l(),Jv=a("li"),Ihe=a("strong"),NQo=o("sew"),jQo=o(" \u2014 "),SV=a("a"),DQo=o("SEWForSequenceClassification"),GQo=o(" (SEW model)"),OQo=l(),Yv=a("li"),qhe=a("strong"),VQo=o("sew-d"),XQo=o(" \u2014 "),RV=a("a"),zQo=o("SEWDForSequenceClassification"),QQo=o(" (SEW-D model)"),WQo=l(),Kv=a("li"),Nhe=a("strong"),HQo=o("unispeech"),UQo=o(" \u2014 "),BV=a("a"),JQo=o("UniSpeechForSequenceClassification"),YQo=o(" (UniSpeech model)"),KQo=l(),Zv=a("li"),jhe=a("strong"),ZQo=o("unispeech-sat"),eWo=o(" \u2014 "),PV=a("a"),oWo=o("UniSpeechSatForSequenceClassification"),rWo=o(" (UniSpeechSat model)"),tWo=l(),eF=a("li"),Dhe=a("strong"),aWo=o("wav2vec2"),nWo=o(" \u2014 "),IV=a("a"),sWo=o("Wav2Vec2ForSequenceClassification"),lWo=o(" (Wav2Vec2 model)"),iWo=l(),oF=a("li"),Ghe=a("strong"),dWo=o("wavlm"),cWo=o(" \u2014 "),qV=a("a"),fWo=o("WavLMForSequenceClassification"),mWo=o(" (WavLM model)"),gWo=l(),rF=a("p"),hWo=o("The model is set in evaluation mode by default using "),Ohe=a("code"),pWo=o("model.eval()"),uWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vhe=a("code"),_Wo=o("model.train()"),bWo=l(),F(tF.$$.fragment),rIe=l(),cd=a("h2"),aF=a("a"),Xhe=a("span"),F(R0.$$.fragment),vWo=l(),zhe=a("span"),FWo=o("AutoModelForAudioFrameClassification"),tIe=l(),Oo=a("div"),F(B0.$$.fragment),TWo=l(),fd=a("p"),MWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),NV=a("a"),EWo=o("from_pretrained()"),CWo=o(" class method or the "),jV=a("a"),wWo=o("from_config()"),AWo=o(` class
method.`),yWo=l(),P0=a("p"),LWo=o("This class cannot be instantiated directly using "),Qhe=a("code"),xWo=o("__init__()"),$Wo=o(" (throws an error)."),kWo=l(),ut=a("div"),F(I0.$$.fragment),SWo=l(),Whe=a("p"),RWo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),BWo=l(),md=a("p"),PWo=o(`Note:
Loading a model from its configuration file does `),Hhe=a("strong"),IWo=o("not"),qWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DV=a("a"),NWo=o("from_pretrained()"),jWo=o(" to load the model weights."),DWo=l(),F(nF.$$.fragment),GWo=l(),io=a("div"),F(q0.$$.fragment),OWo=l(),Uhe=a("p"),VWo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),XWo=l(),Da=a("p"),zWo=o("The model class to instantiate is selected based on the "),Jhe=a("code"),QWo=o("model_type"),WWo=o(` property of the config object (either
passed as an argument or loaded from `),Yhe=a("code"),HWo=o("pretrained_model_name_or_path"),UWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Khe=a("code"),JWo=o("pretrained_model_name_or_path"),YWo=o(":"),KWo=l(),Ga=a("ul"),sF=a("li"),Zhe=a("strong"),ZWo=o("data2vec-audio"),eHo=o(" \u2014 "),GV=a("a"),oHo=o("Data2VecAudioForAudioFrameClassification"),rHo=o(" (Data2VecAudio model)"),tHo=l(),lF=a("li"),epe=a("strong"),aHo=o("unispeech-sat"),nHo=o(" \u2014 "),OV=a("a"),sHo=o("UniSpeechSatForAudioFrameClassification"),lHo=o(" (UniSpeechSat model)"),iHo=l(),iF=a("li"),ope=a("strong"),dHo=o("wav2vec2"),cHo=o(" \u2014 "),VV=a("a"),fHo=o("Wav2Vec2ForAudioFrameClassification"),mHo=o(" (Wav2Vec2 model)"),gHo=l(),dF=a("li"),rpe=a("strong"),hHo=o("wavlm"),pHo=o(" \u2014 "),XV=a("a"),uHo=o("WavLMForAudioFrameClassification"),_Ho=o(" (WavLM model)"),bHo=l(),cF=a("p"),vHo=o("The model is set in evaluation mode by default using "),tpe=a("code"),FHo=o("model.eval()"),THo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ape=a("code"),MHo=o("model.train()"),EHo=l(),F(fF.$$.fragment),aIe=l(),gd=a("h2"),mF=a("a"),npe=a("span"),F(N0.$$.fragment),CHo=l(),spe=a("span"),wHo=o("AutoModelForCTC"),nIe=l(),Vo=a("div"),F(j0.$$.fragment),AHo=l(),hd=a("p"),yHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),zV=a("a"),LHo=o("from_pretrained()"),xHo=o(" class method or the "),QV=a("a"),$Ho=o("from_config()"),kHo=o(` class
method.`),SHo=l(),D0=a("p"),RHo=o("This class cannot be instantiated directly using "),lpe=a("code"),BHo=o("__init__()"),PHo=o(" (throws an error)."),IHo=l(),_t=a("div"),F(G0.$$.fragment),qHo=l(),ipe=a("p"),NHo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),jHo=l(),pd=a("p"),DHo=o(`Note:
Loading a model from its configuration file does `),dpe=a("strong"),GHo=o("not"),OHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WV=a("a"),VHo=o("from_pretrained()"),XHo=o(" to load the model weights."),zHo=l(),F(gF.$$.fragment),QHo=l(),co=a("div"),F(O0.$$.fragment),WHo=l(),cpe=a("p"),HHo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),UHo=l(),Oa=a("p"),JHo=o("The model class to instantiate is selected based on the "),fpe=a("code"),YHo=o("model_type"),KHo=o(` property of the config object (either
passed as an argument or loaded from `),mpe=a("code"),ZHo=o("pretrained_model_name_or_path"),eUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gpe=a("code"),oUo=o("pretrained_model_name_or_path"),rUo=o(":"),tUo=l(),je=a("ul"),hF=a("li"),hpe=a("strong"),aUo=o("data2vec-audio"),nUo=o(" \u2014 "),HV=a("a"),sUo=o("Data2VecAudioForCTC"),lUo=o(" (Data2VecAudio model)"),iUo=l(),pF=a("li"),ppe=a("strong"),dUo=o("hubert"),cUo=o(" \u2014 "),UV=a("a"),fUo=o("HubertForCTC"),mUo=o(" (Hubert model)"),gUo=l(),uF=a("li"),upe=a("strong"),hUo=o("sew"),pUo=o(" \u2014 "),JV=a("a"),uUo=o("SEWForCTC"),_Uo=o(" (SEW model)"),bUo=l(),_F=a("li"),_pe=a("strong"),vUo=o("sew-d"),FUo=o(" \u2014 "),YV=a("a"),TUo=o("SEWDForCTC"),MUo=o(" (SEW-D model)"),EUo=l(),bF=a("li"),bpe=a("strong"),CUo=o("unispeech"),wUo=o(" \u2014 "),KV=a("a"),AUo=o("UniSpeechForCTC"),yUo=o(" (UniSpeech model)"),LUo=l(),vF=a("li"),vpe=a("strong"),xUo=o("unispeech-sat"),$Uo=o(" \u2014 "),ZV=a("a"),kUo=o("UniSpeechSatForCTC"),SUo=o(" (UniSpeechSat model)"),RUo=l(),FF=a("li"),Fpe=a("strong"),BUo=o("wav2vec2"),PUo=o(" \u2014 "),eX=a("a"),IUo=o("Wav2Vec2ForCTC"),qUo=o(" (Wav2Vec2 model)"),NUo=l(),TF=a("li"),Tpe=a("strong"),jUo=o("wavlm"),DUo=o(" \u2014 "),oX=a("a"),GUo=o("WavLMForCTC"),OUo=o(" (WavLM model)"),VUo=l(),MF=a("p"),XUo=o("The model is set in evaluation mode by default using "),Mpe=a("code"),zUo=o("model.eval()"),QUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Epe=a("code"),WUo=o("model.train()"),HUo=l(),F(EF.$$.fragment),sIe=l(),ud=a("h2"),CF=a("a"),Cpe=a("span"),F(V0.$$.fragment),UUo=l(),wpe=a("span"),JUo=o("AutoModelForSpeechSeq2Seq"),lIe=l(),Xo=a("div"),F(X0.$$.fragment),YUo=l(),_d=a("p"),KUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),rX=a("a"),ZUo=o("from_pretrained()"),eJo=o(" class method or the "),tX=a("a"),oJo=o("from_config()"),rJo=o(` class
method.`),tJo=l(),z0=a("p"),aJo=o("This class cannot be instantiated directly using "),Ape=a("code"),nJo=o("__init__()"),sJo=o(" (throws an error)."),lJo=l(),bt=a("div"),F(Q0.$$.fragment),iJo=l(),ype=a("p"),dJo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),cJo=l(),bd=a("p"),fJo=o(`Note:
Loading a model from its configuration file does `),Lpe=a("strong"),mJo=o("not"),gJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aX=a("a"),hJo=o("from_pretrained()"),pJo=o(" to load the model weights."),uJo=l(),F(wF.$$.fragment),_Jo=l(),fo=a("div"),F(W0.$$.fragment),bJo=l(),xpe=a("p"),vJo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),FJo=l(),Va=a("p"),TJo=o("The model class to instantiate is selected based on the "),$pe=a("code"),MJo=o("model_type"),EJo=o(` property of the config object (either
passed as an argument or loaded from `),kpe=a("code"),CJo=o("pretrained_model_name_or_path"),wJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Spe=a("code"),AJo=o("pretrained_model_name_or_path"),yJo=o(":"),LJo=l(),H0=a("ul"),AF=a("li"),Rpe=a("strong"),xJo=o("speech-encoder-decoder"),$Jo=o(" \u2014 "),nX=a("a"),kJo=o("SpeechEncoderDecoderModel"),SJo=o(" (Speech Encoder decoder model)"),RJo=l(),yF=a("li"),Bpe=a("strong"),BJo=o("speech_to_text"),PJo=o(" \u2014 "),sX=a("a"),IJo=o("Speech2TextForConditionalGeneration"),qJo=o(" (Speech2Text model)"),NJo=l(),LF=a("p"),jJo=o("The model is set in evaluation mode by default using "),Ppe=a("code"),DJo=o("model.eval()"),GJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ipe=a("code"),OJo=o("model.train()"),VJo=l(),F(xF.$$.fragment),iIe=l(),vd=a("h2"),$F=a("a"),qpe=a("span"),F(U0.$$.fragment),XJo=l(),Npe=a("span"),zJo=o("AutoModelForAudioXVector"),dIe=l(),zo=a("div"),F(J0.$$.fragment),QJo=l(),Fd=a("p"),WJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),lX=a("a"),HJo=o("from_pretrained()"),UJo=o(" class method or the "),iX=a("a"),JJo=o("from_config()"),YJo=o(` class
method.`),KJo=l(),Y0=a("p"),ZJo=o("This class cannot be instantiated directly using "),jpe=a("code"),eYo=o("__init__()"),oYo=o(" (throws an error)."),rYo=l(),vt=a("div"),F(K0.$$.fragment),tYo=l(),Dpe=a("p"),aYo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),nYo=l(),Td=a("p"),sYo=o(`Note:
Loading a model from its configuration file does `),Gpe=a("strong"),lYo=o("not"),iYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dX=a("a"),dYo=o("from_pretrained()"),cYo=o(" to load the model weights."),fYo=l(),F(kF.$$.fragment),mYo=l(),mo=a("div"),F(Z0.$$.fragment),gYo=l(),Ope=a("p"),hYo=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),pYo=l(),Xa=a("p"),uYo=o("The model class to instantiate is selected based on the "),Vpe=a("code"),_Yo=o("model_type"),bYo=o(` property of the config object (either
passed as an argument or loaded from `),Xpe=a("code"),vYo=o("pretrained_model_name_or_path"),FYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zpe=a("code"),TYo=o("pretrained_model_name_or_path"),MYo=o(":"),EYo=l(),za=a("ul"),SF=a("li"),Qpe=a("strong"),CYo=o("data2vec-audio"),wYo=o(" \u2014 "),cX=a("a"),AYo=o("Data2VecAudioForXVector"),yYo=o(" (Data2VecAudio model)"),LYo=l(),RF=a("li"),Wpe=a("strong"),xYo=o("unispeech-sat"),$Yo=o(" \u2014 "),fX=a("a"),kYo=o("UniSpeechSatForXVector"),SYo=o(" (UniSpeechSat model)"),RYo=l(),BF=a("li"),Hpe=a("strong"),BYo=o("wav2vec2"),PYo=o(" \u2014 "),mX=a("a"),IYo=o("Wav2Vec2ForXVector"),qYo=o(" (Wav2Vec2 model)"),NYo=l(),PF=a("li"),Upe=a("strong"),jYo=o("wavlm"),DYo=o(" \u2014 "),gX=a("a"),GYo=o("WavLMForXVector"),OYo=o(" (WavLM model)"),VYo=l(),IF=a("p"),XYo=o("The model is set in evaluation mode by default using "),Jpe=a("code"),zYo=o("model.eval()"),QYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=a("code"),WYo=o("model.train()"),HYo=l(),F(qF.$$.fragment),cIe=l(),Md=a("h2"),NF=a("a"),Kpe=a("span"),F(ey.$$.fragment),UYo=l(),Zpe=a("span"),JYo=o("AutoModelForMaskedImageModeling"),fIe=l(),Qo=a("div"),F(oy.$$.fragment),YYo=l(),Ed=a("p"),KYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),hX=a("a"),ZYo=o("from_pretrained()"),eKo=o(" class method or the "),pX=a("a"),oKo=o("from_config()"),rKo=o(` class
method.`),tKo=l(),ry=a("p"),aKo=o("This class cannot be instantiated directly using "),eue=a("code"),nKo=o("__init__()"),sKo=o(" (throws an error)."),lKo=l(),Ft=a("div"),F(ty.$$.fragment),iKo=l(),oue=a("p"),dKo=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),cKo=l(),Cd=a("p"),fKo=o(`Note:
Loading a model from its configuration file does `),rue=a("strong"),mKo=o("not"),gKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uX=a("a"),hKo=o("from_pretrained()"),pKo=o(" to load the model weights."),uKo=l(),F(jF.$$.fragment),_Ko=l(),go=a("div"),F(ay.$$.fragment),bKo=l(),tue=a("p"),vKo=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),FKo=l(),Qa=a("p"),TKo=o("The model class to instantiate is selected based on the "),aue=a("code"),MKo=o("model_type"),EKo=o(` property of the config object (either
passed as an argument or loaded from `),nue=a("code"),CKo=o("pretrained_model_name_or_path"),wKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sue=a("code"),AKo=o("pretrained_model_name_or_path"),yKo=o(":"),LKo=l(),wd=a("ul"),DF=a("li"),lue=a("strong"),xKo=o("deit"),$Ko=o(" \u2014 "),_X=a("a"),kKo=o("DeiTForMaskedImageModeling"),SKo=o(" (DeiT model)"),RKo=l(),GF=a("li"),iue=a("strong"),BKo=o("swin"),PKo=o(" \u2014 "),bX=a("a"),IKo=o("SwinForMaskedImageModeling"),qKo=o(" (Swin model)"),NKo=l(),OF=a("li"),due=a("strong"),jKo=o("vit"),DKo=o(" \u2014 "),vX=a("a"),GKo=o("ViTForMaskedImageModeling"),OKo=o(" (ViT model)"),VKo=l(),VF=a("p"),XKo=o("The model is set in evaluation mode by default using "),cue=a("code"),zKo=o("model.eval()"),QKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fue=a("code"),WKo=o("model.train()"),HKo=l(),F(XF.$$.fragment),mIe=l(),Ad=a("h2"),zF=a("a"),mue=a("span"),F(ny.$$.fragment),UKo=l(),gue=a("span"),JKo=o("AutoModelForObjectDetection"),gIe=l(),Wo=a("div"),F(sy.$$.fragment),YKo=l(),yd=a("p"),KKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),FX=a("a"),ZKo=o("from_pretrained()"),eZo=o(" class method or the "),TX=a("a"),oZo=o("from_config()"),rZo=o(` class
method.`),tZo=l(),ly=a("p"),aZo=o("This class cannot be instantiated directly using "),hue=a("code"),nZo=o("__init__()"),sZo=o(" (throws an error)."),lZo=l(),Tt=a("div"),F(iy.$$.fragment),iZo=l(),pue=a("p"),dZo=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),cZo=l(),Ld=a("p"),fZo=o(`Note:
Loading a model from its configuration file does `),uue=a("strong"),mZo=o("not"),gZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=a("a"),hZo=o("from_pretrained()"),pZo=o(" to load the model weights."),uZo=l(),F(QF.$$.fragment),_Zo=l(),ho=a("div"),F(dy.$$.fragment),bZo=l(),_ue=a("p"),vZo=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),FZo=l(),Wa=a("p"),TZo=o("The model class to instantiate is selected based on the "),bue=a("code"),MZo=o("model_type"),EZo=o(` property of the config object (either
passed as an argument or loaded from `),vue=a("code"),CZo=o("pretrained_model_name_or_path"),wZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fue=a("code"),AZo=o("pretrained_model_name_or_path"),yZo=o(":"),LZo=l(),cy=a("ul"),WF=a("li"),Tue=a("strong"),xZo=o("detr"),$Zo=o(" \u2014 "),EX=a("a"),kZo=o("DetrForObjectDetection"),SZo=o(" (DETR model)"),RZo=l(),HF=a("li"),Mue=a("strong"),BZo=o("yolos"),PZo=o(" \u2014 "),CX=a("a"),IZo=o("YolosForObjectDetection"),qZo=o(" (YOLOS model)"),NZo=l(),UF=a("p"),jZo=o("The model is set in evaluation mode by default using "),Eue=a("code"),DZo=o("model.eval()"),GZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cue=a("code"),OZo=o("model.train()"),VZo=l(),F(JF.$$.fragment),hIe=l(),xd=a("h2"),YF=a("a"),wue=a("span"),F(fy.$$.fragment),XZo=l(),Aue=a("span"),zZo=o("AutoModelForImageSegmentation"),pIe=l(),Ho=a("div"),F(my.$$.fragment),QZo=l(),$d=a("p"),WZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),wX=a("a"),HZo=o("from_pretrained()"),UZo=o(" class method or the "),AX=a("a"),JZo=o("from_config()"),YZo=o(` class
method.`),KZo=l(),gy=a("p"),ZZo=o("This class cannot be instantiated directly using "),yue=a("code"),eer=o("__init__()"),oer=o(" (throws an error)."),rer=l(),Mt=a("div"),F(hy.$$.fragment),ter=l(),Lue=a("p"),aer=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),ner=l(),kd=a("p"),ser=o(`Note:
Loading a model from its configuration file does `),xue=a("strong"),ler=o("not"),ier=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yX=a("a"),der=o("from_pretrained()"),cer=o(" to load the model weights."),fer=l(),F(KF.$$.fragment),mer=l(),po=a("div"),F(py.$$.fragment),ger=l(),$ue=a("p"),her=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),per=l(),Ha=a("p"),uer=o("The model class to instantiate is selected based on the "),kue=a("code"),_er=o("model_type"),ber=o(` property of the config object (either
passed as an argument or loaded from `),Sue=a("code"),ver=o("pretrained_model_name_or_path"),Fer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rue=a("code"),Ter=o("pretrained_model_name_or_path"),Mer=o(":"),Eer=l(),Bue=a("ul"),ZF=a("li"),Pue=a("strong"),Cer=o("detr"),wer=o(" \u2014 "),LX=a("a"),Aer=o("DetrForSegmentation"),yer=o(" (DETR model)"),Ler=l(),e6=a("p"),xer=o("The model is set in evaluation mode by default using "),Iue=a("code"),$er=o("model.eval()"),ker=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),que=a("code"),Ser=o("model.train()"),Rer=l(),F(o6.$$.fragment),uIe=l(),Sd=a("h2"),r6=a("a"),Nue=a("span"),F(uy.$$.fragment),Ber=l(),jue=a("span"),Per=o("AutoModelForSemanticSegmentation"),_Ie=l(),Uo=a("div"),F(_y.$$.fragment),Ier=l(),Rd=a("p"),qer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),xX=a("a"),Ner=o("from_pretrained()"),jer=o(" class method or the "),$X=a("a"),Der=o("from_config()"),Ger=o(` class
method.`),Oer=l(),by=a("p"),Ver=o("This class cannot be instantiated directly using "),Due=a("code"),Xer=o("__init__()"),zer=o(" (throws an error)."),Qer=l(),Et=a("div"),F(vy.$$.fragment),Wer=l(),Gue=a("p"),Her=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Uer=l(),Bd=a("p"),Jer=o(`Note:
Loading a model from its configuration file does `),Oue=a("strong"),Yer=o("not"),Ker=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),Zer=o("from_pretrained()"),eor=o(" to load the model weights."),oor=l(),F(t6.$$.fragment),ror=l(),uo=a("div"),F(Fy.$$.fragment),tor=l(),Vue=a("p"),aor=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),nor=l(),Ua=a("p"),sor=o("The model class to instantiate is selected based on the "),Xue=a("code"),lor=o("model_type"),ior=o(` property of the config object (either
passed as an argument or loaded from `),zue=a("code"),dor=o("pretrained_model_name_or_path"),cor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Que=a("code"),mor=o("pretrained_model_name_or_path"),gor=o(":"),hor=l(),Ja=a("ul"),a6=a("li"),Wue=a("strong"),por=o("beit"),uor=o(" \u2014 "),SX=a("a"),_or=o("BeitForSemanticSegmentation"),bor=o(" (BEiT model)"),vor=l(),n6=a("li"),Hue=a("strong"),For=o("data2vec-vision"),Tor=o(" \u2014 "),RX=a("a"),Mor=o("Data2VecVisionForSemanticSegmentation"),Eor=o(" (Data2VecVision model)"),Cor=l(),s6=a("li"),Uue=a("strong"),wor=o("dpt"),Aor=o(" \u2014 "),BX=a("a"),yor=o("DPTForSemanticSegmentation"),Lor=o(" (DPT model)"),xor=l(),l6=a("li"),Jue=a("strong"),$or=o("segformer"),kor=o(" \u2014 "),PX=a("a"),Sor=o("SegformerForSemanticSegmentation"),Ror=o(" (SegFormer model)"),Bor=l(),i6=a("p"),Por=o("The model is set in evaluation mode by default using "),Yue=a("code"),Ior=o("model.eval()"),qor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kue=a("code"),Nor=o("model.train()"),jor=l(),F(d6.$$.fragment),bIe=l(),Pd=a("h2"),c6=a("a"),Zue=a("span"),F(Ty.$$.fragment),Dor=l(),e_e=a("span"),Gor=o("AutoModelForInstanceSegmentation"),vIe=l(),Jo=a("div"),F(My.$$.fragment),Oor=l(),Id=a("p"),Vor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),IX=a("a"),Xor=o("from_pretrained()"),zor=o(" class method or the "),qX=a("a"),Qor=o("from_config()"),Wor=o(` class
method.`),Hor=l(),Ey=a("p"),Uor=o("This class cannot be instantiated directly using "),o_e=a("code"),Jor=o("__init__()"),Yor=o(" (throws an error)."),Kor=l(),Ct=a("div"),F(Cy.$$.fragment),Zor=l(),r_e=a("p"),err=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),orr=l(),qd=a("p"),rrr=o(`Note:
Loading a model from its configuration file does `),t_e=a("strong"),trr=o("not"),arr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NX=a("a"),nrr=o("from_pretrained()"),srr=o(" to load the model weights."),lrr=l(),F(f6.$$.fragment),irr=l(),_o=a("div"),F(wy.$$.fragment),drr=l(),a_e=a("p"),crr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),frr=l(),Ya=a("p"),mrr=o("The model class to instantiate is selected based on the "),n_e=a("code"),grr=o("model_type"),hrr=o(` property of the config object (either
passed as an argument or loaded from `),s_e=a("code"),prr=o("pretrained_model_name_or_path"),urr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l_e=a("code"),_rr=o("pretrained_model_name_or_path"),brr=o(":"),vrr=l(),i_e=a("ul"),m6=a("li"),d_e=a("strong"),Frr=o("maskformer"),Trr=o(" \u2014 "),jX=a("a"),Mrr=o("MaskFormerForInstanceSegmentation"),Err=o(" (MaskFormer model)"),Crr=l(),g6=a("p"),wrr=o("The model is set in evaluation mode by default using "),c_e=a("code"),Arr=o("model.eval()"),yrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f_e=a("code"),Lrr=o("model.train()"),xrr=l(),F(h6.$$.fragment),FIe=l(),Nd=a("h2"),p6=a("a"),m_e=a("span"),F(Ay.$$.fragment),$rr=l(),g_e=a("span"),krr=o("TFAutoModel"),TIe=l(),Yo=a("div"),F(yy.$$.fragment),Srr=l(),jd=a("p"),Rrr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),DX=a("a"),Brr=o("from_pretrained()"),Prr=o(" class method or the "),GX=a("a"),Irr=o("from_config()"),qrr=o(` class
method.`),Nrr=l(),Ly=a("p"),jrr=o("This class cannot be instantiated directly using "),h_e=a("code"),Drr=o("__init__()"),Grr=o(" (throws an error)."),Orr=l(),wt=a("div"),F(xy.$$.fragment),Vrr=l(),p_e=a("p"),Xrr=o("Instantiates one of the base model classes of the library from a configuration."),zrr=l(),Dd=a("p"),Qrr=o(`Note:
Loading a model from its configuration file does `),u_e=a("strong"),Wrr=o("not"),Hrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OX=a("a"),Urr=o("from_pretrained()"),Jrr=o(" to load the model weights."),Yrr=l(),F(u6.$$.fragment),Krr=l(),wr=a("div"),F($y.$$.fragment),Zrr=l(),__e=a("p"),etr=o("Instantiate one of the base model classes of the library from a pretrained model."),otr=l(),Ka=a("p"),rtr=o("The model class to instantiate is selected based on the "),b_e=a("code"),ttr=o("model_type"),atr=o(` property of the config object (either
passed as an argument or loaded from `),v_e=a("code"),ntr=o("pretrained_model_name_or_path"),str=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F_e=a("code"),ltr=o("pretrained_model_name_or_path"),itr=o(":"),dtr=l(),N=a("ul"),_6=a("li"),T_e=a("strong"),ctr=o("albert"),ftr=o(" \u2014 "),VX=a("a"),mtr=o("TFAlbertModel"),gtr=o(" (ALBERT model)"),htr=l(),b6=a("li"),M_e=a("strong"),ptr=o("bart"),utr=o(" \u2014 "),XX=a("a"),_tr=o("TFBartModel"),btr=o(" (BART model)"),vtr=l(),v6=a("li"),E_e=a("strong"),Ftr=o("bert"),Ttr=o(" \u2014 "),zX=a("a"),Mtr=o("TFBertModel"),Etr=o(" (BERT model)"),Ctr=l(),F6=a("li"),C_e=a("strong"),wtr=o("blenderbot"),Atr=o(" \u2014 "),QX=a("a"),ytr=o("TFBlenderbotModel"),Ltr=o(" (Blenderbot model)"),xtr=l(),T6=a("li"),w_e=a("strong"),$tr=o("blenderbot-small"),ktr=o(" \u2014 "),WX=a("a"),Str=o("TFBlenderbotSmallModel"),Rtr=o(" (BlenderbotSmall model)"),Btr=l(),M6=a("li"),A_e=a("strong"),Ptr=o("camembert"),Itr=o(" \u2014 "),HX=a("a"),qtr=o("TFCamembertModel"),Ntr=o(" (CamemBERT model)"),jtr=l(),E6=a("li"),y_e=a("strong"),Dtr=o("clip"),Gtr=o(" \u2014 "),UX=a("a"),Otr=o("TFCLIPModel"),Vtr=o(" (CLIP model)"),Xtr=l(),C6=a("li"),L_e=a("strong"),ztr=o("convbert"),Qtr=o(" \u2014 "),JX=a("a"),Wtr=o("TFConvBertModel"),Htr=o(" (ConvBERT model)"),Utr=l(),w6=a("li"),x_e=a("strong"),Jtr=o("convnext"),Ytr=o(" \u2014 "),YX=a("a"),Ktr=o("TFConvNextModel"),Ztr=o(" (ConvNext model)"),ear=l(),A6=a("li"),$_e=a("strong"),oar=o("ctrl"),rar=o(" \u2014 "),KX=a("a"),tar=o("TFCTRLModel"),aar=o(" (CTRL model)"),nar=l(),y6=a("li"),k_e=a("strong"),sar=o("data2vec-vision"),lar=o(" \u2014 "),ZX=a("a"),iar=o("TFData2VecVisionModel"),dar=o(" (Data2VecVision model)"),car=l(),L6=a("li"),S_e=a("strong"),far=o("deberta"),mar=o(" \u2014 "),ez=a("a"),gar=o("TFDebertaModel"),har=o(" (DeBERTa model)"),par=l(),x6=a("li"),R_e=a("strong"),uar=o("deberta-v2"),_ar=o(" \u2014 "),oz=a("a"),bar=o("TFDebertaV2Model"),Far=o(" (DeBERTa-v2 model)"),Tar=l(),$6=a("li"),B_e=a("strong"),Mar=o("distilbert"),Ear=o(" \u2014 "),rz=a("a"),Car=o("TFDistilBertModel"),war=o(" (DistilBERT model)"),Aar=l(),k6=a("li"),P_e=a("strong"),yar=o("dpr"),Lar=o(" \u2014 "),tz=a("a"),xar=o("TFDPRQuestionEncoder"),$ar=o(" (DPR model)"),kar=l(),S6=a("li"),I_e=a("strong"),Sar=o("electra"),Rar=o(" \u2014 "),az=a("a"),Bar=o("TFElectraModel"),Par=o(" (ELECTRA model)"),Iar=l(),R6=a("li"),q_e=a("strong"),qar=o("flaubert"),Nar=o(" \u2014 "),nz=a("a"),jar=o("TFFlaubertModel"),Dar=o(" (FlauBERT model)"),Gar=l(),Ps=a("li"),N_e=a("strong"),Oar=o("funnel"),Var=o(" \u2014 "),sz=a("a"),Xar=o("TFFunnelModel"),zar=o(" or "),lz=a("a"),Qar=o("TFFunnelBaseModel"),War=o(" (Funnel Transformer model)"),Har=l(),B6=a("li"),j_e=a("strong"),Uar=o("gpt2"),Jar=o(" \u2014 "),iz=a("a"),Yar=o("TFGPT2Model"),Kar=o(" (OpenAI GPT-2 model)"),Zar=l(),P6=a("li"),D_e=a("strong"),enr=o("gptj"),onr=o(" \u2014 "),dz=a("a"),rnr=o("TFGPTJModel"),tnr=o(" (GPT-J model)"),anr=l(),I6=a("li"),G_e=a("strong"),nnr=o("hubert"),snr=o(" \u2014 "),cz=a("a"),lnr=o("TFHubertModel"),inr=o(" (Hubert model)"),dnr=l(),q6=a("li"),O_e=a("strong"),cnr=o("layoutlm"),fnr=o(" \u2014 "),fz=a("a"),mnr=o("TFLayoutLMModel"),gnr=o(" (LayoutLM model)"),hnr=l(),N6=a("li"),V_e=a("strong"),pnr=o("led"),unr=o(" \u2014 "),mz=a("a"),_nr=o("TFLEDModel"),bnr=o(" (LED model)"),vnr=l(),j6=a("li"),X_e=a("strong"),Fnr=o("longformer"),Tnr=o(" \u2014 "),gz=a("a"),Mnr=o("TFLongformerModel"),Enr=o(" (Longformer model)"),Cnr=l(),D6=a("li"),z_e=a("strong"),wnr=o("lxmert"),Anr=o(" \u2014 "),hz=a("a"),ynr=o("TFLxmertModel"),Lnr=o(" (LXMERT model)"),xnr=l(),G6=a("li"),Q_e=a("strong"),$nr=o("marian"),knr=o(" \u2014 "),pz=a("a"),Snr=o("TFMarianModel"),Rnr=o(" (Marian model)"),Bnr=l(),O6=a("li"),W_e=a("strong"),Pnr=o("mbart"),Inr=o(" \u2014 "),uz=a("a"),qnr=o("TFMBartModel"),Nnr=o(" (mBART model)"),jnr=l(),V6=a("li"),H_e=a("strong"),Dnr=o("mobilebert"),Gnr=o(" \u2014 "),_z=a("a"),Onr=o("TFMobileBertModel"),Vnr=o(" (MobileBERT model)"),Xnr=l(),X6=a("li"),U_e=a("strong"),znr=o("mpnet"),Qnr=o(" \u2014 "),bz=a("a"),Wnr=o("TFMPNetModel"),Hnr=o(" (MPNet model)"),Unr=l(),z6=a("li"),J_e=a("strong"),Jnr=o("mt5"),Ynr=o(" \u2014 "),vz=a("a"),Knr=o("TFMT5Model"),Znr=o(" (mT5 model)"),esr=l(),Q6=a("li"),Y_e=a("strong"),osr=o("openai-gpt"),rsr=o(" \u2014 "),Fz=a("a"),tsr=o("TFOpenAIGPTModel"),asr=o(" (OpenAI GPT model)"),nsr=l(),W6=a("li"),K_e=a("strong"),ssr=o("pegasus"),lsr=o(" \u2014 "),Tz=a("a"),isr=o("TFPegasusModel"),dsr=o(" (Pegasus model)"),csr=l(),H6=a("li"),Z_e=a("strong"),fsr=o("rembert"),msr=o(" \u2014 "),Mz=a("a"),gsr=o("TFRemBertModel"),hsr=o(" (RemBERT model)"),psr=l(),U6=a("li"),e1e=a("strong"),usr=o("roberta"),_sr=o(" \u2014 "),Ez=a("a"),bsr=o("TFRobertaModel"),vsr=o(" (RoBERTa model)"),Fsr=l(),J6=a("li"),o1e=a("strong"),Tsr=o("roformer"),Msr=o(" \u2014 "),Cz=a("a"),Esr=o("TFRoFormerModel"),Csr=o(" (RoFormer model)"),wsr=l(),Y6=a("li"),r1e=a("strong"),Asr=o("speech_to_text"),ysr=o(" \u2014 "),wz=a("a"),Lsr=o("TFSpeech2TextModel"),xsr=o(" (Speech2Text model)"),$sr=l(),K6=a("li"),t1e=a("strong"),ksr=o("swin"),Ssr=o(" \u2014 "),Az=a("a"),Rsr=o("TFSwinModel"),Bsr=o(" (Swin model)"),Psr=l(),Z6=a("li"),a1e=a("strong"),Isr=o("t5"),qsr=o(" \u2014 "),yz=a("a"),Nsr=o("TFT5Model"),jsr=o(" (T5 model)"),Dsr=l(),eT=a("li"),n1e=a("strong"),Gsr=o("tapas"),Osr=o(" \u2014 "),Lz=a("a"),Vsr=o("TFTapasModel"),Xsr=o(" (TAPAS model)"),zsr=l(),oT=a("li"),s1e=a("strong"),Qsr=o("transfo-xl"),Wsr=o(" \u2014 "),xz=a("a"),Hsr=o("TFTransfoXLModel"),Usr=o(" (Transformer-XL model)"),Jsr=l(),rT=a("li"),l1e=a("strong"),Ysr=o("vit"),Ksr=o(" \u2014 "),$z=a("a"),Zsr=o("TFViTModel"),elr=o(" (ViT model)"),olr=l(),tT=a("li"),i1e=a("strong"),rlr=o("vit_mae"),tlr=o(" \u2014 "),kz=a("a"),alr=o("TFViTMAEModel"),nlr=o(" (ViTMAE model)"),slr=l(),aT=a("li"),d1e=a("strong"),llr=o("wav2vec2"),ilr=o(" \u2014 "),Sz=a("a"),dlr=o("TFWav2Vec2Model"),clr=o(" (Wav2Vec2 model)"),flr=l(),nT=a("li"),c1e=a("strong"),mlr=o("xlm"),glr=o(" \u2014 "),Rz=a("a"),hlr=o("TFXLMModel"),plr=o(" (XLM model)"),ulr=l(),sT=a("li"),f1e=a("strong"),_lr=o("xlm-roberta"),blr=o(" \u2014 "),Bz=a("a"),vlr=o("TFXLMRobertaModel"),Flr=o(" (XLM-RoBERTa model)"),Tlr=l(),lT=a("li"),m1e=a("strong"),Mlr=o("xlnet"),Elr=o(" \u2014 "),Pz=a("a"),Clr=o("TFXLNetModel"),wlr=o(" (XLNet model)"),Alr=l(),F(iT.$$.fragment),MIe=l(),Gd=a("h2"),dT=a("a"),g1e=a("span"),F(ky.$$.fragment),ylr=l(),h1e=a("span"),Llr=o("TFAutoModelForPreTraining"),EIe=l(),Ko=a("div"),F(Sy.$$.fragment),xlr=l(),Od=a("p"),$lr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Iz=a("a"),klr=o("from_pretrained()"),Slr=o(" class method or the "),qz=a("a"),Rlr=o("from_config()"),Blr=o(` class
method.`),Plr=l(),Ry=a("p"),Ilr=o("This class cannot be instantiated directly using "),p1e=a("code"),qlr=o("__init__()"),Nlr=o(" (throws an error)."),jlr=l(),At=a("div"),F(By.$$.fragment),Dlr=l(),u1e=a("p"),Glr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Olr=l(),Vd=a("p"),Vlr=o(`Note:
Loading a model from its configuration file does `),_1e=a("strong"),Xlr=o("not"),zlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nz=a("a"),Qlr=o("from_pretrained()"),Wlr=o(" to load the model weights."),Hlr=l(),F(cT.$$.fragment),Ulr=l(),Ar=a("div"),F(Py.$$.fragment),Jlr=l(),b1e=a("p"),Ylr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Klr=l(),Za=a("p"),Zlr=o("The model class to instantiate is selected based on the "),v1e=a("code"),eir=o("model_type"),oir=o(` property of the config object (either
passed as an argument or loaded from `),F1e=a("code"),rir=o("pretrained_model_name_or_path"),tir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T1e=a("code"),air=o("pretrained_model_name_or_path"),nir=o(":"),sir=l(),ne=a("ul"),fT=a("li"),M1e=a("strong"),lir=o("albert"),iir=o(" \u2014 "),jz=a("a"),dir=o("TFAlbertForPreTraining"),cir=o(" (ALBERT model)"),fir=l(),mT=a("li"),E1e=a("strong"),mir=o("bart"),gir=o(" \u2014 "),Dz=a("a"),hir=o("TFBartForConditionalGeneration"),pir=o(" (BART model)"),uir=l(),gT=a("li"),C1e=a("strong"),_ir=o("bert"),bir=o(" \u2014 "),Gz=a("a"),vir=o("TFBertForPreTraining"),Fir=o(" (BERT model)"),Tir=l(),hT=a("li"),w1e=a("strong"),Mir=o("camembert"),Eir=o(" \u2014 "),Oz=a("a"),Cir=o("TFCamembertForMaskedLM"),wir=o(" (CamemBERT model)"),Air=l(),pT=a("li"),A1e=a("strong"),yir=o("ctrl"),Lir=o(" \u2014 "),Vz=a("a"),xir=o("TFCTRLLMHeadModel"),$ir=o(" (CTRL model)"),kir=l(),uT=a("li"),y1e=a("strong"),Sir=o("distilbert"),Rir=o(" \u2014 "),Xz=a("a"),Bir=o("TFDistilBertForMaskedLM"),Pir=o(" (DistilBERT model)"),Iir=l(),_T=a("li"),L1e=a("strong"),qir=o("electra"),Nir=o(" \u2014 "),zz=a("a"),jir=o("TFElectraForPreTraining"),Dir=o(" (ELECTRA model)"),Gir=l(),bT=a("li"),x1e=a("strong"),Oir=o("flaubert"),Vir=o(" \u2014 "),Qz=a("a"),Xir=o("TFFlaubertWithLMHeadModel"),zir=o(" (FlauBERT model)"),Qir=l(),vT=a("li"),$1e=a("strong"),Wir=o("funnel"),Hir=o(" \u2014 "),Wz=a("a"),Uir=o("TFFunnelForPreTraining"),Jir=o(" (Funnel Transformer model)"),Yir=l(),FT=a("li"),k1e=a("strong"),Kir=o("gpt2"),Zir=o(" \u2014 "),Hz=a("a"),edr=o("TFGPT2LMHeadModel"),odr=o(" (OpenAI GPT-2 model)"),rdr=l(),TT=a("li"),S1e=a("strong"),tdr=o("layoutlm"),adr=o(" \u2014 "),Uz=a("a"),ndr=o("TFLayoutLMForMaskedLM"),sdr=o(" (LayoutLM model)"),ldr=l(),MT=a("li"),R1e=a("strong"),idr=o("lxmert"),ddr=o(" \u2014 "),Jz=a("a"),cdr=o("TFLxmertForPreTraining"),fdr=o(" (LXMERT model)"),mdr=l(),ET=a("li"),B1e=a("strong"),gdr=o("mobilebert"),hdr=o(" \u2014 "),Yz=a("a"),pdr=o("TFMobileBertForPreTraining"),udr=o(" (MobileBERT model)"),_dr=l(),CT=a("li"),P1e=a("strong"),bdr=o("mpnet"),vdr=o(" \u2014 "),Kz=a("a"),Fdr=o("TFMPNetForMaskedLM"),Tdr=o(" (MPNet model)"),Mdr=l(),wT=a("li"),I1e=a("strong"),Edr=o("openai-gpt"),Cdr=o(" \u2014 "),Zz=a("a"),wdr=o("TFOpenAIGPTLMHeadModel"),Adr=o(" (OpenAI GPT model)"),ydr=l(),AT=a("li"),q1e=a("strong"),Ldr=o("roberta"),xdr=o(" \u2014 "),eQ=a("a"),$dr=o("TFRobertaForMaskedLM"),kdr=o(" (RoBERTa model)"),Sdr=l(),yT=a("li"),N1e=a("strong"),Rdr=o("t5"),Bdr=o(" \u2014 "),oQ=a("a"),Pdr=o("TFT5ForConditionalGeneration"),Idr=o(" (T5 model)"),qdr=l(),LT=a("li"),j1e=a("strong"),Ndr=o("tapas"),jdr=o(" \u2014 "),rQ=a("a"),Ddr=o("TFTapasForMaskedLM"),Gdr=o(" (TAPAS model)"),Odr=l(),xT=a("li"),D1e=a("strong"),Vdr=o("transfo-xl"),Xdr=o(" \u2014 "),tQ=a("a"),zdr=o("TFTransfoXLLMHeadModel"),Qdr=o(" (Transformer-XL model)"),Wdr=l(),$T=a("li"),G1e=a("strong"),Hdr=o("vit_mae"),Udr=o(" \u2014 "),aQ=a("a"),Jdr=o("TFViTMAEForPreTraining"),Ydr=o(" (ViTMAE model)"),Kdr=l(),kT=a("li"),O1e=a("strong"),Zdr=o("xlm"),ecr=o(" \u2014 "),nQ=a("a"),ocr=o("TFXLMWithLMHeadModel"),rcr=o(" (XLM model)"),tcr=l(),ST=a("li"),V1e=a("strong"),acr=o("xlm-roberta"),ncr=o(" \u2014 "),sQ=a("a"),scr=o("TFXLMRobertaForMaskedLM"),lcr=o(" (XLM-RoBERTa model)"),icr=l(),RT=a("li"),X1e=a("strong"),dcr=o("xlnet"),ccr=o(" \u2014 "),lQ=a("a"),fcr=o("TFXLNetLMHeadModel"),mcr=o(" (XLNet model)"),gcr=l(),F(BT.$$.fragment),CIe=l(),Xd=a("h2"),PT=a("a"),z1e=a("span"),F(Iy.$$.fragment),hcr=l(),Q1e=a("span"),pcr=o("TFAutoModelForCausalLM"),wIe=l(),Zo=a("div"),F(qy.$$.fragment),ucr=l(),zd=a("p"),_cr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),iQ=a("a"),bcr=o("from_pretrained()"),vcr=o(" class method or the "),dQ=a("a"),Fcr=o("from_config()"),Tcr=o(` class
method.`),Mcr=l(),Ny=a("p"),Ecr=o("This class cannot be instantiated directly using "),W1e=a("code"),Ccr=o("__init__()"),wcr=o(" (throws an error)."),Acr=l(),yt=a("div"),F(jy.$$.fragment),ycr=l(),H1e=a("p"),Lcr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),xcr=l(),Qd=a("p"),$cr=o(`Note:
Loading a model from its configuration file does `),U1e=a("strong"),kcr=o("not"),Scr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),Rcr=o("from_pretrained()"),Bcr=o(" to load the model weights."),Pcr=l(),F(IT.$$.fragment),Icr=l(),yr=a("div"),F(Dy.$$.fragment),qcr=l(),J1e=a("p"),Ncr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),jcr=l(),en=a("p"),Dcr=o("The model class to instantiate is selected based on the "),Y1e=a("code"),Gcr=o("model_type"),Ocr=o(` property of the config object (either
passed as an argument or loaded from `),K1e=a("code"),Vcr=o("pretrained_model_name_or_path"),Xcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=a("code"),zcr=o("pretrained_model_name_or_path"),Qcr=o(":"),Wcr=l(),Te=a("ul"),qT=a("li"),e8e=a("strong"),Hcr=o("bert"),Ucr=o(" \u2014 "),fQ=a("a"),Jcr=o("TFBertLMHeadModel"),Ycr=o(" (BERT model)"),Kcr=l(),NT=a("li"),o8e=a("strong"),Zcr=o("camembert"),efr=o(" \u2014 "),mQ=a("a"),ofr=o("TFCamembertForCausalLM"),rfr=o(" (CamemBERT model)"),tfr=l(),jT=a("li"),r8e=a("strong"),afr=o("ctrl"),nfr=o(" \u2014 "),gQ=a("a"),sfr=o("TFCTRLLMHeadModel"),lfr=o(" (CTRL model)"),ifr=l(),DT=a("li"),t8e=a("strong"),dfr=o("gpt2"),cfr=o(" \u2014 "),hQ=a("a"),ffr=o("TFGPT2LMHeadModel"),mfr=o(" (OpenAI GPT-2 model)"),gfr=l(),GT=a("li"),a8e=a("strong"),hfr=o("gptj"),pfr=o(" \u2014 "),pQ=a("a"),ufr=o("TFGPTJForCausalLM"),_fr=o(" (GPT-J model)"),bfr=l(),OT=a("li"),n8e=a("strong"),vfr=o("openai-gpt"),Ffr=o(" \u2014 "),uQ=a("a"),Tfr=o("TFOpenAIGPTLMHeadModel"),Mfr=o(" (OpenAI GPT model)"),Efr=l(),VT=a("li"),s8e=a("strong"),Cfr=o("rembert"),wfr=o(" \u2014 "),_Q=a("a"),Afr=o("TFRemBertForCausalLM"),yfr=o(" (RemBERT model)"),Lfr=l(),XT=a("li"),l8e=a("strong"),xfr=o("roberta"),$fr=o(" \u2014 "),bQ=a("a"),kfr=o("TFRobertaForCausalLM"),Sfr=o(" (RoBERTa model)"),Rfr=l(),zT=a("li"),i8e=a("strong"),Bfr=o("roformer"),Pfr=o(" \u2014 "),vQ=a("a"),Ifr=o("TFRoFormerForCausalLM"),qfr=o(" (RoFormer model)"),Nfr=l(),QT=a("li"),d8e=a("strong"),jfr=o("transfo-xl"),Dfr=o(" \u2014 "),FQ=a("a"),Gfr=o("TFTransfoXLLMHeadModel"),Ofr=o(" (Transformer-XL model)"),Vfr=l(),WT=a("li"),c8e=a("strong"),Xfr=o("xlm"),zfr=o(" \u2014 "),TQ=a("a"),Qfr=o("TFXLMWithLMHeadModel"),Wfr=o(" (XLM model)"),Hfr=l(),HT=a("li"),f8e=a("strong"),Ufr=o("xlnet"),Jfr=o(" \u2014 "),MQ=a("a"),Yfr=o("TFXLNetLMHeadModel"),Kfr=o(" (XLNet model)"),Zfr=l(),F(UT.$$.fragment),AIe=l(),Wd=a("h2"),JT=a("a"),m8e=a("span"),F(Gy.$$.fragment),emr=l(),g8e=a("span"),omr=o("TFAutoModelForImageClassification"),yIe=l(),er=a("div"),F(Oy.$$.fragment),rmr=l(),Hd=a("p"),tmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),EQ=a("a"),amr=o("from_pretrained()"),nmr=o(" class method or the "),CQ=a("a"),smr=o("from_config()"),lmr=o(` class
method.`),imr=l(),Vy=a("p"),dmr=o("This class cannot be instantiated directly using "),h8e=a("code"),cmr=o("__init__()"),fmr=o(" (throws an error)."),mmr=l(),Lt=a("div"),F(Xy.$$.fragment),gmr=l(),p8e=a("p"),hmr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),pmr=l(),Ud=a("p"),umr=o(`Note:
Loading a model from its configuration file does `),u8e=a("strong"),_mr=o("not"),bmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wQ=a("a"),vmr=o("from_pretrained()"),Fmr=o(" to load the model weights."),Tmr=l(),F(YT.$$.fragment),Mmr=l(),Lr=a("div"),F(zy.$$.fragment),Emr=l(),_8e=a("p"),Cmr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),wmr=l(),on=a("p"),Amr=o("The model class to instantiate is selected based on the "),b8e=a("code"),ymr=o("model_type"),Lmr=o(` property of the config object (either
passed as an argument or loaded from `),v8e=a("code"),xmr=o("pretrained_model_name_or_path"),$mr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=a("code"),kmr=o("pretrained_model_name_or_path"),Smr=o(":"),Rmr=l(),rn=a("ul"),KT=a("li"),T8e=a("strong"),Bmr=o("convnext"),Pmr=o(" \u2014 "),AQ=a("a"),Imr=o("TFConvNextForImageClassification"),qmr=o(" (ConvNext model)"),Nmr=l(),ZT=a("li"),M8e=a("strong"),jmr=o("data2vec-vision"),Dmr=o(" \u2014 "),yQ=a("a"),Gmr=o("TFData2VecVisionForImageClassification"),Omr=o(" (Data2VecVision model)"),Vmr=l(),e9=a("li"),E8e=a("strong"),Xmr=o("swin"),zmr=o(" \u2014 "),LQ=a("a"),Qmr=o("TFSwinForImageClassification"),Wmr=o(" (Swin model)"),Hmr=l(),o9=a("li"),C8e=a("strong"),Umr=o("vit"),Jmr=o(" \u2014 "),xQ=a("a"),Ymr=o("TFViTForImageClassification"),Kmr=o(" (ViT model)"),Zmr=l(),F(r9.$$.fragment),LIe=l(),Jd=a("h2"),t9=a("a"),w8e=a("span"),F(Qy.$$.fragment),egr=l(),A8e=a("span"),ogr=o("TFAutoModelForMaskedLM"),xIe=l(),or=a("div"),F(Wy.$$.fragment),rgr=l(),Yd=a("p"),tgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),$Q=a("a"),agr=o("from_pretrained()"),ngr=o(" class method or the "),kQ=a("a"),sgr=o("from_config()"),lgr=o(` class
method.`),igr=l(),Hy=a("p"),dgr=o("This class cannot be instantiated directly using "),y8e=a("code"),cgr=o("__init__()"),fgr=o(" (throws an error)."),mgr=l(),xt=a("div"),F(Uy.$$.fragment),ggr=l(),L8e=a("p"),hgr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),pgr=l(),Kd=a("p"),ugr=o(`Note:
Loading a model from its configuration file does `),x8e=a("strong"),_gr=o("not"),bgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),vgr=o("from_pretrained()"),Fgr=o(" to load the model weights."),Tgr=l(),F(a9.$$.fragment),Mgr=l(),xr=a("div"),F(Jy.$$.fragment),Egr=l(),$8e=a("p"),Cgr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),wgr=l(),tn=a("p"),Agr=o("The model class to instantiate is selected based on the "),k8e=a("code"),ygr=o("model_type"),Lgr=o(` property of the config object (either
passed as an argument or loaded from `),S8e=a("code"),xgr=o("pretrained_model_name_or_path"),$gr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R8e=a("code"),kgr=o("pretrained_model_name_or_path"),Sgr=o(":"),Rgr=l(),ie=a("ul"),n9=a("li"),B8e=a("strong"),Bgr=o("albert"),Pgr=o(" \u2014 "),RQ=a("a"),Igr=o("TFAlbertForMaskedLM"),qgr=o(" (ALBERT model)"),Ngr=l(),s9=a("li"),P8e=a("strong"),jgr=o("bert"),Dgr=o(" \u2014 "),BQ=a("a"),Ggr=o("TFBertForMaskedLM"),Ogr=o(" (BERT model)"),Vgr=l(),l9=a("li"),I8e=a("strong"),Xgr=o("camembert"),zgr=o(" \u2014 "),PQ=a("a"),Qgr=o("TFCamembertForMaskedLM"),Wgr=o(" (CamemBERT model)"),Hgr=l(),i9=a("li"),q8e=a("strong"),Ugr=o("convbert"),Jgr=o(" \u2014 "),IQ=a("a"),Ygr=o("TFConvBertForMaskedLM"),Kgr=o(" (ConvBERT model)"),Zgr=l(),d9=a("li"),N8e=a("strong"),ehr=o("deberta"),ohr=o(" \u2014 "),qQ=a("a"),rhr=o("TFDebertaForMaskedLM"),thr=o(" (DeBERTa model)"),ahr=l(),c9=a("li"),j8e=a("strong"),nhr=o("deberta-v2"),shr=o(" \u2014 "),NQ=a("a"),lhr=o("TFDebertaV2ForMaskedLM"),ihr=o(" (DeBERTa-v2 model)"),dhr=l(),f9=a("li"),D8e=a("strong"),chr=o("distilbert"),fhr=o(" \u2014 "),jQ=a("a"),mhr=o("TFDistilBertForMaskedLM"),ghr=o(" (DistilBERT model)"),hhr=l(),m9=a("li"),G8e=a("strong"),phr=o("electra"),uhr=o(" \u2014 "),DQ=a("a"),_hr=o("TFElectraForMaskedLM"),bhr=o(" (ELECTRA model)"),vhr=l(),g9=a("li"),O8e=a("strong"),Fhr=o("flaubert"),Thr=o(" \u2014 "),GQ=a("a"),Mhr=o("TFFlaubertWithLMHeadModel"),Ehr=o(" (FlauBERT model)"),Chr=l(),h9=a("li"),V8e=a("strong"),whr=o("funnel"),Ahr=o(" \u2014 "),OQ=a("a"),yhr=o("TFFunnelForMaskedLM"),Lhr=o(" (Funnel Transformer model)"),xhr=l(),p9=a("li"),X8e=a("strong"),$hr=o("layoutlm"),khr=o(" \u2014 "),VQ=a("a"),Shr=o("TFLayoutLMForMaskedLM"),Rhr=o(" (LayoutLM model)"),Bhr=l(),u9=a("li"),z8e=a("strong"),Phr=o("longformer"),Ihr=o(" \u2014 "),XQ=a("a"),qhr=o("TFLongformerForMaskedLM"),Nhr=o(" (Longformer model)"),jhr=l(),_9=a("li"),Q8e=a("strong"),Dhr=o("mobilebert"),Ghr=o(" \u2014 "),zQ=a("a"),Ohr=o("TFMobileBertForMaskedLM"),Vhr=o(" (MobileBERT model)"),Xhr=l(),b9=a("li"),W8e=a("strong"),zhr=o("mpnet"),Qhr=o(" \u2014 "),QQ=a("a"),Whr=o("TFMPNetForMaskedLM"),Hhr=o(" (MPNet model)"),Uhr=l(),v9=a("li"),H8e=a("strong"),Jhr=o("rembert"),Yhr=o(" \u2014 "),WQ=a("a"),Khr=o("TFRemBertForMaskedLM"),Zhr=o(" (RemBERT model)"),epr=l(),F9=a("li"),U8e=a("strong"),opr=o("roberta"),rpr=o(" \u2014 "),HQ=a("a"),tpr=o("TFRobertaForMaskedLM"),apr=o(" (RoBERTa model)"),npr=l(),T9=a("li"),J8e=a("strong"),spr=o("roformer"),lpr=o(" \u2014 "),UQ=a("a"),ipr=o("TFRoFormerForMaskedLM"),dpr=o(" (RoFormer model)"),cpr=l(),M9=a("li"),Y8e=a("strong"),fpr=o("tapas"),mpr=o(" \u2014 "),JQ=a("a"),gpr=o("TFTapasForMaskedLM"),hpr=o(" (TAPAS model)"),ppr=l(),E9=a("li"),K8e=a("strong"),upr=o("xlm"),_pr=o(" \u2014 "),YQ=a("a"),bpr=o("TFXLMWithLMHeadModel"),vpr=o(" (XLM model)"),Fpr=l(),C9=a("li"),Z8e=a("strong"),Tpr=o("xlm-roberta"),Mpr=o(" \u2014 "),KQ=a("a"),Epr=o("TFXLMRobertaForMaskedLM"),Cpr=o(" (XLM-RoBERTa model)"),wpr=l(),F(w9.$$.fragment),$Ie=l(),Zd=a("h2"),A9=a("a"),ebe=a("span"),F(Yy.$$.fragment),Apr=l(),obe=a("span"),ypr=o("TFAutoModelForSeq2SeqLM"),kIe=l(),rr=a("div"),F(Ky.$$.fragment),Lpr=l(),ec=a("p"),xpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ZQ=a("a"),$pr=o("from_pretrained()"),kpr=o(" class method or the "),eW=a("a"),Spr=o("from_config()"),Rpr=o(` class
method.`),Bpr=l(),Zy=a("p"),Ppr=o("This class cannot be instantiated directly using "),rbe=a("code"),Ipr=o("__init__()"),qpr=o(" (throws an error)."),Npr=l(),$t=a("div"),F(eL.$$.fragment),jpr=l(),tbe=a("p"),Dpr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Gpr=l(),oc=a("p"),Opr=o(`Note:
Loading a model from its configuration file does `),abe=a("strong"),Vpr=o("not"),Xpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=a("a"),zpr=o("from_pretrained()"),Qpr=o(" to load the model weights."),Wpr=l(),F(y9.$$.fragment),Hpr=l(),$r=a("div"),F(oL.$$.fragment),Upr=l(),nbe=a("p"),Jpr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ypr=l(),an=a("p"),Kpr=o("The model class to instantiate is selected based on the "),sbe=a("code"),Zpr=o("model_type"),eur=o(` property of the config object (either
passed as an argument or loaded from `),lbe=a("code"),our=o("pretrained_model_name_or_path"),rur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ibe=a("code"),tur=o("pretrained_model_name_or_path"),aur=o(":"),nur=l(),ye=a("ul"),L9=a("li"),dbe=a("strong"),sur=o("bart"),lur=o(" \u2014 "),rW=a("a"),iur=o("TFBartForConditionalGeneration"),dur=o(" (BART model)"),cur=l(),x9=a("li"),cbe=a("strong"),fur=o("blenderbot"),mur=o(" \u2014 "),tW=a("a"),gur=o("TFBlenderbotForConditionalGeneration"),hur=o(" (Blenderbot model)"),pur=l(),$9=a("li"),fbe=a("strong"),uur=o("blenderbot-small"),_ur=o(" \u2014 "),aW=a("a"),bur=o("TFBlenderbotSmallForConditionalGeneration"),vur=o(" (BlenderbotSmall model)"),Fur=l(),k9=a("li"),mbe=a("strong"),Tur=o("encoder-decoder"),Mur=o(" \u2014 "),nW=a("a"),Eur=o("TFEncoderDecoderModel"),Cur=o(" (Encoder decoder model)"),wur=l(),S9=a("li"),gbe=a("strong"),Aur=o("led"),yur=o(" \u2014 "),sW=a("a"),Lur=o("TFLEDForConditionalGeneration"),xur=o(" (LED model)"),$ur=l(),R9=a("li"),hbe=a("strong"),kur=o("marian"),Sur=o(" \u2014 "),lW=a("a"),Rur=o("TFMarianMTModel"),Bur=o(" (Marian model)"),Pur=l(),B9=a("li"),pbe=a("strong"),Iur=o("mbart"),qur=o(" \u2014 "),iW=a("a"),Nur=o("TFMBartForConditionalGeneration"),jur=o(" (mBART model)"),Dur=l(),P9=a("li"),ube=a("strong"),Gur=o("mt5"),Our=o(" \u2014 "),dW=a("a"),Vur=o("TFMT5ForConditionalGeneration"),Xur=o(" (mT5 model)"),zur=l(),I9=a("li"),_be=a("strong"),Qur=o("pegasus"),Wur=o(" \u2014 "),cW=a("a"),Hur=o("TFPegasusForConditionalGeneration"),Uur=o(" (Pegasus model)"),Jur=l(),q9=a("li"),bbe=a("strong"),Yur=o("t5"),Kur=o(" \u2014 "),fW=a("a"),Zur=o("TFT5ForConditionalGeneration"),e_r=o(" (T5 model)"),o_r=l(),F(N9.$$.fragment),SIe=l(),rc=a("h2"),j9=a("a"),vbe=a("span"),F(rL.$$.fragment),r_r=l(),Fbe=a("span"),t_r=o("TFAutoModelForSequenceClassification"),RIe=l(),tr=a("div"),F(tL.$$.fragment),a_r=l(),tc=a("p"),n_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),mW=a("a"),s_r=o("from_pretrained()"),l_r=o(" class method or the "),gW=a("a"),i_r=o("from_config()"),d_r=o(` class
method.`),c_r=l(),aL=a("p"),f_r=o("This class cannot be instantiated directly using "),Tbe=a("code"),m_r=o("__init__()"),g_r=o(" (throws an error)."),h_r=l(),kt=a("div"),F(nL.$$.fragment),p_r=l(),Mbe=a("p"),u_r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),__r=l(),ac=a("p"),b_r=o(`Note:
Loading a model from its configuration file does `),Ebe=a("strong"),v_r=o("not"),F_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hW=a("a"),T_r=o("from_pretrained()"),M_r=o(" to load the model weights."),E_r=l(),F(D9.$$.fragment),C_r=l(),kr=a("div"),F(sL.$$.fragment),w_r=l(),Cbe=a("p"),A_r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),y_r=l(),nn=a("p"),L_r=o("The model class to instantiate is selected based on the "),wbe=a("code"),x_r=o("model_type"),$_r=o(` property of the config object (either
passed as an argument or loaded from `),Abe=a("code"),k_r=o("pretrained_model_name_or_path"),S_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ybe=a("code"),R_r=o("pretrained_model_name_or_path"),B_r=o(":"),P_r=l(),Z=a("ul"),G9=a("li"),Lbe=a("strong"),I_r=o("albert"),q_r=o(" \u2014 "),pW=a("a"),N_r=o("TFAlbertForSequenceClassification"),j_r=o(" (ALBERT model)"),D_r=l(),O9=a("li"),xbe=a("strong"),G_r=o("bert"),O_r=o(" \u2014 "),uW=a("a"),V_r=o("TFBertForSequenceClassification"),X_r=o(" (BERT model)"),z_r=l(),V9=a("li"),$be=a("strong"),Q_r=o("camembert"),W_r=o(" \u2014 "),_W=a("a"),H_r=o("TFCamembertForSequenceClassification"),U_r=o(" (CamemBERT model)"),J_r=l(),X9=a("li"),kbe=a("strong"),Y_r=o("convbert"),K_r=o(" \u2014 "),bW=a("a"),Z_r=o("TFConvBertForSequenceClassification"),e1r=o(" (ConvBERT model)"),o1r=l(),z9=a("li"),Sbe=a("strong"),r1r=o("ctrl"),t1r=o(" \u2014 "),vW=a("a"),a1r=o("TFCTRLForSequenceClassification"),n1r=o(" (CTRL model)"),s1r=l(),Q9=a("li"),Rbe=a("strong"),l1r=o("deberta"),i1r=o(" \u2014 "),FW=a("a"),d1r=o("TFDebertaForSequenceClassification"),c1r=o(" (DeBERTa model)"),f1r=l(),W9=a("li"),Bbe=a("strong"),m1r=o("deberta-v2"),g1r=o(" \u2014 "),TW=a("a"),h1r=o("TFDebertaV2ForSequenceClassification"),p1r=o(" (DeBERTa-v2 model)"),u1r=l(),H9=a("li"),Pbe=a("strong"),_1r=o("distilbert"),b1r=o(" \u2014 "),MW=a("a"),v1r=o("TFDistilBertForSequenceClassification"),F1r=o(" (DistilBERT model)"),T1r=l(),U9=a("li"),Ibe=a("strong"),M1r=o("electra"),E1r=o(" \u2014 "),EW=a("a"),C1r=o("TFElectraForSequenceClassification"),w1r=o(" (ELECTRA model)"),A1r=l(),J9=a("li"),qbe=a("strong"),y1r=o("flaubert"),L1r=o(" \u2014 "),CW=a("a"),x1r=o("TFFlaubertForSequenceClassification"),$1r=o(" (FlauBERT model)"),k1r=l(),Y9=a("li"),Nbe=a("strong"),S1r=o("funnel"),R1r=o(" \u2014 "),wW=a("a"),B1r=o("TFFunnelForSequenceClassification"),P1r=o(" (Funnel Transformer model)"),I1r=l(),K9=a("li"),jbe=a("strong"),q1r=o("gpt2"),N1r=o(" \u2014 "),AW=a("a"),j1r=o("TFGPT2ForSequenceClassification"),D1r=o(" (OpenAI GPT-2 model)"),G1r=l(),Z9=a("li"),Dbe=a("strong"),O1r=o("gptj"),V1r=o(" \u2014 "),yW=a("a"),X1r=o("TFGPTJForSequenceClassification"),z1r=o(" (GPT-J model)"),Q1r=l(),eM=a("li"),Gbe=a("strong"),W1r=o("layoutlm"),H1r=o(" \u2014 "),LW=a("a"),U1r=o("TFLayoutLMForSequenceClassification"),J1r=o(" (LayoutLM model)"),Y1r=l(),oM=a("li"),Obe=a("strong"),K1r=o("longformer"),Z1r=o(" \u2014 "),xW=a("a"),e8r=o("TFLongformerForSequenceClassification"),o8r=o(" (Longformer model)"),r8r=l(),rM=a("li"),Vbe=a("strong"),t8r=o("mobilebert"),a8r=o(" \u2014 "),$W=a("a"),n8r=o("TFMobileBertForSequenceClassification"),s8r=o(" (MobileBERT model)"),l8r=l(),tM=a("li"),Xbe=a("strong"),i8r=o("mpnet"),d8r=o(" \u2014 "),kW=a("a"),c8r=o("TFMPNetForSequenceClassification"),f8r=o(" (MPNet model)"),m8r=l(),aM=a("li"),zbe=a("strong"),g8r=o("openai-gpt"),h8r=o(" \u2014 "),SW=a("a"),p8r=o("TFOpenAIGPTForSequenceClassification"),u8r=o(" (OpenAI GPT model)"),_8r=l(),nM=a("li"),Qbe=a("strong"),b8r=o("rembert"),v8r=o(" \u2014 "),RW=a("a"),F8r=o("TFRemBertForSequenceClassification"),T8r=o(" (RemBERT model)"),M8r=l(),sM=a("li"),Wbe=a("strong"),E8r=o("roberta"),C8r=o(" \u2014 "),BW=a("a"),w8r=o("TFRobertaForSequenceClassification"),A8r=o(" (RoBERTa model)"),y8r=l(),lM=a("li"),Hbe=a("strong"),L8r=o("roformer"),x8r=o(" \u2014 "),PW=a("a"),$8r=o("TFRoFormerForSequenceClassification"),k8r=o(" (RoFormer model)"),S8r=l(),iM=a("li"),Ube=a("strong"),R8r=o("tapas"),B8r=o(" \u2014 "),IW=a("a"),P8r=o("TFTapasForSequenceClassification"),I8r=o(" (TAPAS model)"),q8r=l(),dM=a("li"),Jbe=a("strong"),N8r=o("transfo-xl"),j8r=o(" \u2014 "),qW=a("a"),D8r=o("TFTransfoXLForSequenceClassification"),G8r=o(" (Transformer-XL model)"),O8r=l(),cM=a("li"),Ybe=a("strong"),V8r=o("xlm"),X8r=o(" \u2014 "),NW=a("a"),z8r=o("TFXLMForSequenceClassification"),Q8r=o(" (XLM model)"),W8r=l(),fM=a("li"),Kbe=a("strong"),H8r=o("xlm-roberta"),U8r=o(" \u2014 "),jW=a("a"),J8r=o("TFXLMRobertaForSequenceClassification"),Y8r=o(" (XLM-RoBERTa model)"),K8r=l(),mM=a("li"),Zbe=a("strong"),Z8r=o("xlnet"),ebr=o(" \u2014 "),DW=a("a"),obr=o("TFXLNetForSequenceClassification"),rbr=o(" (XLNet model)"),tbr=l(),F(gM.$$.fragment),BIe=l(),nc=a("h2"),hM=a("a"),e2e=a("span"),F(lL.$$.fragment),abr=l(),o2e=a("span"),nbr=o("TFAutoModelForMultipleChoice"),PIe=l(),ar=a("div"),F(iL.$$.fragment),sbr=l(),sc=a("p"),lbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GW=a("a"),ibr=o("from_pretrained()"),dbr=o(" class method or the "),OW=a("a"),cbr=o("from_config()"),fbr=o(` class
method.`),mbr=l(),dL=a("p"),gbr=o("This class cannot be instantiated directly using "),r2e=a("code"),hbr=o("__init__()"),pbr=o(" (throws an error)."),ubr=l(),St=a("div"),F(cL.$$.fragment),_br=l(),t2e=a("p"),bbr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vbr=l(),lc=a("p"),Fbr=o(`Note:
Loading a model from its configuration file does `),a2e=a("strong"),Tbr=o("not"),Mbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),Ebr=o("from_pretrained()"),Cbr=o(" to load the model weights."),wbr=l(),F(pM.$$.fragment),Abr=l(),Sr=a("div"),F(fL.$$.fragment),ybr=l(),n2e=a("p"),Lbr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),xbr=l(),sn=a("p"),$br=o("The model class to instantiate is selected based on the "),s2e=a("code"),kbr=o("model_type"),Sbr=o(` property of the config object (either
passed as an argument or loaded from `),l2e=a("code"),Rbr=o("pretrained_model_name_or_path"),Bbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i2e=a("code"),Pbr=o("pretrained_model_name_or_path"),Ibr=o(":"),qbr=l(),pe=a("ul"),uM=a("li"),d2e=a("strong"),Nbr=o("albert"),jbr=o(" \u2014 "),XW=a("a"),Dbr=o("TFAlbertForMultipleChoice"),Gbr=o(" (ALBERT model)"),Obr=l(),_M=a("li"),c2e=a("strong"),Vbr=o("bert"),Xbr=o(" \u2014 "),zW=a("a"),zbr=o("TFBertForMultipleChoice"),Qbr=o(" (BERT model)"),Wbr=l(),bM=a("li"),f2e=a("strong"),Hbr=o("camembert"),Ubr=o(" \u2014 "),QW=a("a"),Jbr=o("TFCamembertForMultipleChoice"),Ybr=o(" (CamemBERT model)"),Kbr=l(),vM=a("li"),m2e=a("strong"),Zbr=o("convbert"),e2r=o(" \u2014 "),WW=a("a"),o2r=o("TFConvBertForMultipleChoice"),r2r=o(" (ConvBERT model)"),t2r=l(),FM=a("li"),g2e=a("strong"),a2r=o("distilbert"),n2r=o(" \u2014 "),HW=a("a"),s2r=o("TFDistilBertForMultipleChoice"),l2r=o(" (DistilBERT model)"),i2r=l(),TM=a("li"),h2e=a("strong"),d2r=o("electra"),c2r=o(" \u2014 "),UW=a("a"),f2r=o("TFElectraForMultipleChoice"),m2r=o(" (ELECTRA model)"),g2r=l(),MM=a("li"),p2e=a("strong"),h2r=o("flaubert"),p2r=o(" \u2014 "),JW=a("a"),u2r=o("TFFlaubertForMultipleChoice"),_2r=o(" (FlauBERT model)"),b2r=l(),EM=a("li"),u2e=a("strong"),v2r=o("funnel"),F2r=o(" \u2014 "),YW=a("a"),T2r=o("TFFunnelForMultipleChoice"),M2r=o(" (Funnel Transformer model)"),E2r=l(),CM=a("li"),_2e=a("strong"),C2r=o("longformer"),w2r=o(" \u2014 "),KW=a("a"),A2r=o("TFLongformerForMultipleChoice"),y2r=o(" (Longformer model)"),L2r=l(),wM=a("li"),b2e=a("strong"),x2r=o("mobilebert"),$2r=o(" \u2014 "),ZW=a("a"),k2r=o("TFMobileBertForMultipleChoice"),S2r=o(" (MobileBERT model)"),R2r=l(),AM=a("li"),v2e=a("strong"),B2r=o("mpnet"),P2r=o(" \u2014 "),eH=a("a"),I2r=o("TFMPNetForMultipleChoice"),q2r=o(" (MPNet model)"),N2r=l(),yM=a("li"),F2e=a("strong"),j2r=o("rembert"),D2r=o(" \u2014 "),oH=a("a"),G2r=o("TFRemBertForMultipleChoice"),O2r=o(" (RemBERT model)"),V2r=l(),LM=a("li"),T2e=a("strong"),X2r=o("roberta"),z2r=o(" \u2014 "),rH=a("a"),Q2r=o("TFRobertaForMultipleChoice"),W2r=o(" (RoBERTa model)"),H2r=l(),xM=a("li"),M2e=a("strong"),U2r=o("roformer"),J2r=o(" \u2014 "),tH=a("a"),Y2r=o("TFRoFormerForMultipleChoice"),K2r=o(" (RoFormer model)"),Z2r=l(),$M=a("li"),E2e=a("strong"),evr=o("xlm"),ovr=o(" \u2014 "),aH=a("a"),rvr=o("TFXLMForMultipleChoice"),tvr=o(" (XLM model)"),avr=l(),kM=a("li"),C2e=a("strong"),nvr=o("xlm-roberta"),svr=o(" \u2014 "),nH=a("a"),lvr=o("TFXLMRobertaForMultipleChoice"),ivr=o(" (XLM-RoBERTa model)"),dvr=l(),SM=a("li"),w2e=a("strong"),cvr=o("xlnet"),fvr=o(" \u2014 "),sH=a("a"),mvr=o("TFXLNetForMultipleChoice"),gvr=o(" (XLNet model)"),hvr=l(),F(RM.$$.fragment),IIe=l(),ic=a("h2"),BM=a("a"),A2e=a("span"),F(mL.$$.fragment),pvr=l(),y2e=a("span"),uvr=o("TFAutoModelForNextSentencePrediction"),qIe=l(),nr=a("div"),F(gL.$$.fragment),_vr=l(),dc=a("p"),bvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),lH=a("a"),vvr=o("from_pretrained()"),Fvr=o(" class method or the "),iH=a("a"),Tvr=o("from_config()"),Mvr=o(` class
method.`),Evr=l(),hL=a("p"),Cvr=o("This class cannot be instantiated directly using "),L2e=a("code"),wvr=o("__init__()"),Avr=o(" (throws an error)."),yvr=l(),Rt=a("div"),F(pL.$$.fragment),Lvr=l(),x2e=a("p"),xvr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$vr=l(),cc=a("p"),kvr=o(`Note:
Loading a model from its configuration file does `),$2e=a("strong"),Svr=o("not"),Rvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dH=a("a"),Bvr=o("from_pretrained()"),Pvr=o(" to load the model weights."),Ivr=l(),F(PM.$$.fragment),qvr=l(),Rr=a("div"),F(uL.$$.fragment),Nvr=l(),k2e=a("p"),jvr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Dvr=l(),ln=a("p"),Gvr=o("The model class to instantiate is selected based on the "),S2e=a("code"),Ovr=o("model_type"),Vvr=o(` property of the config object (either
passed as an argument or loaded from `),R2e=a("code"),Xvr=o("pretrained_model_name_or_path"),zvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B2e=a("code"),Qvr=o("pretrained_model_name_or_path"),Wvr=o(":"),Hvr=l(),_L=a("ul"),IM=a("li"),P2e=a("strong"),Uvr=o("bert"),Jvr=o(" \u2014 "),cH=a("a"),Yvr=o("TFBertForNextSentencePrediction"),Kvr=o(" (BERT model)"),Zvr=l(),qM=a("li"),I2e=a("strong"),eFr=o("mobilebert"),oFr=o(" \u2014 "),fH=a("a"),rFr=o("TFMobileBertForNextSentencePrediction"),tFr=o(" (MobileBERT model)"),aFr=l(),F(NM.$$.fragment),NIe=l(),fc=a("h2"),jM=a("a"),q2e=a("span"),F(bL.$$.fragment),nFr=l(),N2e=a("span"),sFr=o("TFAutoModelForTableQuestionAnswering"),jIe=l(),sr=a("div"),F(vL.$$.fragment),lFr=l(),mc=a("p"),iFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),mH=a("a"),dFr=o("from_pretrained()"),cFr=o(" class method or the "),gH=a("a"),fFr=o("from_config()"),mFr=o(` class
method.`),gFr=l(),FL=a("p"),hFr=o("This class cannot be instantiated directly using "),j2e=a("code"),pFr=o("__init__()"),uFr=o(" (throws an error)."),_Fr=l(),Bt=a("div"),F(TL.$$.fragment),bFr=l(),D2e=a("p"),vFr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),FFr=l(),gc=a("p"),TFr=o(`Note:
Loading a model from its configuration file does `),G2e=a("strong"),MFr=o("not"),EFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hH=a("a"),CFr=o("from_pretrained()"),wFr=o(" to load the model weights."),AFr=l(),F(DM.$$.fragment),yFr=l(),Br=a("div"),F(ML.$$.fragment),LFr=l(),O2e=a("p"),xFr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),$Fr=l(),dn=a("p"),kFr=o("The model class to instantiate is selected based on the "),V2e=a("code"),SFr=o("model_type"),RFr=o(` property of the config object (either
passed as an argument or loaded from `),X2e=a("code"),BFr=o("pretrained_model_name_or_path"),PFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z2e=a("code"),IFr=o("pretrained_model_name_or_path"),qFr=o(":"),NFr=l(),Q2e=a("ul"),GM=a("li"),W2e=a("strong"),jFr=o("tapas"),DFr=o(" \u2014 "),pH=a("a"),GFr=o("TFTapasForQuestionAnswering"),OFr=o(" (TAPAS model)"),VFr=l(),F(OM.$$.fragment),DIe=l(),hc=a("h2"),VM=a("a"),H2e=a("span"),F(EL.$$.fragment),XFr=l(),U2e=a("span"),zFr=o("TFAutoModelForTokenClassification"),GIe=l(),lr=a("div"),F(CL.$$.fragment),QFr=l(),pc=a("p"),WFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),uH=a("a"),HFr=o("from_pretrained()"),UFr=o(" class method or the "),_H=a("a"),JFr=o("from_config()"),YFr=o(` class
method.`),KFr=l(),wL=a("p"),ZFr=o("This class cannot be instantiated directly using "),J2e=a("code"),e6r=o("__init__()"),o6r=o(" (throws an error)."),r6r=l(),Pt=a("div"),F(AL.$$.fragment),t6r=l(),Y2e=a("p"),a6r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),n6r=l(),uc=a("p"),s6r=o(`Note:
Loading a model from its configuration file does `),K2e=a("strong"),l6r=o("not"),i6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bH=a("a"),d6r=o("from_pretrained()"),c6r=o(" to load the model weights."),f6r=l(),F(XM.$$.fragment),m6r=l(),Pr=a("div"),F(yL.$$.fragment),g6r=l(),Z2e=a("p"),h6r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),p6r=l(),cn=a("p"),u6r=o("The model class to instantiate is selected based on the "),eve=a("code"),_6r=o("model_type"),b6r=o(` property of the config object (either
passed as an argument or loaded from `),ove=a("code"),v6r=o("pretrained_model_name_or_path"),F6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rve=a("code"),T6r=o("pretrained_model_name_or_path"),M6r=o(":"),E6r=l(),de=a("ul"),zM=a("li"),tve=a("strong"),C6r=o("albert"),w6r=o(" \u2014 "),vH=a("a"),A6r=o("TFAlbertForTokenClassification"),y6r=o(" (ALBERT model)"),L6r=l(),QM=a("li"),ave=a("strong"),x6r=o("bert"),$6r=o(" \u2014 "),FH=a("a"),k6r=o("TFBertForTokenClassification"),S6r=o(" (BERT model)"),R6r=l(),WM=a("li"),nve=a("strong"),B6r=o("camembert"),P6r=o(" \u2014 "),TH=a("a"),I6r=o("TFCamembertForTokenClassification"),q6r=o(" (CamemBERT model)"),N6r=l(),HM=a("li"),sve=a("strong"),j6r=o("convbert"),D6r=o(" \u2014 "),MH=a("a"),G6r=o("TFConvBertForTokenClassification"),O6r=o(" (ConvBERT model)"),V6r=l(),UM=a("li"),lve=a("strong"),X6r=o("deberta"),z6r=o(" \u2014 "),EH=a("a"),Q6r=o("TFDebertaForTokenClassification"),W6r=o(" (DeBERTa model)"),H6r=l(),JM=a("li"),ive=a("strong"),U6r=o("deberta-v2"),J6r=o(" \u2014 "),CH=a("a"),Y6r=o("TFDebertaV2ForTokenClassification"),K6r=o(" (DeBERTa-v2 model)"),Z6r=l(),YM=a("li"),dve=a("strong"),eTr=o("distilbert"),oTr=o(" \u2014 "),wH=a("a"),rTr=o("TFDistilBertForTokenClassification"),tTr=o(" (DistilBERT model)"),aTr=l(),KM=a("li"),cve=a("strong"),nTr=o("electra"),sTr=o(" \u2014 "),AH=a("a"),lTr=o("TFElectraForTokenClassification"),iTr=o(" (ELECTRA model)"),dTr=l(),ZM=a("li"),fve=a("strong"),cTr=o("flaubert"),fTr=o(" \u2014 "),yH=a("a"),mTr=o("TFFlaubertForTokenClassification"),gTr=o(" (FlauBERT model)"),hTr=l(),e4=a("li"),mve=a("strong"),pTr=o("funnel"),uTr=o(" \u2014 "),LH=a("a"),_Tr=o("TFFunnelForTokenClassification"),bTr=o(" (Funnel Transformer model)"),vTr=l(),o4=a("li"),gve=a("strong"),FTr=o("layoutlm"),TTr=o(" \u2014 "),xH=a("a"),MTr=o("TFLayoutLMForTokenClassification"),ETr=o(" (LayoutLM model)"),CTr=l(),r4=a("li"),hve=a("strong"),wTr=o("longformer"),ATr=o(" \u2014 "),$H=a("a"),yTr=o("TFLongformerForTokenClassification"),LTr=o(" (Longformer model)"),xTr=l(),t4=a("li"),pve=a("strong"),$Tr=o("mobilebert"),kTr=o(" \u2014 "),kH=a("a"),STr=o("TFMobileBertForTokenClassification"),RTr=o(" (MobileBERT model)"),BTr=l(),a4=a("li"),uve=a("strong"),PTr=o("mpnet"),ITr=o(" \u2014 "),SH=a("a"),qTr=o("TFMPNetForTokenClassification"),NTr=o(" (MPNet model)"),jTr=l(),n4=a("li"),_ve=a("strong"),DTr=o("rembert"),GTr=o(" \u2014 "),RH=a("a"),OTr=o("TFRemBertForTokenClassification"),VTr=o(" (RemBERT model)"),XTr=l(),s4=a("li"),bve=a("strong"),zTr=o("roberta"),QTr=o(" \u2014 "),BH=a("a"),WTr=o("TFRobertaForTokenClassification"),HTr=o(" (RoBERTa model)"),UTr=l(),l4=a("li"),vve=a("strong"),JTr=o("roformer"),YTr=o(" \u2014 "),PH=a("a"),KTr=o("TFRoFormerForTokenClassification"),ZTr=o(" (RoFormer model)"),e9r=l(),i4=a("li"),Fve=a("strong"),o9r=o("xlm"),r9r=o(" \u2014 "),IH=a("a"),t9r=o("TFXLMForTokenClassification"),a9r=o(" (XLM model)"),n9r=l(),d4=a("li"),Tve=a("strong"),s9r=o("xlm-roberta"),l9r=o(" \u2014 "),qH=a("a"),i9r=o("TFXLMRobertaForTokenClassification"),d9r=o(" (XLM-RoBERTa model)"),c9r=l(),c4=a("li"),Mve=a("strong"),f9r=o("xlnet"),m9r=o(" \u2014 "),NH=a("a"),g9r=o("TFXLNetForTokenClassification"),h9r=o(" (XLNet model)"),p9r=l(),F(f4.$$.fragment),OIe=l(),_c=a("h2"),m4=a("a"),Eve=a("span"),F(LL.$$.fragment),u9r=l(),Cve=a("span"),_9r=o("TFAutoModelForQuestionAnswering"),VIe=l(),ir=a("div"),F(xL.$$.fragment),b9r=l(),bc=a("p"),v9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jH=a("a"),F9r=o("from_pretrained()"),T9r=o(" class method or the "),DH=a("a"),M9r=o("from_config()"),E9r=o(` class
method.`),C9r=l(),$L=a("p"),w9r=o("This class cannot be instantiated directly using "),wve=a("code"),A9r=o("__init__()"),y9r=o(" (throws an error)."),L9r=l(),It=a("div"),F(kL.$$.fragment),x9r=l(),Ave=a("p"),$9r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),k9r=l(),vc=a("p"),S9r=o(`Note:
Loading a model from its configuration file does `),yve=a("strong"),R9r=o("not"),B9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GH=a("a"),P9r=o("from_pretrained()"),I9r=o(" to load the model weights."),q9r=l(),F(g4.$$.fragment),N9r=l(),Ir=a("div"),F(SL.$$.fragment),j9r=l(),Lve=a("p"),D9r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G9r=l(),fn=a("p"),O9r=o("The model class to instantiate is selected based on the "),xve=a("code"),V9r=o("model_type"),X9r=o(` property of the config object (either
passed as an argument or loaded from `),$ve=a("code"),z9r=o("pretrained_model_name_or_path"),Q9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kve=a("code"),W9r=o("pretrained_model_name_or_path"),H9r=o(":"),U9r=l(),ce=a("ul"),h4=a("li"),Sve=a("strong"),J9r=o("albert"),Y9r=o(" \u2014 "),OH=a("a"),K9r=o("TFAlbertForQuestionAnswering"),Z9r=o(" (ALBERT model)"),eMr=l(),p4=a("li"),Rve=a("strong"),oMr=o("bert"),rMr=o(" \u2014 "),VH=a("a"),tMr=o("TFBertForQuestionAnswering"),aMr=o(" (BERT model)"),nMr=l(),u4=a("li"),Bve=a("strong"),sMr=o("camembert"),lMr=o(" \u2014 "),XH=a("a"),iMr=o("TFCamembertForQuestionAnswering"),dMr=o(" (CamemBERT model)"),cMr=l(),_4=a("li"),Pve=a("strong"),fMr=o("convbert"),mMr=o(" \u2014 "),zH=a("a"),gMr=o("TFConvBertForQuestionAnswering"),hMr=o(" (ConvBERT model)"),pMr=l(),b4=a("li"),Ive=a("strong"),uMr=o("deberta"),_Mr=o(" \u2014 "),QH=a("a"),bMr=o("TFDebertaForQuestionAnswering"),vMr=o(" (DeBERTa model)"),FMr=l(),v4=a("li"),qve=a("strong"),TMr=o("deberta-v2"),MMr=o(" \u2014 "),WH=a("a"),EMr=o("TFDebertaV2ForQuestionAnswering"),CMr=o(" (DeBERTa-v2 model)"),wMr=l(),F4=a("li"),Nve=a("strong"),AMr=o("distilbert"),yMr=o(" \u2014 "),HH=a("a"),LMr=o("TFDistilBertForQuestionAnswering"),xMr=o(" (DistilBERT model)"),$Mr=l(),T4=a("li"),jve=a("strong"),kMr=o("electra"),SMr=o(" \u2014 "),UH=a("a"),RMr=o("TFElectraForQuestionAnswering"),BMr=o(" (ELECTRA model)"),PMr=l(),M4=a("li"),Dve=a("strong"),IMr=o("flaubert"),qMr=o(" \u2014 "),JH=a("a"),NMr=o("TFFlaubertForQuestionAnsweringSimple"),jMr=o(" (FlauBERT model)"),DMr=l(),E4=a("li"),Gve=a("strong"),GMr=o("funnel"),OMr=o(" \u2014 "),YH=a("a"),VMr=o("TFFunnelForQuestionAnswering"),XMr=o(" (Funnel Transformer model)"),zMr=l(),C4=a("li"),Ove=a("strong"),QMr=o("gptj"),WMr=o(" \u2014 "),KH=a("a"),HMr=o("TFGPTJForQuestionAnswering"),UMr=o(" (GPT-J model)"),JMr=l(),w4=a("li"),Vve=a("strong"),YMr=o("longformer"),KMr=o(" \u2014 "),ZH=a("a"),ZMr=o("TFLongformerForQuestionAnswering"),e4r=o(" (Longformer model)"),o4r=l(),A4=a("li"),Xve=a("strong"),r4r=o("mobilebert"),t4r=o(" \u2014 "),eU=a("a"),a4r=o("TFMobileBertForQuestionAnswering"),n4r=o(" (MobileBERT model)"),s4r=l(),y4=a("li"),zve=a("strong"),l4r=o("mpnet"),i4r=o(" \u2014 "),oU=a("a"),d4r=o("TFMPNetForQuestionAnswering"),c4r=o(" (MPNet model)"),f4r=l(),L4=a("li"),Qve=a("strong"),m4r=o("rembert"),g4r=o(" \u2014 "),rU=a("a"),h4r=o("TFRemBertForQuestionAnswering"),p4r=o(" (RemBERT model)"),u4r=l(),x4=a("li"),Wve=a("strong"),_4r=o("roberta"),b4r=o(" \u2014 "),tU=a("a"),v4r=o("TFRobertaForQuestionAnswering"),F4r=o(" (RoBERTa model)"),T4r=l(),$4=a("li"),Hve=a("strong"),M4r=o("roformer"),E4r=o(" \u2014 "),aU=a("a"),C4r=o("TFRoFormerForQuestionAnswering"),w4r=o(" (RoFormer model)"),A4r=l(),k4=a("li"),Uve=a("strong"),y4r=o("xlm"),L4r=o(" \u2014 "),nU=a("a"),x4r=o("TFXLMForQuestionAnsweringSimple"),$4r=o(" (XLM model)"),k4r=l(),S4=a("li"),Jve=a("strong"),S4r=o("xlm-roberta"),R4r=o(" \u2014 "),sU=a("a"),B4r=o("TFXLMRobertaForQuestionAnswering"),P4r=o(" (XLM-RoBERTa model)"),I4r=l(),R4=a("li"),Yve=a("strong"),q4r=o("xlnet"),N4r=o(" \u2014 "),lU=a("a"),j4r=o("TFXLNetForQuestionAnsweringSimple"),D4r=o(" (XLNet model)"),G4r=l(),F(B4.$$.fragment),XIe=l(),Fc=a("h2"),P4=a("a"),Kve=a("span"),F(RL.$$.fragment),O4r=l(),Zve=a("span"),V4r=o("TFAutoModelForVision2Seq"),zIe=l(),dr=a("div"),F(BL.$$.fragment),X4r=l(),Tc=a("p"),z4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),iU=a("a"),Q4r=o("from_pretrained()"),W4r=o(" class method or the "),dU=a("a"),H4r=o("from_config()"),U4r=o(` class
method.`),J4r=l(),PL=a("p"),Y4r=o("This class cannot be instantiated directly using "),eFe=a("code"),K4r=o("__init__()"),Z4r=o(" (throws an error)."),eEr=l(),qt=a("div"),F(IL.$$.fragment),oEr=l(),oFe=a("p"),rEr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),tEr=l(),Mc=a("p"),aEr=o(`Note:
Loading a model from its configuration file does `),rFe=a("strong"),nEr=o("not"),sEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cU=a("a"),lEr=o("from_pretrained()"),iEr=o(" to load the model weights."),dEr=l(),F(I4.$$.fragment),cEr=l(),qr=a("div"),F(qL.$$.fragment),fEr=l(),tFe=a("p"),mEr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gEr=l(),mn=a("p"),hEr=o("The model class to instantiate is selected based on the "),aFe=a("code"),pEr=o("model_type"),uEr=o(` property of the config object (either
passed as an argument or loaded from `),nFe=a("code"),_Er=o("pretrained_model_name_or_path"),bEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=a("code"),vEr=o("pretrained_model_name_or_path"),FEr=o(":"),TEr=l(),lFe=a("ul"),q4=a("li"),iFe=a("strong"),MEr=o("vision-encoder-decoder"),EEr=o(" \u2014 "),fU=a("a"),CEr=o("TFVisionEncoderDecoderModel"),wEr=o(" (Vision Encoder decoder model)"),AEr=l(),F(N4.$$.fragment),QIe=l(),Ec=a("h2"),j4=a("a"),dFe=a("span"),F(NL.$$.fragment),yEr=l(),cFe=a("span"),LEr=o("TFAutoModelForSpeechSeq2Seq"),WIe=l(),cr=a("div"),F(jL.$$.fragment),xEr=l(),Cc=a("p"),$Er=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),mU=a("a"),kEr=o("from_pretrained()"),SEr=o(" class method or the "),gU=a("a"),REr=o("from_config()"),BEr=o(` class
method.`),PEr=l(),DL=a("p"),IEr=o("This class cannot be instantiated directly using "),fFe=a("code"),qEr=o("__init__()"),NEr=o(" (throws an error)."),jEr=l(),Nt=a("div"),F(GL.$$.fragment),DEr=l(),mFe=a("p"),GEr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),OEr=l(),wc=a("p"),VEr=o(`Note:
Loading a model from its configuration file does `),gFe=a("strong"),XEr=o("not"),zEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hU=a("a"),QEr=o("from_pretrained()"),WEr=o(" to load the model weights."),HEr=l(),F(D4.$$.fragment),UEr=l(),Nr=a("div"),F(OL.$$.fragment),JEr=l(),hFe=a("p"),YEr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),KEr=l(),gn=a("p"),ZEr=o("The model class to instantiate is selected based on the "),pFe=a("code"),e5r=o("model_type"),o5r=o(` property of the config object (either
passed as an argument or loaded from `),uFe=a("code"),r5r=o("pretrained_model_name_or_path"),t5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Fe=a("code"),a5r=o("pretrained_model_name_or_path"),n5r=o(":"),s5r=l(),bFe=a("ul"),G4=a("li"),vFe=a("strong"),l5r=o("speech_to_text"),i5r=o(" \u2014 "),pU=a("a"),d5r=o("TFSpeech2TextForConditionalGeneration"),c5r=o(" (Speech2Text model)"),f5r=l(),F(O4.$$.fragment),HIe=l(),Ac=a("h2"),V4=a("a"),FFe=a("span"),F(VL.$$.fragment),m5r=l(),TFe=a("span"),g5r=o("FlaxAutoModel"),UIe=l(),fr=a("div"),F(XL.$$.fragment),h5r=l(),yc=a("p"),p5r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),uU=a("a"),u5r=o("from_pretrained()"),_5r=o(" class method or the "),_U=a("a"),b5r=o("from_config()"),v5r=o(` class
method.`),F5r=l(),zL=a("p"),T5r=o("This class cannot be instantiated directly using "),MFe=a("code"),M5r=o("__init__()"),E5r=o(" (throws an error)."),C5r=l(),jt=a("div"),F(QL.$$.fragment),w5r=l(),EFe=a("p"),A5r=o("Instantiates one of the base model classes of the library from a configuration."),y5r=l(),Lc=a("p"),L5r=o(`Note:
Loading a model from its configuration file does `),CFe=a("strong"),x5r=o("not"),$5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bU=a("a"),k5r=o("from_pretrained()"),S5r=o(" to load the model weights."),R5r=l(),F(X4.$$.fragment),B5r=l(),jr=a("div"),F(WL.$$.fragment),P5r=l(),wFe=a("p"),I5r=o("Instantiate one of the base model classes of the library from a pretrained model."),q5r=l(),hn=a("p"),N5r=o("The model class to instantiate is selected based on the "),AFe=a("code"),j5r=o("model_type"),D5r=o(` property of the config object (either
passed as an argument or loaded from `),yFe=a("code"),G5r=o("pretrained_model_name_or_path"),O5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LFe=a("code"),V5r=o("pretrained_model_name_or_path"),X5r=o(":"),z5r=l(),oe=a("ul"),z4=a("li"),xFe=a("strong"),Q5r=o("albert"),W5r=o(" \u2014 "),vU=a("a"),H5r=o("FlaxAlbertModel"),U5r=o(" (ALBERT model)"),J5r=l(),Q4=a("li"),$Fe=a("strong"),Y5r=o("bart"),K5r=o(" \u2014 "),FU=a("a"),Z5r=o("FlaxBartModel"),eCr=o(" (BART model)"),oCr=l(),W4=a("li"),kFe=a("strong"),rCr=o("beit"),tCr=o(" \u2014 "),TU=a("a"),aCr=o("FlaxBeitModel"),nCr=o(" (BEiT model)"),sCr=l(),H4=a("li"),SFe=a("strong"),lCr=o("bert"),iCr=o(" \u2014 "),MU=a("a"),dCr=o("FlaxBertModel"),cCr=o(" (BERT model)"),fCr=l(),U4=a("li"),RFe=a("strong"),mCr=o("big_bird"),gCr=o(" \u2014 "),EU=a("a"),hCr=o("FlaxBigBirdModel"),pCr=o(" (BigBird model)"),uCr=l(),J4=a("li"),BFe=a("strong"),_Cr=o("blenderbot"),bCr=o(" \u2014 "),CU=a("a"),vCr=o("FlaxBlenderbotModel"),FCr=o(" (Blenderbot model)"),TCr=l(),Y4=a("li"),PFe=a("strong"),MCr=o("blenderbot-small"),ECr=o(" \u2014 "),wU=a("a"),CCr=o("FlaxBlenderbotSmallModel"),wCr=o(" (BlenderbotSmall model)"),ACr=l(),K4=a("li"),IFe=a("strong"),yCr=o("clip"),LCr=o(" \u2014 "),AU=a("a"),xCr=o("FlaxCLIPModel"),$Cr=o(" (CLIP model)"),kCr=l(),Z4=a("li"),qFe=a("strong"),SCr=o("distilbert"),RCr=o(" \u2014 "),yU=a("a"),BCr=o("FlaxDistilBertModel"),PCr=o(" (DistilBERT model)"),ICr=l(),eE=a("li"),NFe=a("strong"),qCr=o("electra"),NCr=o(" \u2014 "),LU=a("a"),jCr=o("FlaxElectraModel"),DCr=o(" (ELECTRA model)"),GCr=l(),oE=a("li"),jFe=a("strong"),OCr=o("gpt2"),VCr=o(" \u2014 "),xU=a("a"),XCr=o("FlaxGPT2Model"),zCr=o(" (OpenAI GPT-2 model)"),QCr=l(),rE=a("li"),DFe=a("strong"),WCr=o("gpt_neo"),HCr=o(" \u2014 "),$U=a("a"),UCr=o("FlaxGPTNeoModel"),JCr=o(" (GPT Neo model)"),YCr=l(),tE=a("li"),GFe=a("strong"),KCr=o("gptj"),ZCr=o(" \u2014 "),kU=a("a"),e3r=o("FlaxGPTJModel"),o3r=o(" (GPT-J model)"),r3r=l(),aE=a("li"),OFe=a("strong"),t3r=o("marian"),a3r=o(" \u2014 "),SU=a("a"),n3r=o("FlaxMarianModel"),s3r=o(" (Marian model)"),l3r=l(),nE=a("li"),VFe=a("strong"),i3r=o("mbart"),d3r=o(" \u2014 "),RU=a("a"),c3r=o("FlaxMBartModel"),f3r=o(" (mBART model)"),m3r=l(),sE=a("li"),XFe=a("strong"),g3r=o("mt5"),h3r=o(" \u2014 "),BU=a("a"),p3r=o("FlaxMT5Model"),u3r=o(" (mT5 model)"),_3r=l(),lE=a("li"),zFe=a("strong"),b3r=o("pegasus"),v3r=o(" \u2014 "),PU=a("a"),F3r=o("FlaxPegasusModel"),T3r=o(" (Pegasus model)"),M3r=l(),iE=a("li"),QFe=a("strong"),E3r=o("roberta"),C3r=o(" \u2014 "),IU=a("a"),w3r=o("FlaxRobertaModel"),A3r=o(" (RoBERTa model)"),y3r=l(),dE=a("li"),WFe=a("strong"),L3r=o("roformer"),x3r=o(" \u2014 "),qU=a("a"),$3r=o("FlaxRoFormerModel"),k3r=o(" (RoFormer model)"),S3r=l(),cE=a("li"),HFe=a("strong"),R3r=o("t5"),B3r=o(" \u2014 "),NU=a("a"),P3r=o("FlaxT5Model"),I3r=o(" (T5 model)"),q3r=l(),fE=a("li"),UFe=a("strong"),N3r=o("vision-text-dual-encoder"),j3r=o(" \u2014 "),jU=a("a"),D3r=o("FlaxVisionTextDualEncoderModel"),G3r=o(" (VisionTextDualEncoder model)"),O3r=l(),mE=a("li"),JFe=a("strong"),V3r=o("vit"),X3r=o(" \u2014 "),DU=a("a"),z3r=o("FlaxViTModel"),Q3r=o(" (ViT model)"),W3r=l(),gE=a("li"),YFe=a("strong"),H3r=o("wav2vec2"),U3r=o(" \u2014 "),GU=a("a"),J3r=o("FlaxWav2Vec2Model"),Y3r=o(" (Wav2Vec2 model)"),K3r=l(),hE=a("li"),KFe=a("strong"),Z3r=o("xglm"),ewr=o(" \u2014 "),OU=a("a"),owr=o("FlaxXGLMModel"),rwr=o(" (XGLM model)"),twr=l(),pE=a("li"),ZFe=a("strong"),awr=o("xlm-roberta"),nwr=o(" \u2014 "),VU=a("a"),swr=o("FlaxXLMRobertaModel"),lwr=o(" (XLM-RoBERTa model)"),iwr=l(),F(uE.$$.fragment),JIe=l(),xc=a("h2"),_E=a("a"),e6e=a("span"),F(HL.$$.fragment),dwr=l(),o6e=a("span"),cwr=o("FlaxAutoModelForCausalLM"),YIe=l(),mr=a("div"),F(UL.$$.fragment),fwr=l(),$c=a("p"),mwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),XU=a("a"),gwr=o("from_pretrained()"),hwr=o(" class method or the "),zU=a("a"),pwr=o("from_config()"),uwr=o(` class
method.`),_wr=l(),JL=a("p"),bwr=o("This class cannot be instantiated directly using "),r6e=a("code"),vwr=o("__init__()"),Fwr=o(" (throws an error)."),Twr=l(),Dt=a("div"),F(YL.$$.fragment),Mwr=l(),t6e=a("p"),Ewr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Cwr=l(),kc=a("p"),wwr=o(`Note:
Loading a model from its configuration file does `),a6e=a("strong"),Awr=o("not"),ywr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QU=a("a"),Lwr=o("from_pretrained()"),xwr=o(" to load the model weights."),$wr=l(),F(bE.$$.fragment),kwr=l(),Dr=a("div"),F(KL.$$.fragment),Swr=l(),n6e=a("p"),Rwr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Bwr=l(),pn=a("p"),Pwr=o("The model class to instantiate is selected based on the "),s6e=a("code"),Iwr=o("model_type"),qwr=o(` property of the config object (either
passed as an argument or loaded from `),l6e=a("code"),Nwr=o("pretrained_model_name_or_path"),jwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i6e=a("code"),Dwr=o("pretrained_model_name_or_path"),Gwr=o(":"),Owr=l(),ke=a("ul"),vE=a("li"),d6e=a("strong"),Vwr=o("bart"),Xwr=o(" \u2014 "),WU=a("a"),zwr=o("FlaxBartForCausalLM"),Qwr=o(" (BART model)"),Wwr=l(),FE=a("li"),c6e=a("strong"),Hwr=o("bert"),Uwr=o(" \u2014 "),HU=a("a"),Jwr=o("FlaxBertForCausalLM"),Ywr=o(" (BERT model)"),Kwr=l(),TE=a("li"),f6e=a("strong"),Zwr=o("big_bird"),eAr=o(" \u2014 "),UU=a("a"),oAr=o("FlaxBigBirdForCausalLM"),rAr=o(" (BigBird model)"),tAr=l(),ME=a("li"),m6e=a("strong"),aAr=o("electra"),nAr=o(" \u2014 "),JU=a("a"),sAr=o("FlaxElectraForCausalLM"),lAr=o(" (ELECTRA model)"),iAr=l(),EE=a("li"),g6e=a("strong"),dAr=o("gpt2"),cAr=o(" \u2014 "),YU=a("a"),fAr=o("FlaxGPT2LMHeadModel"),mAr=o(" (OpenAI GPT-2 model)"),gAr=l(),CE=a("li"),h6e=a("strong"),hAr=o("gpt_neo"),pAr=o(" \u2014 "),KU=a("a"),uAr=o("FlaxGPTNeoForCausalLM"),_Ar=o(" (GPT Neo model)"),bAr=l(),wE=a("li"),p6e=a("strong"),vAr=o("gptj"),FAr=o(" \u2014 "),ZU=a("a"),TAr=o("FlaxGPTJForCausalLM"),MAr=o(" (GPT-J model)"),EAr=l(),AE=a("li"),u6e=a("strong"),CAr=o("roberta"),wAr=o(" \u2014 "),eJ=a("a"),AAr=o("FlaxRobertaForCausalLM"),yAr=o(" (RoBERTa model)"),LAr=l(),yE=a("li"),_6e=a("strong"),xAr=o("xglm"),$Ar=o(" \u2014 "),oJ=a("a"),kAr=o("FlaxXGLMForCausalLM"),SAr=o(" (XGLM model)"),RAr=l(),F(LE.$$.fragment),KIe=l(),Sc=a("h2"),xE=a("a"),b6e=a("span"),F(ZL.$$.fragment),BAr=l(),v6e=a("span"),PAr=o("FlaxAutoModelForPreTraining"),ZIe=l(),gr=a("div"),F(ex.$$.fragment),IAr=l(),Rc=a("p"),qAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rJ=a("a"),NAr=o("from_pretrained()"),jAr=o(" class method or the "),tJ=a("a"),DAr=o("from_config()"),GAr=o(` class
method.`),OAr=l(),ox=a("p"),VAr=o("This class cannot be instantiated directly using "),F6e=a("code"),XAr=o("__init__()"),zAr=o(" (throws an error)."),QAr=l(),Gt=a("div"),F(rx.$$.fragment),WAr=l(),T6e=a("p"),HAr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),UAr=l(),Bc=a("p"),JAr=o(`Note:
Loading a model from its configuration file does `),M6e=a("strong"),YAr=o("not"),KAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aJ=a("a"),ZAr=o("from_pretrained()"),e0r=o(" to load the model weights."),o0r=l(),F($E.$$.fragment),r0r=l(),Gr=a("div"),F(tx.$$.fragment),t0r=l(),E6e=a("p"),a0r=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),n0r=l(),un=a("p"),s0r=o("The model class to instantiate is selected based on the "),C6e=a("code"),l0r=o("model_type"),i0r=o(` property of the config object (either
passed as an argument or loaded from `),w6e=a("code"),d0r=o("pretrained_model_name_or_path"),c0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A6e=a("code"),f0r=o("pretrained_model_name_or_path"),m0r=o(":"),g0r=l(),Me=a("ul"),kE=a("li"),y6e=a("strong"),h0r=o("albert"),p0r=o(" \u2014 "),nJ=a("a"),u0r=o("FlaxAlbertForPreTraining"),_0r=o(" (ALBERT model)"),b0r=l(),SE=a("li"),L6e=a("strong"),v0r=o("bart"),F0r=o(" \u2014 "),sJ=a("a"),T0r=o("FlaxBartForConditionalGeneration"),M0r=o(" (BART model)"),E0r=l(),RE=a("li"),x6e=a("strong"),C0r=o("bert"),w0r=o(" \u2014 "),lJ=a("a"),A0r=o("FlaxBertForPreTraining"),y0r=o(" (BERT model)"),L0r=l(),BE=a("li"),$6e=a("strong"),x0r=o("big_bird"),$0r=o(" \u2014 "),iJ=a("a"),k0r=o("FlaxBigBirdForPreTraining"),S0r=o(" (BigBird model)"),R0r=l(),PE=a("li"),k6e=a("strong"),B0r=o("electra"),P0r=o(" \u2014 "),dJ=a("a"),I0r=o("FlaxElectraForPreTraining"),q0r=o(" (ELECTRA model)"),N0r=l(),IE=a("li"),S6e=a("strong"),j0r=o("mbart"),D0r=o(" \u2014 "),cJ=a("a"),G0r=o("FlaxMBartForConditionalGeneration"),O0r=o(" (mBART model)"),V0r=l(),qE=a("li"),R6e=a("strong"),X0r=o("mt5"),z0r=o(" \u2014 "),fJ=a("a"),Q0r=o("FlaxMT5ForConditionalGeneration"),W0r=o(" (mT5 model)"),H0r=l(),NE=a("li"),B6e=a("strong"),U0r=o("roberta"),J0r=o(" \u2014 "),mJ=a("a"),Y0r=o("FlaxRobertaForMaskedLM"),K0r=o(" (RoBERTa model)"),Z0r=l(),jE=a("li"),P6e=a("strong"),eyr=o("roformer"),oyr=o(" \u2014 "),gJ=a("a"),ryr=o("FlaxRoFormerForMaskedLM"),tyr=o(" (RoFormer model)"),ayr=l(),DE=a("li"),I6e=a("strong"),nyr=o("t5"),syr=o(" \u2014 "),hJ=a("a"),lyr=o("FlaxT5ForConditionalGeneration"),iyr=o(" (T5 model)"),dyr=l(),GE=a("li"),q6e=a("strong"),cyr=o("wav2vec2"),fyr=o(" \u2014 "),pJ=a("a"),myr=o("FlaxWav2Vec2ForPreTraining"),gyr=o(" (Wav2Vec2 model)"),hyr=l(),OE=a("li"),N6e=a("strong"),pyr=o("xlm-roberta"),uyr=o(" \u2014 "),uJ=a("a"),_yr=o("FlaxXLMRobertaForMaskedLM"),byr=o(" (XLM-RoBERTa model)"),vyr=l(),F(VE.$$.fragment),eqe=l(),Pc=a("h2"),XE=a("a"),j6e=a("span"),F(ax.$$.fragment),Fyr=l(),D6e=a("span"),Tyr=o("FlaxAutoModelForMaskedLM"),oqe=l(),hr=a("div"),F(nx.$$.fragment),Myr=l(),Ic=a("p"),Eyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),_J=a("a"),Cyr=o("from_pretrained()"),wyr=o(" class method or the "),bJ=a("a"),Ayr=o("from_config()"),yyr=o(` class
method.`),Lyr=l(),sx=a("p"),xyr=o("This class cannot be instantiated directly using "),G6e=a("code"),$yr=o("__init__()"),kyr=o(" (throws an error)."),Syr=l(),Ot=a("div"),F(lx.$$.fragment),Ryr=l(),O6e=a("p"),Byr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Pyr=l(),qc=a("p"),Iyr=o(`Note:
Loading a model from its configuration file does `),V6e=a("strong"),qyr=o("not"),Nyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),jyr=o("from_pretrained()"),Dyr=o(" to load the model weights."),Gyr=l(),F(zE.$$.fragment),Oyr=l(),Or=a("div"),F(ix.$$.fragment),Vyr=l(),X6e=a("p"),Xyr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),zyr=l(),_n=a("p"),Qyr=o("The model class to instantiate is selected based on the "),z6e=a("code"),Wyr=o("model_type"),Hyr=o(` property of the config object (either
passed as an argument or loaded from `),Q6e=a("code"),Uyr=o("pretrained_model_name_or_path"),Jyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W6e=a("code"),Yyr=o("pretrained_model_name_or_path"),Kyr=o(":"),Zyr=l(),Le=a("ul"),QE=a("li"),H6e=a("strong"),eLr=o("albert"),oLr=o(" \u2014 "),FJ=a("a"),rLr=o("FlaxAlbertForMaskedLM"),tLr=o(" (ALBERT model)"),aLr=l(),WE=a("li"),U6e=a("strong"),nLr=o("bart"),sLr=o(" \u2014 "),TJ=a("a"),lLr=o("FlaxBartForConditionalGeneration"),iLr=o(" (BART model)"),dLr=l(),HE=a("li"),J6e=a("strong"),cLr=o("bert"),fLr=o(" \u2014 "),MJ=a("a"),mLr=o("FlaxBertForMaskedLM"),gLr=o(" (BERT model)"),hLr=l(),UE=a("li"),Y6e=a("strong"),pLr=o("big_bird"),uLr=o(" \u2014 "),EJ=a("a"),_Lr=o("FlaxBigBirdForMaskedLM"),bLr=o(" (BigBird model)"),vLr=l(),JE=a("li"),K6e=a("strong"),FLr=o("distilbert"),TLr=o(" \u2014 "),CJ=a("a"),MLr=o("FlaxDistilBertForMaskedLM"),ELr=o(" (DistilBERT model)"),CLr=l(),YE=a("li"),Z6e=a("strong"),wLr=o("electra"),ALr=o(" \u2014 "),wJ=a("a"),yLr=o("FlaxElectraForMaskedLM"),LLr=o(" (ELECTRA model)"),xLr=l(),KE=a("li"),eTe=a("strong"),$Lr=o("mbart"),kLr=o(" \u2014 "),AJ=a("a"),SLr=o("FlaxMBartForConditionalGeneration"),RLr=o(" (mBART model)"),BLr=l(),ZE=a("li"),oTe=a("strong"),PLr=o("roberta"),ILr=o(" \u2014 "),yJ=a("a"),qLr=o("FlaxRobertaForMaskedLM"),NLr=o(" (RoBERTa model)"),jLr=l(),e5=a("li"),rTe=a("strong"),DLr=o("roformer"),GLr=o(" \u2014 "),LJ=a("a"),OLr=o("FlaxRoFormerForMaskedLM"),VLr=o(" (RoFormer model)"),XLr=l(),o5=a("li"),tTe=a("strong"),zLr=o("xlm-roberta"),QLr=o(" \u2014 "),xJ=a("a"),WLr=o("FlaxXLMRobertaForMaskedLM"),HLr=o(" (XLM-RoBERTa model)"),ULr=l(),F(r5.$$.fragment),rqe=l(),Nc=a("h2"),t5=a("a"),aTe=a("span"),F(dx.$$.fragment),JLr=l(),nTe=a("span"),YLr=o("FlaxAutoModelForSeq2SeqLM"),tqe=l(),pr=a("div"),F(cx.$$.fragment),KLr=l(),jc=a("p"),ZLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$J=a("a"),exr=o("from_pretrained()"),oxr=o(" class method or the "),kJ=a("a"),rxr=o("from_config()"),txr=o(` class
method.`),axr=l(),fx=a("p"),nxr=o("This class cannot be instantiated directly using "),sTe=a("code"),sxr=o("__init__()"),lxr=o(" (throws an error)."),ixr=l(),Vt=a("div"),F(mx.$$.fragment),dxr=l(),lTe=a("p"),cxr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),fxr=l(),Dc=a("p"),mxr=o(`Note:
Loading a model from its configuration file does `),iTe=a("strong"),gxr=o("not"),hxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=a("a"),pxr=o("from_pretrained()"),uxr=o(" to load the model weights."),_xr=l(),F(a5.$$.fragment),bxr=l(),Vr=a("div"),F(gx.$$.fragment),vxr=l(),dTe=a("p"),Fxr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Txr=l(),bn=a("p"),Mxr=o("The model class to instantiate is selected based on the "),cTe=a("code"),Exr=o("model_type"),Cxr=o(` property of the config object (either
passed as an argument or loaded from `),fTe=a("code"),wxr=o("pretrained_model_name_or_path"),Axr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mTe=a("code"),yxr=o("pretrained_model_name_or_path"),Lxr=o(":"),xxr=l(),Se=a("ul"),n5=a("li"),gTe=a("strong"),$xr=o("bart"),kxr=o(" \u2014 "),RJ=a("a"),Sxr=o("FlaxBartForConditionalGeneration"),Rxr=o(" (BART model)"),Bxr=l(),s5=a("li"),hTe=a("strong"),Pxr=o("blenderbot"),Ixr=o(" \u2014 "),BJ=a("a"),qxr=o("FlaxBlenderbotForConditionalGeneration"),Nxr=o(" (Blenderbot model)"),jxr=l(),l5=a("li"),pTe=a("strong"),Dxr=o("blenderbot-small"),Gxr=o(" \u2014 "),PJ=a("a"),Oxr=o("FlaxBlenderbotSmallForConditionalGeneration"),Vxr=o(" (BlenderbotSmall model)"),Xxr=l(),i5=a("li"),uTe=a("strong"),zxr=o("encoder-decoder"),Qxr=o(" \u2014 "),IJ=a("a"),Wxr=o("FlaxEncoderDecoderModel"),Hxr=o(" (Encoder decoder model)"),Uxr=l(),d5=a("li"),_Te=a("strong"),Jxr=o("marian"),Yxr=o(" \u2014 "),qJ=a("a"),Kxr=o("FlaxMarianMTModel"),Zxr=o(" (Marian model)"),e7r=l(),c5=a("li"),bTe=a("strong"),o7r=o("mbart"),r7r=o(" \u2014 "),NJ=a("a"),t7r=o("FlaxMBartForConditionalGeneration"),a7r=o(" (mBART model)"),n7r=l(),f5=a("li"),vTe=a("strong"),s7r=o("mt5"),l7r=o(" \u2014 "),jJ=a("a"),i7r=o("FlaxMT5ForConditionalGeneration"),d7r=o(" (mT5 model)"),c7r=l(),m5=a("li"),FTe=a("strong"),f7r=o("pegasus"),m7r=o(" \u2014 "),DJ=a("a"),g7r=o("FlaxPegasusForConditionalGeneration"),h7r=o(" (Pegasus model)"),p7r=l(),g5=a("li"),TTe=a("strong"),u7r=o("t5"),_7r=o(" \u2014 "),GJ=a("a"),b7r=o("FlaxT5ForConditionalGeneration"),v7r=o(" (T5 model)"),F7r=l(),F(h5.$$.fragment),aqe=l(),Gc=a("h2"),p5=a("a"),MTe=a("span"),F(hx.$$.fragment),T7r=l(),ETe=a("span"),M7r=o("FlaxAutoModelForSequenceClassification"),nqe=l(),ur=a("div"),F(px.$$.fragment),E7r=l(),Oc=a("p"),C7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),OJ=a("a"),w7r=o("from_pretrained()"),A7r=o(" class method or the "),VJ=a("a"),y7r=o("from_config()"),L7r=o(` class
method.`),x7r=l(),ux=a("p"),$7r=o("This class cannot be instantiated directly using "),CTe=a("code"),k7r=o("__init__()"),S7r=o(" (throws an error)."),R7r=l(),Xt=a("div"),F(_x.$$.fragment),B7r=l(),wTe=a("p"),P7r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),I7r=l(),Vc=a("p"),q7r=o(`Note:
Loading a model from its configuration file does `),ATe=a("strong"),N7r=o("not"),j7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XJ=a("a"),D7r=o("from_pretrained()"),G7r=o(" to load the model weights."),O7r=l(),F(u5.$$.fragment),V7r=l(),Xr=a("div"),F(bx.$$.fragment),X7r=l(),yTe=a("p"),z7r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Q7r=l(),vn=a("p"),W7r=o("The model class to instantiate is selected based on the "),LTe=a("code"),H7r=o("model_type"),U7r=o(` property of the config object (either
passed as an argument or loaded from `),xTe=a("code"),J7r=o("pretrained_model_name_or_path"),Y7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Te=a("code"),K7r=o("pretrained_model_name_or_path"),Z7r=o(":"),e$r=l(),xe=a("ul"),_5=a("li"),kTe=a("strong"),o$r=o("albert"),r$r=o(" \u2014 "),zJ=a("a"),t$r=o("FlaxAlbertForSequenceClassification"),a$r=o(" (ALBERT model)"),n$r=l(),b5=a("li"),STe=a("strong"),s$r=o("bart"),l$r=o(" \u2014 "),QJ=a("a"),i$r=o("FlaxBartForSequenceClassification"),d$r=o(" (BART model)"),c$r=l(),v5=a("li"),RTe=a("strong"),f$r=o("bert"),m$r=o(" \u2014 "),WJ=a("a"),g$r=o("FlaxBertForSequenceClassification"),h$r=o(" (BERT model)"),p$r=l(),F5=a("li"),BTe=a("strong"),u$r=o("big_bird"),_$r=o(" \u2014 "),HJ=a("a"),b$r=o("FlaxBigBirdForSequenceClassification"),v$r=o(" (BigBird model)"),F$r=l(),T5=a("li"),PTe=a("strong"),T$r=o("distilbert"),M$r=o(" \u2014 "),UJ=a("a"),E$r=o("FlaxDistilBertForSequenceClassification"),C$r=o(" (DistilBERT model)"),w$r=l(),M5=a("li"),ITe=a("strong"),A$r=o("electra"),y$r=o(" \u2014 "),JJ=a("a"),L$r=o("FlaxElectraForSequenceClassification"),x$r=o(" (ELECTRA model)"),$$r=l(),E5=a("li"),qTe=a("strong"),k$r=o("mbart"),S$r=o(" \u2014 "),YJ=a("a"),R$r=o("FlaxMBartForSequenceClassification"),B$r=o(" (mBART model)"),P$r=l(),C5=a("li"),NTe=a("strong"),I$r=o("roberta"),q$r=o(" \u2014 "),KJ=a("a"),N$r=o("FlaxRobertaForSequenceClassification"),j$r=o(" (RoBERTa model)"),D$r=l(),w5=a("li"),jTe=a("strong"),G$r=o("roformer"),O$r=o(" \u2014 "),ZJ=a("a"),V$r=o("FlaxRoFormerForSequenceClassification"),X$r=o(" (RoFormer model)"),z$r=l(),A5=a("li"),DTe=a("strong"),Q$r=o("xlm-roberta"),W$r=o(" \u2014 "),eY=a("a"),H$r=o("FlaxXLMRobertaForSequenceClassification"),U$r=o(" (XLM-RoBERTa model)"),J$r=l(),F(y5.$$.fragment),sqe=l(),Xc=a("h2"),L5=a("a"),GTe=a("span"),F(vx.$$.fragment),Y$r=l(),OTe=a("span"),K$r=o("FlaxAutoModelForQuestionAnswering"),lqe=l(),_r=a("div"),F(Fx.$$.fragment),Z$r=l(),zc=a("p"),ekr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),oY=a("a"),okr=o("from_pretrained()"),rkr=o(" class method or the "),rY=a("a"),tkr=o("from_config()"),akr=o(` class
method.`),nkr=l(),Tx=a("p"),skr=o("This class cannot be instantiated directly using "),VTe=a("code"),lkr=o("__init__()"),ikr=o(" (throws an error)."),dkr=l(),zt=a("div"),F(Mx.$$.fragment),ckr=l(),XTe=a("p"),fkr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),mkr=l(),Qc=a("p"),gkr=o(`Note:
Loading a model from its configuration file does `),zTe=a("strong"),hkr=o("not"),pkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=a("a"),ukr=o("from_pretrained()"),_kr=o(" to load the model weights."),bkr=l(),F(x5.$$.fragment),vkr=l(),zr=a("div"),F(Ex.$$.fragment),Fkr=l(),QTe=a("p"),Tkr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Mkr=l(),Fn=a("p"),Ekr=o("The model class to instantiate is selected based on the "),WTe=a("code"),Ckr=o("model_type"),wkr=o(` property of the config object (either
passed as an argument or loaded from `),HTe=a("code"),Akr=o("pretrained_model_name_or_path"),ykr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UTe=a("code"),Lkr=o("pretrained_model_name_or_path"),xkr=o(":"),$kr=l(),$e=a("ul"),$5=a("li"),JTe=a("strong"),kkr=o("albert"),Skr=o(" \u2014 "),aY=a("a"),Rkr=o("FlaxAlbertForQuestionAnswering"),Bkr=o(" (ALBERT model)"),Pkr=l(),k5=a("li"),YTe=a("strong"),Ikr=o("bart"),qkr=o(" \u2014 "),nY=a("a"),Nkr=o("FlaxBartForQuestionAnswering"),jkr=o(" (BART model)"),Dkr=l(),S5=a("li"),KTe=a("strong"),Gkr=o("bert"),Okr=o(" \u2014 "),sY=a("a"),Vkr=o("FlaxBertForQuestionAnswering"),Xkr=o(" (BERT model)"),zkr=l(),R5=a("li"),ZTe=a("strong"),Qkr=o("big_bird"),Wkr=o(" \u2014 "),lY=a("a"),Hkr=o("FlaxBigBirdForQuestionAnswering"),Ukr=o(" (BigBird model)"),Jkr=l(),B5=a("li"),e9e=a("strong"),Ykr=o("distilbert"),Kkr=o(" \u2014 "),iY=a("a"),Zkr=o("FlaxDistilBertForQuestionAnswering"),eSr=o(" (DistilBERT model)"),oSr=l(),P5=a("li"),o9e=a("strong"),rSr=o("electra"),tSr=o(" \u2014 "),dY=a("a"),aSr=o("FlaxElectraForQuestionAnswering"),nSr=o(" (ELECTRA model)"),sSr=l(),I5=a("li"),r9e=a("strong"),lSr=o("mbart"),iSr=o(" \u2014 "),cY=a("a"),dSr=o("FlaxMBartForQuestionAnswering"),cSr=o(" (mBART model)"),fSr=l(),q5=a("li"),t9e=a("strong"),mSr=o("roberta"),gSr=o(" \u2014 "),fY=a("a"),hSr=o("FlaxRobertaForQuestionAnswering"),pSr=o(" (RoBERTa model)"),uSr=l(),N5=a("li"),a9e=a("strong"),_Sr=o("roformer"),bSr=o(" \u2014 "),mY=a("a"),vSr=o("FlaxRoFormerForQuestionAnswering"),FSr=o(" (RoFormer model)"),TSr=l(),j5=a("li"),n9e=a("strong"),MSr=o("xlm-roberta"),ESr=o(" \u2014 "),gY=a("a"),CSr=o("FlaxXLMRobertaForQuestionAnswering"),wSr=o(" (XLM-RoBERTa model)"),ASr=l(),F(D5.$$.fragment),iqe=l(),Wc=a("h2"),G5=a("a"),s9e=a("span"),F(Cx.$$.fragment),ySr=l(),l9e=a("span"),LSr=o("FlaxAutoModelForTokenClassification"),dqe=l(),br=a("div"),F(wx.$$.fragment),xSr=l(),Hc=a("p"),$Sr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),hY=a("a"),kSr=o("from_pretrained()"),SSr=o(" class method or the "),pY=a("a"),RSr=o("from_config()"),BSr=o(` class
method.`),PSr=l(),Ax=a("p"),ISr=o("This class cannot be instantiated directly using "),i9e=a("code"),qSr=o("__init__()"),NSr=o(" (throws an error)."),jSr=l(),Qt=a("div"),F(yx.$$.fragment),DSr=l(),d9e=a("p"),GSr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),OSr=l(),Uc=a("p"),VSr=o(`Note:
Loading a model from its configuration file does `),c9e=a("strong"),XSr=o("not"),zSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uY=a("a"),QSr=o("from_pretrained()"),WSr=o(" to load the model weights."),HSr=l(),F(O5.$$.fragment),USr=l(),Qr=a("div"),F(Lx.$$.fragment),JSr=l(),f9e=a("p"),YSr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),KSr=l(),Tn=a("p"),ZSr=o("The model class to instantiate is selected based on the "),m9e=a("code"),eRr=o("model_type"),oRr=o(` property of the config object (either
passed as an argument or loaded from `),g9e=a("code"),rRr=o("pretrained_model_name_or_path"),tRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h9e=a("code"),aRr=o("pretrained_model_name_or_path"),nRr=o(":"),sRr=l(),De=a("ul"),V5=a("li"),p9e=a("strong"),lRr=o("albert"),iRr=o(" \u2014 "),_Y=a("a"),dRr=o("FlaxAlbertForTokenClassification"),cRr=o(" (ALBERT model)"),fRr=l(),X5=a("li"),u9e=a("strong"),mRr=o("bert"),gRr=o(" \u2014 "),bY=a("a"),hRr=o("FlaxBertForTokenClassification"),pRr=o(" (BERT model)"),uRr=l(),z5=a("li"),_9e=a("strong"),_Rr=o("big_bird"),bRr=o(" \u2014 "),vY=a("a"),vRr=o("FlaxBigBirdForTokenClassification"),FRr=o(" (BigBird model)"),TRr=l(),Q5=a("li"),b9e=a("strong"),MRr=o("distilbert"),ERr=o(" \u2014 "),FY=a("a"),CRr=o("FlaxDistilBertForTokenClassification"),wRr=o(" (DistilBERT model)"),ARr=l(),W5=a("li"),v9e=a("strong"),yRr=o("electra"),LRr=o(" \u2014 "),TY=a("a"),xRr=o("FlaxElectraForTokenClassification"),$Rr=o(" (ELECTRA model)"),kRr=l(),H5=a("li"),F9e=a("strong"),SRr=o("roberta"),RRr=o(" \u2014 "),MY=a("a"),BRr=o("FlaxRobertaForTokenClassification"),PRr=o(" (RoBERTa model)"),IRr=l(),U5=a("li"),T9e=a("strong"),qRr=o("roformer"),NRr=o(" \u2014 "),EY=a("a"),jRr=o("FlaxRoFormerForTokenClassification"),DRr=o(" (RoFormer model)"),GRr=l(),J5=a("li"),M9e=a("strong"),ORr=o("xlm-roberta"),VRr=o(" \u2014 "),CY=a("a"),XRr=o("FlaxXLMRobertaForTokenClassification"),zRr=o(" (XLM-RoBERTa model)"),QRr=l(),F(Y5.$$.fragment),cqe=l(),Jc=a("h2"),K5=a("a"),E9e=a("span"),F(xx.$$.fragment),WRr=l(),C9e=a("span"),HRr=o("FlaxAutoModelForMultipleChoice"),fqe=l(),vr=a("div"),F($x.$$.fragment),URr=l(),Yc=a("p"),JRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),wY=a("a"),YRr=o("from_pretrained()"),KRr=o(" class method or the "),AY=a("a"),ZRr=o("from_config()"),eBr=o(` class
method.`),oBr=l(),kx=a("p"),rBr=o("This class cannot be instantiated directly using "),w9e=a("code"),tBr=o("__init__()"),aBr=o(" (throws an error)."),nBr=l(),Wt=a("div"),F(Sx.$$.fragment),sBr=l(),A9e=a("p"),lBr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),iBr=l(),Kc=a("p"),dBr=o(`Note:
Loading a model from its configuration file does `),y9e=a("strong"),cBr=o("not"),fBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=a("a"),mBr=o("from_pretrained()"),gBr=o(" to load the model weights."),hBr=l(),F(Z5.$$.fragment),pBr=l(),Wr=a("div"),F(Rx.$$.fragment),uBr=l(),L9e=a("p"),_Br=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),bBr=l(),Mn=a("p"),vBr=o("The model class to instantiate is selected based on the "),x9e=a("code"),FBr=o("model_type"),TBr=o(` property of the config object (either
passed as an argument or loaded from `),$9e=a("code"),MBr=o("pretrained_model_name_or_path"),EBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k9e=a("code"),CBr=o("pretrained_model_name_or_path"),wBr=o(":"),ABr=l(),Ge=a("ul"),eC=a("li"),S9e=a("strong"),yBr=o("albert"),LBr=o(" \u2014 "),LY=a("a"),xBr=o("FlaxAlbertForMultipleChoice"),$Br=o(" (ALBERT model)"),kBr=l(),oC=a("li"),R9e=a("strong"),SBr=o("bert"),RBr=o(" \u2014 "),xY=a("a"),BBr=o("FlaxBertForMultipleChoice"),PBr=o(" (BERT model)"),IBr=l(),rC=a("li"),B9e=a("strong"),qBr=o("big_bird"),NBr=o(" \u2014 "),$Y=a("a"),jBr=o("FlaxBigBirdForMultipleChoice"),DBr=o(" (BigBird model)"),GBr=l(),tC=a("li"),P9e=a("strong"),OBr=o("distilbert"),VBr=o(" \u2014 "),kY=a("a"),XBr=o("FlaxDistilBertForMultipleChoice"),zBr=o(" (DistilBERT model)"),QBr=l(),aC=a("li"),I9e=a("strong"),WBr=o("electra"),HBr=o(" \u2014 "),SY=a("a"),UBr=o("FlaxElectraForMultipleChoice"),JBr=o(" (ELECTRA model)"),YBr=l(),nC=a("li"),q9e=a("strong"),KBr=o("roberta"),ZBr=o(" \u2014 "),RY=a("a"),ePr=o("FlaxRobertaForMultipleChoice"),oPr=o(" (RoBERTa model)"),rPr=l(),sC=a("li"),N9e=a("strong"),tPr=o("roformer"),aPr=o(" \u2014 "),BY=a("a"),nPr=o("FlaxRoFormerForMultipleChoice"),sPr=o(" (RoFormer model)"),lPr=l(),lC=a("li"),j9e=a("strong"),iPr=o("xlm-roberta"),dPr=o(" \u2014 "),PY=a("a"),cPr=o("FlaxXLMRobertaForMultipleChoice"),fPr=o(" (XLM-RoBERTa model)"),mPr=l(),F(iC.$$.fragment),mqe=l(),Zc=a("h2"),dC=a("a"),D9e=a("span"),F(Bx.$$.fragment),gPr=l(),G9e=a("span"),hPr=o("FlaxAutoModelForNextSentencePrediction"),gqe=l(),Fr=a("div"),F(Px.$$.fragment),pPr=l(),ef=a("p"),uPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),IY=a("a"),_Pr=o("from_pretrained()"),bPr=o(" class method or the "),qY=a("a"),vPr=o("from_config()"),FPr=o(` class
method.`),TPr=l(),Ix=a("p"),MPr=o("This class cannot be instantiated directly using "),O9e=a("code"),EPr=o("__init__()"),CPr=o(" (throws an error)."),wPr=l(),Ht=a("div"),F(qx.$$.fragment),APr=l(),V9e=a("p"),yPr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),LPr=l(),of=a("p"),xPr=o(`Note:
Loading a model from its configuration file does `),X9e=a("strong"),$Pr=o("not"),kPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NY=a("a"),SPr=o("from_pretrained()"),RPr=o(" to load the model weights."),BPr=l(),F(cC.$$.fragment),PPr=l(),Hr=a("div"),F(Nx.$$.fragment),IPr=l(),z9e=a("p"),qPr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),NPr=l(),En=a("p"),jPr=o("The model class to instantiate is selected based on the "),Q9e=a("code"),DPr=o("model_type"),GPr=o(` property of the config object (either
passed as an argument or loaded from `),W9e=a("code"),OPr=o("pretrained_model_name_or_path"),VPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H9e=a("code"),XPr=o("pretrained_model_name_or_path"),zPr=o(":"),QPr=l(),U9e=a("ul"),fC=a("li"),J9e=a("strong"),WPr=o("bert"),HPr=o(" \u2014 "),jY=a("a"),UPr=o("FlaxBertForNextSentencePrediction"),JPr=o(" (BERT model)"),YPr=l(),F(mC.$$.fragment),hqe=l(),rf=a("h2"),gC=a("a"),Y9e=a("span"),F(jx.$$.fragment),KPr=l(),K9e=a("span"),ZPr=o("FlaxAutoModelForImageClassification"),pqe=l(),Tr=a("div"),F(Dx.$$.fragment),eIr=l(),tf=a("p"),oIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),DY=a("a"),rIr=o("from_pretrained()"),tIr=o(" class method or the "),GY=a("a"),aIr=o("from_config()"),nIr=o(` class
method.`),sIr=l(),Gx=a("p"),lIr=o("This class cannot be instantiated directly using "),Z9e=a("code"),iIr=o("__init__()"),dIr=o(" (throws an error)."),cIr=l(),Ut=a("div"),F(Ox.$$.fragment),fIr=l(),eMe=a("p"),mIr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),gIr=l(),af=a("p"),hIr=o(`Note:
Loading a model from its configuration file does `),oMe=a("strong"),pIr=o("not"),uIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OY=a("a"),_Ir=o("from_pretrained()"),bIr=o(" to load the model weights."),vIr=l(),F(hC.$$.fragment),FIr=l(),Ur=a("div"),F(Vx.$$.fragment),TIr=l(),rMe=a("p"),MIr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),EIr=l(),Cn=a("p"),CIr=o("The model class to instantiate is selected based on the "),tMe=a("code"),wIr=o("model_type"),AIr=o(` property of the config object (either
passed as an argument or loaded from `),aMe=a("code"),yIr=o("pretrained_model_name_or_path"),LIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=a("code"),xIr=o("pretrained_model_name_or_path"),$Ir=o(":"),kIr=l(),Xx=a("ul"),pC=a("li"),sMe=a("strong"),SIr=o("beit"),RIr=o(" \u2014 "),VY=a("a"),BIr=o("FlaxBeitForImageClassification"),PIr=o(" (BEiT model)"),IIr=l(),uC=a("li"),lMe=a("strong"),qIr=o("vit"),NIr=o(" \u2014 "),XY=a("a"),jIr=o("FlaxViTForImageClassification"),DIr=o(" (ViT model)"),GIr=l(),F(_C.$$.fragment),uqe=l(),nf=a("h2"),bC=a("a"),iMe=a("span"),F(zx.$$.fragment),OIr=l(),dMe=a("span"),VIr=o("FlaxAutoModelForVision2Seq"),_qe=l(),Mr=a("div"),F(Qx.$$.fragment),XIr=l(),sf=a("p"),zIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),zY=a("a"),QIr=o("from_pretrained()"),WIr=o(" class method or the "),QY=a("a"),HIr=o("from_config()"),UIr=o(` class
method.`),JIr=l(),Wx=a("p"),YIr=o("This class cannot be instantiated directly using "),cMe=a("code"),KIr=o("__init__()"),ZIr=o(" (throws an error)."),eqr=l(),Jt=a("div"),F(Hx.$$.fragment),oqr=l(),fMe=a("p"),rqr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),tqr=l(),lf=a("p"),aqr=o(`Note:
Loading a model from its configuration file does `),mMe=a("strong"),nqr=o("not"),sqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WY=a("a"),lqr=o("from_pretrained()"),iqr=o(" to load the model weights."),dqr=l(),F(vC.$$.fragment),cqr=l(),Jr=a("div"),F(Ux.$$.fragment),fqr=l(),gMe=a("p"),mqr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gqr=l(),wn=a("p"),hqr=o("The model class to instantiate is selected based on the "),hMe=a("code"),pqr=o("model_type"),uqr=o(` property of the config object (either
passed as an argument or loaded from `),pMe=a("code"),_qr=o("pretrained_model_name_or_path"),bqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uMe=a("code"),vqr=o("pretrained_model_name_or_path"),Fqr=o(":"),Tqr=l(),_Me=a("ul"),FC=a("li"),bMe=a("strong"),Mqr=o("vision-encoder-decoder"),Eqr=o(" \u2014 "),HY=a("a"),Cqr=o("FlaxVisionEncoderDecoderModel"),wqr=o(" (Vision Encoder decoder model)"),Aqr=l(),F(TC.$$.fragment),this.h()},l(f){const _=G3t('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var Jx=s(p);m=n(Jx,"A",{id:!0,class:!0,href:!0});var vMe=s(m);u=n(vMe,"SPAN",{});var FMe=s(u);T(d.$$.fragment,FMe),FMe.forEach(t),vMe.forEach(t),h=i(Jx),Mo=n(Jx,"SPAN",{});var TMe=s(Mo);ii=r(TMe,"Auto Classes"),TMe.forEach(t),Jx.forEach(t),mf=i(f),et=n(f,"P",{});var Yx=s(et);di=r(Yx,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ci=n(Yx,"CODE",{});var MMe=s(ci);Gw=r(MMe,"from_pretrained()"),MMe.forEach(t),gf=r(Yx,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Yx.forEach(t),qe=i(f),Xe=n(f,"P",{});var An=s(Xe);fi=r(An,"Instantiating one of "),yn=n(An,"A",{href:!0});var EMe=s(yn);Ow=r(EMe,"AutoConfig"),EMe.forEach(t),Ln=r(An,", "),xn=n(An,"A",{href:!0});var CMe=s(xn);Vw=r(CMe,"AutoModel"),CMe.forEach(t),mi=r(An,`, and
`),$n=n(An,"A",{href:!0});var wMe=s($n);Xw=r(wMe,"AutoTokenizer"),wMe.forEach(t),gi=r(An," will directly create a class of the relevant architecture. For instance"),An.forEach(t),hf=i(f),T(Ma.$$.fragment,f),ze=i(f),Ae=n(f,"P",{});var Kx=s(Ae);i$=r(Kx,"will create a model that is an instance of "),hi=n(Kx,"A",{href:!0});var AMe=s(hi);d$=r(AMe,"BertModel"),AMe.forEach(t),c$=r(Kx,"."),Kx.forEach(t),Eo=i(f),Ea=n(f,"P",{});var Zx=s(Ea);f$=r(Zx,"There is one class of "),pf=n(Zx,"CODE",{});var yMe=s(pf);m$=r(yMe,"AutoModel"),yMe.forEach(t),Aje=r(Zx," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Zx.forEach(t),pPe=i(f),pi=n(f,"H2",{class:!0});var e7=s(pi);uf=n(e7,"A",{id:!0,class:!0,href:!0});var LMe=s(uf);GZ=n(LMe,"SPAN",{});var xMe=s(GZ);T(zw.$$.fragment,xMe),xMe.forEach(t),LMe.forEach(t),yje=i(e7),OZ=n(e7,"SPAN",{});var $Me=s(OZ);Lje=r($Me,"Extending the Auto Classes"),$Me.forEach(t),e7.forEach(t),uPe=i(f),kn=n(f,"P",{});var df=s(kn);xje=r(df,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),VZ=n(df,"CODE",{});var kMe=s(VZ);$je=r(kMe,"NewModel"),kMe.forEach(t),kje=r(df,", make sure you have a "),XZ=n(df,"CODE",{});var SMe=s(XZ);Sje=r(SMe,"NewModelConfig"),SMe.forEach(t),Rje=r(df,` then you can add those to the auto
classes like this:`),df.forEach(t),_Pe=i(f),T(Qw.$$.fragment,f),bPe=i(f),g$=n(f,"P",{});var RMe=s(g$);Bje=r(RMe,"You will then be able to use the auto classes like you would usually do!"),RMe.forEach(t),vPe=i(f),T(_f.$$.fragment,f),FPe=i(f),ui=n(f,"H2",{class:!0});var o7=s(ui);bf=n(o7,"A",{id:!0,class:!0,href:!0});var BMe=s(bf);zZ=n(BMe,"SPAN",{});var PMe=s(zZ);T(Ww.$$.fragment,PMe),PMe.forEach(t),BMe.forEach(t),Pje=i(o7),QZ=n(o7,"SPAN",{});var IMe=s(QZ);Ije=r(IMe,"AutoConfig"),IMe.forEach(t),o7.forEach(t),TPe=i(f),Co=n(f,"DIV",{class:!0});var Kr=s(Co);T(Hw.$$.fragment,Kr),qje=i(Kr),Uw=n(Kr,"P",{});var r7=s(Uw);Nje=r(r7,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),h$=n(r7,"A",{href:!0});var qMe=s(h$);jje=r(qMe,"from_pretrained()"),qMe.forEach(t),Dje=r(r7," class method."),r7.forEach(t),Gje=i(Kr),Jw=n(Kr,"P",{});var t7=s(Jw);Oje=r(t7,"This class cannot be instantiated directly using "),WZ=n(t7,"CODE",{});var NMe=s(WZ);Vje=r(NMe,"__init__()"),NMe.forEach(t),Xje=r(t7," (throws an error)."),t7.forEach(t),zje=i(Kr),Er=n(Kr,"DIV",{class:!0});var Zr=s(Er);T(Yw.$$.fragment,Zr),Qje=i(Zr),HZ=n(Zr,"P",{});var jMe=s(HZ);Wje=r(jMe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),jMe.forEach(t),Hje=i(Zr),_i=n(Zr,"P",{});var cf=s(_i);Uje=r(cf,"The configuration class to instantiate is selected based on the "),UZ=n(cf,"CODE",{});var DMe=s(UZ);Jje=r(DMe,"model_type"),DMe.forEach(t),Yje=r(cf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),JZ=n(cf,"CODE",{});var GMe=s(JZ);Kje=r(GMe,"pretrained_model_name_or_path"),GMe.forEach(t),Zje=r(cf,":"),cf.forEach(t),eDe=i(Zr),y=n(Zr,"UL",{});var L=s(y);vf=n(L,"LI",{});var MC=s(vf);YZ=n(MC,"STRONG",{});var OMe=s(YZ);oDe=r(OMe,"albert"),OMe.forEach(t),rDe=r(MC," \u2014 "),p$=n(MC,"A",{href:!0});var VMe=s(p$);tDe=r(VMe,"AlbertConfig"),VMe.forEach(t),aDe=r(MC," (ALBERT model)"),MC.forEach(t),nDe=i(L),Ff=n(L,"LI",{});var EC=s(Ff);KZ=n(EC,"STRONG",{});var XMe=s(KZ);sDe=r(XMe,"bart"),XMe.forEach(t),lDe=r(EC," \u2014 "),u$=n(EC,"A",{href:!0});var zMe=s(u$);iDe=r(zMe,"BartConfig"),zMe.forEach(t),dDe=r(EC," (BART model)"),EC.forEach(t),cDe=i(L),Tf=n(L,"LI",{});var CC=s(Tf);ZZ=n(CC,"STRONG",{});var QMe=s(ZZ);fDe=r(QMe,"beit"),QMe.forEach(t),mDe=r(CC," \u2014 "),_$=n(CC,"A",{href:!0});var WMe=s(_$);gDe=r(WMe,"BeitConfig"),WMe.forEach(t),hDe=r(CC," (BEiT model)"),CC.forEach(t),pDe=i(L),Mf=n(L,"LI",{});var wC=s(Mf);eee=n(wC,"STRONG",{});var HMe=s(eee);uDe=r(HMe,"bert"),HMe.forEach(t),_De=r(wC," \u2014 "),b$=n(wC,"A",{href:!0});var UMe=s(b$);bDe=r(UMe,"BertConfig"),UMe.forEach(t),vDe=r(wC," (BERT model)"),wC.forEach(t),FDe=i(L),Ef=n(L,"LI",{});var AC=s(Ef);oee=n(AC,"STRONG",{});var JMe=s(oee);TDe=r(JMe,"bert-generation"),JMe.forEach(t),MDe=r(AC," \u2014 "),v$=n(AC,"A",{href:!0});var YMe=s(v$);EDe=r(YMe,"BertGenerationConfig"),YMe.forEach(t),CDe=r(AC," (Bert Generation model)"),AC.forEach(t),wDe=i(L),Cf=n(L,"LI",{});var yC=s(Cf);ree=n(yC,"STRONG",{});var KMe=s(ree);ADe=r(KMe,"big_bird"),KMe.forEach(t),yDe=r(yC," \u2014 "),F$=n(yC,"A",{href:!0});var ZMe=s(F$);LDe=r(ZMe,"BigBirdConfig"),ZMe.forEach(t),xDe=r(yC," (BigBird model)"),yC.forEach(t),$De=i(L),wf=n(L,"LI",{});var LC=s(wf);tee=n(LC,"STRONG",{});var e4e=s(tee);kDe=r(e4e,"bigbird_pegasus"),e4e.forEach(t),SDe=r(LC," \u2014 "),T$=n(LC,"A",{href:!0});var o4e=s(T$);RDe=r(o4e,"BigBirdPegasusConfig"),o4e.forEach(t),BDe=r(LC," (BigBirdPegasus model)"),LC.forEach(t),PDe=i(L),Af=n(L,"LI",{});var xC=s(Af);aee=n(xC,"STRONG",{});var r4e=s(aee);IDe=r(r4e,"blenderbot"),r4e.forEach(t),qDe=r(xC," \u2014 "),M$=n(xC,"A",{href:!0});var t4e=s(M$);NDe=r(t4e,"BlenderbotConfig"),t4e.forEach(t),jDe=r(xC," (Blenderbot model)"),xC.forEach(t),DDe=i(L),yf=n(L,"LI",{});var $C=s(yf);nee=n($C,"STRONG",{});var a4e=s(nee);GDe=r(a4e,"blenderbot-small"),a4e.forEach(t),ODe=r($C," \u2014 "),E$=n($C,"A",{href:!0});var n4e=s(E$);VDe=r(n4e,"BlenderbotSmallConfig"),n4e.forEach(t),XDe=r($C," (BlenderbotSmall model)"),$C.forEach(t),zDe=i(L),Lf=n(L,"LI",{});var kC=s(Lf);see=n(kC,"STRONG",{});var s4e=s(see);QDe=r(s4e,"camembert"),s4e.forEach(t),WDe=r(kC," \u2014 "),C$=n(kC,"A",{href:!0});var l4e=s(C$);HDe=r(l4e,"CamembertConfig"),l4e.forEach(t),UDe=r(kC," (CamemBERT model)"),kC.forEach(t),JDe=i(L),xf=n(L,"LI",{});var SC=s(xf);lee=n(SC,"STRONG",{});var i4e=s(lee);YDe=r(i4e,"canine"),i4e.forEach(t),KDe=r(SC," \u2014 "),w$=n(SC,"A",{href:!0});var d4e=s(w$);ZDe=r(d4e,"CanineConfig"),d4e.forEach(t),eGe=r(SC," (Canine model)"),SC.forEach(t),oGe=i(L),$f=n(L,"LI",{});var RC=s($f);iee=n(RC,"STRONG",{});var c4e=s(iee);rGe=r(c4e,"clip"),c4e.forEach(t),tGe=r(RC," \u2014 "),A$=n(RC,"A",{href:!0});var f4e=s(A$);aGe=r(f4e,"CLIPConfig"),f4e.forEach(t),nGe=r(RC," (CLIP model)"),RC.forEach(t),sGe=i(L),kf=n(L,"LI",{});var BC=s(kf);dee=n(BC,"STRONG",{});var m4e=s(dee);lGe=r(m4e,"convbert"),m4e.forEach(t),iGe=r(BC," \u2014 "),y$=n(BC,"A",{href:!0});var g4e=s(y$);dGe=r(g4e,"ConvBertConfig"),g4e.forEach(t),cGe=r(BC," (ConvBERT model)"),BC.forEach(t),fGe=i(L),Sf=n(L,"LI",{});var PC=s(Sf);cee=n(PC,"STRONG",{});var h4e=s(cee);mGe=r(h4e,"convnext"),h4e.forEach(t),gGe=r(PC," \u2014 "),L$=n(PC,"A",{href:!0});var p4e=s(L$);hGe=r(p4e,"ConvNextConfig"),p4e.forEach(t),pGe=r(PC," (ConvNext model)"),PC.forEach(t),uGe=i(L),Rf=n(L,"LI",{});var IC=s(Rf);fee=n(IC,"STRONG",{});var u4e=s(fee);_Ge=r(u4e,"ctrl"),u4e.forEach(t),bGe=r(IC," \u2014 "),x$=n(IC,"A",{href:!0});var _4e=s(x$);vGe=r(_4e,"CTRLConfig"),_4e.forEach(t),FGe=r(IC," (CTRL model)"),IC.forEach(t),TGe=i(L),Bf=n(L,"LI",{});var qC=s(Bf);mee=n(qC,"STRONG",{});var b4e=s(mee);MGe=r(b4e,"data2vec-audio"),b4e.forEach(t),EGe=r(qC," \u2014 "),$$=n(qC,"A",{href:!0});var v4e=s($$);CGe=r(v4e,"Data2VecAudioConfig"),v4e.forEach(t),wGe=r(qC," (Data2VecAudio model)"),qC.forEach(t),AGe=i(L),Pf=n(L,"LI",{});var NC=s(Pf);gee=n(NC,"STRONG",{});var F4e=s(gee);yGe=r(F4e,"data2vec-text"),F4e.forEach(t),LGe=r(NC," \u2014 "),k$=n(NC,"A",{href:!0});var T4e=s(k$);xGe=r(T4e,"Data2VecTextConfig"),T4e.forEach(t),$Ge=r(NC," (Data2VecText model)"),NC.forEach(t),kGe=i(L),If=n(L,"LI",{});var jC=s(If);hee=n(jC,"STRONG",{});var M4e=s(hee);SGe=r(M4e,"data2vec-vision"),M4e.forEach(t),RGe=r(jC," \u2014 "),S$=n(jC,"A",{href:!0});var E4e=s(S$);BGe=r(E4e,"Data2VecVisionConfig"),E4e.forEach(t),PGe=r(jC," (Data2VecVision model)"),jC.forEach(t),IGe=i(L),qf=n(L,"LI",{});var DC=s(qf);pee=n(DC,"STRONG",{});var C4e=s(pee);qGe=r(C4e,"deberta"),C4e.forEach(t),NGe=r(DC," \u2014 "),R$=n(DC,"A",{href:!0});var w4e=s(R$);jGe=r(w4e,"DebertaConfig"),w4e.forEach(t),DGe=r(DC," (DeBERTa model)"),DC.forEach(t),GGe=i(L),Nf=n(L,"LI",{});var GC=s(Nf);uee=n(GC,"STRONG",{});var A4e=s(uee);OGe=r(A4e,"deberta-v2"),A4e.forEach(t),VGe=r(GC," \u2014 "),B$=n(GC,"A",{href:!0});var y4e=s(B$);XGe=r(y4e,"DebertaV2Config"),y4e.forEach(t),zGe=r(GC," (DeBERTa-v2 model)"),GC.forEach(t),QGe=i(L),jf=n(L,"LI",{});var OC=s(jf);_ee=n(OC,"STRONG",{});var L4e=s(_ee);WGe=r(L4e,"decision_transformer"),L4e.forEach(t),HGe=r(OC," \u2014 "),P$=n(OC,"A",{href:!0});var x4e=s(P$);UGe=r(x4e,"DecisionTransformerConfig"),x4e.forEach(t),JGe=r(OC," (Decision Transformer model)"),OC.forEach(t),YGe=i(L),Df=n(L,"LI",{});var VC=s(Df);bee=n(VC,"STRONG",{});var $4e=s(bee);KGe=r($4e,"deit"),$4e.forEach(t),ZGe=r(VC," \u2014 "),I$=n(VC,"A",{href:!0});var k4e=s(I$);eOe=r(k4e,"DeiTConfig"),k4e.forEach(t),oOe=r(VC," (DeiT model)"),VC.forEach(t),rOe=i(L),Gf=n(L,"LI",{});var XC=s(Gf);vee=n(XC,"STRONG",{});var S4e=s(vee);tOe=r(S4e,"detr"),S4e.forEach(t),aOe=r(XC," \u2014 "),q$=n(XC,"A",{href:!0});var Lqr=s(q$);nOe=r(Lqr,"DetrConfig"),Lqr.forEach(t),sOe=r(XC," (DETR model)"),XC.forEach(t),lOe=i(L),Of=n(L,"LI",{});var R4e=s(Of);Fee=n(R4e,"STRONG",{});var xqr=s(Fee);iOe=r(xqr,"distilbert"),xqr.forEach(t),dOe=r(R4e," \u2014 "),N$=n(R4e,"A",{href:!0});var $qr=s(N$);cOe=r($qr,"DistilBertConfig"),$qr.forEach(t),fOe=r(R4e," (DistilBERT model)"),R4e.forEach(t),mOe=i(L),Vf=n(L,"LI",{});var B4e=s(Vf);Tee=n(B4e,"STRONG",{});var kqr=s(Tee);gOe=r(kqr,"dpr"),kqr.forEach(t),hOe=r(B4e," \u2014 "),j$=n(B4e,"A",{href:!0});var Sqr=s(j$);pOe=r(Sqr,"DPRConfig"),Sqr.forEach(t),uOe=r(B4e," (DPR model)"),B4e.forEach(t),_Oe=i(L),Xf=n(L,"LI",{});var P4e=s(Xf);Mee=n(P4e,"STRONG",{});var Rqr=s(Mee);bOe=r(Rqr,"dpt"),Rqr.forEach(t),vOe=r(P4e," \u2014 "),D$=n(P4e,"A",{href:!0});var Bqr=s(D$);FOe=r(Bqr,"DPTConfig"),Bqr.forEach(t),TOe=r(P4e," (DPT model)"),P4e.forEach(t),MOe=i(L),zf=n(L,"LI",{});var I4e=s(zf);Eee=n(I4e,"STRONG",{});var Pqr=s(Eee);EOe=r(Pqr,"electra"),Pqr.forEach(t),COe=r(I4e," \u2014 "),G$=n(I4e,"A",{href:!0});var Iqr=s(G$);wOe=r(Iqr,"ElectraConfig"),Iqr.forEach(t),AOe=r(I4e," (ELECTRA model)"),I4e.forEach(t),yOe=i(L),Qf=n(L,"LI",{});var q4e=s(Qf);Cee=n(q4e,"STRONG",{});var qqr=s(Cee);LOe=r(qqr,"encoder-decoder"),qqr.forEach(t),xOe=r(q4e," \u2014 "),O$=n(q4e,"A",{href:!0});var Nqr=s(O$);$Oe=r(Nqr,"EncoderDecoderConfig"),Nqr.forEach(t),kOe=r(q4e," (Encoder decoder model)"),q4e.forEach(t),SOe=i(L),Wf=n(L,"LI",{});var N4e=s(Wf);wee=n(N4e,"STRONG",{});var jqr=s(wee);ROe=r(jqr,"flaubert"),jqr.forEach(t),BOe=r(N4e," \u2014 "),V$=n(N4e,"A",{href:!0});var Dqr=s(V$);POe=r(Dqr,"FlaubertConfig"),Dqr.forEach(t),IOe=r(N4e," (FlauBERT model)"),N4e.forEach(t),qOe=i(L),Hf=n(L,"LI",{});var j4e=s(Hf);Aee=n(j4e,"STRONG",{});var Gqr=s(Aee);NOe=r(Gqr,"fnet"),Gqr.forEach(t),jOe=r(j4e," \u2014 "),X$=n(j4e,"A",{href:!0});var Oqr=s(X$);DOe=r(Oqr,"FNetConfig"),Oqr.forEach(t),GOe=r(j4e," (FNet model)"),j4e.forEach(t),OOe=i(L),Uf=n(L,"LI",{});var D4e=s(Uf);yee=n(D4e,"STRONG",{});var Vqr=s(yee);VOe=r(Vqr,"fsmt"),Vqr.forEach(t),XOe=r(D4e," \u2014 "),z$=n(D4e,"A",{href:!0});var Xqr=s(z$);zOe=r(Xqr,"FSMTConfig"),Xqr.forEach(t),QOe=r(D4e," (FairSeq Machine-Translation model)"),D4e.forEach(t),WOe=i(L),Jf=n(L,"LI",{});var G4e=s(Jf);Lee=n(G4e,"STRONG",{});var zqr=s(Lee);HOe=r(zqr,"funnel"),zqr.forEach(t),UOe=r(G4e," \u2014 "),Q$=n(G4e,"A",{href:!0});var Qqr=s(Q$);JOe=r(Qqr,"FunnelConfig"),Qqr.forEach(t),YOe=r(G4e," (Funnel Transformer model)"),G4e.forEach(t),KOe=i(L),Yf=n(L,"LI",{});var O4e=s(Yf);xee=n(O4e,"STRONG",{});var Wqr=s(xee);ZOe=r(Wqr,"glpn"),Wqr.forEach(t),eVe=r(O4e," \u2014 "),W$=n(O4e,"A",{href:!0});var Hqr=s(W$);oVe=r(Hqr,"GLPNConfig"),Hqr.forEach(t),rVe=r(O4e," (GLPN model)"),O4e.forEach(t),tVe=i(L),Kf=n(L,"LI",{});var V4e=s(Kf);$ee=n(V4e,"STRONG",{});var Uqr=s($ee);aVe=r(Uqr,"gpt2"),Uqr.forEach(t),nVe=r(V4e," \u2014 "),H$=n(V4e,"A",{href:!0});var Jqr=s(H$);sVe=r(Jqr,"GPT2Config"),Jqr.forEach(t),lVe=r(V4e," (OpenAI GPT-2 model)"),V4e.forEach(t),iVe=i(L),Zf=n(L,"LI",{});var X4e=s(Zf);kee=n(X4e,"STRONG",{});var Yqr=s(kee);dVe=r(Yqr,"gpt_neo"),Yqr.forEach(t),cVe=r(X4e," \u2014 "),U$=n(X4e,"A",{href:!0});var Kqr=s(U$);fVe=r(Kqr,"GPTNeoConfig"),Kqr.forEach(t),mVe=r(X4e," (GPT Neo model)"),X4e.forEach(t),gVe=i(L),em=n(L,"LI",{});var z4e=s(em);See=n(z4e,"STRONG",{});var Zqr=s(See);hVe=r(Zqr,"gptj"),Zqr.forEach(t),pVe=r(z4e," \u2014 "),J$=n(z4e,"A",{href:!0});var eNr=s(J$);uVe=r(eNr,"GPTJConfig"),eNr.forEach(t),_Ve=r(z4e," (GPT-J model)"),z4e.forEach(t),bVe=i(L),om=n(L,"LI",{});var Q4e=s(om);Ree=n(Q4e,"STRONG",{});var oNr=s(Ree);vVe=r(oNr,"hubert"),oNr.forEach(t),FVe=r(Q4e," \u2014 "),Y$=n(Q4e,"A",{href:!0});var rNr=s(Y$);TVe=r(rNr,"HubertConfig"),rNr.forEach(t),MVe=r(Q4e," (Hubert model)"),Q4e.forEach(t),EVe=i(L),rm=n(L,"LI",{});var W4e=s(rm);Bee=n(W4e,"STRONG",{});var tNr=s(Bee);CVe=r(tNr,"ibert"),tNr.forEach(t),wVe=r(W4e," \u2014 "),K$=n(W4e,"A",{href:!0});var aNr=s(K$);AVe=r(aNr,"IBertConfig"),aNr.forEach(t),yVe=r(W4e," (I-BERT model)"),W4e.forEach(t),LVe=i(L),tm=n(L,"LI",{});var H4e=s(tm);Pee=n(H4e,"STRONG",{});var nNr=s(Pee);xVe=r(nNr,"imagegpt"),nNr.forEach(t),$Ve=r(H4e," \u2014 "),Z$=n(H4e,"A",{href:!0});var sNr=s(Z$);kVe=r(sNr,"ImageGPTConfig"),sNr.forEach(t),SVe=r(H4e," (ImageGPT model)"),H4e.forEach(t),RVe=i(L),am=n(L,"LI",{});var U4e=s(am);Iee=n(U4e,"STRONG",{});var lNr=s(Iee);BVe=r(lNr,"layoutlm"),lNr.forEach(t),PVe=r(U4e," \u2014 "),ek=n(U4e,"A",{href:!0});var iNr=s(ek);IVe=r(iNr,"LayoutLMConfig"),iNr.forEach(t),qVe=r(U4e," (LayoutLM model)"),U4e.forEach(t),NVe=i(L),nm=n(L,"LI",{});var J4e=s(nm);qee=n(J4e,"STRONG",{});var dNr=s(qee);jVe=r(dNr,"layoutlmv2"),dNr.forEach(t),DVe=r(J4e," \u2014 "),ok=n(J4e,"A",{href:!0});var cNr=s(ok);GVe=r(cNr,"LayoutLMv2Config"),cNr.forEach(t),OVe=r(J4e," (LayoutLMv2 model)"),J4e.forEach(t),VVe=i(L),sm=n(L,"LI",{});var Y4e=s(sm);Nee=n(Y4e,"STRONG",{});var fNr=s(Nee);XVe=r(fNr,"led"),fNr.forEach(t),zVe=r(Y4e," \u2014 "),rk=n(Y4e,"A",{href:!0});var mNr=s(rk);QVe=r(mNr,"LEDConfig"),mNr.forEach(t),WVe=r(Y4e," (LED model)"),Y4e.forEach(t),HVe=i(L),lm=n(L,"LI",{});var K4e=s(lm);jee=n(K4e,"STRONG",{});var gNr=s(jee);UVe=r(gNr,"longformer"),gNr.forEach(t),JVe=r(K4e," \u2014 "),tk=n(K4e,"A",{href:!0});var hNr=s(tk);YVe=r(hNr,"LongformerConfig"),hNr.forEach(t),KVe=r(K4e," (Longformer model)"),K4e.forEach(t),ZVe=i(L),im=n(L,"LI",{});var Z4e=s(im);Dee=n(Z4e,"STRONG",{});var pNr=s(Dee);eXe=r(pNr,"luke"),pNr.forEach(t),oXe=r(Z4e," \u2014 "),ak=n(Z4e,"A",{href:!0});var uNr=s(ak);rXe=r(uNr,"LukeConfig"),uNr.forEach(t),tXe=r(Z4e," (LUKE model)"),Z4e.forEach(t),aXe=i(L),dm=n(L,"LI",{});var eEe=s(dm);Gee=n(eEe,"STRONG",{});var _Nr=s(Gee);nXe=r(_Nr,"lxmert"),_Nr.forEach(t),sXe=r(eEe," \u2014 "),nk=n(eEe,"A",{href:!0});var bNr=s(nk);lXe=r(bNr,"LxmertConfig"),bNr.forEach(t),iXe=r(eEe," (LXMERT model)"),eEe.forEach(t),dXe=i(L),cm=n(L,"LI",{});var oEe=s(cm);Oee=n(oEe,"STRONG",{});var vNr=s(Oee);cXe=r(vNr,"m2m_100"),vNr.forEach(t),fXe=r(oEe," \u2014 "),sk=n(oEe,"A",{href:!0});var FNr=s(sk);mXe=r(FNr,"M2M100Config"),FNr.forEach(t),gXe=r(oEe," (M2M100 model)"),oEe.forEach(t),hXe=i(L),fm=n(L,"LI",{});var rEe=s(fm);Vee=n(rEe,"STRONG",{});var TNr=s(Vee);pXe=r(TNr,"marian"),TNr.forEach(t),uXe=r(rEe," \u2014 "),lk=n(rEe,"A",{href:!0});var MNr=s(lk);_Xe=r(MNr,"MarianConfig"),MNr.forEach(t),bXe=r(rEe," (Marian model)"),rEe.forEach(t),vXe=i(L),mm=n(L,"LI",{});var tEe=s(mm);Xee=n(tEe,"STRONG",{});var ENr=s(Xee);FXe=r(ENr,"maskformer"),ENr.forEach(t),TXe=r(tEe," \u2014 "),ik=n(tEe,"A",{href:!0});var CNr=s(ik);MXe=r(CNr,"MaskFormerConfig"),CNr.forEach(t),EXe=r(tEe," (MaskFormer model)"),tEe.forEach(t),CXe=i(L),gm=n(L,"LI",{});var aEe=s(gm);zee=n(aEe,"STRONG",{});var wNr=s(zee);wXe=r(wNr,"mbart"),wNr.forEach(t),AXe=r(aEe," \u2014 "),dk=n(aEe,"A",{href:!0});var ANr=s(dk);yXe=r(ANr,"MBartConfig"),ANr.forEach(t),LXe=r(aEe," (mBART model)"),aEe.forEach(t),xXe=i(L),hm=n(L,"LI",{});var nEe=s(hm);Qee=n(nEe,"STRONG",{});var yNr=s(Qee);$Xe=r(yNr,"megatron-bert"),yNr.forEach(t),kXe=r(nEe," \u2014 "),ck=n(nEe,"A",{href:!0});var LNr=s(ck);SXe=r(LNr,"MegatronBertConfig"),LNr.forEach(t),RXe=r(nEe," (MegatronBert model)"),nEe.forEach(t),BXe=i(L),pm=n(L,"LI",{});var sEe=s(pm);Wee=n(sEe,"STRONG",{});var xNr=s(Wee);PXe=r(xNr,"mobilebert"),xNr.forEach(t),IXe=r(sEe," \u2014 "),fk=n(sEe,"A",{href:!0});var $Nr=s(fk);qXe=r($Nr,"MobileBertConfig"),$Nr.forEach(t),NXe=r(sEe," (MobileBERT model)"),sEe.forEach(t),jXe=i(L),um=n(L,"LI",{});var lEe=s(um);Hee=n(lEe,"STRONG",{});var kNr=s(Hee);DXe=r(kNr,"mpnet"),kNr.forEach(t),GXe=r(lEe," \u2014 "),mk=n(lEe,"A",{href:!0});var SNr=s(mk);OXe=r(SNr,"MPNetConfig"),SNr.forEach(t),VXe=r(lEe," (MPNet model)"),lEe.forEach(t),XXe=i(L),_m=n(L,"LI",{});var iEe=s(_m);Uee=n(iEe,"STRONG",{});var RNr=s(Uee);zXe=r(RNr,"mt5"),RNr.forEach(t),QXe=r(iEe," \u2014 "),gk=n(iEe,"A",{href:!0});var BNr=s(gk);WXe=r(BNr,"MT5Config"),BNr.forEach(t),HXe=r(iEe," (mT5 model)"),iEe.forEach(t),UXe=i(L),bm=n(L,"LI",{});var dEe=s(bm);Jee=n(dEe,"STRONG",{});var PNr=s(Jee);JXe=r(PNr,"nystromformer"),PNr.forEach(t),YXe=r(dEe," \u2014 "),hk=n(dEe,"A",{href:!0});var INr=s(hk);KXe=r(INr,"NystromformerConfig"),INr.forEach(t),ZXe=r(dEe," (Nystromformer model)"),dEe.forEach(t),eze=i(L),vm=n(L,"LI",{});var cEe=s(vm);Yee=n(cEe,"STRONG",{});var qNr=s(Yee);oze=r(qNr,"openai-gpt"),qNr.forEach(t),rze=r(cEe," \u2014 "),pk=n(cEe,"A",{href:!0});var NNr=s(pk);tze=r(NNr,"OpenAIGPTConfig"),NNr.forEach(t),aze=r(cEe," (OpenAI GPT model)"),cEe.forEach(t),nze=i(L),Fm=n(L,"LI",{});var fEe=s(Fm);Kee=n(fEe,"STRONG",{});var jNr=s(Kee);sze=r(jNr,"pegasus"),jNr.forEach(t),lze=r(fEe," \u2014 "),uk=n(fEe,"A",{href:!0});var DNr=s(uk);ize=r(DNr,"PegasusConfig"),DNr.forEach(t),dze=r(fEe," (Pegasus model)"),fEe.forEach(t),cze=i(L),Tm=n(L,"LI",{});var mEe=s(Tm);Zee=n(mEe,"STRONG",{});var GNr=s(Zee);fze=r(GNr,"perceiver"),GNr.forEach(t),mze=r(mEe," \u2014 "),_k=n(mEe,"A",{href:!0});var ONr=s(_k);gze=r(ONr,"PerceiverConfig"),ONr.forEach(t),hze=r(mEe," (Perceiver model)"),mEe.forEach(t),pze=i(L),Mm=n(L,"LI",{});var gEe=s(Mm);eoe=n(gEe,"STRONG",{});var VNr=s(eoe);uze=r(VNr,"plbart"),VNr.forEach(t),_ze=r(gEe," \u2014 "),bk=n(gEe,"A",{href:!0});var XNr=s(bk);bze=r(XNr,"PLBartConfig"),XNr.forEach(t),vze=r(gEe," (PLBart model)"),gEe.forEach(t),Fze=i(L),Em=n(L,"LI",{});var hEe=s(Em);ooe=n(hEe,"STRONG",{});var zNr=s(ooe);Tze=r(zNr,"poolformer"),zNr.forEach(t),Mze=r(hEe," \u2014 "),vk=n(hEe,"A",{href:!0});var QNr=s(vk);Eze=r(QNr,"PoolFormerConfig"),QNr.forEach(t),Cze=r(hEe," (PoolFormer model)"),hEe.forEach(t),wze=i(L),Cm=n(L,"LI",{});var pEe=s(Cm);roe=n(pEe,"STRONG",{});var WNr=s(roe);Aze=r(WNr,"prophetnet"),WNr.forEach(t),yze=r(pEe," \u2014 "),Fk=n(pEe,"A",{href:!0});var HNr=s(Fk);Lze=r(HNr,"ProphetNetConfig"),HNr.forEach(t),xze=r(pEe," (ProphetNet model)"),pEe.forEach(t),$ze=i(L),wm=n(L,"LI",{});var uEe=s(wm);toe=n(uEe,"STRONG",{});var UNr=s(toe);kze=r(UNr,"qdqbert"),UNr.forEach(t),Sze=r(uEe," \u2014 "),Tk=n(uEe,"A",{href:!0});var JNr=s(Tk);Rze=r(JNr,"QDQBertConfig"),JNr.forEach(t),Bze=r(uEe," (QDQBert model)"),uEe.forEach(t),Pze=i(L),Am=n(L,"LI",{});var _Ee=s(Am);aoe=n(_Ee,"STRONG",{});var YNr=s(aoe);Ize=r(YNr,"rag"),YNr.forEach(t),qze=r(_Ee," \u2014 "),Mk=n(_Ee,"A",{href:!0});var KNr=s(Mk);Nze=r(KNr,"RagConfig"),KNr.forEach(t),jze=r(_Ee," (RAG model)"),_Ee.forEach(t),Dze=i(L),ym=n(L,"LI",{});var bEe=s(ym);noe=n(bEe,"STRONG",{});var ZNr=s(noe);Gze=r(ZNr,"realm"),ZNr.forEach(t),Oze=r(bEe," \u2014 "),Ek=n(bEe,"A",{href:!0});var ejr=s(Ek);Vze=r(ejr,"RealmConfig"),ejr.forEach(t),Xze=r(bEe," (Realm model)"),bEe.forEach(t),zze=i(L),Lm=n(L,"LI",{});var vEe=s(Lm);soe=n(vEe,"STRONG",{});var ojr=s(soe);Qze=r(ojr,"reformer"),ojr.forEach(t),Wze=r(vEe," \u2014 "),Ck=n(vEe,"A",{href:!0});var rjr=s(Ck);Hze=r(rjr,"ReformerConfig"),rjr.forEach(t),Uze=r(vEe," (Reformer model)"),vEe.forEach(t),Jze=i(L),xm=n(L,"LI",{});var FEe=s(xm);loe=n(FEe,"STRONG",{});var tjr=s(loe);Yze=r(tjr,"regnet"),tjr.forEach(t),Kze=r(FEe," \u2014 "),wk=n(FEe,"A",{href:!0});var ajr=s(wk);Zze=r(ajr,"RegNetConfig"),ajr.forEach(t),eQe=r(FEe," (RegNet model)"),FEe.forEach(t),oQe=i(L),$m=n(L,"LI",{});var TEe=s($m);ioe=n(TEe,"STRONG",{});var njr=s(ioe);rQe=r(njr,"rembert"),njr.forEach(t),tQe=r(TEe," \u2014 "),Ak=n(TEe,"A",{href:!0});var sjr=s(Ak);aQe=r(sjr,"RemBertConfig"),sjr.forEach(t),nQe=r(TEe," (RemBERT model)"),TEe.forEach(t),sQe=i(L),km=n(L,"LI",{});var MEe=s(km);doe=n(MEe,"STRONG",{});var ljr=s(doe);lQe=r(ljr,"resnet"),ljr.forEach(t),iQe=r(MEe," \u2014 "),yk=n(MEe,"A",{href:!0});var ijr=s(yk);dQe=r(ijr,"ResNetConfig"),ijr.forEach(t),cQe=r(MEe," (ResNet model)"),MEe.forEach(t),fQe=i(L),Sm=n(L,"LI",{});var EEe=s(Sm);coe=n(EEe,"STRONG",{});var djr=s(coe);mQe=r(djr,"retribert"),djr.forEach(t),gQe=r(EEe," \u2014 "),Lk=n(EEe,"A",{href:!0});var cjr=s(Lk);hQe=r(cjr,"RetriBertConfig"),cjr.forEach(t),pQe=r(EEe," (RetriBERT model)"),EEe.forEach(t),uQe=i(L),Rm=n(L,"LI",{});var CEe=s(Rm);foe=n(CEe,"STRONG",{});var fjr=s(foe);_Qe=r(fjr,"roberta"),fjr.forEach(t),bQe=r(CEe," \u2014 "),xk=n(CEe,"A",{href:!0});var mjr=s(xk);vQe=r(mjr,"RobertaConfig"),mjr.forEach(t),FQe=r(CEe," (RoBERTa model)"),CEe.forEach(t),TQe=i(L),Bm=n(L,"LI",{});var wEe=s(Bm);moe=n(wEe,"STRONG",{});var gjr=s(moe);MQe=r(gjr,"roformer"),gjr.forEach(t),EQe=r(wEe," \u2014 "),$k=n(wEe,"A",{href:!0});var hjr=s($k);CQe=r(hjr,"RoFormerConfig"),hjr.forEach(t),wQe=r(wEe," (RoFormer model)"),wEe.forEach(t),AQe=i(L),Pm=n(L,"LI",{});var AEe=s(Pm);goe=n(AEe,"STRONG",{});var pjr=s(goe);yQe=r(pjr,"segformer"),pjr.forEach(t),LQe=r(AEe," \u2014 "),kk=n(AEe,"A",{href:!0});var ujr=s(kk);xQe=r(ujr,"SegformerConfig"),ujr.forEach(t),$Qe=r(AEe," (SegFormer model)"),AEe.forEach(t),kQe=i(L),Im=n(L,"LI",{});var yEe=s(Im);hoe=n(yEe,"STRONG",{});var _jr=s(hoe);SQe=r(_jr,"sew"),_jr.forEach(t),RQe=r(yEe," \u2014 "),Sk=n(yEe,"A",{href:!0});var bjr=s(Sk);BQe=r(bjr,"SEWConfig"),bjr.forEach(t),PQe=r(yEe," (SEW model)"),yEe.forEach(t),IQe=i(L),qm=n(L,"LI",{});var LEe=s(qm);poe=n(LEe,"STRONG",{});var vjr=s(poe);qQe=r(vjr,"sew-d"),vjr.forEach(t),NQe=r(LEe," \u2014 "),Rk=n(LEe,"A",{href:!0});var Fjr=s(Rk);jQe=r(Fjr,"SEWDConfig"),Fjr.forEach(t),DQe=r(LEe," (SEW-D model)"),LEe.forEach(t),GQe=i(L),Nm=n(L,"LI",{});var xEe=s(Nm);uoe=n(xEe,"STRONG",{});var Tjr=s(uoe);OQe=r(Tjr,"speech-encoder-decoder"),Tjr.forEach(t),VQe=r(xEe," \u2014 "),Bk=n(xEe,"A",{href:!0});var Mjr=s(Bk);XQe=r(Mjr,"SpeechEncoderDecoderConfig"),Mjr.forEach(t),zQe=r(xEe," (Speech Encoder decoder model)"),xEe.forEach(t),QQe=i(L),jm=n(L,"LI",{});var $Ee=s(jm);_oe=n($Ee,"STRONG",{});var Ejr=s(_oe);WQe=r(Ejr,"speech_to_text"),Ejr.forEach(t),HQe=r($Ee," \u2014 "),Pk=n($Ee,"A",{href:!0});var Cjr=s(Pk);UQe=r(Cjr,"Speech2TextConfig"),Cjr.forEach(t),JQe=r($Ee," (Speech2Text model)"),$Ee.forEach(t),YQe=i(L),Dm=n(L,"LI",{});var kEe=s(Dm);boe=n(kEe,"STRONG",{});var wjr=s(boe);KQe=r(wjr,"speech_to_text_2"),wjr.forEach(t),ZQe=r(kEe," \u2014 "),Ik=n(kEe,"A",{href:!0});var Ajr=s(Ik);eWe=r(Ajr,"Speech2Text2Config"),Ajr.forEach(t),oWe=r(kEe," (Speech2Text2 model)"),kEe.forEach(t),rWe=i(L),Gm=n(L,"LI",{});var SEe=s(Gm);voe=n(SEe,"STRONG",{});var yjr=s(voe);tWe=r(yjr,"splinter"),yjr.forEach(t),aWe=r(SEe," \u2014 "),qk=n(SEe,"A",{href:!0});var Ljr=s(qk);nWe=r(Ljr,"SplinterConfig"),Ljr.forEach(t),sWe=r(SEe," (Splinter model)"),SEe.forEach(t),lWe=i(L),Om=n(L,"LI",{});var REe=s(Om);Foe=n(REe,"STRONG",{});var xjr=s(Foe);iWe=r(xjr,"squeezebert"),xjr.forEach(t),dWe=r(REe," \u2014 "),Nk=n(REe,"A",{href:!0});var $jr=s(Nk);cWe=r($jr,"SqueezeBertConfig"),$jr.forEach(t),fWe=r(REe," (SqueezeBERT model)"),REe.forEach(t),mWe=i(L),Vm=n(L,"LI",{});var BEe=s(Vm);Toe=n(BEe,"STRONG",{});var kjr=s(Toe);gWe=r(kjr,"swin"),kjr.forEach(t),hWe=r(BEe," \u2014 "),jk=n(BEe,"A",{href:!0});var Sjr=s(jk);pWe=r(Sjr,"SwinConfig"),Sjr.forEach(t),uWe=r(BEe," (Swin model)"),BEe.forEach(t),_We=i(L),Xm=n(L,"LI",{});var PEe=s(Xm);Moe=n(PEe,"STRONG",{});var Rjr=s(Moe);bWe=r(Rjr,"t5"),Rjr.forEach(t),vWe=r(PEe," \u2014 "),Dk=n(PEe,"A",{href:!0});var Bjr=s(Dk);FWe=r(Bjr,"T5Config"),Bjr.forEach(t),TWe=r(PEe," (T5 model)"),PEe.forEach(t),MWe=i(L),zm=n(L,"LI",{});var IEe=s(zm);Eoe=n(IEe,"STRONG",{});var Pjr=s(Eoe);EWe=r(Pjr,"tapas"),Pjr.forEach(t),CWe=r(IEe," \u2014 "),Gk=n(IEe,"A",{href:!0});var Ijr=s(Gk);wWe=r(Ijr,"TapasConfig"),Ijr.forEach(t),AWe=r(IEe," (TAPAS model)"),IEe.forEach(t),yWe=i(L),Qm=n(L,"LI",{});var qEe=s(Qm);Coe=n(qEe,"STRONG",{});var qjr=s(Coe);LWe=r(qjr,"tapex"),qjr.forEach(t),xWe=r(qEe," \u2014 "),Ok=n(qEe,"A",{href:!0});var Njr=s(Ok);$We=r(Njr,"BartConfig"),Njr.forEach(t),kWe=r(qEe," (TAPEX model)"),qEe.forEach(t),SWe=i(L),Wm=n(L,"LI",{});var NEe=s(Wm);woe=n(NEe,"STRONG",{});var jjr=s(woe);RWe=r(jjr,"transfo-xl"),jjr.forEach(t),BWe=r(NEe," \u2014 "),Vk=n(NEe,"A",{href:!0});var Djr=s(Vk);PWe=r(Djr,"TransfoXLConfig"),Djr.forEach(t),IWe=r(NEe," (Transformer-XL model)"),NEe.forEach(t),qWe=i(L),Hm=n(L,"LI",{});var jEe=s(Hm);Aoe=n(jEe,"STRONG",{});var Gjr=s(Aoe);NWe=r(Gjr,"trocr"),Gjr.forEach(t),jWe=r(jEe," \u2014 "),Xk=n(jEe,"A",{href:!0});var Ojr=s(Xk);DWe=r(Ojr,"TrOCRConfig"),Ojr.forEach(t),GWe=r(jEe," (TrOCR model)"),jEe.forEach(t),OWe=i(L),Um=n(L,"LI",{});var DEe=s(Um);yoe=n(DEe,"STRONG",{});var Vjr=s(yoe);VWe=r(Vjr,"unispeech"),Vjr.forEach(t),XWe=r(DEe," \u2014 "),zk=n(DEe,"A",{href:!0});var Xjr=s(zk);zWe=r(Xjr,"UniSpeechConfig"),Xjr.forEach(t),QWe=r(DEe," (UniSpeech model)"),DEe.forEach(t),WWe=i(L),Jm=n(L,"LI",{});var GEe=s(Jm);Loe=n(GEe,"STRONG",{});var zjr=s(Loe);HWe=r(zjr,"unispeech-sat"),zjr.forEach(t),UWe=r(GEe," \u2014 "),Qk=n(GEe,"A",{href:!0});var Qjr=s(Qk);JWe=r(Qjr,"UniSpeechSatConfig"),Qjr.forEach(t),YWe=r(GEe," (UniSpeechSat model)"),GEe.forEach(t),KWe=i(L),Ym=n(L,"LI",{});var OEe=s(Ym);xoe=n(OEe,"STRONG",{});var Wjr=s(xoe);ZWe=r(Wjr,"van"),Wjr.forEach(t),eHe=r(OEe," \u2014 "),Wk=n(OEe,"A",{href:!0});var Hjr=s(Wk);oHe=r(Hjr,"VanConfig"),Hjr.forEach(t),rHe=r(OEe," (VAN model)"),OEe.forEach(t),tHe=i(L),Km=n(L,"LI",{});var VEe=s(Km);$oe=n(VEe,"STRONG",{});var Ujr=s($oe);aHe=r(Ujr,"vilt"),Ujr.forEach(t),nHe=r(VEe," \u2014 "),Hk=n(VEe,"A",{href:!0});var Jjr=s(Hk);sHe=r(Jjr,"ViltConfig"),Jjr.forEach(t),lHe=r(VEe," (ViLT model)"),VEe.forEach(t),iHe=i(L),Zm=n(L,"LI",{});var XEe=s(Zm);koe=n(XEe,"STRONG",{});var Yjr=s(koe);dHe=r(Yjr,"vision-encoder-decoder"),Yjr.forEach(t),cHe=r(XEe," \u2014 "),Uk=n(XEe,"A",{href:!0});var Kjr=s(Uk);fHe=r(Kjr,"VisionEncoderDecoderConfig"),Kjr.forEach(t),mHe=r(XEe," (Vision Encoder decoder model)"),XEe.forEach(t),gHe=i(L),eg=n(L,"LI",{});var zEe=s(eg);Soe=n(zEe,"STRONG",{});var Zjr=s(Soe);hHe=r(Zjr,"vision-text-dual-encoder"),Zjr.forEach(t),pHe=r(zEe," \u2014 "),Jk=n(zEe,"A",{href:!0});var eDr=s(Jk);uHe=r(eDr,"VisionTextDualEncoderConfig"),eDr.forEach(t),_He=r(zEe," (VisionTextDualEncoder model)"),zEe.forEach(t),bHe=i(L),og=n(L,"LI",{});var QEe=s(og);Roe=n(QEe,"STRONG",{});var oDr=s(Roe);vHe=r(oDr,"visual_bert"),oDr.forEach(t),FHe=r(QEe," \u2014 "),Yk=n(QEe,"A",{href:!0});var rDr=s(Yk);THe=r(rDr,"VisualBertConfig"),rDr.forEach(t),MHe=r(QEe," (VisualBert model)"),QEe.forEach(t),EHe=i(L),rg=n(L,"LI",{});var WEe=s(rg);Boe=n(WEe,"STRONG",{});var tDr=s(Boe);CHe=r(tDr,"vit"),tDr.forEach(t),wHe=r(WEe," \u2014 "),Kk=n(WEe,"A",{href:!0});var aDr=s(Kk);AHe=r(aDr,"ViTConfig"),aDr.forEach(t),yHe=r(WEe," (ViT model)"),WEe.forEach(t),LHe=i(L),tg=n(L,"LI",{});var HEe=s(tg);Poe=n(HEe,"STRONG",{});var nDr=s(Poe);xHe=r(nDr,"vit_mae"),nDr.forEach(t),$He=r(HEe," \u2014 "),Zk=n(HEe,"A",{href:!0});var sDr=s(Zk);kHe=r(sDr,"ViTMAEConfig"),sDr.forEach(t),SHe=r(HEe," (ViTMAE model)"),HEe.forEach(t),RHe=i(L),ag=n(L,"LI",{});var UEe=s(ag);Ioe=n(UEe,"STRONG",{});var lDr=s(Ioe);BHe=r(lDr,"wav2vec2"),lDr.forEach(t),PHe=r(UEe," \u2014 "),eS=n(UEe,"A",{href:!0});var iDr=s(eS);IHe=r(iDr,"Wav2Vec2Config"),iDr.forEach(t),qHe=r(UEe," (Wav2Vec2 model)"),UEe.forEach(t),NHe=i(L),ng=n(L,"LI",{});var JEe=s(ng);qoe=n(JEe,"STRONG",{});var dDr=s(qoe);jHe=r(dDr,"wavlm"),dDr.forEach(t),DHe=r(JEe," \u2014 "),oS=n(JEe,"A",{href:!0});var cDr=s(oS);GHe=r(cDr,"WavLMConfig"),cDr.forEach(t),OHe=r(JEe," (WavLM model)"),JEe.forEach(t),VHe=i(L),sg=n(L,"LI",{});var YEe=s(sg);Noe=n(YEe,"STRONG",{});var fDr=s(Noe);XHe=r(fDr,"xglm"),fDr.forEach(t),zHe=r(YEe," \u2014 "),rS=n(YEe,"A",{href:!0});var mDr=s(rS);QHe=r(mDr,"XGLMConfig"),mDr.forEach(t),WHe=r(YEe," (XGLM model)"),YEe.forEach(t),HHe=i(L),lg=n(L,"LI",{});var KEe=s(lg);joe=n(KEe,"STRONG",{});var gDr=s(joe);UHe=r(gDr,"xlm"),gDr.forEach(t),JHe=r(KEe," \u2014 "),tS=n(KEe,"A",{href:!0});var hDr=s(tS);YHe=r(hDr,"XLMConfig"),hDr.forEach(t),KHe=r(KEe," (XLM model)"),KEe.forEach(t),ZHe=i(L),ig=n(L,"LI",{});var ZEe=s(ig);Doe=n(ZEe,"STRONG",{});var pDr=s(Doe);eUe=r(pDr,"xlm-prophetnet"),pDr.forEach(t),oUe=r(ZEe," \u2014 "),aS=n(ZEe,"A",{href:!0});var uDr=s(aS);rUe=r(uDr,"XLMProphetNetConfig"),uDr.forEach(t),tUe=r(ZEe," (XLMProphetNet model)"),ZEe.forEach(t),aUe=i(L),dg=n(L,"LI",{});var e5e=s(dg);Goe=n(e5e,"STRONG",{});var _Dr=s(Goe);nUe=r(_Dr,"xlm-roberta"),_Dr.forEach(t),sUe=r(e5e," \u2014 "),nS=n(e5e,"A",{href:!0});var bDr=s(nS);lUe=r(bDr,"XLMRobertaConfig"),bDr.forEach(t),iUe=r(e5e," (XLM-RoBERTa model)"),e5e.forEach(t),dUe=i(L),cg=n(L,"LI",{});var o5e=s(cg);Ooe=n(o5e,"STRONG",{});var vDr=s(Ooe);cUe=r(vDr,"xlm-roberta-xl"),vDr.forEach(t),fUe=r(o5e," \u2014 "),sS=n(o5e,"A",{href:!0});var FDr=s(sS);mUe=r(FDr,"XLMRobertaXLConfig"),FDr.forEach(t),gUe=r(o5e," (XLM-RoBERTa-XL model)"),o5e.forEach(t),hUe=i(L),fg=n(L,"LI",{});var r5e=s(fg);Voe=n(r5e,"STRONG",{});var TDr=s(Voe);pUe=r(TDr,"xlnet"),TDr.forEach(t),uUe=r(r5e," \u2014 "),lS=n(r5e,"A",{href:!0});var MDr=s(lS);_Ue=r(MDr,"XLNetConfig"),MDr.forEach(t),bUe=r(r5e," (XLNet model)"),r5e.forEach(t),vUe=i(L),mg=n(L,"LI",{});var t5e=s(mg);Xoe=n(t5e,"STRONG",{});var EDr=s(Xoe);FUe=r(EDr,"yolos"),EDr.forEach(t),TUe=r(t5e," \u2014 "),iS=n(t5e,"A",{href:!0});var CDr=s(iS);MUe=r(CDr,"YolosConfig"),CDr.forEach(t),EUe=r(t5e," (YOLOS model)"),t5e.forEach(t),CUe=i(L),gg=n(L,"LI",{});var a5e=s(gg);zoe=n(a5e,"STRONG",{});var wDr=s(zoe);wUe=r(wDr,"yoso"),wDr.forEach(t),AUe=r(a5e," \u2014 "),dS=n(a5e,"A",{href:!0});var ADr=s(dS);yUe=r(ADr,"YosoConfig"),ADr.forEach(t),LUe=r(a5e," (YOSO model)"),a5e.forEach(t),L.forEach(t),xUe=i(Zr),T(hg.$$.fragment,Zr),Zr.forEach(t),$Ue=i(Kr),pg=n(Kr,"DIV",{class:!0});var vqe=s(pg);T(Kw.$$.fragment,vqe),kUe=i(vqe),Qoe=n(vqe,"P",{});var yDr=s(Qoe);SUe=r(yDr,"Register a new configuration for this class."),yDr.forEach(t),vqe.forEach(t),Kr.forEach(t),MPe=i(f),bi=n(f,"H2",{class:!0});var Fqe=s(bi);ug=n(Fqe,"A",{id:!0,class:!0,href:!0});var LDr=s(ug);Woe=n(LDr,"SPAN",{});var xDr=s(Woe);T(Zw.$$.fragment,xDr),xDr.forEach(t),LDr.forEach(t),RUe=i(Fqe),Hoe=n(Fqe,"SPAN",{});var $Dr=s(Hoe);BUe=r($Dr,"AutoTokenizer"),$Dr.forEach(t),Fqe.forEach(t),EPe=i(f),wo=n(f,"DIV",{class:!0});var Is=s(wo);T(eA.$$.fragment,Is),PUe=i(Is),oA=n(Is,"P",{});var Tqe=s(oA);IUe=r(Tqe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),cS=n(Tqe,"A",{href:!0});var kDr=s(cS);qUe=r(kDr,"AutoTokenizer.from_pretrained()"),kDr.forEach(t),NUe=r(Tqe," class method."),Tqe.forEach(t),jUe=i(Is),rA=n(Is,"P",{});var Mqe=s(rA);DUe=r(Mqe,"This class cannot be instantiated directly using "),Uoe=n(Mqe,"CODE",{});var SDr=s(Uoe);GUe=r(SDr,"__init__()"),SDr.forEach(t),OUe=r(Mqe," (throws an error)."),Mqe.forEach(t),VUe=i(Is),Cr=n(Is,"DIV",{class:!0});var qs=s(Cr);T(tA.$$.fragment,qs),XUe=i(qs),Joe=n(qs,"P",{});var RDr=s(Joe);zUe=r(RDr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),RDr.forEach(t),QUe=i(qs),Ca=n(qs,"P",{});var zC=s(Ca);WUe=r(zC,"The tokenizer class to instantiate is selected based on the "),Yoe=n(zC,"CODE",{});var BDr=s(Yoe);HUe=r(BDr,"model_type"),BDr.forEach(t),UUe=r(zC,` property of the config object (either
passed as an argument or loaded from `),Koe=n(zC,"CODE",{});var PDr=s(Koe);JUe=r(PDr,"pretrained_model_name_or_path"),PDr.forEach(t),YUe=r(zC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zoe=n(zC,"CODE",{});var IDr=s(Zoe);KUe=r(IDr,"pretrained_model_name_or_path"),IDr.forEach(t),ZUe=r(zC,":"),zC.forEach(t),eJe=i(qs),k=n(qs,"UL",{});var S=s(k);Sn=n(S,"LI",{});var a7=s(Sn);ere=n(a7,"STRONG",{});var qDr=s(ere);oJe=r(qDr,"albert"),qDr.forEach(t),rJe=r(a7," \u2014 "),fS=n(a7,"A",{href:!0});var NDr=s(fS);tJe=r(NDr,"AlbertTokenizer"),NDr.forEach(t),aJe=r(a7," or "),mS=n(a7,"A",{href:!0});var jDr=s(mS);nJe=r(jDr,"AlbertTokenizerFast"),jDr.forEach(t),sJe=r(a7," (ALBERT model)"),a7.forEach(t),lJe=i(S),Rn=n(S,"LI",{});var n7=s(Rn);ore=n(n7,"STRONG",{});var DDr=s(ore);iJe=r(DDr,"bart"),DDr.forEach(t),dJe=r(n7," \u2014 "),gS=n(n7,"A",{href:!0});var GDr=s(gS);cJe=r(GDr,"BartTokenizer"),GDr.forEach(t),fJe=r(n7," or "),hS=n(n7,"A",{href:!0});var ODr=s(hS);mJe=r(ODr,"BartTokenizerFast"),ODr.forEach(t),gJe=r(n7," (BART model)"),n7.forEach(t),hJe=i(S),Bn=n(S,"LI",{});var s7=s(Bn);rre=n(s7,"STRONG",{});var VDr=s(rre);pJe=r(VDr,"barthez"),VDr.forEach(t),uJe=r(s7," \u2014 "),pS=n(s7,"A",{href:!0});var XDr=s(pS);_Je=r(XDr,"BarthezTokenizer"),XDr.forEach(t),bJe=r(s7," or "),uS=n(s7,"A",{href:!0});var zDr=s(uS);vJe=r(zDr,"BarthezTokenizerFast"),zDr.forEach(t),FJe=r(s7," (BARThez model)"),s7.forEach(t),TJe=i(S),_g=n(S,"LI",{});var n5e=s(_g);tre=n(n5e,"STRONG",{});var QDr=s(tre);MJe=r(QDr,"bartpho"),QDr.forEach(t),EJe=r(n5e," \u2014 "),_S=n(n5e,"A",{href:!0});var WDr=s(_S);CJe=r(WDr,"BartphoTokenizer"),WDr.forEach(t),wJe=r(n5e," (BARTpho model)"),n5e.forEach(t),AJe=i(S),Pn=n(S,"LI",{});var l7=s(Pn);are=n(l7,"STRONG",{});var HDr=s(are);yJe=r(HDr,"bert"),HDr.forEach(t),LJe=r(l7," \u2014 "),bS=n(l7,"A",{href:!0});var UDr=s(bS);xJe=r(UDr,"BertTokenizer"),UDr.forEach(t),$Je=r(l7," or "),vS=n(l7,"A",{href:!0});var JDr=s(vS);kJe=r(JDr,"BertTokenizerFast"),JDr.forEach(t),SJe=r(l7," (BERT model)"),l7.forEach(t),RJe=i(S),bg=n(S,"LI",{});var s5e=s(bg);nre=n(s5e,"STRONG",{});var YDr=s(nre);BJe=r(YDr,"bert-generation"),YDr.forEach(t),PJe=r(s5e," \u2014 "),FS=n(s5e,"A",{href:!0});var KDr=s(FS);IJe=r(KDr,"BertGenerationTokenizer"),KDr.forEach(t),qJe=r(s5e," (Bert Generation model)"),s5e.forEach(t),NJe=i(S),vg=n(S,"LI",{});var l5e=s(vg);sre=n(l5e,"STRONG",{});var ZDr=s(sre);jJe=r(ZDr,"bert-japanese"),ZDr.forEach(t),DJe=r(l5e," \u2014 "),TS=n(l5e,"A",{href:!0});var eGr=s(TS);GJe=r(eGr,"BertJapaneseTokenizer"),eGr.forEach(t),OJe=r(l5e," (BertJapanese model)"),l5e.forEach(t),VJe=i(S),Fg=n(S,"LI",{});var i5e=s(Fg);lre=n(i5e,"STRONG",{});var oGr=s(lre);XJe=r(oGr,"bertweet"),oGr.forEach(t),zJe=r(i5e," \u2014 "),MS=n(i5e,"A",{href:!0});var rGr=s(MS);QJe=r(rGr,"BertweetTokenizer"),rGr.forEach(t),WJe=r(i5e," (Bertweet model)"),i5e.forEach(t),HJe=i(S),In=n(S,"LI",{});var i7=s(In);ire=n(i7,"STRONG",{});var tGr=s(ire);UJe=r(tGr,"big_bird"),tGr.forEach(t),JJe=r(i7," \u2014 "),ES=n(i7,"A",{href:!0});var aGr=s(ES);YJe=r(aGr,"BigBirdTokenizer"),aGr.forEach(t),KJe=r(i7," or "),CS=n(i7,"A",{href:!0});var nGr=s(CS);ZJe=r(nGr,"BigBirdTokenizerFast"),nGr.forEach(t),eYe=r(i7," (BigBird model)"),i7.forEach(t),oYe=i(S),qn=n(S,"LI",{});var d7=s(qn);dre=n(d7,"STRONG",{});var sGr=s(dre);rYe=r(sGr,"bigbird_pegasus"),sGr.forEach(t),tYe=r(d7," \u2014 "),wS=n(d7,"A",{href:!0});var lGr=s(wS);aYe=r(lGr,"PegasusTokenizer"),lGr.forEach(t),nYe=r(d7," or "),AS=n(d7,"A",{href:!0});var iGr=s(AS);sYe=r(iGr,"PegasusTokenizerFast"),iGr.forEach(t),lYe=r(d7," (BigBirdPegasus model)"),d7.forEach(t),iYe=i(S),Nn=n(S,"LI",{});var c7=s(Nn);cre=n(c7,"STRONG",{});var dGr=s(cre);dYe=r(dGr,"blenderbot"),dGr.forEach(t),cYe=r(c7," \u2014 "),yS=n(c7,"A",{href:!0});var cGr=s(yS);fYe=r(cGr,"BlenderbotTokenizer"),cGr.forEach(t),mYe=r(c7," or "),LS=n(c7,"A",{href:!0});var fGr=s(LS);gYe=r(fGr,"BlenderbotTokenizerFast"),fGr.forEach(t),hYe=r(c7," (Blenderbot model)"),c7.forEach(t),pYe=i(S),Tg=n(S,"LI",{});var d5e=s(Tg);fre=n(d5e,"STRONG",{});var mGr=s(fre);uYe=r(mGr,"blenderbot-small"),mGr.forEach(t),_Ye=r(d5e," \u2014 "),xS=n(d5e,"A",{href:!0});var gGr=s(xS);bYe=r(gGr,"BlenderbotSmallTokenizer"),gGr.forEach(t),vYe=r(d5e," (BlenderbotSmall model)"),d5e.forEach(t),FYe=i(S),Mg=n(S,"LI",{});var c5e=s(Mg);mre=n(c5e,"STRONG",{});var hGr=s(mre);TYe=r(hGr,"byt5"),hGr.forEach(t),MYe=r(c5e," \u2014 "),$S=n(c5e,"A",{href:!0});var pGr=s($S);EYe=r(pGr,"ByT5Tokenizer"),pGr.forEach(t),CYe=r(c5e," (ByT5 model)"),c5e.forEach(t),wYe=i(S),jn=n(S,"LI",{});var f7=s(jn);gre=n(f7,"STRONG",{});var uGr=s(gre);AYe=r(uGr,"camembert"),uGr.forEach(t),yYe=r(f7," \u2014 "),kS=n(f7,"A",{href:!0});var _Gr=s(kS);LYe=r(_Gr,"CamembertTokenizer"),_Gr.forEach(t),xYe=r(f7," or "),SS=n(f7,"A",{href:!0});var bGr=s(SS);$Ye=r(bGr,"CamembertTokenizerFast"),bGr.forEach(t),kYe=r(f7," (CamemBERT model)"),f7.forEach(t),SYe=i(S),Eg=n(S,"LI",{});var f5e=s(Eg);hre=n(f5e,"STRONG",{});var vGr=s(hre);RYe=r(vGr,"canine"),vGr.forEach(t),BYe=r(f5e," \u2014 "),RS=n(f5e,"A",{href:!0});var FGr=s(RS);PYe=r(FGr,"CanineTokenizer"),FGr.forEach(t),IYe=r(f5e," (Canine model)"),f5e.forEach(t),qYe=i(S),Dn=n(S,"LI",{});var m7=s(Dn);pre=n(m7,"STRONG",{});var TGr=s(pre);NYe=r(TGr,"clip"),TGr.forEach(t),jYe=r(m7," \u2014 "),BS=n(m7,"A",{href:!0});var MGr=s(BS);DYe=r(MGr,"CLIPTokenizer"),MGr.forEach(t),GYe=r(m7," or "),PS=n(m7,"A",{href:!0});var EGr=s(PS);OYe=r(EGr,"CLIPTokenizerFast"),EGr.forEach(t),VYe=r(m7," (CLIP model)"),m7.forEach(t),XYe=i(S),Gn=n(S,"LI",{});var g7=s(Gn);ure=n(g7,"STRONG",{});var CGr=s(ure);zYe=r(CGr,"convbert"),CGr.forEach(t),QYe=r(g7," \u2014 "),IS=n(g7,"A",{href:!0});var wGr=s(IS);WYe=r(wGr,"ConvBertTokenizer"),wGr.forEach(t),HYe=r(g7," or "),qS=n(g7,"A",{href:!0});var AGr=s(qS);UYe=r(AGr,"ConvBertTokenizerFast"),AGr.forEach(t),JYe=r(g7," (ConvBERT model)"),g7.forEach(t),YYe=i(S),On=n(S,"LI",{});var h7=s(On);_re=n(h7,"STRONG",{});var yGr=s(_re);KYe=r(yGr,"cpm"),yGr.forEach(t),ZYe=r(h7," \u2014 "),NS=n(h7,"A",{href:!0});var LGr=s(NS);eKe=r(LGr,"CpmTokenizer"),LGr.forEach(t),oKe=r(h7," or "),jS=n(h7,"A",{href:!0});var xGr=s(jS);rKe=r(xGr,"CpmTokenizerFast"),xGr.forEach(t),tKe=r(h7," (CPM model)"),h7.forEach(t),aKe=i(S),Cg=n(S,"LI",{});var m5e=s(Cg);bre=n(m5e,"STRONG",{});var $Gr=s(bre);nKe=r($Gr,"ctrl"),$Gr.forEach(t),sKe=r(m5e," \u2014 "),DS=n(m5e,"A",{href:!0});var kGr=s(DS);lKe=r(kGr,"CTRLTokenizer"),kGr.forEach(t),iKe=r(m5e," (CTRL model)"),m5e.forEach(t),dKe=i(S),Vn=n(S,"LI",{});var p7=s(Vn);vre=n(p7,"STRONG",{});var SGr=s(vre);cKe=r(SGr,"data2vec-text"),SGr.forEach(t),fKe=r(p7," \u2014 "),GS=n(p7,"A",{href:!0});var RGr=s(GS);mKe=r(RGr,"RobertaTokenizer"),RGr.forEach(t),gKe=r(p7," or "),OS=n(p7,"A",{href:!0});var BGr=s(OS);hKe=r(BGr,"RobertaTokenizerFast"),BGr.forEach(t),pKe=r(p7," (Data2VecText model)"),p7.forEach(t),uKe=i(S),Xn=n(S,"LI",{});var u7=s(Xn);Fre=n(u7,"STRONG",{});var PGr=s(Fre);_Ke=r(PGr,"deberta"),PGr.forEach(t),bKe=r(u7," \u2014 "),VS=n(u7,"A",{href:!0});var IGr=s(VS);vKe=r(IGr,"DebertaTokenizer"),IGr.forEach(t),FKe=r(u7," or "),XS=n(u7,"A",{href:!0});var qGr=s(XS);TKe=r(qGr,"DebertaTokenizerFast"),qGr.forEach(t),MKe=r(u7," (DeBERTa model)"),u7.forEach(t),EKe=i(S),zn=n(S,"LI",{});var _7=s(zn);Tre=n(_7,"STRONG",{});var NGr=s(Tre);CKe=r(NGr,"deberta-v2"),NGr.forEach(t),wKe=r(_7," \u2014 "),zS=n(_7,"A",{href:!0});var jGr=s(zS);AKe=r(jGr,"DebertaV2Tokenizer"),jGr.forEach(t),yKe=r(_7," or "),QS=n(_7,"A",{href:!0});var DGr=s(QS);LKe=r(DGr,"DebertaV2TokenizerFast"),DGr.forEach(t),xKe=r(_7," (DeBERTa-v2 model)"),_7.forEach(t),$Ke=i(S),Qn=n(S,"LI",{});var b7=s(Qn);Mre=n(b7,"STRONG",{});var GGr=s(Mre);kKe=r(GGr,"distilbert"),GGr.forEach(t),SKe=r(b7," \u2014 "),WS=n(b7,"A",{href:!0});var OGr=s(WS);RKe=r(OGr,"DistilBertTokenizer"),OGr.forEach(t),BKe=r(b7," or "),HS=n(b7,"A",{href:!0});var VGr=s(HS);PKe=r(VGr,"DistilBertTokenizerFast"),VGr.forEach(t),IKe=r(b7," (DistilBERT model)"),b7.forEach(t),qKe=i(S),Wn=n(S,"LI",{});var v7=s(Wn);Ere=n(v7,"STRONG",{});var XGr=s(Ere);NKe=r(XGr,"dpr"),XGr.forEach(t),jKe=r(v7," \u2014 "),US=n(v7,"A",{href:!0});var zGr=s(US);DKe=r(zGr,"DPRQuestionEncoderTokenizer"),zGr.forEach(t),GKe=r(v7," or "),JS=n(v7,"A",{href:!0});var QGr=s(JS);OKe=r(QGr,"DPRQuestionEncoderTokenizerFast"),QGr.forEach(t),VKe=r(v7," (DPR model)"),v7.forEach(t),XKe=i(S),Hn=n(S,"LI",{});var F7=s(Hn);Cre=n(F7,"STRONG",{});var WGr=s(Cre);zKe=r(WGr,"electra"),WGr.forEach(t),QKe=r(F7," \u2014 "),YS=n(F7,"A",{href:!0});var HGr=s(YS);WKe=r(HGr,"ElectraTokenizer"),HGr.forEach(t),HKe=r(F7," or "),KS=n(F7,"A",{href:!0});var UGr=s(KS);UKe=r(UGr,"ElectraTokenizerFast"),UGr.forEach(t),JKe=r(F7," (ELECTRA model)"),F7.forEach(t),YKe=i(S),wg=n(S,"LI",{});var g5e=s(wg);wre=n(g5e,"STRONG",{});var JGr=s(wre);KKe=r(JGr,"flaubert"),JGr.forEach(t),ZKe=r(g5e," \u2014 "),ZS=n(g5e,"A",{href:!0});var YGr=s(ZS);eZe=r(YGr,"FlaubertTokenizer"),YGr.forEach(t),oZe=r(g5e," (FlauBERT model)"),g5e.forEach(t),rZe=i(S),Un=n(S,"LI",{});var T7=s(Un);Are=n(T7,"STRONG",{});var KGr=s(Are);tZe=r(KGr,"fnet"),KGr.forEach(t),aZe=r(T7," \u2014 "),eR=n(T7,"A",{href:!0});var ZGr=s(eR);nZe=r(ZGr,"FNetTokenizer"),ZGr.forEach(t),sZe=r(T7," or "),oR=n(T7,"A",{href:!0});var eOr=s(oR);lZe=r(eOr,"FNetTokenizerFast"),eOr.forEach(t),iZe=r(T7," (FNet model)"),T7.forEach(t),dZe=i(S),Ag=n(S,"LI",{});var h5e=s(Ag);yre=n(h5e,"STRONG",{});var oOr=s(yre);cZe=r(oOr,"fsmt"),oOr.forEach(t),fZe=r(h5e," \u2014 "),rR=n(h5e,"A",{href:!0});var rOr=s(rR);mZe=r(rOr,"FSMTTokenizer"),rOr.forEach(t),gZe=r(h5e," (FairSeq Machine-Translation model)"),h5e.forEach(t),hZe=i(S),Jn=n(S,"LI",{});var M7=s(Jn);Lre=n(M7,"STRONG",{});var tOr=s(Lre);pZe=r(tOr,"funnel"),tOr.forEach(t),uZe=r(M7," \u2014 "),tR=n(M7,"A",{href:!0});var aOr=s(tR);_Ze=r(aOr,"FunnelTokenizer"),aOr.forEach(t),bZe=r(M7," or "),aR=n(M7,"A",{href:!0});var nOr=s(aR);vZe=r(nOr,"FunnelTokenizerFast"),nOr.forEach(t),FZe=r(M7," (Funnel Transformer model)"),M7.forEach(t),TZe=i(S),Yn=n(S,"LI",{});var E7=s(Yn);xre=n(E7,"STRONG",{});var sOr=s(xre);MZe=r(sOr,"gpt2"),sOr.forEach(t),EZe=r(E7," \u2014 "),nR=n(E7,"A",{href:!0});var lOr=s(nR);CZe=r(lOr,"GPT2Tokenizer"),lOr.forEach(t),wZe=r(E7," or "),sR=n(E7,"A",{href:!0});var iOr=s(sR);AZe=r(iOr,"GPT2TokenizerFast"),iOr.forEach(t),yZe=r(E7," (OpenAI GPT-2 model)"),E7.forEach(t),LZe=i(S),Kn=n(S,"LI",{});var C7=s(Kn);$re=n(C7,"STRONG",{});var dOr=s($re);xZe=r(dOr,"gpt_neo"),dOr.forEach(t),$Ze=r(C7," \u2014 "),lR=n(C7,"A",{href:!0});var cOr=s(lR);kZe=r(cOr,"GPT2Tokenizer"),cOr.forEach(t),SZe=r(C7," or "),iR=n(C7,"A",{href:!0});var fOr=s(iR);RZe=r(fOr,"GPT2TokenizerFast"),fOr.forEach(t),BZe=r(C7," (GPT Neo model)"),C7.forEach(t),PZe=i(S),Zn=n(S,"LI",{});var w7=s(Zn);kre=n(w7,"STRONG",{});var mOr=s(kre);IZe=r(mOr,"gptj"),mOr.forEach(t),qZe=r(w7," \u2014 "),dR=n(w7,"A",{href:!0});var gOr=s(dR);NZe=r(gOr,"GPT2Tokenizer"),gOr.forEach(t),jZe=r(w7," or "),cR=n(w7,"A",{href:!0});var hOr=s(cR);DZe=r(hOr,"GPT2TokenizerFast"),hOr.forEach(t),GZe=r(w7," (GPT-J model)"),w7.forEach(t),OZe=i(S),es=n(S,"LI",{});var A7=s(es);Sre=n(A7,"STRONG",{});var pOr=s(Sre);VZe=r(pOr,"herbert"),pOr.forEach(t),XZe=r(A7," \u2014 "),fR=n(A7,"A",{href:!0});var uOr=s(fR);zZe=r(uOr,"HerbertTokenizer"),uOr.forEach(t),QZe=r(A7," or "),mR=n(A7,"A",{href:!0});var _Or=s(mR);WZe=r(_Or,"HerbertTokenizerFast"),_Or.forEach(t),HZe=r(A7," (HerBERT model)"),A7.forEach(t),UZe=i(S),yg=n(S,"LI",{});var p5e=s(yg);Rre=n(p5e,"STRONG",{});var bOr=s(Rre);JZe=r(bOr,"hubert"),bOr.forEach(t),YZe=r(p5e," \u2014 "),gR=n(p5e,"A",{href:!0});var vOr=s(gR);KZe=r(vOr,"Wav2Vec2CTCTokenizer"),vOr.forEach(t),ZZe=r(p5e," (Hubert model)"),p5e.forEach(t),eeo=i(S),os=n(S,"LI",{});var y7=s(os);Bre=n(y7,"STRONG",{});var FOr=s(Bre);oeo=r(FOr,"ibert"),FOr.forEach(t),reo=r(y7," \u2014 "),hR=n(y7,"A",{href:!0});var TOr=s(hR);teo=r(TOr,"RobertaTokenizer"),TOr.forEach(t),aeo=r(y7," or "),pR=n(y7,"A",{href:!0});var MOr=s(pR);neo=r(MOr,"RobertaTokenizerFast"),MOr.forEach(t),seo=r(y7," (I-BERT model)"),y7.forEach(t),leo=i(S),rs=n(S,"LI",{});var L7=s(rs);Pre=n(L7,"STRONG",{});var EOr=s(Pre);ieo=r(EOr,"layoutlm"),EOr.forEach(t),deo=r(L7," \u2014 "),uR=n(L7,"A",{href:!0});var COr=s(uR);ceo=r(COr,"LayoutLMTokenizer"),COr.forEach(t),feo=r(L7," or "),_R=n(L7,"A",{href:!0});var wOr=s(_R);meo=r(wOr,"LayoutLMTokenizerFast"),wOr.forEach(t),geo=r(L7," (LayoutLM model)"),L7.forEach(t),heo=i(S),ts=n(S,"LI",{});var x7=s(ts);Ire=n(x7,"STRONG",{});var AOr=s(Ire);peo=r(AOr,"layoutlmv2"),AOr.forEach(t),ueo=r(x7," \u2014 "),bR=n(x7,"A",{href:!0});var yOr=s(bR);_eo=r(yOr,"LayoutLMv2Tokenizer"),yOr.forEach(t),beo=r(x7," or "),vR=n(x7,"A",{href:!0});var LOr=s(vR);veo=r(LOr,"LayoutLMv2TokenizerFast"),LOr.forEach(t),Feo=r(x7," (LayoutLMv2 model)"),x7.forEach(t),Teo=i(S),as=n(S,"LI",{});var $7=s(as);qre=n($7,"STRONG",{});var xOr=s(qre);Meo=r(xOr,"layoutxlm"),xOr.forEach(t),Eeo=r($7," \u2014 "),FR=n($7,"A",{href:!0});var $Or=s(FR);Ceo=r($Or,"LayoutXLMTokenizer"),$Or.forEach(t),weo=r($7," or "),TR=n($7,"A",{href:!0});var kOr=s(TR);Aeo=r(kOr,"LayoutXLMTokenizerFast"),kOr.forEach(t),yeo=r($7," (LayoutXLM model)"),$7.forEach(t),Leo=i(S),ns=n(S,"LI",{});var k7=s(ns);Nre=n(k7,"STRONG",{});var SOr=s(Nre);xeo=r(SOr,"led"),SOr.forEach(t),$eo=r(k7," \u2014 "),MR=n(k7,"A",{href:!0});var ROr=s(MR);keo=r(ROr,"LEDTokenizer"),ROr.forEach(t),Seo=r(k7," or "),ER=n(k7,"A",{href:!0});var BOr=s(ER);Reo=r(BOr,"LEDTokenizerFast"),BOr.forEach(t),Beo=r(k7," (LED model)"),k7.forEach(t),Peo=i(S),ss=n(S,"LI",{});var S7=s(ss);jre=n(S7,"STRONG",{});var POr=s(jre);Ieo=r(POr,"longformer"),POr.forEach(t),qeo=r(S7," \u2014 "),CR=n(S7,"A",{href:!0});var IOr=s(CR);Neo=r(IOr,"LongformerTokenizer"),IOr.forEach(t),jeo=r(S7," or "),wR=n(S7,"A",{href:!0});var qOr=s(wR);Deo=r(qOr,"LongformerTokenizerFast"),qOr.forEach(t),Geo=r(S7," (Longformer model)"),S7.forEach(t),Oeo=i(S),Lg=n(S,"LI",{});var u5e=s(Lg);Dre=n(u5e,"STRONG",{});var NOr=s(Dre);Veo=r(NOr,"luke"),NOr.forEach(t),Xeo=r(u5e," \u2014 "),AR=n(u5e,"A",{href:!0});var jOr=s(AR);zeo=r(jOr,"LukeTokenizer"),jOr.forEach(t),Qeo=r(u5e," (LUKE model)"),u5e.forEach(t),Weo=i(S),ls=n(S,"LI",{});var R7=s(ls);Gre=n(R7,"STRONG",{});var DOr=s(Gre);Heo=r(DOr,"lxmert"),DOr.forEach(t),Ueo=r(R7," \u2014 "),yR=n(R7,"A",{href:!0});var GOr=s(yR);Jeo=r(GOr,"LxmertTokenizer"),GOr.forEach(t),Yeo=r(R7," or "),LR=n(R7,"A",{href:!0});var OOr=s(LR);Keo=r(OOr,"LxmertTokenizerFast"),OOr.forEach(t),Zeo=r(R7," (LXMERT model)"),R7.forEach(t),eoo=i(S),xg=n(S,"LI",{});var _5e=s(xg);Ore=n(_5e,"STRONG",{});var VOr=s(Ore);ooo=r(VOr,"m2m_100"),VOr.forEach(t),roo=r(_5e," \u2014 "),xR=n(_5e,"A",{href:!0});var XOr=s(xR);too=r(XOr,"M2M100Tokenizer"),XOr.forEach(t),aoo=r(_5e," (M2M100 model)"),_5e.forEach(t),noo=i(S),$g=n(S,"LI",{});var b5e=s($g);Vre=n(b5e,"STRONG",{});var zOr=s(Vre);soo=r(zOr,"marian"),zOr.forEach(t),loo=r(b5e," \u2014 "),$R=n(b5e,"A",{href:!0});var QOr=s($R);ioo=r(QOr,"MarianTokenizer"),QOr.forEach(t),doo=r(b5e," (Marian model)"),b5e.forEach(t),coo=i(S),is=n(S,"LI",{});var B7=s(is);Xre=n(B7,"STRONG",{});var WOr=s(Xre);foo=r(WOr,"mbart"),WOr.forEach(t),moo=r(B7," \u2014 "),kR=n(B7,"A",{href:!0});var HOr=s(kR);goo=r(HOr,"MBartTokenizer"),HOr.forEach(t),hoo=r(B7," or "),SR=n(B7,"A",{href:!0});var UOr=s(SR);poo=r(UOr,"MBartTokenizerFast"),UOr.forEach(t),uoo=r(B7," (mBART model)"),B7.forEach(t),_oo=i(S),ds=n(S,"LI",{});var P7=s(ds);zre=n(P7,"STRONG",{});var JOr=s(zre);boo=r(JOr,"mbart50"),JOr.forEach(t),voo=r(P7," \u2014 "),RR=n(P7,"A",{href:!0});var YOr=s(RR);Foo=r(YOr,"MBart50Tokenizer"),YOr.forEach(t),Too=r(P7," or "),BR=n(P7,"A",{href:!0});var KOr=s(BR);Moo=r(KOr,"MBart50TokenizerFast"),KOr.forEach(t),Eoo=r(P7," (mBART-50 model)"),P7.forEach(t),Coo=i(S),cs=n(S,"LI",{});var I7=s(cs);Qre=n(I7,"STRONG",{});var ZOr=s(Qre);woo=r(ZOr,"megatron-bert"),ZOr.forEach(t),Aoo=r(I7," \u2014 "),PR=n(I7,"A",{href:!0});var eVr=s(PR);yoo=r(eVr,"BertTokenizer"),eVr.forEach(t),Loo=r(I7," or "),IR=n(I7,"A",{href:!0});var oVr=s(IR);xoo=r(oVr,"BertTokenizerFast"),oVr.forEach(t),$oo=r(I7," (MegatronBert model)"),I7.forEach(t),koo=i(S),kg=n(S,"LI",{});var v5e=s(kg);Wre=n(v5e,"STRONG",{});var rVr=s(Wre);Soo=r(rVr,"mluke"),rVr.forEach(t),Roo=r(v5e," \u2014 "),qR=n(v5e,"A",{href:!0});var tVr=s(qR);Boo=r(tVr,"MLukeTokenizer"),tVr.forEach(t),Poo=r(v5e," (mLUKE model)"),v5e.forEach(t),Ioo=i(S),fs=n(S,"LI",{});var q7=s(fs);Hre=n(q7,"STRONG",{});var aVr=s(Hre);qoo=r(aVr,"mobilebert"),aVr.forEach(t),Noo=r(q7," \u2014 "),NR=n(q7,"A",{href:!0});var nVr=s(NR);joo=r(nVr,"MobileBertTokenizer"),nVr.forEach(t),Doo=r(q7," or "),jR=n(q7,"A",{href:!0});var sVr=s(jR);Goo=r(sVr,"MobileBertTokenizerFast"),sVr.forEach(t),Ooo=r(q7," (MobileBERT model)"),q7.forEach(t),Voo=i(S),ms=n(S,"LI",{});var N7=s(ms);Ure=n(N7,"STRONG",{});var lVr=s(Ure);Xoo=r(lVr,"mpnet"),lVr.forEach(t),zoo=r(N7," \u2014 "),DR=n(N7,"A",{href:!0});var iVr=s(DR);Qoo=r(iVr,"MPNetTokenizer"),iVr.forEach(t),Woo=r(N7," or "),GR=n(N7,"A",{href:!0});var dVr=s(GR);Hoo=r(dVr,"MPNetTokenizerFast"),dVr.forEach(t),Uoo=r(N7," (MPNet model)"),N7.forEach(t),Joo=i(S),gs=n(S,"LI",{});var j7=s(gs);Jre=n(j7,"STRONG",{});var cVr=s(Jre);Yoo=r(cVr,"mt5"),cVr.forEach(t),Koo=r(j7," \u2014 "),OR=n(j7,"A",{href:!0});var fVr=s(OR);Zoo=r(fVr,"MT5Tokenizer"),fVr.forEach(t),ero=r(j7," or "),VR=n(j7,"A",{href:!0});var mVr=s(VR);oro=r(mVr,"MT5TokenizerFast"),mVr.forEach(t),rro=r(j7," (mT5 model)"),j7.forEach(t),tro=i(S),hs=n(S,"LI",{});var D7=s(hs);Yre=n(D7,"STRONG",{});var gVr=s(Yre);aro=r(gVr,"nystromformer"),gVr.forEach(t),nro=r(D7," \u2014 "),XR=n(D7,"A",{href:!0});var hVr=s(XR);sro=r(hVr,"AlbertTokenizer"),hVr.forEach(t),lro=r(D7," or "),zR=n(D7,"A",{href:!0});var pVr=s(zR);iro=r(pVr,"AlbertTokenizerFast"),pVr.forEach(t),dro=r(D7," (Nystromformer model)"),D7.forEach(t),cro=i(S),ps=n(S,"LI",{});var G7=s(ps);Kre=n(G7,"STRONG",{});var uVr=s(Kre);fro=r(uVr,"openai-gpt"),uVr.forEach(t),mro=r(G7," \u2014 "),QR=n(G7,"A",{href:!0});var _Vr=s(QR);gro=r(_Vr,"OpenAIGPTTokenizer"),_Vr.forEach(t),hro=r(G7," or "),WR=n(G7,"A",{href:!0});var bVr=s(WR);pro=r(bVr,"OpenAIGPTTokenizerFast"),bVr.forEach(t),uro=r(G7," (OpenAI GPT model)"),G7.forEach(t),_ro=i(S),us=n(S,"LI",{});var O7=s(us);Zre=n(O7,"STRONG",{});var vVr=s(Zre);bro=r(vVr,"pegasus"),vVr.forEach(t),vro=r(O7," \u2014 "),HR=n(O7,"A",{href:!0});var FVr=s(HR);Fro=r(FVr,"PegasusTokenizer"),FVr.forEach(t),Tro=r(O7," or "),UR=n(O7,"A",{href:!0});var TVr=s(UR);Mro=r(TVr,"PegasusTokenizerFast"),TVr.forEach(t),Ero=r(O7," (Pegasus model)"),O7.forEach(t),Cro=i(S),Sg=n(S,"LI",{});var F5e=s(Sg);ete=n(F5e,"STRONG",{});var MVr=s(ete);wro=r(MVr,"perceiver"),MVr.forEach(t),Aro=r(F5e," \u2014 "),JR=n(F5e,"A",{href:!0});var EVr=s(JR);yro=r(EVr,"PerceiverTokenizer"),EVr.forEach(t),Lro=r(F5e," (Perceiver model)"),F5e.forEach(t),xro=i(S),Rg=n(S,"LI",{});var T5e=s(Rg);ote=n(T5e,"STRONG",{});var CVr=s(ote);$ro=r(CVr,"phobert"),CVr.forEach(t),kro=r(T5e," \u2014 "),YR=n(T5e,"A",{href:!0});var wVr=s(YR);Sro=r(wVr,"PhobertTokenizer"),wVr.forEach(t),Rro=r(T5e," (PhoBERT model)"),T5e.forEach(t),Bro=i(S),Bg=n(S,"LI",{});var M5e=s(Bg);rte=n(M5e,"STRONG",{});var AVr=s(rte);Pro=r(AVr,"plbart"),AVr.forEach(t),Iro=r(M5e," \u2014 "),KR=n(M5e,"A",{href:!0});var yVr=s(KR);qro=r(yVr,"PLBartTokenizer"),yVr.forEach(t),Nro=r(M5e," (PLBart model)"),M5e.forEach(t),jro=i(S),Pg=n(S,"LI",{});var E5e=s(Pg);tte=n(E5e,"STRONG",{});var LVr=s(tte);Dro=r(LVr,"prophetnet"),LVr.forEach(t),Gro=r(E5e," \u2014 "),ZR=n(E5e,"A",{href:!0});var xVr=s(ZR);Oro=r(xVr,"ProphetNetTokenizer"),xVr.forEach(t),Vro=r(E5e," (ProphetNet model)"),E5e.forEach(t),Xro=i(S),_s=n(S,"LI",{});var V7=s(_s);ate=n(V7,"STRONG",{});var $Vr=s(ate);zro=r($Vr,"qdqbert"),$Vr.forEach(t),Qro=r(V7," \u2014 "),eB=n(V7,"A",{href:!0});var kVr=s(eB);Wro=r(kVr,"BertTokenizer"),kVr.forEach(t),Hro=r(V7," or "),oB=n(V7,"A",{href:!0});var SVr=s(oB);Uro=r(SVr,"BertTokenizerFast"),SVr.forEach(t),Jro=r(V7," (QDQBert model)"),V7.forEach(t),Yro=i(S),Ig=n(S,"LI",{});var C5e=s(Ig);nte=n(C5e,"STRONG",{});var RVr=s(nte);Kro=r(RVr,"rag"),RVr.forEach(t),Zro=r(C5e," \u2014 "),rB=n(C5e,"A",{href:!0});var BVr=s(rB);eto=r(BVr,"RagTokenizer"),BVr.forEach(t),oto=r(C5e," (RAG model)"),C5e.forEach(t),rto=i(S),bs=n(S,"LI",{});var X7=s(bs);ste=n(X7,"STRONG",{});var PVr=s(ste);tto=r(PVr,"realm"),PVr.forEach(t),ato=r(X7," \u2014 "),tB=n(X7,"A",{href:!0});var IVr=s(tB);nto=r(IVr,"RealmTokenizer"),IVr.forEach(t),sto=r(X7," or "),aB=n(X7,"A",{href:!0});var qVr=s(aB);lto=r(qVr,"RealmTokenizerFast"),qVr.forEach(t),ito=r(X7," (Realm model)"),X7.forEach(t),dto=i(S),vs=n(S,"LI",{});var z7=s(vs);lte=n(z7,"STRONG",{});var NVr=s(lte);cto=r(NVr,"reformer"),NVr.forEach(t),fto=r(z7," \u2014 "),nB=n(z7,"A",{href:!0});var jVr=s(nB);mto=r(jVr,"ReformerTokenizer"),jVr.forEach(t),gto=r(z7," or "),sB=n(z7,"A",{href:!0});var DVr=s(sB);hto=r(DVr,"ReformerTokenizerFast"),DVr.forEach(t),pto=r(z7," (Reformer model)"),z7.forEach(t),uto=i(S),Fs=n(S,"LI",{});var Q7=s(Fs);ite=n(Q7,"STRONG",{});var GVr=s(ite);_to=r(GVr,"rembert"),GVr.forEach(t),bto=r(Q7," \u2014 "),lB=n(Q7,"A",{href:!0});var OVr=s(lB);vto=r(OVr,"RemBertTokenizer"),OVr.forEach(t),Fto=r(Q7," or "),iB=n(Q7,"A",{href:!0});var VVr=s(iB);Tto=r(VVr,"RemBertTokenizerFast"),VVr.forEach(t),Mto=r(Q7," (RemBERT model)"),Q7.forEach(t),Eto=i(S),Ts=n(S,"LI",{});var W7=s(Ts);dte=n(W7,"STRONG",{});var XVr=s(dte);Cto=r(XVr,"retribert"),XVr.forEach(t),wto=r(W7," \u2014 "),dB=n(W7,"A",{href:!0});var zVr=s(dB);Ato=r(zVr,"RetriBertTokenizer"),zVr.forEach(t),yto=r(W7," or "),cB=n(W7,"A",{href:!0});var QVr=s(cB);Lto=r(QVr,"RetriBertTokenizerFast"),QVr.forEach(t),xto=r(W7," (RetriBERT model)"),W7.forEach(t),$to=i(S),Ms=n(S,"LI",{});var H7=s(Ms);cte=n(H7,"STRONG",{});var WVr=s(cte);kto=r(WVr,"roberta"),WVr.forEach(t),Sto=r(H7," \u2014 "),fB=n(H7,"A",{href:!0});var HVr=s(fB);Rto=r(HVr,"RobertaTokenizer"),HVr.forEach(t),Bto=r(H7," or "),mB=n(H7,"A",{href:!0});var UVr=s(mB);Pto=r(UVr,"RobertaTokenizerFast"),UVr.forEach(t),Ito=r(H7," (RoBERTa model)"),H7.forEach(t),qto=i(S),Es=n(S,"LI",{});var U7=s(Es);fte=n(U7,"STRONG",{});var JVr=s(fte);Nto=r(JVr,"roformer"),JVr.forEach(t),jto=r(U7," \u2014 "),gB=n(U7,"A",{href:!0});var YVr=s(gB);Dto=r(YVr,"RoFormerTokenizer"),YVr.forEach(t),Gto=r(U7," or "),hB=n(U7,"A",{href:!0});var KVr=s(hB);Oto=r(KVr,"RoFormerTokenizerFast"),KVr.forEach(t),Vto=r(U7," (RoFormer model)"),U7.forEach(t),Xto=i(S),qg=n(S,"LI",{});var w5e=s(qg);mte=n(w5e,"STRONG",{});var ZVr=s(mte);zto=r(ZVr,"speech_to_text"),ZVr.forEach(t),Qto=r(w5e," \u2014 "),pB=n(w5e,"A",{href:!0});var eXr=s(pB);Wto=r(eXr,"Speech2TextTokenizer"),eXr.forEach(t),Hto=r(w5e," (Speech2Text model)"),w5e.forEach(t),Uto=i(S),Ng=n(S,"LI",{});var A5e=s(Ng);gte=n(A5e,"STRONG",{});var oXr=s(gte);Jto=r(oXr,"speech_to_text_2"),oXr.forEach(t),Yto=r(A5e," \u2014 "),uB=n(A5e,"A",{href:!0});var rXr=s(uB);Kto=r(rXr,"Speech2Text2Tokenizer"),rXr.forEach(t),Zto=r(A5e," (Speech2Text2 model)"),A5e.forEach(t),eao=i(S),Cs=n(S,"LI",{});var J7=s(Cs);hte=n(J7,"STRONG",{});var tXr=s(hte);oao=r(tXr,"splinter"),tXr.forEach(t),rao=r(J7," \u2014 "),_B=n(J7,"A",{href:!0});var aXr=s(_B);tao=r(aXr,"SplinterTokenizer"),aXr.forEach(t),aao=r(J7," or "),bB=n(J7,"A",{href:!0});var nXr=s(bB);nao=r(nXr,"SplinterTokenizerFast"),nXr.forEach(t),sao=r(J7," (Splinter model)"),J7.forEach(t),lao=i(S),ws=n(S,"LI",{});var Y7=s(ws);pte=n(Y7,"STRONG",{});var sXr=s(pte);iao=r(sXr,"squeezebert"),sXr.forEach(t),dao=r(Y7," \u2014 "),vB=n(Y7,"A",{href:!0});var lXr=s(vB);cao=r(lXr,"SqueezeBertTokenizer"),lXr.forEach(t),fao=r(Y7," or "),FB=n(Y7,"A",{href:!0});var iXr=s(FB);mao=r(iXr,"SqueezeBertTokenizerFast"),iXr.forEach(t),gao=r(Y7," (SqueezeBERT model)"),Y7.forEach(t),hao=i(S),As=n(S,"LI",{});var K7=s(As);ute=n(K7,"STRONG",{});var dXr=s(ute);pao=r(dXr,"t5"),dXr.forEach(t),uao=r(K7," \u2014 "),TB=n(K7,"A",{href:!0});var cXr=s(TB);_ao=r(cXr,"T5Tokenizer"),cXr.forEach(t),bao=r(K7," or "),MB=n(K7,"A",{href:!0});var fXr=s(MB);vao=r(fXr,"T5TokenizerFast"),fXr.forEach(t),Fao=r(K7," (T5 model)"),K7.forEach(t),Tao=i(S),jg=n(S,"LI",{});var y5e=s(jg);_te=n(y5e,"STRONG",{});var mXr=s(_te);Mao=r(mXr,"tapas"),mXr.forEach(t),Eao=r(y5e," \u2014 "),EB=n(y5e,"A",{href:!0});var gXr=s(EB);Cao=r(gXr,"TapasTokenizer"),gXr.forEach(t),wao=r(y5e," (TAPAS model)"),y5e.forEach(t),Aao=i(S),Dg=n(S,"LI",{});var L5e=s(Dg);bte=n(L5e,"STRONG",{});var hXr=s(bte);yao=r(hXr,"tapex"),hXr.forEach(t),Lao=r(L5e," \u2014 "),CB=n(L5e,"A",{href:!0});var pXr=s(CB);xao=r(pXr,"TapexTokenizer"),pXr.forEach(t),$ao=r(L5e," (TAPEX model)"),L5e.forEach(t),kao=i(S),Gg=n(S,"LI",{});var x5e=s(Gg);vte=n(x5e,"STRONG",{});var uXr=s(vte);Sao=r(uXr,"transfo-xl"),uXr.forEach(t),Rao=r(x5e," \u2014 "),wB=n(x5e,"A",{href:!0});var _Xr=s(wB);Bao=r(_Xr,"TransfoXLTokenizer"),_Xr.forEach(t),Pao=r(x5e," (Transformer-XL model)"),x5e.forEach(t),Iao=i(S),ys=n(S,"LI",{});var Z7=s(ys);Fte=n(Z7,"STRONG",{});var bXr=s(Fte);qao=r(bXr,"visual_bert"),bXr.forEach(t),Nao=r(Z7," \u2014 "),AB=n(Z7,"A",{href:!0});var vXr=s(AB);jao=r(vXr,"BertTokenizer"),vXr.forEach(t),Dao=r(Z7," or "),yB=n(Z7,"A",{href:!0});var FXr=s(yB);Gao=r(FXr,"BertTokenizerFast"),FXr.forEach(t),Oao=r(Z7," (VisualBert model)"),Z7.forEach(t),Vao=i(S),Og=n(S,"LI",{});var $5e=s(Og);Tte=n($5e,"STRONG",{});var TXr=s(Tte);Xao=r(TXr,"wav2vec2"),TXr.forEach(t),zao=r($5e," \u2014 "),LB=n($5e,"A",{href:!0});var MXr=s(LB);Qao=r(MXr,"Wav2Vec2CTCTokenizer"),MXr.forEach(t),Wao=r($5e," (Wav2Vec2 model)"),$5e.forEach(t),Hao=i(S),Vg=n(S,"LI",{});var k5e=s(Vg);Mte=n(k5e,"STRONG",{});var EXr=s(Mte);Uao=r(EXr,"wav2vec2_phoneme"),EXr.forEach(t),Jao=r(k5e," \u2014 "),xB=n(k5e,"A",{href:!0});var CXr=s(xB);Yao=r(CXr,"Wav2Vec2PhonemeCTCTokenizer"),CXr.forEach(t),Kao=r(k5e," (Wav2Vec2Phoneme model)"),k5e.forEach(t),Zao=i(S),Ls=n(S,"LI",{});var e$=s(Ls);Ete=n(e$,"STRONG",{});var wXr=s(Ete);eno=r(wXr,"xglm"),wXr.forEach(t),ono=r(e$," \u2014 "),$B=n(e$,"A",{href:!0});var AXr=s($B);rno=r(AXr,"XGLMTokenizer"),AXr.forEach(t),tno=r(e$," or "),kB=n(e$,"A",{href:!0});var yXr=s(kB);ano=r(yXr,"XGLMTokenizerFast"),yXr.forEach(t),nno=r(e$," (XGLM model)"),e$.forEach(t),sno=i(S),Xg=n(S,"LI",{});var S5e=s(Xg);Cte=n(S5e,"STRONG",{});var LXr=s(Cte);lno=r(LXr,"xlm"),LXr.forEach(t),ino=r(S5e," \u2014 "),SB=n(S5e,"A",{href:!0});var xXr=s(SB);dno=r(xXr,"XLMTokenizer"),xXr.forEach(t),cno=r(S5e," (XLM model)"),S5e.forEach(t),fno=i(S),zg=n(S,"LI",{});var R5e=s(zg);wte=n(R5e,"STRONG",{});var $Xr=s(wte);mno=r($Xr,"xlm-prophetnet"),$Xr.forEach(t),gno=r(R5e," \u2014 "),RB=n(R5e,"A",{href:!0});var kXr=s(RB);hno=r(kXr,"XLMProphetNetTokenizer"),kXr.forEach(t),pno=r(R5e," (XLMProphetNet model)"),R5e.forEach(t),uno=i(S),xs=n(S,"LI",{});var o$=s(xs);Ate=n(o$,"STRONG",{});var SXr=s(Ate);_no=r(SXr,"xlm-roberta"),SXr.forEach(t),bno=r(o$," \u2014 "),BB=n(o$,"A",{href:!0});var RXr=s(BB);vno=r(RXr,"XLMRobertaTokenizer"),RXr.forEach(t),Fno=r(o$," or "),PB=n(o$,"A",{href:!0});var BXr=s(PB);Tno=r(BXr,"XLMRobertaTokenizerFast"),BXr.forEach(t),Mno=r(o$," (XLM-RoBERTa model)"),o$.forEach(t),Eno=i(S),$s=n(S,"LI",{});var r$=s($s);yte=n(r$,"STRONG",{});var PXr=s(yte);Cno=r(PXr,"xlm-roberta-xl"),PXr.forEach(t),wno=r(r$," \u2014 "),IB=n(r$,"A",{href:!0});var IXr=s(IB);Ano=r(IXr,"RobertaTokenizer"),IXr.forEach(t),yno=r(r$," or "),qB=n(r$,"A",{href:!0});var qXr=s(qB);Lno=r(qXr,"RobertaTokenizerFast"),qXr.forEach(t),xno=r(r$," (XLM-RoBERTa-XL model)"),r$.forEach(t),$no=i(S),ks=n(S,"LI",{});var t$=s(ks);Lte=n(t$,"STRONG",{});var NXr=s(Lte);kno=r(NXr,"xlnet"),NXr.forEach(t),Sno=r(t$," \u2014 "),NB=n(t$,"A",{href:!0});var jXr=s(NB);Rno=r(jXr,"XLNetTokenizer"),jXr.forEach(t),Bno=r(t$," or "),jB=n(t$,"A",{href:!0});var DXr=s(jB);Pno=r(DXr,"XLNetTokenizerFast"),DXr.forEach(t),Ino=r(t$," (XLNet model)"),t$.forEach(t),qno=i(S),Ss=n(S,"LI",{});var a$=s(Ss);xte=n(a$,"STRONG",{});var GXr=s(xte);Nno=r(GXr,"yoso"),GXr.forEach(t),jno=r(a$," \u2014 "),DB=n(a$,"A",{href:!0});var OXr=s(DB);Dno=r(OXr,"AlbertTokenizer"),OXr.forEach(t),Gno=r(a$," or "),GB=n(a$,"A",{href:!0});var VXr=s(GB);Ono=r(VXr,"AlbertTokenizerFast"),VXr.forEach(t),Vno=r(a$," (YOSO model)"),a$.forEach(t),S.forEach(t),Xno=i(qs),T(Qg.$$.fragment,qs),qs.forEach(t),zno=i(Is),Wg=n(Is,"DIV",{class:!0});var Eqe=s(Wg);T(aA.$$.fragment,Eqe),Qno=i(Eqe),$te=n(Eqe,"P",{});var XXr=s($te);Wno=r(XXr,"Register a new tokenizer in this mapping."),XXr.forEach(t),Eqe.forEach(t),Is.forEach(t),CPe=i(f),vi=n(f,"H2",{class:!0});var Cqe=s(vi);Hg=n(Cqe,"A",{id:!0,class:!0,href:!0});var zXr=s(Hg);kte=n(zXr,"SPAN",{});var QXr=s(kte);T(nA.$$.fragment,QXr),QXr.forEach(t),zXr.forEach(t),Hno=i(Cqe),Ste=n(Cqe,"SPAN",{});var WXr=s(Ste);Uno=r(WXr,"AutoFeatureExtractor"),WXr.forEach(t),Cqe.forEach(t),wPe=i(f),Ao=n(f,"DIV",{class:!0});var Ns=s(Ao);T(sA.$$.fragment,Ns),Jno=i(Ns),lA=n(Ns,"P",{});var wqe=s(lA);Yno=r(wqe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),OB=n(wqe,"A",{href:!0});var HXr=s(OB);Kno=r(HXr,"AutoFeatureExtractor.from_pretrained()"),HXr.forEach(t),Zno=r(wqe," class method."),wqe.forEach(t),eso=i(Ns),iA=n(Ns,"P",{});var Aqe=s(iA);oso=r(Aqe,"This class cannot be instantiated directly using "),Rte=n(Aqe,"CODE",{});var UXr=s(Rte);rso=r(UXr,"__init__()"),UXr.forEach(t),tso=r(Aqe," (throws an error)."),Aqe.forEach(t),aso=i(Ns),Qe=n(Ns,"DIV",{class:!0});var Yt=s(Qe);T(dA.$$.fragment,Yt),nso=i(Yt),Bte=n(Yt,"P",{});var JXr=s(Bte);sso=r(JXr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),JXr.forEach(t),lso=i(Yt),wa=n(Yt,"P",{});var QC=s(wa);iso=r(QC,"The feature extractor class to instantiate is selected based on the "),Pte=n(QC,"CODE",{});var YXr=s(Pte);dso=r(YXr,"model_type"),YXr.forEach(t),cso=r(QC,` property of the config object
(either passed as an argument or loaded from `),Ite=n(QC,"CODE",{});var KXr=s(Ite);fso=r(KXr,"pretrained_model_name_or_path"),KXr.forEach(t),mso=r(QC,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),qte=n(QC,"CODE",{});var ZXr=s(qte);gso=r(ZXr,"pretrained_model_name_or_path"),ZXr.forEach(t),hso=r(QC,":"),QC.forEach(t),pso=i(Yt),te=n(Yt,"UL",{});var se=s(te);Ug=n(se,"LI",{});var B5e=s(Ug);Nte=n(B5e,"STRONG",{});var ezr=s(Nte);uso=r(ezr,"beit"),ezr.forEach(t),_so=r(B5e," \u2014 "),VB=n(B5e,"A",{href:!0});var ozr=s(VB);bso=r(ozr,"BeitFeatureExtractor"),ozr.forEach(t),vso=r(B5e," (BEiT model)"),B5e.forEach(t),Fso=i(se),Jg=n(se,"LI",{});var P5e=s(Jg);jte=n(P5e,"STRONG",{});var rzr=s(jte);Tso=r(rzr,"clip"),rzr.forEach(t),Mso=r(P5e," \u2014 "),XB=n(P5e,"A",{href:!0});var tzr=s(XB);Eso=r(tzr,"CLIPFeatureExtractor"),tzr.forEach(t),Cso=r(P5e," (CLIP model)"),P5e.forEach(t),wso=i(se),Yg=n(se,"LI",{});var I5e=s(Yg);Dte=n(I5e,"STRONG",{});var azr=s(Dte);Aso=r(azr,"convnext"),azr.forEach(t),yso=r(I5e," \u2014 "),zB=n(I5e,"A",{href:!0});var nzr=s(zB);Lso=r(nzr,"ConvNextFeatureExtractor"),nzr.forEach(t),xso=r(I5e," (ConvNext model)"),I5e.forEach(t),$so=i(se),Kg=n(se,"LI",{});var q5e=s(Kg);Gte=n(q5e,"STRONG",{});var szr=s(Gte);kso=r(szr,"data2vec-audio"),szr.forEach(t),Sso=r(q5e," \u2014 "),QB=n(q5e,"A",{href:!0});var lzr=s(QB);Rso=r(lzr,"Wav2Vec2FeatureExtractor"),lzr.forEach(t),Bso=r(q5e," (Data2VecAudio model)"),q5e.forEach(t),Pso=i(se),Zg=n(se,"LI",{});var N5e=s(Zg);Ote=n(N5e,"STRONG",{});var izr=s(Ote);Iso=r(izr,"data2vec-vision"),izr.forEach(t),qso=r(N5e," \u2014 "),WB=n(N5e,"A",{href:!0});var dzr=s(WB);Nso=r(dzr,"BeitFeatureExtractor"),dzr.forEach(t),jso=r(N5e," (Data2VecVision model)"),N5e.forEach(t),Dso=i(se),eh=n(se,"LI",{});var j5e=s(eh);Vte=n(j5e,"STRONG",{});var czr=s(Vte);Gso=r(czr,"deit"),czr.forEach(t),Oso=r(j5e," \u2014 "),HB=n(j5e,"A",{href:!0});var fzr=s(HB);Vso=r(fzr,"DeiTFeatureExtractor"),fzr.forEach(t),Xso=r(j5e," (DeiT model)"),j5e.forEach(t),zso=i(se),oh=n(se,"LI",{});var D5e=s(oh);Xte=n(D5e,"STRONG",{});var mzr=s(Xte);Qso=r(mzr,"detr"),mzr.forEach(t),Wso=r(D5e," \u2014 "),UB=n(D5e,"A",{href:!0});var gzr=s(UB);Hso=r(gzr,"DetrFeatureExtractor"),gzr.forEach(t),Uso=r(D5e," (DETR model)"),D5e.forEach(t),Jso=i(se),rh=n(se,"LI",{});var G5e=s(rh);zte=n(G5e,"STRONG",{});var hzr=s(zte);Yso=r(hzr,"dpt"),hzr.forEach(t),Kso=r(G5e," \u2014 "),JB=n(G5e,"A",{href:!0});var pzr=s(JB);Zso=r(pzr,"DPTFeatureExtractor"),pzr.forEach(t),elo=r(G5e," (DPT model)"),G5e.forEach(t),olo=i(se),th=n(se,"LI",{});var O5e=s(th);Qte=n(O5e,"STRONG",{});var uzr=s(Qte);rlo=r(uzr,"glpn"),uzr.forEach(t),tlo=r(O5e," \u2014 "),YB=n(O5e,"A",{href:!0});var _zr=s(YB);alo=r(_zr,"GLPNFeatureExtractor"),_zr.forEach(t),nlo=r(O5e," (GLPN model)"),O5e.forEach(t),slo=i(se),ah=n(se,"LI",{});var V5e=s(ah);Wte=n(V5e,"STRONG",{});var bzr=s(Wte);llo=r(bzr,"hubert"),bzr.forEach(t),ilo=r(V5e," \u2014 "),KB=n(V5e,"A",{href:!0});var vzr=s(KB);dlo=r(vzr,"Wav2Vec2FeatureExtractor"),vzr.forEach(t),clo=r(V5e," (Hubert model)"),V5e.forEach(t),flo=i(se),nh=n(se,"LI",{});var X5e=s(nh);Hte=n(X5e,"STRONG",{});var Fzr=s(Hte);mlo=r(Fzr,"layoutlmv2"),Fzr.forEach(t),glo=r(X5e," \u2014 "),ZB=n(X5e,"A",{href:!0});var Tzr=s(ZB);hlo=r(Tzr,"LayoutLMv2FeatureExtractor"),Tzr.forEach(t),plo=r(X5e," (LayoutLMv2 model)"),X5e.forEach(t),ulo=i(se),sh=n(se,"LI",{});var z5e=s(sh);Ute=n(z5e,"STRONG",{});var Mzr=s(Ute);_lo=r(Mzr,"maskformer"),Mzr.forEach(t),blo=r(z5e," \u2014 "),eP=n(z5e,"A",{href:!0});var Ezr=s(eP);vlo=r(Ezr,"MaskFormerFeatureExtractor"),Ezr.forEach(t),Flo=r(z5e," (MaskFormer model)"),z5e.forEach(t),Tlo=i(se),lh=n(se,"LI",{});var Q5e=s(lh);Jte=n(Q5e,"STRONG",{});var Czr=s(Jte);Mlo=r(Czr,"perceiver"),Czr.forEach(t),Elo=r(Q5e," \u2014 "),oP=n(Q5e,"A",{href:!0});var wzr=s(oP);Clo=r(wzr,"PerceiverFeatureExtractor"),wzr.forEach(t),wlo=r(Q5e," (Perceiver model)"),Q5e.forEach(t),Alo=i(se),ih=n(se,"LI",{});var W5e=s(ih);Yte=n(W5e,"STRONG",{});var Azr=s(Yte);ylo=r(Azr,"poolformer"),Azr.forEach(t),Llo=r(W5e," \u2014 "),rP=n(W5e,"A",{href:!0});var yzr=s(rP);xlo=r(yzr,"PoolFormerFeatureExtractor"),yzr.forEach(t),$lo=r(W5e," (PoolFormer model)"),W5e.forEach(t),klo=i(se),dh=n(se,"LI",{});var H5e=s(dh);Kte=n(H5e,"STRONG",{});var Lzr=s(Kte);Slo=r(Lzr,"regnet"),Lzr.forEach(t),Rlo=r(H5e," \u2014 "),tP=n(H5e,"A",{href:!0});var xzr=s(tP);Blo=r(xzr,"ConvNextFeatureExtractor"),xzr.forEach(t),Plo=r(H5e," (RegNet model)"),H5e.forEach(t),Ilo=i(se),ch=n(se,"LI",{});var U5e=s(ch);Zte=n(U5e,"STRONG",{});var $zr=s(Zte);qlo=r($zr,"resnet"),$zr.forEach(t),Nlo=r(U5e," \u2014 "),aP=n(U5e,"A",{href:!0});var kzr=s(aP);jlo=r(kzr,"ConvNextFeatureExtractor"),kzr.forEach(t),Dlo=r(U5e," (ResNet model)"),U5e.forEach(t),Glo=i(se),fh=n(se,"LI",{});var J5e=s(fh);eae=n(J5e,"STRONG",{});var Szr=s(eae);Olo=r(Szr,"segformer"),Szr.forEach(t),Vlo=r(J5e," \u2014 "),nP=n(J5e,"A",{href:!0});var Rzr=s(nP);Xlo=r(Rzr,"SegformerFeatureExtractor"),Rzr.forEach(t),zlo=r(J5e," (SegFormer model)"),J5e.forEach(t),Qlo=i(se),mh=n(se,"LI",{});var Y5e=s(mh);oae=n(Y5e,"STRONG",{});var Bzr=s(oae);Wlo=r(Bzr,"speech_to_text"),Bzr.forEach(t),Hlo=r(Y5e," \u2014 "),sP=n(Y5e,"A",{href:!0});var Pzr=s(sP);Ulo=r(Pzr,"Speech2TextFeatureExtractor"),Pzr.forEach(t),Jlo=r(Y5e," (Speech2Text model)"),Y5e.forEach(t),Ylo=i(se),gh=n(se,"LI",{});var K5e=s(gh);rae=n(K5e,"STRONG",{});var Izr=s(rae);Klo=r(Izr,"swin"),Izr.forEach(t),Zlo=r(K5e," \u2014 "),lP=n(K5e,"A",{href:!0});var qzr=s(lP);eio=r(qzr,"ViTFeatureExtractor"),qzr.forEach(t),oio=r(K5e," (Swin model)"),K5e.forEach(t),rio=i(se),hh=n(se,"LI",{});var Z5e=s(hh);tae=n(Z5e,"STRONG",{});var Nzr=s(tae);tio=r(Nzr,"van"),Nzr.forEach(t),aio=r(Z5e," \u2014 "),iP=n(Z5e,"A",{href:!0});var jzr=s(iP);nio=r(jzr,"ConvNextFeatureExtractor"),jzr.forEach(t),sio=r(Z5e," (VAN model)"),Z5e.forEach(t),lio=i(se),ph=n(se,"LI",{});var eCe=s(ph);aae=n(eCe,"STRONG",{});var Dzr=s(aae);iio=r(Dzr,"vit"),Dzr.forEach(t),dio=r(eCe," \u2014 "),dP=n(eCe,"A",{href:!0});var Gzr=s(dP);cio=r(Gzr,"ViTFeatureExtractor"),Gzr.forEach(t),fio=r(eCe," (ViT model)"),eCe.forEach(t),mio=i(se),uh=n(se,"LI",{});var oCe=s(uh);nae=n(oCe,"STRONG",{});var Ozr=s(nae);gio=r(Ozr,"vit_mae"),Ozr.forEach(t),hio=r(oCe," \u2014 "),cP=n(oCe,"A",{href:!0});var Vzr=s(cP);pio=r(Vzr,"ViTFeatureExtractor"),Vzr.forEach(t),uio=r(oCe," (ViTMAE model)"),oCe.forEach(t),_io=i(se),_h=n(se,"LI",{});var rCe=s(_h);sae=n(rCe,"STRONG",{});var Xzr=s(sae);bio=r(Xzr,"wav2vec2"),Xzr.forEach(t),vio=r(rCe," \u2014 "),fP=n(rCe,"A",{href:!0});var zzr=s(fP);Fio=r(zzr,"Wav2Vec2FeatureExtractor"),zzr.forEach(t),Tio=r(rCe," (Wav2Vec2 model)"),rCe.forEach(t),Mio=i(se),bh=n(se,"LI",{});var tCe=s(bh);lae=n(tCe,"STRONG",{});var Qzr=s(lae);Eio=r(Qzr,"yolos"),Qzr.forEach(t),Cio=r(tCe," \u2014 "),mP=n(tCe,"A",{href:!0});var Wzr=s(mP);wio=r(Wzr,"YolosFeatureExtractor"),Wzr.forEach(t),Aio=r(tCe," (YOLOS model)"),tCe.forEach(t),se.forEach(t),yio=i(Yt),T(vh.$$.fragment,Yt),Lio=i(Yt),T(Fh.$$.fragment,Yt),Yt.forEach(t),xio=i(Ns),Th=n(Ns,"DIV",{class:!0});var yqe=s(Th);T(cA.$$.fragment,yqe),$io=i(yqe),iae=n(yqe,"P",{});var Hzr=s(iae);kio=r(Hzr,"Register a new feature extractor for this class."),Hzr.forEach(t),yqe.forEach(t),Ns.forEach(t),APe=i(f),Fi=n(f,"H2",{class:!0});var Lqe=s(Fi);Mh=n(Lqe,"A",{id:!0,class:!0,href:!0});var Uzr=s(Mh);dae=n(Uzr,"SPAN",{});var Jzr=s(dae);T(fA.$$.fragment,Jzr),Jzr.forEach(t),Uzr.forEach(t),Sio=i(Lqe),cae=n(Lqe,"SPAN",{});var Yzr=s(cae);Rio=r(Yzr,"AutoProcessor"),Yzr.forEach(t),Lqe.forEach(t),yPe=i(f),yo=n(f,"DIV",{class:!0});var js=s(yo);T(mA.$$.fragment,js),Bio=i(js),gA=n(js,"P",{});var xqe=s(gA);Pio=r(xqe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),gP=n(xqe,"A",{href:!0});var Kzr=s(gP);Iio=r(Kzr,"AutoProcessor.from_pretrained()"),Kzr.forEach(t),qio=r(xqe," class method."),xqe.forEach(t),Nio=i(js),hA=n(js,"P",{});var $qe=s(hA);jio=r($qe,"This class cannot be instantiated directly using "),fae=n($qe,"CODE",{});var Zzr=s(fae);Dio=r(Zzr,"__init__()"),Zzr.forEach(t),Gio=r($qe," (throws an error)."),$qe.forEach(t),Oio=i(js),We=n(js,"DIV",{class:!0});var Kt=s(We);T(pA.$$.fragment,Kt),Vio=i(Kt),mae=n(Kt,"P",{});var eQr=s(mae);Xio=r(eQr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),eQr.forEach(t),zio=i(Kt),Ti=n(Kt,"P",{});var UY=s(Ti);Qio=r(UY,"The processor class to instantiate is selected based on the "),gae=n(UY,"CODE",{});var oQr=s(gae);Wio=r(oQr,"model_type"),oQr.forEach(t),Hio=r(UY,` property of the config object (either
passed as an argument or loaded from `),hae=n(UY,"CODE",{});var rQr=s(hae);Uio=r(rQr,"pretrained_model_name_or_path"),rQr.forEach(t),Jio=r(UY," if possible):"),UY.forEach(t),Yio=i(Kt),be=n(Kt,"UL",{});var Fe=s(be);Eh=n(Fe,"LI",{});var aCe=s(Eh);pae=n(aCe,"STRONG",{});var tQr=s(pae);Kio=r(tQr,"clip"),tQr.forEach(t),Zio=r(aCe," \u2014 "),hP=n(aCe,"A",{href:!0});var aQr=s(hP);edo=r(aQr,"CLIPProcessor"),aQr.forEach(t),odo=r(aCe," (CLIP model)"),aCe.forEach(t),rdo=i(Fe),Ch=n(Fe,"LI",{});var nCe=s(Ch);uae=n(nCe,"STRONG",{});var nQr=s(uae);tdo=r(nQr,"layoutlmv2"),nQr.forEach(t),ado=r(nCe," \u2014 "),pP=n(nCe,"A",{href:!0});var sQr=s(pP);ndo=r(sQr,"LayoutLMv2Processor"),sQr.forEach(t),sdo=r(nCe," (LayoutLMv2 model)"),nCe.forEach(t),ldo=i(Fe),wh=n(Fe,"LI",{});var sCe=s(wh);_ae=n(sCe,"STRONG",{});var lQr=s(_ae);ido=r(lQr,"layoutxlm"),lQr.forEach(t),ddo=r(sCe," \u2014 "),uP=n(sCe,"A",{href:!0});var iQr=s(uP);cdo=r(iQr,"LayoutXLMProcessor"),iQr.forEach(t),fdo=r(sCe," (LayoutXLM model)"),sCe.forEach(t),mdo=i(Fe),Ah=n(Fe,"LI",{});var lCe=s(Ah);bae=n(lCe,"STRONG",{});var dQr=s(bae);gdo=r(dQr,"sew"),dQr.forEach(t),hdo=r(lCe," \u2014 "),_P=n(lCe,"A",{href:!0});var cQr=s(_P);pdo=r(cQr,"Wav2Vec2Processor"),cQr.forEach(t),udo=r(lCe," (SEW model)"),lCe.forEach(t),_do=i(Fe),yh=n(Fe,"LI",{});var iCe=s(yh);vae=n(iCe,"STRONG",{});var fQr=s(vae);bdo=r(fQr,"sew-d"),fQr.forEach(t),vdo=r(iCe," \u2014 "),bP=n(iCe,"A",{href:!0});var mQr=s(bP);Fdo=r(mQr,"Wav2Vec2Processor"),mQr.forEach(t),Tdo=r(iCe," (SEW-D model)"),iCe.forEach(t),Mdo=i(Fe),Lh=n(Fe,"LI",{});var dCe=s(Lh);Fae=n(dCe,"STRONG",{});var gQr=s(Fae);Edo=r(gQr,"speech_to_text"),gQr.forEach(t),Cdo=r(dCe," \u2014 "),vP=n(dCe,"A",{href:!0});var hQr=s(vP);wdo=r(hQr,"Speech2TextProcessor"),hQr.forEach(t),Ado=r(dCe," (Speech2Text model)"),dCe.forEach(t),ydo=i(Fe),xh=n(Fe,"LI",{});var cCe=s(xh);Tae=n(cCe,"STRONG",{});var pQr=s(Tae);Ldo=r(pQr,"speech_to_text_2"),pQr.forEach(t),xdo=r(cCe," \u2014 "),FP=n(cCe,"A",{href:!0});var uQr=s(FP);$do=r(uQr,"Speech2Text2Processor"),uQr.forEach(t),kdo=r(cCe," (Speech2Text2 model)"),cCe.forEach(t),Sdo=i(Fe),$h=n(Fe,"LI",{});var fCe=s($h);Mae=n(fCe,"STRONG",{});var _Qr=s(Mae);Rdo=r(_Qr,"trocr"),_Qr.forEach(t),Bdo=r(fCe," \u2014 "),TP=n(fCe,"A",{href:!0});var bQr=s(TP);Pdo=r(bQr,"TrOCRProcessor"),bQr.forEach(t),Ido=r(fCe," (TrOCR model)"),fCe.forEach(t),qdo=i(Fe),kh=n(Fe,"LI",{});var mCe=s(kh);Eae=n(mCe,"STRONG",{});var vQr=s(Eae);Ndo=r(vQr,"unispeech"),vQr.forEach(t),jdo=r(mCe," \u2014 "),MP=n(mCe,"A",{href:!0});var FQr=s(MP);Ddo=r(FQr,"Wav2Vec2Processor"),FQr.forEach(t),Gdo=r(mCe," (UniSpeech model)"),mCe.forEach(t),Odo=i(Fe),Sh=n(Fe,"LI",{});var gCe=s(Sh);Cae=n(gCe,"STRONG",{});var TQr=s(Cae);Vdo=r(TQr,"unispeech-sat"),TQr.forEach(t),Xdo=r(gCe," \u2014 "),EP=n(gCe,"A",{href:!0});var MQr=s(EP);zdo=r(MQr,"Wav2Vec2Processor"),MQr.forEach(t),Qdo=r(gCe," (UniSpeechSat model)"),gCe.forEach(t),Wdo=i(Fe),Rh=n(Fe,"LI",{});var hCe=s(Rh);wae=n(hCe,"STRONG",{});var EQr=s(wae);Hdo=r(EQr,"vilt"),EQr.forEach(t),Udo=r(hCe," \u2014 "),CP=n(hCe,"A",{href:!0});var CQr=s(CP);Jdo=r(CQr,"ViltProcessor"),CQr.forEach(t),Ydo=r(hCe," (ViLT model)"),hCe.forEach(t),Kdo=i(Fe),Bh=n(Fe,"LI",{});var pCe=s(Bh);Aae=n(pCe,"STRONG",{});var wQr=s(Aae);Zdo=r(wQr,"vision-text-dual-encoder"),wQr.forEach(t),eco=r(pCe," \u2014 "),wP=n(pCe,"A",{href:!0});var AQr=s(wP);oco=r(AQr,"VisionTextDualEncoderProcessor"),AQr.forEach(t),rco=r(pCe," (VisionTextDualEncoder model)"),pCe.forEach(t),tco=i(Fe),Ph=n(Fe,"LI",{});var uCe=s(Ph);yae=n(uCe,"STRONG",{});var yQr=s(yae);aco=r(yQr,"wav2vec2"),yQr.forEach(t),nco=r(uCe," \u2014 "),AP=n(uCe,"A",{href:!0});var LQr=s(AP);sco=r(LQr,"Wav2Vec2Processor"),LQr.forEach(t),lco=r(uCe," (Wav2Vec2 model)"),uCe.forEach(t),ico=i(Fe),Ih=n(Fe,"LI",{});var _Ce=s(Ih);Lae=n(_Ce,"STRONG",{});var xQr=s(Lae);dco=r(xQr,"wavlm"),xQr.forEach(t),cco=r(_Ce," \u2014 "),yP=n(_Ce,"A",{href:!0});var $Qr=s(yP);fco=r($Qr,"Wav2Vec2Processor"),$Qr.forEach(t),mco=r(_Ce," (WavLM model)"),_Ce.forEach(t),Fe.forEach(t),gco=i(Kt),T(qh.$$.fragment,Kt),hco=i(Kt),T(Nh.$$.fragment,Kt),Kt.forEach(t),pco=i(js),jh=n(js,"DIV",{class:!0});var kqe=s(jh);T(uA.$$.fragment,kqe),uco=i(kqe),xae=n(kqe,"P",{});var kQr=s(xae);_co=r(kQr,"Register a new processor for this class."),kQr.forEach(t),kqe.forEach(t),js.forEach(t),LPe=i(f),Mi=n(f,"H2",{class:!0});var Sqe=s(Mi);Dh=n(Sqe,"A",{id:!0,class:!0,href:!0});var SQr=s(Dh);$ae=n(SQr,"SPAN",{});var RQr=s($ae);T(_A.$$.fragment,RQr),RQr.forEach(t),SQr.forEach(t),bco=i(Sqe),kae=n(Sqe,"SPAN",{});var BQr=s(kae);vco=r(BQr,"AutoModel"),BQr.forEach(t),Sqe.forEach(t),xPe=i(f),Lo=n(f,"DIV",{class:!0});var Ds=s(Lo);T(bA.$$.fragment,Ds),Fco=i(Ds),Ei=n(Ds,"P",{});var JY=s(Ei);Tco=r(JY,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),LP=n(JY,"A",{href:!0});var PQr=s(LP);Mco=r(PQr,"from_pretrained()"),PQr.forEach(t),Eco=r(JY," class method or the "),xP=n(JY,"A",{href:!0});var IQr=s(xP);Cco=r(IQr,"from_config()"),IQr.forEach(t),wco=r(JY,` class
method.`),JY.forEach(t),Aco=i(Ds),vA=n(Ds,"P",{});var Rqe=s(vA);yco=r(Rqe,"This class cannot be instantiated directly using "),Sae=n(Rqe,"CODE",{});var qQr=s(Sae);Lco=r(qQr,"__init__()"),qQr.forEach(t),xco=r(Rqe," (throws an error)."),Rqe.forEach(t),$co=i(Ds),ot=n(Ds,"DIV",{class:!0});var WC=s(ot);T(FA.$$.fragment,WC),kco=i(WC),Rae=n(WC,"P",{});var NQr=s(Rae);Sco=r(NQr,"Instantiates one of the base model classes of the library from a configuration."),NQr.forEach(t),Rco=i(WC),Ci=n(WC,"P",{});var YY=s(Ci);Bco=r(YY,`Note:
Loading a model from its configuration file does `),Bae=n(YY,"STRONG",{});var jQr=s(Bae);Pco=r(jQr,"not"),jQr.forEach(t),Ico=r(YY,` load the model weights. It only affects the
model\u2019s configuration. Use `),$P=n(YY,"A",{href:!0});var DQr=s($P);qco=r(DQr,"from_pretrained()"),DQr.forEach(t),Nco=r(YY," to load the model weights."),YY.forEach(t),jco=i(WC),T(Gh.$$.fragment,WC),WC.forEach(t),Dco=i(Ds),He=n(Ds,"DIV",{class:!0});var Zt=s(He);T(TA.$$.fragment,Zt),Gco=i(Zt),Pae=n(Zt,"P",{});var GQr=s(Pae);Oco=r(GQr,"Instantiate one of the base model classes of the library from a pretrained model."),GQr.forEach(t),Vco=i(Zt),Aa=n(Zt,"P",{});var HC=s(Aa);Xco=r(HC,"The model class to instantiate is selected based on the "),Iae=n(HC,"CODE",{});var OQr=s(Iae);zco=r(OQr,"model_type"),OQr.forEach(t),Qco=r(HC,` property of the config object (either
passed as an argument or loaded from `),qae=n(HC,"CODE",{});var VQr=s(qae);Wco=r(VQr,"pretrained_model_name_or_path"),VQr.forEach(t),Hco=r(HC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nae=n(HC,"CODE",{});var XQr=s(Nae);Uco=r(XQr,"pretrained_model_name_or_path"),XQr.forEach(t),Jco=r(HC,":"),HC.forEach(t),Yco=i(Zt),x=n(Zt,"UL",{});var $=s(x);Oh=n($,"LI",{});var bCe=s(Oh);jae=n(bCe,"STRONG",{});var zQr=s(jae);Kco=r(zQr,"albert"),zQr.forEach(t),Zco=r(bCe," \u2014 "),kP=n(bCe,"A",{href:!0});var QQr=s(kP);efo=r(QQr,"AlbertModel"),QQr.forEach(t),ofo=r(bCe," (ALBERT model)"),bCe.forEach(t),rfo=i($),Vh=n($,"LI",{});var vCe=s(Vh);Dae=n(vCe,"STRONG",{});var WQr=s(Dae);tfo=r(WQr,"bart"),WQr.forEach(t),afo=r(vCe," \u2014 "),SP=n(vCe,"A",{href:!0});var HQr=s(SP);nfo=r(HQr,"BartModel"),HQr.forEach(t),sfo=r(vCe," (BART model)"),vCe.forEach(t),lfo=i($),Xh=n($,"LI",{});var FCe=s(Xh);Gae=n(FCe,"STRONG",{});var UQr=s(Gae);ifo=r(UQr,"beit"),UQr.forEach(t),dfo=r(FCe," \u2014 "),RP=n(FCe,"A",{href:!0});var JQr=s(RP);cfo=r(JQr,"BeitModel"),JQr.forEach(t),ffo=r(FCe," (BEiT model)"),FCe.forEach(t),mfo=i($),zh=n($,"LI",{});var TCe=s(zh);Oae=n(TCe,"STRONG",{});var YQr=s(Oae);gfo=r(YQr,"bert"),YQr.forEach(t),hfo=r(TCe," \u2014 "),BP=n(TCe,"A",{href:!0});var KQr=s(BP);pfo=r(KQr,"BertModel"),KQr.forEach(t),ufo=r(TCe," (BERT model)"),TCe.forEach(t),_fo=i($),Qh=n($,"LI",{});var MCe=s(Qh);Vae=n(MCe,"STRONG",{});var ZQr=s(Vae);bfo=r(ZQr,"bert-generation"),ZQr.forEach(t),vfo=r(MCe," \u2014 "),PP=n(MCe,"A",{href:!0});var eWr=s(PP);Ffo=r(eWr,"BertGenerationEncoder"),eWr.forEach(t),Tfo=r(MCe," (Bert Generation model)"),MCe.forEach(t),Mfo=i($),Wh=n($,"LI",{});var ECe=s(Wh);Xae=n(ECe,"STRONG",{});var oWr=s(Xae);Efo=r(oWr,"big_bird"),oWr.forEach(t),Cfo=r(ECe," \u2014 "),IP=n(ECe,"A",{href:!0});var rWr=s(IP);wfo=r(rWr,"BigBirdModel"),rWr.forEach(t),Afo=r(ECe," (BigBird model)"),ECe.forEach(t),yfo=i($),Hh=n($,"LI",{});var CCe=s(Hh);zae=n(CCe,"STRONG",{});var tWr=s(zae);Lfo=r(tWr,"bigbird_pegasus"),tWr.forEach(t),xfo=r(CCe," \u2014 "),qP=n(CCe,"A",{href:!0});var aWr=s(qP);$fo=r(aWr,"BigBirdPegasusModel"),aWr.forEach(t),kfo=r(CCe," (BigBirdPegasus model)"),CCe.forEach(t),Sfo=i($),Uh=n($,"LI",{});var wCe=s(Uh);Qae=n(wCe,"STRONG",{});var nWr=s(Qae);Rfo=r(nWr,"blenderbot"),nWr.forEach(t),Bfo=r(wCe," \u2014 "),NP=n(wCe,"A",{href:!0});var sWr=s(NP);Pfo=r(sWr,"BlenderbotModel"),sWr.forEach(t),Ifo=r(wCe," (Blenderbot model)"),wCe.forEach(t),qfo=i($),Jh=n($,"LI",{});var ACe=s(Jh);Wae=n(ACe,"STRONG",{});var lWr=s(Wae);Nfo=r(lWr,"blenderbot-small"),lWr.forEach(t),jfo=r(ACe," \u2014 "),jP=n(ACe,"A",{href:!0});var iWr=s(jP);Dfo=r(iWr,"BlenderbotSmallModel"),iWr.forEach(t),Gfo=r(ACe," (BlenderbotSmall model)"),ACe.forEach(t),Ofo=i($),Yh=n($,"LI",{});var yCe=s(Yh);Hae=n(yCe,"STRONG",{});var dWr=s(Hae);Vfo=r(dWr,"camembert"),dWr.forEach(t),Xfo=r(yCe," \u2014 "),DP=n(yCe,"A",{href:!0});var cWr=s(DP);zfo=r(cWr,"CamembertModel"),cWr.forEach(t),Qfo=r(yCe," (CamemBERT model)"),yCe.forEach(t),Wfo=i($),Kh=n($,"LI",{});var LCe=s(Kh);Uae=n(LCe,"STRONG",{});var fWr=s(Uae);Hfo=r(fWr,"canine"),fWr.forEach(t),Ufo=r(LCe," \u2014 "),GP=n(LCe,"A",{href:!0});var mWr=s(GP);Jfo=r(mWr,"CanineModel"),mWr.forEach(t),Yfo=r(LCe," (Canine model)"),LCe.forEach(t),Kfo=i($),Zh=n($,"LI",{});var xCe=s(Zh);Jae=n(xCe,"STRONG",{});var gWr=s(Jae);Zfo=r(gWr,"clip"),gWr.forEach(t),emo=r(xCe," \u2014 "),OP=n(xCe,"A",{href:!0});var hWr=s(OP);omo=r(hWr,"CLIPModel"),hWr.forEach(t),rmo=r(xCe," (CLIP model)"),xCe.forEach(t),tmo=i($),ep=n($,"LI",{});var $Ce=s(ep);Yae=n($Ce,"STRONG",{});var pWr=s(Yae);amo=r(pWr,"convbert"),pWr.forEach(t),nmo=r($Ce," \u2014 "),VP=n($Ce,"A",{href:!0});var uWr=s(VP);smo=r(uWr,"ConvBertModel"),uWr.forEach(t),lmo=r($Ce," (ConvBERT model)"),$Ce.forEach(t),imo=i($),op=n($,"LI",{});var kCe=s(op);Kae=n(kCe,"STRONG",{});var _Wr=s(Kae);dmo=r(_Wr,"convnext"),_Wr.forEach(t),cmo=r(kCe," \u2014 "),XP=n(kCe,"A",{href:!0});var bWr=s(XP);fmo=r(bWr,"ConvNextModel"),bWr.forEach(t),mmo=r(kCe," (ConvNext model)"),kCe.forEach(t),gmo=i($),rp=n($,"LI",{});var SCe=s(rp);Zae=n(SCe,"STRONG",{});var vWr=s(Zae);hmo=r(vWr,"ctrl"),vWr.forEach(t),pmo=r(SCe," \u2014 "),zP=n(SCe,"A",{href:!0});var FWr=s(zP);umo=r(FWr,"CTRLModel"),FWr.forEach(t),_mo=r(SCe," (CTRL model)"),SCe.forEach(t),bmo=i($),tp=n($,"LI",{});var RCe=s(tp);ene=n(RCe,"STRONG",{});var TWr=s(ene);vmo=r(TWr,"data2vec-audio"),TWr.forEach(t),Fmo=r(RCe," \u2014 "),QP=n(RCe,"A",{href:!0});var MWr=s(QP);Tmo=r(MWr,"Data2VecAudioModel"),MWr.forEach(t),Mmo=r(RCe," (Data2VecAudio model)"),RCe.forEach(t),Emo=i($),ap=n($,"LI",{});var BCe=s(ap);one=n(BCe,"STRONG",{});var EWr=s(one);Cmo=r(EWr,"data2vec-text"),EWr.forEach(t),wmo=r(BCe," \u2014 "),WP=n(BCe,"A",{href:!0});var CWr=s(WP);Amo=r(CWr,"Data2VecTextModel"),CWr.forEach(t),ymo=r(BCe," (Data2VecText model)"),BCe.forEach(t),Lmo=i($),np=n($,"LI",{});var PCe=s(np);rne=n(PCe,"STRONG",{});var wWr=s(rne);xmo=r(wWr,"data2vec-vision"),wWr.forEach(t),$mo=r(PCe," \u2014 "),HP=n(PCe,"A",{href:!0});var AWr=s(HP);kmo=r(AWr,"Data2VecVisionModel"),AWr.forEach(t),Smo=r(PCe," (Data2VecVision model)"),PCe.forEach(t),Rmo=i($),sp=n($,"LI",{});var ICe=s(sp);tne=n(ICe,"STRONG",{});var yWr=s(tne);Bmo=r(yWr,"deberta"),yWr.forEach(t),Pmo=r(ICe," \u2014 "),UP=n(ICe,"A",{href:!0});var LWr=s(UP);Imo=r(LWr,"DebertaModel"),LWr.forEach(t),qmo=r(ICe," (DeBERTa model)"),ICe.forEach(t),Nmo=i($),lp=n($,"LI",{});var qCe=s(lp);ane=n(qCe,"STRONG",{});var xWr=s(ane);jmo=r(xWr,"deberta-v2"),xWr.forEach(t),Dmo=r(qCe," \u2014 "),JP=n(qCe,"A",{href:!0});var $Wr=s(JP);Gmo=r($Wr,"DebertaV2Model"),$Wr.forEach(t),Omo=r(qCe," (DeBERTa-v2 model)"),qCe.forEach(t),Vmo=i($),ip=n($,"LI",{});var NCe=s(ip);nne=n(NCe,"STRONG",{});var kWr=s(nne);Xmo=r(kWr,"decision_transformer"),kWr.forEach(t),zmo=r(NCe," \u2014 "),YP=n(NCe,"A",{href:!0});var SWr=s(YP);Qmo=r(SWr,"DecisionTransformerModel"),SWr.forEach(t),Wmo=r(NCe," (Decision Transformer model)"),NCe.forEach(t),Hmo=i($),dp=n($,"LI",{});var jCe=s(dp);sne=n(jCe,"STRONG",{});var RWr=s(sne);Umo=r(RWr,"deit"),RWr.forEach(t),Jmo=r(jCe," \u2014 "),KP=n(jCe,"A",{href:!0});var BWr=s(KP);Ymo=r(BWr,"DeiTModel"),BWr.forEach(t),Kmo=r(jCe," (DeiT model)"),jCe.forEach(t),Zmo=i($),cp=n($,"LI",{});var DCe=s(cp);lne=n(DCe,"STRONG",{});var PWr=s(lne);ego=r(PWr,"detr"),PWr.forEach(t),ogo=r(DCe," \u2014 "),ZP=n(DCe,"A",{href:!0});var IWr=s(ZP);rgo=r(IWr,"DetrModel"),IWr.forEach(t),tgo=r(DCe," (DETR model)"),DCe.forEach(t),ago=i($),fp=n($,"LI",{});var GCe=s(fp);ine=n(GCe,"STRONG",{});var qWr=s(ine);ngo=r(qWr,"distilbert"),qWr.forEach(t),sgo=r(GCe," \u2014 "),eI=n(GCe,"A",{href:!0});var NWr=s(eI);lgo=r(NWr,"DistilBertModel"),NWr.forEach(t),igo=r(GCe," (DistilBERT model)"),GCe.forEach(t),dgo=i($),mp=n($,"LI",{});var OCe=s(mp);dne=n(OCe,"STRONG",{});var jWr=s(dne);cgo=r(jWr,"dpr"),jWr.forEach(t),fgo=r(OCe," \u2014 "),oI=n(OCe,"A",{href:!0});var DWr=s(oI);mgo=r(DWr,"DPRQuestionEncoder"),DWr.forEach(t),ggo=r(OCe," (DPR model)"),OCe.forEach(t),hgo=i($),gp=n($,"LI",{});var VCe=s(gp);cne=n(VCe,"STRONG",{});var GWr=s(cne);pgo=r(GWr,"dpt"),GWr.forEach(t),ugo=r(VCe," \u2014 "),rI=n(VCe,"A",{href:!0});var OWr=s(rI);_go=r(OWr,"DPTModel"),OWr.forEach(t),bgo=r(VCe," (DPT model)"),VCe.forEach(t),vgo=i($),hp=n($,"LI",{});var XCe=s(hp);fne=n(XCe,"STRONG",{});var VWr=s(fne);Fgo=r(VWr,"electra"),VWr.forEach(t),Tgo=r(XCe," \u2014 "),tI=n(XCe,"A",{href:!0});var XWr=s(tI);Mgo=r(XWr,"ElectraModel"),XWr.forEach(t),Ego=r(XCe," (ELECTRA model)"),XCe.forEach(t),Cgo=i($),pp=n($,"LI",{});var zCe=s(pp);mne=n(zCe,"STRONG",{});var zWr=s(mne);wgo=r(zWr,"flaubert"),zWr.forEach(t),Ago=r(zCe," \u2014 "),aI=n(zCe,"A",{href:!0});var QWr=s(aI);ygo=r(QWr,"FlaubertModel"),QWr.forEach(t),Lgo=r(zCe," (FlauBERT model)"),zCe.forEach(t),xgo=i($),up=n($,"LI",{});var QCe=s(up);gne=n(QCe,"STRONG",{});var WWr=s(gne);$go=r(WWr,"fnet"),WWr.forEach(t),kgo=r(QCe," \u2014 "),nI=n(QCe,"A",{href:!0});var HWr=s(nI);Sgo=r(HWr,"FNetModel"),HWr.forEach(t),Rgo=r(QCe," (FNet model)"),QCe.forEach(t),Bgo=i($),_p=n($,"LI",{});var WCe=s(_p);hne=n(WCe,"STRONG",{});var UWr=s(hne);Pgo=r(UWr,"fsmt"),UWr.forEach(t),Igo=r(WCe," \u2014 "),sI=n(WCe,"A",{href:!0});var JWr=s(sI);qgo=r(JWr,"FSMTModel"),JWr.forEach(t),Ngo=r(WCe," (FairSeq Machine-Translation model)"),WCe.forEach(t),jgo=i($),Rs=n($,"LI",{});var n$=s(Rs);pne=n(n$,"STRONG",{});var YWr=s(pne);Dgo=r(YWr,"funnel"),YWr.forEach(t),Ggo=r(n$," \u2014 "),lI=n(n$,"A",{href:!0});var KWr=s(lI);Ogo=r(KWr,"FunnelModel"),KWr.forEach(t),Vgo=r(n$," or "),iI=n(n$,"A",{href:!0});var ZWr=s(iI);Xgo=r(ZWr,"FunnelBaseModel"),ZWr.forEach(t),zgo=r(n$," (Funnel Transformer model)"),n$.forEach(t),Qgo=i($),bp=n($,"LI",{});var HCe=s(bp);une=n(HCe,"STRONG",{});var eHr=s(une);Wgo=r(eHr,"glpn"),eHr.forEach(t),Hgo=r(HCe," \u2014 "),dI=n(HCe,"A",{href:!0});var oHr=s(dI);Ugo=r(oHr,"GLPNModel"),oHr.forEach(t),Jgo=r(HCe," (GLPN model)"),HCe.forEach(t),Ygo=i($),vp=n($,"LI",{});var UCe=s(vp);_ne=n(UCe,"STRONG",{});var rHr=s(_ne);Kgo=r(rHr,"gpt2"),rHr.forEach(t),Zgo=r(UCe," \u2014 "),cI=n(UCe,"A",{href:!0});var tHr=s(cI);eho=r(tHr,"GPT2Model"),tHr.forEach(t),oho=r(UCe," (OpenAI GPT-2 model)"),UCe.forEach(t),rho=i($),Fp=n($,"LI",{});var JCe=s(Fp);bne=n(JCe,"STRONG",{});var aHr=s(bne);tho=r(aHr,"gpt_neo"),aHr.forEach(t),aho=r(JCe," \u2014 "),fI=n(JCe,"A",{href:!0});var nHr=s(fI);nho=r(nHr,"GPTNeoModel"),nHr.forEach(t),sho=r(JCe," (GPT Neo model)"),JCe.forEach(t),lho=i($),Tp=n($,"LI",{});var YCe=s(Tp);vne=n(YCe,"STRONG",{});var sHr=s(vne);iho=r(sHr,"gptj"),sHr.forEach(t),dho=r(YCe," \u2014 "),mI=n(YCe,"A",{href:!0});var lHr=s(mI);cho=r(lHr,"GPTJModel"),lHr.forEach(t),fho=r(YCe," (GPT-J model)"),YCe.forEach(t),mho=i($),Mp=n($,"LI",{});var KCe=s(Mp);Fne=n(KCe,"STRONG",{});var iHr=s(Fne);gho=r(iHr,"hubert"),iHr.forEach(t),hho=r(KCe," \u2014 "),gI=n(KCe,"A",{href:!0});var dHr=s(gI);pho=r(dHr,"HubertModel"),dHr.forEach(t),uho=r(KCe," (Hubert model)"),KCe.forEach(t),_ho=i($),Ep=n($,"LI",{});var ZCe=s(Ep);Tne=n(ZCe,"STRONG",{});var cHr=s(Tne);bho=r(cHr,"ibert"),cHr.forEach(t),vho=r(ZCe," \u2014 "),hI=n(ZCe,"A",{href:!0});var fHr=s(hI);Fho=r(fHr,"IBertModel"),fHr.forEach(t),Tho=r(ZCe," (I-BERT model)"),ZCe.forEach(t),Mho=i($),Cp=n($,"LI",{});var e3e=s(Cp);Mne=n(e3e,"STRONG",{});var mHr=s(Mne);Eho=r(mHr,"imagegpt"),mHr.forEach(t),Cho=r(e3e," \u2014 "),pI=n(e3e,"A",{href:!0});var gHr=s(pI);who=r(gHr,"ImageGPTModel"),gHr.forEach(t),Aho=r(e3e," (ImageGPT model)"),e3e.forEach(t),yho=i($),wp=n($,"LI",{});var o3e=s(wp);Ene=n(o3e,"STRONG",{});var hHr=s(Ene);Lho=r(hHr,"layoutlm"),hHr.forEach(t),xho=r(o3e," \u2014 "),uI=n(o3e,"A",{href:!0});var pHr=s(uI);$ho=r(pHr,"LayoutLMModel"),pHr.forEach(t),kho=r(o3e," (LayoutLM model)"),o3e.forEach(t),Sho=i($),Ap=n($,"LI",{});var r3e=s(Ap);Cne=n(r3e,"STRONG",{});var uHr=s(Cne);Rho=r(uHr,"layoutlmv2"),uHr.forEach(t),Bho=r(r3e," \u2014 "),_I=n(r3e,"A",{href:!0});var _Hr=s(_I);Pho=r(_Hr,"LayoutLMv2Model"),_Hr.forEach(t),Iho=r(r3e," (LayoutLMv2 model)"),r3e.forEach(t),qho=i($),yp=n($,"LI",{});var t3e=s(yp);wne=n(t3e,"STRONG",{});var bHr=s(wne);Nho=r(bHr,"led"),bHr.forEach(t),jho=r(t3e," \u2014 "),bI=n(t3e,"A",{href:!0});var vHr=s(bI);Dho=r(vHr,"LEDModel"),vHr.forEach(t),Gho=r(t3e," (LED model)"),t3e.forEach(t),Oho=i($),Lp=n($,"LI",{});var a3e=s(Lp);Ane=n(a3e,"STRONG",{});var FHr=s(Ane);Vho=r(FHr,"longformer"),FHr.forEach(t),Xho=r(a3e," \u2014 "),vI=n(a3e,"A",{href:!0});var THr=s(vI);zho=r(THr,"LongformerModel"),THr.forEach(t),Qho=r(a3e," (Longformer model)"),a3e.forEach(t),Who=i($),xp=n($,"LI",{});var n3e=s(xp);yne=n(n3e,"STRONG",{});var MHr=s(yne);Hho=r(MHr,"luke"),MHr.forEach(t),Uho=r(n3e," \u2014 "),FI=n(n3e,"A",{href:!0});var EHr=s(FI);Jho=r(EHr,"LukeModel"),EHr.forEach(t),Yho=r(n3e," (LUKE model)"),n3e.forEach(t),Kho=i($),$p=n($,"LI",{});var s3e=s($p);Lne=n(s3e,"STRONG",{});var CHr=s(Lne);Zho=r(CHr,"lxmert"),CHr.forEach(t),epo=r(s3e," \u2014 "),TI=n(s3e,"A",{href:!0});var wHr=s(TI);opo=r(wHr,"LxmertModel"),wHr.forEach(t),rpo=r(s3e," (LXMERT model)"),s3e.forEach(t),tpo=i($),kp=n($,"LI",{});var l3e=s(kp);xne=n(l3e,"STRONG",{});var AHr=s(xne);apo=r(AHr,"m2m_100"),AHr.forEach(t),npo=r(l3e," \u2014 "),MI=n(l3e,"A",{href:!0});var yHr=s(MI);spo=r(yHr,"M2M100Model"),yHr.forEach(t),lpo=r(l3e," (M2M100 model)"),l3e.forEach(t),ipo=i($),Sp=n($,"LI",{});var i3e=s(Sp);$ne=n(i3e,"STRONG",{});var LHr=s($ne);dpo=r(LHr,"marian"),LHr.forEach(t),cpo=r(i3e," \u2014 "),EI=n(i3e,"A",{href:!0});var xHr=s(EI);fpo=r(xHr,"MarianModel"),xHr.forEach(t),mpo=r(i3e," (Marian model)"),i3e.forEach(t),gpo=i($),Rp=n($,"LI",{});var d3e=s(Rp);kne=n(d3e,"STRONG",{});var $Hr=s(kne);hpo=r($Hr,"maskformer"),$Hr.forEach(t),ppo=r(d3e," \u2014 "),CI=n(d3e,"A",{href:!0});var kHr=s(CI);upo=r(kHr,"MaskFormerModel"),kHr.forEach(t),_po=r(d3e," (MaskFormer model)"),d3e.forEach(t),bpo=i($),Bp=n($,"LI",{});var c3e=s(Bp);Sne=n(c3e,"STRONG",{});var SHr=s(Sne);vpo=r(SHr,"mbart"),SHr.forEach(t),Fpo=r(c3e," \u2014 "),wI=n(c3e,"A",{href:!0});var RHr=s(wI);Tpo=r(RHr,"MBartModel"),RHr.forEach(t),Mpo=r(c3e," (mBART model)"),c3e.forEach(t),Epo=i($),Pp=n($,"LI",{});var f3e=s(Pp);Rne=n(f3e,"STRONG",{});var BHr=s(Rne);Cpo=r(BHr,"megatron-bert"),BHr.forEach(t),wpo=r(f3e," \u2014 "),AI=n(f3e,"A",{href:!0});var PHr=s(AI);Apo=r(PHr,"MegatronBertModel"),PHr.forEach(t),ypo=r(f3e," (MegatronBert model)"),f3e.forEach(t),Lpo=i($),Ip=n($,"LI",{});var m3e=s(Ip);Bne=n(m3e,"STRONG",{});var IHr=s(Bne);xpo=r(IHr,"mobilebert"),IHr.forEach(t),$po=r(m3e," \u2014 "),yI=n(m3e,"A",{href:!0});var qHr=s(yI);kpo=r(qHr,"MobileBertModel"),qHr.forEach(t),Spo=r(m3e," (MobileBERT model)"),m3e.forEach(t),Rpo=i($),qp=n($,"LI",{});var g3e=s(qp);Pne=n(g3e,"STRONG",{});var NHr=s(Pne);Bpo=r(NHr,"mpnet"),NHr.forEach(t),Ppo=r(g3e," \u2014 "),LI=n(g3e,"A",{href:!0});var jHr=s(LI);Ipo=r(jHr,"MPNetModel"),jHr.forEach(t),qpo=r(g3e," (MPNet model)"),g3e.forEach(t),Npo=i($),Np=n($,"LI",{});var h3e=s(Np);Ine=n(h3e,"STRONG",{});var DHr=s(Ine);jpo=r(DHr,"mt5"),DHr.forEach(t),Dpo=r(h3e," \u2014 "),xI=n(h3e,"A",{href:!0});var GHr=s(xI);Gpo=r(GHr,"MT5Model"),GHr.forEach(t),Opo=r(h3e," (mT5 model)"),h3e.forEach(t),Vpo=i($),jp=n($,"LI",{});var p3e=s(jp);qne=n(p3e,"STRONG",{});var OHr=s(qne);Xpo=r(OHr,"nystromformer"),OHr.forEach(t),zpo=r(p3e," \u2014 "),$I=n(p3e,"A",{href:!0});var VHr=s($I);Qpo=r(VHr,"NystromformerModel"),VHr.forEach(t),Wpo=r(p3e," (Nystromformer model)"),p3e.forEach(t),Hpo=i($),Dp=n($,"LI",{});var u3e=s(Dp);Nne=n(u3e,"STRONG",{});var XHr=s(Nne);Upo=r(XHr,"openai-gpt"),XHr.forEach(t),Jpo=r(u3e," \u2014 "),kI=n(u3e,"A",{href:!0});var zHr=s(kI);Ypo=r(zHr,"OpenAIGPTModel"),zHr.forEach(t),Kpo=r(u3e," (OpenAI GPT model)"),u3e.forEach(t),Zpo=i($),Gp=n($,"LI",{});var _3e=s(Gp);jne=n(_3e,"STRONG",{});var QHr=s(jne);euo=r(QHr,"pegasus"),QHr.forEach(t),ouo=r(_3e," \u2014 "),SI=n(_3e,"A",{href:!0});var WHr=s(SI);ruo=r(WHr,"PegasusModel"),WHr.forEach(t),tuo=r(_3e," (Pegasus model)"),_3e.forEach(t),auo=i($),Op=n($,"LI",{});var b3e=s(Op);Dne=n(b3e,"STRONG",{});var HHr=s(Dne);nuo=r(HHr,"perceiver"),HHr.forEach(t),suo=r(b3e," \u2014 "),RI=n(b3e,"A",{href:!0});var UHr=s(RI);luo=r(UHr,"PerceiverModel"),UHr.forEach(t),iuo=r(b3e," (Perceiver model)"),b3e.forEach(t),duo=i($),Vp=n($,"LI",{});var v3e=s(Vp);Gne=n(v3e,"STRONG",{});var JHr=s(Gne);cuo=r(JHr,"plbart"),JHr.forEach(t),fuo=r(v3e," \u2014 "),BI=n(v3e,"A",{href:!0});var YHr=s(BI);muo=r(YHr,"PLBartModel"),YHr.forEach(t),guo=r(v3e," (PLBart model)"),v3e.forEach(t),huo=i($),Xp=n($,"LI",{});var F3e=s(Xp);One=n(F3e,"STRONG",{});var KHr=s(One);puo=r(KHr,"poolformer"),KHr.forEach(t),uuo=r(F3e," \u2014 "),PI=n(F3e,"A",{href:!0});var ZHr=s(PI);_uo=r(ZHr,"PoolFormerModel"),ZHr.forEach(t),buo=r(F3e," (PoolFormer model)"),F3e.forEach(t),vuo=i($),zp=n($,"LI",{});var T3e=s(zp);Vne=n(T3e,"STRONG",{});var eUr=s(Vne);Fuo=r(eUr,"prophetnet"),eUr.forEach(t),Tuo=r(T3e," \u2014 "),II=n(T3e,"A",{href:!0});var oUr=s(II);Muo=r(oUr,"ProphetNetModel"),oUr.forEach(t),Euo=r(T3e," (ProphetNet model)"),T3e.forEach(t),Cuo=i($),Qp=n($,"LI",{});var M3e=s(Qp);Xne=n(M3e,"STRONG",{});var rUr=s(Xne);wuo=r(rUr,"qdqbert"),rUr.forEach(t),Auo=r(M3e," \u2014 "),qI=n(M3e,"A",{href:!0});var tUr=s(qI);yuo=r(tUr,"QDQBertModel"),tUr.forEach(t),Luo=r(M3e," (QDQBert model)"),M3e.forEach(t),xuo=i($),Wp=n($,"LI",{});var E3e=s(Wp);zne=n(E3e,"STRONG",{});var aUr=s(zne);$uo=r(aUr,"reformer"),aUr.forEach(t),kuo=r(E3e," \u2014 "),NI=n(E3e,"A",{href:!0});var nUr=s(NI);Suo=r(nUr,"ReformerModel"),nUr.forEach(t),Ruo=r(E3e," (Reformer model)"),E3e.forEach(t),Buo=i($),Hp=n($,"LI",{});var C3e=s(Hp);Qne=n(C3e,"STRONG",{});var sUr=s(Qne);Puo=r(sUr,"regnet"),sUr.forEach(t),Iuo=r(C3e," \u2014 "),jI=n(C3e,"A",{href:!0});var lUr=s(jI);quo=r(lUr,"RegNetModel"),lUr.forEach(t),Nuo=r(C3e," (RegNet model)"),C3e.forEach(t),juo=i($),Up=n($,"LI",{});var w3e=s(Up);Wne=n(w3e,"STRONG",{});var iUr=s(Wne);Duo=r(iUr,"rembert"),iUr.forEach(t),Guo=r(w3e," \u2014 "),DI=n(w3e,"A",{href:!0});var dUr=s(DI);Ouo=r(dUr,"RemBertModel"),dUr.forEach(t),Vuo=r(w3e," (RemBERT model)"),w3e.forEach(t),Xuo=i($),Jp=n($,"LI",{});var A3e=s(Jp);Hne=n(A3e,"STRONG",{});var cUr=s(Hne);zuo=r(cUr,"resnet"),cUr.forEach(t),Quo=r(A3e," \u2014 "),GI=n(A3e,"A",{href:!0});var fUr=s(GI);Wuo=r(fUr,"ResNetModel"),fUr.forEach(t),Huo=r(A3e," (ResNet model)"),A3e.forEach(t),Uuo=i($),Yp=n($,"LI",{});var y3e=s(Yp);Une=n(y3e,"STRONG",{});var mUr=s(Une);Juo=r(mUr,"retribert"),mUr.forEach(t),Yuo=r(y3e," \u2014 "),OI=n(y3e,"A",{href:!0});var gUr=s(OI);Kuo=r(gUr,"RetriBertModel"),gUr.forEach(t),Zuo=r(y3e," (RetriBERT model)"),y3e.forEach(t),e_o=i($),Kp=n($,"LI",{});var L3e=s(Kp);Jne=n(L3e,"STRONG",{});var hUr=s(Jne);o_o=r(hUr,"roberta"),hUr.forEach(t),r_o=r(L3e," \u2014 "),VI=n(L3e,"A",{href:!0});var pUr=s(VI);t_o=r(pUr,"RobertaModel"),pUr.forEach(t),a_o=r(L3e," (RoBERTa model)"),L3e.forEach(t),n_o=i($),Zp=n($,"LI",{});var x3e=s(Zp);Yne=n(x3e,"STRONG",{});var uUr=s(Yne);s_o=r(uUr,"roformer"),uUr.forEach(t),l_o=r(x3e," \u2014 "),XI=n(x3e,"A",{href:!0});var _Ur=s(XI);i_o=r(_Ur,"RoFormerModel"),_Ur.forEach(t),d_o=r(x3e," (RoFormer model)"),x3e.forEach(t),c_o=i($),eu=n($,"LI",{});var $3e=s(eu);Kne=n($3e,"STRONG",{});var bUr=s(Kne);f_o=r(bUr,"segformer"),bUr.forEach(t),m_o=r($3e," \u2014 "),zI=n($3e,"A",{href:!0});var vUr=s(zI);g_o=r(vUr,"SegformerModel"),vUr.forEach(t),h_o=r($3e," (SegFormer model)"),$3e.forEach(t),p_o=i($),ou=n($,"LI",{});var k3e=s(ou);Zne=n(k3e,"STRONG",{});var FUr=s(Zne);u_o=r(FUr,"sew"),FUr.forEach(t),__o=r(k3e," \u2014 "),QI=n(k3e,"A",{href:!0});var TUr=s(QI);b_o=r(TUr,"SEWModel"),TUr.forEach(t),v_o=r(k3e," (SEW model)"),k3e.forEach(t),F_o=i($),ru=n($,"LI",{});var S3e=s(ru);ese=n(S3e,"STRONG",{});var MUr=s(ese);T_o=r(MUr,"sew-d"),MUr.forEach(t),M_o=r(S3e," \u2014 "),WI=n(S3e,"A",{href:!0});var EUr=s(WI);E_o=r(EUr,"SEWDModel"),EUr.forEach(t),C_o=r(S3e," (SEW-D model)"),S3e.forEach(t),w_o=i($),tu=n($,"LI",{});var R3e=s(tu);ose=n(R3e,"STRONG",{});var CUr=s(ose);A_o=r(CUr,"speech_to_text"),CUr.forEach(t),y_o=r(R3e," \u2014 "),HI=n(R3e,"A",{href:!0});var wUr=s(HI);L_o=r(wUr,"Speech2TextModel"),wUr.forEach(t),x_o=r(R3e," (Speech2Text model)"),R3e.forEach(t),$_o=i($),au=n($,"LI",{});var B3e=s(au);rse=n(B3e,"STRONG",{});var AUr=s(rse);k_o=r(AUr,"splinter"),AUr.forEach(t),S_o=r(B3e," \u2014 "),UI=n(B3e,"A",{href:!0});var yUr=s(UI);R_o=r(yUr,"SplinterModel"),yUr.forEach(t),B_o=r(B3e," (Splinter model)"),B3e.forEach(t),P_o=i($),nu=n($,"LI",{});var P3e=s(nu);tse=n(P3e,"STRONG",{});var LUr=s(tse);I_o=r(LUr,"squeezebert"),LUr.forEach(t),q_o=r(P3e," \u2014 "),JI=n(P3e,"A",{href:!0});var xUr=s(JI);N_o=r(xUr,"SqueezeBertModel"),xUr.forEach(t),j_o=r(P3e," (SqueezeBERT model)"),P3e.forEach(t),D_o=i($),su=n($,"LI",{});var I3e=s(su);ase=n(I3e,"STRONG",{});var $Ur=s(ase);G_o=r($Ur,"swin"),$Ur.forEach(t),O_o=r(I3e," \u2014 "),YI=n(I3e,"A",{href:!0});var kUr=s(YI);V_o=r(kUr,"SwinModel"),kUr.forEach(t),X_o=r(I3e," (Swin model)"),I3e.forEach(t),z_o=i($),lu=n($,"LI",{});var q3e=s(lu);nse=n(q3e,"STRONG",{});var SUr=s(nse);Q_o=r(SUr,"t5"),SUr.forEach(t),W_o=r(q3e," \u2014 "),KI=n(q3e,"A",{href:!0});var RUr=s(KI);H_o=r(RUr,"T5Model"),RUr.forEach(t),U_o=r(q3e," (T5 model)"),q3e.forEach(t),J_o=i($),iu=n($,"LI",{});var N3e=s(iu);sse=n(N3e,"STRONG",{});var BUr=s(sse);Y_o=r(BUr,"tapas"),BUr.forEach(t),K_o=r(N3e," \u2014 "),ZI=n(N3e,"A",{href:!0});var PUr=s(ZI);Z_o=r(PUr,"TapasModel"),PUr.forEach(t),e1o=r(N3e," (TAPAS model)"),N3e.forEach(t),o1o=i($),du=n($,"LI",{});var j3e=s(du);lse=n(j3e,"STRONG",{});var IUr=s(lse);r1o=r(IUr,"transfo-xl"),IUr.forEach(t),t1o=r(j3e," \u2014 "),eq=n(j3e,"A",{href:!0});var qUr=s(eq);a1o=r(qUr,"TransfoXLModel"),qUr.forEach(t),n1o=r(j3e," (Transformer-XL model)"),j3e.forEach(t),s1o=i($),cu=n($,"LI",{});var D3e=s(cu);ise=n(D3e,"STRONG",{});var NUr=s(ise);l1o=r(NUr,"unispeech"),NUr.forEach(t),i1o=r(D3e," \u2014 "),oq=n(D3e,"A",{href:!0});var jUr=s(oq);d1o=r(jUr,"UniSpeechModel"),jUr.forEach(t),c1o=r(D3e," (UniSpeech model)"),D3e.forEach(t),f1o=i($),fu=n($,"LI",{});var G3e=s(fu);dse=n(G3e,"STRONG",{});var DUr=s(dse);m1o=r(DUr,"unispeech-sat"),DUr.forEach(t),g1o=r(G3e," \u2014 "),rq=n(G3e,"A",{href:!0});var GUr=s(rq);h1o=r(GUr,"UniSpeechSatModel"),GUr.forEach(t),p1o=r(G3e," (UniSpeechSat model)"),G3e.forEach(t),u1o=i($),mu=n($,"LI",{});var O3e=s(mu);cse=n(O3e,"STRONG",{});var OUr=s(cse);_1o=r(OUr,"van"),OUr.forEach(t),b1o=r(O3e," \u2014 "),tq=n(O3e,"A",{href:!0});var VUr=s(tq);v1o=r(VUr,"VanModel"),VUr.forEach(t),F1o=r(O3e," (VAN model)"),O3e.forEach(t),T1o=i($),gu=n($,"LI",{});var V3e=s(gu);fse=n(V3e,"STRONG",{});var XUr=s(fse);M1o=r(XUr,"vilt"),XUr.forEach(t),E1o=r(V3e," \u2014 "),aq=n(V3e,"A",{href:!0});var zUr=s(aq);C1o=r(zUr,"ViltModel"),zUr.forEach(t),w1o=r(V3e," (ViLT model)"),V3e.forEach(t),A1o=i($),hu=n($,"LI",{});var X3e=s(hu);mse=n(X3e,"STRONG",{});var QUr=s(mse);y1o=r(QUr,"vision-text-dual-encoder"),QUr.forEach(t),L1o=r(X3e," \u2014 "),nq=n(X3e,"A",{href:!0});var WUr=s(nq);x1o=r(WUr,"VisionTextDualEncoderModel"),WUr.forEach(t),$1o=r(X3e," (VisionTextDualEncoder model)"),X3e.forEach(t),k1o=i($),pu=n($,"LI",{});var z3e=s(pu);gse=n(z3e,"STRONG",{});var HUr=s(gse);S1o=r(HUr,"visual_bert"),HUr.forEach(t),R1o=r(z3e," \u2014 "),sq=n(z3e,"A",{href:!0});var UUr=s(sq);B1o=r(UUr,"VisualBertModel"),UUr.forEach(t),P1o=r(z3e," (VisualBert model)"),z3e.forEach(t),I1o=i($),uu=n($,"LI",{});var Q3e=s(uu);hse=n(Q3e,"STRONG",{});var JUr=s(hse);q1o=r(JUr,"vit"),JUr.forEach(t),N1o=r(Q3e," \u2014 "),lq=n(Q3e,"A",{href:!0});var YUr=s(lq);j1o=r(YUr,"ViTModel"),YUr.forEach(t),D1o=r(Q3e," (ViT model)"),Q3e.forEach(t),G1o=i($),_u=n($,"LI",{});var W3e=s(_u);pse=n(W3e,"STRONG",{});var KUr=s(pse);O1o=r(KUr,"vit_mae"),KUr.forEach(t),V1o=r(W3e," \u2014 "),iq=n(W3e,"A",{href:!0});var ZUr=s(iq);X1o=r(ZUr,"ViTMAEModel"),ZUr.forEach(t),z1o=r(W3e," (ViTMAE model)"),W3e.forEach(t),Q1o=i($),bu=n($,"LI",{});var H3e=s(bu);use=n(H3e,"STRONG",{});var eJr=s(use);W1o=r(eJr,"wav2vec2"),eJr.forEach(t),H1o=r(H3e," \u2014 "),dq=n(H3e,"A",{href:!0});var oJr=s(dq);U1o=r(oJr,"Wav2Vec2Model"),oJr.forEach(t),J1o=r(H3e," (Wav2Vec2 model)"),H3e.forEach(t),Y1o=i($),vu=n($,"LI",{});var U3e=s(vu);_se=n(U3e,"STRONG",{});var rJr=s(_se);K1o=r(rJr,"wavlm"),rJr.forEach(t),Z1o=r(U3e," \u2014 "),cq=n(U3e,"A",{href:!0});var tJr=s(cq);e8o=r(tJr,"WavLMModel"),tJr.forEach(t),o8o=r(U3e," (WavLM model)"),U3e.forEach(t),r8o=i($),Fu=n($,"LI",{});var J3e=s(Fu);bse=n(J3e,"STRONG",{});var aJr=s(bse);t8o=r(aJr,"xglm"),aJr.forEach(t),a8o=r(J3e," \u2014 "),fq=n(J3e,"A",{href:!0});var nJr=s(fq);n8o=r(nJr,"XGLMModel"),nJr.forEach(t),s8o=r(J3e," (XGLM model)"),J3e.forEach(t),l8o=i($),Tu=n($,"LI",{});var Y3e=s(Tu);vse=n(Y3e,"STRONG",{});var sJr=s(vse);i8o=r(sJr,"xlm"),sJr.forEach(t),d8o=r(Y3e," \u2014 "),mq=n(Y3e,"A",{href:!0});var lJr=s(mq);c8o=r(lJr,"XLMModel"),lJr.forEach(t),f8o=r(Y3e," (XLM model)"),Y3e.forEach(t),m8o=i($),Mu=n($,"LI",{});var K3e=s(Mu);Fse=n(K3e,"STRONG",{});var iJr=s(Fse);g8o=r(iJr,"xlm-prophetnet"),iJr.forEach(t),h8o=r(K3e," \u2014 "),gq=n(K3e,"A",{href:!0});var dJr=s(gq);p8o=r(dJr,"XLMProphetNetModel"),dJr.forEach(t),u8o=r(K3e," (XLMProphetNet model)"),K3e.forEach(t),_8o=i($),Eu=n($,"LI",{});var Z3e=s(Eu);Tse=n(Z3e,"STRONG",{});var cJr=s(Tse);b8o=r(cJr,"xlm-roberta"),cJr.forEach(t),v8o=r(Z3e," \u2014 "),hq=n(Z3e,"A",{href:!0});var fJr=s(hq);F8o=r(fJr,"XLMRobertaModel"),fJr.forEach(t),T8o=r(Z3e," (XLM-RoBERTa model)"),Z3e.forEach(t),M8o=i($),Cu=n($,"LI",{});var ewe=s(Cu);Mse=n(ewe,"STRONG",{});var mJr=s(Mse);E8o=r(mJr,"xlm-roberta-xl"),mJr.forEach(t),C8o=r(ewe," \u2014 "),pq=n(ewe,"A",{href:!0});var gJr=s(pq);w8o=r(gJr,"XLMRobertaXLModel"),gJr.forEach(t),A8o=r(ewe," (XLM-RoBERTa-XL model)"),ewe.forEach(t),y8o=i($),wu=n($,"LI",{});var owe=s(wu);Ese=n(owe,"STRONG",{});var hJr=s(Ese);L8o=r(hJr,"xlnet"),hJr.forEach(t),x8o=r(owe," \u2014 "),uq=n(owe,"A",{href:!0});var pJr=s(uq);$8o=r(pJr,"XLNetModel"),pJr.forEach(t),k8o=r(owe," (XLNet model)"),owe.forEach(t),S8o=i($),Au=n($,"LI",{});var rwe=s(Au);Cse=n(rwe,"STRONG",{});var uJr=s(Cse);R8o=r(uJr,"yolos"),uJr.forEach(t),B8o=r(rwe," \u2014 "),_q=n(rwe,"A",{href:!0});var _Jr=s(_q);P8o=r(_Jr,"YolosModel"),_Jr.forEach(t),I8o=r(rwe," (YOLOS model)"),rwe.forEach(t),q8o=i($),yu=n($,"LI",{});var twe=s(yu);wse=n(twe,"STRONG",{});var bJr=s(wse);N8o=r(bJr,"yoso"),bJr.forEach(t),j8o=r(twe," \u2014 "),bq=n(twe,"A",{href:!0});var vJr=s(bq);D8o=r(vJr,"YosoModel"),vJr.forEach(t),G8o=r(twe," (YOSO model)"),twe.forEach(t),$.forEach(t),O8o=i(Zt),Lu=n(Zt,"P",{});var awe=s(Lu);V8o=r(awe,"The model is set in evaluation mode by default using "),Ase=n(awe,"CODE",{});var FJr=s(Ase);X8o=r(FJr,"model.eval()"),FJr.forEach(t),z8o=r(awe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yse=n(awe,"CODE",{});var TJr=s(yse);Q8o=r(TJr,"model.train()"),TJr.forEach(t),awe.forEach(t),W8o=i(Zt),T(xu.$$.fragment,Zt),Zt.forEach(t),Ds.forEach(t),$Pe=i(f),wi=n(f,"H2",{class:!0});var Bqe=s(wi);$u=n(Bqe,"A",{id:!0,class:!0,href:!0});var MJr=s($u);Lse=n(MJr,"SPAN",{});var EJr=s(Lse);T(MA.$$.fragment,EJr),EJr.forEach(t),MJr.forEach(t),H8o=i(Bqe),xse=n(Bqe,"SPAN",{});var CJr=s(xse);U8o=r(CJr,"AutoModelForPreTraining"),CJr.forEach(t),Bqe.forEach(t),kPe=i(f),xo=n(f,"DIV",{class:!0});var Gs=s(xo);T(EA.$$.fragment,Gs),J8o=i(Gs),Ai=n(Gs,"P",{});var KY=s(Ai);Y8o=r(KY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),vq=n(KY,"A",{href:!0});var wJr=s(vq);K8o=r(wJr,"from_pretrained()"),wJr.forEach(t),Z8o=r(KY," class method or the "),Fq=n(KY,"A",{href:!0});var AJr=s(Fq);ebo=r(AJr,"from_config()"),AJr.forEach(t),obo=r(KY,` class
method.`),KY.forEach(t),rbo=i(Gs),CA=n(Gs,"P",{});var Pqe=s(CA);tbo=r(Pqe,"This class cannot be instantiated directly using "),$se=n(Pqe,"CODE",{});var yJr=s($se);abo=r(yJr,"__init__()"),yJr.forEach(t),nbo=r(Pqe," (throws an error)."),Pqe.forEach(t),sbo=i(Gs),rt=n(Gs,"DIV",{class:!0});var UC=s(rt);T(wA.$$.fragment,UC),lbo=i(UC),kse=n(UC,"P",{});var LJr=s(kse);ibo=r(LJr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),LJr.forEach(t),dbo=i(UC),yi=n(UC,"P",{});var ZY=s(yi);cbo=r(ZY,`Note:
Loading a model from its configuration file does `),Sse=n(ZY,"STRONG",{});var xJr=s(Sse);fbo=r(xJr,"not"),xJr.forEach(t),mbo=r(ZY,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tq=n(ZY,"A",{href:!0});var $Jr=s(Tq);gbo=r($Jr,"from_pretrained()"),$Jr.forEach(t),hbo=r(ZY," to load the model weights."),ZY.forEach(t),pbo=i(UC),T(ku.$$.fragment,UC),UC.forEach(t),ubo=i(Gs),Ue=n(Gs,"DIV",{class:!0});var ea=s(Ue);T(AA.$$.fragment,ea),_bo=i(ea),Rse=n(ea,"P",{});var kJr=s(Rse);bbo=r(kJr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),kJr.forEach(t),vbo=i(ea),ya=n(ea,"P",{});var JC=s(ya);Fbo=r(JC,"The model class to instantiate is selected based on the "),Bse=n(JC,"CODE",{});var SJr=s(Bse);Tbo=r(SJr,"model_type"),SJr.forEach(t),Mbo=r(JC,` property of the config object (either
passed as an argument or loaded from `),Pse=n(JC,"CODE",{});var RJr=s(Pse);Ebo=r(RJr,"pretrained_model_name_or_path"),RJr.forEach(t),Cbo=r(JC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ise=n(JC,"CODE",{});var BJr=s(Ise);wbo=r(BJr,"pretrained_model_name_or_path"),BJr.forEach(t),Abo=r(JC,":"),JC.forEach(t),ybo=i(ea),G=n(ea,"UL",{});var V=s(G);Su=n(V,"LI",{});var nwe=s(Su);qse=n(nwe,"STRONG",{});var PJr=s(qse);Lbo=r(PJr,"albert"),PJr.forEach(t),xbo=r(nwe," \u2014 "),Mq=n(nwe,"A",{href:!0});var IJr=s(Mq);$bo=r(IJr,"AlbertForPreTraining"),IJr.forEach(t),kbo=r(nwe," (ALBERT model)"),nwe.forEach(t),Sbo=i(V),Ru=n(V,"LI",{});var swe=s(Ru);Nse=n(swe,"STRONG",{});var qJr=s(Nse);Rbo=r(qJr,"bart"),qJr.forEach(t),Bbo=r(swe," \u2014 "),Eq=n(swe,"A",{href:!0});var NJr=s(Eq);Pbo=r(NJr,"BartForConditionalGeneration"),NJr.forEach(t),Ibo=r(swe," (BART model)"),swe.forEach(t),qbo=i(V),Bu=n(V,"LI",{});var lwe=s(Bu);jse=n(lwe,"STRONG",{});var jJr=s(jse);Nbo=r(jJr,"bert"),jJr.forEach(t),jbo=r(lwe," \u2014 "),Cq=n(lwe,"A",{href:!0});var DJr=s(Cq);Dbo=r(DJr,"BertForPreTraining"),DJr.forEach(t),Gbo=r(lwe," (BERT model)"),lwe.forEach(t),Obo=i(V),Pu=n(V,"LI",{});var iwe=s(Pu);Dse=n(iwe,"STRONG",{});var GJr=s(Dse);Vbo=r(GJr,"big_bird"),GJr.forEach(t),Xbo=r(iwe," \u2014 "),wq=n(iwe,"A",{href:!0});var OJr=s(wq);zbo=r(OJr,"BigBirdForPreTraining"),OJr.forEach(t),Qbo=r(iwe," (BigBird model)"),iwe.forEach(t),Wbo=i(V),Iu=n(V,"LI",{});var dwe=s(Iu);Gse=n(dwe,"STRONG",{});var VJr=s(Gse);Hbo=r(VJr,"camembert"),VJr.forEach(t),Ubo=r(dwe," \u2014 "),Aq=n(dwe,"A",{href:!0});var XJr=s(Aq);Jbo=r(XJr,"CamembertForMaskedLM"),XJr.forEach(t),Ybo=r(dwe," (CamemBERT model)"),dwe.forEach(t),Kbo=i(V),qu=n(V,"LI",{});var cwe=s(qu);Ose=n(cwe,"STRONG",{});var zJr=s(Ose);Zbo=r(zJr,"ctrl"),zJr.forEach(t),e2o=r(cwe," \u2014 "),yq=n(cwe,"A",{href:!0});var QJr=s(yq);o2o=r(QJr,"CTRLLMHeadModel"),QJr.forEach(t),r2o=r(cwe," (CTRL model)"),cwe.forEach(t),t2o=i(V),Nu=n(V,"LI",{});var fwe=s(Nu);Vse=n(fwe,"STRONG",{});var WJr=s(Vse);a2o=r(WJr,"data2vec-text"),WJr.forEach(t),n2o=r(fwe," \u2014 "),Lq=n(fwe,"A",{href:!0});var HJr=s(Lq);s2o=r(HJr,"Data2VecTextForMaskedLM"),HJr.forEach(t),l2o=r(fwe," (Data2VecText model)"),fwe.forEach(t),i2o=i(V),ju=n(V,"LI",{});var mwe=s(ju);Xse=n(mwe,"STRONG",{});var UJr=s(Xse);d2o=r(UJr,"deberta"),UJr.forEach(t),c2o=r(mwe," \u2014 "),xq=n(mwe,"A",{href:!0});var JJr=s(xq);f2o=r(JJr,"DebertaForMaskedLM"),JJr.forEach(t),m2o=r(mwe," (DeBERTa model)"),mwe.forEach(t),g2o=i(V),Du=n(V,"LI",{});var gwe=s(Du);zse=n(gwe,"STRONG",{});var YJr=s(zse);h2o=r(YJr,"deberta-v2"),YJr.forEach(t),p2o=r(gwe," \u2014 "),$q=n(gwe,"A",{href:!0});var KJr=s($q);u2o=r(KJr,"DebertaV2ForMaskedLM"),KJr.forEach(t),_2o=r(gwe," (DeBERTa-v2 model)"),gwe.forEach(t),b2o=i(V),Gu=n(V,"LI",{});var hwe=s(Gu);Qse=n(hwe,"STRONG",{});var ZJr=s(Qse);v2o=r(ZJr,"distilbert"),ZJr.forEach(t),F2o=r(hwe," \u2014 "),kq=n(hwe,"A",{href:!0});var eYr=s(kq);T2o=r(eYr,"DistilBertForMaskedLM"),eYr.forEach(t),M2o=r(hwe," (DistilBERT model)"),hwe.forEach(t),E2o=i(V),Ou=n(V,"LI",{});var pwe=s(Ou);Wse=n(pwe,"STRONG",{});var oYr=s(Wse);C2o=r(oYr,"electra"),oYr.forEach(t),w2o=r(pwe," \u2014 "),Sq=n(pwe,"A",{href:!0});var rYr=s(Sq);A2o=r(rYr,"ElectraForPreTraining"),rYr.forEach(t),y2o=r(pwe," (ELECTRA model)"),pwe.forEach(t),L2o=i(V),Vu=n(V,"LI",{});var uwe=s(Vu);Hse=n(uwe,"STRONG",{});var tYr=s(Hse);x2o=r(tYr,"flaubert"),tYr.forEach(t),$2o=r(uwe," \u2014 "),Rq=n(uwe,"A",{href:!0});var aYr=s(Rq);k2o=r(aYr,"FlaubertWithLMHeadModel"),aYr.forEach(t),S2o=r(uwe," (FlauBERT model)"),uwe.forEach(t),R2o=i(V),Xu=n(V,"LI",{});var _we=s(Xu);Use=n(_we,"STRONG",{});var nYr=s(Use);B2o=r(nYr,"fnet"),nYr.forEach(t),P2o=r(_we," \u2014 "),Bq=n(_we,"A",{href:!0});var sYr=s(Bq);I2o=r(sYr,"FNetForPreTraining"),sYr.forEach(t),q2o=r(_we," (FNet model)"),_we.forEach(t),N2o=i(V),zu=n(V,"LI",{});var bwe=s(zu);Jse=n(bwe,"STRONG",{});var lYr=s(Jse);j2o=r(lYr,"fsmt"),lYr.forEach(t),D2o=r(bwe," \u2014 "),Pq=n(bwe,"A",{href:!0});var iYr=s(Pq);G2o=r(iYr,"FSMTForConditionalGeneration"),iYr.forEach(t),O2o=r(bwe," (FairSeq Machine-Translation model)"),bwe.forEach(t),V2o=i(V),Qu=n(V,"LI",{});var vwe=s(Qu);Yse=n(vwe,"STRONG",{});var dYr=s(Yse);X2o=r(dYr,"funnel"),dYr.forEach(t),z2o=r(vwe," \u2014 "),Iq=n(vwe,"A",{href:!0});var cYr=s(Iq);Q2o=r(cYr,"FunnelForPreTraining"),cYr.forEach(t),W2o=r(vwe," (Funnel Transformer model)"),vwe.forEach(t),H2o=i(V),Wu=n(V,"LI",{});var Fwe=s(Wu);Kse=n(Fwe,"STRONG",{});var fYr=s(Kse);U2o=r(fYr,"gpt2"),fYr.forEach(t),J2o=r(Fwe," \u2014 "),qq=n(Fwe,"A",{href:!0});var mYr=s(qq);Y2o=r(mYr,"GPT2LMHeadModel"),mYr.forEach(t),K2o=r(Fwe," (OpenAI GPT-2 model)"),Fwe.forEach(t),Z2o=i(V),Hu=n(V,"LI",{});var Twe=s(Hu);Zse=n(Twe,"STRONG",{});var gYr=s(Zse);evo=r(gYr,"ibert"),gYr.forEach(t),ovo=r(Twe," \u2014 "),Nq=n(Twe,"A",{href:!0});var hYr=s(Nq);rvo=r(hYr,"IBertForMaskedLM"),hYr.forEach(t),tvo=r(Twe," (I-BERT model)"),Twe.forEach(t),avo=i(V),Uu=n(V,"LI",{});var Mwe=s(Uu);ele=n(Mwe,"STRONG",{});var pYr=s(ele);nvo=r(pYr,"layoutlm"),pYr.forEach(t),svo=r(Mwe," \u2014 "),jq=n(Mwe,"A",{href:!0});var uYr=s(jq);lvo=r(uYr,"LayoutLMForMaskedLM"),uYr.forEach(t),ivo=r(Mwe," (LayoutLM model)"),Mwe.forEach(t),dvo=i(V),Ju=n(V,"LI",{});var Ewe=s(Ju);ole=n(Ewe,"STRONG",{});var _Yr=s(ole);cvo=r(_Yr,"longformer"),_Yr.forEach(t),fvo=r(Ewe," \u2014 "),Dq=n(Ewe,"A",{href:!0});var bYr=s(Dq);mvo=r(bYr,"LongformerForMaskedLM"),bYr.forEach(t),gvo=r(Ewe," (Longformer model)"),Ewe.forEach(t),hvo=i(V),Yu=n(V,"LI",{});var Cwe=s(Yu);rle=n(Cwe,"STRONG",{});var vYr=s(rle);pvo=r(vYr,"lxmert"),vYr.forEach(t),uvo=r(Cwe," \u2014 "),Gq=n(Cwe,"A",{href:!0});var FYr=s(Gq);_vo=r(FYr,"LxmertForPreTraining"),FYr.forEach(t),bvo=r(Cwe," (LXMERT model)"),Cwe.forEach(t),vvo=i(V),Ku=n(V,"LI",{});var wwe=s(Ku);tle=n(wwe,"STRONG",{});var TYr=s(tle);Fvo=r(TYr,"megatron-bert"),TYr.forEach(t),Tvo=r(wwe," \u2014 "),Oq=n(wwe,"A",{href:!0});var MYr=s(Oq);Mvo=r(MYr,"MegatronBertForPreTraining"),MYr.forEach(t),Evo=r(wwe," (MegatronBert model)"),wwe.forEach(t),Cvo=i(V),Zu=n(V,"LI",{});var Awe=s(Zu);ale=n(Awe,"STRONG",{});var EYr=s(ale);wvo=r(EYr,"mobilebert"),EYr.forEach(t),Avo=r(Awe," \u2014 "),Vq=n(Awe,"A",{href:!0});var CYr=s(Vq);yvo=r(CYr,"MobileBertForPreTraining"),CYr.forEach(t),Lvo=r(Awe," (MobileBERT model)"),Awe.forEach(t),xvo=i(V),e_=n(V,"LI",{});var ywe=s(e_);nle=n(ywe,"STRONG",{});var wYr=s(nle);$vo=r(wYr,"mpnet"),wYr.forEach(t),kvo=r(ywe," \u2014 "),Xq=n(ywe,"A",{href:!0});var AYr=s(Xq);Svo=r(AYr,"MPNetForMaskedLM"),AYr.forEach(t),Rvo=r(ywe," (MPNet model)"),ywe.forEach(t),Bvo=i(V),o_=n(V,"LI",{});var Lwe=s(o_);sle=n(Lwe,"STRONG",{});var yYr=s(sle);Pvo=r(yYr,"openai-gpt"),yYr.forEach(t),Ivo=r(Lwe," \u2014 "),zq=n(Lwe,"A",{href:!0});var LYr=s(zq);qvo=r(LYr,"OpenAIGPTLMHeadModel"),LYr.forEach(t),Nvo=r(Lwe," (OpenAI GPT model)"),Lwe.forEach(t),jvo=i(V),r_=n(V,"LI",{});var xwe=s(r_);lle=n(xwe,"STRONG",{});var xYr=s(lle);Dvo=r(xYr,"retribert"),xYr.forEach(t),Gvo=r(xwe," \u2014 "),Qq=n(xwe,"A",{href:!0});var $Yr=s(Qq);Ovo=r($Yr,"RetriBertModel"),$Yr.forEach(t),Vvo=r(xwe," (RetriBERT model)"),xwe.forEach(t),Xvo=i(V),t_=n(V,"LI",{});var $we=s(t_);ile=n($we,"STRONG",{});var kYr=s(ile);zvo=r(kYr,"roberta"),kYr.forEach(t),Qvo=r($we," \u2014 "),Wq=n($we,"A",{href:!0});var SYr=s(Wq);Wvo=r(SYr,"RobertaForMaskedLM"),SYr.forEach(t),Hvo=r($we," (RoBERTa model)"),$we.forEach(t),Uvo=i(V),a_=n(V,"LI",{});var kwe=s(a_);dle=n(kwe,"STRONG",{});var RYr=s(dle);Jvo=r(RYr,"squeezebert"),RYr.forEach(t),Yvo=r(kwe," \u2014 "),Hq=n(kwe,"A",{href:!0});var BYr=s(Hq);Kvo=r(BYr,"SqueezeBertForMaskedLM"),BYr.forEach(t),Zvo=r(kwe," (SqueezeBERT model)"),kwe.forEach(t),eFo=i(V),n_=n(V,"LI",{});var Swe=s(n_);cle=n(Swe,"STRONG",{});var PYr=s(cle);oFo=r(PYr,"t5"),PYr.forEach(t),rFo=r(Swe," \u2014 "),Uq=n(Swe,"A",{href:!0});var IYr=s(Uq);tFo=r(IYr,"T5ForConditionalGeneration"),IYr.forEach(t),aFo=r(Swe," (T5 model)"),Swe.forEach(t),nFo=i(V),s_=n(V,"LI",{});var Rwe=s(s_);fle=n(Rwe,"STRONG",{});var qYr=s(fle);sFo=r(qYr,"tapas"),qYr.forEach(t),lFo=r(Rwe," \u2014 "),Jq=n(Rwe,"A",{href:!0});var NYr=s(Jq);iFo=r(NYr,"TapasForMaskedLM"),NYr.forEach(t),dFo=r(Rwe," (TAPAS model)"),Rwe.forEach(t),cFo=i(V),l_=n(V,"LI",{});var Bwe=s(l_);mle=n(Bwe,"STRONG",{});var jYr=s(mle);fFo=r(jYr,"transfo-xl"),jYr.forEach(t),mFo=r(Bwe," \u2014 "),Yq=n(Bwe,"A",{href:!0});var DYr=s(Yq);gFo=r(DYr,"TransfoXLLMHeadModel"),DYr.forEach(t),hFo=r(Bwe," (Transformer-XL model)"),Bwe.forEach(t),pFo=i(V),i_=n(V,"LI",{});var Pwe=s(i_);gle=n(Pwe,"STRONG",{});var GYr=s(gle);uFo=r(GYr,"unispeech"),GYr.forEach(t),_Fo=r(Pwe," \u2014 "),Kq=n(Pwe,"A",{href:!0});var OYr=s(Kq);bFo=r(OYr,"UniSpeechForPreTraining"),OYr.forEach(t),vFo=r(Pwe," (UniSpeech model)"),Pwe.forEach(t),FFo=i(V),d_=n(V,"LI",{});var Iwe=s(d_);hle=n(Iwe,"STRONG",{});var VYr=s(hle);TFo=r(VYr,"unispeech-sat"),VYr.forEach(t),MFo=r(Iwe," \u2014 "),Zq=n(Iwe,"A",{href:!0});var XYr=s(Zq);EFo=r(XYr,"UniSpeechSatForPreTraining"),XYr.forEach(t),CFo=r(Iwe," (UniSpeechSat model)"),Iwe.forEach(t),wFo=i(V),c_=n(V,"LI",{});var qwe=s(c_);ple=n(qwe,"STRONG",{});var zYr=s(ple);AFo=r(zYr,"visual_bert"),zYr.forEach(t),yFo=r(qwe," \u2014 "),eN=n(qwe,"A",{href:!0});var QYr=s(eN);LFo=r(QYr,"VisualBertForPreTraining"),QYr.forEach(t),xFo=r(qwe," (VisualBert model)"),qwe.forEach(t),$Fo=i(V),f_=n(V,"LI",{});var Nwe=s(f_);ule=n(Nwe,"STRONG",{});var WYr=s(ule);kFo=r(WYr,"vit_mae"),WYr.forEach(t),SFo=r(Nwe," \u2014 "),oN=n(Nwe,"A",{href:!0});var HYr=s(oN);RFo=r(HYr,"ViTMAEForPreTraining"),HYr.forEach(t),BFo=r(Nwe," (ViTMAE model)"),Nwe.forEach(t),PFo=i(V),m_=n(V,"LI",{});var jwe=s(m_);_le=n(jwe,"STRONG",{});var UYr=s(_le);IFo=r(UYr,"wav2vec2"),UYr.forEach(t),qFo=r(jwe," \u2014 "),rN=n(jwe,"A",{href:!0});var JYr=s(rN);NFo=r(JYr,"Wav2Vec2ForPreTraining"),JYr.forEach(t),jFo=r(jwe," (Wav2Vec2 model)"),jwe.forEach(t),DFo=i(V),g_=n(V,"LI",{});var Dwe=s(g_);ble=n(Dwe,"STRONG",{});var YYr=s(ble);GFo=r(YYr,"xlm"),YYr.forEach(t),OFo=r(Dwe," \u2014 "),tN=n(Dwe,"A",{href:!0});var KYr=s(tN);VFo=r(KYr,"XLMWithLMHeadModel"),KYr.forEach(t),XFo=r(Dwe," (XLM model)"),Dwe.forEach(t),zFo=i(V),h_=n(V,"LI",{});var Gwe=s(h_);vle=n(Gwe,"STRONG",{});var ZYr=s(vle);QFo=r(ZYr,"xlm-roberta"),ZYr.forEach(t),WFo=r(Gwe," \u2014 "),aN=n(Gwe,"A",{href:!0});var eKr=s(aN);HFo=r(eKr,"XLMRobertaForMaskedLM"),eKr.forEach(t),UFo=r(Gwe," (XLM-RoBERTa model)"),Gwe.forEach(t),JFo=i(V),p_=n(V,"LI",{});var Owe=s(p_);Fle=n(Owe,"STRONG",{});var oKr=s(Fle);YFo=r(oKr,"xlm-roberta-xl"),oKr.forEach(t),KFo=r(Owe," \u2014 "),nN=n(Owe,"A",{href:!0});var rKr=s(nN);ZFo=r(rKr,"XLMRobertaXLForMaskedLM"),rKr.forEach(t),e6o=r(Owe," (XLM-RoBERTa-XL model)"),Owe.forEach(t),o6o=i(V),u_=n(V,"LI",{});var Vwe=s(u_);Tle=n(Vwe,"STRONG",{});var tKr=s(Tle);r6o=r(tKr,"xlnet"),tKr.forEach(t),t6o=r(Vwe," \u2014 "),sN=n(Vwe,"A",{href:!0});var aKr=s(sN);a6o=r(aKr,"XLNetLMHeadModel"),aKr.forEach(t),n6o=r(Vwe," (XLNet model)"),Vwe.forEach(t),V.forEach(t),s6o=i(ea),__=n(ea,"P",{});var Xwe=s(__);l6o=r(Xwe,"The model is set in evaluation mode by default using "),Mle=n(Xwe,"CODE",{});var nKr=s(Mle);i6o=r(nKr,"model.eval()"),nKr.forEach(t),d6o=r(Xwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ele=n(Xwe,"CODE",{});var sKr=s(Ele);c6o=r(sKr,"model.train()"),sKr.forEach(t),Xwe.forEach(t),f6o=i(ea),T(b_.$$.fragment,ea),ea.forEach(t),Gs.forEach(t),SPe=i(f),Li=n(f,"H2",{class:!0});var Iqe=s(Li);v_=n(Iqe,"A",{id:!0,class:!0,href:!0});var lKr=s(v_);Cle=n(lKr,"SPAN",{});var iKr=s(Cle);T(yA.$$.fragment,iKr),iKr.forEach(t),lKr.forEach(t),m6o=i(Iqe),wle=n(Iqe,"SPAN",{});var dKr=s(wle);g6o=r(dKr,"AutoModelForCausalLM"),dKr.forEach(t),Iqe.forEach(t),RPe=i(f),$o=n(f,"DIV",{class:!0});var Os=s($o);T(LA.$$.fragment,Os),h6o=i(Os),xi=n(Os,"P",{});var eK=s(xi);p6o=r(eK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lN=n(eK,"A",{href:!0});var cKr=s(lN);u6o=r(cKr,"from_pretrained()"),cKr.forEach(t),_6o=r(eK," class method or the "),iN=n(eK,"A",{href:!0});var fKr=s(iN);b6o=r(fKr,"from_config()"),fKr.forEach(t),v6o=r(eK,` class
method.`),eK.forEach(t),F6o=i(Os),xA=n(Os,"P",{});var qqe=s(xA);T6o=r(qqe,"This class cannot be instantiated directly using "),Ale=n(qqe,"CODE",{});var mKr=s(Ale);M6o=r(mKr,"__init__()"),mKr.forEach(t),E6o=r(qqe," (throws an error)."),qqe.forEach(t),C6o=i(Os),tt=n(Os,"DIV",{class:!0});var YC=s(tt);T($A.$$.fragment,YC),w6o=i(YC),yle=n(YC,"P",{});var gKr=s(yle);A6o=r(gKr,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gKr.forEach(t),y6o=i(YC),$i=n(YC,"P",{});var oK=s($i);L6o=r(oK,`Note:
Loading a model from its configuration file does `),Lle=n(oK,"STRONG",{});var hKr=s(Lle);x6o=r(hKr,"not"),hKr.forEach(t),$6o=r(oK,` load the model weights. It only affects the
model\u2019s configuration. Use `),dN=n(oK,"A",{href:!0});var pKr=s(dN);k6o=r(pKr,"from_pretrained()"),pKr.forEach(t),S6o=r(oK," to load the model weights."),oK.forEach(t),R6o=i(YC),T(F_.$$.fragment,YC),YC.forEach(t),B6o=i(Os),Je=n(Os,"DIV",{class:!0});var oa=s(Je);T(kA.$$.fragment,oa),P6o=i(oa),xle=n(oa,"P",{});var uKr=s(xle);I6o=r(uKr,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uKr.forEach(t),q6o=i(oa),La=n(oa,"P",{});var KC=s(La);N6o=r(KC,"The model class to instantiate is selected based on the "),$le=n(KC,"CODE",{});var _Kr=s($le);j6o=r(_Kr,"model_type"),_Kr.forEach(t),D6o=r(KC,` property of the config object (either
passed as an argument or loaded from `),kle=n(KC,"CODE",{});var bKr=s(kle);G6o=r(bKr,"pretrained_model_name_or_path"),bKr.forEach(t),O6o=r(KC,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sle=n(KC,"CODE",{});var vKr=s(Sle);V6o=r(vKr,"pretrained_model_name_or_path"),vKr.forEach(t),X6o=r(KC,":"),KC.forEach(t),z6o=i(oa),z=n(oa,"UL",{});var W=s(z);T_=n(W,"LI",{});var zwe=s(T_);Rle=n(zwe,"STRONG",{});var FKr=s(Rle);Q6o=r(FKr,"bart"),FKr.forEach(t),W6o=r(zwe," \u2014 "),cN=n(zwe,"A",{href:!0});var TKr=s(cN);H6o=r(TKr,"BartForCausalLM"),TKr.forEach(t),U6o=r(zwe," (BART model)"),zwe.forEach(t),J6o=i(W),M_=n(W,"LI",{});var Qwe=s(M_);Ble=n(Qwe,"STRONG",{});var MKr=s(Ble);Y6o=r(MKr,"bert"),MKr.forEach(t),K6o=r(Qwe," \u2014 "),fN=n(Qwe,"A",{href:!0});var EKr=s(fN);Z6o=r(EKr,"BertLMHeadModel"),EKr.forEach(t),eTo=r(Qwe," (BERT model)"),Qwe.forEach(t),oTo=i(W),E_=n(W,"LI",{});var Wwe=s(E_);Ple=n(Wwe,"STRONG",{});var CKr=s(Ple);rTo=r(CKr,"bert-generation"),CKr.forEach(t),tTo=r(Wwe," \u2014 "),mN=n(Wwe,"A",{href:!0});var wKr=s(mN);aTo=r(wKr,"BertGenerationDecoder"),wKr.forEach(t),nTo=r(Wwe," (Bert Generation model)"),Wwe.forEach(t),sTo=i(W),C_=n(W,"LI",{});var Hwe=s(C_);Ile=n(Hwe,"STRONG",{});var AKr=s(Ile);lTo=r(AKr,"big_bird"),AKr.forEach(t),iTo=r(Hwe," \u2014 "),gN=n(Hwe,"A",{href:!0});var yKr=s(gN);dTo=r(yKr,"BigBirdForCausalLM"),yKr.forEach(t),cTo=r(Hwe," (BigBird model)"),Hwe.forEach(t),fTo=i(W),w_=n(W,"LI",{});var Uwe=s(w_);qle=n(Uwe,"STRONG",{});var LKr=s(qle);mTo=r(LKr,"bigbird_pegasus"),LKr.forEach(t),gTo=r(Uwe," \u2014 "),hN=n(Uwe,"A",{href:!0});var xKr=s(hN);hTo=r(xKr,"BigBirdPegasusForCausalLM"),xKr.forEach(t),pTo=r(Uwe," (BigBirdPegasus model)"),Uwe.forEach(t),uTo=i(W),A_=n(W,"LI",{});var Jwe=s(A_);Nle=n(Jwe,"STRONG",{});var $Kr=s(Nle);_To=r($Kr,"blenderbot"),$Kr.forEach(t),bTo=r(Jwe," \u2014 "),pN=n(Jwe,"A",{href:!0});var kKr=s(pN);vTo=r(kKr,"BlenderbotForCausalLM"),kKr.forEach(t),FTo=r(Jwe," (Blenderbot model)"),Jwe.forEach(t),TTo=i(W),y_=n(W,"LI",{});var Ywe=s(y_);jle=n(Ywe,"STRONG",{});var SKr=s(jle);MTo=r(SKr,"blenderbot-small"),SKr.forEach(t),ETo=r(Ywe," \u2014 "),uN=n(Ywe,"A",{href:!0});var RKr=s(uN);CTo=r(RKr,"BlenderbotSmallForCausalLM"),RKr.forEach(t),wTo=r(Ywe," (BlenderbotSmall model)"),Ywe.forEach(t),ATo=i(W),L_=n(W,"LI",{});var Kwe=s(L_);Dle=n(Kwe,"STRONG",{});var BKr=s(Dle);yTo=r(BKr,"camembert"),BKr.forEach(t),LTo=r(Kwe," \u2014 "),_N=n(Kwe,"A",{href:!0});var PKr=s(_N);xTo=r(PKr,"CamembertForCausalLM"),PKr.forEach(t),$To=r(Kwe," (CamemBERT model)"),Kwe.forEach(t),kTo=i(W),x_=n(W,"LI",{});var Zwe=s(x_);Gle=n(Zwe,"STRONG",{});var IKr=s(Gle);STo=r(IKr,"ctrl"),IKr.forEach(t),RTo=r(Zwe," \u2014 "),bN=n(Zwe,"A",{href:!0});var qKr=s(bN);BTo=r(qKr,"CTRLLMHeadModel"),qKr.forEach(t),PTo=r(Zwe," (CTRL model)"),Zwe.forEach(t),ITo=i(W),$_=n(W,"LI",{});var eAe=s($_);Ole=n(eAe,"STRONG",{});var NKr=s(Ole);qTo=r(NKr,"data2vec-text"),NKr.forEach(t),NTo=r(eAe," \u2014 "),vN=n(eAe,"A",{href:!0});var jKr=s(vN);jTo=r(jKr,"Data2VecTextForCausalLM"),jKr.forEach(t),DTo=r(eAe," (Data2VecText model)"),eAe.forEach(t),GTo=i(W),k_=n(W,"LI",{});var oAe=s(k_);Vle=n(oAe,"STRONG",{});var DKr=s(Vle);OTo=r(DKr,"electra"),DKr.forEach(t),VTo=r(oAe," \u2014 "),FN=n(oAe,"A",{href:!0});var GKr=s(FN);XTo=r(GKr,"ElectraForCausalLM"),GKr.forEach(t),zTo=r(oAe," (ELECTRA model)"),oAe.forEach(t),QTo=i(W),S_=n(W,"LI",{});var rAe=s(S_);Xle=n(rAe,"STRONG",{});var OKr=s(Xle);WTo=r(OKr,"gpt2"),OKr.forEach(t),HTo=r(rAe," \u2014 "),TN=n(rAe,"A",{href:!0});var VKr=s(TN);UTo=r(VKr,"GPT2LMHeadModel"),VKr.forEach(t),JTo=r(rAe," (OpenAI GPT-2 model)"),rAe.forEach(t),YTo=i(W),R_=n(W,"LI",{});var tAe=s(R_);zle=n(tAe,"STRONG",{});var XKr=s(zle);KTo=r(XKr,"gpt_neo"),XKr.forEach(t),ZTo=r(tAe," \u2014 "),MN=n(tAe,"A",{href:!0});var zKr=s(MN);e9o=r(zKr,"GPTNeoForCausalLM"),zKr.forEach(t),o9o=r(tAe," (GPT Neo model)"),tAe.forEach(t),r9o=i(W),B_=n(W,"LI",{});var aAe=s(B_);Qle=n(aAe,"STRONG",{});var QKr=s(Qle);t9o=r(QKr,"gptj"),QKr.forEach(t),a9o=r(aAe," \u2014 "),EN=n(aAe,"A",{href:!0});var WKr=s(EN);n9o=r(WKr,"GPTJForCausalLM"),WKr.forEach(t),s9o=r(aAe," (GPT-J model)"),aAe.forEach(t),l9o=i(W),P_=n(W,"LI",{});var nAe=s(P_);Wle=n(nAe,"STRONG",{});var HKr=s(Wle);i9o=r(HKr,"marian"),HKr.forEach(t),d9o=r(nAe," \u2014 "),CN=n(nAe,"A",{href:!0});var UKr=s(CN);c9o=r(UKr,"MarianForCausalLM"),UKr.forEach(t),f9o=r(nAe," (Marian model)"),nAe.forEach(t),m9o=i(W),I_=n(W,"LI",{});var sAe=s(I_);Hle=n(sAe,"STRONG",{});var JKr=s(Hle);g9o=r(JKr,"mbart"),JKr.forEach(t),h9o=r(sAe," \u2014 "),wN=n(sAe,"A",{href:!0});var YKr=s(wN);p9o=r(YKr,"MBartForCausalLM"),YKr.forEach(t),u9o=r(sAe," (mBART model)"),sAe.forEach(t),_9o=i(W),q_=n(W,"LI",{});var lAe=s(q_);Ule=n(lAe,"STRONG",{});var KKr=s(Ule);b9o=r(KKr,"megatron-bert"),KKr.forEach(t),v9o=r(lAe," \u2014 "),AN=n(lAe,"A",{href:!0});var ZKr=s(AN);F9o=r(ZKr,"MegatronBertForCausalLM"),ZKr.forEach(t),T9o=r(lAe," (MegatronBert model)"),lAe.forEach(t),M9o=i(W),N_=n(W,"LI",{});var iAe=s(N_);Jle=n(iAe,"STRONG",{});var eZr=s(Jle);E9o=r(eZr,"openai-gpt"),eZr.forEach(t),C9o=r(iAe," \u2014 "),yN=n(iAe,"A",{href:!0});var oZr=s(yN);w9o=r(oZr,"OpenAIGPTLMHeadModel"),oZr.forEach(t),A9o=r(iAe," (OpenAI GPT model)"),iAe.forEach(t),y9o=i(W),j_=n(W,"LI",{});var dAe=s(j_);Yle=n(dAe,"STRONG",{});var rZr=s(Yle);L9o=r(rZr,"pegasus"),rZr.forEach(t),x9o=r(dAe," \u2014 "),LN=n(dAe,"A",{href:!0});var tZr=s(LN);$9o=r(tZr,"PegasusForCausalLM"),tZr.forEach(t),k9o=r(dAe," (Pegasus model)"),dAe.forEach(t),S9o=i(W),D_=n(W,"LI",{});var cAe=s(D_);Kle=n(cAe,"STRONG",{});var aZr=s(Kle);R9o=r(aZr,"plbart"),aZr.forEach(t),B9o=r(cAe," \u2014 "),xN=n(cAe,"A",{href:!0});var nZr=s(xN);P9o=r(nZr,"PLBartForCausalLM"),nZr.forEach(t),I9o=r(cAe," (PLBart model)"),cAe.forEach(t),q9o=i(W),G_=n(W,"LI",{});var fAe=s(G_);Zle=n(fAe,"STRONG",{});var sZr=s(Zle);N9o=r(sZr,"prophetnet"),sZr.forEach(t),j9o=r(fAe," \u2014 "),$N=n(fAe,"A",{href:!0});var lZr=s($N);D9o=r(lZr,"ProphetNetForCausalLM"),lZr.forEach(t),G9o=r(fAe," (ProphetNet model)"),fAe.forEach(t),O9o=i(W),O_=n(W,"LI",{});var mAe=s(O_);eie=n(mAe,"STRONG",{});var iZr=s(eie);V9o=r(iZr,"qdqbert"),iZr.forEach(t),X9o=r(mAe," \u2014 "),kN=n(mAe,"A",{href:!0});var dZr=s(kN);z9o=r(dZr,"QDQBertLMHeadModel"),dZr.forEach(t),Q9o=r(mAe," (QDQBert model)"),mAe.forEach(t),W9o=i(W),V_=n(W,"LI",{});var gAe=s(V_);oie=n(gAe,"STRONG",{});var cZr=s(oie);H9o=r(cZr,"reformer"),cZr.forEach(t),U9o=r(gAe," \u2014 "),SN=n(gAe,"A",{href:!0});var fZr=s(SN);J9o=r(fZr,"ReformerModelWithLMHead"),fZr.forEach(t),Y9o=r(gAe," (Reformer model)"),gAe.forEach(t),K9o=i(W),X_=n(W,"LI",{});var hAe=s(X_);rie=n(hAe,"STRONG",{});var mZr=s(rie);Z9o=r(mZr,"rembert"),mZr.forEach(t),eMo=r(hAe," \u2014 "),RN=n(hAe,"A",{href:!0});var gZr=s(RN);oMo=r(gZr,"RemBertForCausalLM"),gZr.forEach(t),rMo=r(hAe," (RemBERT model)"),hAe.forEach(t),tMo=i(W),z_=n(W,"LI",{});var pAe=s(z_);tie=n(pAe,"STRONG",{});var hZr=s(tie);aMo=r(hZr,"roberta"),hZr.forEach(t),nMo=r(pAe," \u2014 "),BN=n(pAe,"A",{href:!0});var pZr=s(BN);sMo=r(pZr,"RobertaForCausalLM"),pZr.forEach(t),lMo=r(pAe," (RoBERTa model)"),pAe.forEach(t),iMo=i(W),Q_=n(W,"LI",{});var uAe=s(Q_);aie=n(uAe,"STRONG",{});var uZr=s(aie);dMo=r(uZr,"roformer"),uZr.forEach(t),cMo=r(uAe," \u2014 "),PN=n(uAe,"A",{href:!0});var _Zr=s(PN);fMo=r(_Zr,"RoFormerForCausalLM"),_Zr.forEach(t),mMo=r(uAe," (RoFormer model)"),uAe.forEach(t),gMo=i(W),W_=n(W,"LI",{});var _Ae=s(W_);nie=n(_Ae,"STRONG",{});var bZr=s(nie);hMo=r(bZr,"speech_to_text_2"),bZr.forEach(t),pMo=r(_Ae," \u2014 "),IN=n(_Ae,"A",{href:!0});var vZr=s(IN);uMo=r(vZr,"Speech2Text2ForCausalLM"),vZr.forEach(t),_Mo=r(_Ae," (Speech2Text2 model)"),_Ae.forEach(t),bMo=i(W),H_=n(W,"LI",{});var bAe=s(H_);sie=n(bAe,"STRONG",{});var FZr=s(sie);vMo=r(FZr,"transfo-xl"),FZr.forEach(t),FMo=r(bAe," \u2014 "),qN=n(bAe,"A",{href:!0});var TZr=s(qN);TMo=r(TZr,"TransfoXLLMHeadModel"),TZr.forEach(t),MMo=r(bAe," (Transformer-XL model)"),bAe.forEach(t),EMo=i(W),U_=n(W,"LI",{});var vAe=s(U_);lie=n(vAe,"STRONG",{});var MZr=s(lie);CMo=r(MZr,"trocr"),MZr.forEach(t),wMo=r(vAe," \u2014 "),NN=n(vAe,"A",{href:!0});var EZr=s(NN);AMo=r(EZr,"TrOCRForCausalLM"),EZr.forEach(t),yMo=r(vAe," (TrOCR model)"),vAe.forEach(t),LMo=i(W),J_=n(W,"LI",{});var FAe=s(J_);iie=n(FAe,"STRONG",{});var CZr=s(iie);xMo=r(CZr,"xglm"),CZr.forEach(t),$Mo=r(FAe," \u2014 "),jN=n(FAe,"A",{href:!0});var wZr=s(jN);kMo=r(wZr,"XGLMForCausalLM"),wZr.forEach(t),SMo=r(FAe," (XGLM model)"),FAe.forEach(t),RMo=i(W),Y_=n(W,"LI",{});var TAe=s(Y_);die=n(TAe,"STRONG",{});var AZr=s(die);BMo=r(AZr,"xlm"),AZr.forEach(t),PMo=r(TAe," \u2014 "),DN=n(TAe,"A",{href:!0});var yZr=s(DN);IMo=r(yZr,"XLMWithLMHeadModel"),yZr.forEach(t),qMo=r(TAe," (XLM model)"),TAe.forEach(t),NMo=i(W),K_=n(W,"LI",{});var MAe=s(K_);cie=n(MAe,"STRONG",{});var LZr=s(cie);jMo=r(LZr,"xlm-prophetnet"),LZr.forEach(t),DMo=r(MAe," \u2014 "),GN=n(MAe,"A",{href:!0});var xZr=s(GN);GMo=r(xZr,"XLMProphetNetForCausalLM"),xZr.forEach(t),OMo=r(MAe," (XLMProphetNet model)"),MAe.forEach(t),VMo=i(W),Z_=n(W,"LI",{});var EAe=s(Z_);fie=n(EAe,"STRONG",{});var $Zr=s(fie);XMo=r($Zr,"xlm-roberta"),$Zr.forEach(t),zMo=r(EAe," \u2014 "),ON=n(EAe,"A",{href:!0});var kZr=s(ON);QMo=r(kZr,"XLMRobertaForCausalLM"),kZr.forEach(t),WMo=r(EAe," (XLM-RoBERTa model)"),EAe.forEach(t),HMo=i(W),e1=n(W,"LI",{});var CAe=s(e1);mie=n(CAe,"STRONG",{});var SZr=s(mie);UMo=r(SZr,"xlm-roberta-xl"),SZr.forEach(t),JMo=r(CAe," \u2014 "),VN=n(CAe,"A",{href:!0});var RZr=s(VN);YMo=r(RZr,"XLMRobertaXLForCausalLM"),RZr.forEach(t),KMo=r(CAe," (XLM-RoBERTa-XL model)"),CAe.forEach(t),ZMo=i(W),o1=n(W,"LI",{});var wAe=s(o1);gie=n(wAe,"STRONG",{});var BZr=s(gie);e4o=r(BZr,"xlnet"),BZr.forEach(t),o4o=r(wAe," \u2014 "),XN=n(wAe,"A",{href:!0});var PZr=s(XN);r4o=r(PZr,"XLNetLMHeadModel"),PZr.forEach(t),t4o=r(wAe," (XLNet model)"),wAe.forEach(t),W.forEach(t),a4o=i(oa),r1=n(oa,"P",{});var AAe=s(r1);n4o=r(AAe,"The model is set in evaluation mode by default using "),hie=n(AAe,"CODE",{});var IZr=s(hie);s4o=r(IZr,"model.eval()"),IZr.forEach(t),l4o=r(AAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pie=n(AAe,"CODE",{});var qZr=s(pie);i4o=r(qZr,"model.train()"),qZr.forEach(t),AAe.forEach(t),d4o=i(oa),T(t1.$$.fragment,oa),oa.forEach(t),Os.forEach(t),BPe=i(f),ki=n(f,"H2",{class:!0});var Nqe=s(ki);a1=n(Nqe,"A",{id:!0,class:!0,href:!0});var NZr=s(a1);uie=n(NZr,"SPAN",{});var jZr=s(uie);T(SA.$$.fragment,jZr),jZr.forEach(t),NZr.forEach(t),c4o=i(Nqe),_ie=n(Nqe,"SPAN",{});var DZr=s(_ie);f4o=r(DZr,"AutoModelForMaskedLM"),DZr.forEach(t),Nqe.forEach(t),PPe=i(f),ko=n(f,"DIV",{class:!0});var Vs=s(ko);T(RA.$$.fragment,Vs),m4o=i(Vs),Si=n(Vs,"P",{});var rK=s(Si);g4o=r(rK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),zN=n(rK,"A",{href:!0});var GZr=s(zN);h4o=r(GZr,"from_pretrained()"),GZr.forEach(t),p4o=r(rK," class method or the "),QN=n(rK,"A",{href:!0});var OZr=s(QN);u4o=r(OZr,"from_config()"),OZr.forEach(t),_4o=r(rK,` class
method.`),rK.forEach(t),b4o=i(Vs),BA=n(Vs,"P",{});var jqe=s(BA);v4o=r(jqe,"This class cannot be instantiated directly using "),bie=n(jqe,"CODE",{});var VZr=s(bie);F4o=r(VZr,"__init__()"),VZr.forEach(t),T4o=r(jqe," (throws an error)."),jqe.forEach(t),M4o=i(Vs),at=n(Vs,"DIV",{class:!0});var ZC=s(at);T(PA.$$.fragment,ZC),E4o=i(ZC),vie=n(ZC,"P",{});var XZr=s(vie);C4o=r(XZr,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),XZr.forEach(t),w4o=i(ZC),Ri=n(ZC,"P",{});var tK=s(Ri);A4o=r(tK,`Note:
Loading a model from its configuration file does `),Fie=n(tK,"STRONG",{});var zZr=s(Fie);y4o=r(zZr,"not"),zZr.forEach(t),L4o=r(tK,` load the model weights. It only affects the
model\u2019s configuration. Use `),WN=n(tK,"A",{href:!0});var QZr=s(WN);x4o=r(QZr,"from_pretrained()"),QZr.forEach(t),$4o=r(tK," to load the model weights."),tK.forEach(t),k4o=i(ZC),T(n1.$$.fragment,ZC),ZC.forEach(t),S4o=i(Vs),Ye=n(Vs,"DIV",{class:!0});var ra=s(Ye);T(IA.$$.fragment,ra),R4o=i(ra),Tie=n(ra,"P",{});var WZr=s(Tie);B4o=r(WZr,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),WZr.forEach(t),P4o=i(ra),xa=n(ra,"P",{});var e3=s(xa);I4o=r(e3,"The model class to instantiate is selected based on the "),Mie=n(e3,"CODE",{});var HZr=s(Mie);q4o=r(HZr,"model_type"),HZr.forEach(t),N4o=r(e3,` property of the config object (either
passed as an argument or loaded from `),Eie=n(e3,"CODE",{});var UZr=s(Eie);j4o=r(UZr,"pretrained_model_name_or_path"),UZr.forEach(t),D4o=r(e3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cie=n(e3,"CODE",{});var JZr=s(Cie);G4o=r(JZr,"pretrained_model_name_or_path"),JZr.forEach(t),O4o=r(e3,":"),e3.forEach(t),V4o=i(ra),Q=n(ra,"UL",{});var H=s(Q);s1=n(H,"LI",{});var yAe=s(s1);wie=n(yAe,"STRONG",{});var YZr=s(wie);X4o=r(YZr,"albert"),YZr.forEach(t),z4o=r(yAe," \u2014 "),HN=n(yAe,"A",{href:!0});var KZr=s(HN);Q4o=r(KZr,"AlbertForMaskedLM"),KZr.forEach(t),W4o=r(yAe," (ALBERT model)"),yAe.forEach(t),H4o=i(H),l1=n(H,"LI",{});var LAe=s(l1);Aie=n(LAe,"STRONG",{});var ZZr=s(Aie);U4o=r(ZZr,"bart"),ZZr.forEach(t),J4o=r(LAe," \u2014 "),UN=n(LAe,"A",{href:!0});var eet=s(UN);Y4o=r(eet,"BartForConditionalGeneration"),eet.forEach(t),K4o=r(LAe," (BART model)"),LAe.forEach(t),Z4o=i(H),i1=n(H,"LI",{});var xAe=s(i1);yie=n(xAe,"STRONG",{});var oet=s(yie);eEo=r(oet,"bert"),oet.forEach(t),oEo=r(xAe," \u2014 "),JN=n(xAe,"A",{href:!0});var ret=s(JN);rEo=r(ret,"BertForMaskedLM"),ret.forEach(t),tEo=r(xAe," (BERT model)"),xAe.forEach(t),aEo=i(H),d1=n(H,"LI",{});var $Ae=s(d1);Lie=n($Ae,"STRONG",{});var tet=s(Lie);nEo=r(tet,"big_bird"),tet.forEach(t),sEo=r($Ae," \u2014 "),YN=n($Ae,"A",{href:!0});var aet=s(YN);lEo=r(aet,"BigBirdForMaskedLM"),aet.forEach(t),iEo=r($Ae," (BigBird model)"),$Ae.forEach(t),dEo=i(H),c1=n(H,"LI",{});var kAe=s(c1);xie=n(kAe,"STRONG",{});var net=s(xie);cEo=r(net,"camembert"),net.forEach(t),fEo=r(kAe," \u2014 "),KN=n(kAe,"A",{href:!0});var set=s(KN);mEo=r(set,"CamembertForMaskedLM"),set.forEach(t),gEo=r(kAe," (CamemBERT model)"),kAe.forEach(t),hEo=i(H),f1=n(H,"LI",{});var SAe=s(f1);$ie=n(SAe,"STRONG",{});var iet=s($ie);pEo=r(iet,"convbert"),iet.forEach(t),uEo=r(SAe," \u2014 "),ZN=n(SAe,"A",{href:!0});var det=s(ZN);_Eo=r(det,"ConvBertForMaskedLM"),det.forEach(t),bEo=r(SAe," (ConvBERT model)"),SAe.forEach(t),vEo=i(H),m1=n(H,"LI",{});var RAe=s(m1);kie=n(RAe,"STRONG",{});var cet=s(kie);FEo=r(cet,"data2vec-text"),cet.forEach(t),TEo=r(RAe," \u2014 "),ej=n(RAe,"A",{href:!0});var fet=s(ej);MEo=r(fet,"Data2VecTextForMaskedLM"),fet.forEach(t),EEo=r(RAe," (Data2VecText model)"),RAe.forEach(t),CEo=i(H),g1=n(H,"LI",{});var BAe=s(g1);Sie=n(BAe,"STRONG",{});var met=s(Sie);wEo=r(met,"deberta"),met.forEach(t),AEo=r(BAe," \u2014 "),oj=n(BAe,"A",{href:!0});var get=s(oj);yEo=r(get,"DebertaForMaskedLM"),get.forEach(t),LEo=r(BAe," (DeBERTa model)"),BAe.forEach(t),xEo=i(H),h1=n(H,"LI",{});var PAe=s(h1);Rie=n(PAe,"STRONG",{});var het=s(Rie);$Eo=r(het,"deberta-v2"),het.forEach(t),kEo=r(PAe," \u2014 "),rj=n(PAe,"A",{href:!0});var pet=s(rj);SEo=r(pet,"DebertaV2ForMaskedLM"),pet.forEach(t),REo=r(PAe," (DeBERTa-v2 model)"),PAe.forEach(t),BEo=i(H),p1=n(H,"LI",{});var IAe=s(p1);Bie=n(IAe,"STRONG",{});var uet=s(Bie);PEo=r(uet,"distilbert"),uet.forEach(t),IEo=r(IAe," \u2014 "),tj=n(IAe,"A",{href:!0});var _et=s(tj);qEo=r(_et,"DistilBertForMaskedLM"),_et.forEach(t),NEo=r(IAe," (DistilBERT model)"),IAe.forEach(t),jEo=i(H),u1=n(H,"LI",{});var qAe=s(u1);Pie=n(qAe,"STRONG",{});var bet=s(Pie);DEo=r(bet,"electra"),bet.forEach(t),GEo=r(qAe," \u2014 "),aj=n(qAe,"A",{href:!0});var vet=s(aj);OEo=r(vet,"ElectraForMaskedLM"),vet.forEach(t),VEo=r(qAe," (ELECTRA model)"),qAe.forEach(t),XEo=i(H),_1=n(H,"LI",{});var NAe=s(_1);Iie=n(NAe,"STRONG",{});var Fet=s(Iie);zEo=r(Fet,"flaubert"),Fet.forEach(t),QEo=r(NAe," \u2014 "),nj=n(NAe,"A",{href:!0});var Tet=s(nj);WEo=r(Tet,"FlaubertWithLMHeadModel"),Tet.forEach(t),HEo=r(NAe," (FlauBERT model)"),NAe.forEach(t),UEo=i(H),b1=n(H,"LI",{});var jAe=s(b1);qie=n(jAe,"STRONG",{});var Met=s(qie);JEo=r(Met,"fnet"),Met.forEach(t),YEo=r(jAe," \u2014 "),sj=n(jAe,"A",{href:!0});var Eet=s(sj);KEo=r(Eet,"FNetForMaskedLM"),Eet.forEach(t),ZEo=r(jAe," (FNet model)"),jAe.forEach(t),e5o=i(H),v1=n(H,"LI",{});var DAe=s(v1);Nie=n(DAe,"STRONG",{});var Cet=s(Nie);o5o=r(Cet,"funnel"),Cet.forEach(t),r5o=r(DAe," \u2014 "),lj=n(DAe,"A",{href:!0});var wet=s(lj);t5o=r(wet,"FunnelForMaskedLM"),wet.forEach(t),a5o=r(DAe," (Funnel Transformer model)"),DAe.forEach(t),n5o=i(H),F1=n(H,"LI",{});var GAe=s(F1);jie=n(GAe,"STRONG",{});var Aet=s(jie);s5o=r(Aet,"ibert"),Aet.forEach(t),l5o=r(GAe," \u2014 "),ij=n(GAe,"A",{href:!0});var yet=s(ij);i5o=r(yet,"IBertForMaskedLM"),yet.forEach(t),d5o=r(GAe," (I-BERT model)"),GAe.forEach(t),c5o=i(H),T1=n(H,"LI",{});var OAe=s(T1);Die=n(OAe,"STRONG",{});var Let=s(Die);f5o=r(Let,"layoutlm"),Let.forEach(t),m5o=r(OAe," \u2014 "),dj=n(OAe,"A",{href:!0});var xet=s(dj);g5o=r(xet,"LayoutLMForMaskedLM"),xet.forEach(t),h5o=r(OAe," (LayoutLM model)"),OAe.forEach(t),p5o=i(H),M1=n(H,"LI",{});var VAe=s(M1);Gie=n(VAe,"STRONG",{});var $et=s(Gie);u5o=r($et,"longformer"),$et.forEach(t),_5o=r(VAe," \u2014 "),cj=n(VAe,"A",{href:!0});var ket=s(cj);b5o=r(ket,"LongformerForMaskedLM"),ket.forEach(t),v5o=r(VAe," (Longformer model)"),VAe.forEach(t),F5o=i(H),E1=n(H,"LI",{});var XAe=s(E1);Oie=n(XAe,"STRONG",{});var Set=s(Oie);T5o=r(Set,"mbart"),Set.forEach(t),M5o=r(XAe," \u2014 "),fj=n(XAe,"A",{href:!0});var Ret=s(fj);E5o=r(Ret,"MBartForConditionalGeneration"),Ret.forEach(t),C5o=r(XAe," (mBART model)"),XAe.forEach(t),w5o=i(H),C1=n(H,"LI",{});var zAe=s(C1);Vie=n(zAe,"STRONG",{});var Bet=s(Vie);A5o=r(Bet,"megatron-bert"),Bet.forEach(t),y5o=r(zAe," \u2014 "),mj=n(zAe,"A",{href:!0});var Pet=s(mj);L5o=r(Pet,"MegatronBertForMaskedLM"),Pet.forEach(t),x5o=r(zAe," (MegatronBert model)"),zAe.forEach(t),$5o=i(H),w1=n(H,"LI",{});var QAe=s(w1);Xie=n(QAe,"STRONG",{});var Iet=s(Xie);k5o=r(Iet,"mobilebert"),Iet.forEach(t),S5o=r(QAe," \u2014 "),gj=n(QAe,"A",{href:!0});var qet=s(gj);R5o=r(qet,"MobileBertForMaskedLM"),qet.forEach(t),B5o=r(QAe," (MobileBERT model)"),QAe.forEach(t),P5o=i(H),A1=n(H,"LI",{});var WAe=s(A1);zie=n(WAe,"STRONG",{});var Net=s(zie);I5o=r(Net,"mpnet"),Net.forEach(t),q5o=r(WAe," \u2014 "),hj=n(WAe,"A",{href:!0});var jet=s(hj);N5o=r(jet,"MPNetForMaskedLM"),jet.forEach(t),j5o=r(WAe," (MPNet model)"),WAe.forEach(t),D5o=i(H),y1=n(H,"LI",{});var HAe=s(y1);Qie=n(HAe,"STRONG",{});var Det=s(Qie);G5o=r(Det,"nystromformer"),Det.forEach(t),O5o=r(HAe," \u2014 "),pj=n(HAe,"A",{href:!0});var Get=s(pj);V5o=r(Get,"NystromformerForMaskedLM"),Get.forEach(t),X5o=r(HAe," (Nystromformer model)"),HAe.forEach(t),z5o=i(H),L1=n(H,"LI",{});var UAe=s(L1);Wie=n(UAe,"STRONG",{});var Oet=s(Wie);Q5o=r(Oet,"perceiver"),Oet.forEach(t),W5o=r(UAe," \u2014 "),uj=n(UAe,"A",{href:!0});var Vet=s(uj);H5o=r(Vet,"PerceiverForMaskedLM"),Vet.forEach(t),U5o=r(UAe," (Perceiver model)"),UAe.forEach(t),J5o=i(H),x1=n(H,"LI",{});var JAe=s(x1);Hie=n(JAe,"STRONG",{});var Xet=s(Hie);Y5o=r(Xet,"qdqbert"),Xet.forEach(t),K5o=r(JAe," \u2014 "),_j=n(JAe,"A",{href:!0});var zet=s(_j);Z5o=r(zet,"QDQBertForMaskedLM"),zet.forEach(t),eCo=r(JAe," (QDQBert model)"),JAe.forEach(t),oCo=i(H),$1=n(H,"LI",{});var YAe=s($1);Uie=n(YAe,"STRONG",{});var Qet=s(Uie);rCo=r(Qet,"reformer"),Qet.forEach(t),tCo=r(YAe," \u2014 "),bj=n(YAe,"A",{href:!0});var Wet=s(bj);aCo=r(Wet,"ReformerForMaskedLM"),Wet.forEach(t),nCo=r(YAe," (Reformer model)"),YAe.forEach(t),sCo=i(H),k1=n(H,"LI",{});var KAe=s(k1);Jie=n(KAe,"STRONG",{});var Het=s(Jie);lCo=r(Het,"rembert"),Het.forEach(t),iCo=r(KAe," \u2014 "),vj=n(KAe,"A",{href:!0});var Uet=s(vj);dCo=r(Uet,"RemBertForMaskedLM"),Uet.forEach(t),cCo=r(KAe," (RemBERT model)"),KAe.forEach(t),fCo=i(H),S1=n(H,"LI",{});var ZAe=s(S1);Yie=n(ZAe,"STRONG",{});var Jet=s(Yie);mCo=r(Jet,"roberta"),Jet.forEach(t),gCo=r(ZAe," \u2014 "),Fj=n(ZAe,"A",{href:!0});var Yet=s(Fj);hCo=r(Yet,"RobertaForMaskedLM"),Yet.forEach(t),pCo=r(ZAe," (RoBERTa model)"),ZAe.forEach(t),uCo=i(H),R1=n(H,"LI",{});var e0e=s(R1);Kie=n(e0e,"STRONG",{});var Ket=s(Kie);_Co=r(Ket,"roformer"),Ket.forEach(t),bCo=r(e0e," \u2014 "),Tj=n(e0e,"A",{href:!0});var Zet=s(Tj);vCo=r(Zet,"RoFormerForMaskedLM"),Zet.forEach(t),FCo=r(e0e," (RoFormer model)"),e0e.forEach(t),TCo=i(H),B1=n(H,"LI",{});var o0e=s(B1);Zie=n(o0e,"STRONG",{});var eot=s(Zie);MCo=r(eot,"squeezebert"),eot.forEach(t),ECo=r(o0e," \u2014 "),Mj=n(o0e,"A",{href:!0});var oot=s(Mj);CCo=r(oot,"SqueezeBertForMaskedLM"),oot.forEach(t),wCo=r(o0e," (SqueezeBERT model)"),o0e.forEach(t),ACo=i(H),P1=n(H,"LI",{});var r0e=s(P1);ede=n(r0e,"STRONG",{});var rot=s(ede);yCo=r(rot,"tapas"),rot.forEach(t),LCo=r(r0e," \u2014 "),Ej=n(r0e,"A",{href:!0});var tot=s(Ej);xCo=r(tot,"TapasForMaskedLM"),tot.forEach(t),$Co=r(r0e," (TAPAS model)"),r0e.forEach(t),kCo=i(H),I1=n(H,"LI",{});var t0e=s(I1);ode=n(t0e,"STRONG",{});var aot=s(ode);SCo=r(aot,"wav2vec2"),aot.forEach(t),RCo=r(t0e," \u2014 "),rde=n(t0e,"CODE",{});var not=s(rde);BCo=r(not,"Wav2Vec2ForMaskedLM"),not.forEach(t),PCo=r(t0e," (Wav2Vec2 model)"),t0e.forEach(t),ICo=i(H),q1=n(H,"LI",{});var a0e=s(q1);tde=n(a0e,"STRONG",{});var sot=s(tde);qCo=r(sot,"xlm"),sot.forEach(t),NCo=r(a0e," \u2014 "),Cj=n(a0e,"A",{href:!0});var lot=s(Cj);jCo=r(lot,"XLMWithLMHeadModel"),lot.forEach(t),DCo=r(a0e," (XLM model)"),a0e.forEach(t),GCo=i(H),N1=n(H,"LI",{});var n0e=s(N1);ade=n(n0e,"STRONG",{});var iot=s(ade);OCo=r(iot,"xlm-roberta"),iot.forEach(t),VCo=r(n0e," \u2014 "),wj=n(n0e,"A",{href:!0});var dot=s(wj);XCo=r(dot,"XLMRobertaForMaskedLM"),dot.forEach(t),zCo=r(n0e," (XLM-RoBERTa model)"),n0e.forEach(t),QCo=i(H),j1=n(H,"LI",{});var s0e=s(j1);nde=n(s0e,"STRONG",{});var cot=s(nde);WCo=r(cot,"xlm-roberta-xl"),cot.forEach(t),HCo=r(s0e," \u2014 "),Aj=n(s0e,"A",{href:!0});var fot=s(Aj);UCo=r(fot,"XLMRobertaXLForMaskedLM"),fot.forEach(t),JCo=r(s0e," (XLM-RoBERTa-XL model)"),s0e.forEach(t),YCo=i(H),D1=n(H,"LI",{});var l0e=s(D1);sde=n(l0e,"STRONG",{});var mot=s(sde);KCo=r(mot,"yoso"),mot.forEach(t),ZCo=r(l0e," \u2014 "),yj=n(l0e,"A",{href:!0});var got=s(yj);e3o=r(got,"YosoForMaskedLM"),got.forEach(t),o3o=r(l0e," (YOSO model)"),l0e.forEach(t),H.forEach(t),r3o=i(ra),G1=n(ra,"P",{});var i0e=s(G1);t3o=r(i0e,"The model is set in evaluation mode by default using "),lde=n(i0e,"CODE",{});var hot=s(lde);a3o=r(hot,"model.eval()"),hot.forEach(t),n3o=r(i0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ide=n(i0e,"CODE",{});var pot=s(ide);s3o=r(pot,"model.train()"),pot.forEach(t),i0e.forEach(t),l3o=i(ra),T(O1.$$.fragment,ra),ra.forEach(t),Vs.forEach(t),IPe=i(f),Bi=n(f,"H2",{class:!0});var Dqe=s(Bi);V1=n(Dqe,"A",{id:!0,class:!0,href:!0});var uot=s(V1);dde=n(uot,"SPAN",{});var _ot=s(dde);T(qA.$$.fragment,_ot),_ot.forEach(t),uot.forEach(t),i3o=i(Dqe),cde=n(Dqe,"SPAN",{});var bot=s(cde);d3o=r(bot,"AutoModelForSeq2SeqLM"),bot.forEach(t),Dqe.forEach(t),qPe=i(f),So=n(f,"DIV",{class:!0});var Xs=s(So);T(NA.$$.fragment,Xs),c3o=i(Xs),Pi=n(Xs,"P",{});var aK=s(Pi);f3o=r(aK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Lj=n(aK,"A",{href:!0});var vot=s(Lj);m3o=r(vot,"from_pretrained()"),vot.forEach(t),g3o=r(aK," class method or the "),xj=n(aK,"A",{href:!0});var Fot=s(xj);h3o=r(Fot,"from_config()"),Fot.forEach(t),p3o=r(aK,` class
method.`),aK.forEach(t),u3o=i(Xs),jA=n(Xs,"P",{});var Gqe=s(jA);_3o=r(Gqe,"This class cannot be instantiated directly using "),fde=n(Gqe,"CODE",{});var Tot=s(fde);b3o=r(Tot,"__init__()"),Tot.forEach(t),v3o=r(Gqe," (throws an error)."),Gqe.forEach(t),F3o=i(Xs),nt=n(Xs,"DIV",{class:!0});var o3=s(nt);T(DA.$$.fragment,o3),T3o=i(o3),mde=n(o3,"P",{});var Mot=s(mde);M3o=r(Mot,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Mot.forEach(t),E3o=i(o3),Ii=n(o3,"P",{});var nK=s(Ii);C3o=r(nK,`Note:
Loading a model from its configuration file does `),gde=n(nK,"STRONG",{});var Eot=s(gde);w3o=r(Eot,"not"),Eot.forEach(t),A3o=r(nK,` load the model weights. It only affects the
model\u2019s configuration. Use `),$j=n(nK,"A",{href:!0});var Cot=s($j);y3o=r(Cot,"from_pretrained()"),Cot.forEach(t),L3o=r(nK," to load the model weights."),nK.forEach(t),x3o=i(o3),T(X1.$$.fragment,o3),o3.forEach(t),$3o=i(Xs),Ke=n(Xs,"DIV",{class:!0});var ta=s(Ke);T(GA.$$.fragment,ta),k3o=i(ta),hde=n(ta,"P",{});var wot=s(hde);S3o=r(wot,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),wot.forEach(t),R3o=i(ta),$a=n(ta,"P",{});var r3=s($a);B3o=r(r3,"The model class to instantiate is selected based on the "),pde=n(r3,"CODE",{});var Aot=s(pde);P3o=r(Aot,"model_type"),Aot.forEach(t),I3o=r(r3,` property of the config object (either
passed as an argument or loaded from `),ude=n(r3,"CODE",{});var yot=s(ude);q3o=r(yot,"pretrained_model_name_or_path"),yot.forEach(t),N3o=r(r3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_de=n(r3,"CODE",{});var Lot=s(_de);j3o=r(Lot,"pretrained_model_name_or_path"),Lot.forEach(t),D3o=r(r3,":"),r3.forEach(t),G3o=i(ta),he=n(ta,"UL",{});var ue=s(he);z1=n(ue,"LI",{});var d0e=s(z1);bde=n(d0e,"STRONG",{});var xot=s(bde);O3o=r(xot,"bart"),xot.forEach(t),V3o=r(d0e," \u2014 "),kj=n(d0e,"A",{href:!0});var $ot=s(kj);X3o=r($ot,"BartForConditionalGeneration"),$ot.forEach(t),z3o=r(d0e," (BART model)"),d0e.forEach(t),Q3o=i(ue),Q1=n(ue,"LI",{});var c0e=s(Q1);vde=n(c0e,"STRONG",{});var kot=s(vde);W3o=r(kot,"bigbird_pegasus"),kot.forEach(t),H3o=r(c0e," \u2014 "),Sj=n(c0e,"A",{href:!0});var Sot=s(Sj);U3o=r(Sot,"BigBirdPegasusForConditionalGeneration"),Sot.forEach(t),J3o=r(c0e," (BigBirdPegasus model)"),c0e.forEach(t),Y3o=i(ue),W1=n(ue,"LI",{});var f0e=s(W1);Fde=n(f0e,"STRONG",{});var Rot=s(Fde);K3o=r(Rot,"blenderbot"),Rot.forEach(t),Z3o=r(f0e," \u2014 "),Rj=n(f0e,"A",{href:!0});var Bot=s(Rj);ewo=r(Bot,"BlenderbotForConditionalGeneration"),Bot.forEach(t),owo=r(f0e," (Blenderbot model)"),f0e.forEach(t),rwo=i(ue),H1=n(ue,"LI",{});var m0e=s(H1);Tde=n(m0e,"STRONG",{});var Pot=s(Tde);two=r(Pot,"blenderbot-small"),Pot.forEach(t),awo=r(m0e," \u2014 "),Bj=n(m0e,"A",{href:!0});var Iot=s(Bj);nwo=r(Iot,"BlenderbotSmallForConditionalGeneration"),Iot.forEach(t),swo=r(m0e," (BlenderbotSmall model)"),m0e.forEach(t),lwo=i(ue),U1=n(ue,"LI",{});var g0e=s(U1);Mde=n(g0e,"STRONG",{});var qot=s(Mde);iwo=r(qot,"encoder-decoder"),qot.forEach(t),dwo=r(g0e," \u2014 "),Pj=n(g0e,"A",{href:!0});var Not=s(Pj);cwo=r(Not,"EncoderDecoderModel"),Not.forEach(t),fwo=r(g0e," (Encoder decoder model)"),g0e.forEach(t),mwo=i(ue),J1=n(ue,"LI",{});var h0e=s(J1);Ede=n(h0e,"STRONG",{});var jot=s(Ede);gwo=r(jot,"fsmt"),jot.forEach(t),hwo=r(h0e," \u2014 "),Ij=n(h0e,"A",{href:!0});var Dot=s(Ij);pwo=r(Dot,"FSMTForConditionalGeneration"),Dot.forEach(t),uwo=r(h0e," (FairSeq Machine-Translation model)"),h0e.forEach(t),_wo=i(ue),Y1=n(ue,"LI",{});var p0e=s(Y1);Cde=n(p0e,"STRONG",{});var Got=s(Cde);bwo=r(Got,"led"),Got.forEach(t),vwo=r(p0e," \u2014 "),qj=n(p0e,"A",{href:!0});var Oot=s(qj);Fwo=r(Oot,"LEDForConditionalGeneration"),Oot.forEach(t),Two=r(p0e," (LED model)"),p0e.forEach(t),Mwo=i(ue),K1=n(ue,"LI",{});var u0e=s(K1);wde=n(u0e,"STRONG",{});var Vot=s(wde);Ewo=r(Vot,"m2m_100"),Vot.forEach(t),Cwo=r(u0e," \u2014 "),Nj=n(u0e,"A",{href:!0});var Xot=s(Nj);wwo=r(Xot,"M2M100ForConditionalGeneration"),Xot.forEach(t),Awo=r(u0e," (M2M100 model)"),u0e.forEach(t),ywo=i(ue),Z1=n(ue,"LI",{});var _0e=s(Z1);Ade=n(_0e,"STRONG",{});var zot=s(Ade);Lwo=r(zot,"marian"),zot.forEach(t),xwo=r(_0e," \u2014 "),jj=n(_0e,"A",{href:!0});var Qot=s(jj);$wo=r(Qot,"MarianMTModel"),Qot.forEach(t),kwo=r(_0e," (Marian model)"),_0e.forEach(t),Swo=i(ue),e8=n(ue,"LI",{});var b0e=s(e8);yde=n(b0e,"STRONG",{});var Wot=s(yde);Rwo=r(Wot,"mbart"),Wot.forEach(t),Bwo=r(b0e," \u2014 "),Dj=n(b0e,"A",{href:!0});var Hot=s(Dj);Pwo=r(Hot,"MBartForConditionalGeneration"),Hot.forEach(t),Iwo=r(b0e," (mBART model)"),b0e.forEach(t),qwo=i(ue),o8=n(ue,"LI",{});var v0e=s(o8);Lde=n(v0e,"STRONG",{});var Uot=s(Lde);Nwo=r(Uot,"mt5"),Uot.forEach(t),jwo=r(v0e," \u2014 "),Gj=n(v0e,"A",{href:!0});var Jot=s(Gj);Dwo=r(Jot,"MT5ForConditionalGeneration"),Jot.forEach(t),Gwo=r(v0e," (mT5 model)"),v0e.forEach(t),Owo=i(ue),r8=n(ue,"LI",{});var F0e=s(r8);xde=n(F0e,"STRONG",{});var Yot=s(xde);Vwo=r(Yot,"pegasus"),Yot.forEach(t),Xwo=r(F0e," \u2014 "),Oj=n(F0e,"A",{href:!0});var Kot=s(Oj);zwo=r(Kot,"PegasusForConditionalGeneration"),Kot.forEach(t),Qwo=r(F0e," (Pegasus model)"),F0e.forEach(t),Wwo=i(ue),t8=n(ue,"LI",{});var T0e=s(t8);$de=n(T0e,"STRONG",{});var Zot=s($de);Hwo=r(Zot,"plbart"),Zot.forEach(t),Uwo=r(T0e," \u2014 "),Vj=n(T0e,"A",{href:!0});var ert=s(Vj);Jwo=r(ert,"PLBartForConditionalGeneration"),ert.forEach(t),Ywo=r(T0e," (PLBart model)"),T0e.forEach(t),Kwo=i(ue),a8=n(ue,"LI",{});var M0e=s(a8);kde=n(M0e,"STRONG",{});var ort=s(kde);Zwo=r(ort,"prophetnet"),ort.forEach(t),eAo=r(M0e," \u2014 "),Xj=n(M0e,"A",{href:!0});var rrt=s(Xj);oAo=r(rrt,"ProphetNetForConditionalGeneration"),rrt.forEach(t),rAo=r(M0e," (ProphetNet model)"),M0e.forEach(t),tAo=i(ue),n8=n(ue,"LI",{});var E0e=s(n8);Sde=n(E0e,"STRONG",{});var trt=s(Sde);aAo=r(trt,"t5"),trt.forEach(t),nAo=r(E0e," \u2014 "),zj=n(E0e,"A",{href:!0});var art=s(zj);sAo=r(art,"T5ForConditionalGeneration"),art.forEach(t),lAo=r(E0e," (T5 model)"),E0e.forEach(t),iAo=i(ue),s8=n(ue,"LI",{});var C0e=s(s8);Rde=n(C0e,"STRONG",{});var nrt=s(Rde);dAo=r(nrt,"tapex"),nrt.forEach(t),cAo=r(C0e," \u2014 "),Qj=n(C0e,"A",{href:!0});var srt=s(Qj);fAo=r(srt,"BartForConditionalGeneration"),srt.forEach(t),mAo=r(C0e," (TAPEX model)"),C0e.forEach(t),gAo=i(ue),l8=n(ue,"LI",{});var w0e=s(l8);Bde=n(w0e,"STRONG",{});var lrt=s(Bde);hAo=r(lrt,"xlm-prophetnet"),lrt.forEach(t),pAo=r(w0e," \u2014 "),Wj=n(w0e,"A",{href:!0});var irt=s(Wj);uAo=r(irt,"XLMProphetNetForConditionalGeneration"),irt.forEach(t),_Ao=r(w0e," (XLMProphetNet model)"),w0e.forEach(t),ue.forEach(t),bAo=i(ta),i8=n(ta,"P",{});var A0e=s(i8);vAo=r(A0e,"The model is set in evaluation mode by default using "),Pde=n(A0e,"CODE",{});var drt=s(Pde);FAo=r(drt,"model.eval()"),drt.forEach(t),TAo=r(A0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ide=n(A0e,"CODE",{});var crt=s(Ide);MAo=r(crt,"model.train()"),crt.forEach(t),A0e.forEach(t),EAo=i(ta),T(d8.$$.fragment,ta),ta.forEach(t),Xs.forEach(t),NPe=i(f),qi=n(f,"H2",{class:!0});var Oqe=s(qi);c8=n(Oqe,"A",{id:!0,class:!0,href:!0});var frt=s(c8);qde=n(frt,"SPAN",{});var mrt=s(qde);T(OA.$$.fragment,mrt),mrt.forEach(t),frt.forEach(t),CAo=i(Oqe),Nde=n(Oqe,"SPAN",{});var grt=s(Nde);wAo=r(grt,"AutoModelForSequenceClassification"),grt.forEach(t),Oqe.forEach(t),jPe=i(f),Ro=n(f,"DIV",{class:!0});var zs=s(Ro);T(VA.$$.fragment,zs),AAo=i(zs),Ni=n(zs,"P",{});var sK=s(Ni);yAo=r(sK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Hj=n(sK,"A",{href:!0});var hrt=s(Hj);LAo=r(hrt,"from_pretrained()"),hrt.forEach(t),xAo=r(sK," class method or the "),Uj=n(sK,"A",{href:!0});var prt=s(Uj);$Ao=r(prt,"from_config()"),prt.forEach(t),kAo=r(sK,` class
method.`),sK.forEach(t),SAo=i(zs),XA=n(zs,"P",{});var Vqe=s(XA);RAo=r(Vqe,"This class cannot be instantiated directly using "),jde=n(Vqe,"CODE",{});var urt=s(jde);BAo=r(urt,"__init__()"),urt.forEach(t),PAo=r(Vqe," (throws an error)."),Vqe.forEach(t),IAo=i(zs),st=n(zs,"DIV",{class:!0});var t3=s(st);T(zA.$$.fragment,t3),qAo=i(t3),Dde=n(t3,"P",{});var _rt=s(Dde);NAo=r(_rt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),_rt.forEach(t),jAo=i(t3),ji=n(t3,"P",{});var lK=s(ji);DAo=r(lK,`Note:
Loading a model from its configuration file does `),Gde=n(lK,"STRONG",{});var brt=s(Gde);GAo=r(brt,"not"),brt.forEach(t),OAo=r(lK,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jj=n(lK,"A",{href:!0});var vrt=s(Jj);VAo=r(vrt,"from_pretrained()"),vrt.forEach(t),XAo=r(lK," to load the model weights."),lK.forEach(t),zAo=i(t3),T(f8.$$.fragment,t3),t3.forEach(t),QAo=i(zs),Ze=n(zs,"DIV",{class:!0});var aa=s(Ze);T(QA.$$.fragment,aa),WAo=i(aa),Ode=n(aa,"P",{});var Frt=s(Ode);HAo=r(Frt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Frt.forEach(t),UAo=i(aa),ka=n(aa,"P",{});var a3=s(ka);JAo=r(a3,"The model class to instantiate is selected based on the "),Vde=n(a3,"CODE",{});var Trt=s(Vde);YAo=r(Trt,"model_type"),Trt.forEach(t),KAo=r(a3,` property of the config object (either
passed as an argument or loaded from `),Xde=n(a3,"CODE",{});var Mrt=s(Xde);ZAo=r(Mrt,"pretrained_model_name_or_path"),Mrt.forEach(t),e0o=r(a3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zde=n(a3,"CODE",{});var Ert=s(zde);o0o=r(Ert,"pretrained_model_name_or_path"),Ert.forEach(t),r0o=r(a3,":"),a3.forEach(t),t0o=i(aa),q=n(aa,"UL",{});var j=s(q);m8=n(j,"LI",{});var y0e=s(m8);Qde=n(y0e,"STRONG",{});var Crt=s(Qde);a0o=r(Crt,"albert"),Crt.forEach(t),n0o=r(y0e," \u2014 "),Yj=n(y0e,"A",{href:!0});var wrt=s(Yj);s0o=r(wrt,"AlbertForSequenceClassification"),wrt.forEach(t),l0o=r(y0e," (ALBERT model)"),y0e.forEach(t),i0o=i(j),g8=n(j,"LI",{});var L0e=s(g8);Wde=n(L0e,"STRONG",{});var Art=s(Wde);d0o=r(Art,"bart"),Art.forEach(t),c0o=r(L0e," \u2014 "),Kj=n(L0e,"A",{href:!0});var yrt=s(Kj);f0o=r(yrt,"BartForSequenceClassification"),yrt.forEach(t),m0o=r(L0e," (BART model)"),L0e.forEach(t),g0o=i(j),h8=n(j,"LI",{});var x0e=s(h8);Hde=n(x0e,"STRONG",{});var Lrt=s(Hde);h0o=r(Lrt,"bert"),Lrt.forEach(t),p0o=r(x0e," \u2014 "),Zj=n(x0e,"A",{href:!0});var xrt=s(Zj);u0o=r(xrt,"BertForSequenceClassification"),xrt.forEach(t),_0o=r(x0e," (BERT model)"),x0e.forEach(t),b0o=i(j),p8=n(j,"LI",{});var $0e=s(p8);Ude=n($0e,"STRONG",{});var $rt=s(Ude);v0o=r($rt,"big_bird"),$rt.forEach(t),F0o=r($0e," \u2014 "),eD=n($0e,"A",{href:!0});var krt=s(eD);T0o=r(krt,"BigBirdForSequenceClassification"),krt.forEach(t),M0o=r($0e," (BigBird model)"),$0e.forEach(t),E0o=i(j),u8=n(j,"LI",{});var k0e=s(u8);Jde=n(k0e,"STRONG",{});var Srt=s(Jde);C0o=r(Srt,"bigbird_pegasus"),Srt.forEach(t),w0o=r(k0e," \u2014 "),oD=n(k0e,"A",{href:!0});var Rrt=s(oD);A0o=r(Rrt,"BigBirdPegasusForSequenceClassification"),Rrt.forEach(t),y0o=r(k0e," (BigBirdPegasus model)"),k0e.forEach(t),L0o=i(j),_8=n(j,"LI",{});var S0e=s(_8);Yde=n(S0e,"STRONG",{});var Brt=s(Yde);x0o=r(Brt,"camembert"),Brt.forEach(t),$0o=r(S0e," \u2014 "),rD=n(S0e,"A",{href:!0});var Prt=s(rD);k0o=r(Prt,"CamembertForSequenceClassification"),Prt.forEach(t),S0o=r(S0e," (CamemBERT model)"),S0e.forEach(t),R0o=i(j),b8=n(j,"LI",{});var R0e=s(b8);Kde=n(R0e,"STRONG",{});var Irt=s(Kde);B0o=r(Irt,"canine"),Irt.forEach(t),P0o=r(R0e," \u2014 "),tD=n(R0e,"A",{href:!0});var qrt=s(tD);I0o=r(qrt,"CanineForSequenceClassification"),qrt.forEach(t),q0o=r(R0e," (Canine model)"),R0e.forEach(t),N0o=i(j),v8=n(j,"LI",{});var B0e=s(v8);Zde=n(B0e,"STRONG",{});var Nrt=s(Zde);j0o=r(Nrt,"convbert"),Nrt.forEach(t),D0o=r(B0e," \u2014 "),aD=n(B0e,"A",{href:!0});var jrt=s(aD);G0o=r(jrt,"ConvBertForSequenceClassification"),jrt.forEach(t),O0o=r(B0e," (ConvBERT model)"),B0e.forEach(t),V0o=i(j),F8=n(j,"LI",{});var P0e=s(F8);ece=n(P0e,"STRONG",{});var Drt=s(ece);X0o=r(Drt,"ctrl"),Drt.forEach(t),z0o=r(P0e," \u2014 "),nD=n(P0e,"A",{href:!0});var Grt=s(nD);Q0o=r(Grt,"CTRLForSequenceClassification"),Grt.forEach(t),W0o=r(P0e," (CTRL model)"),P0e.forEach(t),H0o=i(j),T8=n(j,"LI",{});var I0e=s(T8);oce=n(I0e,"STRONG",{});var Ort=s(oce);U0o=r(Ort,"data2vec-text"),Ort.forEach(t),J0o=r(I0e," \u2014 "),sD=n(I0e,"A",{href:!0});var Vrt=s(sD);Y0o=r(Vrt,"Data2VecTextForSequenceClassification"),Vrt.forEach(t),K0o=r(I0e," (Data2VecText model)"),I0e.forEach(t),Z0o=i(j),M8=n(j,"LI",{});var q0e=s(M8);rce=n(q0e,"STRONG",{});var Xrt=s(rce);eyo=r(Xrt,"deberta"),Xrt.forEach(t),oyo=r(q0e," \u2014 "),lD=n(q0e,"A",{href:!0});var zrt=s(lD);ryo=r(zrt,"DebertaForSequenceClassification"),zrt.forEach(t),tyo=r(q0e," (DeBERTa model)"),q0e.forEach(t),ayo=i(j),E8=n(j,"LI",{});var N0e=s(E8);tce=n(N0e,"STRONG",{});var Qrt=s(tce);nyo=r(Qrt,"deberta-v2"),Qrt.forEach(t),syo=r(N0e," \u2014 "),iD=n(N0e,"A",{href:!0});var Wrt=s(iD);lyo=r(Wrt,"DebertaV2ForSequenceClassification"),Wrt.forEach(t),iyo=r(N0e," (DeBERTa-v2 model)"),N0e.forEach(t),dyo=i(j),C8=n(j,"LI",{});var j0e=s(C8);ace=n(j0e,"STRONG",{});var Hrt=s(ace);cyo=r(Hrt,"distilbert"),Hrt.forEach(t),fyo=r(j0e," \u2014 "),dD=n(j0e,"A",{href:!0});var Urt=s(dD);myo=r(Urt,"DistilBertForSequenceClassification"),Urt.forEach(t),gyo=r(j0e," (DistilBERT model)"),j0e.forEach(t),hyo=i(j),w8=n(j,"LI",{});var D0e=s(w8);nce=n(D0e,"STRONG",{});var Jrt=s(nce);pyo=r(Jrt,"electra"),Jrt.forEach(t),uyo=r(D0e," \u2014 "),cD=n(D0e,"A",{href:!0});var Yrt=s(cD);_yo=r(Yrt,"ElectraForSequenceClassification"),Yrt.forEach(t),byo=r(D0e," (ELECTRA model)"),D0e.forEach(t),vyo=i(j),A8=n(j,"LI",{});var G0e=s(A8);sce=n(G0e,"STRONG",{});var Krt=s(sce);Fyo=r(Krt,"flaubert"),Krt.forEach(t),Tyo=r(G0e," \u2014 "),fD=n(G0e,"A",{href:!0});var Zrt=s(fD);Myo=r(Zrt,"FlaubertForSequenceClassification"),Zrt.forEach(t),Eyo=r(G0e," (FlauBERT model)"),G0e.forEach(t),Cyo=i(j),y8=n(j,"LI",{});var O0e=s(y8);lce=n(O0e,"STRONG",{});var ett=s(lce);wyo=r(ett,"fnet"),ett.forEach(t),Ayo=r(O0e," \u2014 "),mD=n(O0e,"A",{href:!0});var ott=s(mD);yyo=r(ott,"FNetForSequenceClassification"),ott.forEach(t),Lyo=r(O0e," (FNet model)"),O0e.forEach(t),xyo=i(j),L8=n(j,"LI",{});var V0e=s(L8);ice=n(V0e,"STRONG",{});var rtt=s(ice);$yo=r(rtt,"funnel"),rtt.forEach(t),kyo=r(V0e," \u2014 "),gD=n(V0e,"A",{href:!0});var ttt=s(gD);Syo=r(ttt,"FunnelForSequenceClassification"),ttt.forEach(t),Ryo=r(V0e," (Funnel Transformer model)"),V0e.forEach(t),Byo=i(j),x8=n(j,"LI",{});var X0e=s(x8);dce=n(X0e,"STRONG",{});var att=s(dce);Pyo=r(att,"gpt2"),att.forEach(t),Iyo=r(X0e," \u2014 "),hD=n(X0e,"A",{href:!0});var ntt=s(hD);qyo=r(ntt,"GPT2ForSequenceClassification"),ntt.forEach(t),Nyo=r(X0e," (OpenAI GPT-2 model)"),X0e.forEach(t),jyo=i(j),$8=n(j,"LI",{});var z0e=s($8);cce=n(z0e,"STRONG",{});var stt=s(cce);Dyo=r(stt,"gpt_neo"),stt.forEach(t),Gyo=r(z0e," \u2014 "),pD=n(z0e,"A",{href:!0});var ltt=s(pD);Oyo=r(ltt,"GPTNeoForSequenceClassification"),ltt.forEach(t),Vyo=r(z0e," (GPT Neo model)"),z0e.forEach(t),Xyo=i(j),k8=n(j,"LI",{});var Q0e=s(k8);fce=n(Q0e,"STRONG",{});var itt=s(fce);zyo=r(itt,"gptj"),itt.forEach(t),Qyo=r(Q0e," \u2014 "),uD=n(Q0e,"A",{href:!0});var dtt=s(uD);Wyo=r(dtt,"GPTJForSequenceClassification"),dtt.forEach(t),Hyo=r(Q0e," (GPT-J model)"),Q0e.forEach(t),Uyo=i(j),S8=n(j,"LI",{});var W0e=s(S8);mce=n(W0e,"STRONG",{});var ctt=s(mce);Jyo=r(ctt,"ibert"),ctt.forEach(t),Yyo=r(W0e," \u2014 "),_D=n(W0e,"A",{href:!0});var ftt=s(_D);Kyo=r(ftt,"IBertForSequenceClassification"),ftt.forEach(t),Zyo=r(W0e," (I-BERT model)"),W0e.forEach(t),eLo=i(j),R8=n(j,"LI",{});var H0e=s(R8);gce=n(H0e,"STRONG",{});var mtt=s(gce);oLo=r(mtt,"layoutlm"),mtt.forEach(t),rLo=r(H0e," \u2014 "),bD=n(H0e,"A",{href:!0});var gtt=s(bD);tLo=r(gtt,"LayoutLMForSequenceClassification"),gtt.forEach(t),aLo=r(H0e," (LayoutLM model)"),H0e.forEach(t),nLo=i(j),B8=n(j,"LI",{});var U0e=s(B8);hce=n(U0e,"STRONG",{});var htt=s(hce);sLo=r(htt,"layoutlmv2"),htt.forEach(t),lLo=r(U0e," \u2014 "),vD=n(U0e,"A",{href:!0});var ptt=s(vD);iLo=r(ptt,"LayoutLMv2ForSequenceClassification"),ptt.forEach(t),dLo=r(U0e," (LayoutLMv2 model)"),U0e.forEach(t),cLo=i(j),P8=n(j,"LI",{});var J0e=s(P8);pce=n(J0e,"STRONG",{});var utt=s(pce);fLo=r(utt,"led"),utt.forEach(t),mLo=r(J0e," \u2014 "),FD=n(J0e,"A",{href:!0});var _tt=s(FD);gLo=r(_tt,"LEDForSequenceClassification"),_tt.forEach(t),hLo=r(J0e," (LED model)"),J0e.forEach(t),pLo=i(j),I8=n(j,"LI",{});var Y0e=s(I8);uce=n(Y0e,"STRONG",{});var btt=s(uce);uLo=r(btt,"longformer"),btt.forEach(t),_Lo=r(Y0e," \u2014 "),TD=n(Y0e,"A",{href:!0});var vtt=s(TD);bLo=r(vtt,"LongformerForSequenceClassification"),vtt.forEach(t),vLo=r(Y0e," (Longformer model)"),Y0e.forEach(t),FLo=i(j),q8=n(j,"LI",{});var K0e=s(q8);_ce=n(K0e,"STRONG",{});var Ftt=s(_ce);TLo=r(Ftt,"mbart"),Ftt.forEach(t),MLo=r(K0e," \u2014 "),MD=n(K0e,"A",{href:!0});var Ttt=s(MD);ELo=r(Ttt,"MBartForSequenceClassification"),Ttt.forEach(t),CLo=r(K0e," (mBART model)"),K0e.forEach(t),wLo=i(j),N8=n(j,"LI",{});var Z0e=s(N8);bce=n(Z0e,"STRONG",{});var Mtt=s(bce);ALo=r(Mtt,"megatron-bert"),Mtt.forEach(t),yLo=r(Z0e," \u2014 "),ED=n(Z0e,"A",{href:!0});var Ett=s(ED);LLo=r(Ett,"MegatronBertForSequenceClassification"),Ett.forEach(t),xLo=r(Z0e," (MegatronBert model)"),Z0e.forEach(t),$Lo=i(j),j8=n(j,"LI",{});var eye=s(j8);vce=n(eye,"STRONG",{});var Ctt=s(vce);kLo=r(Ctt,"mobilebert"),Ctt.forEach(t),SLo=r(eye," \u2014 "),CD=n(eye,"A",{href:!0});var wtt=s(CD);RLo=r(wtt,"MobileBertForSequenceClassification"),wtt.forEach(t),BLo=r(eye," (MobileBERT model)"),eye.forEach(t),PLo=i(j),D8=n(j,"LI",{});var oye=s(D8);Fce=n(oye,"STRONG",{});var Att=s(Fce);ILo=r(Att,"mpnet"),Att.forEach(t),qLo=r(oye," \u2014 "),wD=n(oye,"A",{href:!0});var ytt=s(wD);NLo=r(ytt,"MPNetForSequenceClassification"),ytt.forEach(t),jLo=r(oye," (MPNet model)"),oye.forEach(t),DLo=i(j),G8=n(j,"LI",{});var rye=s(G8);Tce=n(rye,"STRONG",{});var Ltt=s(Tce);GLo=r(Ltt,"nystromformer"),Ltt.forEach(t),OLo=r(rye," \u2014 "),AD=n(rye,"A",{href:!0});var xtt=s(AD);VLo=r(xtt,"NystromformerForSequenceClassification"),xtt.forEach(t),XLo=r(rye," (Nystromformer model)"),rye.forEach(t),zLo=i(j),O8=n(j,"LI",{});var tye=s(O8);Mce=n(tye,"STRONG",{});var $tt=s(Mce);QLo=r($tt,"openai-gpt"),$tt.forEach(t),WLo=r(tye," \u2014 "),yD=n(tye,"A",{href:!0});var ktt=s(yD);HLo=r(ktt,"OpenAIGPTForSequenceClassification"),ktt.forEach(t),ULo=r(tye," (OpenAI GPT model)"),tye.forEach(t),JLo=i(j),V8=n(j,"LI",{});var aye=s(V8);Ece=n(aye,"STRONG",{});var Stt=s(Ece);YLo=r(Stt,"perceiver"),Stt.forEach(t),KLo=r(aye," \u2014 "),LD=n(aye,"A",{href:!0});var Rtt=s(LD);ZLo=r(Rtt,"PerceiverForSequenceClassification"),Rtt.forEach(t),exo=r(aye," (Perceiver model)"),aye.forEach(t),oxo=i(j),X8=n(j,"LI",{});var nye=s(X8);Cce=n(nye,"STRONG",{});var Btt=s(Cce);rxo=r(Btt,"plbart"),Btt.forEach(t),txo=r(nye," \u2014 "),xD=n(nye,"A",{href:!0});var Ptt=s(xD);axo=r(Ptt,"PLBartForSequenceClassification"),Ptt.forEach(t),nxo=r(nye," (PLBart model)"),nye.forEach(t),sxo=i(j),z8=n(j,"LI",{});var sye=s(z8);wce=n(sye,"STRONG",{});var Itt=s(wce);lxo=r(Itt,"qdqbert"),Itt.forEach(t),ixo=r(sye," \u2014 "),$D=n(sye,"A",{href:!0});var qtt=s($D);dxo=r(qtt,"QDQBertForSequenceClassification"),qtt.forEach(t),cxo=r(sye," (QDQBert model)"),sye.forEach(t),fxo=i(j),Q8=n(j,"LI",{});var lye=s(Q8);Ace=n(lye,"STRONG",{});var Ntt=s(Ace);mxo=r(Ntt,"reformer"),Ntt.forEach(t),gxo=r(lye," \u2014 "),kD=n(lye,"A",{href:!0});var jtt=s(kD);hxo=r(jtt,"ReformerForSequenceClassification"),jtt.forEach(t),pxo=r(lye," (Reformer model)"),lye.forEach(t),uxo=i(j),W8=n(j,"LI",{});var iye=s(W8);yce=n(iye,"STRONG",{});var Dtt=s(yce);_xo=r(Dtt,"rembert"),Dtt.forEach(t),bxo=r(iye," \u2014 "),SD=n(iye,"A",{href:!0});var Gtt=s(SD);vxo=r(Gtt,"RemBertForSequenceClassification"),Gtt.forEach(t),Fxo=r(iye," (RemBERT model)"),iye.forEach(t),Txo=i(j),H8=n(j,"LI",{});var dye=s(H8);Lce=n(dye,"STRONG",{});var Ott=s(Lce);Mxo=r(Ott,"roberta"),Ott.forEach(t),Exo=r(dye," \u2014 "),RD=n(dye,"A",{href:!0});var Vtt=s(RD);Cxo=r(Vtt,"RobertaForSequenceClassification"),Vtt.forEach(t),wxo=r(dye," (RoBERTa model)"),dye.forEach(t),Axo=i(j),U8=n(j,"LI",{});var cye=s(U8);xce=n(cye,"STRONG",{});var Xtt=s(xce);yxo=r(Xtt,"roformer"),Xtt.forEach(t),Lxo=r(cye," \u2014 "),BD=n(cye,"A",{href:!0});var ztt=s(BD);xxo=r(ztt,"RoFormerForSequenceClassification"),ztt.forEach(t),$xo=r(cye," (RoFormer model)"),cye.forEach(t),kxo=i(j),J8=n(j,"LI",{});var fye=s(J8);$ce=n(fye,"STRONG",{});var Qtt=s($ce);Sxo=r(Qtt,"squeezebert"),Qtt.forEach(t),Rxo=r(fye," \u2014 "),PD=n(fye,"A",{href:!0});var Wtt=s(PD);Bxo=r(Wtt,"SqueezeBertForSequenceClassification"),Wtt.forEach(t),Pxo=r(fye," (SqueezeBERT model)"),fye.forEach(t),Ixo=i(j),Y8=n(j,"LI",{});var mye=s(Y8);kce=n(mye,"STRONG",{});var Htt=s(kce);qxo=r(Htt,"tapas"),Htt.forEach(t),Nxo=r(mye," \u2014 "),ID=n(mye,"A",{href:!0});var Utt=s(ID);jxo=r(Utt,"TapasForSequenceClassification"),Utt.forEach(t),Dxo=r(mye," (TAPAS model)"),mye.forEach(t),Gxo=i(j),K8=n(j,"LI",{});var gye=s(K8);Sce=n(gye,"STRONG",{});var Jtt=s(Sce);Oxo=r(Jtt,"tapex"),Jtt.forEach(t),Vxo=r(gye," \u2014 "),qD=n(gye,"A",{href:!0});var Ytt=s(qD);Xxo=r(Ytt,"BartForSequenceClassification"),Ytt.forEach(t),zxo=r(gye," (TAPEX model)"),gye.forEach(t),Qxo=i(j),Z8=n(j,"LI",{});var hye=s(Z8);Rce=n(hye,"STRONG",{});var Ktt=s(Rce);Wxo=r(Ktt,"transfo-xl"),Ktt.forEach(t),Hxo=r(hye," \u2014 "),ND=n(hye,"A",{href:!0});var Ztt=s(ND);Uxo=r(Ztt,"TransfoXLForSequenceClassification"),Ztt.forEach(t),Jxo=r(hye," (Transformer-XL model)"),hye.forEach(t),Yxo=i(j),eb=n(j,"LI",{});var pye=s(eb);Bce=n(pye,"STRONG",{});var eat=s(Bce);Kxo=r(eat,"xlm"),eat.forEach(t),Zxo=r(pye," \u2014 "),jD=n(pye,"A",{href:!0});var oat=s(jD);e7o=r(oat,"XLMForSequenceClassification"),oat.forEach(t),o7o=r(pye," (XLM model)"),pye.forEach(t),r7o=i(j),ob=n(j,"LI",{});var uye=s(ob);Pce=n(uye,"STRONG",{});var rat=s(Pce);t7o=r(rat,"xlm-roberta"),rat.forEach(t),a7o=r(uye," \u2014 "),DD=n(uye,"A",{href:!0});var tat=s(DD);n7o=r(tat,"XLMRobertaForSequenceClassification"),tat.forEach(t),s7o=r(uye," (XLM-RoBERTa model)"),uye.forEach(t),l7o=i(j),rb=n(j,"LI",{});var _ye=s(rb);Ice=n(_ye,"STRONG",{});var aat=s(Ice);i7o=r(aat,"xlm-roberta-xl"),aat.forEach(t),d7o=r(_ye," \u2014 "),GD=n(_ye,"A",{href:!0});var nat=s(GD);c7o=r(nat,"XLMRobertaXLForSequenceClassification"),nat.forEach(t),f7o=r(_ye," (XLM-RoBERTa-XL model)"),_ye.forEach(t),m7o=i(j),tb=n(j,"LI",{});var bye=s(tb);qce=n(bye,"STRONG",{});var sat=s(qce);g7o=r(sat,"xlnet"),sat.forEach(t),h7o=r(bye," \u2014 "),OD=n(bye,"A",{href:!0});var lat=s(OD);p7o=r(lat,"XLNetForSequenceClassification"),lat.forEach(t),u7o=r(bye," (XLNet model)"),bye.forEach(t),_7o=i(j),ab=n(j,"LI",{});var vye=s(ab);Nce=n(vye,"STRONG",{});var iat=s(Nce);b7o=r(iat,"yoso"),iat.forEach(t),v7o=r(vye," \u2014 "),VD=n(vye,"A",{href:!0});var dat=s(VD);F7o=r(dat,"YosoForSequenceClassification"),dat.forEach(t),T7o=r(vye," (YOSO model)"),vye.forEach(t),j.forEach(t),M7o=i(aa),nb=n(aa,"P",{});var Fye=s(nb);E7o=r(Fye,"The model is set in evaluation mode by default using "),jce=n(Fye,"CODE",{});var cat=s(jce);C7o=r(cat,"model.eval()"),cat.forEach(t),w7o=r(Fye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dce=n(Fye,"CODE",{});var fat=s(Dce);A7o=r(fat,"model.train()"),fat.forEach(t),Fye.forEach(t),y7o=i(aa),T(sb.$$.fragment,aa),aa.forEach(t),zs.forEach(t),DPe=i(f),Di=n(f,"H2",{class:!0});var Xqe=s(Di);lb=n(Xqe,"A",{id:!0,class:!0,href:!0});var mat=s(lb);Gce=n(mat,"SPAN",{});var gat=s(Gce);T(WA.$$.fragment,gat),gat.forEach(t),mat.forEach(t),L7o=i(Xqe),Oce=n(Xqe,"SPAN",{});var hat=s(Oce);x7o=r(hat,"AutoModelForMultipleChoice"),hat.forEach(t),Xqe.forEach(t),GPe=i(f),Bo=n(f,"DIV",{class:!0});var Qs=s(Bo);T(HA.$$.fragment,Qs),$7o=i(Qs),Gi=n(Qs,"P",{});var iK=s(Gi);k7o=r(iK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),XD=n(iK,"A",{href:!0});var pat=s(XD);S7o=r(pat,"from_pretrained()"),pat.forEach(t),R7o=r(iK," class method or the "),zD=n(iK,"A",{href:!0});var uat=s(zD);B7o=r(uat,"from_config()"),uat.forEach(t),P7o=r(iK,` class
method.`),iK.forEach(t),I7o=i(Qs),UA=n(Qs,"P",{});var zqe=s(UA);q7o=r(zqe,"This class cannot be instantiated directly using "),Vce=n(zqe,"CODE",{});var _at=s(Vce);N7o=r(_at,"__init__()"),_at.forEach(t),j7o=r(zqe," (throws an error)."),zqe.forEach(t),D7o=i(Qs),lt=n(Qs,"DIV",{class:!0});var n3=s(lt);T(JA.$$.fragment,n3),G7o=i(n3),Xce=n(n3,"P",{});var bat=s(Xce);O7o=r(bat,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),bat.forEach(t),V7o=i(n3),Oi=n(n3,"P",{});var dK=s(Oi);X7o=r(dK,`Note:
Loading a model from its configuration file does `),zce=n(dK,"STRONG",{});var vat=s(zce);z7o=r(vat,"not"),vat.forEach(t),Q7o=r(dK,` load the model weights. It only affects the
model\u2019s configuration. Use `),QD=n(dK,"A",{href:!0});var Fat=s(QD);W7o=r(Fat,"from_pretrained()"),Fat.forEach(t),H7o=r(dK," to load the model weights."),dK.forEach(t),U7o=i(n3),T(ib.$$.fragment,n3),n3.forEach(t),J7o=i(Qs),eo=n(Qs,"DIV",{class:!0});var na=s(eo);T(YA.$$.fragment,na),Y7o=i(na),Qce=n(na,"P",{});var Tat=s(Qce);K7o=r(Tat,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Tat.forEach(t),Z7o=i(na),Sa=n(na,"P",{});var s3=s(Sa);e$o=r(s3,"The model class to instantiate is selected based on the "),Wce=n(s3,"CODE",{});var Mat=s(Wce);o$o=r(Mat,"model_type"),Mat.forEach(t),r$o=r(s3,` property of the config object (either
passed as an argument or loaded from `),Hce=n(s3,"CODE",{});var Eat=s(Hce);t$o=r(Eat,"pretrained_model_name_or_path"),Eat.forEach(t),a$o=r(s3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uce=n(s3,"CODE",{});var Cat=s(Uce);n$o=r(Cat,"pretrained_model_name_or_path"),Cat.forEach(t),s$o=r(s3,":"),s3.forEach(t),l$o=i(na),Y=n(na,"UL",{});var K=s(Y);db=n(K,"LI",{});var Tye=s(db);Jce=n(Tye,"STRONG",{});var wat=s(Jce);i$o=r(wat,"albert"),wat.forEach(t),d$o=r(Tye," \u2014 "),WD=n(Tye,"A",{href:!0});var Aat=s(WD);c$o=r(Aat,"AlbertForMultipleChoice"),Aat.forEach(t),f$o=r(Tye," (ALBERT model)"),Tye.forEach(t),m$o=i(K),cb=n(K,"LI",{});var Mye=s(cb);Yce=n(Mye,"STRONG",{});var yat=s(Yce);g$o=r(yat,"bert"),yat.forEach(t),h$o=r(Mye," \u2014 "),HD=n(Mye,"A",{href:!0});var Lat=s(HD);p$o=r(Lat,"BertForMultipleChoice"),Lat.forEach(t),u$o=r(Mye," (BERT model)"),Mye.forEach(t),_$o=i(K),fb=n(K,"LI",{});var Eye=s(fb);Kce=n(Eye,"STRONG",{});var xat=s(Kce);b$o=r(xat,"big_bird"),xat.forEach(t),v$o=r(Eye," \u2014 "),UD=n(Eye,"A",{href:!0});var $at=s(UD);F$o=r($at,"BigBirdForMultipleChoice"),$at.forEach(t),T$o=r(Eye," (BigBird model)"),Eye.forEach(t),M$o=i(K),mb=n(K,"LI",{});var Cye=s(mb);Zce=n(Cye,"STRONG",{});var kat=s(Zce);E$o=r(kat,"camembert"),kat.forEach(t),C$o=r(Cye," \u2014 "),JD=n(Cye,"A",{href:!0});var Sat=s(JD);w$o=r(Sat,"CamembertForMultipleChoice"),Sat.forEach(t),A$o=r(Cye," (CamemBERT model)"),Cye.forEach(t),y$o=i(K),gb=n(K,"LI",{});var wye=s(gb);efe=n(wye,"STRONG",{});var Rat=s(efe);L$o=r(Rat,"canine"),Rat.forEach(t),x$o=r(wye," \u2014 "),YD=n(wye,"A",{href:!0});var Bat=s(YD);$$o=r(Bat,"CanineForMultipleChoice"),Bat.forEach(t),k$o=r(wye," (Canine model)"),wye.forEach(t),S$o=i(K),hb=n(K,"LI",{});var Aye=s(hb);ofe=n(Aye,"STRONG",{});var Pat=s(ofe);R$o=r(Pat,"convbert"),Pat.forEach(t),B$o=r(Aye," \u2014 "),KD=n(Aye,"A",{href:!0});var Iat=s(KD);P$o=r(Iat,"ConvBertForMultipleChoice"),Iat.forEach(t),I$o=r(Aye," (ConvBERT model)"),Aye.forEach(t),q$o=i(K),pb=n(K,"LI",{});var yye=s(pb);rfe=n(yye,"STRONG",{});var qat=s(rfe);N$o=r(qat,"data2vec-text"),qat.forEach(t),j$o=r(yye," \u2014 "),ZD=n(yye,"A",{href:!0});var Nat=s(ZD);D$o=r(Nat,"Data2VecTextForMultipleChoice"),Nat.forEach(t),G$o=r(yye," (Data2VecText model)"),yye.forEach(t),O$o=i(K),ub=n(K,"LI",{});var Lye=s(ub);tfe=n(Lye,"STRONG",{});var jat=s(tfe);V$o=r(jat,"deberta-v2"),jat.forEach(t),X$o=r(Lye," \u2014 "),eG=n(Lye,"A",{href:!0});var Dat=s(eG);z$o=r(Dat,"DebertaV2ForMultipleChoice"),Dat.forEach(t),Q$o=r(Lye," (DeBERTa-v2 model)"),Lye.forEach(t),W$o=i(K),_b=n(K,"LI",{});var xye=s(_b);afe=n(xye,"STRONG",{});var Gat=s(afe);H$o=r(Gat,"distilbert"),Gat.forEach(t),U$o=r(xye," \u2014 "),oG=n(xye,"A",{href:!0});var Oat=s(oG);J$o=r(Oat,"DistilBertForMultipleChoice"),Oat.forEach(t),Y$o=r(xye," (DistilBERT model)"),xye.forEach(t),K$o=i(K),bb=n(K,"LI",{});var $ye=s(bb);nfe=n($ye,"STRONG",{});var Vat=s(nfe);Z$o=r(Vat,"electra"),Vat.forEach(t),eko=r($ye," \u2014 "),rG=n($ye,"A",{href:!0});var Xat=s(rG);oko=r(Xat,"ElectraForMultipleChoice"),Xat.forEach(t),rko=r($ye," (ELECTRA model)"),$ye.forEach(t),tko=i(K),vb=n(K,"LI",{});var kye=s(vb);sfe=n(kye,"STRONG",{});var zat=s(sfe);ako=r(zat,"flaubert"),zat.forEach(t),nko=r(kye," \u2014 "),tG=n(kye,"A",{href:!0});var Qat=s(tG);sko=r(Qat,"FlaubertForMultipleChoice"),Qat.forEach(t),lko=r(kye," (FlauBERT model)"),kye.forEach(t),iko=i(K),Fb=n(K,"LI",{});var Sye=s(Fb);lfe=n(Sye,"STRONG",{});var Wat=s(lfe);dko=r(Wat,"fnet"),Wat.forEach(t),cko=r(Sye," \u2014 "),aG=n(Sye,"A",{href:!0});var Hat=s(aG);fko=r(Hat,"FNetForMultipleChoice"),Hat.forEach(t),mko=r(Sye," (FNet model)"),Sye.forEach(t),gko=i(K),Tb=n(K,"LI",{});var Rye=s(Tb);ife=n(Rye,"STRONG",{});var Uat=s(ife);hko=r(Uat,"funnel"),Uat.forEach(t),pko=r(Rye," \u2014 "),nG=n(Rye,"A",{href:!0});var Jat=s(nG);uko=r(Jat,"FunnelForMultipleChoice"),Jat.forEach(t),_ko=r(Rye," (Funnel Transformer model)"),Rye.forEach(t),bko=i(K),Mb=n(K,"LI",{});var Bye=s(Mb);dfe=n(Bye,"STRONG",{});var Yat=s(dfe);vko=r(Yat,"ibert"),Yat.forEach(t),Fko=r(Bye," \u2014 "),sG=n(Bye,"A",{href:!0});var Kat=s(sG);Tko=r(Kat,"IBertForMultipleChoice"),Kat.forEach(t),Mko=r(Bye," (I-BERT model)"),Bye.forEach(t),Eko=i(K),Eb=n(K,"LI",{});var Pye=s(Eb);cfe=n(Pye,"STRONG",{});var Zat=s(cfe);Cko=r(Zat,"longformer"),Zat.forEach(t),wko=r(Pye," \u2014 "),lG=n(Pye,"A",{href:!0});var ent=s(lG);Ako=r(ent,"LongformerForMultipleChoice"),ent.forEach(t),yko=r(Pye," (Longformer model)"),Pye.forEach(t),Lko=i(K),Cb=n(K,"LI",{});var Iye=s(Cb);ffe=n(Iye,"STRONG",{});var ont=s(ffe);xko=r(ont,"megatron-bert"),ont.forEach(t),$ko=r(Iye," \u2014 "),iG=n(Iye,"A",{href:!0});var rnt=s(iG);kko=r(rnt,"MegatronBertForMultipleChoice"),rnt.forEach(t),Sko=r(Iye," (MegatronBert model)"),Iye.forEach(t),Rko=i(K),wb=n(K,"LI",{});var qye=s(wb);mfe=n(qye,"STRONG",{});var tnt=s(mfe);Bko=r(tnt,"mobilebert"),tnt.forEach(t),Pko=r(qye," \u2014 "),dG=n(qye,"A",{href:!0});var ant=s(dG);Iko=r(ant,"MobileBertForMultipleChoice"),ant.forEach(t),qko=r(qye," (MobileBERT model)"),qye.forEach(t),Nko=i(K),Ab=n(K,"LI",{});var Nye=s(Ab);gfe=n(Nye,"STRONG",{});var nnt=s(gfe);jko=r(nnt,"mpnet"),nnt.forEach(t),Dko=r(Nye," \u2014 "),cG=n(Nye,"A",{href:!0});var snt=s(cG);Gko=r(snt,"MPNetForMultipleChoice"),snt.forEach(t),Oko=r(Nye," (MPNet model)"),Nye.forEach(t),Vko=i(K),yb=n(K,"LI",{});var jye=s(yb);hfe=n(jye,"STRONG",{});var lnt=s(hfe);Xko=r(lnt,"nystromformer"),lnt.forEach(t),zko=r(jye," \u2014 "),fG=n(jye,"A",{href:!0});var int=s(fG);Qko=r(int,"NystromformerForMultipleChoice"),int.forEach(t),Wko=r(jye," (Nystromformer model)"),jye.forEach(t),Hko=i(K),Lb=n(K,"LI",{});var Dye=s(Lb);pfe=n(Dye,"STRONG",{});var dnt=s(pfe);Uko=r(dnt,"qdqbert"),dnt.forEach(t),Jko=r(Dye," \u2014 "),mG=n(Dye,"A",{href:!0});var cnt=s(mG);Yko=r(cnt,"QDQBertForMultipleChoice"),cnt.forEach(t),Kko=r(Dye," (QDQBert model)"),Dye.forEach(t),Zko=i(K),xb=n(K,"LI",{});var Gye=s(xb);ufe=n(Gye,"STRONG",{});var fnt=s(ufe);eSo=r(fnt,"rembert"),fnt.forEach(t),oSo=r(Gye," \u2014 "),gG=n(Gye,"A",{href:!0});var mnt=s(gG);rSo=r(mnt,"RemBertForMultipleChoice"),mnt.forEach(t),tSo=r(Gye," (RemBERT model)"),Gye.forEach(t),aSo=i(K),$b=n(K,"LI",{});var Oye=s($b);_fe=n(Oye,"STRONG",{});var gnt=s(_fe);nSo=r(gnt,"roberta"),gnt.forEach(t),sSo=r(Oye," \u2014 "),hG=n(Oye,"A",{href:!0});var hnt=s(hG);lSo=r(hnt,"RobertaForMultipleChoice"),hnt.forEach(t),iSo=r(Oye," (RoBERTa model)"),Oye.forEach(t),dSo=i(K),kb=n(K,"LI",{});var Vye=s(kb);bfe=n(Vye,"STRONG",{});var pnt=s(bfe);cSo=r(pnt,"roformer"),pnt.forEach(t),fSo=r(Vye," \u2014 "),pG=n(Vye,"A",{href:!0});var unt=s(pG);mSo=r(unt,"RoFormerForMultipleChoice"),unt.forEach(t),gSo=r(Vye," (RoFormer model)"),Vye.forEach(t),hSo=i(K),Sb=n(K,"LI",{});var Xye=s(Sb);vfe=n(Xye,"STRONG",{});var _nt=s(vfe);pSo=r(_nt,"squeezebert"),_nt.forEach(t),uSo=r(Xye," \u2014 "),uG=n(Xye,"A",{href:!0});var bnt=s(uG);_So=r(bnt,"SqueezeBertForMultipleChoice"),bnt.forEach(t),bSo=r(Xye," (SqueezeBERT model)"),Xye.forEach(t),vSo=i(K),Rb=n(K,"LI",{});var zye=s(Rb);Ffe=n(zye,"STRONG",{});var vnt=s(Ffe);FSo=r(vnt,"xlm"),vnt.forEach(t),TSo=r(zye," \u2014 "),_G=n(zye,"A",{href:!0});var Fnt=s(_G);MSo=r(Fnt,"XLMForMultipleChoice"),Fnt.forEach(t),ESo=r(zye," (XLM model)"),zye.forEach(t),CSo=i(K),Bb=n(K,"LI",{});var Qye=s(Bb);Tfe=n(Qye,"STRONG",{});var Tnt=s(Tfe);wSo=r(Tnt,"xlm-roberta"),Tnt.forEach(t),ASo=r(Qye," \u2014 "),bG=n(Qye,"A",{href:!0});var Mnt=s(bG);ySo=r(Mnt,"XLMRobertaForMultipleChoice"),Mnt.forEach(t),LSo=r(Qye," (XLM-RoBERTa model)"),Qye.forEach(t),xSo=i(K),Pb=n(K,"LI",{});var Wye=s(Pb);Mfe=n(Wye,"STRONG",{});var Ent=s(Mfe);$So=r(Ent,"xlm-roberta-xl"),Ent.forEach(t),kSo=r(Wye," \u2014 "),vG=n(Wye,"A",{href:!0});var Cnt=s(vG);SSo=r(Cnt,"XLMRobertaXLForMultipleChoice"),Cnt.forEach(t),RSo=r(Wye," (XLM-RoBERTa-XL model)"),Wye.forEach(t),BSo=i(K),Ib=n(K,"LI",{});var Hye=s(Ib);Efe=n(Hye,"STRONG",{});var wnt=s(Efe);PSo=r(wnt,"xlnet"),wnt.forEach(t),ISo=r(Hye," \u2014 "),FG=n(Hye,"A",{href:!0});var Ant=s(FG);qSo=r(Ant,"XLNetForMultipleChoice"),Ant.forEach(t),NSo=r(Hye," (XLNet model)"),Hye.forEach(t),jSo=i(K),qb=n(K,"LI",{});var Uye=s(qb);Cfe=n(Uye,"STRONG",{});var ynt=s(Cfe);DSo=r(ynt,"yoso"),ynt.forEach(t),GSo=r(Uye," \u2014 "),TG=n(Uye,"A",{href:!0});var Lnt=s(TG);OSo=r(Lnt,"YosoForMultipleChoice"),Lnt.forEach(t),VSo=r(Uye," (YOSO model)"),Uye.forEach(t),K.forEach(t),XSo=i(na),Nb=n(na,"P",{});var Jye=s(Nb);zSo=r(Jye,"The model is set in evaluation mode by default using "),wfe=n(Jye,"CODE",{});var xnt=s(wfe);QSo=r(xnt,"model.eval()"),xnt.forEach(t),WSo=r(Jye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Afe=n(Jye,"CODE",{});var $nt=s(Afe);HSo=r($nt,"model.train()"),$nt.forEach(t),Jye.forEach(t),USo=i(na),T(jb.$$.fragment,na),na.forEach(t),Qs.forEach(t),OPe=i(f),Vi=n(f,"H2",{class:!0});var Qqe=s(Vi);Db=n(Qqe,"A",{id:!0,class:!0,href:!0});var knt=s(Db);yfe=n(knt,"SPAN",{});var Snt=s(yfe);T(KA.$$.fragment,Snt),Snt.forEach(t),knt.forEach(t),JSo=i(Qqe),Lfe=n(Qqe,"SPAN",{});var Rnt=s(Lfe);YSo=r(Rnt,"AutoModelForNextSentencePrediction"),Rnt.forEach(t),Qqe.forEach(t),VPe=i(f),Po=n(f,"DIV",{class:!0});var Ws=s(Po);T(ZA.$$.fragment,Ws),KSo=i(Ws),Xi=n(Ws,"P",{});var cK=s(Xi);ZSo=r(cK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),MG=n(cK,"A",{href:!0});var Bnt=s(MG);eRo=r(Bnt,"from_pretrained()"),Bnt.forEach(t),oRo=r(cK," class method or the "),EG=n(cK,"A",{href:!0});var Pnt=s(EG);rRo=r(Pnt,"from_config()"),Pnt.forEach(t),tRo=r(cK,` class
method.`),cK.forEach(t),aRo=i(Ws),e0=n(Ws,"P",{});var Wqe=s(e0);nRo=r(Wqe,"This class cannot be instantiated directly using "),xfe=n(Wqe,"CODE",{});var Int=s(xfe);sRo=r(Int,"__init__()"),Int.forEach(t),lRo=r(Wqe," (throws an error)."),Wqe.forEach(t),iRo=i(Ws),it=n(Ws,"DIV",{class:!0});var l3=s(it);T(o0.$$.fragment,l3),dRo=i(l3),$fe=n(l3,"P",{});var qnt=s($fe);cRo=r(qnt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),qnt.forEach(t),fRo=i(l3),zi=n(l3,"P",{});var fK=s(zi);mRo=r(fK,`Note:
Loading a model from its configuration file does `),kfe=n(fK,"STRONG",{});var Nnt=s(kfe);gRo=r(Nnt,"not"),Nnt.forEach(t),hRo=r(fK,` load the model weights. It only affects the
model\u2019s configuration. Use `),CG=n(fK,"A",{href:!0});var jnt=s(CG);pRo=r(jnt,"from_pretrained()"),jnt.forEach(t),uRo=r(fK," to load the model weights."),fK.forEach(t),_Ro=i(l3),T(Gb.$$.fragment,l3),l3.forEach(t),bRo=i(Ws),oo=n(Ws,"DIV",{class:!0});var sa=s(oo);T(r0.$$.fragment,sa),vRo=i(sa),Sfe=n(sa,"P",{});var Dnt=s(Sfe);FRo=r(Dnt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Dnt.forEach(t),TRo=i(sa),Ra=n(sa,"P",{});var i3=s(Ra);MRo=r(i3,"The model class to instantiate is selected based on the "),Rfe=n(i3,"CODE",{});var Gnt=s(Rfe);ERo=r(Gnt,"model_type"),Gnt.forEach(t),CRo=r(i3,` property of the config object (either
passed as an argument or loaded from `),Bfe=n(i3,"CODE",{});var Ont=s(Bfe);wRo=r(Ont,"pretrained_model_name_or_path"),Ont.forEach(t),ARo=r(i3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pfe=n(i3,"CODE",{});var Vnt=s(Pfe);yRo=r(Vnt,"pretrained_model_name_or_path"),Vnt.forEach(t),LRo=r(i3,":"),i3.forEach(t),xRo=i(sa),Yr=n(sa,"UL",{});var Hs=s(Yr);Ob=n(Hs,"LI",{});var Yye=s(Ob);Ife=n(Yye,"STRONG",{});var Xnt=s(Ife);$Ro=r(Xnt,"bert"),Xnt.forEach(t),kRo=r(Yye," \u2014 "),wG=n(Yye,"A",{href:!0});var znt=s(wG);SRo=r(znt,"BertForNextSentencePrediction"),znt.forEach(t),RRo=r(Yye," (BERT model)"),Yye.forEach(t),BRo=i(Hs),Vb=n(Hs,"LI",{});var Kye=s(Vb);qfe=n(Kye,"STRONG",{});var Qnt=s(qfe);PRo=r(Qnt,"fnet"),Qnt.forEach(t),IRo=r(Kye," \u2014 "),AG=n(Kye,"A",{href:!0});var Wnt=s(AG);qRo=r(Wnt,"FNetForNextSentencePrediction"),Wnt.forEach(t),NRo=r(Kye," (FNet model)"),Kye.forEach(t),jRo=i(Hs),Xb=n(Hs,"LI",{});var Zye=s(Xb);Nfe=n(Zye,"STRONG",{});var Hnt=s(Nfe);DRo=r(Hnt,"megatron-bert"),Hnt.forEach(t),GRo=r(Zye," \u2014 "),yG=n(Zye,"A",{href:!0});var Unt=s(yG);ORo=r(Unt,"MegatronBertForNextSentencePrediction"),Unt.forEach(t),VRo=r(Zye," (MegatronBert model)"),Zye.forEach(t),XRo=i(Hs),zb=n(Hs,"LI",{});var eLe=s(zb);jfe=n(eLe,"STRONG",{});var Jnt=s(jfe);zRo=r(Jnt,"mobilebert"),Jnt.forEach(t),QRo=r(eLe," \u2014 "),LG=n(eLe,"A",{href:!0});var Ynt=s(LG);WRo=r(Ynt,"MobileBertForNextSentencePrediction"),Ynt.forEach(t),HRo=r(eLe," (MobileBERT model)"),eLe.forEach(t),URo=i(Hs),Qb=n(Hs,"LI",{});var oLe=s(Qb);Dfe=n(oLe,"STRONG",{});var Knt=s(Dfe);JRo=r(Knt,"qdqbert"),Knt.forEach(t),YRo=r(oLe," \u2014 "),xG=n(oLe,"A",{href:!0});var Znt=s(xG);KRo=r(Znt,"QDQBertForNextSentencePrediction"),Znt.forEach(t),ZRo=r(oLe," (QDQBert model)"),oLe.forEach(t),Hs.forEach(t),eBo=i(sa),Wb=n(sa,"P",{});var rLe=s(Wb);oBo=r(rLe,"The model is set in evaluation mode by default using "),Gfe=n(rLe,"CODE",{});var est=s(Gfe);rBo=r(est,"model.eval()"),est.forEach(t),tBo=r(rLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=n(rLe,"CODE",{});var ost=s(Ofe);aBo=r(ost,"model.train()"),ost.forEach(t),rLe.forEach(t),nBo=i(sa),T(Hb.$$.fragment,sa),sa.forEach(t),Ws.forEach(t),XPe=i(f),Qi=n(f,"H2",{class:!0});var Hqe=s(Qi);Ub=n(Hqe,"A",{id:!0,class:!0,href:!0});var rst=s(Ub);Vfe=n(rst,"SPAN",{});var tst=s(Vfe);T(t0.$$.fragment,tst),tst.forEach(t),rst.forEach(t),sBo=i(Hqe),Xfe=n(Hqe,"SPAN",{});var ast=s(Xfe);lBo=r(ast,"AutoModelForTokenClassification"),ast.forEach(t),Hqe.forEach(t),zPe=i(f),Io=n(f,"DIV",{class:!0});var Us=s(Io);T(a0.$$.fragment,Us),iBo=i(Us),Wi=n(Us,"P",{});var mK=s(Wi);dBo=r(mK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$G=n(mK,"A",{href:!0});var nst=s($G);cBo=r(nst,"from_pretrained()"),nst.forEach(t),fBo=r(mK," class method or the "),kG=n(mK,"A",{href:!0});var sst=s(kG);mBo=r(sst,"from_config()"),sst.forEach(t),gBo=r(mK,` class
method.`),mK.forEach(t),hBo=i(Us),n0=n(Us,"P",{});var Uqe=s(n0);pBo=r(Uqe,"This class cannot be instantiated directly using "),zfe=n(Uqe,"CODE",{});var lst=s(zfe);uBo=r(lst,"__init__()"),lst.forEach(t),_Bo=r(Uqe," (throws an error)."),Uqe.forEach(t),bBo=i(Us),dt=n(Us,"DIV",{class:!0});var d3=s(dt);T(s0.$$.fragment,d3),vBo=i(d3),Qfe=n(d3,"P",{});var ist=s(Qfe);FBo=r(ist,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ist.forEach(t),TBo=i(d3),Hi=n(d3,"P",{});var gK=s(Hi);MBo=r(gK,`Note:
Loading a model from its configuration file does `),Wfe=n(gK,"STRONG",{});var dst=s(Wfe);EBo=r(dst,"not"),dst.forEach(t),CBo=r(gK,` load the model weights. It only affects the
model\u2019s configuration. Use `),SG=n(gK,"A",{href:!0});var cst=s(SG);wBo=r(cst,"from_pretrained()"),cst.forEach(t),ABo=r(gK," to load the model weights."),gK.forEach(t),yBo=i(d3),T(Jb.$$.fragment,d3),d3.forEach(t),LBo=i(Us),ro=n(Us,"DIV",{class:!0});var la=s(ro);T(l0.$$.fragment,la),xBo=i(la),Hfe=n(la,"P",{});var fst=s(Hfe);$Bo=r(fst,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),fst.forEach(t),kBo=i(la),Ba=n(la,"P",{});var c3=s(Ba);SBo=r(c3,"The model class to instantiate is selected based on the "),Ufe=n(c3,"CODE",{});var mst=s(Ufe);RBo=r(mst,"model_type"),mst.forEach(t),BBo=r(c3,` property of the config object (either
passed as an argument or loaded from `),Jfe=n(c3,"CODE",{});var gst=s(Jfe);PBo=r(gst,"pretrained_model_name_or_path"),gst.forEach(t),IBo=r(c3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=n(c3,"CODE",{});var hst=s(Yfe);qBo=r(hst,"pretrained_model_name_or_path"),hst.forEach(t),NBo=r(c3,":"),c3.forEach(t),jBo=i(la),U=n(la,"UL",{});var J=s(U);Yb=n(J,"LI",{});var tLe=s(Yb);Kfe=n(tLe,"STRONG",{});var pst=s(Kfe);DBo=r(pst,"albert"),pst.forEach(t),GBo=r(tLe," \u2014 "),RG=n(tLe,"A",{href:!0});var ust=s(RG);OBo=r(ust,"AlbertForTokenClassification"),ust.forEach(t),VBo=r(tLe," (ALBERT model)"),tLe.forEach(t),XBo=i(J),Kb=n(J,"LI",{});var aLe=s(Kb);Zfe=n(aLe,"STRONG",{});var _st=s(Zfe);zBo=r(_st,"bert"),_st.forEach(t),QBo=r(aLe," \u2014 "),BG=n(aLe,"A",{href:!0});var bst=s(BG);WBo=r(bst,"BertForTokenClassification"),bst.forEach(t),HBo=r(aLe," (BERT model)"),aLe.forEach(t),UBo=i(J),Zb=n(J,"LI",{});var nLe=s(Zb);eme=n(nLe,"STRONG",{});var vst=s(eme);JBo=r(vst,"big_bird"),vst.forEach(t),YBo=r(nLe," \u2014 "),PG=n(nLe,"A",{href:!0});var Fst=s(PG);KBo=r(Fst,"BigBirdForTokenClassification"),Fst.forEach(t),ZBo=r(nLe," (BigBird model)"),nLe.forEach(t),ePo=i(J),e2=n(J,"LI",{});var sLe=s(e2);ome=n(sLe,"STRONG",{});var Tst=s(ome);oPo=r(Tst,"camembert"),Tst.forEach(t),rPo=r(sLe," \u2014 "),IG=n(sLe,"A",{href:!0});var Mst=s(IG);tPo=r(Mst,"CamembertForTokenClassification"),Mst.forEach(t),aPo=r(sLe," (CamemBERT model)"),sLe.forEach(t),nPo=i(J),o2=n(J,"LI",{});var lLe=s(o2);rme=n(lLe,"STRONG",{});var Est=s(rme);sPo=r(Est,"canine"),Est.forEach(t),lPo=r(lLe," \u2014 "),qG=n(lLe,"A",{href:!0});var Cst=s(qG);iPo=r(Cst,"CanineForTokenClassification"),Cst.forEach(t),dPo=r(lLe," (Canine model)"),lLe.forEach(t),cPo=i(J),r2=n(J,"LI",{});var iLe=s(r2);tme=n(iLe,"STRONG",{});var wst=s(tme);fPo=r(wst,"convbert"),wst.forEach(t),mPo=r(iLe," \u2014 "),NG=n(iLe,"A",{href:!0});var Ast=s(NG);gPo=r(Ast,"ConvBertForTokenClassification"),Ast.forEach(t),hPo=r(iLe," (ConvBERT model)"),iLe.forEach(t),pPo=i(J),t2=n(J,"LI",{});var dLe=s(t2);ame=n(dLe,"STRONG",{});var yst=s(ame);uPo=r(yst,"data2vec-text"),yst.forEach(t),_Po=r(dLe," \u2014 "),jG=n(dLe,"A",{href:!0});var Lst=s(jG);bPo=r(Lst,"Data2VecTextForTokenClassification"),Lst.forEach(t),vPo=r(dLe," (Data2VecText model)"),dLe.forEach(t),FPo=i(J),a2=n(J,"LI",{});var cLe=s(a2);nme=n(cLe,"STRONG",{});var xst=s(nme);TPo=r(xst,"deberta"),xst.forEach(t),MPo=r(cLe," \u2014 "),DG=n(cLe,"A",{href:!0});var $st=s(DG);EPo=r($st,"DebertaForTokenClassification"),$st.forEach(t),CPo=r(cLe," (DeBERTa model)"),cLe.forEach(t),wPo=i(J),n2=n(J,"LI",{});var fLe=s(n2);sme=n(fLe,"STRONG",{});var kst=s(sme);APo=r(kst,"deberta-v2"),kst.forEach(t),yPo=r(fLe," \u2014 "),GG=n(fLe,"A",{href:!0});var Sst=s(GG);LPo=r(Sst,"DebertaV2ForTokenClassification"),Sst.forEach(t),xPo=r(fLe," (DeBERTa-v2 model)"),fLe.forEach(t),$Po=i(J),s2=n(J,"LI",{});var mLe=s(s2);lme=n(mLe,"STRONG",{});var Rst=s(lme);kPo=r(Rst,"distilbert"),Rst.forEach(t),SPo=r(mLe," \u2014 "),OG=n(mLe,"A",{href:!0});var Bst=s(OG);RPo=r(Bst,"DistilBertForTokenClassification"),Bst.forEach(t),BPo=r(mLe," (DistilBERT model)"),mLe.forEach(t),PPo=i(J),l2=n(J,"LI",{});var gLe=s(l2);ime=n(gLe,"STRONG",{});var Pst=s(ime);IPo=r(Pst,"electra"),Pst.forEach(t),qPo=r(gLe," \u2014 "),VG=n(gLe,"A",{href:!0});var Ist=s(VG);NPo=r(Ist,"ElectraForTokenClassification"),Ist.forEach(t),jPo=r(gLe," (ELECTRA model)"),gLe.forEach(t),DPo=i(J),i2=n(J,"LI",{});var hLe=s(i2);dme=n(hLe,"STRONG",{});var qst=s(dme);GPo=r(qst,"flaubert"),qst.forEach(t),OPo=r(hLe," \u2014 "),XG=n(hLe,"A",{href:!0});var Nst=s(XG);VPo=r(Nst,"FlaubertForTokenClassification"),Nst.forEach(t),XPo=r(hLe," (FlauBERT model)"),hLe.forEach(t),zPo=i(J),d2=n(J,"LI",{});var pLe=s(d2);cme=n(pLe,"STRONG",{});var jst=s(cme);QPo=r(jst,"fnet"),jst.forEach(t),WPo=r(pLe," \u2014 "),zG=n(pLe,"A",{href:!0});var Dst=s(zG);HPo=r(Dst,"FNetForTokenClassification"),Dst.forEach(t),UPo=r(pLe," (FNet model)"),pLe.forEach(t),JPo=i(J),c2=n(J,"LI",{});var uLe=s(c2);fme=n(uLe,"STRONG",{});var Gst=s(fme);YPo=r(Gst,"funnel"),Gst.forEach(t),KPo=r(uLe," \u2014 "),QG=n(uLe,"A",{href:!0});var Ost=s(QG);ZPo=r(Ost,"FunnelForTokenClassification"),Ost.forEach(t),eIo=r(uLe," (Funnel Transformer model)"),uLe.forEach(t),oIo=i(J),f2=n(J,"LI",{});var _Le=s(f2);mme=n(_Le,"STRONG",{});var Vst=s(mme);rIo=r(Vst,"gpt2"),Vst.forEach(t),tIo=r(_Le," \u2014 "),WG=n(_Le,"A",{href:!0});var Xst=s(WG);aIo=r(Xst,"GPT2ForTokenClassification"),Xst.forEach(t),nIo=r(_Le," (OpenAI GPT-2 model)"),_Le.forEach(t),sIo=i(J),m2=n(J,"LI",{});var bLe=s(m2);gme=n(bLe,"STRONG",{});var zst=s(gme);lIo=r(zst,"ibert"),zst.forEach(t),iIo=r(bLe," \u2014 "),HG=n(bLe,"A",{href:!0});var Qst=s(HG);dIo=r(Qst,"IBertForTokenClassification"),Qst.forEach(t),cIo=r(bLe," (I-BERT model)"),bLe.forEach(t),fIo=i(J),g2=n(J,"LI",{});var vLe=s(g2);hme=n(vLe,"STRONG",{});var Wst=s(hme);mIo=r(Wst,"layoutlm"),Wst.forEach(t),gIo=r(vLe," \u2014 "),UG=n(vLe,"A",{href:!0});var Hst=s(UG);hIo=r(Hst,"LayoutLMForTokenClassification"),Hst.forEach(t),pIo=r(vLe," (LayoutLM model)"),vLe.forEach(t),uIo=i(J),h2=n(J,"LI",{});var FLe=s(h2);pme=n(FLe,"STRONG",{});var Ust=s(pme);_Io=r(Ust,"layoutlmv2"),Ust.forEach(t),bIo=r(FLe," \u2014 "),JG=n(FLe,"A",{href:!0});var Jst=s(JG);vIo=r(Jst,"LayoutLMv2ForTokenClassification"),Jst.forEach(t),FIo=r(FLe," (LayoutLMv2 model)"),FLe.forEach(t),TIo=i(J),p2=n(J,"LI",{});var TLe=s(p2);ume=n(TLe,"STRONG",{});var Yst=s(ume);MIo=r(Yst,"longformer"),Yst.forEach(t),EIo=r(TLe," \u2014 "),YG=n(TLe,"A",{href:!0});var Kst=s(YG);CIo=r(Kst,"LongformerForTokenClassification"),Kst.forEach(t),wIo=r(TLe," (Longformer model)"),TLe.forEach(t),AIo=i(J),u2=n(J,"LI",{});var MLe=s(u2);_me=n(MLe,"STRONG",{});var Zst=s(_me);yIo=r(Zst,"megatron-bert"),Zst.forEach(t),LIo=r(MLe," \u2014 "),KG=n(MLe,"A",{href:!0});var elt=s(KG);xIo=r(elt,"MegatronBertForTokenClassification"),elt.forEach(t),$Io=r(MLe," (MegatronBert model)"),MLe.forEach(t),kIo=i(J),_2=n(J,"LI",{});var ELe=s(_2);bme=n(ELe,"STRONG",{});var olt=s(bme);SIo=r(olt,"mobilebert"),olt.forEach(t),RIo=r(ELe," \u2014 "),ZG=n(ELe,"A",{href:!0});var rlt=s(ZG);BIo=r(rlt,"MobileBertForTokenClassification"),rlt.forEach(t),PIo=r(ELe," (MobileBERT model)"),ELe.forEach(t),IIo=i(J),b2=n(J,"LI",{});var CLe=s(b2);vme=n(CLe,"STRONG",{});var tlt=s(vme);qIo=r(tlt,"mpnet"),tlt.forEach(t),NIo=r(CLe," \u2014 "),eO=n(CLe,"A",{href:!0});var alt=s(eO);jIo=r(alt,"MPNetForTokenClassification"),alt.forEach(t),DIo=r(CLe," (MPNet model)"),CLe.forEach(t),GIo=i(J),v2=n(J,"LI",{});var wLe=s(v2);Fme=n(wLe,"STRONG",{});var nlt=s(Fme);OIo=r(nlt,"nystromformer"),nlt.forEach(t),VIo=r(wLe," \u2014 "),oO=n(wLe,"A",{href:!0});var slt=s(oO);XIo=r(slt,"NystromformerForTokenClassification"),slt.forEach(t),zIo=r(wLe," (Nystromformer model)"),wLe.forEach(t),QIo=i(J),F2=n(J,"LI",{});var ALe=s(F2);Tme=n(ALe,"STRONG",{});var llt=s(Tme);WIo=r(llt,"qdqbert"),llt.forEach(t),HIo=r(ALe," \u2014 "),rO=n(ALe,"A",{href:!0});var ilt=s(rO);UIo=r(ilt,"QDQBertForTokenClassification"),ilt.forEach(t),JIo=r(ALe," (QDQBert model)"),ALe.forEach(t),YIo=i(J),T2=n(J,"LI",{});var yLe=s(T2);Mme=n(yLe,"STRONG",{});var dlt=s(Mme);KIo=r(dlt,"rembert"),dlt.forEach(t),ZIo=r(yLe," \u2014 "),tO=n(yLe,"A",{href:!0});var clt=s(tO);eqo=r(clt,"RemBertForTokenClassification"),clt.forEach(t),oqo=r(yLe," (RemBERT model)"),yLe.forEach(t),rqo=i(J),M2=n(J,"LI",{});var LLe=s(M2);Eme=n(LLe,"STRONG",{});var flt=s(Eme);tqo=r(flt,"roberta"),flt.forEach(t),aqo=r(LLe," \u2014 "),aO=n(LLe,"A",{href:!0});var mlt=s(aO);nqo=r(mlt,"RobertaForTokenClassification"),mlt.forEach(t),sqo=r(LLe," (RoBERTa model)"),LLe.forEach(t),lqo=i(J),E2=n(J,"LI",{});var xLe=s(E2);Cme=n(xLe,"STRONG",{});var glt=s(Cme);iqo=r(glt,"roformer"),glt.forEach(t),dqo=r(xLe," \u2014 "),nO=n(xLe,"A",{href:!0});var hlt=s(nO);cqo=r(hlt,"RoFormerForTokenClassification"),hlt.forEach(t),fqo=r(xLe," (RoFormer model)"),xLe.forEach(t),mqo=i(J),C2=n(J,"LI",{});var $Le=s(C2);wme=n($Le,"STRONG",{});var plt=s(wme);gqo=r(plt,"squeezebert"),plt.forEach(t),hqo=r($Le," \u2014 "),sO=n($Le,"A",{href:!0});var ult=s(sO);pqo=r(ult,"SqueezeBertForTokenClassification"),ult.forEach(t),uqo=r($Le," (SqueezeBERT model)"),$Le.forEach(t),_qo=i(J),w2=n(J,"LI",{});var kLe=s(w2);Ame=n(kLe,"STRONG",{});var _lt=s(Ame);bqo=r(_lt,"xlm"),_lt.forEach(t),vqo=r(kLe," \u2014 "),lO=n(kLe,"A",{href:!0});var blt=s(lO);Fqo=r(blt,"XLMForTokenClassification"),blt.forEach(t),Tqo=r(kLe," (XLM model)"),kLe.forEach(t),Mqo=i(J),A2=n(J,"LI",{});var SLe=s(A2);yme=n(SLe,"STRONG",{});var vlt=s(yme);Eqo=r(vlt,"xlm-roberta"),vlt.forEach(t),Cqo=r(SLe," \u2014 "),iO=n(SLe,"A",{href:!0});var Flt=s(iO);wqo=r(Flt,"XLMRobertaForTokenClassification"),Flt.forEach(t),Aqo=r(SLe," (XLM-RoBERTa model)"),SLe.forEach(t),yqo=i(J),y2=n(J,"LI",{});var RLe=s(y2);Lme=n(RLe,"STRONG",{});var Tlt=s(Lme);Lqo=r(Tlt,"xlm-roberta-xl"),Tlt.forEach(t),xqo=r(RLe," \u2014 "),dO=n(RLe,"A",{href:!0});var Mlt=s(dO);$qo=r(Mlt,"XLMRobertaXLForTokenClassification"),Mlt.forEach(t),kqo=r(RLe," (XLM-RoBERTa-XL model)"),RLe.forEach(t),Sqo=i(J),L2=n(J,"LI",{});var BLe=s(L2);xme=n(BLe,"STRONG",{});var Elt=s(xme);Rqo=r(Elt,"xlnet"),Elt.forEach(t),Bqo=r(BLe," \u2014 "),cO=n(BLe,"A",{href:!0});var Clt=s(cO);Pqo=r(Clt,"XLNetForTokenClassification"),Clt.forEach(t),Iqo=r(BLe," (XLNet model)"),BLe.forEach(t),qqo=i(J),x2=n(J,"LI",{});var PLe=s(x2);$me=n(PLe,"STRONG",{});var wlt=s($me);Nqo=r(wlt,"yoso"),wlt.forEach(t),jqo=r(PLe," \u2014 "),fO=n(PLe,"A",{href:!0});var Alt=s(fO);Dqo=r(Alt,"YosoForTokenClassification"),Alt.forEach(t),Gqo=r(PLe," (YOSO model)"),PLe.forEach(t),J.forEach(t),Oqo=i(la),$2=n(la,"P",{});var ILe=s($2);Vqo=r(ILe,"The model is set in evaluation mode by default using "),kme=n(ILe,"CODE",{});var ylt=s(kme);Xqo=r(ylt,"model.eval()"),ylt.forEach(t),zqo=r(ILe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sme=n(ILe,"CODE",{});var Llt=s(Sme);Qqo=r(Llt,"model.train()"),Llt.forEach(t),ILe.forEach(t),Wqo=i(la),T(k2.$$.fragment,la),la.forEach(t),Us.forEach(t),QPe=i(f),Ui=n(f,"H2",{class:!0});var Jqe=s(Ui);S2=n(Jqe,"A",{id:!0,class:!0,href:!0});var xlt=s(S2);Rme=n(xlt,"SPAN",{});var $lt=s(Rme);T(i0.$$.fragment,$lt),$lt.forEach(t),xlt.forEach(t),Hqo=i(Jqe),Bme=n(Jqe,"SPAN",{});var klt=s(Bme);Uqo=r(klt,"AutoModelForQuestionAnswering"),klt.forEach(t),Jqe.forEach(t),WPe=i(f),qo=n(f,"DIV",{class:!0});var Js=s(qo);T(d0.$$.fragment,Js),Jqo=i(Js),Ji=n(Js,"P",{});var hK=s(Ji);Yqo=r(hK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),mO=n(hK,"A",{href:!0});var Slt=s(mO);Kqo=r(Slt,"from_pretrained()"),Slt.forEach(t),Zqo=r(hK," class method or the "),gO=n(hK,"A",{href:!0});var Rlt=s(gO);eNo=r(Rlt,"from_config()"),Rlt.forEach(t),oNo=r(hK,` class
method.`),hK.forEach(t),rNo=i(Js),c0=n(Js,"P",{});var Yqe=s(c0);tNo=r(Yqe,"This class cannot be instantiated directly using "),Pme=n(Yqe,"CODE",{});var Blt=s(Pme);aNo=r(Blt,"__init__()"),Blt.forEach(t),nNo=r(Yqe," (throws an error)."),Yqe.forEach(t),sNo=i(Js),ct=n(Js,"DIV",{class:!0});var f3=s(ct);T(f0.$$.fragment,f3),lNo=i(f3),Ime=n(f3,"P",{});var Plt=s(Ime);iNo=r(Plt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Plt.forEach(t),dNo=i(f3),Yi=n(f3,"P",{});var pK=s(Yi);cNo=r(pK,`Note:
Loading a model from its configuration file does `),qme=n(pK,"STRONG",{});var Ilt=s(qme);fNo=r(Ilt,"not"),Ilt.forEach(t),mNo=r(pK,` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=n(pK,"A",{href:!0});var qlt=s(hO);gNo=r(qlt,"from_pretrained()"),qlt.forEach(t),hNo=r(pK," to load the model weights."),pK.forEach(t),pNo=i(f3),T(R2.$$.fragment,f3),f3.forEach(t),uNo=i(Js),to=n(Js,"DIV",{class:!0});var ia=s(to);T(m0.$$.fragment,ia),_No=i(ia),Nme=n(ia,"P",{});var Nlt=s(Nme);bNo=r(Nlt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Nlt.forEach(t),vNo=i(ia),Pa=n(ia,"P",{});var m3=s(Pa);FNo=r(m3,"The model class to instantiate is selected based on the "),jme=n(m3,"CODE",{});var jlt=s(jme);TNo=r(jlt,"model_type"),jlt.forEach(t),MNo=r(m3,` property of the config object (either
passed as an argument or loaded from `),Dme=n(m3,"CODE",{});var Dlt=s(Dme);ENo=r(Dlt,"pretrained_model_name_or_path"),Dlt.forEach(t),CNo=r(m3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gme=n(m3,"CODE",{});var Glt=s(Gme);wNo=r(Glt,"pretrained_model_name_or_path"),Glt.forEach(t),ANo=r(m3,":"),m3.forEach(t),yNo=i(ia),O=n(ia,"UL",{});var X=s(O);B2=n(X,"LI",{});var qLe=s(B2);Ome=n(qLe,"STRONG",{});var Olt=s(Ome);LNo=r(Olt,"albert"),Olt.forEach(t),xNo=r(qLe," \u2014 "),pO=n(qLe,"A",{href:!0});var Vlt=s(pO);$No=r(Vlt,"AlbertForQuestionAnswering"),Vlt.forEach(t),kNo=r(qLe," (ALBERT model)"),qLe.forEach(t),SNo=i(X),P2=n(X,"LI",{});var NLe=s(P2);Vme=n(NLe,"STRONG",{});var Xlt=s(Vme);RNo=r(Xlt,"bart"),Xlt.forEach(t),BNo=r(NLe," \u2014 "),uO=n(NLe,"A",{href:!0});var zlt=s(uO);PNo=r(zlt,"BartForQuestionAnswering"),zlt.forEach(t),INo=r(NLe," (BART model)"),NLe.forEach(t),qNo=i(X),I2=n(X,"LI",{});var jLe=s(I2);Xme=n(jLe,"STRONG",{});var Qlt=s(Xme);NNo=r(Qlt,"bert"),Qlt.forEach(t),jNo=r(jLe," \u2014 "),_O=n(jLe,"A",{href:!0});var Wlt=s(_O);DNo=r(Wlt,"BertForQuestionAnswering"),Wlt.forEach(t),GNo=r(jLe," (BERT model)"),jLe.forEach(t),ONo=i(X),q2=n(X,"LI",{});var DLe=s(q2);zme=n(DLe,"STRONG",{});var Hlt=s(zme);VNo=r(Hlt,"big_bird"),Hlt.forEach(t),XNo=r(DLe," \u2014 "),bO=n(DLe,"A",{href:!0});var Ult=s(bO);zNo=r(Ult,"BigBirdForQuestionAnswering"),Ult.forEach(t),QNo=r(DLe," (BigBird model)"),DLe.forEach(t),WNo=i(X),N2=n(X,"LI",{});var GLe=s(N2);Qme=n(GLe,"STRONG",{});var Jlt=s(Qme);HNo=r(Jlt,"bigbird_pegasus"),Jlt.forEach(t),UNo=r(GLe," \u2014 "),vO=n(GLe,"A",{href:!0});var Ylt=s(vO);JNo=r(Ylt,"BigBirdPegasusForQuestionAnswering"),Ylt.forEach(t),YNo=r(GLe," (BigBirdPegasus model)"),GLe.forEach(t),KNo=i(X),j2=n(X,"LI",{});var OLe=s(j2);Wme=n(OLe,"STRONG",{});var Klt=s(Wme);ZNo=r(Klt,"camembert"),Klt.forEach(t),ejo=r(OLe," \u2014 "),FO=n(OLe,"A",{href:!0});var Zlt=s(FO);ojo=r(Zlt,"CamembertForQuestionAnswering"),Zlt.forEach(t),rjo=r(OLe," (CamemBERT model)"),OLe.forEach(t),tjo=i(X),D2=n(X,"LI",{});var VLe=s(D2);Hme=n(VLe,"STRONG",{});var eit=s(Hme);ajo=r(eit,"canine"),eit.forEach(t),njo=r(VLe," \u2014 "),TO=n(VLe,"A",{href:!0});var oit=s(TO);sjo=r(oit,"CanineForQuestionAnswering"),oit.forEach(t),ljo=r(VLe," (Canine model)"),VLe.forEach(t),ijo=i(X),G2=n(X,"LI",{});var XLe=s(G2);Ume=n(XLe,"STRONG",{});var rit=s(Ume);djo=r(rit,"convbert"),rit.forEach(t),cjo=r(XLe," \u2014 "),MO=n(XLe,"A",{href:!0});var tit=s(MO);fjo=r(tit,"ConvBertForQuestionAnswering"),tit.forEach(t),mjo=r(XLe," (ConvBERT model)"),XLe.forEach(t),gjo=i(X),O2=n(X,"LI",{});var zLe=s(O2);Jme=n(zLe,"STRONG",{});var ait=s(Jme);hjo=r(ait,"data2vec-text"),ait.forEach(t),pjo=r(zLe," \u2014 "),EO=n(zLe,"A",{href:!0});var nit=s(EO);ujo=r(nit,"Data2VecTextForQuestionAnswering"),nit.forEach(t),_jo=r(zLe," (Data2VecText model)"),zLe.forEach(t),bjo=i(X),V2=n(X,"LI",{});var QLe=s(V2);Yme=n(QLe,"STRONG",{});var sit=s(Yme);vjo=r(sit,"deberta"),sit.forEach(t),Fjo=r(QLe," \u2014 "),CO=n(QLe,"A",{href:!0});var lit=s(CO);Tjo=r(lit,"DebertaForQuestionAnswering"),lit.forEach(t),Mjo=r(QLe," (DeBERTa model)"),QLe.forEach(t),Ejo=i(X),X2=n(X,"LI",{});var WLe=s(X2);Kme=n(WLe,"STRONG",{});var iit=s(Kme);Cjo=r(iit,"deberta-v2"),iit.forEach(t),wjo=r(WLe," \u2014 "),wO=n(WLe,"A",{href:!0});var dit=s(wO);Ajo=r(dit,"DebertaV2ForQuestionAnswering"),dit.forEach(t),yjo=r(WLe," (DeBERTa-v2 model)"),WLe.forEach(t),Ljo=i(X),z2=n(X,"LI",{});var HLe=s(z2);Zme=n(HLe,"STRONG",{});var cit=s(Zme);xjo=r(cit,"distilbert"),cit.forEach(t),$jo=r(HLe," \u2014 "),AO=n(HLe,"A",{href:!0});var fit=s(AO);kjo=r(fit,"DistilBertForQuestionAnswering"),fit.forEach(t),Sjo=r(HLe," (DistilBERT model)"),HLe.forEach(t),Rjo=i(X),Q2=n(X,"LI",{});var ULe=s(Q2);ege=n(ULe,"STRONG",{});var mit=s(ege);Bjo=r(mit,"electra"),mit.forEach(t),Pjo=r(ULe," \u2014 "),yO=n(ULe,"A",{href:!0});var git=s(yO);Ijo=r(git,"ElectraForQuestionAnswering"),git.forEach(t),qjo=r(ULe," (ELECTRA model)"),ULe.forEach(t),Njo=i(X),W2=n(X,"LI",{});var JLe=s(W2);oge=n(JLe,"STRONG",{});var hit=s(oge);jjo=r(hit,"flaubert"),hit.forEach(t),Djo=r(JLe," \u2014 "),LO=n(JLe,"A",{href:!0});var pit=s(LO);Gjo=r(pit,"FlaubertForQuestionAnsweringSimple"),pit.forEach(t),Ojo=r(JLe," (FlauBERT model)"),JLe.forEach(t),Vjo=i(X),H2=n(X,"LI",{});var YLe=s(H2);rge=n(YLe,"STRONG",{});var uit=s(rge);Xjo=r(uit,"fnet"),uit.forEach(t),zjo=r(YLe," \u2014 "),xO=n(YLe,"A",{href:!0});var _it=s(xO);Qjo=r(_it,"FNetForQuestionAnswering"),_it.forEach(t),Wjo=r(YLe," (FNet model)"),YLe.forEach(t),Hjo=i(X),U2=n(X,"LI",{});var KLe=s(U2);tge=n(KLe,"STRONG",{});var bit=s(tge);Ujo=r(bit,"funnel"),bit.forEach(t),Jjo=r(KLe," \u2014 "),$O=n(KLe,"A",{href:!0});var vit=s($O);Yjo=r(vit,"FunnelForQuestionAnswering"),vit.forEach(t),Kjo=r(KLe," (Funnel Transformer model)"),KLe.forEach(t),Zjo=i(X),J2=n(X,"LI",{});var ZLe=s(J2);age=n(ZLe,"STRONG",{});var Fit=s(age);eDo=r(Fit,"gptj"),Fit.forEach(t),oDo=r(ZLe," \u2014 "),kO=n(ZLe,"A",{href:!0});var Tit=s(kO);rDo=r(Tit,"GPTJForQuestionAnswering"),Tit.forEach(t),tDo=r(ZLe," (GPT-J model)"),ZLe.forEach(t),aDo=i(X),Y2=n(X,"LI",{});var exe=s(Y2);nge=n(exe,"STRONG",{});var Mit=s(nge);nDo=r(Mit,"ibert"),Mit.forEach(t),sDo=r(exe," \u2014 "),SO=n(exe,"A",{href:!0});var Eit=s(SO);lDo=r(Eit,"IBertForQuestionAnswering"),Eit.forEach(t),iDo=r(exe," (I-BERT model)"),exe.forEach(t),dDo=i(X),K2=n(X,"LI",{});var oxe=s(K2);sge=n(oxe,"STRONG",{});var Cit=s(sge);cDo=r(Cit,"layoutlmv2"),Cit.forEach(t),fDo=r(oxe," \u2014 "),RO=n(oxe,"A",{href:!0});var wit=s(RO);mDo=r(wit,"LayoutLMv2ForQuestionAnswering"),wit.forEach(t),gDo=r(oxe," (LayoutLMv2 model)"),oxe.forEach(t),hDo=i(X),Z2=n(X,"LI",{});var rxe=s(Z2);lge=n(rxe,"STRONG",{});var Ait=s(lge);pDo=r(Ait,"led"),Ait.forEach(t),uDo=r(rxe," \u2014 "),BO=n(rxe,"A",{href:!0});var yit=s(BO);_Do=r(yit,"LEDForQuestionAnswering"),yit.forEach(t),bDo=r(rxe," (LED model)"),rxe.forEach(t),vDo=i(X),ev=n(X,"LI",{});var txe=s(ev);ige=n(txe,"STRONG",{});var Lit=s(ige);FDo=r(Lit,"longformer"),Lit.forEach(t),TDo=r(txe," \u2014 "),PO=n(txe,"A",{href:!0});var xit=s(PO);MDo=r(xit,"LongformerForQuestionAnswering"),xit.forEach(t),EDo=r(txe," (Longformer model)"),txe.forEach(t),CDo=i(X),ov=n(X,"LI",{});var axe=s(ov);dge=n(axe,"STRONG",{});var $it=s(dge);wDo=r($it,"lxmert"),$it.forEach(t),ADo=r(axe," \u2014 "),IO=n(axe,"A",{href:!0});var kit=s(IO);yDo=r(kit,"LxmertForQuestionAnswering"),kit.forEach(t),LDo=r(axe," (LXMERT model)"),axe.forEach(t),xDo=i(X),rv=n(X,"LI",{});var nxe=s(rv);cge=n(nxe,"STRONG",{});var Sit=s(cge);$Do=r(Sit,"mbart"),Sit.forEach(t),kDo=r(nxe," \u2014 "),qO=n(nxe,"A",{href:!0});var Rit=s(qO);SDo=r(Rit,"MBartForQuestionAnswering"),Rit.forEach(t),RDo=r(nxe," (mBART model)"),nxe.forEach(t),BDo=i(X),tv=n(X,"LI",{});var sxe=s(tv);fge=n(sxe,"STRONG",{});var Bit=s(fge);PDo=r(Bit,"megatron-bert"),Bit.forEach(t),IDo=r(sxe," \u2014 "),NO=n(sxe,"A",{href:!0});var Pit=s(NO);qDo=r(Pit,"MegatronBertForQuestionAnswering"),Pit.forEach(t),NDo=r(sxe," (MegatronBert model)"),sxe.forEach(t),jDo=i(X),av=n(X,"LI",{});var lxe=s(av);mge=n(lxe,"STRONG",{});var Iit=s(mge);DDo=r(Iit,"mobilebert"),Iit.forEach(t),GDo=r(lxe," \u2014 "),jO=n(lxe,"A",{href:!0});var qit=s(jO);ODo=r(qit,"MobileBertForQuestionAnswering"),qit.forEach(t),VDo=r(lxe," (MobileBERT model)"),lxe.forEach(t),XDo=i(X),nv=n(X,"LI",{});var ixe=s(nv);gge=n(ixe,"STRONG",{});var Nit=s(gge);zDo=r(Nit,"mpnet"),Nit.forEach(t),QDo=r(ixe," \u2014 "),DO=n(ixe,"A",{href:!0});var jit=s(DO);WDo=r(jit,"MPNetForQuestionAnswering"),jit.forEach(t),HDo=r(ixe," (MPNet model)"),ixe.forEach(t),UDo=i(X),sv=n(X,"LI",{});var dxe=s(sv);hge=n(dxe,"STRONG",{});var Dit=s(hge);JDo=r(Dit,"nystromformer"),Dit.forEach(t),YDo=r(dxe," \u2014 "),GO=n(dxe,"A",{href:!0});var Git=s(GO);KDo=r(Git,"NystromformerForQuestionAnswering"),Git.forEach(t),ZDo=r(dxe," (Nystromformer model)"),dxe.forEach(t),eGo=i(X),lv=n(X,"LI",{});var cxe=s(lv);pge=n(cxe,"STRONG",{});var Oit=s(pge);oGo=r(Oit,"qdqbert"),Oit.forEach(t),rGo=r(cxe," \u2014 "),OO=n(cxe,"A",{href:!0});var Vit=s(OO);tGo=r(Vit,"QDQBertForQuestionAnswering"),Vit.forEach(t),aGo=r(cxe," (QDQBert model)"),cxe.forEach(t),nGo=i(X),iv=n(X,"LI",{});var fxe=s(iv);uge=n(fxe,"STRONG",{});var Xit=s(uge);sGo=r(Xit,"reformer"),Xit.forEach(t),lGo=r(fxe," \u2014 "),VO=n(fxe,"A",{href:!0});var zit=s(VO);iGo=r(zit,"ReformerForQuestionAnswering"),zit.forEach(t),dGo=r(fxe," (Reformer model)"),fxe.forEach(t),cGo=i(X),dv=n(X,"LI",{});var mxe=s(dv);_ge=n(mxe,"STRONG",{});var Qit=s(_ge);fGo=r(Qit,"rembert"),Qit.forEach(t),mGo=r(mxe," \u2014 "),XO=n(mxe,"A",{href:!0});var Wit=s(XO);gGo=r(Wit,"RemBertForQuestionAnswering"),Wit.forEach(t),hGo=r(mxe," (RemBERT model)"),mxe.forEach(t),pGo=i(X),cv=n(X,"LI",{});var gxe=s(cv);bge=n(gxe,"STRONG",{});var Hit=s(bge);uGo=r(Hit,"roberta"),Hit.forEach(t),_Go=r(gxe," \u2014 "),zO=n(gxe,"A",{href:!0});var Uit=s(zO);bGo=r(Uit,"RobertaForQuestionAnswering"),Uit.forEach(t),vGo=r(gxe," (RoBERTa model)"),gxe.forEach(t),FGo=i(X),fv=n(X,"LI",{});var hxe=s(fv);vge=n(hxe,"STRONG",{});var Jit=s(vge);TGo=r(Jit,"roformer"),Jit.forEach(t),MGo=r(hxe," \u2014 "),QO=n(hxe,"A",{href:!0});var Yit=s(QO);EGo=r(Yit,"RoFormerForQuestionAnswering"),Yit.forEach(t),CGo=r(hxe," (RoFormer model)"),hxe.forEach(t),wGo=i(X),mv=n(X,"LI",{});var pxe=s(mv);Fge=n(pxe,"STRONG",{});var Kit=s(Fge);AGo=r(Kit,"splinter"),Kit.forEach(t),yGo=r(pxe," \u2014 "),WO=n(pxe,"A",{href:!0});var Zit=s(WO);LGo=r(Zit,"SplinterForQuestionAnswering"),Zit.forEach(t),xGo=r(pxe," (Splinter model)"),pxe.forEach(t),$Go=i(X),gv=n(X,"LI",{});var uxe=s(gv);Tge=n(uxe,"STRONG",{});var edt=s(Tge);kGo=r(edt,"squeezebert"),edt.forEach(t),SGo=r(uxe," \u2014 "),HO=n(uxe,"A",{href:!0});var odt=s(HO);RGo=r(odt,"SqueezeBertForQuestionAnswering"),odt.forEach(t),BGo=r(uxe," (SqueezeBERT model)"),uxe.forEach(t),PGo=i(X),hv=n(X,"LI",{});var _xe=s(hv);Mge=n(_xe,"STRONG",{});var rdt=s(Mge);IGo=r(rdt,"xlm"),rdt.forEach(t),qGo=r(_xe," \u2014 "),UO=n(_xe,"A",{href:!0});var tdt=s(UO);NGo=r(tdt,"XLMForQuestionAnsweringSimple"),tdt.forEach(t),jGo=r(_xe," (XLM model)"),_xe.forEach(t),DGo=i(X),pv=n(X,"LI",{});var bxe=s(pv);Ege=n(bxe,"STRONG",{});var adt=s(Ege);GGo=r(adt,"xlm-roberta"),adt.forEach(t),OGo=r(bxe," \u2014 "),JO=n(bxe,"A",{href:!0});var ndt=s(JO);VGo=r(ndt,"XLMRobertaForQuestionAnswering"),ndt.forEach(t),XGo=r(bxe," (XLM-RoBERTa model)"),bxe.forEach(t),zGo=i(X),uv=n(X,"LI",{});var vxe=s(uv);Cge=n(vxe,"STRONG",{});var sdt=s(Cge);QGo=r(sdt,"xlm-roberta-xl"),sdt.forEach(t),WGo=r(vxe," \u2014 "),YO=n(vxe,"A",{href:!0});var ldt=s(YO);HGo=r(ldt,"XLMRobertaXLForQuestionAnswering"),ldt.forEach(t),UGo=r(vxe," (XLM-RoBERTa-XL model)"),vxe.forEach(t),JGo=i(X),_v=n(X,"LI",{});var Fxe=s(_v);wge=n(Fxe,"STRONG",{});var idt=s(wge);YGo=r(idt,"xlnet"),idt.forEach(t),KGo=r(Fxe," \u2014 "),KO=n(Fxe,"A",{href:!0});var ddt=s(KO);ZGo=r(ddt,"XLNetForQuestionAnsweringSimple"),ddt.forEach(t),eOo=r(Fxe," (XLNet model)"),Fxe.forEach(t),oOo=i(X),bv=n(X,"LI",{});var Txe=s(bv);Age=n(Txe,"STRONG",{});var cdt=s(Age);rOo=r(cdt,"yoso"),cdt.forEach(t),tOo=r(Txe," \u2014 "),ZO=n(Txe,"A",{href:!0});var fdt=s(ZO);aOo=r(fdt,"YosoForQuestionAnswering"),fdt.forEach(t),nOo=r(Txe," (YOSO model)"),Txe.forEach(t),X.forEach(t),sOo=i(ia),vv=n(ia,"P",{});var Mxe=s(vv);lOo=r(Mxe,"The model is set in evaluation mode by default using "),yge=n(Mxe,"CODE",{});var mdt=s(yge);iOo=r(mdt,"model.eval()"),mdt.forEach(t),dOo=r(Mxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lge=n(Mxe,"CODE",{});var gdt=s(Lge);cOo=r(gdt,"model.train()"),gdt.forEach(t),Mxe.forEach(t),fOo=i(ia),T(Fv.$$.fragment,ia),ia.forEach(t),Js.forEach(t),HPe=i(f),Ki=n(f,"H2",{class:!0});var Kqe=s(Ki);Tv=n(Kqe,"A",{id:!0,class:!0,href:!0});var hdt=s(Tv);xge=n(hdt,"SPAN",{});var pdt=s(xge);T(g0.$$.fragment,pdt),pdt.forEach(t),hdt.forEach(t),mOo=i(Kqe),$ge=n(Kqe,"SPAN",{});var udt=s($ge);gOo=r(udt,"AutoModelForTableQuestionAnswering"),udt.forEach(t),Kqe.forEach(t),UPe=i(f),No=n(f,"DIV",{class:!0});var Ys=s(No);T(h0.$$.fragment,Ys),hOo=i(Ys),Zi=n(Ys,"P",{});var uK=s(Zi);pOo=r(uK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),eV=n(uK,"A",{href:!0});var _dt=s(eV);uOo=r(_dt,"from_pretrained()"),_dt.forEach(t),_Oo=r(uK," class method or the "),oV=n(uK,"A",{href:!0});var bdt=s(oV);bOo=r(bdt,"from_config()"),bdt.forEach(t),vOo=r(uK,` class
method.`),uK.forEach(t),FOo=i(Ys),p0=n(Ys,"P",{});var Zqe=s(p0);TOo=r(Zqe,"This class cannot be instantiated directly using "),kge=n(Zqe,"CODE",{});var vdt=s(kge);MOo=r(vdt,"__init__()"),vdt.forEach(t),EOo=r(Zqe," (throws an error)."),Zqe.forEach(t),COo=i(Ys),ft=n(Ys,"DIV",{class:!0});var g3=s(ft);T(u0.$$.fragment,g3),wOo=i(g3),Sge=n(g3,"P",{});var Fdt=s(Sge);AOo=r(Fdt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Fdt.forEach(t),yOo=i(g3),ed=n(g3,"P",{});var _K=s(ed);LOo=r(_K,`Note:
Loading a model from its configuration file does `),Rge=n(_K,"STRONG",{});var Tdt=s(Rge);xOo=r(Tdt,"not"),Tdt.forEach(t),$Oo=r(_K,` load the model weights. It only affects the
model\u2019s configuration. Use `),rV=n(_K,"A",{href:!0});var Mdt=s(rV);kOo=r(Mdt,"from_pretrained()"),Mdt.forEach(t),SOo=r(_K," to load the model weights."),_K.forEach(t),ROo=i(g3),T(Mv.$$.fragment,g3),g3.forEach(t),BOo=i(Ys),ao=n(Ys,"DIV",{class:!0});var da=s(ao);T(_0.$$.fragment,da),POo=i(da),Bge=n(da,"P",{});var Edt=s(Bge);IOo=r(Edt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Edt.forEach(t),qOo=i(da),Ia=n(da,"P",{});var h3=s(Ia);NOo=r(h3,"The model class to instantiate is selected based on the "),Pge=n(h3,"CODE",{});var Cdt=s(Pge);jOo=r(Cdt,"model_type"),Cdt.forEach(t),DOo=r(h3,` property of the config object (either
passed as an argument or loaded from `),Ige=n(h3,"CODE",{});var wdt=s(Ige);GOo=r(wdt,"pretrained_model_name_or_path"),wdt.forEach(t),OOo=r(h3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qge=n(h3,"CODE",{});var Adt=s(qge);VOo=r(Adt,"pretrained_model_name_or_path"),Adt.forEach(t),XOo=r(h3,":"),h3.forEach(t),zOo=i(da),Nge=n(da,"UL",{});var ydt=s(Nge);Ev=n(ydt,"LI",{});var Exe=s(Ev);jge=n(Exe,"STRONG",{});var Ldt=s(jge);QOo=r(Ldt,"tapas"),Ldt.forEach(t),WOo=r(Exe," \u2014 "),tV=n(Exe,"A",{href:!0});var xdt=s(tV);HOo=r(xdt,"TapasForQuestionAnswering"),xdt.forEach(t),UOo=r(Exe," (TAPAS model)"),Exe.forEach(t),ydt.forEach(t),JOo=i(da),Cv=n(da,"P",{});var Cxe=s(Cv);YOo=r(Cxe,"The model is set in evaluation mode by default using "),Dge=n(Cxe,"CODE",{});var $dt=s(Dge);KOo=r($dt,"model.eval()"),$dt.forEach(t),ZOo=r(Cxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gge=n(Cxe,"CODE",{});var kdt=s(Gge);eVo=r(kdt,"model.train()"),kdt.forEach(t),Cxe.forEach(t),oVo=i(da),T(wv.$$.fragment,da),da.forEach(t),Ys.forEach(t),JPe=i(f),od=n(f,"H2",{class:!0});var eNe=s(od);Av=n(eNe,"A",{id:!0,class:!0,href:!0});var Sdt=s(Av);Oge=n(Sdt,"SPAN",{});var Rdt=s(Oge);T(b0.$$.fragment,Rdt),Rdt.forEach(t),Sdt.forEach(t),rVo=i(eNe),Vge=n(eNe,"SPAN",{});var Bdt=s(Vge);tVo=r(Bdt,"AutoModelForImageClassification"),Bdt.forEach(t),eNe.forEach(t),YPe=i(f),jo=n(f,"DIV",{class:!0});var Ks=s(jo);T(v0.$$.fragment,Ks),aVo=i(Ks),rd=n(Ks,"P",{});var bK=s(rd);nVo=r(bK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aV=n(bK,"A",{href:!0});var Pdt=s(aV);sVo=r(Pdt,"from_pretrained()"),Pdt.forEach(t),lVo=r(bK," class method or the "),nV=n(bK,"A",{href:!0});var Idt=s(nV);iVo=r(Idt,"from_config()"),Idt.forEach(t),dVo=r(bK,` class
method.`),bK.forEach(t),cVo=i(Ks),F0=n(Ks,"P",{});var oNe=s(F0);fVo=r(oNe,"This class cannot be instantiated directly using "),Xge=n(oNe,"CODE",{});var qdt=s(Xge);mVo=r(qdt,"__init__()"),qdt.forEach(t),gVo=r(oNe," (throws an error)."),oNe.forEach(t),hVo=i(Ks),mt=n(Ks,"DIV",{class:!0});var p3=s(mt);T(T0.$$.fragment,p3),pVo=i(p3),zge=n(p3,"P",{});var Ndt=s(zge);uVo=r(Ndt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Ndt.forEach(t),_Vo=i(p3),td=n(p3,"P",{});var vK=s(td);bVo=r(vK,`Note:
Loading a model from its configuration file does `),Qge=n(vK,"STRONG",{});var jdt=s(Qge);vVo=r(jdt,"not"),jdt.forEach(t),FVo=r(vK,` load the model weights. It only affects the
model\u2019s configuration. Use `),sV=n(vK,"A",{href:!0});var Ddt=s(sV);TVo=r(Ddt,"from_pretrained()"),Ddt.forEach(t),MVo=r(vK," to load the model weights."),vK.forEach(t),EVo=i(p3),T(yv.$$.fragment,p3),p3.forEach(t),CVo=i(Ks),no=n(Ks,"DIV",{class:!0});var ca=s(no);T(M0.$$.fragment,ca),wVo=i(ca),Wge=n(ca,"P",{});var Gdt=s(Wge);AVo=r(Gdt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Gdt.forEach(t),yVo=i(ca),qa=n(ca,"P",{});var u3=s(qa);LVo=r(u3,"The model class to instantiate is selected based on the "),Hge=n(u3,"CODE",{});var Odt=s(Hge);xVo=r(Odt,"model_type"),Odt.forEach(t),$Vo=r(u3,` property of the config object (either
passed as an argument or loaded from `),Uge=n(u3,"CODE",{});var Vdt=s(Uge);kVo=r(Vdt,"pretrained_model_name_or_path"),Vdt.forEach(t),SVo=r(u3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jge=n(u3,"CODE",{});var Xdt=s(Jge);RVo=r(Xdt,"pretrained_model_name_or_path"),Xdt.forEach(t),BVo=r(u3,":"),u3.forEach(t),PVo=i(ca),ve=n(ca,"UL",{});var Ee=s(ve);Lv=n(Ee,"LI",{});var wxe=s(Lv);Yge=n(wxe,"STRONG",{});var zdt=s(Yge);IVo=r(zdt,"beit"),zdt.forEach(t),qVo=r(wxe," \u2014 "),lV=n(wxe,"A",{href:!0});var Qdt=s(lV);NVo=r(Qdt,"BeitForImageClassification"),Qdt.forEach(t),jVo=r(wxe," (BEiT model)"),wxe.forEach(t),DVo=i(Ee),xv=n(Ee,"LI",{});var Axe=s(xv);Kge=n(Axe,"STRONG",{});var Wdt=s(Kge);GVo=r(Wdt,"convnext"),Wdt.forEach(t),OVo=r(Axe," \u2014 "),iV=n(Axe,"A",{href:!0});var Hdt=s(iV);VVo=r(Hdt,"ConvNextForImageClassification"),Hdt.forEach(t),XVo=r(Axe," (ConvNext model)"),Axe.forEach(t),zVo=i(Ee),$v=n(Ee,"LI",{});var yxe=s($v);Zge=n(yxe,"STRONG",{});var Udt=s(Zge);QVo=r(Udt,"data2vec-vision"),Udt.forEach(t),WVo=r(yxe," \u2014 "),dV=n(yxe,"A",{href:!0});var Jdt=s(dV);HVo=r(Jdt,"Data2VecVisionForImageClassification"),Jdt.forEach(t),UVo=r(yxe," (Data2VecVision model)"),yxe.forEach(t),JVo=i(Ee),Bs=n(Ee,"LI",{});var s$=s(Bs);ehe=n(s$,"STRONG",{});var Ydt=s(ehe);YVo=r(Ydt,"deit"),Ydt.forEach(t),KVo=r(s$," \u2014 "),cV=n(s$,"A",{href:!0});var Kdt=s(cV);ZVo=r(Kdt,"DeiTForImageClassification"),Kdt.forEach(t),eXo=r(s$," or "),fV=n(s$,"A",{href:!0});var Zdt=s(fV);oXo=r(Zdt,"DeiTForImageClassificationWithTeacher"),Zdt.forEach(t),rXo=r(s$," (DeiT model)"),s$.forEach(t),tXo=i(Ee),kv=n(Ee,"LI",{});var Lxe=s(kv);ohe=n(Lxe,"STRONG",{});var ect=s(ohe);aXo=r(ect,"imagegpt"),ect.forEach(t),nXo=r(Lxe," \u2014 "),mV=n(Lxe,"A",{href:!0});var oct=s(mV);sXo=r(oct,"ImageGPTForImageClassification"),oct.forEach(t),lXo=r(Lxe," (ImageGPT model)"),Lxe.forEach(t),iXo=i(Ee),gt=n(Ee,"LI",{});var ff=s(gt);rhe=n(ff,"STRONG",{});var rct=s(rhe);dXo=r(rct,"perceiver"),rct.forEach(t),cXo=r(ff," \u2014 "),gV=n(ff,"A",{href:!0});var tct=s(gV);fXo=r(tct,"PerceiverForImageClassificationLearned"),tct.forEach(t),mXo=r(ff," or "),hV=n(ff,"A",{href:!0});var act=s(hV);gXo=r(act,"PerceiverForImageClassificationFourier"),act.forEach(t),hXo=r(ff," or "),pV=n(ff,"A",{href:!0});var nct=s(pV);pXo=r(nct,"PerceiverForImageClassificationConvProcessing"),nct.forEach(t),uXo=r(ff," (Perceiver model)"),ff.forEach(t),_Xo=i(Ee),Sv=n(Ee,"LI",{});var xxe=s(Sv);the=n(xxe,"STRONG",{});var sct=s(the);bXo=r(sct,"poolformer"),sct.forEach(t),vXo=r(xxe," \u2014 "),uV=n(xxe,"A",{href:!0});var lct=s(uV);FXo=r(lct,"PoolFormerForImageClassification"),lct.forEach(t),TXo=r(xxe," (PoolFormer model)"),xxe.forEach(t),MXo=i(Ee),Rv=n(Ee,"LI",{});var $xe=s(Rv);ahe=n($xe,"STRONG",{});var ict=s(ahe);EXo=r(ict,"regnet"),ict.forEach(t),CXo=r($xe," \u2014 "),_V=n($xe,"A",{href:!0});var dct=s(_V);wXo=r(dct,"RegNetForImageClassification"),dct.forEach(t),AXo=r($xe," (RegNet model)"),$xe.forEach(t),yXo=i(Ee),Bv=n(Ee,"LI",{});var kxe=s(Bv);nhe=n(kxe,"STRONG",{});var cct=s(nhe);LXo=r(cct,"resnet"),cct.forEach(t),xXo=r(kxe," \u2014 "),bV=n(kxe,"A",{href:!0});var fct=s(bV);$Xo=r(fct,"ResNetForImageClassification"),fct.forEach(t),kXo=r(kxe," (ResNet model)"),kxe.forEach(t),SXo=i(Ee),Pv=n(Ee,"LI",{});var Sxe=s(Pv);she=n(Sxe,"STRONG",{});var mct=s(she);RXo=r(mct,"segformer"),mct.forEach(t),BXo=r(Sxe," \u2014 "),vV=n(Sxe,"A",{href:!0});var gct=s(vV);PXo=r(gct,"SegformerForImageClassification"),gct.forEach(t),IXo=r(Sxe," (SegFormer model)"),Sxe.forEach(t),qXo=i(Ee),Iv=n(Ee,"LI",{});var Rxe=s(Iv);lhe=n(Rxe,"STRONG",{});var hct=s(lhe);NXo=r(hct,"swin"),hct.forEach(t),jXo=r(Rxe," \u2014 "),FV=n(Rxe,"A",{href:!0});var pct=s(FV);DXo=r(pct,"SwinForImageClassification"),pct.forEach(t),GXo=r(Rxe," (Swin model)"),Rxe.forEach(t),OXo=i(Ee),qv=n(Ee,"LI",{});var Bxe=s(qv);ihe=n(Bxe,"STRONG",{});var uct=s(ihe);VXo=r(uct,"van"),uct.forEach(t),XXo=r(Bxe," \u2014 "),TV=n(Bxe,"A",{href:!0});var _ct=s(TV);zXo=r(_ct,"VanForImageClassification"),_ct.forEach(t),QXo=r(Bxe," (VAN model)"),Bxe.forEach(t),WXo=i(Ee),Nv=n(Ee,"LI",{});var Pxe=s(Nv);dhe=n(Pxe,"STRONG",{});var bct=s(dhe);HXo=r(bct,"vit"),bct.forEach(t),UXo=r(Pxe," \u2014 "),MV=n(Pxe,"A",{href:!0});var vct=s(MV);JXo=r(vct,"ViTForImageClassification"),vct.forEach(t),YXo=r(Pxe," (ViT model)"),Pxe.forEach(t),Ee.forEach(t),KXo=i(ca),jv=n(ca,"P",{});var Ixe=s(jv);ZXo=r(Ixe,"The model is set in evaluation mode by default using "),che=n(Ixe,"CODE",{});var Fct=s(che);ezo=r(Fct,"model.eval()"),Fct.forEach(t),ozo=r(Ixe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fhe=n(Ixe,"CODE",{});var Tct=s(fhe);rzo=r(Tct,"model.train()"),Tct.forEach(t),Ixe.forEach(t),tzo=i(ca),T(Dv.$$.fragment,ca),ca.forEach(t),Ks.forEach(t),KPe=i(f),ad=n(f,"H2",{class:!0});var rNe=s(ad);Gv=n(rNe,"A",{id:!0,class:!0,href:!0});var Mct=s(Gv);mhe=n(Mct,"SPAN",{});var Ect=s(mhe);T(E0.$$.fragment,Ect),Ect.forEach(t),Mct.forEach(t),azo=i(rNe),ghe=n(rNe,"SPAN",{});var Cct=s(ghe);nzo=r(Cct,"AutoModelForVision2Seq"),Cct.forEach(t),rNe.forEach(t),ZPe=i(f),Do=n(f,"DIV",{class:!0});var Zs=s(Do);T(C0.$$.fragment,Zs),szo=i(Zs),nd=n(Zs,"P",{});var FK=s(nd);lzo=r(FK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),EV=n(FK,"A",{href:!0});var wct=s(EV);izo=r(wct,"from_pretrained()"),wct.forEach(t),dzo=r(FK," class method or the "),CV=n(FK,"A",{href:!0});var Act=s(CV);czo=r(Act,"from_config()"),Act.forEach(t),fzo=r(FK,` class
method.`),FK.forEach(t),mzo=i(Zs),w0=n(Zs,"P",{});var tNe=s(w0);gzo=r(tNe,"This class cannot be instantiated directly using "),hhe=n(tNe,"CODE",{});var yct=s(hhe);hzo=r(yct,"__init__()"),yct.forEach(t),pzo=r(tNe," (throws an error)."),tNe.forEach(t),uzo=i(Zs),ht=n(Zs,"DIV",{class:!0});var _3=s(ht);T(A0.$$.fragment,_3),_zo=i(_3),phe=n(_3,"P",{});var Lct=s(phe);bzo=r(Lct,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Lct.forEach(t),vzo=i(_3),sd=n(_3,"P",{});var TK=s(sd);Fzo=r(TK,`Note:
Loading a model from its configuration file does `),uhe=n(TK,"STRONG",{});var xct=s(uhe);Tzo=r(xct,"not"),xct.forEach(t),Mzo=r(TK,` load the model weights. It only affects the
model\u2019s configuration. Use `),wV=n(TK,"A",{href:!0});var $ct=s(wV);Ezo=r($ct,"from_pretrained()"),$ct.forEach(t),Czo=r(TK," to load the model weights."),TK.forEach(t),wzo=i(_3),T(Ov.$$.fragment,_3),_3.forEach(t),Azo=i(Zs),so=n(Zs,"DIV",{class:!0});var fa=s(so);T(y0.$$.fragment,fa),yzo=i(fa),_he=n(fa,"P",{});var kct=s(_he);Lzo=r(kct,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),kct.forEach(t),xzo=i(fa),Na=n(fa,"P",{});var b3=s(Na);$zo=r(b3,"The model class to instantiate is selected based on the "),bhe=n(b3,"CODE",{});var Sct=s(bhe);kzo=r(Sct,"model_type"),Sct.forEach(t),Szo=r(b3,` property of the config object (either
passed as an argument or loaded from `),vhe=n(b3,"CODE",{});var Rct=s(vhe);Rzo=r(Rct,"pretrained_model_name_or_path"),Rct.forEach(t),Bzo=r(b3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fhe=n(b3,"CODE",{});var Bct=s(Fhe);Pzo=r(Bct,"pretrained_model_name_or_path"),Bct.forEach(t),Izo=r(b3,":"),b3.forEach(t),qzo=i(fa),The=n(fa,"UL",{});var Pct=s(The);Vv=n(Pct,"LI",{});var qxe=s(Vv);Mhe=n(qxe,"STRONG",{});var Ict=s(Mhe);Nzo=r(Ict,"vision-encoder-decoder"),Ict.forEach(t),jzo=r(qxe," \u2014 "),AV=n(qxe,"A",{href:!0});var qct=s(AV);Dzo=r(qct,"VisionEncoderDecoderModel"),qct.forEach(t),Gzo=r(qxe," (Vision Encoder decoder model)"),qxe.forEach(t),Pct.forEach(t),Ozo=i(fa),Xv=n(fa,"P",{});var Nxe=s(Xv);Vzo=r(Nxe,"The model is set in evaluation mode by default using "),Ehe=n(Nxe,"CODE",{});var Nct=s(Ehe);Xzo=r(Nct,"model.eval()"),Nct.forEach(t),zzo=r(Nxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Che=n(Nxe,"CODE",{});var jct=s(Che);Qzo=r(jct,"model.train()"),jct.forEach(t),Nxe.forEach(t),Wzo=i(fa),T(zv.$$.fragment,fa),fa.forEach(t),Zs.forEach(t),eIe=i(f),ld=n(f,"H2",{class:!0});var aNe=s(ld);Qv=n(aNe,"A",{id:!0,class:!0,href:!0});var Dct=s(Qv);whe=n(Dct,"SPAN",{});var Gct=s(whe);T(L0.$$.fragment,Gct),Gct.forEach(t),Dct.forEach(t),Hzo=i(aNe),Ahe=n(aNe,"SPAN",{});var Oct=s(Ahe);Uzo=r(Oct,"AutoModelForAudioClassification"),Oct.forEach(t),aNe.forEach(t),oIe=i(f),Go=n(f,"DIV",{class:!0});var el=s(Go);T(x0.$$.fragment,el),Jzo=i(el),id=n(el,"P",{});var MK=s(id);Yzo=r(MK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),yV=n(MK,"A",{href:!0});var Vct=s(yV);Kzo=r(Vct,"from_pretrained()"),Vct.forEach(t),Zzo=r(MK," class method or the "),LV=n(MK,"A",{href:!0});var Xct=s(LV);eQo=r(Xct,"from_config()"),Xct.forEach(t),oQo=r(MK,` class
method.`),MK.forEach(t),rQo=i(el),$0=n(el,"P",{});var nNe=s($0);tQo=r(nNe,"This class cannot be instantiated directly using "),yhe=n(nNe,"CODE",{});var zct=s(yhe);aQo=r(zct,"__init__()"),zct.forEach(t),nQo=r(nNe," (throws an error)."),nNe.forEach(t),sQo=i(el),pt=n(el,"DIV",{class:!0});var v3=s(pt);T(k0.$$.fragment,v3),lQo=i(v3),Lhe=n(v3,"P",{});var Qct=s(Lhe);iQo=r(Qct,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Qct.forEach(t),dQo=i(v3),dd=n(v3,"P",{});var EK=s(dd);cQo=r(EK,`Note:
Loading a model from its configuration file does `),xhe=n(EK,"STRONG",{});var Wct=s(xhe);fQo=r(Wct,"not"),Wct.forEach(t),mQo=r(EK,` load the model weights. It only affects the
model\u2019s configuration. Use `),xV=n(EK,"A",{href:!0});var Hct=s(xV);gQo=r(Hct,"from_pretrained()"),Hct.forEach(t),hQo=r(EK," to load the model weights."),EK.forEach(t),pQo=i(v3),T(Wv.$$.fragment,v3),v3.forEach(t),uQo=i(el),lo=n(el,"DIV",{class:!0});var ma=s(lo);T(S0.$$.fragment,ma),_Qo=i(ma),$he=n(ma,"P",{});var Uct=s($he);bQo=r(Uct,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Uct.forEach(t),vQo=i(ma),ja=n(ma,"P",{});var F3=s(ja);FQo=r(F3,"The model class to instantiate is selected based on the "),khe=n(F3,"CODE",{});var Jct=s(khe);TQo=r(Jct,"model_type"),Jct.forEach(t),MQo=r(F3,` property of the config object (either
passed as an argument or loaded from `),She=n(F3,"CODE",{});var Yct=s(She);EQo=r(Yct,"pretrained_model_name_or_path"),Yct.forEach(t),CQo=r(F3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rhe=n(F3,"CODE",{});var Kct=s(Rhe);wQo=r(Kct,"pretrained_model_name_or_path"),Kct.forEach(t),AQo=r(F3,":"),F3.forEach(t),yQo=i(ma),Ne=n(ma,"UL",{});var bo=s(Ne);Hv=n(bo,"LI",{});var jxe=s(Hv);Bhe=n(jxe,"STRONG",{});var Zct=s(Bhe);LQo=r(Zct,"data2vec-audio"),Zct.forEach(t),xQo=r(jxe," \u2014 "),$V=n(jxe,"A",{href:!0});var eft=s($V);$Qo=r(eft,"Data2VecAudioForSequenceClassification"),eft.forEach(t),kQo=r(jxe," (Data2VecAudio model)"),jxe.forEach(t),SQo=i(bo),Uv=n(bo,"LI",{});var Dxe=s(Uv);Phe=n(Dxe,"STRONG",{});var oft=s(Phe);RQo=r(oft,"hubert"),oft.forEach(t),BQo=r(Dxe," \u2014 "),kV=n(Dxe,"A",{href:!0});var rft=s(kV);PQo=r(rft,"HubertForSequenceClassification"),rft.forEach(t),IQo=r(Dxe," (Hubert model)"),Dxe.forEach(t),qQo=i(bo),Jv=n(bo,"LI",{});var Gxe=s(Jv);Ihe=n(Gxe,"STRONG",{});var tft=s(Ihe);NQo=r(tft,"sew"),tft.forEach(t),jQo=r(Gxe," \u2014 "),SV=n(Gxe,"A",{href:!0});var aft=s(SV);DQo=r(aft,"SEWForSequenceClassification"),aft.forEach(t),GQo=r(Gxe," (SEW model)"),Gxe.forEach(t),OQo=i(bo),Yv=n(bo,"LI",{});var Oxe=s(Yv);qhe=n(Oxe,"STRONG",{});var nft=s(qhe);VQo=r(nft,"sew-d"),nft.forEach(t),XQo=r(Oxe," \u2014 "),RV=n(Oxe,"A",{href:!0});var sft=s(RV);zQo=r(sft,"SEWDForSequenceClassification"),sft.forEach(t),QQo=r(Oxe," (SEW-D model)"),Oxe.forEach(t),WQo=i(bo),Kv=n(bo,"LI",{});var Vxe=s(Kv);Nhe=n(Vxe,"STRONG",{});var lft=s(Nhe);HQo=r(lft,"unispeech"),lft.forEach(t),UQo=r(Vxe," \u2014 "),BV=n(Vxe,"A",{href:!0});var ift=s(BV);JQo=r(ift,"UniSpeechForSequenceClassification"),ift.forEach(t),YQo=r(Vxe," (UniSpeech model)"),Vxe.forEach(t),KQo=i(bo),Zv=n(bo,"LI",{});var Xxe=s(Zv);jhe=n(Xxe,"STRONG",{});var dft=s(jhe);ZQo=r(dft,"unispeech-sat"),dft.forEach(t),eWo=r(Xxe," \u2014 "),PV=n(Xxe,"A",{href:!0});var cft=s(PV);oWo=r(cft,"UniSpeechSatForSequenceClassification"),cft.forEach(t),rWo=r(Xxe," (UniSpeechSat model)"),Xxe.forEach(t),tWo=i(bo),eF=n(bo,"LI",{});var zxe=s(eF);Dhe=n(zxe,"STRONG",{});var fft=s(Dhe);aWo=r(fft,"wav2vec2"),fft.forEach(t),nWo=r(zxe," \u2014 "),IV=n(zxe,"A",{href:!0});var mft=s(IV);sWo=r(mft,"Wav2Vec2ForSequenceClassification"),mft.forEach(t),lWo=r(zxe," (Wav2Vec2 model)"),zxe.forEach(t),iWo=i(bo),oF=n(bo,"LI",{});var Qxe=s(oF);Ghe=n(Qxe,"STRONG",{});var gft=s(Ghe);dWo=r(gft,"wavlm"),gft.forEach(t),cWo=r(Qxe," \u2014 "),qV=n(Qxe,"A",{href:!0});var hft=s(qV);fWo=r(hft,"WavLMForSequenceClassification"),hft.forEach(t),mWo=r(Qxe," (WavLM model)"),Qxe.forEach(t),bo.forEach(t),gWo=i(ma),rF=n(ma,"P",{});var Wxe=s(rF);hWo=r(Wxe,"The model is set in evaluation mode by default using "),Ohe=n(Wxe,"CODE",{});var pft=s(Ohe);pWo=r(pft,"model.eval()"),pft.forEach(t),uWo=r(Wxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vhe=n(Wxe,"CODE",{});var uft=s(Vhe);_Wo=r(uft,"model.train()"),uft.forEach(t),Wxe.forEach(t),bWo=i(ma),T(tF.$$.fragment,ma),ma.forEach(t),el.forEach(t),rIe=i(f),cd=n(f,"H2",{class:!0});var sNe=s(cd);aF=n(sNe,"A",{id:!0,class:!0,href:!0});var _ft=s(aF);Xhe=n(_ft,"SPAN",{});var bft=s(Xhe);T(R0.$$.fragment,bft),bft.forEach(t),_ft.forEach(t),vWo=i(sNe),zhe=n(sNe,"SPAN",{});var vft=s(zhe);FWo=r(vft,"AutoModelForAudioFrameClassification"),vft.forEach(t),sNe.forEach(t),tIe=i(f),Oo=n(f,"DIV",{class:!0});var ol=s(Oo);T(B0.$$.fragment,ol),TWo=i(ol),fd=n(ol,"P",{});var CK=s(fd);MWo=r(CK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),NV=n(CK,"A",{href:!0});var Fft=s(NV);EWo=r(Fft,"from_pretrained()"),Fft.forEach(t),CWo=r(CK," class method or the "),jV=n(CK,"A",{href:!0});var Tft=s(jV);wWo=r(Tft,"from_config()"),Tft.forEach(t),AWo=r(CK,` class
method.`),CK.forEach(t),yWo=i(ol),P0=n(ol,"P",{});var lNe=s(P0);LWo=r(lNe,"This class cannot be instantiated directly using "),Qhe=n(lNe,"CODE",{});var Mft=s(Qhe);xWo=r(Mft,"__init__()"),Mft.forEach(t),$Wo=r(lNe," (throws an error)."),lNe.forEach(t),kWo=i(ol),ut=n(ol,"DIV",{class:!0});var T3=s(ut);T(I0.$$.fragment,T3),SWo=i(T3),Whe=n(T3,"P",{});var Eft=s(Whe);RWo=r(Eft,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Eft.forEach(t),BWo=i(T3),md=n(T3,"P",{});var wK=s(md);PWo=r(wK,`Note:
Loading a model from its configuration file does `),Hhe=n(wK,"STRONG",{});var Cft=s(Hhe);IWo=r(Cft,"not"),Cft.forEach(t),qWo=r(wK,` load the model weights. It only affects the
model\u2019s configuration. Use `),DV=n(wK,"A",{href:!0});var wft=s(DV);NWo=r(wft,"from_pretrained()"),wft.forEach(t),jWo=r(wK," to load the model weights."),wK.forEach(t),DWo=i(T3),T(nF.$$.fragment,T3),T3.forEach(t),GWo=i(ol),io=n(ol,"DIV",{class:!0});var ga=s(io);T(q0.$$.fragment,ga),OWo=i(ga),Uhe=n(ga,"P",{});var Aft=s(Uhe);VWo=r(Aft,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Aft.forEach(t),XWo=i(ga),Da=n(ga,"P",{});var M3=s(Da);zWo=r(M3,"The model class to instantiate is selected based on the "),Jhe=n(M3,"CODE",{});var yft=s(Jhe);QWo=r(yft,"model_type"),yft.forEach(t),WWo=r(M3,` property of the config object (either
passed as an argument or loaded from `),Yhe=n(M3,"CODE",{});var Lft=s(Yhe);HWo=r(Lft,"pretrained_model_name_or_path"),Lft.forEach(t),UWo=r(M3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Khe=n(M3,"CODE",{});var xft=s(Khe);JWo=r(xft,"pretrained_model_name_or_path"),xft.forEach(t),YWo=r(M3,":"),M3.forEach(t),KWo=i(ga),Ga=n(ga,"UL",{});var E3=s(Ga);sF=n(E3,"LI",{});var Hxe=s(sF);Zhe=n(Hxe,"STRONG",{});var $ft=s(Zhe);ZWo=r($ft,"data2vec-audio"),$ft.forEach(t),eHo=r(Hxe," \u2014 "),GV=n(Hxe,"A",{href:!0});var kft=s(GV);oHo=r(kft,"Data2VecAudioForAudioFrameClassification"),kft.forEach(t),rHo=r(Hxe," (Data2VecAudio model)"),Hxe.forEach(t),tHo=i(E3),lF=n(E3,"LI",{});var Uxe=s(lF);epe=n(Uxe,"STRONG",{});var Sft=s(epe);aHo=r(Sft,"unispeech-sat"),Sft.forEach(t),nHo=r(Uxe," \u2014 "),OV=n(Uxe,"A",{href:!0});var Rft=s(OV);sHo=r(Rft,"UniSpeechSatForAudioFrameClassification"),Rft.forEach(t),lHo=r(Uxe," (UniSpeechSat model)"),Uxe.forEach(t),iHo=i(E3),iF=n(E3,"LI",{});var Jxe=s(iF);ope=n(Jxe,"STRONG",{});var Bft=s(ope);dHo=r(Bft,"wav2vec2"),Bft.forEach(t),cHo=r(Jxe," \u2014 "),VV=n(Jxe,"A",{href:!0});var Pft=s(VV);fHo=r(Pft,"Wav2Vec2ForAudioFrameClassification"),Pft.forEach(t),mHo=r(Jxe," (Wav2Vec2 model)"),Jxe.forEach(t),gHo=i(E3),dF=n(E3,"LI",{});var Yxe=s(dF);rpe=n(Yxe,"STRONG",{});var Ift=s(rpe);hHo=r(Ift,"wavlm"),Ift.forEach(t),pHo=r(Yxe," \u2014 "),XV=n(Yxe,"A",{href:!0});var qft=s(XV);uHo=r(qft,"WavLMForAudioFrameClassification"),qft.forEach(t),_Ho=r(Yxe," (WavLM model)"),Yxe.forEach(t),E3.forEach(t),bHo=i(ga),cF=n(ga,"P",{});var Kxe=s(cF);vHo=r(Kxe,"The model is set in evaluation mode by default using "),tpe=n(Kxe,"CODE",{});var Nft=s(tpe);FHo=r(Nft,"model.eval()"),Nft.forEach(t),THo=r(Kxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ape=n(Kxe,"CODE",{});var jft=s(ape);MHo=r(jft,"model.train()"),jft.forEach(t),Kxe.forEach(t),EHo=i(ga),T(fF.$$.fragment,ga),ga.forEach(t),ol.forEach(t),aIe=i(f),gd=n(f,"H2",{class:!0});var iNe=s(gd);mF=n(iNe,"A",{id:!0,class:!0,href:!0});var Dft=s(mF);npe=n(Dft,"SPAN",{});var Gft=s(npe);T(N0.$$.fragment,Gft),Gft.forEach(t),Dft.forEach(t),CHo=i(iNe),spe=n(iNe,"SPAN",{});var Oft=s(spe);wHo=r(Oft,"AutoModelForCTC"),Oft.forEach(t),iNe.forEach(t),nIe=i(f),Vo=n(f,"DIV",{class:!0});var rl=s(Vo);T(j0.$$.fragment,rl),AHo=i(rl),hd=n(rl,"P",{});var AK=s(hd);yHo=r(AK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),zV=n(AK,"A",{href:!0});var Vft=s(zV);LHo=r(Vft,"from_pretrained()"),Vft.forEach(t),xHo=r(AK," class method or the "),QV=n(AK,"A",{href:!0});var Xft=s(QV);$Ho=r(Xft,"from_config()"),Xft.forEach(t),kHo=r(AK,` class
method.`),AK.forEach(t),SHo=i(rl),D0=n(rl,"P",{});var dNe=s(D0);RHo=r(dNe,"This class cannot be instantiated directly using "),lpe=n(dNe,"CODE",{});var zft=s(lpe);BHo=r(zft,"__init__()"),zft.forEach(t),PHo=r(dNe," (throws an error)."),dNe.forEach(t),IHo=i(rl),_t=n(rl,"DIV",{class:!0});var C3=s(_t);T(G0.$$.fragment,C3),qHo=i(C3),ipe=n(C3,"P",{});var Qft=s(ipe);NHo=r(Qft,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Qft.forEach(t),jHo=i(C3),pd=n(C3,"P",{});var yK=s(pd);DHo=r(yK,`Note:
Loading a model from its configuration file does `),dpe=n(yK,"STRONG",{});var Wft=s(dpe);GHo=r(Wft,"not"),Wft.forEach(t),OHo=r(yK,` load the model weights. It only affects the
model\u2019s configuration. Use `),WV=n(yK,"A",{href:!0});var Hft=s(WV);VHo=r(Hft,"from_pretrained()"),Hft.forEach(t),XHo=r(yK," to load the model weights."),yK.forEach(t),zHo=i(C3),T(gF.$$.fragment,C3),C3.forEach(t),QHo=i(rl),co=n(rl,"DIV",{class:!0});var ha=s(co);T(O0.$$.fragment,ha),WHo=i(ha),cpe=n(ha,"P",{});var Uft=s(cpe);HHo=r(Uft,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Uft.forEach(t),UHo=i(ha),Oa=n(ha,"P",{});var w3=s(Oa);JHo=r(w3,"The model class to instantiate is selected based on the "),fpe=n(w3,"CODE",{});var Jft=s(fpe);YHo=r(Jft,"model_type"),Jft.forEach(t),KHo=r(w3,` property of the config object (either
passed as an argument or loaded from `),mpe=n(w3,"CODE",{});var Yft=s(mpe);ZHo=r(Yft,"pretrained_model_name_or_path"),Yft.forEach(t),eUo=r(w3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gpe=n(w3,"CODE",{});var Kft=s(gpe);oUo=r(Kft,"pretrained_model_name_or_path"),Kft.forEach(t),rUo=r(w3,":"),w3.forEach(t),tUo=i(ha),je=n(ha,"UL",{});var vo=s(je);hF=n(vo,"LI",{});var Zxe=s(hF);hpe=n(Zxe,"STRONG",{});var Zft=s(hpe);aUo=r(Zft,"data2vec-audio"),Zft.forEach(t),nUo=r(Zxe," \u2014 "),HV=n(Zxe,"A",{href:!0});var emt=s(HV);sUo=r(emt,"Data2VecAudioForCTC"),emt.forEach(t),lUo=r(Zxe," (Data2VecAudio model)"),Zxe.forEach(t),iUo=i(vo),pF=n(vo,"LI",{});var e7e=s(pF);ppe=n(e7e,"STRONG",{});var omt=s(ppe);dUo=r(omt,"hubert"),omt.forEach(t),cUo=r(e7e," \u2014 "),UV=n(e7e,"A",{href:!0});var rmt=s(UV);fUo=r(rmt,"HubertForCTC"),rmt.forEach(t),mUo=r(e7e," (Hubert model)"),e7e.forEach(t),gUo=i(vo),uF=n(vo,"LI",{});var o7e=s(uF);upe=n(o7e,"STRONG",{});var tmt=s(upe);hUo=r(tmt,"sew"),tmt.forEach(t),pUo=r(o7e," \u2014 "),JV=n(o7e,"A",{href:!0});var amt=s(JV);uUo=r(amt,"SEWForCTC"),amt.forEach(t),_Uo=r(o7e," (SEW model)"),o7e.forEach(t),bUo=i(vo),_F=n(vo,"LI",{});var r7e=s(_F);_pe=n(r7e,"STRONG",{});var nmt=s(_pe);vUo=r(nmt,"sew-d"),nmt.forEach(t),FUo=r(r7e," \u2014 "),YV=n(r7e,"A",{href:!0});var smt=s(YV);TUo=r(smt,"SEWDForCTC"),smt.forEach(t),MUo=r(r7e," (SEW-D model)"),r7e.forEach(t),EUo=i(vo),bF=n(vo,"LI",{});var t7e=s(bF);bpe=n(t7e,"STRONG",{});var lmt=s(bpe);CUo=r(lmt,"unispeech"),lmt.forEach(t),wUo=r(t7e," \u2014 "),KV=n(t7e,"A",{href:!0});var imt=s(KV);AUo=r(imt,"UniSpeechForCTC"),imt.forEach(t),yUo=r(t7e," (UniSpeech model)"),t7e.forEach(t),LUo=i(vo),vF=n(vo,"LI",{});var a7e=s(vF);vpe=n(a7e,"STRONG",{});var dmt=s(vpe);xUo=r(dmt,"unispeech-sat"),dmt.forEach(t),$Uo=r(a7e," \u2014 "),ZV=n(a7e,"A",{href:!0});var cmt=s(ZV);kUo=r(cmt,"UniSpeechSatForCTC"),cmt.forEach(t),SUo=r(a7e," (UniSpeechSat model)"),a7e.forEach(t),RUo=i(vo),FF=n(vo,"LI",{});var n7e=s(FF);Fpe=n(n7e,"STRONG",{});var fmt=s(Fpe);BUo=r(fmt,"wav2vec2"),fmt.forEach(t),PUo=r(n7e," \u2014 "),eX=n(n7e,"A",{href:!0});var mmt=s(eX);IUo=r(mmt,"Wav2Vec2ForCTC"),mmt.forEach(t),qUo=r(n7e," (Wav2Vec2 model)"),n7e.forEach(t),NUo=i(vo),TF=n(vo,"LI",{});var s7e=s(TF);Tpe=n(s7e,"STRONG",{});var gmt=s(Tpe);jUo=r(gmt,"wavlm"),gmt.forEach(t),DUo=r(s7e," \u2014 "),oX=n(s7e,"A",{href:!0});var hmt=s(oX);GUo=r(hmt,"WavLMForCTC"),hmt.forEach(t),OUo=r(s7e," (WavLM model)"),s7e.forEach(t),vo.forEach(t),VUo=i(ha),MF=n(ha,"P",{});var l7e=s(MF);XUo=r(l7e,"The model is set in evaluation mode by default using "),Mpe=n(l7e,"CODE",{});var pmt=s(Mpe);zUo=r(pmt,"model.eval()"),pmt.forEach(t),QUo=r(l7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Epe=n(l7e,"CODE",{});var umt=s(Epe);WUo=r(umt,"model.train()"),umt.forEach(t),l7e.forEach(t),HUo=i(ha),T(EF.$$.fragment,ha),ha.forEach(t),rl.forEach(t),sIe=i(f),ud=n(f,"H2",{class:!0});var cNe=s(ud);CF=n(cNe,"A",{id:!0,class:!0,href:!0});var _mt=s(CF);Cpe=n(_mt,"SPAN",{});var bmt=s(Cpe);T(V0.$$.fragment,bmt),bmt.forEach(t),_mt.forEach(t),UUo=i(cNe),wpe=n(cNe,"SPAN",{});var vmt=s(wpe);JUo=r(vmt,"AutoModelForSpeechSeq2Seq"),vmt.forEach(t),cNe.forEach(t),lIe=i(f),Xo=n(f,"DIV",{class:!0});var tl=s(Xo);T(X0.$$.fragment,tl),YUo=i(tl),_d=n(tl,"P",{});var LK=s(_d);KUo=r(LK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),rX=n(LK,"A",{href:!0});var Fmt=s(rX);ZUo=r(Fmt,"from_pretrained()"),Fmt.forEach(t),eJo=r(LK," class method or the "),tX=n(LK,"A",{href:!0});var Tmt=s(tX);oJo=r(Tmt,"from_config()"),Tmt.forEach(t),rJo=r(LK,` class
method.`),LK.forEach(t),tJo=i(tl),z0=n(tl,"P",{});var fNe=s(z0);aJo=r(fNe,"This class cannot be instantiated directly using "),Ape=n(fNe,"CODE",{});var Mmt=s(Ape);nJo=r(Mmt,"__init__()"),Mmt.forEach(t),sJo=r(fNe," (throws an error)."),fNe.forEach(t),lJo=i(tl),bt=n(tl,"DIV",{class:!0});var A3=s(bt);T(Q0.$$.fragment,A3),iJo=i(A3),ype=n(A3,"P",{});var Emt=s(ype);dJo=r(Emt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Emt.forEach(t),cJo=i(A3),bd=n(A3,"P",{});var xK=s(bd);fJo=r(xK,`Note:
Loading a model from its configuration file does `),Lpe=n(xK,"STRONG",{});var Cmt=s(Lpe);mJo=r(Cmt,"not"),Cmt.forEach(t),gJo=r(xK,` load the model weights. It only affects the
model\u2019s configuration. Use `),aX=n(xK,"A",{href:!0});var wmt=s(aX);hJo=r(wmt,"from_pretrained()"),wmt.forEach(t),pJo=r(xK," to load the model weights."),xK.forEach(t),uJo=i(A3),T(wF.$$.fragment,A3),A3.forEach(t),_Jo=i(tl),fo=n(tl,"DIV",{class:!0});var pa=s(fo);T(W0.$$.fragment,pa),bJo=i(pa),xpe=n(pa,"P",{});var Amt=s(xpe);vJo=r(Amt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Amt.forEach(t),FJo=i(pa),Va=n(pa,"P",{});var y3=s(Va);TJo=r(y3,"The model class to instantiate is selected based on the "),$pe=n(y3,"CODE",{});var ymt=s($pe);MJo=r(ymt,"model_type"),ymt.forEach(t),EJo=r(y3,` property of the config object (either
passed as an argument or loaded from `),kpe=n(y3,"CODE",{});var Lmt=s(kpe);CJo=r(Lmt,"pretrained_model_name_or_path"),Lmt.forEach(t),wJo=r(y3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Spe=n(y3,"CODE",{});var xmt=s(Spe);AJo=r(xmt,"pretrained_model_name_or_path"),xmt.forEach(t),yJo=r(y3,":"),y3.forEach(t),LJo=i(pa),H0=n(pa,"UL",{});var mNe=s(H0);AF=n(mNe,"LI",{});var i7e=s(AF);Rpe=n(i7e,"STRONG",{});var $mt=s(Rpe);xJo=r($mt,"speech-encoder-decoder"),$mt.forEach(t),$Jo=r(i7e," \u2014 "),nX=n(i7e,"A",{href:!0});var kmt=s(nX);kJo=r(kmt,"SpeechEncoderDecoderModel"),kmt.forEach(t),SJo=r(i7e," (Speech Encoder decoder model)"),i7e.forEach(t),RJo=i(mNe),yF=n(mNe,"LI",{});var d7e=s(yF);Bpe=n(d7e,"STRONG",{});var Smt=s(Bpe);BJo=r(Smt,"speech_to_text"),Smt.forEach(t),PJo=r(d7e," \u2014 "),sX=n(d7e,"A",{href:!0});var Rmt=s(sX);IJo=r(Rmt,"Speech2TextForConditionalGeneration"),Rmt.forEach(t),qJo=r(d7e," (Speech2Text model)"),d7e.forEach(t),mNe.forEach(t),NJo=i(pa),LF=n(pa,"P",{});var c7e=s(LF);jJo=r(c7e,"The model is set in evaluation mode by default using "),Ppe=n(c7e,"CODE",{});var Bmt=s(Ppe);DJo=r(Bmt,"model.eval()"),Bmt.forEach(t),GJo=r(c7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ipe=n(c7e,"CODE",{});var Pmt=s(Ipe);OJo=r(Pmt,"model.train()"),Pmt.forEach(t),c7e.forEach(t),VJo=i(pa),T(xF.$$.fragment,pa),pa.forEach(t),tl.forEach(t),iIe=i(f),vd=n(f,"H2",{class:!0});var gNe=s(vd);$F=n(gNe,"A",{id:!0,class:!0,href:!0});var Imt=s($F);qpe=n(Imt,"SPAN",{});var qmt=s(qpe);T(U0.$$.fragment,qmt),qmt.forEach(t),Imt.forEach(t),XJo=i(gNe),Npe=n(gNe,"SPAN",{});var Nmt=s(Npe);zJo=r(Nmt,"AutoModelForAudioXVector"),Nmt.forEach(t),gNe.forEach(t),dIe=i(f),zo=n(f,"DIV",{class:!0});var al=s(zo);T(J0.$$.fragment,al),QJo=i(al),Fd=n(al,"P",{});var $K=s(Fd);WJo=r($K,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),lX=n($K,"A",{href:!0});var jmt=s(lX);HJo=r(jmt,"from_pretrained()"),jmt.forEach(t),UJo=r($K," class method or the "),iX=n($K,"A",{href:!0});var Dmt=s(iX);JJo=r(Dmt,"from_config()"),Dmt.forEach(t),YJo=r($K,` class
method.`),$K.forEach(t),KJo=i(al),Y0=n(al,"P",{});var hNe=s(Y0);ZJo=r(hNe,"This class cannot be instantiated directly using "),jpe=n(hNe,"CODE",{});var Gmt=s(jpe);eYo=r(Gmt,"__init__()"),Gmt.forEach(t),oYo=r(hNe," (throws an error)."),hNe.forEach(t),rYo=i(al),vt=n(al,"DIV",{class:!0});var L3=s(vt);T(K0.$$.fragment,L3),tYo=i(L3),Dpe=n(L3,"P",{});var Omt=s(Dpe);aYo=r(Omt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Omt.forEach(t),nYo=i(L3),Td=n(L3,"P",{});var kK=s(Td);sYo=r(kK,`Note:
Loading a model from its configuration file does `),Gpe=n(kK,"STRONG",{});var Vmt=s(Gpe);lYo=r(Vmt,"not"),Vmt.forEach(t),iYo=r(kK,` load the model weights. It only affects the
model\u2019s configuration. Use `),dX=n(kK,"A",{href:!0});var Xmt=s(dX);dYo=r(Xmt,"from_pretrained()"),Xmt.forEach(t),cYo=r(kK," to load the model weights."),kK.forEach(t),fYo=i(L3),T(kF.$$.fragment,L3),L3.forEach(t),mYo=i(al),mo=n(al,"DIV",{class:!0});var ua=s(mo);T(Z0.$$.fragment,ua),gYo=i(ua),Ope=n(ua,"P",{});var zmt=s(Ope);hYo=r(zmt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),zmt.forEach(t),pYo=i(ua),Xa=n(ua,"P",{});var x3=s(Xa);uYo=r(x3,"The model class to instantiate is selected based on the "),Vpe=n(x3,"CODE",{});var Qmt=s(Vpe);_Yo=r(Qmt,"model_type"),Qmt.forEach(t),bYo=r(x3,` property of the config object (either
passed as an argument or loaded from `),Xpe=n(x3,"CODE",{});var Wmt=s(Xpe);vYo=r(Wmt,"pretrained_model_name_or_path"),Wmt.forEach(t),FYo=r(x3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zpe=n(x3,"CODE",{});var Hmt=s(zpe);TYo=r(Hmt,"pretrained_model_name_or_path"),Hmt.forEach(t),MYo=r(x3,":"),x3.forEach(t),EYo=i(ua),za=n(ua,"UL",{});var $3=s(za);SF=n($3,"LI",{});var f7e=s(SF);Qpe=n(f7e,"STRONG",{});var Umt=s(Qpe);CYo=r(Umt,"data2vec-audio"),Umt.forEach(t),wYo=r(f7e," \u2014 "),cX=n(f7e,"A",{href:!0});var Jmt=s(cX);AYo=r(Jmt,"Data2VecAudioForXVector"),Jmt.forEach(t),yYo=r(f7e," (Data2VecAudio model)"),f7e.forEach(t),LYo=i($3),RF=n($3,"LI",{});var m7e=s(RF);Wpe=n(m7e,"STRONG",{});var Ymt=s(Wpe);xYo=r(Ymt,"unispeech-sat"),Ymt.forEach(t),$Yo=r(m7e," \u2014 "),fX=n(m7e,"A",{href:!0});var Kmt=s(fX);kYo=r(Kmt,"UniSpeechSatForXVector"),Kmt.forEach(t),SYo=r(m7e," (UniSpeechSat model)"),m7e.forEach(t),RYo=i($3),BF=n($3,"LI",{});var g7e=s(BF);Hpe=n(g7e,"STRONG",{});var Zmt=s(Hpe);BYo=r(Zmt,"wav2vec2"),Zmt.forEach(t),PYo=r(g7e," \u2014 "),mX=n(g7e,"A",{href:!0});var egt=s(mX);IYo=r(egt,"Wav2Vec2ForXVector"),egt.forEach(t),qYo=r(g7e," (Wav2Vec2 model)"),g7e.forEach(t),NYo=i($3),PF=n($3,"LI",{});var h7e=s(PF);Upe=n(h7e,"STRONG",{});var ogt=s(Upe);jYo=r(ogt,"wavlm"),ogt.forEach(t),DYo=r(h7e," \u2014 "),gX=n(h7e,"A",{href:!0});var rgt=s(gX);GYo=r(rgt,"WavLMForXVector"),rgt.forEach(t),OYo=r(h7e," (WavLM model)"),h7e.forEach(t),$3.forEach(t),VYo=i(ua),IF=n(ua,"P",{});var p7e=s(IF);XYo=r(p7e,"The model is set in evaluation mode by default using "),Jpe=n(p7e,"CODE",{});var tgt=s(Jpe);zYo=r(tgt,"model.eval()"),tgt.forEach(t),QYo=r(p7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=n(p7e,"CODE",{});var agt=s(Ype);WYo=r(agt,"model.train()"),agt.forEach(t),p7e.forEach(t),HYo=i(ua),T(qF.$$.fragment,ua),ua.forEach(t),al.forEach(t),cIe=i(f),Md=n(f,"H2",{class:!0});var pNe=s(Md);NF=n(pNe,"A",{id:!0,class:!0,href:!0});var ngt=s(NF);Kpe=n(ngt,"SPAN",{});var sgt=s(Kpe);T(ey.$$.fragment,sgt),sgt.forEach(t),ngt.forEach(t),UYo=i(pNe),Zpe=n(pNe,"SPAN",{});var lgt=s(Zpe);JYo=r(lgt,"AutoModelForMaskedImageModeling"),lgt.forEach(t),pNe.forEach(t),fIe=i(f),Qo=n(f,"DIV",{class:!0});var nl=s(Qo);T(oy.$$.fragment,nl),YYo=i(nl),Ed=n(nl,"P",{});var SK=s(Ed);KYo=r(SK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),hX=n(SK,"A",{href:!0});var igt=s(hX);ZYo=r(igt,"from_pretrained()"),igt.forEach(t),eKo=r(SK," class method or the "),pX=n(SK,"A",{href:!0});var dgt=s(pX);oKo=r(dgt,"from_config()"),dgt.forEach(t),rKo=r(SK,` class
method.`),SK.forEach(t),tKo=i(nl),ry=n(nl,"P",{});var uNe=s(ry);aKo=r(uNe,"This class cannot be instantiated directly using "),eue=n(uNe,"CODE",{});var cgt=s(eue);nKo=r(cgt,"__init__()"),cgt.forEach(t),sKo=r(uNe," (throws an error)."),uNe.forEach(t),lKo=i(nl),Ft=n(nl,"DIV",{class:!0});var k3=s(Ft);T(ty.$$.fragment,k3),iKo=i(k3),oue=n(k3,"P",{});var fgt=s(oue);dKo=r(fgt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),fgt.forEach(t),cKo=i(k3),Cd=n(k3,"P",{});var RK=s(Cd);fKo=r(RK,`Note:
Loading a model from its configuration file does `),rue=n(RK,"STRONG",{});var mgt=s(rue);mKo=r(mgt,"not"),mgt.forEach(t),gKo=r(RK,` load the model weights. It only affects the
model\u2019s configuration. Use `),uX=n(RK,"A",{href:!0});var ggt=s(uX);hKo=r(ggt,"from_pretrained()"),ggt.forEach(t),pKo=r(RK," to load the model weights."),RK.forEach(t),uKo=i(k3),T(jF.$$.fragment,k3),k3.forEach(t),_Ko=i(nl),go=n(nl,"DIV",{class:!0});var _a=s(go);T(ay.$$.fragment,_a),bKo=i(_a),tue=n(_a,"P",{});var hgt=s(tue);vKo=r(hgt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),hgt.forEach(t),FKo=i(_a),Qa=n(_a,"P",{});var S3=s(Qa);TKo=r(S3,"The model class to instantiate is selected based on the "),aue=n(S3,"CODE",{});var pgt=s(aue);MKo=r(pgt,"model_type"),pgt.forEach(t),EKo=r(S3,` property of the config object (either
passed as an argument or loaded from `),nue=n(S3,"CODE",{});var ugt=s(nue);CKo=r(ugt,"pretrained_model_name_or_path"),ugt.forEach(t),wKo=r(S3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sue=n(S3,"CODE",{});var _gt=s(sue);AKo=r(_gt,"pretrained_model_name_or_path"),_gt.forEach(t),yKo=r(S3,":"),S3.forEach(t),LKo=i(_a),wd=n(_a,"UL",{});var BK=s(wd);DF=n(BK,"LI",{});var u7e=s(DF);lue=n(u7e,"STRONG",{});var bgt=s(lue);xKo=r(bgt,"deit"),bgt.forEach(t),$Ko=r(u7e," \u2014 "),_X=n(u7e,"A",{href:!0});var vgt=s(_X);kKo=r(vgt,"DeiTForMaskedImageModeling"),vgt.forEach(t),SKo=r(u7e," (DeiT model)"),u7e.forEach(t),RKo=i(BK),GF=n(BK,"LI",{});var _7e=s(GF);iue=n(_7e,"STRONG",{});var Fgt=s(iue);BKo=r(Fgt,"swin"),Fgt.forEach(t),PKo=r(_7e," \u2014 "),bX=n(_7e,"A",{href:!0});var Tgt=s(bX);IKo=r(Tgt,"SwinForMaskedImageModeling"),Tgt.forEach(t),qKo=r(_7e," (Swin model)"),_7e.forEach(t),NKo=i(BK),OF=n(BK,"LI",{});var b7e=s(OF);due=n(b7e,"STRONG",{});var Mgt=s(due);jKo=r(Mgt,"vit"),Mgt.forEach(t),DKo=r(b7e," \u2014 "),vX=n(b7e,"A",{href:!0});var Egt=s(vX);GKo=r(Egt,"ViTForMaskedImageModeling"),Egt.forEach(t),OKo=r(b7e," (ViT model)"),b7e.forEach(t),BK.forEach(t),VKo=i(_a),VF=n(_a,"P",{});var v7e=s(VF);XKo=r(v7e,"The model is set in evaluation mode by default using "),cue=n(v7e,"CODE",{});var Cgt=s(cue);zKo=r(Cgt,"model.eval()"),Cgt.forEach(t),QKo=r(v7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fue=n(v7e,"CODE",{});var wgt=s(fue);WKo=r(wgt,"model.train()"),wgt.forEach(t),v7e.forEach(t),HKo=i(_a),T(XF.$$.fragment,_a),_a.forEach(t),nl.forEach(t),mIe=i(f),Ad=n(f,"H2",{class:!0});var _Ne=s(Ad);zF=n(_Ne,"A",{id:!0,class:!0,href:!0});var Agt=s(zF);mue=n(Agt,"SPAN",{});var ygt=s(mue);T(ny.$$.fragment,ygt),ygt.forEach(t),Agt.forEach(t),UKo=i(_Ne),gue=n(_Ne,"SPAN",{});var Lgt=s(gue);JKo=r(Lgt,"AutoModelForObjectDetection"),Lgt.forEach(t),_Ne.forEach(t),gIe=i(f),Wo=n(f,"DIV",{class:!0});var sl=s(Wo);T(sy.$$.fragment,sl),YKo=i(sl),yd=n(sl,"P",{});var PK=s(yd);KKo=r(PK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),FX=n(PK,"A",{href:!0});var xgt=s(FX);ZKo=r(xgt,"from_pretrained()"),xgt.forEach(t),eZo=r(PK," class method or the "),TX=n(PK,"A",{href:!0});var $gt=s(TX);oZo=r($gt,"from_config()"),$gt.forEach(t),rZo=r(PK,` class
method.`),PK.forEach(t),tZo=i(sl),ly=n(sl,"P",{});var bNe=s(ly);aZo=r(bNe,"This class cannot be instantiated directly using "),hue=n(bNe,"CODE",{});var kgt=s(hue);nZo=r(kgt,"__init__()"),kgt.forEach(t),sZo=r(bNe," (throws an error)."),bNe.forEach(t),lZo=i(sl),Tt=n(sl,"DIV",{class:!0});var R3=s(Tt);T(iy.$$.fragment,R3),iZo=i(R3),pue=n(R3,"P",{});var Sgt=s(pue);dZo=r(Sgt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Sgt.forEach(t),cZo=i(R3),Ld=n(R3,"P",{});var IK=s(Ld);fZo=r(IK,`Note:
Loading a model from its configuration file does `),uue=n(IK,"STRONG",{});var Rgt=s(uue);mZo=r(Rgt,"not"),Rgt.forEach(t),gZo=r(IK,` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=n(IK,"A",{href:!0});var Bgt=s(MX);hZo=r(Bgt,"from_pretrained()"),Bgt.forEach(t),pZo=r(IK," to load the model weights."),IK.forEach(t),uZo=i(R3),T(QF.$$.fragment,R3),R3.forEach(t),_Zo=i(sl),ho=n(sl,"DIV",{class:!0});var ba=s(ho);T(dy.$$.fragment,ba),bZo=i(ba),_ue=n(ba,"P",{});var Pgt=s(_ue);vZo=r(Pgt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Pgt.forEach(t),FZo=i(ba),Wa=n(ba,"P",{});var B3=s(Wa);TZo=r(B3,"The model class to instantiate is selected based on the "),bue=n(B3,"CODE",{});var Igt=s(bue);MZo=r(Igt,"model_type"),Igt.forEach(t),EZo=r(B3,` property of the config object (either
passed as an argument or loaded from `),vue=n(B3,"CODE",{});var qgt=s(vue);CZo=r(qgt,"pretrained_model_name_or_path"),qgt.forEach(t),wZo=r(B3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fue=n(B3,"CODE",{});var Ngt=s(Fue);AZo=r(Ngt,"pretrained_model_name_or_path"),Ngt.forEach(t),yZo=r(B3,":"),B3.forEach(t),LZo=i(ba),cy=n(ba,"UL",{});var vNe=s(cy);WF=n(vNe,"LI",{});var F7e=s(WF);Tue=n(F7e,"STRONG",{});var jgt=s(Tue);xZo=r(jgt,"detr"),jgt.forEach(t),$Zo=r(F7e," \u2014 "),EX=n(F7e,"A",{href:!0});var Dgt=s(EX);kZo=r(Dgt,"DetrForObjectDetection"),Dgt.forEach(t),SZo=r(F7e," (DETR model)"),F7e.forEach(t),RZo=i(vNe),HF=n(vNe,"LI",{});var T7e=s(HF);Mue=n(T7e,"STRONG",{});var Ggt=s(Mue);BZo=r(Ggt,"yolos"),Ggt.forEach(t),PZo=r(T7e," \u2014 "),CX=n(T7e,"A",{href:!0});var Ogt=s(CX);IZo=r(Ogt,"YolosForObjectDetection"),Ogt.forEach(t),qZo=r(T7e," (YOLOS model)"),T7e.forEach(t),vNe.forEach(t),NZo=i(ba),UF=n(ba,"P",{});var M7e=s(UF);jZo=r(M7e,"The model is set in evaluation mode by default using "),Eue=n(M7e,"CODE",{});var Vgt=s(Eue);DZo=r(Vgt,"model.eval()"),Vgt.forEach(t),GZo=r(M7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cue=n(M7e,"CODE",{});var Xgt=s(Cue);OZo=r(Xgt,"model.train()"),Xgt.forEach(t),M7e.forEach(t),VZo=i(ba),T(JF.$$.fragment,ba),ba.forEach(t),sl.forEach(t),hIe=i(f),xd=n(f,"H2",{class:!0});var FNe=s(xd);YF=n(FNe,"A",{id:!0,class:!0,href:!0});var zgt=s(YF);wue=n(zgt,"SPAN",{});var Qgt=s(wue);T(fy.$$.fragment,Qgt),Qgt.forEach(t),zgt.forEach(t),XZo=i(FNe),Aue=n(FNe,"SPAN",{});var Wgt=s(Aue);zZo=r(Wgt,"AutoModelForImageSegmentation"),Wgt.forEach(t),FNe.forEach(t),pIe=i(f),Ho=n(f,"DIV",{class:!0});var ll=s(Ho);T(my.$$.fragment,ll),QZo=i(ll),$d=n(ll,"P",{});var qK=s($d);WZo=r(qK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),wX=n(qK,"A",{href:!0});var Hgt=s(wX);HZo=r(Hgt,"from_pretrained()"),Hgt.forEach(t),UZo=r(qK," class method or the "),AX=n(qK,"A",{href:!0});var Ugt=s(AX);JZo=r(Ugt,"from_config()"),Ugt.forEach(t),YZo=r(qK,` class
method.`),qK.forEach(t),KZo=i(ll),gy=n(ll,"P",{});var TNe=s(gy);ZZo=r(TNe,"This class cannot be instantiated directly using "),yue=n(TNe,"CODE",{});var Jgt=s(yue);eer=r(Jgt,"__init__()"),Jgt.forEach(t),oer=r(TNe," (throws an error)."),TNe.forEach(t),rer=i(ll),Mt=n(ll,"DIV",{class:!0});var P3=s(Mt);T(hy.$$.fragment,P3),ter=i(P3),Lue=n(P3,"P",{});var Ygt=s(Lue);aer=r(Ygt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Ygt.forEach(t),ner=i(P3),kd=n(P3,"P",{});var NK=s(kd);ser=r(NK,`Note:
Loading a model from its configuration file does `),xue=n(NK,"STRONG",{});var Kgt=s(xue);ler=r(Kgt,"not"),Kgt.forEach(t),ier=r(NK,` load the model weights. It only affects the
model\u2019s configuration. Use `),yX=n(NK,"A",{href:!0});var Zgt=s(yX);der=r(Zgt,"from_pretrained()"),Zgt.forEach(t),cer=r(NK," to load the model weights."),NK.forEach(t),fer=i(P3),T(KF.$$.fragment,P3),P3.forEach(t),mer=i(ll),po=n(ll,"DIV",{class:!0});var va=s(po);T(py.$$.fragment,va),ger=i(va),$ue=n(va,"P",{});var eht=s($ue);her=r(eht,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),eht.forEach(t),per=i(va),Ha=n(va,"P",{});var I3=s(Ha);uer=r(I3,"The model class to instantiate is selected based on the "),kue=n(I3,"CODE",{});var oht=s(kue);_er=r(oht,"model_type"),oht.forEach(t),ber=r(I3,` property of the config object (either
passed as an argument or loaded from `),Sue=n(I3,"CODE",{});var rht=s(Sue);ver=r(rht,"pretrained_model_name_or_path"),rht.forEach(t),Fer=r(I3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rue=n(I3,"CODE",{});var tht=s(Rue);Ter=r(tht,"pretrained_model_name_or_path"),tht.forEach(t),Mer=r(I3,":"),I3.forEach(t),Eer=i(va),Bue=n(va,"UL",{});var aht=s(Bue);ZF=n(aht,"LI",{});var E7e=s(ZF);Pue=n(E7e,"STRONG",{});var nht=s(Pue);Cer=r(nht,"detr"),nht.forEach(t),wer=r(E7e," \u2014 "),LX=n(E7e,"A",{href:!0});var sht=s(LX);Aer=r(sht,"DetrForSegmentation"),sht.forEach(t),yer=r(E7e," (DETR model)"),E7e.forEach(t),aht.forEach(t),Ler=i(va),e6=n(va,"P",{});var C7e=s(e6);xer=r(C7e,"The model is set in evaluation mode by default using "),Iue=n(C7e,"CODE",{});var lht=s(Iue);$er=r(lht,"model.eval()"),lht.forEach(t),ker=r(C7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),que=n(C7e,"CODE",{});var iht=s(que);Ser=r(iht,"model.train()"),iht.forEach(t),C7e.forEach(t),Rer=i(va),T(o6.$$.fragment,va),va.forEach(t),ll.forEach(t),uIe=i(f),Sd=n(f,"H2",{class:!0});var MNe=s(Sd);r6=n(MNe,"A",{id:!0,class:!0,href:!0});var dht=s(r6);Nue=n(dht,"SPAN",{});var cht=s(Nue);T(uy.$$.fragment,cht),cht.forEach(t),dht.forEach(t),Ber=i(MNe),jue=n(MNe,"SPAN",{});var fht=s(jue);Per=r(fht,"AutoModelForSemanticSegmentation"),fht.forEach(t),MNe.forEach(t),_Ie=i(f),Uo=n(f,"DIV",{class:!0});var il=s(Uo);T(_y.$$.fragment,il),Ier=i(il),Rd=n(il,"P",{});var jK=s(Rd);qer=r(jK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),xX=n(jK,"A",{href:!0});var mht=s(xX);Ner=r(mht,"from_pretrained()"),mht.forEach(t),jer=r(jK," class method or the "),$X=n(jK,"A",{href:!0});var ght=s($X);Der=r(ght,"from_config()"),ght.forEach(t),Ger=r(jK,` class
method.`),jK.forEach(t),Oer=i(il),by=n(il,"P",{});var ENe=s(by);Ver=r(ENe,"This class cannot be instantiated directly using "),Due=n(ENe,"CODE",{});var hht=s(Due);Xer=r(hht,"__init__()"),hht.forEach(t),zer=r(ENe," (throws an error)."),ENe.forEach(t),Qer=i(il),Et=n(il,"DIV",{class:!0});var q3=s(Et);T(vy.$$.fragment,q3),Wer=i(q3),Gue=n(q3,"P",{});var pht=s(Gue);Her=r(pht,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),pht.forEach(t),Uer=i(q3),Bd=n(q3,"P",{});var DK=s(Bd);Jer=r(DK,`Note:
Loading a model from its configuration file does `),Oue=n(DK,"STRONG",{});var uht=s(Oue);Yer=r(uht,"not"),uht.forEach(t),Ker=r(DK,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(DK,"A",{href:!0});var _ht=s(kX);Zer=r(_ht,"from_pretrained()"),_ht.forEach(t),eor=r(DK," to load the model weights."),DK.forEach(t),oor=i(q3),T(t6.$$.fragment,q3),q3.forEach(t),ror=i(il),uo=n(il,"DIV",{class:!0});var Fa=s(uo);T(Fy.$$.fragment,Fa),tor=i(Fa),Vue=n(Fa,"P",{});var bht=s(Vue);aor=r(bht,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),bht.forEach(t),nor=i(Fa),Ua=n(Fa,"P",{});var N3=s(Ua);sor=r(N3,"The model class to instantiate is selected based on the "),Xue=n(N3,"CODE",{});var vht=s(Xue);lor=r(vht,"model_type"),vht.forEach(t),ior=r(N3,` property of the config object (either
passed as an argument or loaded from `),zue=n(N3,"CODE",{});var Fht=s(zue);dor=r(Fht,"pretrained_model_name_or_path"),Fht.forEach(t),cor=r(N3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Que=n(N3,"CODE",{});var Tht=s(Que);mor=r(Tht,"pretrained_model_name_or_path"),Tht.forEach(t),gor=r(N3,":"),N3.forEach(t),hor=i(Fa),Ja=n(Fa,"UL",{});var j3=s(Ja);a6=n(j3,"LI",{});var w7e=s(a6);Wue=n(w7e,"STRONG",{});var Mht=s(Wue);por=r(Mht,"beit"),Mht.forEach(t),uor=r(w7e," \u2014 "),SX=n(w7e,"A",{href:!0});var Eht=s(SX);_or=r(Eht,"BeitForSemanticSegmentation"),Eht.forEach(t),bor=r(w7e," (BEiT model)"),w7e.forEach(t),vor=i(j3),n6=n(j3,"LI",{});var A7e=s(n6);Hue=n(A7e,"STRONG",{});var Cht=s(Hue);For=r(Cht,"data2vec-vision"),Cht.forEach(t),Tor=r(A7e," \u2014 "),RX=n(A7e,"A",{href:!0});var wht=s(RX);Mor=r(wht,"Data2VecVisionForSemanticSegmentation"),wht.forEach(t),Eor=r(A7e," (Data2VecVision model)"),A7e.forEach(t),Cor=i(j3),s6=n(j3,"LI",{});var y7e=s(s6);Uue=n(y7e,"STRONG",{});var Aht=s(Uue);wor=r(Aht,"dpt"),Aht.forEach(t),Aor=r(y7e," \u2014 "),BX=n(y7e,"A",{href:!0});var yht=s(BX);yor=r(yht,"DPTForSemanticSegmentation"),yht.forEach(t),Lor=r(y7e," (DPT model)"),y7e.forEach(t),xor=i(j3),l6=n(j3,"LI",{});var L7e=s(l6);Jue=n(L7e,"STRONG",{});var Lht=s(Jue);$or=r(Lht,"segformer"),Lht.forEach(t),kor=r(L7e," \u2014 "),PX=n(L7e,"A",{href:!0});var xht=s(PX);Sor=r(xht,"SegformerForSemanticSegmentation"),xht.forEach(t),Ror=r(L7e," (SegFormer model)"),L7e.forEach(t),j3.forEach(t),Bor=i(Fa),i6=n(Fa,"P",{});var x7e=s(i6);Por=r(x7e,"The model is set in evaluation mode by default using "),Yue=n(x7e,"CODE",{});var $ht=s(Yue);Ior=r($ht,"model.eval()"),$ht.forEach(t),qor=r(x7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kue=n(x7e,"CODE",{});var kht=s(Kue);Nor=r(kht,"model.train()"),kht.forEach(t),x7e.forEach(t),jor=i(Fa),T(d6.$$.fragment,Fa),Fa.forEach(t),il.forEach(t),bIe=i(f),Pd=n(f,"H2",{class:!0});var CNe=s(Pd);c6=n(CNe,"A",{id:!0,class:!0,href:!0});var Sht=s(c6);Zue=n(Sht,"SPAN",{});var Rht=s(Zue);T(Ty.$$.fragment,Rht),Rht.forEach(t),Sht.forEach(t),Dor=i(CNe),e_e=n(CNe,"SPAN",{});var Bht=s(e_e);Gor=r(Bht,"AutoModelForInstanceSegmentation"),Bht.forEach(t),CNe.forEach(t),vIe=i(f),Jo=n(f,"DIV",{class:!0});var dl=s(Jo);T(My.$$.fragment,dl),Oor=i(dl),Id=n(dl,"P",{});var GK=s(Id);Vor=r(GK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),IX=n(GK,"A",{href:!0});var Pht=s(IX);Xor=r(Pht,"from_pretrained()"),Pht.forEach(t),zor=r(GK," class method or the "),qX=n(GK,"A",{href:!0});var Iht=s(qX);Qor=r(Iht,"from_config()"),Iht.forEach(t),Wor=r(GK,` class
method.`),GK.forEach(t),Hor=i(dl),Ey=n(dl,"P",{});var wNe=s(Ey);Uor=r(wNe,"This class cannot be instantiated directly using "),o_e=n(wNe,"CODE",{});var qht=s(o_e);Jor=r(qht,"__init__()"),qht.forEach(t),Yor=r(wNe," (throws an error)."),wNe.forEach(t),Kor=i(dl),Ct=n(dl,"DIV",{class:!0});var D3=s(Ct);T(Cy.$$.fragment,D3),Zor=i(D3),r_e=n(D3,"P",{});var Nht=s(r_e);err=r(Nht,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Nht.forEach(t),orr=i(D3),qd=n(D3,"P",{});var OK=s(qd);rrr=r(OK,`Note:
Loading a model from its configuration file does `),t_e=n(OK,"STRONG",{});var jht=s(t_e);trr=r(jht,"not"),jht.forEach(t),arr=r(OK,` load the model weights. It only affects the
model\u2019s configuration. Use `),NX=n(OK,"A",{href:!0});var Dht=s(NX);nrr=r(Dht,"from_pretrained()"),Dht.forEach(t),srr=r(OK," to load the model weights."),OK.forEach(t),lrr=i(D3),T(f6.$$.fragment,D3),D3.forEach(t),irr=i(dl),_o=n(dl,"DIV",{class:!0});var Ta=s(_o);T(wy.$$.fragment,Ta),drr=i(Ta),a_e=n(Ta,"P",{});var Ght=s(a_e);crr=r(Ght,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Ght.forEach(t),frr=i(Ta),Ya=n(Ta,"P",{});var G3=s(Ya);mrr=r(G3,"The model class to instantiate is selected based on the "),n_e=n(G3,"CODE",{});var Oht=s(n_e);grr=r(Oht,"model_type"),Oht.forEach(t),hrr=r(G3,` property of the config object (either
passed as an argument or loaded from `),s_e=n(G3,"CODE",{});var Vht=s(s_e);prr=r(Vht,"pretrained_model_name_or_path"),Vht.forEach(t),urr=r(G3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l_e=n(G3,"CODE",{});var Xht=s(l_e);_rr=r(Xht,"pretrained_model_name_or_path"),Xht.forEach(t),brr=r(G3,":"),G3.forEach(t),vrr=i(Ta),i_e=n(Ta,"UL",{});var zht=s(i_e);m6=n(zht,"LI",{});var $7e=s(m6);d_e=n($7e,"STRONG",{});var Qht=s(d_e);Frr=r(Qht,"maskformer"),Qht.forEach(t),Trr=r($7e," \u2014 "),jX=n($7e,"A",{href:!0});var Wht=s(jX);Mrr=r(Wht,"MaskFormerForInstanceSegmentation"),Wht.forEach(t),Err=r($7e," (MaskFormer model)"),$7e.forEach(t),zht.forEach(t),Crr=i(Ta),g6=n(Ta,"P",{});var k7e=s(g6);wrr=r(k7e,"The model is set in evaluation mode by default using "),c_e=n(k7e,"CODE",{});var Hht=s(c_e);Arr=r(Hht,"model.eval()"),Hht.forEach(t),yrr=r(k7e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f_e=n(k7e,"CODE",{});var Uht=s(f_e);Lrr=r(Uht,"model.train()"),Uht.forEach(t),k7e.forEach(t),xrr=i(Ta),T(h6.$$.fragment,Ta),Ta.forEach(t),dl.forEach(t),FIe=i(f),Nd=n(f,"H2",{class:!0});var ANe=s(Nd);p6=n(ANe,"A",{id:!0,class:!0,href:!0});var Jht=s(p6);m_e=n(Jht,"SPAN",{});var Yht=s(m_e);T(Ay.$$.fragment,Yht),Yht.forEach(t),Jht.forEach(t),$rr=i(ANe),g_e=n(ANe,"SPAN",{});var Kht=s(g_e);krr=r(Kht,"TFAutoModel"),Kht.forEach(t),ANe.forEach(t),TIe=i(f),Yo=n(f,"DIV",{class:!0});var cl=s(Yo);T(yy.$$.fragment,cl),Srr=i(cl),jd=n(cl,"P",{});var VK=s(jd);Rrr=r(VK,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),DX=n(VK,"A",{href:!0});var Zht=s(DX);Brr=r(Zht,"from_pretrained()"),Zht.forEach(t),Prr=r(VK," class method or the "),GX=n(VK,"A",{href:!0});var ept=s(GX);Irr=r(ept,"from_config()"),ept.forEach(t),qrr=r(VK,` class
method.`),VK.forEach(t),Nrr=i(cl),Ly=n(cl,"P",{});var yNe=s(Ly);jrr=r(yNe,"This class cannot be instantiated directly using "),h_e=n(yNe,"CODE",{});var opt=s(h_e);Drr=r(opt,"__init__()"),opt.forEach(t),Grr=r(yNe," (throws an error)."),yNe.forEach(t),Orr=i(cl),wt=n(cl,"DIV",{class:!0});var O3=s(wt);T(xy.$$.fragment,O3),Vrr=i(O3),p_e=n(O3,"P",{});var rpt=s(p_e);Xrr=r(rpt,"Instantiates one of the base model classes of the library from a configuration."),rpt.forEach(t),zrr=i(O3),Dd=n(O3,"P",{});var XK=s(Dd);Qrr=r(XK,`Note:
Loading a model from its configuration file does `),u_e=n(XK,"STRONG",{});var tpt=s(u_e);Wrr=r(tpt,"not"),tpt.forEach(t),Hrr=r(XK,` load the model weights. It only affects the
model\u2019s configuration. Use `),OX=n(XK,"A",{href:!0});var apt=s(OX);Urr=r(apt,"from_pretrained()"),apt.forEach(t),Jrr=r(XK," to load the model weights."),XK.forEach(t),Yrr=i(O3),T(u6.$$.fragment,O3),O3.forEach(t),Krr=i(cl),wr=n(cl,"DIV",{class:!0});var fl=s(wr);T($y.$$.fragment,fl),Zrr=i(fl),__e=n(fl,"P",{});var npt=s(__e);etr=r(npt,"Instantiate one of the base model classes of the library from a pretrained model."),npt.forEach(t),otr=i(fl),Ka=n(fl,"P",{});var V3=s(Ka);rtr=r(V3,"The model class to instantiate is selected based on the "),b_e=n(V3,"CODE",{});var spt=s(b_e);ttr=r(spt,"model_type"),spt.forEach(t),atr=r(V3,` property of the config object (either
passed as an argument or loaded from `),v_e=n(V3,"CODE",{});var lpt=s(v_e);ntr=r(lpt,"pretrained_model_name_or_path"),lpt.forEach(t),str=r(V3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F_e=n(V3,"CODE",{});var ipt=s(F_e);ltr=r(ipt,"pretrained_model_name_or_path"),ipt.forEach(t),itr=r(V3,":"),V3.forEach(t),dtr=i(fl),N=n(fl,"UL",{});var D=s(N);_6=n(D,"LI",{});var S7e=s(_6);T_e=n(S7e,"STRONG",{});var dpt=s(T_e);ctr=r(dpt,"albert"),dpt.forEach(t),ftr=r(S7e," \u2014 "),VX=n(S7e,"A",{href:!0});var cpt=s(VX);mtr=r(cpt,"TFAlbertModel"),cpt.forEach(t),gtr=r(S7e," (ALBERT model)"),S7e.forEach(t),htr=i(D),b6=n(D,"LI",{});var R7e=s(b6);M_e=n(R7e,"STRONG",{});var fpt=s(M_e);ptr=r(fpt,"bart"),fpt.forEach(t),utr=r(R7e," \u2014 "),XX=n(R7e,"A",{href:!0});var mpt=s(XX);_tr=r(mpt,"TFBartModel"),mpt.forEach(t),btr=r(R7e," (BART model)"),R7e.forEach(t),vtr=i(D),v6=n(D,"LI",{});var B7e=s(v6);E_e=n(B7e,"STRONG",{});var gpt=s(E_e);Ftr=r(gpt,"bert"),gpt.forEach(t),Ttr=r(B7e," \u2014 "),zX=n(B7e,"A",{href:!0});var hpt=s(zX);Mtr=r(hpt,"TFBertModel"),hpt.forEach(t),Etr=r(B7e," (BERT model)"),B7e.forEach(t),Ctr=i(D),F6=n(D,"LI",{});var P7e=s(F6);C_e=n(P7e,"STRONG",{});var ppt=s(C_e);wtr=r(ppt,"blenderbot"),ppt.forEach(t),Atr=r(P7e," \u2014 "),QX=n(P7e,"A",{href:!0});var upt=s(QX);ytr=r(upt,"TFBlenderbotModel"),upt.forEach(t),Ltr=r(P7e," (Blenderbot model)"),P7e.forEach(t),xtr=i(D),T6=n(D,"LI",{});var I7e=s(T6);w_e=n(I7e,"STRONG",{});var _pt=s(w_e);$tr=r(_pt,"blenderbot-small"),_pt.forEach(t),ktr=r(I7e," \u2014 "),WX=n(I7e,"A",{href:!0});var bpt=s(WX);Str=r(bpt,"TFBlenderbotSmallModel"),bpt.forEach(t),Rtr=r(I7e," (BlenderbotSmall model)"),I7e.forEach(t),Btr=i(D),M6=n(D,"LI",{});var q7e=s(M6);A_e=n(q7e,"STRONG",{});var vpt=s(A_e);Ptr=r(vpt,"camembert"),vpt.forEach(t),Itr=r(q7e," \u2014 "),HX=n(q7e,"A",{href:!0});var Fpt=s(HX);qtr=r(Fpt,"TFCamembertModel"),Fpt.forEach(t),Ntr=r(q7e," (CamemBERT model)"),q7e.forEach(t),jtr=i(D),E6=n(D,"LI",{});var N7e=s(E6);y_e=n(N7e,"STRONG",{});var Tpt=s(y_e);Dtr=r(Tpt,"clip"),Tpt.forEach(t),Gtr=r(N7e," \u2014 "),UX=n(N7e,"A",{href:!0});var Mpt=s(UX);Otr=r(Mpt,"TFCLIPModel"),Mpt.forEach(t),Vtr=r(N7e," (CLIP model)"),N7e.forEach(t),Xtr=i(D),C6=n(D,"LI",{});var j7e=s(C6);L_e=n(j7e,"STRONG",{});var Ept=s(L_e);ztr=r(Ept,"convbert"),Ept.forEach(t),Qtr=r(j7e," \u2014 "),JX=n(j7e,"A",{href:!0});var Cpt=s(JX);Wtr=r(Cpt,"TFConvBertModel"),Cpt.forEach(t),Htr=r(j7e," (ConvBERT model)"),j7e.forEach(t),Utr=i(D),w6=n(D,"LI",{});var D7e=s(w6);x_e=n(D7e,"STRONG",{});var wpt=s(x_e);Jtr=r(wpt,"convnext"),wpt.forEach(t),Ytr=r(D7e," \u2014 "),YX=n(D7e,"A",{href:!0});var Apt=s(YX);Ktr=r(Apt,"TFConvNextModel"),Apt.forEach(t),Ztr=r(D7e," (ConvNext model)"),D7e.forEach(t),ear=i(D),A6=n(D,"LI",{});var G7e=s(A6);$_e=n(G7e,"STRONG",{});var ypt=s($_e);oar=r(ypt,"ctrl"),ypt.forEach(t),rar=r(G7e," \u2014 "),KX=n(G7e,"A",{href:!0});var Lpt=s(KX);tar=r(Lpt,"TFCTRLModel"),Lpt.forEach(t),aar=r(G7e," (CTRL model)"),G7e.forEach(t),nar=i(D),y6=n(D,"LI",{});var O7e=s(y6);k_e=n(O7e,"STRONG",{});var xpt=s(k_e);sar=r(xpt,"data2vec-vision"),xpt.forEach(t),lar=r(O7e," \u2014 "),ZX=n(O7e,"A",{href:!0});var $pt=s(ZX);iar=r($pt,"TFData2VecVisionModel"),$pt.forEach(t),dar=r(O7e," (Data2VecVision model)"),O7e.forEach(t),car=i(D),L6=n(D,"LI",{});var V7e=s(L6);S_e=n(V7e,"STRONG",{});var kpt=s(S_e);far=r(kpt,"deberta"),kpt.forEach(t),mar=r(V7e," \u2014 "),ez=n(V7e,"A",{href:!0});var Spt=s(ez);gar=r(Spt,"TFDebertaModel"),Spt.forEach(t),har=r(V7e," (DeBERTa model)"),V7e.forEach(t),par=i(D),x6=n(D,"LI",{});var X7e=s(x6);R_e=n(X7e,"STRONG",{});var Rpt=s(R_e);uar=r(Rpt,"deberta-v2"),Rpt.forEach(t),_ar=r(X7e," \u2014 "),oz=n(X7e,"A",{href:!0});var Bpt=s(oz);bar=r(Bpt,"TFDebertaV2Model"),Bpt.forEach(t),Far=r(X7e," (DeBERTa-v2 model)"),X7e.forEach(t),Tar=i(D),$6=n(D,"LI",{});var z7e=s($6);B_e=n(z7e,"STRONG",{});var Ppt=s(B_e);Mar=r(Ppt,"distilbert"),Ppt.forEach(t),Ear=r(z7e," \u2014 "),rz=n(z7e,"A",{href:!0});var Ipt=s(rz);Car=r(Ipt,"TFDistilBertModel"),Ipt.forEach(t),war=r(z7e," (DistilBERT model)"),z7e.forEach(t),Aar=i(D),k6=n(D,"LI",{});var Q7e=s(k6);P_e=n(Q7e,"STRONG",{});var qpt=s(P_e);yar=r(qpt,"dpr"),qpt.forEach(t),Lar=r(Q7e," \u2014 "),tz=n(Q7e,"A",{href:!0});var Npt=s(tz);xar=r(Npt,"TFDPRQuestionEncoder"),Npt.forEach(t),$ar=r(Q7e," (DPR model)"),Q7e.forEach(t),kar=i(D),S6=n(D,"LI",{});var W7e=s(S6);I_e=n(W7e,"STRONG",{});var jpt=s(I_e);Sar=r(jpt,"electra"),jpt.forEach(t),Rar=r(W7e," \u2014 "),az=n(W7e,"A",{href:!0});var Dpt=s(az);Bar=r(Dpt,"TFElectraModel"),Dpt.forEach(t),Par=r(W7e," (ELECTRA model)"),W7e.forEach(t),Iar=i(D),R6=n(D,"LI",{});var H7e=s(R6);q_e=n(H7e,"STRONG",{});var Gpt=s(q_e);qar=r(Gpt,"flaubert"),Gpt.forEach(t),Nar=r(H7e," \u2014 "),nz=n(H7e,"A",{href:!0});var Opt=s(nz);jar=r(Opt,"TFFlaubertModel"),Opt.forEach(t),Dar=r(H7e," (FlauBERT model)"),H7e.forEach(t),Gar=i(D),Ps=n(D,"LI",{});var l$=s(Ps);N_e=n(l$,"STRONG",{});var Vpt=s(N_e);Oar=r(Vpt,"funnel"),Vpt.forEach(t),Var=r(l$," \u2014 "),sz=n(l$,"A",{href:!0});var Xpt=s(sz);Xar=r(Xpt,"TFFunnelModel"),Xpt.forEach(t),zar=r(l$," or "),lz=n(l$,"A",{href:!0});var zpt=s(lz);Qar=r(zpt,"TFFunnelBaseModel"),zpt.forEach(t),War=r(l$," (Funnel Transformer model)"),l$.forEach(t),Har=i(D),B6=n(D,"LI",{});var U7e=s(B6);j_e=n(U7e,"STRONG",{});var Qpt=s(j_e);Uar=r(Qpt,"gpt2"),Qpt.forEach(t),Jar=r(U7e," \u2014 "),iz=n(U7e,"A",{href:!0});var Wpt=s(iz);Yar=r(Wpt,"TFGPT2Model"),Wpt.forEach(t),Kar=r(U7e," (OpenAI GPT-2 model)"),U7e.forEach(t),Zar=i(D),P6=n(D,"LI",{});var J7e=s(P6);D_e=n(J7e,"STRONG",{});var Hpt=s(D_e);enr=r(Hpt,"gptj"),Hpt.forEach(t),onr=r(J7e," \u2014 "),dz=n(J7e,"A",{href:!0});var Upt=s(dz);rnr=r(Upt,"TFGPTJModel"),Upt.forEach(t),tnr=r(J7e," (GPT-J model)"),J7e.forEach(t),anr=i(D),I6=n(D,"LI",{});var Y7e=s(I6);G_e=n(Y7e,"STRONG",{});var Jpt=s(G_e);nnr=r(Jpt,"hubert"),Jpt.forEach(t),snr=r(Y7e," \u2014 "),cz=n(Y7e,"A",{href:!0});var Ypt=s(cz);lnr=r(Ypt,"TFHubertModel"),Ypt.forEach(t),inr=r(Y7e," (Hubert model)"),Y7e.forEach(t),dnr=i(D),q6=n(D,"LI",{});var K7e=s(q6);O_e=n(K7e,"STRONG",{});var Kpt=s(O_e);cnr=r(Kpt,"layoutlm"),Kpt.forEach(t),fnr=r(K7e," \u2014 "),fz=n(K7e,"A",{href:!0});var Zpt=s(fz);mnr=r(Zpt,"TFLayoutLMModel"),Zpt.forEach(t),gnr=r(K7e," (LayoutLM model)"),K7e.forEach(t),hnr=i(D),N6=n(D,"LI",{});var Z7e=s(N6);V_e=n(Z7e,"STRONG",{});var eut=s(V_e);pnr=r(eut,"led"),eut.forEach(t),unr=r(Z7e," \u2014 "),mz=n(Z7e,"A",{href:!0});var out=s(mz);_nr=r(out,"TFLEDModel"),out.forEach(t),bnr=r(Z7e," (LED model)"),Z7e.forEach(t),vnr=i(D),j6=n(D,"LI",{});var e$e=s(j6);X_e=n(e$e,"STRONG",{});var rut=s(X_e);Fnr=r(rut,"longformer"),rut.forEach(t),Tnr=r(e$e," \u2014 "),gz=n(e$e,"A",{href:!0});var tut=s(gz);Mnr=r(tut,"TFLongformerModel"),tut.forEach(t),Enr=r(e$e," (Longformer model)"),e$e.forEach(t),Cnr=i(D),D6=n(D,"LI",{});var o$e=s(D6);z_e=n(o$e,"STRONG",{});var aut=s(z_e);wnr=r(aut,"lxmert"),aut.forEach(t),Anr=r(o$e," \u2014 "),hz=n(o$e,"A",{href:!0});var nut=s(hz);ynr=r(nut,"TFLxmertModel"),nut.forEach(t),Lnr=r(o$e," (LXMERT model)"),o$e.forEach(t),xnr=i(D),G6=n(D,"LI",{});var r$e=s(G6);Q_e=n(r$e,"STRONG",{});var sut=s(Q_e);$nr=r(sut,"marian"),sut.forEach(t),knr=r(r$e," \u2014 "),pz=n(r$e,"A",{href:!0});var lut=s(pz);Snr=r(lut,"TFMarianModel"),lut.forEach(t),Rnr=r(r$e," (Marian model)"),r$e.forEach(t),Bnr=i(D),O6=n(D,"LI",{});var t$e=s(O6);W_e=n(t$e,"STRONG",{});var iut=s(W_e);Pnr=r(iut,"mbart"),iut.forEach(t),Inr=r(t$e," \u2014 "),uz=n(t$e,"A",{href:!0});var dut=s(uz);qnr=r(dut,"TFMBartModel"),dut.forEach(t),Nnr=r(t$e," (mBART model)"),t$e.forEach(t),jnr=i(D),V6=n(D,"LI",{});var a$e=s(V6);H_e=n(a$e,"STRONG",{});var cut=s(H_e);Dnr=r(cut,"mobilebert"),cut.forEach(t),Gnr=r(a$e," \u2014 "),_z=n(a$e,"A",{href:!0});var fut=s(_z);Onr=r(fut,"TFMobileBertModel"),fut.forEach(t),Vnr=r(a$e," (MobileBERT model)"),a$e.forEach(t),Xnr=i(D),X6=n(D,"LI",{});var n$e=s(X6);U_e=n(n$e,"STRONG",{});var mut=s(U_e);znr=r(mut,"mpnet"),mut.forEach(t),Qnr=r(n$e," \u2014 "),bz=n(n$e,"A",{href:!0});var gut=s(bz);Wnr=r(gut,"TFMPNetModel"),gut.forEach(t),Hnr=r(n$e," (MPNet model)"),n$e.forEach(t),Unr=i(D),z6=n(D,"LI",{});var s$e=s(z6);J_e=n(s$e,"STRONG",{});var hut=s(J_e);Jnr=r(hut,"mt5"),hut.forEach(t),Ynr=r(s$e," \u2014 "),vz=n(s$e,"A",{href:!0});var put=s(vz);Knr=r(put,"TFMT5Model"),put.forEach(t),Znr=r(s$e," (mT5 model)"),s$e.forEach(t),esr=i(D),Q6=n(D,"LI",{});var l$e=s(Q6);Y_e=n(l$e,"STRONG",{});var uut=s(Y_e);osr=r(uut,"openai-gpt"),uut.forEach(t),rsr=r(l$e," \u2014 "),Fz=n(l$e,"A",{href:!0});var _ut=s(Fz);tsr=r(_ut,"TFOpenAIGPTModel"),_ut.forEach(t),asr=r(l$e," (OpenAI GPT model)"),l$e.forEach(t),nsr=i(D),W6=n(D,"LI",{});var i$e=s(W6);K_e=n(i$e,"STRONG",{});var but=s(K_e);ssr=r(but,"pegasus"),but.forEach(t),lsr=r(i$e," \u2014 "),Tz=n(i$e,"A",{href:!0});var vut=s(Tz);isr=r(vut,"TFPegasusModel"),vut.forEach(t),dsr=r(i$e," (Pegasus model)"),i$e.forEach(t),csr=i(D),H6=n(D,"LI",{});var d$e=s(H6);Z_e=n(d$e,"STRONG",{});var Fut=s(Z_e);fsr=r(Fut,"rembert"),Fut.forEach(t),msr=r(d$e," \u2014 "),Mz=n(d$e,"A",{href:!0});var Tut=s(Mz);gsr=r(Tut,"TFRemBertModel"),Tut.forEach(t),hsr=r(d$e," (RemBERT model)"),d$e.forEach(t),psr=i(D),U6=n(D,"LI",{});var c$e=s(U6);e1e=n(c$e,"STRONG",{});var Mut=s(e1e);usr=r(Mut,"roberta"),Mut.forEach(t),_sr=r(c$e," \u2014 "),Ez=n(c$e,"A",{href:!0});var Eut=s(Ez);bsr=r(Eut,"TFRobertaModel"),Eut.forEach(t),vsr=r(c$e," (RoBERTa model)"),c$e.forEach(t),Fsr=i(D),J6=n(D,"LI",{});var f$e=s(J6);o1e=n(f$e,"STRONG",{});var Cut=s(o1e);Tsr=r(Cut,"roformer"),Cut.forEach(t),Msr=r(f$e," \u2014 "),Cz=n(f$e,"A",{href:!0});var wut=s(Cz);Esr=r(wut,"TFRoFormerModel"),wut.forEach(t),Csr=r(f$e," (RoFormer model)"),f$e.forEach(t),wsr=i(D),Y6=n(D,"LI",{});var m$e=s(Y6);r1e=n(m$e,"STRONG",{});var Aut=s(r1e);Asr=r(Aut,"speech_to_text"),Aut.forEach(t),ysr=r(m$e," \u2014 "),wz=n(m$e,"A",{href:!0});var yut=s(wz);Lsr=r(yut,"TFSpeech2TextModel"),yut.forEach(t),xsr=r(m$e," (Speech2Text model)"),m$e.forEach(t),$sr=i(D),K6=n(D,"LI",{});var g$e=s(K6);t1e=n(g$e,"STRONG",{});var Lut=s(t1e);ksr=r(Lut,"swin"),Lut.forEach(t),Ssr=r(g$e," \u2014 "),Az=n(g$e,"A",{href:!0});var xut=s(Az);Rsr=r(xut,"TFSwinModel"),xut.forEach(t),Bsr=r(g$e," (Swin model)"),g$e.forEach(t),Psr=i(D),Z6=n(D,"LI",{});var h$e=s(Z6);a1e=n(h$e,"STRONG",{});var $ut=s(a1e);Isr=r($ut,"t5"),$ut.forEach(t),qsr=r(h$e," \u2014 "),yz=n(h$e,"A",{href:!0});var kut=s(yz);Nsr=r(kut,"TFT5Model"),kut.forEach(t),jsr=r(h$e," (T5 model)"),h$e.forEach(t),Dsr=i(D),eT=n(D,"LI",{});var p$e=s(eT);n1e=n(p$e,"STRONG",{});var Sut=s(n1e);Gsr=r(Sut,"tapas"),Sut.forEach(t),Osr=r(p$e," \u2014 "),Lz=n(p$e,"A",{href:!0});var Rut=s(Lz);Vsr=r(Rut,"TFTapasModel"),Rut.forEach(t),Xsr=r(p$e," (TAPAS model)"),p$e.forEach(t),zsr=i(D),oT=n(D,"LI",{});var u$e=s(oT);s1e=n(u$e,"STRONG",{});var But=s(s1e);Qsr=r(But,"transfo-xl"),But.forEach(t),Wsr=r(u$e," \u2014 "),xz=n(u$e,"A",{href:!0});var Put=s(xz);Hsr=r(Put,"TFTransfoXLModel"),Put.forEach(t),Usr=r(u$e," (Transformer-XL model)"),u$e.forEach(t),Jsr=i(D),rT=n(D,"LI",{});var _$e=s(rT);l1e=n(_$e,"STRONG",{});var Iut=s(l1e);Ysr=r(Iut,"vit"),Iut.forEach(t),Ksr=r(_$e," \u2014 "),$z=n(_$e,"A",{href:!0});var qut=s($z);Zsr=r(qut,"TFViTModel"),qut.forEach(t),elr=r(_$e," (ViT model)"),_$e.forEach(t),olr=i(D),tT=n(D,"LI",{});var b$e=s(tT);i1e=n(b$e,"STRONG",{});var Nut=s(i1e);rlr=r(Nut,"vit_mae"),Nut.forEach(t),tlr=r(b$e," \u2014 "),kz=n(b$e,"A",{href:!0});var jut=s(kz);alr=r(jut,"TFViTMAEModel"),jut.forEach(t),nlr=r(b$e," (ViTMAE model)"),b$e.forEach(t),slr=i(D),aT=n(D,"LI",{});var v$e=s(aT);d1e=n(v$e,"STRONG",{});var Dut=s(d1e);llr=r(Dut,"wav2vec2"),Dut.forEach(t),ilr=r(v$e," \u2014 "),Sz=n(v$e,"A",{href:!0});var Gut=s(Sz);dlr=r(Gut,"TFWav2Vec2Model"),Gut.forEach(t),clr=r(v$e," (Wav2Vec2 model)"),v$e.forEach(t),flr=i(D),nT=n(D,"LI",{});var F$e=s(nT);c1e=n(F$e,"STRONG",{});var Out=s(c1e);mlr=r(Out,"xlm"),Out.forEach(t),glr=r(F$e," \u2014 "),Rz=n(F$e,"A",{href:!0});var Vut=s(Rz);hlr=r(Vut,"TFXLMModel"),Vut.forEach(t),plr=r(F$e," (XLM model)"),F$e.forEach(t),ulr=i(D),sT=n(D,"LI",{});var T$e=s(sT);f1e=n(T$e,"STRONG",{});var Xut=s(f1e);_lr=r(Xut,"xlm-roberta"),Xut.forEach(t),blr=r(T$e," \u2014 "),Bz=n(T$e,"A",{href:!0});var zut=s(Bz);vlr=r(zut,"TFXLMRobertaModel"),zut.forEach(t),Flr=r(T$e," (XLM-RoBERTa model)"),T$e.forEach(t),Tlr=i(D),lT=n(D,"LI",{});var M$e=s(lT);m1e=n(M$e,"STRONG",{});var Qut=s(m1e);Mlr=r(Qut,"xlnet"),Qut.forEach(t),Elr=r(M$e," \u2014 "),Pz=n(M$e,"A",{href:!0});var Wut=s(Pz);Clr=r(Wut,"TFXLNetModel"),Wut.forEach(t),wlr=r(M$e," (XLNet model)"),M$e.forEach(t),D.forEach(t),Alr=i(fl),T(iT.$$.fragment,fl),fl.forEach(t),cl.forEach(t),MIe=i(f),Gd=n(f,"H2",{class:!0});var LNe=s(Gd);dT=n(LNe,"A",{id:!0,class:!0,href:!0});var Hut=s(dT);g1e=n(Hut,"SPAN",{});var Uut=s(g1e);T(ky.$$.fragment,Uut),Uut.forEach(t),Hut.forEach(t),ylr=i(LNe),h1e=n(LNe,"SPAN",{});var Jut=s(h1e);Llr=r(Jut,"TFAutoModelForPreTraining"),Jut.forEach(t),LNe.forEach(t),EIe=i(f),Ko=n(f,"DIV",{class:!0});var ml=s(Ko);T(Sy.$$.fragment,ml),xlr=i(ml),Od=n(ml,"P",{});var zK=s(Od);$lr=r(zK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Iz=n(zK,"A",{href:!0});var Yut=s(Iz);klr=r(Yut,"from_pretrained()"),Yut.forEach(t),Slr=r(zK," class method or the "),qz=n(zK,"A",{href:!0});var Kut=s(qz);Rlr=r(Kut,"from_config()"),Kut.forEach(t),Blr=r(zK,` class
method.`),zK.forEach(t),Plr=i(ml),Ry=n(ml,"P",{});var xNe=s(Ry);Ilr=r(xNe,"This class cannot be instantiated directly using "),p1e=n(xNe,"CODE",{});var Zut=s(p1e);qlr=r(Zut,"__init__()"),Zut.forEach(t),Nlr=r(xNe," (throws an error)."),xNe.forEach(t),jlr=i(ml),At=n(ml,"DIV",{class:!0});var X3=s(At);T(By.$$.fragment,X3),Dlr=i(X3),u1e=n(X3,"P",{});var e_t=s(u1e);Glr=r(e_t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),e_t.forEach(t),Olr=i(X3),Vd=n(X3,"P",{});var QK=s(Vd);Vlr=r(QK,`Note:
Loading a model from its configuration file does `),_1e=n(QK,"STRONG",{});var o_t=s(_1e);Xlr=r(o_t,"not"),o_t.forEach(t),zlr=r(QK,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nz=n(QK,"A",{href:!0});var r_t=s(Nz);Qlr=r(r_t,"from_pretrained()"),r_t.forEach(t),Wlr=r(QK," to load the model weights."),QK.forEach(t),Hlr=i(X3),T(cT.$$.fragment,X3),X3.forEach(t),Ulr=i(ml),Ar=n(ml,"DIV",{class:!0});var gl=s(Ar);T(Py.$$.fragment,gl),Jlr=i(gl),b1e=n(gl,"P",{});var t_t=s(b1e);Ylr=r(t_t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),t_t.forEach(t),Klr=i(gl),Za=n(gl,"P",{});var z3=s(Za);Zlr=r(z3,"The model class to instantiate is selected based on the "),v1e=n(z3,"CODE",{});var a_t=s(v1e);eir=r(a_t,"model_type"),a_t.forEach(t),oir=r(z3,` property of the config object (either
passed as an argument or loaded from `),F1e=n(z3,"CODE",{});var n_t=s(F1e);rir=r(n_t,"pretrained_model_name_or_path"),n_t.forEach(t),tir=r(z3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T1e=n(z3,"CODE",{});var s_t=s(T1e);air=r(s_t,"pretrained_model_name_or_path"),s_t.forEach(t),nir=r(z3,":"),z3.forEach(t),sir=i(gl),ne=n(gl,"UL",{});var le=s(ne);fT=n(le,"LI",{});var E$e=s(fT);M1e=n(E$e,"STRONG",{});var l_t=s(M1e);lir=r(l_t,"albert"),l_t.forEach(t),iir=r(E$e," \u2014 "),jz=n(E$e,"A",{href:!0});var i_t=s(jz);dir=r(i_t,"TFAlbertForPreTraining"),i_t.forEach(t),cir=r(E$e," (ALBERT model)"),E$e.forEach(t),fir=i(le),mT=n(le,"LI",{});var C$e=s(mT);E1e=n(C$e,"STRONG",{});var d_t=s(E1e);mir=r(d_t,"bart"),d_t.forEach(t),gir=r(C$e," \u2014 "),Dz=n(C$e,"A",{href:!0});var c_t=s(Dz);hir=r(c_t,"TFBartForConditionalGeneration"),c_t.forEach(t),pir=r(C$e," (BART model)"),C$e.forEach(t),uir=i(le),gT=n(le,"LI",{});var w$e=s(gT);C1e=n(w$e,"STRONG",{});var f_t=s(C1e);_ir=r(f_t,"bert"),f_t.forEach(t),bir=r(w$e," \u2014 "),Gz=n(w$e,"A",{href:!0});var m_t=s(Gz);vir=r(m_t,"TFBertForPreTraining"),m_t.forEach(t),Fir=r(w$e," (BERT model)"),w$e.forEach(t),Tir=i(le),hT=n(le,"LI",{});var A$e=s(hT);w1e=n(A$e,"STRONG",{});var g_t=s(w1e);Mir=r(g_t,"camembert"),g_t.forEach(t),Eir=r(A$e," \u2014 "),Oz=n(A$e,"A",{href:!0});var h_t=s(Oz);Cir=r(h_t,"TFCamembertForMaskedLM"),h_t.forEach(t),wir=r(A$e," (CamemBERT model)"),A$e.forEach(t),Air=i(le),pT=n(le,"LI",{});var y$e=s(pT);A1e=n(y$e,"STRONG",{});var p_t=s(A1e);yir=r(p_t,"ctrl"),p_t.forEach(t),Lir=r(y$e," \u2014 "),Vz=n(y$e,"A",{href:!0});var u_t=s(Vz);xir=r(u_t,"TFCTRLLMHeadModel"),u_t.forEach(t),$ir=r(y$e," (CTRL model)"),y$e.forEach(t),kir=i(le),uT=n(le,"LI",{});var L$e=s(uT);y1e=n(L$e,"STRONG",{});var __t=s(y1e);Sir=r(__t,"distilbert"),__t.forEach(t),Rir=r(L$e," \u2014 "),Xz=n(L$e,"A",{href:!0});var b_t=s(Xz);Bir=r(b_t,"TFDistilBertForMaskedLM"),b_t.forEach(t),Pir=r(L$e," (DistilBERT model)"),L$e.forEach(t),Iir=i(le),_T=n(le,"LI",{});var x$e=s(_T);L1e=n(x$e,"STRONG",{});var v_t=s(L1e);qir=r(v_t,"electra"),v_t.forEach(t),Nir=r(x$e," \u2014 "),zz=n(x$e,"A",{href:!0});var F_t=s(zz);jir=r(F_t,"TFElectraForPreTraining"),F_t.forEach(t),Dir=r(x$e," (ELECTRA model)"),x$e.forEach(t),Gir=i(le),bT=n(le,"LI",{});var $$e=s(bT);x1e=n($$e,"STRONG",{});var T_t=s(x1e);Oir=r(T_t,"flaubert"),T_t.forEach(t),Vir=r($$e," \u2014 "),Qz=n($$e,"A",{href:!0});var M_t=s(Qz);Xir=r(M_t,"TFFlaubertWithLMHeadModel"),M_t.forEach(t),zir=r($$e," (FlauBERT model)"),$$e.forEach(t),Qir=i(le),vT=n(le,"LI",{});var k$e=s(vT);$1e=n(k$e,"STRONG",{});var E_t=s($1e);Wir=r(E_t,"funnel"),E_t.forEach(t),Hir=r(k$e," \u2014 "),Wz=n(k$e,"A",{href:!0});var C_t=s(Wz);Uir=r(C_t,"TFFunnelForPreTraining"),C_t.forEach(t),Jir=r(k$e," (Funnel Transformer model)"),k$e.forEach(t),Yir=i(le),FT=n(le,"LI",{});var S$e=s(FT);k1e=n(S$e,"STRONG",{});var w_t=s(k1e);Kir=r(w_t,"gpt2"),w_t.forEach(t),Zir=r(S$e," \u2014 "),Hz=n(S$e,"A",{href:!0});var A_t=s(Hz);edr=r(A_t,"TFGPT2LMHeadModel"),A_t.forEach(t),odr=r(S$e," (OpenAI GPT-2 model)"),S$e.forEach(t),rdr=i(le),TT=n(le,"LI",{});var R$e=s(TT);S1e=n(R$e,"STRONG",{});var y_t=s(S1e);tdr=r(y_t,"layoutlm"),y_t.forEach(t),adr=r(R$e," \u2014 "),Uz=n(R$e,"A",{href:!0});var L_t=s(Uz);ndr=r(L_t,"TFLayoutLMForMaskedLM"),L_t.forEach(t),sdr=r(R$e," (LayoutLM model)"),R$e.forEach(t),ldr=i(le),MT=n(le,"LI",{});var B$e=s(MT);R1e=n(B$e,"STRONG",{});var x_t=s(R1e);idr=r(x_t,"lxmert"),x_t.forEach(t),ddr=r(B$e," \u2014 "),Jz=n(B$e,"A",{href:!0});var $_t=s(Jz);cdr=r($_t,"TFLxmertForPreTraining"),$_t.forEach(t),fdr=r(B$e," (LXMERT model)"),B$e.forEach(t),mdr=i(le),ET=n(le,"LI",{});var P$e=s(ET);B1e=n(P$e,"STRONG",{});var k_t=s(B1e);gdr=r(k_t,"mobilebert"),k_t.forEach(t),hdr=r(P$e," \u2014 "),Yz=n(P$e,"A",{href:!0});var S_t=s(Yz);pdr=r(S_t,"TFMobileBertForPreTraining"),S_t.forEach(t),udr=r(P$e," (MobileBERT model)"),P$e.forEach(t),_dr=i(le),CT=n(le,"LI",{});var I$e=s(CT);P1e=n(I$e,"STRONG",{});var R_t=s(P1e);bdr=r(R_t,"mpnet"),R_t.forEach(t),vdr=r(I$e," \u2014 "),Kz=n(I$e,"A",{href:!0});var B_t=s(Kz);Fdr=r(B_t,"TFMPNetForMaskedLM"),B_t.forEach(t),Tdr=r(I$e," (MPNet model)"),I$e.forEach(t),Mdr=i(le),wT=n(le,"LI",{});var q$e=s(wT);I1e=n(q$e,"STRONG",{});var P_t=s(I1e);Edr=r(P_t,"openai-gpt"),P_t.forEach(t),Cdr=r(q$e," \u2014 "),Zz=n(q$e,"A",{href:!0});var I_t=s(Zz);wdr=r(I_t,"TFOpenAIGPTLMHeadModel"),I_t.forEach(t),Adr=r(q$e," (OpenAI GPT model)"),q$e.forEach(t),ydr=i(le),AT=n(le,"LI",{});var N$e=s(AT);q1e=n(N$e,"STRONG",{});var q_t=s(q1e);Ldr=r(q_t,"roberta"),q_t.forEach(t),xdr=r(N$e," \u2014 "),eQ=n(N$e,"A",{href:!0});var N_t=s(eQ);$dr=r(N_t,"TFRobertaForMaskedLM"),N_t.forEach(t),kdr=r(N$e," (RoBERTa model)"),N$e.forEach(t),Sdr=i(le),yT=n(le,"LI",{});var j$e=s(yT);N1e=n(j$e,"STRONG",{});var j_t=s(N1e);Rdr=r(j_t,"t5"),j_t.forEach(t),Bdr=r(j$e," \u2014 "),oQ=n(j$e,"A",{href:!0});var D_t=s(oQ);Pdr=r(D_t,"TFT5ForConditionalGeneration"),D_t.forEach(t),Idr=r(j$e," (T5 model)"),j$e.forEach(t),qdr=i(le),LT=n(le,"LI",{});var D$e=s(LT);j1e=n(D$e,"STRONG",{});var G_t=s(j1e);Ndr=r(G_t,"tapas"),G_t.forEach(t),jdr=r(D$e," \u2014 "),rQ=n(D$e,"A",{href:!0});var O_t=s(rQ);Ddr=r(O_t,"TFTapasForMaskedLM"),O_t.forEach(t),Gdr=r(D$e," (TAPAS model)"),D$e.forEach(t),Odr=i(le),xT=n(le,"LI",{});var G$e=s(xT);D1e=n(G$e,"STRONG",{});var V_t=s(D1e);Vdr=r(V_t,"transfo-xl"),V_t.forEach(t),Xdr=r(G$e," \u2014 "),tQ=n(G$e,"A",{href:!0});var X_t=s(tQ);zdr=r(X_t,"TFTransfoXLLMHeadModel"),X_t.forEach(t),Qdr=r(G$e," (Transformer-XL model)"),G$e.forEach(t),Wdr=i(le),$T=n(le,"LI",{});var O$e=s($T);G1e=n(O$e,"STRONG",{});var z_t=s(G1e);Hdr=r(z_t,"vit_mae"),z_t.forEach(t),Udr=r(O$e," \u2014 "),aQ=n(O$e,"A",{href:!0});var Q_t=s(aQ);Jdr=r(Q_t,"TFViTMAEForPreTraining"),Q_t.forEach(t),Ydr=r(O$e," (ViTMAE model)"),O$e.forEach(t),Kdr=i(le),kT=n(le,"LI",{});var V$e=s(kT);O1e=n(V$e,"STRONG",{});var W_t=s(O1e);Zdr=r(W_t,"xlm"),W_t.forEach(t),ecr=r(V$e," \u2014 "),nQ=n(V$e,"A",{href:!0});var H_t=s(nQ);ocr=r(H_t,"TFXLMWithLMHeadModel"),H_t.forEach(t),rcr=r(V$e," (XLM model)"),V$e.forEach(t),tcr=i(le),ST=n(le,"LI",{});var X$e=s(ST);V1e=n(X$e,"STRONG",{});var U_t=s(V1e);acr=r(U_t,"xlm-roberta"),U_t.forEach(t),ncr=r(X$e," \u2014 "),sQ=n(X$e,"A",{href:!0});var J_t=s(sQ);scr=r(J_t,"TFXLMRobertaForMaskedLM"),J_t.forEach(t),lcr=r(X$e," (XLM-RoBERTa model)"),X$e.forEach(t),icr=i(le),RT=n(le,"LI",{});var z$e=s(RT);X1e=n(z$e,"STRONG",{});var Y_t=s(X1e);dcr=r(Y_t,"xlnet"),Y_t.forEach(t),ccr=r(z$e," \u2014 "),lQ=n(z$e,"A",{href:!0});var K_t=s(lQ);fcr=r(K_t,"TFXLNetLMHeadModel"),K_t.forEach(t),mcr=r(z$e," (XLNet model)"),z$e.forEach(t),le.forEach(t),gcr=i(gl),T(BT.$$.fragment,gl),gl.forEach(t),ml.forEach(t),CIe=i(f),Xd=n(f,"H2",{class:!0});var $Ne=s(Xd);PT=n($Ne,"A",{id:!0,class:!0,href:!0});var Z_t=s(PT);z1e=n(Z_t,"SPAN",{});var e1t=s(z1e);T(Iy.$$.fragment,e1t),e1t.forEach(t),Z_t.forEach(t),hcr=i($Ne),Q1e=n($Ne,"SPAN",{});var o1t=s(Q1e);pcr=r(o1t,"TFAutoModelForCausalLM"),o1t.forEach(t),$Ne.forEach(t),wIe=i(f),Zo=n(f,"DIV",{class:!0});var hl=s(Zo);T(qy.$$.fragment,hl),ucr=i(hl),zd=n(hl,"P",{});var WK=s(zd);_cr=r(WK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),iQ=n(WK,"A",{href:!0});var r1t=s(iQ);bcr=r(r1t,"from_pretrained()"),r1t.forEach(t),vcr=r(WK," class method or the "),dQ=n(WK,"A",{href:!0});var t1t=s(dQ);Fcr=r(t1t,"from_config()"),t1t.forEach(t),Tcr=r(WK,` class
method.`),WK.forEach(t),Mcr=i(hl),Ny=n(hl,"P",{});var kNe=s(Ny);Ecr=r(kNe,"This class cannot be instantiated directly using "),W1e=n(kNe,"CODE",{});var a1t=s(W1e);Ccr=r(a1t,"__init__()"),a1t.forEach(t),wcr=r(kNe," (throws an error)."),kNe.forEach(t),Acr=i(hl),yt=n(hl,"DIV",{class:!0});var Q3=s(yt);T(jy.$$.fragment,Q3),ycr=i(Q3),H1e=n(Q3,"P",{});var n1t=s(H1e);Lcr=r(n1t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),n1t.forEach(t),xcr=i(Q3),Qd=n(Q3,"P",{});var HK=s(Qd);$cr=r(HK,`Note:
Loading a model from its configuration file does `),U1e=n(HK,"STRONG",{});var s1t=s(U1e);kcr=r(s1t,"not"),s1t.forEach(t),Scr=r(HK,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(HK,"A",{href:!0});var l1t=s(cQ);Rcr=r(l1t,"from_pretrained()"),l1t.forEach(t),Bcr=r(HK," to load the model weights."),HK.forEach(t),Pcr=i(Q3),T(IT.$$.fragment,Q3),Q3.forEach(t),Icr=i(hl),yr=n(hl,"DIV",{class:!0});var pl=s(yr);T(Dy.$$.fragment,pl),qcr=i(pl),J1e=n(pl,"P",{});var i1t=s(J1e);Ncr=r(i1t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),i1t.forEach(t),jcr=i(pl),en=n(pl,"P",{});var W3=s(en);Dcr=r(W3,"The model class to instantiate is selected based on the "),Y1e=n(W3,"CODE",{});var d1t=s(Y1e);Gcr=r(d1t,"model_type"),d1t.forEach(t),Ocr=r(W3,` property of the config object (either
passed as an argument or loaded from `),K1e=n(W3,"CODE",{});var c1t=s(K1e);Vcr=r(c1t,"pretrained_model_name_or_path"),c1t.forEach(t),Xcr=r(W3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=n(W3,"CODE",{});var f1t=s(Z1e);zcr=r(f1t,"pretrained_model_name_or_path"),f1t.forEach(t),Qcr=r(W3,":"),W3.forEach(t),Wcr=i(pl),Te=n(pl,"UL",{});var Ce=s(Te);qT=n(Ce,"LI",{});var Q$e=s(qT);e8e=n(Q$e,"STRONG",{});var m1t=s(e8e);Hcr=r(m1t,"bert"),m1t.forEach(t),Ucr=r(Q$e," \u2014 "),fQ=n(Q$e,"A",{href:!0});var g1t=s(fQ);Jcr=r(g1t,"TFBertLMHeadModel"),g1t.forEach(t),Ycr=r(Q$e," (BERT model)"),Q$e.forEach(t),Kcr=i(Ce),NT=n(Ce,"LI",{});var W$e=s(NT);o8e=n(W$e,"STRONG",{});var h1t=s(o8e);Zcr=r(h1t,"camembert"),h1t.forEach(t),efr=r(W$e," \u2014 "),mQ=n(W$e,"A",{href:!0});var p1t=s(mQ);ofr=r(p1t,"TFCamembertForCausalLM"),p1t.forEach(t),rfr=r(W$e," (CamemBERT model)"),W$e.forEach(t),tfr=i(Ce),jT=n(Ce,"LI",{});var H$e=s(jT);r8e=n(H$e,"STRONG",{});var u1t=s(r8e);afr=r(u1t,"ctrl"),u1t.forEach(t),nfr=r(H$e," \u2014 "),gQ=n(H$e,"A",{href:!0});var _1t=s(gQ);sfr=r(_1t,"TFCTRLLMHeadModel"),_1t.forEach(t),lfr=r(H$e," (CTRL model)"),H$e.forEach(t),ifr=i(Ce),DT=n(Ce,"LI",{});var U$e=s(DT);t8e=n(U$e,"STRONG",{});var b1t=s(t8e);dfr=r(b1t,"gpt2"),b1t.forEach(t),cfr=r(U$e," \u2014 "),hQ=n(U$e,"A",{href:!0});var v1t=s(hQ);ffr=r(v1t,"TFGPT2LMHeadModel"),v1t.forEach(t),mfr=r(U$e," (OpenAI GPT-2 model)"),U$e.forEach(t),gfr=i(Ce),GT=n(Ce,"LI",{});var J$e=s(GT);a8e=n(J$e,"STRONG",{});var F1t=s(a8e);hfr=r(F1t,"gptj"),F1t.forEach(t),pfr=r(J$e," \u2014 "),pQ=n(J$e,"A",{href:!0});var T1t=s(pQ);ufr=r(T1t,"TFGPTJForCausalLM"),T1t.forEach(t),_fr=r(J$e," (GPT-J model)"),J$e.forEach(t),bfr=i(Ce),OT=n(Ce,"LI",{});var Y$e=s(OT);n8e=n(Y$e,"STRONG",{});var M1t=s(n8e);vfr=r(M1t,"openai-gpt"),M1t.forEach(t),Ffr=r(Y$e," \u2014 "),uQ=n(Y$e,"A",{href:!0});var E1t=s(uQ);Tfr=r(E1t,"TFOpenAIGPTLMHeadModel"),E1t.forEach(t),Mfr=r(Y$e," (OpenAI GPT model)"),Y$e.forEach(t),Efr=i(Ce),VT=n(Ce,"LI",{});var K$e=s(VT);s8e=n(K$e,"STRONG",{});var C1t=s(s8e);Cfr=r(C1t,"rembert"),C1t.forEach(t),wfr=r(K$e," \u2014 "),_Q=n(K$e,"A",{href:!0});var w1t=s(_Q);Afr=r(w1t,"TFRemBertForCausalLM"),w1t.forEach(t),yfr=r(K$e," (RemBERT model)"),K$e.forEach(t),Lfr=i(Ce),XT=n(Ce,"LI",{});var Z$e=s(XT);l8e=n(Z$e,"STRONG",{});var A1t=s(l8e);xfr=r(A1t,"roberta"),A1t.forEach(t),$fr=r(Z$e," \u2014 "),bQ=n(Z$e,"A",{href:!0});var y1t=s(bQ);kfr=r(y1t,"TFRobertaForCausalLM"),y1t.forEach(t),Sfr=r(Z$e," (RoBERTa model)"),Z$e.forEach(t),Rfr=i(Ce),zT=n(Ce,"LI",{});var eke=s(zT);i8e=n(eke,"STRONG",{});var L1t=s(i8e);Bfr=r(L1t,"roformer"),L1t.forEach(t),Pfr=r(eke," \u2014 "),vQ=n(eke,"A",{href:!0});var x1t=s(vQ);Ifr=r(x1t,"TFRoFormerForCausalLM"),x1t.forEach(t),qfr=r(eke," (RoFormer model)"),eke.forEach(t),Nfr=i(Ce),QT=n(Ce,"LI",{});var oke=s(QT);d8e=n(oke,"STRONG",{});var $1t=s(d8e);jfr=r($1t,"transfo-xl"),$1t.forEach(t),Dfr=r(oke," \u2014 "),FQ=n(oke,"A",{href:!0});var k1t=s(FQ);Gfr=r(k1t,"TFTransfoXLLMHeadModel"),k1t.forEach(t),Ofr=r(oke," (Transformer-XL model)"),oke.forEach(t),Vfr=i(Ce),WT=n(Ce,"LI",{});var rke=s(WT);c8e=n(rke,"STRONG",{});var S1t=s(c8e);Xfr=r(S1t,"xlm"),S1t.forEach(t),zfr=r(rke," \u2014 "),TQ=n(rke,"A",{href:!0});var R1t=s(TQ);Qfr=r(R1t,"TFXLMWithLMHeadModel"),R1t.forEach(t),Wfr=r(rke," (XLM model)"),rke.forEach(t),Hfr=i(Ce),HT=n(Ce,"LI",{});var tke=s(HT);f8e=n(tke,"STRONG",{});var B1t=s(f8e);Ufr=r(B1t,"xlnet"),B1t.forEach(t),Jfr=r(tke," \u2014 "),MQ=n(tke,"A",{href:!0});var P1t=s(MQ);Yfr=r(P1t,"TFXLNetLMHeadModel"),P1t.forEach(t),Kfr=r(tke," (XLNet model)"),tke.forEach(t),Ce.forEach(t),Zfr=i(pl),T(UT.$$.fragment,pl),pl.forEach(t),hl.forEach(t),AIe=i(f),Wd=n(f,"H2",{class:!0});var SNe=s(Wd);JT=n(SNe,"A",{id:!0,class:!0,href:!0});var I1t=s(JT);m8e=n(I1t,"SPAN",{});var q1t=s(m8e);T(Gy.$$.fragment,q1t),q1t.forEach(t),I1t.forEach(t),emr=i(SNe),g8e=n(SNe,"SPAN",{});var N1t=s(g8e);omr=r(N1t,"TFAutoModelForImageClassification"),N1t.forEach(t),SNe.forEach(t),yIe=i(f),er=n(f,"DIV",{class:!0});var ul=s(er);T(Oy.$$.fragment,ul),rmr=i(ul),Hd=n(ul,"P",{});var UK=s(Hd);tmr=r(UK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),EQ=n(UK,"A",{href:!0});var j1t=s(EQ);amr=r(j1t,"from_pretrained()"),j1t.forEach(t),nmr=r(UK," class method or the "),CQ=n(UK,"A",{href:!0});var D1t=s(CQ);smr=r(D1t,"from_config()"),D1t.forEach(t),lmr=r(UK,` class
method.`),UK.forEach(t),imr=i(ul),Vy=n(ul,"P",{});var RNe=s(Vy);dmr=r(RNe,"This class cannot be instantiated directly using "),h8e=n(RNe,"CODE",{});var G1t=s(h8e);cmr=r(G1t,"__init__()"),G1t.forEach(t),fmr=r(RNe," (throws an error)."),RNe.forEach(t),mmr=i(ul),Lt=n(ul,"DIV",{class:!0});var H3=s(Lt);T(Xy.$$.fragment,H3),gmr=i(H3),p8e=n(H3,"P",{});var O1t=s(p8e);hmr=r(O1t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),O1t.forEach(t),pmr=i(H3),Ud=n(H3,"P",{});var JK=s(Ud);umr=r(JK,`Note:
Loading a model from its configuration file does `),u8e=n(JK,"STRONG",{});var V1t=s(u8e);_mr=r(V1t,"not"),V1t.forEach(t),bmr=r(JK,` load the model weights. It only affects the
model\u2019s configuration. Use `),wQ=n(JK,"A",{href:!0});var X1t=s(wQ);vmr=r(X1t,"from_pretrained()"),X1t.forEach(t),Fmr=r(JK," to load the model weights."),JK.forEach(t),Tmr=i(H3),T(YT.$$.fragment,H3),H3.forEach(t),Mmr=i(ul),Lr=n(ul,"DIV",{class:!0});var _l=s(Lr);T(zy.$$.fragment,_l),Emr=i(_l),_8e=n(_l,"P",{});var z1t=s(_8e);Cmr=r(z1t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),z1t.forEach(t),wmr=i(_l),on=n(_l,"P",{});var U3=s(on);Amr=r(U3,"The model class to instantiate is selected based on the "),b8e=n(U3,"CODE",{});var Q1t=s(b8e);ymr=r(Q1t,"model_type"),Q1t.forEach(t),Lmr=r(U3,` property of the config object (either
passed as an argument or loaded from `),v8e=n(U3,"CODE",{});var W1t=s(v8e);xmr=r(W1t,"pretrained_model_name_or_path"),W1t.forEach(t),$mr=r(U3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=n(U3,"CODE",{});var H1t=s(F8e);kmr=r(H1t,"pretrained_model_name_or_path"),H1t.forEach(t),Smr=r(U3,":"),U3.forEach(t),Rmr=i(_l),rn=n(_l,"UL",{});var J3=s(rn);KT=n(J3,"LI",{});var ake=s(KT);T8e=n(ake,"STRONG",{});var U1t=s(T8e);Bmr=r(U1t,"convnext"),U1t.forEach(t),Pmr=r(ake," \u2014 "),AQ=n(ake,"A",{href:!0});var J1t=s(AQ);Imr=r(J1t,"TFConvNextForImageClassification"),J1t.forEach(t),qmr=r(ake," (ConvNext model)"),ake.forEach(t),Nmr=i(J3),ZT=n(J3,"LI",{});var nke=s(ZT);M8e=n(nke,"STRONG",{});var Y1t=s(M8e);jmr=r(Y1t,"data2vec-vision"),Y1t.forEach(t),Dmr=r(nke," \u2014 "),yQ=n(nke,"A",{href:!0});var K1t=s(yQ);Gmr=r(K1t,"TFData2VecVisionForImageClassification"),K1t.forEach(t),Omr=r(nke," (Data2VecVision model)"),nke.forEach(t),Vmr=i(J3),e9=n(J3,"LI",{});var ske=s(e9);E8e=n(ske,"STRONG",{});var Z1t=s(E8e);Xmr=r(Z1t,"swin"),Z1t.forEach(t),zmr=r(ske," \u2014 "),LQ=n(ske,"A",{href:!0});var e8t=s(LQ);Qmr=r(e8t,"TFSwinForImageClassification"),e8t.forEach(t),Wmr=r(ske," (Swin model)"),ske.forEach(t),Hmr=i(J3),o9=n(J3,"LI",{});var lke=s(o9);C8e=n(lke,"STRONG",{});var o8t=s(C8e);Umr=r(o8t,"vit"),o8t.forEach(t),Jmr=r(lke," \u2014 "),xQ=n(lke,"A",{href:!0});var r8t=s(xQ);Ymr=r(r8t,"TFViTForImageClassification"),r8t.forEach(t),Kmr=r(lke," (ViT model)"),lke.forEach(t),J3.forEach(t),Zmr=i(_l),T(r9.$$.fragment,_l),_l.forEach(t),ul.forEach(t),LIe=i(f),Jd=n(f,"H2",{class:!0});var BNe=s(Jd);t9=n(BNe,"A",{id:!0,class:!0,href:!0});var t8t=s(t9);w8e=n(t8t,"SPAN",{});var a8t=s(w8e);T(Qy.$$.fragment,a8t),a8t.forEach(t),t8t.forEach(t),egr=i(BNe),A8e=n(BNe,"SPAN",{});var n8t=s(A8e);ogr=r(n8t,"TFAutoModelForMaskedLM"),n8t.forEach(t),BNe.forEach(t),xIe=i(f),or=n(f,"DIV",{class:!0});var bl=s(or);T(Wy.$$.fragment,bl),rgr=i(bl),Yd=n(bl,"P",{});var YK=s(Yd);tgr=r(YK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),$Q=n(YK,"A",{href:!0});var s8t=s($Q);agr=r(s8t,"from_pretrained()"),s8t.forEach(t),ngr=r(YK," class method or the "),kQ=n(YK,"A",{href:!0});var l8t=s(kQ);sgr=r(l8t,"from_config()"),l8t.forEach(t),lgr=r(YK,` class
method.`),YK.forEach(t),igr=i(bl),Hy=n(bl,"P",{});var PNe=s(Hy);dgr=r(PNe,"This class cannot be instantiated directly using "),y8e=n(PNe,"CODE",{});var i8t=s(y8e);cgr=r(i8t,"__init__()"),i8t.forEach(t),fgr=r(PNe," (throws an error)."),PNe.forEach(t),mgr=i(bl),xt=n(bl,"DIV",{class:!0});var Y3=s(xt);T(Uy.$$.fragment,Y3),ggr=i(Y3),L8e=n(Y3,"P",{});var d8t=s(L8e);hgr=r(d8t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),d8t.forEach(t),pgr=i(Y3),Kd=n(Y3,"P",{});var KK=s(Kd);ugr=r(KK,`Note:
Loading a model from its configuration file does `),x8e=n(KK,"STRONG",{});var c8t=s(x8e);_gr=r(c8t,"not"),c8t.forEach(t),bgr=r(KK,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(KK,"A",{href:!0});var f8t=s(SQ);vgr=r(f8t,"from_pretrained()"),f8t.forEach(t),Fgr=r(KK," to load the model weights."),KK.forEach(t),Tgr=i(Y3),T(a9.$$.fragment,Y3),Y3.forEach(t),Mgr=i(bl),xr=n(bl,"DIV",{class:!0});var vl=s(xr);T(Jy.$$.fragment,vl),Egr=i(vl),$8e=n(vl,"P",{});var m8t=s($8e);Cgr=r(m8t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),m8t.forEach(t),wgr=i(vl),tn=n(vl,"P",{});var K3=s(tn);Agr=r(K3,"The model class to instantiate is selected based on the "),k8e=n(K3,"CODE",{});var g8t=s(k8e);ygr=r(g8t,"model_type"),g8t.forEach(t),Lgr=r(K3,` property of the config object (either
passed as an argument or loaded from `),S8e=n(K3,"CODE",{});var h8t=s(S8e);xgr=r(h8t,"pretrained_model_name_or_path"),h8t.forEach(t),$gr=r(K3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R8e=n(K3,"CODE",{});var p8t=s(R8e);kgr=r(p8t,"pretrained_model_name_or_path"),p8t.forEach(t),Sgr=r(K3,":"),K3.forEach(t),Rgr=i(vl),ie=n(vl,"UL",{});var fe=s(ie);n9=n(fe,"LI",{});var ike=s(n9);B8e=n(ike,"STRONG",{});var u8t=s(B8e);Bgr=r(u8t,"albert"),u8t.forEach(t),Pgr=r(ike," \u2014 "),RQ=n(ike,"A",{href:!0});var _8t=s(RQ);Igr=r(_8t,"TFAlbertForMaskedLM"),_8t.forEach(t),qgr=r(ike," (ALBERT model)"),ike.forEach(t),Ngr=i(fe),s9=n(fe,"LI",{});var dke=s(s9);P8e=n(dke,"STRONG",{});var b8t=s(P8e);jgr=r(b8t,"bert"),b8t.forEach(t),Dgr=r(dke," \u2014 "),BQ=n(dke,"A",{href:!0});var v8t=s(BQ);Ggr=r(v8t,"TFBertForMaskedLM"),v8t.forEach(t),Ogr=r(dke," (BERT model)"),dke.forEach(t),Vgr=i(fe),l9=n(fe,"LI",{});var cke=s(l9);I8e=n(cke,"STRONG",{});var F8t=s(I8e);Xgr=r(F8t,"camembert"),F8t.forEach(t),zgr=r(cke," \u2014 "),PQ=n(cke,"A",{href:!0});var T8t=s(PQ);Qgr=r(T8t,"TFCamembertForMaskedLM"),T8t.forEach(t),Wgr=r(cke," (CamemBERT model)"),cke.forEach(t),Hgr=i(fe),i9=n(fe,"LI",{});var fke=s(i9);q8e=n(fke,"STRONG",{});var M8t=s(q8e);Ugr=r(M8t,"convbert"),M8t.forEach(t),Jgr=r(fke," \u2014 "),IQ=n(fke,"A",{href:!0});var E8t=s(IQ);Ygr=r(E8t,"TFConvBertForMaskedLM"),E8t.forEach(t),Kgr=r(fke," (ConvBERT model)"),fke.forEach(t),Zgr=i(fe),d9=n(fe,"LI",{});var mke=s(d9);N8e=n(mke,"STRONG",{});var C8t=s(N8e);ehr=r(C8t,"deberta"),C8t.forEach(t),ohr=r(mke," \u2014 "),qQ=n(mke,"A",{href:!0});var w8t=s(qQ);rhr=r(w8t,"TFDebertaForMaskedLM"),w8t.forEach(t),thr=r(mke," (DeBERTa model)"),mke.forEach(t),ahr=i(fe),c9=n(fe,"LI",{});var gke=s(c9);j8e=n(gke,"STRONG",{});var A8t=s(j8e);nhr=r(A8t,"deberta-v2"),A8t.forEach(t),shr=r(gke," \u2014 "),NQ=n(gke,"A",{href:!0});var y8t=s(NQ);lhr=r(y8t,"TFDebertaV2ForMaskedLM"),y8t.forEach(t),ihr=r(gke," (DeBERTa-v2 model)"),gke.forEach(t),dhr=i(fe),f9=n(fe,"LI",{});var hke=s(f9);D8e=n(hke,"STRONG",{});var L8t=s(D8e);chr=r(L8t,"distilbert"),L8t.forEach(t),fhr=r(hke," \u2014 "),jQ=n(hke,"A",{href:!0});var x8t=s(jQ);mhr=r(x8t,"TFDistilBertForMaskedLM"),x8t.forEach(t),ghr=r(hke," (DistilBERT model)"),hke.forEach(t),hhr=i(fe),m9=n(fe,"LI",{});var pke=s(m9);G8e=n(pke,"STRONG",{});var $8t=s(G8e);phr=r($8t,"electra"),$8t.forEach(t),uhr=r(pke," \u2014 "),DQ=n(pke,"A",{href:!0});var k8t=s(DQ);_hr=r(k8t,"TFElectraForMaskedLM"),k8t.forEach(t),bhr=r(pke," (ELECTRA model)"),pke.forEach(t),vhr=i(fe),g9=n(fe,"LI",{});var uke=s(g9);O8e=n(uke,"STRONG",{});var S8t=s(O8e);Fhr=r(S8t,"flaubert"),S8t.forEach(t),Thr=r(uke," \u2014 "),GQ=n(uke,"A",{href:!0});var R8t=s(GQ);Mhr=r(R8t,"TFFlaubertWithLMHeadModel"),R8t.forEach(t),Ehr=r(uke," (FlauBERT model)"),uke.forEach(t),Chr=i(fe),h9=n(fe,"LI",{});var _ke=s(h9);V8e=n(_ke,"STRONG",{});var B8t=s(V8e);whr=r(B8t,"funnel"),B8t.forEach(t),Ahr=r(_ke," \u2014 "),OQ=n(_ke,"A",{href:!0});var P8t=s(OQ);yhr=r(P8t,"TFFunnelForMaskedLM"),P8t.forEach(t),Lhr=r(_ke," (Funnel Transformer model)"),_ke.forEach(t),xhr=i(fe),p9=n(fe,"LI",{});var bke=s(p9);X8e=n(bke,"STRONG",{});var I8t=s(X8e);$hr=r(I8t,"layoutlm"),I8t.forEach(t),khr=r(bke," \u2014 "),VQ=n(bke,"A",{href:!0});var q8t=s(VQ);Shr=r(q8t,"TFLayoutLMForMaskedLM"),q8t.forEach(t),Rhr=r(bke," (LayoutLM model)"),bke.forEach(t),Bhr=i(fe),u9=n(fe,"LI",{});var vke=s(u9);z8e=n(vke,"STRONG",{});var N8t=s(z8e);Phr=r(N8t,"longformer"),N8t.forEach(t),Ihr=r(vke," \u2014 "),XQ=n(vke,"A",{href:!0});var j8t=s(XQ);qhr=r(j8t,"TFLongformerForMaskedLM"),j8t.forEach(t),Nhr=r(vke," (Longformer model)"),vke.forEach(t),jhr=i(fe),_9=n(fe,"LI",{});var Fke=s(_9);Q8e=n(Fke,"STRONG",{});var D8t=s(Q8e);Dhr=r(D8t,"mobilebert"),D8t.forEach(t),Ghr=r(Fke," \u2014 "),zQ=n(Fke,"A",{href:!0});var G8t=s(zQ);Ohr=r(G8t,"TFMobileBertForMaskedLM"),G8t.forEach(t),Vhr=r(Fke," (MobileBERT model)"),Fke.forEach(t),Xhr=i(fe),b9=n(fe,"LI",{});var Tke=s(b9);W8e=n(Tke,"STRONG",{});var O8t=s(W8e);zhr=r(O8t,"mpnet"),O8t.forEach(t),Qhr=r(Tke," \u2014 "),QQ=n(Tke,"A",{href:!0});var V8t=s(QQ);Whr=r(V8t,"TFMPNetForMaskedLM"),V8t.forEach(t),Hhr=r(Tke," (MPNet model)"),Tke.forEach(t),Uhr=i(fe),v9=n(fe,"LI",{});var Mke=s(v9);H8e=n(Mke,"STRONG",{});var X8t=s(H8e);Jhr=r(X8t,"rembert"),X8t.forEach(t),Yhr=r(Mke," \u2014 "),WQ=n(Mke,"A",{href:!0});var z8t=s(WQ);Khr=r(z8t,"TFRemBertForMaskedLM"),z8t.forEach(t),Zhr=r(Mke," (RemBERT model)"),Mke.forEach(t),epr=i(fe),F9=n(fe,"LI",{});var Eke=s(F9);U8e=n(Eke,"STRONG",{});var Q8t=s(U8e);opr=r(Q8t,"roberta"),Q8t.forEach(t),rpr=r(Eke," \u2014 "),HQ=n(Eke,"A",{href:!0});var W8t=s(HQ);tpr=r(W8t,"TFRobertaForMaskedLM"),W8t.forEach(t),apr=r(Eke," (RoBERTa model)"),Eke.forEach(t),npr=i(fe),T9=n(fe,"LI",{});var Cke=s(T9);J8e=n(Cke,"STRONG",{});var H8t=s(J8e);spr=r(H8t,"roformer"),H8t.forEach(t),lpr=r(Cke," \u2014 "),UQ=n(Cke,"A",{href:!0});var U8t=s(UQ);ipr=r(U8t,"TFRoFormerForMaskedLM"),U8t.forEach(t),dpr=r(Cke," (RoFormer model)"),Cke.forEach(t),cpr=i(fe),M9=n(fe,"LI",{});var wke=s(M9);Y8e=n(wke,"STRONG",{});var J8t=s(Y8e);fpr=r(J8t,"tapas"),J8t.forEach(t),mpr=r(wke," \u2014 "),JQ=n(wke,"A",{href:!0});var Y8t=s(JQ);gpr=r(Y8t,"TFTapasForMaskedLM"),Y8t.forEach(t),hpr=r(wke," (TAPAS model)"),wke.forEach(t),ppr=i(fe),E9=n(fe,"LI",{});var Ake=s(E9);K8e=n(Ake,"STRONG",{});var K8t=s(K8e);upr=r(K8t,"xlm"),K8t.forEach(t),_pr=r(Ake," \u2014 "),YQ=n(Ake,"A",{href:!0});var Z8t=s(YQ);bpr=r(Z8t,"TFXLMWithLMHeadModel"),Z8t.forEach(t),vpr=r(Ake," (XLM model)"),Ake.forEach(t),Fpr=i(fe),C9=n(fe,"LI",{});var yke=s(C9);Z8e=n(yke,"STRONG",{});var ebt=s(Z8e);Tpr=r(ebt,"xlm-roberta"),ebt.forEach(t),Mpr=r(yke," \u2014 "),KQ=n(yke,"A",{href:!0});var obt=s(KQ);Epr=r(obt,"TFXLMRobertaForMaskedLM"),obt.forEach(t),Cpr=r(yke," (XLM-RoBERTa model)"),yke.forEach(t),fe.forEach(t),wpr=i(vl),T(w9.$$.fragment,vl),vl.forEach(t),bl.forEach(t),$Ie=i(f),Zd=n(f,"H2",{class:!0});var INe=s(Zd);A9=n(INe,"A",{id:!0,class:!0,href:!0});var rbt=s(A9);ebe=n(rbt,"SPAN",{});var tbt=s(ebe);T(Yy.$$.fragment,tbt),tbt.forEach(t),rbt.forEach(t),Apr=i(INe),obe=n(INe,"SPAN",{});var abt=s(obe);ypr=r(abt,"TFAutoModelForSeq2SeqLM"),abt.forEach(t),INe.forEach(t),kIe=i(f),rr=n(f,"DIV",{class:!0});var Fl=s(rr);T(Ky.$$.fragment,Fl),Lpr=i(Fl),ec=n(Fl,"P",{});var ZK=s(ec);xpr=r(ZK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ZQ=n(ZK,"A",{href:!0});var nbt=s(ZQ);$pr=r(nbt,"from_pretrained()"),nbt.forEach(t),kpr=r(ZK," class method or the "),eW=n(ZK,"A",{href:!0});var sbt=s(eW);Spr=r(sbt,"from_config()"),sbt.forEach(t),Rpr=r(ZK,` class
method.`),ZK.forEach(t),Bpr=i(Fl),Zy=n(Fl,"P",{});var qNe=s(Zy);Ppr=r(qNe,"This class cannot be instantiated directly using "),rbe=n(qNe,"CODE",{});var lbt=s(rbe);Ipr=r(lbt,"__init__()"),lbt.forEach(t),qpr=r(qNe," (throws an error)."),qNe.forEach(t),Npr=i(Fl),$t=n(Fl,"DIV",{class:!0});var Z3=s($t);T(eL.$$.fragment,Z3),jpr=i(Z3),tbe=n(Z3,"P",{});var ibt=s(tbe);Dpr=r(ibt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ibt.forEach(t),Gpr=i(Z3),oc=n(Z3,"P",{});var eZ=s(oc);Opr=r(eZ,`Note:
Loading a model from its configuration file does `),abe=n(eZ,"STRONG",{});var dbt=s(abe);Vpr=r(dbt,"not"),dbt.forEach(t),Xpr=r(eZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=n(eZ,"A",{href:!0});var cbt=s(oW);zpr=r(cbt,"from_pretrained()"),cbt.forEach(t),Qpr=r(eZ," to load the model weights."),eZ.forEach(t),Wpr=i(Z3),T(y9.$$.fragment,Z3),Z3.forEach(t),Hpr=i(Fl),$r=n(Fl,"DIV",{class:!0});var Tl=s($r);T(oL.$$.fragment,Tl),Upr=i(Tl),nbe=n(Tl,"P",{});var fbt=s(nbe);Jpr=r(fbt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),fbt.forEach(t),Ypr=i(Tl),an=n(Tl,"P",{});var ew=s(an);Kpr=r(ew,"The model class to instantiate is selected based on the "),sbe=n(ew,"CODE",{});var mbt=s(sbe);Zpr=r(mbt,"model_type"),mbt.forEach(t),eur=r(ew,` property of the config object (either
passed as an argument or loaded from `),lbe=n(ew,"CODE",{});var gbt=s(lbe);our=r(gbt,"pretrained_model_name_or_path"),gbt.forEach(t),rur=r(ew,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ibe=n(ew,"CODE",{});var hbt=s(ibe);tur=r(hbt,"pretrained_model_name_or_path"),hbt.forEach(t),aur=r(ew,":"),ew.forEach(t),nur=i(Tl),ye=n(Tl,"UL",{});var Re=s(ye);L9=n(Re,"LI",{});var Lke=s(L9);dbe=n(Lke,"STRONG",{});var pbt=s(dbe);sur=r(pbt,"bart"),pbt.forEach(t),lur=r(Lke," \u2014 "),rW=n(Lke,"A",{href:!0});var ubt=s(rW);iur=r(ubt,"TFBartForConditionalGeneration"),ubt.forEach(t),dur=r(Lke," (BART model)"),Lke.forEach(t),cur=i(Re),x9=n(Re,"LI",{});var xke=s(x9);cbe=n(xke,"STRONG",{});var _bt=s(cbe);fur=r(_bt,"blenderbot"),_bt.forEach(t),mur=r(xke," \u2014 "),tW=n(xke,"A",{href:!0});var bbt=s(tW);gur=r(bbt,"TFBlenderbotForConditionalGeneration"),bbt.forEach(t),hur=r(xke," (Blenderbot model)"),xke.forEach(t),pur=i(Re),$9=n(Re,"LI",{});var $ke=s($9);fbe=n($ke,"STRONG",{});var vbt=s(fbe);uur=r(vbt,"blenderbot-small"),vbt.forEach(t),_ur=r($ke," \u2014 "),aW=n($ke,"A",{href:!0});var Fbt=s(aW);bur=r(Fbt,"TFBlenderbotSmallForConditionalGeneration"),Fbt.forEach(t),vur=r($ke," (BlenderbotSmall model)"),$ke.forEach(t),Fur=i(Re),k9=n(Re,"LI",{});var kke=s(k9);mbe=n(kke,"STRONG",{});var Tbt=s(mbe);Tur=r(Tbt,"encoder-decoder"),Tbt.forEach(t),Mur=r(kke," \u2014 "),nW=n(kke,"A",{href:!0});var Mbt=s(nW);Eur=r(Mbt,"TFEncoderDecoderModel"),Mbt.forEach(t),Cur=r(kke," (Encoder decoder model)"),kke.forEach(t),wur=i(Re),S9=n(Re,"LI",{});var Ske=s(S9);gbe=n(Ske,"STRONG",{});var Ebt=s(gbe);Aur=r(Ebt,"led"),Ebt.forEach(t),yur=r(Ske," \u2014 "),sW=n(Ske,"A",{href:!0});var Cbt=s(sW);Lur=r(Cbt,"TFLEDForConditionalGeneration"),Cbt.forEach(t),xur=r(Ske," (LED model)"),Ske.forEach(t),$ur=i(Re),R9=n(Re,"LI",{});var Rke=s(R9);hbe=n(Rke,"STRONG",{});var wbt=s(hbe);kur=r(wbt,"marian"),wbt.forEach(t),Sur=r(Rke," \u2014 "),lW=n(Rke,"A",{href:!0});var Abt=s(lW);Rur=r(Abt,"TFMarianMTModel"),Abt.forEach(t),Bur=r(Rke," (Marian model)"),Rke.forEach(t),Pur=i(Re),B9=n(Re,"LI",{});var Bke=s(B9);pbe=n(Bke,"STRONG",{});var ybt=s(pbe);Iur=r(ybt,"mbart"),ybt.forEach(t),qur=r(Bke," \u2014 "),iW=n(Bke,"A",{href:!0});var Lbt=s(iW);Nur=r(Lbt,"TFMBartForConditionalGeneration"),Lbt.forEach(t),jur=r(Bke," (mBART model)"),Bke.forEach(t),Dur=i(Re),P9=n(Re,"LI",{});var Pke=s(P9);ube=n(Pke,"STRONG",{});var xbt=s(ube);Gur=r(xbt,"mt5"),xbt.forEach(t),Our=r(Pke," \u2014 "),dW=n(Pke,"A",{href:!0});var $bt=s(dW);Vur=r($bt,"TFMT5ForConditionalGeneration"),$bt.forEach(t),Xur=r(Pke," (mT5 model)"),Pke.forEach(t),zur=i(Re),I9=n(Re,"LI",{});var Ike=s(I9);_be=n(Ike,"STRONG",{});var kbt=s(_be);Qur=r(kbt,"pegasus"),kbt.forEach(t),Wur=r(Ike," \u2014 "),cW=n(Ike,"A",{href:!0});var Sbt=s(cW);Hur=r(Sbt,"TFPegasusForConditionalGeneration"),Sbt.forEach(t),Uur=r(Ike," (Pegasus model)"),Ike.forEach(t),Jur=i(Re),q9=n(Re,"LI",{});var qke=s(q9);bbe=n(qke,"STRONG",{});var Rbt=s(bbe);Yur=r(Rbt,"t5"),Rbt.forEach(t),Kur=r(qke," \u2014 "),fW=n(qke,"A",{href:!0});var Bbt=s(fW);Zur=r(Bbt,"TFT5ForConditionalGeneration"),Bbt.forEach(t),e_r=r(qke," (T5 model)"),qke.forEach(t),Re.forEach(t),o_r=i(Tl),T(N9.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),SIe=i(f),rc=n(f,"H2",{class:!0});var NNe=s(rc);j9=n(NNe,"A",{id:!0,class:!0,href:!0});var Pbt=s(j9);vbe=n(Pbt,"SPAN",{});var Ibt=s(vbe);T(rL.$$.fragment,Ibt),Ibt.forEach(t),Pbt.forEach(t),r_r=i(NNe),Fbe=n(NNe,"SPAN",{});var qbt=s(Fbe);t_r=r(qbt,"TFAutoModelForSequenceClassification"),qbt.forEach(t),NNe.forEach(t),RIe=i(f),tr=n(f,"DIV",{class:!0});var Ml=s(tr);T(tL.$$.fragment,Ml),a_r=i(Ml),tc=n(Ml,"P",{});var oZ=s(tc);n_r=r(oZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),mW=n(oZ,"A",{href:!0});var Nbt=s(mW);s_r=r(Nbt,"from_pretrained()"),Nbt.forEach(t),l_r=r(oZ," class method or the "),gW=n(oZ,"A",{href:!0});var jbt=s(gW);i_r=r(jbt,"from_config()"),jbt.forEach(t),d_r=r(oZ,` class
method.`),oZ.forEach(t),c_r=i(Ml),aL=n(Ml,"P",{});var jNe=s(aL);f_r=r(jNe,"This class cannot be instantiated directly using "),Tbe=n(jNe,"CODE",{});var Dbt=s(Tbe);m_r=r(Dbt,"__init__()"),Dbt.forEach(t),g_r=r(jNe," (throws an error)."),jNe.forEach(t),h_r=i(Ml),kt=n(Ml,"DIV",{class:!0});var ow=s(kt);T(nL.$$.fragment,ow),p_r=i(ow),Mbe=n(ow,"P",{});var Gbt=s(Mbe);u_r=r(Gbt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Gbt.forEach(t),__r=i(ow),ac=n(ow,"P",{});var rZ=s(ac);b_r=r(rZ,`Note:
Loading a model from its configuration file does `),Ebe=n(rZ,"STRONG",{});var Obt=s(Ebe);v_r=r(Obt,"not"),Obt.forEach(t),F_r=r(rZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hW=n(rZ,"A",{href:!0});var Vbt=s(hW);T_r=r(Vbt,"from_pretrained()"),Vbt.forEach(t),M_r=r(rZ," to load the model weights."),rZ.forEach(t),E_r=i(ow),T(D9.$$.fragment,ow),ow.forEach(t),C_r=i(Ml),kr=n(Ml,"DIV",{class:!0});var El=s(kr);T(sL.$$.fragment,El),w_r=i(El),Cbe=n(El,"P",{});var Xbt=s(Cbe);A_r=r(Xbt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Xbt.forEach(t),y_r=i(El),nn=n(El,"P",{});var rw=s(nn);L_r=r(rw,"The model class to instantiate is selected based on the "),wbe=n(rw,"CODE",{});var zbt=s(wbe);x_r=r(zbt,"model_type"),zbt.forEach(t),$_r=r(rw,` property of the config object (either
passed as an argument or loaded from `),Abe=n(rw,"CODE",{});var Qbt=s(Abe);k_r=r(Qbt,"pretrained_model_name_or_path"),Qbt.forEach(t),S_r=r(rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ybe=n(rw,"CODE",{});var Wbt=s(ybe);R_r=r(Wbt,"pretrained_model_name_or_path"),Wbt.forEach(t),B_r=r(rw,":"),rw.forEach(t),P_r=i(El),Z=n(El,"UL",{});var re=s(Z);G9=n(re,"LI",{});var Nke=s(G9);Lbe=n(Nke,"STRONG",{});var Hbt=s(Lbe);I_r=r(Hbt,"albert"),Hbt.forEach(t),q_r=r(Nke," \u2014 "),pW=n(Nke,"A",{href:!0});var Ubt=s(pW);N_r=r(Ubt,"TFAlbertForSequenceClassification"),Ubt.forEach(t),j_r=r(Nke," (ALBERT model)"),Nke.forEach(t),D_r=i(re),O9=n(re,"LI",{});var jke=s(O9);xbe=n(jke,"STRONG",{});var Jbt=s(xbe);G_r=r(Jbt,"bert"),Jbt.forEach(t),O_r=r(jke," \u2014 "),uW=n(jke,"A",{href:!0});var Ybt=s(uW);V_r=r(Ybt,"TFBertForSequenceClassification"),Ybt.forEach(t),X_r=r(jke," (BERT model)"),jke.forEach(t),z_r=i(re),V9=n(re,"LI",{});var Dke=s(V9);$be=n(Dke,"STRONG",{});var Kbt=s($be);Q_r=r(Kbt,"camembert"),Kbt.forEach(t),W_r=r(Dke," \u2014 "),_W=n(Dke,"A",{href:!0});var Zbt=s(_W);H_r=r(Zbt,"TFCamembertForSequenceClassification"),Zbt.forEach(t),U_r=r(Dke," (CamemBERT model)"),Dke.forEach(t),J_r=i(re),X9=n(re,"LI",{});var Gke=s(X9);kbe=n(Gke,"STRONG",{});var e2t=s(kbe);Y_r=r(e2t,"convbert"),e2t.forEach(t),K_r=r(Gke," \u2014 "),bW=n(Gke,"A",{href:!0});var o2t=s(bW);Z_r=r(o2t,"TFConvBertForSequenceClassification"),o2t.forEach(t),e1r=r(Gke," (ConvBERT model)"),Gke.forEach(t),o1r=i(re),z9=n(re,"LI",{});var Oke=s(z9);Sbe=n(Oke,"STRONG",{});var r2t=s(Sbe);r1r=r(r2t,"ctrl"),r2t.forEach(t),t1r=r(Oke," \u2014 "),vW=n(Oke,"A",{href:!0});var t2t=s(vW);a1r=r(t2t,"TFCTRLForSequenceClassification"),t2t.forEach(t),n1r=r(Oke," (CTRL model)"),Oke.forEach(t),s1r=i(re),Q9=n(re,"LI",{});var Vke=s(Q9);Rbe=n(Vke,"STRONG",{});var a2t=s(Rbe);l1r=r(a2t,"deberta"),a2t.forEach(t),i1r=r(Vke," \u2014 "),FW=n(Vke,"A",{href:!0});var n2t=s(FW);d1r=r(n2t,"TFDebertaForSequenceClassification"),n2t.forEach(t),c1r=r(Vke," (DeBERTa model)"),Vke.forEach(t),f1r=i(re),W9=n(re,"LI",{});var Xke=s(W9);Bbe=n(Xke,"STRONG",{});var s2t=s(Bbe);m1r=r(s2t,"deberta-v2"),s2t.forEach(t),g1r=r(Xke," \u2014 "),TW=n(Xke,"A",{href:!0});var l2t=s(TW);h1r=r(l2t,"TFDebertaV2ForSequenceClassification"),l2t.forEach(t),p1r=r(Xke," (DeBERTa-v2 model)"),Xke.forEach(t),u1r=i(re),H9=n(re,"LI",{});var zke=s(H9);Pbe=n(zke,"STRONG",{});var i2t=s(Pbe);_1r=r(i2t,"distilbert"),i2t.forEach(t),b1r=r(zke," \u2014 "),MW=n(zke,"A",{href:!0});var d2t=s(MW);v1r=r(d2t,"TFDistilBertForSequenceClassification"),d2t.forEach(t),F1r=r(zke," (DistilBERT model)"),zke.forEach(t),T1r=i(re),U9=n(re,"LI",{});var Qke=s(U9);Ibe=n(Qke,"STRONG",{});var c2t=s(Ibe);M1r=r(c2t,"electra"),c2t.forEach(t),E1r=r(Qke," \u2014 "),EW=n(Qke,"A",{href:!0});var f2t=s(EW);C1r=r(f2t,"TFElectraForSequenceClassification"),f2t.forEach(t),w1r=r(Qke," (ELECTRA model)"),Qke.forEach(t),A1r=i(re),J9=n(re,"LI",{});var Wke=s(J9);qbe=n(Wke,"STRONG",{});var m2t=s(qbe);y1r=r(m2t,"flaubert"),m2t.forEach(t),L1r=r(Wke," \u2014 "),CW=n(Wke,"A",{href:!0});var g2t=s(CW);x1r=r(g2t,"TFFlaubertForSequenceClassification"),g2t.forEach(t),$1r=r(Wke," (FlauBERT model)"),Wke.forEach(t),k1r=i(re),Y9=n(re,"LI",{});var Hke=s(Y9);Nbe=n(Hke,"STRONG",{});var h2t=s(Nbe);S1r=r(h2t,"funnel"),h2t.forEach(t),R1r=r(Hke," \u2014 "),wW=n(Hke,"A",{href:!0});var p2t=s(wW);B1r=r(p2t,"TFFunnelForSequenceClassification"),p2t.forEach(t),P1r=r(Hke," (Funnel Transformer model)"),Hke.forEach(t),I1r=i(re),K9=n(re,"LI",{});var Uke=s(K9);jbe=n(Uke,"STRONG",{});var u2t=s(jbe);q1r=r(u2t,"gpt2"),u2t.forEach(t),N1r=r(Uke," \u2014 "),AW=n(Uke,"A",{href:!0});var _2t=s(AW);j1r=r(_2t,"TFGPT2ForSequenceClassification"),_2t.forEach(t),D1r=r(Uke," (OpenAI GPT-2 model)"),Uke.forEach(t),G1r=i(re),Z9=n(re,"LI",{});var Jke=s(Z9);Dbe=n(Jke,"STRONG",{});var b2t=s(Dbe);O1r=r(b2t,"gptj"),b2t.forEach(t),V1r=r(Jke," \u2014 "),yW=n(Jke,"A",{href:!0});var v2t=s(yW);X1r=r(v2t,"TFGPTJForSequenceClassification"),v2t.forEach(t),z1r=r(Jke," (GPT-J model)"),Jke.forEach(t),Q1r=i(re),eM=n(re,"LI",{});var Yke=s(eM);Gbe=n(Yke,"STRONG",{});var F2t=s(Gbe);W1r=r(F2t,"layoutlm"),F2t.forEach(t),H1r=r(Yke," \u2014 "),LW=n(Yke,"A",{href:!0});var T2t=s(LW);U1r=r(T2t,"TFLayoutLMForSequenceClassification"),T2t.forEach(t),J1r=r(Yke," (LayoutLM model)"),Yke.forEach(t),Y1r=i(re),oM=n(re,"LI",{});var Kke=s(oM);Obe=n(Kke,"STRONG",{});var M2t=s(Obe);K1r=r(M2t,"longformer"),M2t.forEach(t),Z1r=r(Kke," \u2014 "),xW=n(Kke,"A",{href:!0});var E2t=s(xW);e8r=r(E2t,"TFLongformerForSequenceClassification"),E2t.forEach(t),o8r=r(Kke," (Longformer model)"),Kke.forEach(t),r8r=i(re),rM=n(re,"LI",{});var Zke=s(rM);Vbe=n(Zke,"STRONG",{});var C2t=s(Vbe);t8r=r(C2t,"mobilebert"),C2t.forEach(t),a8r=r(Zke," \u2014 "),$W=n(Zke,"A",{href:!0});var w2t=s($W);n8r=r(w2t,"TFMobileBertForSequenceClassification"),w2t.forEach(t),s8r=r(Zke," (MobileBERT model)"),Zke.forEach(t),l8r=i(re),tM=n(re,"LI",{});var eSe=s(tM);Xbe=n(eSe,"STRONG",{});var A2t=s(Xbe);i8r=r(A2t,"mpnet"),A2t.forEach(t),d8r=r(eSe," \u2014 "),kW=n(eSe,"A",{href:!0});var y2t=s(kW);c8r=r(y2t,"TFMPNetForSequenceClassification"),y2t.forEach(t),f8r=r(eSe," (MPNet model)"),eSe.forEach(t),m8r=i(re),aM=n(re,"LI",{});var oSe=s(aM);zbe=n(oSe,"STRONG",{});var L2t=s(zbe);g8r=r(L2t,"openai-gpt"),L2t.forEach(t),h8r=r(oSe," \u2014 "),SW=n(oSe,"A",{href:!0});var x2t=s(SW);p8r=r(x2t,"TFOpenAIGPTForSequenceClassification"),x2t.forEach(t),u8r=r(oSe," (OpenAI GPT model)"),oSe.forEach(t),_8r=i(re),nM=n(re,"LI",{});var rSe=s(nM);Qbe=n(rSe,"STRONG",{});var $2t=s(Qbe);b8r=r($2t,"rembert"),$2t.forEach(t),v8r=r(rSe," \u2014 "),RW=n(rSe,"A",{href:!0});var k2t=s(RW);F8r=r(k2t,"TFRemBertForSequenceClassification"),k2t.forEach(t),T8r=r(rSe," (RemBERT model)"),rSe.forEach(t),M8r=i(re),sM=n(re,"LI",{});var tSe=s(sM);Wbe=n(tSe,"STRONG",{});var S2t=s(Wbe);E8r=r(S2t,"roberta"),S2t.forEach(t),C8r=r(tSe," \u2014 "),BW=n(tSe,"A",{href:!0});var R2t=s(BW);w8r=r(R2t,"TFRobertaForSequenceClassification"),R2t.forEach(t),A8r=r(tSe," (RoBERTa model)"),tSe.forEach(t),y8r=i(re),lM=n(re,"LI",{});var aSe=s(lM);Hbe=n(aSe,"STRONG",{});var B2t=s(Hbe);L8r=r(B2t,"roformer"),B2t.forEach(t),x8r=r(aSe," \u2014 "),PW=n(aSe,"A",{href:!0});var P2t=s(PW);$8r=r(P2t,"TFRoFormerForSequenceClassification"),P2t.forEach(t),k8r=r(aSe," (RoFormer model)"),aSe.forEach(t),S8r=i(re),iM=n(re,"LI",{});var nSe=s(iM);Ube=n(nSe,"STRONG",{});var I2t=s(Ube);R8r=r(I2t,"tapas"),I2t.forEach(t),B8r=r(nSe," \u2014 "),IW=n(nSe,"A",{href:!0});var q2t=s(IW);P8r=r(q2t,"TFTapasForSequenceClassification"),q2t.forEach(t),I8r=r(nSe," (TAPAS model)"),nSe.forEach(t),q8r=i(re),dM=n(re,"LI",{});var sSe=s(dM);Jbe=n(sSe,"STRONG",{});var N2t=s(Jbe);N8r=r(N2t,"transfo-xl"),N2t.forEach(t),j8r=r(sSe," \u2014 "),qW=n(sSe,"A",{href:!0});var j2t=s(qW);D8r=r(j2t,"TFTransfoXLForSequenceClassification"),j2t.forEach(t),G8r=r(sSe," (Transformer-XL model)"),sSe.forEach(t),O8r=i(re),cM=n(re,"LI",{});var lSe=s(cM);Ybe=n(lSe,"STRONG",{});var D2t=s(Ybe);V8r=r(D2t,"xlm"),D2t.forEach(t),X8r=r(lSe," \u2014 "),NW=n(lSe,"A",{href:!0});var G2t=s(NW);z8r=r(G2t,"TFXLMForSequenceClassification"),G2t.forEach(t),Q8r=r(lSe," (XLM model)"),lSe.forEach(t),W8r=i(re),fM=n(re,"LI",{});var iSe=s(fM);Kbe=n(iSe,"STRONG",{});var O2t=s(Kbe);H8r=r(O2t,"xlm-roberta"),O2t.forEach(t),U8r=r(iSe," \u2014 "),jW=n(iSe,"A",{href:!0});var V2t=s(jW);J8r=r(V2t,"TFXLMRobertaForSequenceClassification"),V2t.forEach(t),Y8r=r(iSe," (XLM-RoBERTa model)"),iSe.forEach(t),K8r=i(re),mM=n(re,"LI",{});var dSe=s(mM);Zbe=n(dSe,"STRONG",{});var X2t=s(Zbe);Z8r=r(X2t,"xlnet"),X2t.forEach(t),ebr=r(dSe," \u2014 "),DW=n(dSe,"A",{href:!0});var z2t=s(DW);obr=r(z2t,"TFXLNetForSequenceClassification"),z2t.forEach(t),rbr=r(dSe," (XLNet model)"),dSe.forEach(t),re.forEach(t),tbr=i(El),T(gM.$$.fragment,El),El.forEach(t),Ml.forEach(t),BIe=i(f),nc=n(f,"H2",{class:!0});var DNe=s(nc);hM=n(DNe,"A",{id:!0,class:!0,href:!0});var Q2t=s(hM);e2e=n(Q2t,"SPAN",{});var W2t=s(e2e);T(lL.$$.fragment,W2t),W2t.forEach(t),Q2t.forEach(t),abr=i(DNe),o2e=n(DNe,"SPAN",{});var H2t=s(o2e);nbr=r(H2t,"TFAutoModelForMultipleChoice"),H2t.forEach(t),DNe.forEach(t),PIe=i(f),ar=n(f,"DIV",{class:!0});var Cl=s(ar);T(iL.$$.fragment,Cl),sbr=i(Cl),sc=n(Cl,"P",{});var tZ=s(sc);lbr=r(tZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GW=n(tZ,"A",{href:!0});var U2t=s(GW);ibr=r(U2t,"from_pretrained()"),U2t.forEach(t),dbr=r(tZ," class method or the "),OW=n(tZ,"A",{href:!0});var J2t=s(OW);cbr=r(J2t,"from_config()"),J2t.forEach(t),fbr=r(tZ,` class
method.`),tZ.forEach(t),mbr=i(Cl),dL=n(Cl,"P",{});var GNe=s(dL);gbr=r(GNe,"This class cannot be instantiated directly using "),r2e=n(GNe,"CODE",{});var Y2t=s(r2e);hbr=r(Y2t,"__init__()"),Y2t.forEach(t),pbr=r(GNe," (throws an error)."),GNe.forEach(t),ubr=i(Cl),St=n(Cl,"DIV",{class:!0});var tw=s(St);T(cL.$$.fragment,tw),_br=i(tw),t2e=n(tw,"P",{});var K2t=s(t2e);bbr=r(K2t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),K2t.forEach(t),vbr=i(tw),lc=n(tw,"P",{});var aZ=s(lc);Fbr=r(aZ,`Note:
Loading a model from its configuration file does `),a2e=n(aZ,"STRONG",{});var Z2t=s(a2e);Tbr=r(Z2t,"not"),Z2t.forEach(t),Mbr=r(aZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(aZ,"A",{href:!0});var evt=s(VW);Ebr=r(evt,"from_pretrained()"),evt.forEach(t),Cbr=r(aZ," to load the model weights."),aZ.forEach(t),wbr=i(tw),T(pM.$$.fragment,tw),tw.forEach(t),Abr=i(Cl),Sr=n(Cl,"DIV",{class:!0});var wl=s(Sr);T(fL.$$.fragment,wl),ybr=i(wl),n2e=n(wl,"P",{});var ovt=s(n2e);Lbr=r(ovt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ovt.forEach(t),xbr=i(wl),sn=n(wl,"P",{});var aw=s(sn);$br=r(aw,"The model class to instantiate is selected based on the "),s2e=n(aw,"CODE",{});var rvt=s(s2e);kbr=r(rvt,"model_type"),rvt.forEach(t),Sbr=r(aw,` property of the config object (either
passed as an argument or loaded from `),l2e=n(aw,"CODE",{});var tvt=s(l2e);Rbr=r(tvt,"pretrained_model_name_or_path"),tvt.forEach(t),Bbr=r(aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i2e=n(aw,"CODE",{});var avt=s(i2e);Pbr=r(avt,"pretrained_model_name_or_path"),avt.forEach(t),Ibr=r(aw,":"),aw.forEach(t),qbr=i(wl),pe=n(wl,"UL",{});var _e=s(pe);uM=n(_e,"LI",{});var cSe=s(uM);d2e=n(cSe,"STRONG",{});var nvt=s(d2e);Nbr=r(nvt,"albert"),nvt.forEach(t),jbr=r(cSe," \u2014 "),XW=n(cSe,"A",{href:!0});var svt=s(XW);Dbr=r(svt,"TFAlbertForMultipleChoice"),svt.forEach(t),Gbr=r(cSe," (ALBERT model)"),cSe.forEach(t),Obr=i(_e),_M=n(_e,"LI",{});var fSe=s(_M);c2e=n(fSe,"STRONG",{});var lvt=s(c2e);Vbr=r(lvt,"bert"),lvt.forEach(t),Xbr=r(fSe," \u2014 "),zW=n(fSe,"A",{href:!0});var ivt=s(zW);zbr=r(ivt,"TFBertForMultipleChoice"),ivt.forEach(t),Qbr=r(fSe," (BERT model)"),fSe.forEach(t),Wbr=i(_e),bM=n(_e,"LI",{});var mSe=s(bM);f2e=n(mSe,"STRONG",{});var dvt=s(f2e);Hbr=r(dvt,"camembert"),dvt.forEach(t),Ubr=r(mSe," \u2014 "),QW=n(mSe,"A",{href:!0});var cvt=s(QW);Jbr=r(cvt,"TFCamembertForMultipleChoice"),cvt.forEach(t),Ybr=r(mSe," (CamemBERT model)"),mSe.forEach(t),Kbr=i(_e),vM=n(_e,"LI",{});var gSe=s(vM);m2e=n(gSe,"STRONG",{});var fvt=s(m2e);Zbr=r(fvt,"convbert"),fvt.forEach(t),e2r=r(gSe," \u2014 "),WW=n(gSe,"A",{href:!0});var mvt=s(WW);o2r=r(mvt,"TFConvBertForMultipleChoice"),mvt.forEach(t),r2r=r(gSe," (ConvBERT model)"),gSe.forEach(t),t2r=i(_e),FM=n(_e,"LI",{});var hSe=s(FM);g2e=n(hSe,"STRONG",{});var gvt=s(g2e);a2r=r(gvt,"distilbert"),gvt.forEach(t),n2r=r(hSe," \u2014 "),HW=n(hSe,"A",{href:!0});var hvt=s(HW);s2r=r(hvt,"TFDistilBertForMultipleChoice"),hvt.forEach(t),l2r=r(hSe," (DistilBERT model)"),hSe.forEach(t),i2r=i(_e),TM=n(_e,"LI",{});var pSe=s(TM);h2e=n(pSe,"STRONG",{});var pvt=s(h2e);d2r=r(pvt,"electra"),pvt.forEach(t),c2r=r(pSe," \u2014 "),UW=n(pSe,"A",{href:!0});var uvt=s(UW);f2r=r(uvt,"TFElectraForMultipleChoice"),uvt.forEach(t),m2r=r(pSe," (ELECTRA model)"),pSe.forEach(t),g2r=i(_e),MM=n(_e,"LI",{});var uSe=s(MM);p2e=n(uSe,"STRONG",{});var _vt=s(p2e);h2r=r(_vt,"flaubert"),_vt.forEach(t),p2r=r(uSe," \u2014 "),JW=n(uSe,"A",{href:!0});var bvt=s(JW);u2r=r(bvt,"TFFlaubertForMultipleChoice"),bvt.forEach(t),_2r=r(uSe," (FlauBERT model)"),uSe.forEach(t),b2r=i(_e),EM=n(_e,"LI",{});var _Se=s(EM);u2e=n(_Se,"STRONG",{});var vvt=s(u2e);v2r=r(vvt,"funnel"),vvt.forEach(t),F2r=r(_Se," \u2014 "),YW=n(_Se,"A",{href:!0});var Fvt=s(YW);T2r=r(Fvt,"TFFunnelForMultipleChoice"),Fvt.forEach(t),M2r=r(_Se," (Funnel Transformer model)"),_Se.forEach(t),E2r=i(_e),CM=n(_e,"LI",{});var bSe=s(CM);_2e=n(bSe,"STRONG",{});var Tvt=s(_2e);C2r=r(Tvt,"longformer"),Tvt.forEach(t),w2r=r(bSe," \u2014 "),KW=n(bSe,"A",{href:!0});var Mvt=s(KW);A2r=r(Mvt,"TFLongformerForMultipleChoice"),Mvt.forEach(t),y2r=r(bSe," (Longformer model)"),bSe.forEach(t),L2r=i(_e),wM=n(_e,"LI",{});var vSe=s(wM);b2e=n(vSe,"STRONG",{});var Evt=s(b2e);x2r=r(Evt,"mobilebert"),Evt.forEach(t),$2r=r(vSe," \u2014 "),ZW=n(vSe,"A",{href:!0});var Cvt=s(ZW);k2r=r(Cvt,"TFMobileBertForMultipleChoice"),Cvt.forEach(t),S2r=r(vSe," (MobileBERT model)"),vSe.forEach(t),R2r=i(_e),AM=n(_e,"LI",{});var FSe=s(AM);v2e=n(FSe,"STRONG",{});var wvt=s(v2e);B2r=r(wvt,"mpnet"),wvt.forEach(t),P2r=r(FSe," \u2014 "),eH=n(FSe,"A",{href:!0});var Avt=s(eH);I2r=r(Avt,"TFMPNetForMultipleChoice"),Avt.forEach(t),q2r=r(FSe," (MPNet model)"),FSe.forEach(t),N2r=i(_e),yM=n(_e,"LI",{});var TSe=s(yM);F2e=n(TSe,"STRONG",{});var yvt=s(F2e);j2r=r(yvt,"rembert"),yvt.forEach(t),D2r=r(TSe," \u2014 "),oH=n(TSe,"A",{href:!0});var Lvt=s(oH);G2r=r(Lvt,"TFRemBertForMultipleChoice"),Lvt.forEach(t),O2r=r(TSe," (RemBERT model)"),TSe.forEach(t),V2r=i(_e),LM=n(_e,"LI",{});var MSe=s(LM);T2e=n(MSe,"STRONG",{});var xvt=s(T2e);X2r=r(xvt,"roberta"),xvt.forEach(t),z2r=r(MSe," \u2014 "),rH=n(MSe,"A",{href:!0});var $vt=s(rH);Q2r=r($vt,"TFRobertaForMultipleChoice"),$vt.forEach(t),W2r=r(MSe," (RoBERTa model)"),MSe.forEach(t),H2r=i(_e),xM=n(_e,"LI",{});var ESe=s(xM);M2e=n(ESe,"STRONG",{});var kvt=s(M2e);U2r=r(kvt,"roformer"),kvt.forEach(t),J2r=r(ESe," \u2014 "),tH=n(ESe,"A",{href:!0});var Svt=s(tH);Y2r=r(Svt,"TFRoFormerForMultipleChoice"),Svt.forEach(t),K2r=r(ESe," (RoFormer model)"),ESe.forEach(t),Z2r=i(_e),$M=n(_e,"LI",{});var CSe=s($M);E2e=n(CSe,"STRONG",{});var Rvt=s(E2e);evr=r(Rvt,"xlm"),Rvt.forEach(t),ovr=r(CSe," \u2014 "),aH=n(CSe,"A",{href:!0});var Bvt=s(aH);rvr=r(Bvt,"TFXLMForMultipleChoice"),Bvt.forEach(t),tvr=r(CSe," (XLM model)"),CSe.forEach(t),avr=i(_e),kM=n(_e,"LI",{});var wSe=s(kM);C2e=n(wSe,"STRONG",{});var Pvt=s(C2e);nvr=r(Pvt,"xlm-roberta"),Pvt.forEach(t),svr=r(wSe," \u2014 "),nH=n(wSe,"A",{href:!0});var Ivt=s(nH);lvr=r(Ivt,"TFXLMRobertaForMultipleChoice"),Ivt.forEach(t),ivr=r(wSe," (XLM-RoBERTa model)"),wSe.forEach(t),dvr=i(_e),SM=n(_e,"LI",{});var ASe=s(SM);w2e=n(ASe,"STRONG",{});var qvt=s(w2e);cvr=r(qvt,"xlnet"),qvt.forEach(t),fvr=r(ASe," \u2014 "),sH=n(ASe,"A",{href:!0});var Nvt=s(sH);mvr=r(Nvt,"TFXLNetForMultipleChoice"),Nvt.forEach(t),gvr=r(ASe," (XLNet model)"),ASe.forEach(t),_e.forEach(t),hvr=i(wl),T(RM.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),IIe=i(f),ic=n(f,"H2",{class:!0});var ONe=s(ic);BM=n(ONe,"A",{id:!0,class:!0,href:!0});var jvt=s(BM);A2e=n(jvt,"SPAN",{});var Dvt=s(A2e);T(mL.$$.fragment,Dvt),Dvt.forEach(t),jvt.forEach(t),pvr=i(ONe),y2e=n(ONe,"SPAN",{});var Gvt=s(y2e);uvr=r(Gvt,"TFAutoModelForNextSentencePrediction"),Gvt.forEach(t),ONe.forEach(t),qIe=i(f),nr=n(f,"DIV",{class:!0});var Al=s(nr);T(gL.$$.fragment,Al),_vr=i(Al),dc=n(Al,"P",{});var nZ=s(dc);bvr=r(nZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),lH=n(nZ,"A",{href:!0});var Ovt=s(lH);vvr=r(Ovt,"from_pretrained()"),Ovt.forEach(t),Fvr=r(nZ," class method or the "),iH=n(nZ,"A",{href:!0});var Vvt=s(iH);Tvr=r(Vvt,"from_config()"),Vvt.forEach(t),Mvr=r(nZ,` class
method.`),nZ.forEach(t),Evr=i(Al),hL=n(Al,"P",{});var VNe=s(hL);Cvr=r(VNe,"This class cannot be instantiated directly using "),L2e=n(VNe,"CODE",{});var Xvt=s(L2e);wvr=r(Xvt,"__init__()"),Xvt.forEach(t),Avr=r(VNe," (throws an error)."),VNe.forEach(t),yvr=i(Al),Rt=n(Al,"DIV",{class:!0});var nw=s(Rt);T(pL.$$.fragment,nw),Lvr=i(nw),x2e=n(nw,"P",{});var zvt=s(x2e);xvr=r(zvt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),zvt.forEach(t),$vr=i(nw),cc=n(nw,"P",{});var sZ=s(cc);kvr=r(sZ,`Note:
Loading a model from its configuration file does `),$2e=n(sZ,"STRONG",{});var Qvt=s($2e);Svr=r(Qvt,"not"),Qvt.forEach(t),Rvr=r(sZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),dH=n(sZ,"A",{href:!0});var Wvt=s(dH);Bvr=r(Wvt,"from_pretrained()"),Wvt.forEach(t),Pvr=r(sZ," to load the model weights."),sZ.forEach(t),Ivr=i(nw),T(PM.$$.fragment,nw),nw.forEach(t),qvr=i(Al),Rr=n(Al,"DIV",{class:!0});var yl=s(Rr);T(uL.$$.fragment,yl),Nvr=i(yl),k2e=n(yl,"P",{});var Hvt=s(k2e);jvr=r(Hvt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Hvt.forEach(t),Dvr=i(yl),ln=n(yl,"P",{});var sw=s(ln);Gvr=r(sw,"The model class to instantiate is selected based on the "),S2e=n(sw,"CODE",{});var Uvt=s(S2e);Ovr=r(Uvt,"model_type"),Uvt.forEach(t),Vvr=r(sw,` property of the config object (either
passed as an argument or loaded from `),R2e=n(sw,"CODE",{});var Jvt=s(R2e);Xvr=r(Jvt,"pretrained_model_name_or_path"),Jvt.forEach(t),zvr=r(sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B2e=n(sw,"CODE",{});var Yvt=s(B2e);Qvr=r(Yvt,"pretrained_model_name_or_path"),Yvt.forEach(t),Wvr=r(sw,":"),sw.forEach(t),Hvr=i(yl),_L=n(yl,"UL",{});var XNe=s(_L);IM=n(XNe,"LI",{});var ySe=s(IM);P2e=n(ySe,"STRONG",{});var Kvt=s(P2e);Uvr=r(Kvt,"bert"),Kvt.forEach(t),Jvr=r(ySe," \u2014 "),cH=n(ySe,"A",{href:!0});var Zvt=s(cH);Yvr=r(Zvt,"TFBertForNextSentencePrediction"),Zvt.forEach(t),Kvr=r(ySe," (BERT model)"),ySe.forEach(t),Zvr=i(XNe),qM=n(XNe,"LI",{});var LSe=s(qM);I2e=n(LSe,"STRONG",{});var eFt=s(I2e);eFr=r(eFt,"mobilebert"),eFt.forEach(t),oFr=r(LSe," \u2014 "),fH=n(LSe,"A",{href:!0});var oFt=s(fH);rFr=r(oFt,"TFMobileBertForNextSentencePrediction"),oFt.forEach(t),tFr=r(LSe," (MobileBERT model)"),LSe.forEach(t),XNe.forEach(t),aFr=i(yl),T(NM.$$.fragment,yl),yl.forEach(t),Al.forEach(t),NIe=i(f),fc=n(f,"H2",{class:!0});var zNe=s(fc);jM=n(zNe,"A",{id:!0,class:!0,href:!0});var rFt=s(jM);q2e=n(rFt,"SPAN",{});var tFt=s(q2e);T(bL.$$.fragment,tFt),tFt.forEach(t),rFt.forEach(t),nFr=i(zNe),N2e=n(zNe,"SPAN",{});var aFt=s(N2e);sFr=r(aFt,"TFAutoModelForTableQuestionAnswering"),aFt.forEach(t),zNe.forEach(t),jIe=i(f),sr=n(f,"DIV",{class:!0});var Ll=s(sr);T(vL.$$.fragment,Ll),lFr=i(Ll),mc=n(Ll,"P",{});var lZ=s(mc);iFr=r(lZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),mH=n(lZ,"A",{href:!0});var nFt=s(mH);dFr=r(nFt,"from_pretrained()"),nFt.forEach(t),cFr=r(lZ," class method or the "),gH=n(lZ,"A",{href:!0});var sFt=s(gH);fFr=r(sFt,"from_config()"),sFt.forEach(t),mFr=r(lZ,` class
method.`),lZ.forEach(t),gFr=i(Ll),FL=n(Ll,"P",{});var QNe=s(FL);hFr=r(QNe,"This class cannot be instantiated directly using "),j2e=n(QNe,"CODE",{});var lFt=s(j2e);pFr=r(lFt,"__init__()"),lFt.forEach(t),uFr=r(QNe," (throws an error)."),QNe.forEach(t),_Fr=i(Ll),Bt=n(Ll,"DIV",{class:!0});var lw=s(Bt);T(TL.$$.fragment,lw),bFr=i(lw),D2e=n(lw,"P",{});var iFt=s(D2e);vFr=r(iFt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),iFt.forEach(t),FFr=i(lw),gc=n(lw,"P",{});var iZ=s(gc);TFr=r(iZ,`Note:
Loading a model from its configuration file does `),G2e=n(iZ,"STRONG",{});var dFt=s(G2e);MFr=r(dFt,"not"),dFt.forEach(t),EFr=r(iZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hH=n(iZ,"A",{href:!0});var cFt=s(hH);CFr=r(cFt,"from_pretrained()"),cFt.forEach(t),wFr=r(iZ," to load the model weights."),iZ.forEach(t),AFr=i(lw),T(DM.$$.fragment,lw),lw.forEach(t),yFr=i(Ll),Br=n(Ll,"DIV",{class:!0});var xl=s(Br);T(ML.$$.fragment,xl),LFr=i(xl),O2e=n(xl,"P",{});var fFt=s(O2e);xFr=r(fFt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),fFt.forEach(t),$Fr=i(xl),dn=n(xl,"P",{});var iw=s(dn);kFr=r(iw,"The model class to instantiate is selected based on the "),V2e=n(iw,"CODE",{});var mFt=s(V2e);SFr=r(mFt,"model_type"),mFt.forEach(t),RFr=r(iw,` property of the config object (either
passed as an argument or loaded from `),X2e=n(iw,"CODE",{});var gFt=s(X2e);BFr=r(gFt,"pretrained_model_name_or_path"),gFt.forEach(t),PFr=r(iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z2e=n(iw,"CODE",{});var hFt=s(z2e);IFr=r(hFt,"pretrained_model_name_or_path"),hFt.forEach(t),qFr=r(iw,":"),iw.forEach(t),NFr=i(xl),Q2e=n(xl,"UL",{});var pFt=s(Q2e);GM=n(pFt,"LI",{});var xSe=s(GM);W2e=n(xSe,"STRONG",{});var uFt=s(W2e);jFr=r(uFt,"tapas"),uFt.forEach(t),DFr=r(xSe," \u2014 "),pH=n(xSe,"A",{href:!0});var _Ft=s(pH);GFr=r(_Ft,"TFTapasForQuestionAnswering"),_Ft.forEach(t),OFr=r(xSe," (TAPAS model)"),xSe.forEach(t),pFt.forEach(t),VFr=i(xl),T(OM.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),DIe=i(f),hc=n(f,"H2",{class:!0});var WNe=s(hc);VM=n(WNe,"A",{id:!0,class:!0,href:!0});var bFt=s(VM);H2e=n(bFt,"SPAN",{});var vFt=s(H2e);T(EL.$$.fragment,vFt),vFt.forEach(t),bFt.forEach(t),XFr=i(WNe),U2e=n(WNe,"SPAN",{});var FFt=s(U2e);zFr=r(FFt,"TFAutoModelForTokenClassification"),FFt.forEach(t),WNe.forEach(t),GIe=i(f),lr=n(f,"DIV",{class:!0});var $l=s(lr);T(CL.$$.fragment,$l),QFr=i($l),pc=n($l,"P",{});var dZ=s(pc);WFr=r(dZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),uH=n(dZ,"A",{href:!0});var TFt=s(uH);HFr=r(TFt,"from_pretrained()"),TFt.forEach(t),UFr=r(dZ," class method or the "),_H=n(dZ,"A",{href:!0});var MFt=s(_H);JFr=r(MFt,"from_config()"),MFt.forEach(t),YFr=r(dZ,` class
method.`),dZ.forEach(t),KFr=i($l),wL=n($l,"P",{});var HNe=s(wL);ZFr=r(HNe,"This class cannot be instantiated directly using "),J2e=n(HNe,"CODE",{});var EFt=s(J2e);e6r=r(EFt,"__init__()"),EFt.forEach(t),o6r=r(HNe," (throws an error)."),HNe.forEach(t),r6r=i($l),Pt=n($l,"DIV",{class:!0});var dw=s(Pt);T(AL.$$.fragment,dw),t6r=i(dw),Y2e=n(dw,"P",{});var CFt=s(Y2e);a6r=r(CFt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),CFt.forEach(t),n6r=i(dw),uc=n(dw,"P",{});var cZ=s(uc);s6r=r(cZ,`Note:
Loading a model from its configuration file does `),K2e=n(cZ,"STRONG",{});var wFt=s(K2e);l6r=r(wFt,"not"),wFt.forEach(t),i6r=r(cZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),bH=n(cZ,"A",{href:!0});var AFt=s(bH);d6r=r(AFt,"from_pretrained()"),AFt.forEach(t),c6r=r(cZ," to load the model weights."),cZ.forEach(t),f6r=i(dw),T(XM.$$.fragment,dw),dw.forEach(t),m6r=i($l),Pr=n($l,"DIV",{class:!0});var kl=s(Pr);T(yL.$$.fragment,kl),g6r=i(kl),Z2e=n(kl,"P",{});var yFt=s(Z2e);h6r=r(yFt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),yFt.forEach(t),p6r=i(kl),cn=n(kl,"P",{});var cw=s(cn);u6r=r(cw,"The model class to instantiate is selected based on the "),eve=n(cw,"CODE",{});var LFt=s(eve);_6r=r(LFt,"model_type"),LFt.forEach(t),b6r=r(cw,` property of the config object (either
passed as an argument or loaded from `),ove=n(cw,"CODE",{});var xFt=s(ove);v6r=r(xFt,"pretrained_model_name_or_path"),xFt.forEach(t),F6r=r(cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rve=n(cw,"CODE",{});var $Ft=s(rve);T6r=r($Ft,"pretrained_model_name_or_path"),$Ft.forEach(t),M6r=r(cw,":"),cw.forEach(t),E6r=i(kl),de=n(kl,"UL",{});var me=s(de);zM=n(me,"LI",{});var $Se=s(zM);tve=n($Se,"STRONG",{});var kFt=s(tve);C6r=r(kFt,"albert"),kFt.forEach(t),w6r=r($Se," \u2014 "),vH=n($Se,"A",{href:!0});var SFt=s(vH);A6r=r(SFt,"TFAlbertForTokenClassification"),SFt.forEach(t),y6r=r($Se," (ALBERT model)"),$Se.forEach(t),L6r=i(me),QM=n(me,"LI",{});var kSe=s(QM);ave=n(kSe,"STRONG",{});var RFt=s(ave);x6r=r(RFt,"bert"),RFt.forEach(t),$6r=r(kSe," \u2014 "),FH=n(kSe,"A",{href:!0});var BFt=s(FH);k6r=r(BFt,"TFBertForTokenClassification"),BFt.forEach(t),S6r=r(kSe," (BERT model)"),kSe.forEach(t),R6r=i(me),WM=n(me,"LI",{});var SSe=s(WM);nve=n(SSe,"STRONG",{});var PFt=s(nve);B6r=r(PFt,"camembert"),PFt.forEach(t),P6r=r(SSe," \u2014 "),TH=n(SSe,"A",{href:!0});var IFt=s(TH);I6r=r(IFt,"TFCamembertForTokenClassification"),IFt.forEach(t),q6r=r(SSe," (CamemBERT model)"),SSe.forEach(t),N6r=i(me),HM=n(me,"LI",{});var RSe=s(HM);sve=n(RSe,"STRONG",{});var qFt=s(sve);j6r=r(qFt,"convbert"),qFt.forEach(t),D6r=r(RSe," \u2014 "),MH=n(RSe,"A",{href:!0});var NFt=s(MH);G6r=r(NFt,"TFConvBertForTokenClassification"),NFt.forEach(t),O6r=r(RSe," (ConvBERT model)"),RSe.forEach(t),V6r=i(me),UM=n(me,"LI",{});var BSe=s(UM);lve=n(BSe,"STRONG",{});var jFt=s(lve);X6r=r(jFt,"deberta"),jFt.forEach(t),z6r=r(BSe," \u2014 "),EH=n(BSe,"A",{href:!0});var DFt=s(EH);Q6r=r(DFt,"TFDebertaForTokenClassification"),DFt.forEach(t),W6r=r(BSe," (DeBERTa model)"),BSe.forEach(t),H6r=i(me),JM=n(me,"LI",{});var PSe=s(JM);ive=n(PSe,"STRONG",{});var GFt=s(ive);U6r=r(GFt,"deberta-v2"),GFt.forEach(t),J6r=r(PSe," \u2014 "),CH=n(PSe,"A",{href:!0});var OFt=s(CH);Y6r=r(OFt,"TFDebertaV2ForTokenClassification"),OFt.forEach(t),K6r=r(PSe," (DeBERTa-v2 model)"),PSe.forEach(t),Z6r=i(me),YM=n(me,"LI",{});var ISe=s(YM);dve=n(ISe,"STRONG",{});var VFt=s(dve);eTr=r(VFt,"distilbert"),VFt.forEach(t),oTr=r(ISe," \u2014 "),wH=n(ISe,"A",{href:!0});var XFt=s(wH);rTr=r(XFt,"TFDistilBertForTokenClassification"),XFt.forEach(t),tTr=r(ISe," (DistilBERT model)"),ISe.forEach(t),aTr=i(me),KM=n(me,"LI",{});var qSe=s(KM);cve=n(qSe,"STRONG",{});var zFt=s(cve);nTr=r(zFt,"electra"),zFt.forEach(t),sTr=r(qSe," \u2014 "),AH=n(qSe,"A",{href:!0});var QFt=s(AH);lTr=r(QFt,"TFElectraForTokenClassification"),QFt.forEach(t),iTr=r(qSe," (ELECTRA model)"),qSe.forEach(t),dTr=i(me),ZM=n(me,"LI",{});var NSe=s(ZM);fve=n(NSe,"STRONG",{});var WFt=s(fve);cTr=r(WFt,"flaubert"),WFt.forEach(t),fTr=r(NSe," \u2014 "),yH=n(NSe,"A",{href:!0});var HFt=s(yH);mTr=r(HFt,"TFFlaubertForTokenClassification"),HFt.forEach(t),gTr=r(NSe," (FlauBERT model)"),NSe.forEach(t),hTr=i(me),e4=n(me,"LI",{});var jSe=s(e4);mve=n(jSe,"STRONG",{});var UFt=s(mve);pTr=r(UFt,"funnel"),UFt.forEach(t),uTr=r(jSe," \u2014 "),LH=n(jSe,"A",{href:!0});var JFt=s(LH);_Tr=r(JFt,"TFFunnelForTokenClassification"),JFt.forEach(t),bTr=r(jSe," (Funnel Transformer model)"),jSe.forEach(t),vTr=i(me),o4=n(me,"LI",{});var DSe=s(o4);gve=n(DSe,"STRONG",{});var YFt=s(gve);FTr=r(YFt,"layoutlm"),YFt.forEach(t),TTr=r(DSe," \u2014 "),xH=n(DSe,"A",{href:!0});var KFt=s(xH);MTr=r(KFt,"TFLayoutLMForTokenClassification"),KFt.forEach(t),ETr=r(DSe," (LayoutLM model)"),DSe.forEach(t),CTr=i(me),r4=n(me,"LI",{});var GSe=s(r4);hve=n(GSe,"STRONG",{});var ZFt=s(hve);wTr=r(ZFt,"longformer"),ZFt.forEach(t),ATr=r(GSe," \u2014 "),$H=n(GSe,"A",{href:!0});var e6t=s($H);yTr=r(e6t,"TFLongformerForTokenClassification"),e6t.forEach(t),LTr=r(GSe," (Longformer model)"),GSe.forEach(t),xTr=i(me),t4=n(me,"LI",{});var OSe=s(t4);pve=n(OSe,"STRONG",{});var o6t=s(pve);$Tr=r(o6t,"mobilebert"),o6t.forEach(t),kTr=r(OSe," \u2014 "),kH=n(OSe,"A",{href:!0});var r6t=s(kH);STr=r(r6t,"TFMobileBertForTokenClassification"),r6t.forEach(t),RTr=r(OSe," (MobileBERT model)"),OSe.forEach(t),BTr=i(me),a4=n(me,"LI",{});var VSe=s(a4);uve=n(VSe,"STRONG",{});var t6t=s(uve);PTr=r(t6t,"mpnet"),t6t.forEach(t),ITr=r(VSe," \u2014 "),SH=n(VSe,"A",{href:!0});var a6t=s(SH);qTr=r(a6t,"TFMPNetForTokenClassification"),a6t.forEach(t),NTr=r(VSe," (MPNet model)"),VSe.forEach(t),jTr=i(me),n4=n(me,"LI",{});var XSe=s(n4);_ve=n(XSe,"STRONG",{});var n6t=s(_ve);DTr=r(n6t,"rembert"),n6t.forEach(t),GTr=r(XSe," \u2014 "),RH=n(XSe,"A",{href:!0});var s6t=s(RH);OTr=r(s6t,"TFRemBertForTokenClassification"),s6t.forEach(t),VTr=r(XSe," (RemBERT model)"),XSe.forEach(t),XTr=i(me),s4=n(me,"LI",{});var zSe=s(s4);bve=n(zSe,"STRONG",{});var l6t=s(bve);zTr=r(l6t,"roberta"),l6t.forEach(t),QTr=r(zSe," \u2014 "),BH=n(zSe,"A",{href:!0});var i6t=s(BH);WTr=r(i6t,"TFRobertaForTokenClassification"),i6t.forEach(t),HTr=r(zSe," (RoBERTa model)"),zSe.forEach(t),UTr=i(me),l4=n(me,"LI",{});var QSe=s(l4);vve=n(QSe,"STRONG",{});var d6t=s(vve);JTr=r(d6t,"roformer"),d6t.forEach(t),YTr=r(QSe," \u2014 "),PH=n(QSe,"A",{href:!0});var c6t=s(PH);KTr=r(c6t,"TFRoFormerForTokenClassification"),c6t.forEach(t),ZTr=r(QSe," (RoFormer model)"),QSe.forEach(t),e9r=i(me),i4=n(me,"LI",{});var WSe=s(i4);Fve=n(WSe,"STRONG",{});var f6t=s(Fve);o9r=r(f6t,"xlm"),f6t.forEach(t),r9r=r(WSe," \u2014 "),IH=n(WSe,"A",{href:!0});var m6t=s(IH);t9r=r(m6t,"TFXLMForTokenClassification"),m6t.forEach(t),a9r=r(WSe," (XLM model)"),WSe.forEach(t),n9r=i(me),d4=n(me,"LI",{});var HSe=s(d4);Tve=n(HSe,"STRONG",{});var g6t=s(Tve);s9r=r(g6t,"xlm-roberta"),g6t.forEach(t),l9r=r(HSe," \u2014 "),qH=n(HSe,"A",{href:!0});var h6t=s(qH);i9r=r(h6t,"TFXLMRobertaForTokenClassification"),h6t.forEach(t),d9r=r(HSe," (XLM-RoBERTa model)"),HSe.forEach(t),c9r=i(me),c4=n(me,"LI",{});var USe=s(c4);Mve=n(USe,"STRONG",{});var p6t=s(Mve);f9r=r(p6t,"xlnet"),p6t.forEach(t),m9r=r(USe," \u2014 "),NH=n(USe,"A",{href:!0});var u6t=s(NH);g9r=r(u6t,"TFXLNetForTokenClassification"),u6t.forEach(t),h9r=r(USe," (XLNet model)"),USe.forEach(t),me.forEach(t),p9r=i(kl),T(f4.$$.fragment,kl),kl.forEach(t),$l.forEach(t),OIe=i(f),_c=n(f,"H2",{class:!0});var UNe=s(_c);m4=n(UNe,"A",{id:!0,class:!0,href:!0});var _6t=s(m4);Eve=n(_6t,"SPAN",{});var b6t=s(Eve);T(LL.$$.fragment,b6t),b6t.forEach(t),_6t.forEach(t),u9r=i(UNe),Cve=n(UNe,"SPAN",{});var v6t=s(Cve);_9r=r(v6t,"TFAutoModelForQuestionAnswering"),v6t.forEach(t),UNe.forEach(t),VIe=i(f),ir=n(f,"DIV",{class:!0});var Sl=s(ir);T(xL.$$.fragment,Sl),b9r=i(Sl),bc=n(Sl,"P",{});var fZ=s(bc);v9r=r(fZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jH=n(fZ,"A",{href:!0});var F6t=s(jH);F9r=r(F6t,"from_pretrained()"),F6t.forEach(t),T9r=r(fZ," class method or the "),DH=n(fZ,"A",{href:!0});var T6t=s(DH);M9r=r(T6t,"from_config()"),T6t.forEach(t),E9r=r(fZ,` class
method.`),fZ.forEach(t),C9r=i(Sl),$L=n(Sl,"P",{});var JNe=s($L);w9r=r(JNe,"This class cannot be instantiated directly using "),wve=n(JNe,"CODE",{});var M6t=s(wve);A9r=r(M6t,"__init__()"),M6t.forEach(t),y9r=r(JNe," (throws an error)."),JNe.forEach(t),L9r=i(Sl),It=n(Sl,"DIV",{class:!0});var fw=s(It);T(kL.$$.fragment,fw),x9r=i(fw),Ave=n(fw,"P",{});var E6t=s(Ave);$9r=r(E6t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),E6t.forEach(t),k9r=i(fw),vc=n(fw,"P",{});var mZ=s(vc);S9r=r(mZ,`Note:
Loading a model from its configuration file does `),yve=n(mZ,"STRONG",{});var C6t=s(yve);R9r=r(C6t,"not"),C6t.forEach(t),B9r=r(mZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),GH=n(mZ,"A",{href:!0});var w6t=s(GH);P9r=r(w6t,"from_pretrained()"),w6t.forEach(t),I9r=r(mZ," to load the model weights."),mZ.forEach(t),q9r=i(fw),T(g4.$$.fragment,fw),fw.forEach(t),N9r=i(Sl),Ir=n(Sl,"DIV",{class:!0});var Rl=s(Ir);T(SL.$$.fragment,Rl),j9r=i(Rl),Lve=n(Rl,"P",{});var A6t=s(Lve);D9r=r(A6t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),A6t.forEach(t),G9r=i(Rl),fn=n(Rl,"P",{});var mw=s(fn);O9r=r(mw,"The model class to instantiate is selected based on the "),xve=n(mw,"CODE",{});var y6t=s(xve);V9r=r(y6t,"model_type"),y6t.forEach(t),X9r=r(mw,` property of the config object (either
passed as an argument or loaded from `),$ve=n(mw,"CODE",{});var L6t=s($ve);z9r=r(L6t,"pretrained_model_name_or_path"),L6t.forEach(t),Q9r=r(mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kve=n(mw,"CODE",{});var x6t=s(kve);W9r=r(x6t,"pretrained_model_name_or_path"),x6t.forEach(t),H9r=r(mw,":"),mw.forEach(t),U9r=i(Rl),ce=n(Rl,"UL",{});var ge=s(ce);h4=n(ge,"LI",{});var JSe=s(h4);Sve=n(JSe,"STRONG",{});var $6t=s(Sve);J9r=r($6t,"albert"),$6t.forEach(t),Y9r=r(JSe," \u2014 "),OH=n(JSe,"A",{href:!0});var k6t=s(OH);K9r=r(k6t,"TFAlbertForQuestionAnswering"),k6t.forEach(t),Z9r=r(JSe," (ALBERT model)"),JSe.forEach(t),eMr=i(ge),p4=n(ge,"LI",{});var YSe=s(p4);Rve=n(YSe,"STRONG",{});var S6t=s(Rve);oMr=r(S6t,"bert"),S6t.forEach(t),rMr=r(YSe," \u2014 "),VH=n(YSe,"A",{href:!0});var R6t=s(VH);tMr=r(R6t,"TFBertForQuestionAnswering"),R6t.forEach(t),aMr=r(YSe," (BERT model)"),YSe.forEach(t),nMr=i(ge),u4=n(ge,"LI",{});var KSe=s(u4);Bve=n(KSe,"STRONG",{});var B6t=s(Bve);sMr=r(B6t,"camembert"),B6t.forEach(t),lMr=r(KSe," \u2014 "),XH=n(KSe,"A",{href:!0});var P6t=s(XH);iMr=r(P6t,"TFCamembertForQuestionAnswering"),P6t.forEach(t),dMr=r(KSe," (CamemBERT model)"),KSe.forEach(t),cMr=i(ge),_4=n(ge,"LI",{});var ZSe=s(_4);Pve=n(ZSe,"STRONG",{});var I6t=s(Pve);fMr=r(I6t,"convbert"),I6t.forEach(t),mMr=r(ZSe," \u2014 "),zH=n(ZSe,"A",{href:!0});var q6t=s(zH);gMr=r(q6t,"TFConvBertForQuestionAnswering"),q6t.forEach(t),hMr=r(ZSe," (ConvBERT model)"),ZSe.forEach(t),pMr=i(ge),b4=n(ge,"LI",{});var eRe=s(b4);Ive=n(eRe,"STRONG",{});var N6t=s(Ive);uMr=r(N6t,"deberta"),N6t.forEach(t),_Mr=r(eRe," \u2014 "),QH=n(eRe,"A",{href:!0});var j6t=s(QH);bMr=r(j6t,"TFDebertaForQuestionAnswering"),j6t.forEach(t),vMr=r(eRe," (DeBERTa model)"),eRe.forEach(t),FMr=i(ge),v4=n(ge,"LI",{});var oRe=s(v4);qve=n(oRe,"STRONG",{});var D6t=s(qve);TMr=r(D6t,"deberta-v2"),D6t.forEach(t),MMr=r(oRe," \u2014 "),WH=n(oRe,"A",{href:!0});var G6t=s(WH);EMr=r(G6t,"TFDebertaV2ForQuestionAnswering"),G6t.forEach(t),CMr=r(oRe," (DeBERTa-v2 model)"),oRe.forEach(t),wMr=i(ge),F4=n(ge,"LI",{});var rRe=s(F4);Nve=n(rRe,"STRONG",{});var O6t=s(Nve);AMr=r(O6t,"distilbert"),O6t.forEach(t),yMr=r(rRe," \u2014 "),HH=n(rRe,"A",{href:!0});var V6t=s(HH);LMr=r(V6t,"TFDistilBertForQuestionAnswering"),V6t.forEach(t),xMr=r(rRe," (DistilBERT model)"),rRe.forEach(t),$Mr=i(ge),T4=n(ge,"LI",{});var tRe=s(T4);jve=n(tRe,"STRONG",{});var X6t=s(jve);kMr=r(X6t,"electra"),X6t.forEach(t),SMr=r(tRe," \u2014 "),UH=n(tRe,"A",{href:!0});var z6t=s(UH);RMr=r(z6t,"TFElectraForQuestionAnswering"),z6t.forEach(t),BMr=r(tRe," (ELECTRA model)"),tRe.forEach(t),PMr=i(ge),M4=n(ge,"LI",{});var aRe=s(M4);Dve=n(aRe,"STRONG",{});var Q6t=s(Dve);IMr=r(Q6t,"flaubert"),Q6t.forEach(t),qMr=r(aRe," \u2014 "),JH=n(aRe,"A",{href:!0});var W6t=s(JH);NMr=r(W6t,"TFFlaubertForQuestionAnsweringSimple"),W6t.forEach(t),jMr=r(aRe," (FlauBERT model)"),aRe.forEach(t),DMr=i(ge),E4=n(ge,"LI",{});var nRe=s(E4);Gve=n(nRe,"STRONG",{});var H6t=s(Gve);GMr=r(H6t,"funnel"),H6t.forEach(t),OMr=r(nRe," \u2014 "),YH=n(nRe,"A",{href:!0});var U6t=s(YH);VMr=r(U6t,"TFFunnelForQuestionAnswering"),U6t.forEach(t),XMr=r(nRe," (Funnel Transformer model)"),nRe.forEach(t),zMr=i(ge),C4=n(ge,"LI",{});var sRe=s(C4);Ove=n(sRe,"STRONG",{});var J6t=s(Ove);QMr=r(J6t,"gptj"),J6t.forEach(t),WMr=r(sRe," \u2014 "),KH=n(sRe,"A",{href:!0});var Y6t=s(KH);HMr=r(Y6t,"TFGPTJForQuestionAnswering"),Y6t.forEach(t),UMr=r(sRe," (GPT-J model)"),sRe.forEach(t),JMr=i(ge),w4=n(ge,"LI",{});var lRe=s(w4);Vve=n(lRe,"STRONG",{});var K6t=s(Vve);YMr=r(K6t,"longformer"),K6t.forEach(t),KMr=r(lRe," \u2014 "),ZH=n(lRe,"A",{href:!0});var Z6t=s(ZH);ZMr=r(Z6t,"TFLongformerForQuestionAnswering"),Z6t.forEach(t),e4r=r(lRe," (Longformer model)"),lRe.forEach(t),o4r=i(ge),A4=n(ge,"LI",{});var iRe=s(A4);Xve=n(iRe,"STRONG",{});var eTt=s(Xve);r4r=r(eTt,"mobilebert"),eTt.forEach(t),t4r=r(iRe," \u2014 "),eU=n(iRe,"A",{href:!0});var oTt=s(eU);a4r=r(oTt,"TFMobileBertForQuestionAnswering"),oTt.forEach(t),n4r=r(iRe," (MobileBERT model)"),iRe.forEach(t),s4r=i(ge),y4=n(ge,"LI",{});var dRe=s(y4);zve=n(dRe,"STRONG",{});var rTt=s(zve);l4r=r(rTt,"mpnet"),rTt.forEach(t),i4r=r(dRe," \u2014 "),oU=n(dRe,"A",{href:!0});var tTt=s(oU);d4r=r(tTt,"TFMPNetForQuestionAnswering"),tTt.forEach(t),c4r=r(dRe," (MPNet model)"),dRe.forEach(t),f4r=i(ge),L4=n(ge,"LI",{});var cRe=s(L4);Qve=n(cRe,"STRONG",{});var aTt=s(Qve);m4r=r(aTt,"rembert"),aTt.forEach(t),g4r=r(cRe," \u2014 "),rU=n(cRe,"A",{href:!0});var nTt=s(rU);h4r=r(nTt,"TFRemBertForQuestionAnswering"),nTt.forEach(t),p4r=r(cRe," (RemBERT model)"),cRe.forEach(t),u4r=i(ge),x4=n(ge,"LI",{});var fRe=s(x4);Wve=n(fRe,"STRONG",{});var sTt=s(Wve);_4r=r(sTt,"roberta"),sTt.forEach(t),b4r=r(fRe," \u2014 "),tU=n(fRe,"A",{href:!0});var lTt=s(tU);v4r=r(lTt,"TFRobertaForQuestionAnswering"),lTt.forEach(t),F4r=r(fRe," (RoBERTa model)"),fRe.forEach(t),T4r=i(ge),$4=n(ge,"LI",{});var mRe=s($4);Hve=n(mRe,"STRONG",{});var iTt=s(Hve);M4r=r(iTt,"roformer"),iTt.forEach(t),E4r=r(mRe," \u2014 "),aU=n(mRe,"A",{href:!0});var dTt=s(aU);C4r=r(dTt,"TFRoFormerForQuestionAnswering"),dTt.forEach(t),w4r=r(mRe," (RoFormer model)"),mRe.forEach(t),A4r=i(ge),k4=n(ge,"LI",{});var gRe=s(k4);Uve=n(gRe,"STRONG",{});var cTt=s(Uve);y4r=r(cTt,"xlm"),cTt.forEach(t),L4r=r(gRe," \u2014 "),nU=n(gRe,"A",{href:!0});var fTt=s(nU);x4r=r(fTt,"TFXLMForQuestionAnsweringSimple"),fTt.forEach(t),$4r=r(gRe," (XLM model)"),gRe.forEach(t),k4r=i(ge),S4=n(ge,"LI",{});var hRe=s(S4);Jve=n(hRe,"STRONG",{});var mTt=s(Jve);S4r=r(mTt,"xlm-roberta"),mTt.forEach(t),R4r=r(hRe," \u2014 "),sU=n(hRe,"A",{href:!0});var gTt=s(sU);B4r=r(gTt,"TFXLMRobertaForQuestionAnswering"),gTt.forEach(t),P4r=r(hRe," (XLM-RoBERTa model)"),hRe.forEach(t),I4r=i(ge),R4=n(ge,"LI",{});var pRe=s(R4);Yve=n(pRe,"STRONG",{});var hTt=s(Yve);q4r=r(hTt,"xlnet"),hTt.forEach(t),N4r=r(pRe," \u2014 "),lU=n(pRe,"A",{href:!0});var pTt=s(lU);j4r=r(pTt,"TFXLNetForQuestionAnsweringSimple"),pTt.forEach(t),D4r=r(pRe," (XLNet model)"),pRe.forEach(t),ge.forEach(t),G4r=i(Rl),T(B4.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),XIe=i(f),Fc=n(f,"H2",{class:!0});var YNe=s(Fc);P4=n(YNe,"A",{id:!0,class:!0,href:!0});var uTt=s(P4);Kve=n(uTt,"SPAN",{});var _Tt=s(Kve);T(RL.$$.fragment,_Tt),_Tt.forEach(t),uTt.forEach(t),O4r=i(YNe),Zve=n(YNe,"SPAN",{});var bTt=s(Zve);V4r=r(bTt,"TFAutoModelForVision2Seq"),bTt.forEach(t),YNe.forEach(t),zIe=i(f),dr=n(f,"DIV",{class:!0});var Bl=s(dr);T(BL.$$.fragment,Bl),X4r=i(Bl),Tc=n(Bl,"P",{});var gZ=s(Tc);z4r=r(gZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),iU=n(gZ,"A",{href:!0});var vTt=s(iU);Q4r=r(vTt,"from_pretrained()"),vTt.forEach(t),W4r=r(gZ," class method or the "),dU=n(gZ,"A",{href:!0});var FTt=s(dU);H4r=r(FTt,"from_config()"),FTt.forEach(t),U4r=r(gZ,` class
method.`),gZ.forEach(t),J4r=i(Bl),PL=n(Bl,"P",{});var KNe=s(PL);Y4r=r(KNe,"This class cannot be instantiated directly using "),eFe=n(KNe,"CODE",{});var TTt=s(eFe);K4r=r(TTt,"__init__()"),TTt.forEach(t),Z4r=r(KNe," (throws an error)."),KNe.forEach(t),eEr=i(Bl),qt=n(Bl,"DIV",{class:!0});var gw=s(qt);T(IL.$$.fragment,gw),oEr=i(gw),oFe=n(gw,"P",{});var MTt=s(oFe);rEr=r(MTt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),MTt.forEach(t),tEr=i(gw),Mc=n(gw,"P",{});var hZ=s(Mc);aEr=r(hZ,`Note:
Loading a model from its configuration file does `),rFe=n(hZ,"STRONG",{});var ETt=s(rFe);nEr=r(ETt,"not"),ETt.forEach(t),sEr=r(hZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),cU=n(hZ,"A",{href:!0});var CTt=s(cU);lEr=r(CTt,"from_pretrained()"),CTt.forEach(t),iEr=r(hZ," to load the model weights."),hZ.forEach(t),dEr=i(gw),T(I4.$$.fragment,gw),gw.forEach(t),cEr=i(Bl),qr=n(Bl,"DIV",{class:!0});var Pl=s(qr);T(qL.$$.fragment,Pl),fEr=i(Pl),tFe=n(Pl,"P",{});var wTt=s(tFe);mEr=r(wTt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),wTt.forEach(t),gEr=i(Pl),mn=n(Pl,"P",{});var hw=s(mn);hEr=r(hw,"The model class to instantiate is selected based on the "),aFe=n(hw,"CODE",{});var ATt=s(aFe);pEr=r(ATt,"model_type"),ATt.forEach(t),uEr=r(hw,` property of the config object (either
passed as an argument or loaded from `),nFe=n(hw,"CODE",{});var yTt=s(nFe);_Er=r(yTt,"pretrained_model_name_or_path"),yTt.forEach(t),bEr=r(hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=n(hw,"CODE",{});var LTt=s(sFe);vEr=r(LTt,"pretrained_model_name_or_path"),LTt.forEach(t),FEr=r(hw,":"),hw.forEach(t),TEr=i(Pl),lFe=n(Pl,"UL",{});var xTt=s(lFe);q4=n(xTt,"LI",{});var uRe=s(q4);iFe=n(uRe,"STRONG",{});var $Tt=s(iFe);MEr=r($Tt,"vision-encoder-decoder"),$Tt.forEach(t),EEr=r(uRe," \u2014 "),fU=n(uRe,"A",{href:!0});var kTt=s(fU);CEr=r(kTt,"TFVisionEncoderDecoderModel"),kTt.forEach(t),wEr=r(uRe," (Vision Encoder decoder model)"),uRe.forEach(t),xTt.forEach(t),AEr=i(Pl),T(N4.$$.fragment,Pl),Pl.forEach(t),Bl.forEach(t),QIe=i(f),Ec=n(f,"H2",{class:!0});var ZNe=s(Ec);j4=n(ZNe,"A",{id:!0,class:!0,href:!0});var STt=s(j4);dFe=n(STt,"SPAN",{});var RTt=s(dFe);T(NL.$$.fragment,RTt),RTt.forEach(t),STt.forEach(t),yEr=i(ZNe),cFe=n(ZNe,"SPAN",{});var BTt=s(cFe);LEr=r(BTt,"TFAutoModelForSpeechSeq2Seq"),BTt.forEach(t),ZNe.forEach(t),WIe=i(f),cr=n(f,"DIV",{class:!0});var Il=s(cr);T(jL.$$.fragment,Il),xEr=i(Il),Cc=n(Il,"P",{});var pZ=s(Cc);$Er=r(pZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),mU=n(pZ,"A",{href:!0});var PTt=s(mU);kEr=r(PTt,"from_pretrained()"),PTt.forEach(t),SEr=r(pZ," class method or the "),gU=n(pZ,"A",{href:!0});var ITt=s(gU);REr=r(ITt,"from_config()"),ITt.forEach(t),BEr=r(pZ,` class
method.`),pZ.forEach(t),PEr=i(Il),DL=n(Il,"P",{});var eje=s(DL);IEr=r(eje,"This class cannot be instantiated directly using "),fFe=n(eje,"CODE",{});var qTt=s(fFe);qEr=r(qTt,"__init__()"),qTt.forEach(t),NEr=r(eje," (throws an error)."),eje.forEach(t),jEr=i(Il),Nt=n(Il,"DIV",{class:!0});var pw=s(Nt);T(GL.$$.fragment,pw),DEr=i(pw),mFe=n(pw,"P",{});var NTt=s(mFe);GEr=r(NTt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),NTt.forEach(t),OEr=i(pw),wc=n(pw,"P",{});var uZ=s(wc);VEr=r(uZ,`Note:
Loading a model from its configuration file does `),gFe=n(uZ,"STRONG",{});var jTt=s(gFe);XEr=r(jTt,"not"),jTt.forEach(t),zEr=r(uZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hU=n(uZ,"A",{href:!0});var DTt=s(hU);QEr=r(DTt,"from_pretrained()"),DTt.forEach(t),WEr=r(uZ," to load the model weights."),uZ.forEach(t),HEr=i(pw),T(D4.$$.fragment,pw),pw.forEach(t),UEr=i(Il),Nr=n(Il,"DIV",{class:!0});var ql=s(Nr);T(OL.$$.fragment,ql),JEr=i(ql),hFe=n(ql,"P",{});var GTt=s(hFe);YEr=r(GTt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),GTt.forEach(t),KEr=i(ql),gn=n(ql,"P",{});var uw=s(gn);ZEr=r(uw,"The model class to instantiate is selected based on the "),pFe=n(uw,"CODE",{});var OTt=s(pFe);e5r=r(OTt,"model_type"),OTt.forEach(t),o5r=r(uw,` property of the config object (either
passed as an argument or loaded from `),uFe=n(uw,"CODE",{});var VTt=s(uFe);r5r=r(VTt,"pretrained_model_name_or_path"),VTt.forEach(t),t5r=r(uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Fe=n(uw,"CODE",{});var XTt=s(_Fe);a5r=r(XTt,"pretrained_model_name_or_path"),XTt.forEach(t),n5r=r(uw,":"),uw.forEach(t),s5r=i(ql),bFe=n(ql,"UL",{});var zTt=s(bFe);G4=n(zTt,"LI",{});var _Re=s(G4);vFe=n(_Re,"STRONG",{});var QTt=s(vFe);l5r=r(QTt,"speech_to_text"),QTt.forEach(t),i5r=r(_Re," \u2014 "),pU=n(_Re,"A",{href:!0});var WTt=s(pU);d5r=r(WTt,"TFSpeech2TextForConditionalGeneration"),WTt.forEach(t),c5r=r(_Re," (Speech2Text model)"),_Re.forEach(t),zTt.forEach(t),f5r=i(ql),T(O4.$$.fragment,ql),ql.forEach(t),Il.forEach(t),HIe=i(f),Ac=n(f,"H2",{class:!0});var oje=s(Ac);V4=n(oje,"A",{id:!0,class:!0,href:!0});var HTt=s(V4);FFe=n(HTt,"SPAN",{});var UTt=s(FFe);T(VL.$$.fragment,UTt),UTt.forEach(t),HTt.forEach(t),m5r=i(oje),TFe=n(oje,"SPAN",{});var JTt=s(TFe);g5r=r(JTt,"FlaxAutoModel"),JTt.forEach(t),oje.forEach(t),UIe=i(f),fr=n(f,"DIV",{class:!0});var Nl=s(fr);T(XL.$$.fragment,Nl),h5r=i(Nl),yc=n(Nl,"P",{});var _Z=s(yc);p5r=r(_Z,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),uU=n(_Z,"A",{href:!0});var YTt=s(uU);u5r=r(YTt,"from_pretrained()"),YTt.forEach(t),_5r=r(_Z," class method or the "),_U=n(_Z,"A",{href:!0});var KTt=s(_U);b5r=r(KTt,"from_config()"),KTt.forEach(t),v5r=r(_Z,` class
method.`),_Z.forEach(t),F5r=i(Nl),zL=n(Nl,"P",{});var rje=s(zL);T5r=r(rje,"This class cannot be instantiated directly using "),MFe=n(rje,"CODE",{});var ZTt=s(MFe);M5r=r(ZTt,"__init__()"),ZTt.forEach(t),E5r=r(rje," (throws an error)."),rje.forEach(t),C5r=i(Nl),jt=n(Nl,"DIV",{class:!0});var _w=s(jt);T(QL.$$.fragment,_w),w5r=i(_w),EFe=n(_w,"P",{});var e9t=s(EFe);A5r=r(e9t,"Instantiates one of the base model classes of the library from a configuration."),e9t.forEach(t),y5r=i(_w),Lc=n(_w,"P",{});var bZ=s(Lc);L5r=r(bZ,`Note:
Loading a model from its configuration file does `),CFe=n(bZ,"STRONG",{});var o9t=s(CFe);x5r=r(o9t,"not"),o9t.forEach(t),$5r=r(bZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),bU=n(bZ,"A",{href:!0});var r9t=s(bU);k5r=r(r9t,"from_pretrained()"),r9t.forEach(t),S5r=r(bZ," to load the model weights."),bZ.forEach(t),R5r=i(_w),T(X4.$$.fragment,_w),_w.forEach(t),B5r=i(Nl),jr=n(Nl,"DIV",{class:!0});var jl=s(jr);T(WL.$$.fragment,jl),P5r=i(jl),wFe=n(jl,"P",{});var t9t=s(wFe);I5r=r(t9t,"Instantiate one of the base model classes of the library from a pretrained model."),t9t.forEach(t),q5r=i(jl),hn=n(jl,"P",{});var bw=s(hn);N5r=r(bw,"The model class to instantiate is selected based on the "),AFe=n(bw,"CODE",{});var a9t=s(AFe);j5r=r(a9t,"model_type"),a9t.forEach(t),D5r=r(bw,` property of the config object (either
passed as an argument or loaded from `),yFe=n(bw,"CODE",{});var n9t=s(yFe);G5r=r(n9t,"pretrained_model_name_or_path"),n9t.forEach(t),O5r=r(bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LFe=n(bw,"CODE",{});var s9t=s(LFe);V5r=r(s9t,"pretrained_model_name_or_path"),s9t.forEach(t),X5r=r(bw,":"),bw.forEach(t),z5r=i(jl),oe=n(jl,"UL",{});var ae=s(oe);z4=n(ae,"LI",{});var bRe=s(z4);xFe=n(bRe,"STRONG",{});var l9t=s(xFe);Q5r=r(l9t,"albert"),l9t.forEach(t),W5r=r(bRe," \u2014 "),vU=n(bRe,"A",{href:!0});var i9t=s(vU);H5r=r(i9t,"FlaxAlbertModel"),i9t.forEach(t),U5r=r(bRe," (ALBERT model)"),bRe.forEach(t),J5r=i(ae),Q4=n(ae,"LI",{});var vRe=s(Q4);$Fe=n(vRe,"STRONG",{});var d9t=s($Fe);Y5r=r(d9t,"bart"),d9t.forEach(t),K5r=r(vRe," \u2014 "),FU=n(vRe,"A",{href:!0});var c9t=s(FU);Z5r=r(c9t,"FlaxBartModel"),c9t.forEach(t),eCr=r(vRe," (BART model)"),vRe.forEach(t),oCr=i(ae),W4=n(ae,"LI",{});var FRe=s(W4);kFe=n(FRe,"STRONG",{});var f9t=s(kFe);rCr=r(f9t,"beit"),f9t.forEach(t),tCr=r(FRe," \u2014 "),TU=n(FRe,"A",{href:!0});var m9t=s(TU);aCr=r(m9t,"FlaxBeitModel"),m9t.forEach(t),nCr=r(FRe," (BEiT model)"),FRe.forEach(t),sCr=i(ae),H4=n(ae,"LI",{});var TRe=s(H4);SFe=n(TRe,"STRONG",{});var g9t=s(SFe);lCr=r(g9t,"bert"),g9t.forEach(t),iCr=r(TRe," \u2014 "),MU=n(TRe,"A",{href:!0});var h9t=s(MU);dCr=r(h9t,"FlaxBertModel"),h9t.forEach(t),cCr=r(TRe," (BERT model)"),TRe.forEach(t),fCr=i(ae),U4=n(ae,"LI",{});var MRe=s(U4);RFe=n(MRe,"STRONG",{});var p9t=s(RFe);mCr=r(p9t,"big_bird"),p9t.forEach(t),gCr=r(MRe," \u2014 "),EU=n(MRe,"A",{href:!0});var u9t=s(EU);hCr=r(u9t,"FlaxBigBirdModel"),u9t.forEach(t),pCr=r(MRe," (BigBird model)"),MRe.forEach(t),uCr=i(ae),J4=n(ae,"LI",{});var ERe=s(J4);BFe=n(ERe,"STRONG",{});var _9t=s(BFe);_Cr=r(_9t,"blenderbot"),_9t.forEach(t),bCr=r(ERe," \u2014 "),CU=n(ERe,"A",{href:!0});var b9t=s(CU);vCr=r(b9t,"FlaxBlenderbotModel"),b9t.forEach(t),FCr=r(ERe," (Blenderbot model)"),ERe.forEach(t),TCr=i(ae),Y4=n(ae,"LI",{});var CRe=s(Y4);PFe=n(CRe,"STRONG",{});var v9t=s(PFe);MCr=r(v9t,"blenderbot-small"),v9t.forEach(t),ECr=r(CRe," \u2014 "),wU=n(CRe,"A",{href:!0});var F9t=s(wU);CCr=r(F9t,"FlaxBlenderbotSmallModel"),F9t.forEach(t),wCr=r(CRe," (BlenderbotSmall model)"),CRe.forEach(t),ACr=i(ae),K4=n(ae,"LI",{});var wRe=s(K4);IFe=n(wRe,"STRONG",{});var T9t=s(IFe);yCr=r(T9t,"clip"),T9t.forEach(t),LCr=r(wRe," \u2014 "),AU=n(wRe,"A",{href:!0});var M9t=s(AU);xCr=r(M9t,"FlaxCLIPModel"),M9t.forEach(t),$Cr=r(wRe," (CLIP model)"),wRe.forEach(t),kCr=i(ae),Z4=n(ae,"LI",{});var ARe=s(Z4);qFe=n(ARe,"STRONG",{});var E9t=s(qFe);SCr=r(E9t,"distilbert"),E9t.forEach(t),RCr=r(ARe," \u2014 "),yU=n(ARe,"A",{href:!0});var C9t=s(yU);BCr=r(C9t,"FlaxDistilBertModel"),C9t.forEach(t),PCr=r(ARe," (DistilBERT model)"),ARe.forEach(t),ICr=i(ae),eE=n(ae,"LI",{});var yRe=s(eE);NFe=n(yRe,"STRONG",{});var w9t=s(NFe);qCr=r(w9t,"electra"),w9t.forEach(t),NCr=r(yRe," \u2014 "),LU=n(yRe,"A",{href:!0});var A9t=s(LU);jCr=r(A9t,"FlaxElectraModel"),A9t.forEach(t),DCr=r(yRe," (ELECTRA model)"),yRe.forEach(t),GCr=i(ae),oE=n(ae,"LI",{});var LRe=s(oE);jFe=n(LRe,"STRONG",{});var y9t=s(jFe);OCr=r(y9t,"gpt2"),y9t.forEach(t),VCr=r(LRe," \u2014 "),xU=n(LRe,"A",{href:!0});var L9t=s(xU);XCr=r(L9t,"FlaxGPT2Model"),L9t.forEach(t),zCr=r(LRe," (OpenAI GPT-2 model)"),LRe.forEach(t),QCr=i(ae),rE=n(ae,"LI",{});var xRe=s(rE);DFe=n(xRe,"STRONG",{});var x9t=s(DFe);WCr=r(x9t,"gpt_neo"),x9t.forEach(t),HCr=r(xRe," \u2014 "),$U=n(xRe,"A",{href:!0});var $9t=s($U);UCr=r($9t,"FlaxGPTNeoModel"),$9t.forEach(t),JCr=r(xRe," (GPT Neo model)"),xRe.forEach(t),YCr=i(ae),tE=n(ae,"LI",{});var $Re=s(tE);GFe=n($Re,"STRONG",{});var k9t=s(GFe);KCr=r(k9t,"gptj"),k9t.forEach(t),ZCr=r($Re," \u2014 "),kU=n($Re,"A",{href:!0});var S9t=s(kU);e3r=r(S9t,"FlaxGPTJModel"),S9t.forEach(t),o3r=r($Re," (GPT-J model)"),$Re.forEach(t),r3r=i(ae),aE=n(ae,"LI",{});var kRe=s(aE);OFe=n(kRe,"STRONG",{});var R9t=s(OFe);t3r=r(R9t,"marian"),R9t.forEach(t),a3r=r(kRe," \u2014 "),SU=n(kRe,"A",{href:!0});var B9t=s(SU);n3r=r(B9t,"FlaxMarianModel"),B9t.forEach(t),s3r=r(kRe," (Marian model)"),kRe.forEach(t),l3r=i(ae),nE=n(ae,"LI",{});var SRe=s(nE);VFe=n(SRe,"STRONG",{});var P9t=s(VFe);i3r=r(P9t,"mbart"),P9t.forEach(t),d3r=r(SRe," \u2014 "),RU=n(SRe,"A",{href:!0});var I9t=s(RU);c3r=r(I9t,"FlaxMBartModel"),I9t.forEach(t),f3r=r(SRe," (mBART model)"),SRe.forEach(t),m3r=i(ae),sE=n(ae,"LI",{});var RRe=s(sE);XFe=n(RRe,"STRONG",{});var q9t=s(XFe);g3r=r(q9t,"mt5"),q9t.forEach(t),h3r=r(RRe," \u2014 "),BU=n(RRe,"A",{href:!0});var N9t=s(BU);p3r=r(N9t,"FlaxMT5Model"),N9t.forEach(t),u3r=r(RRe," (mT5 model)"),RRe.forEach(t),_3r=i(ae),lE=n(ae,"LI",{});var BRe=s(lE);zFe=n(BRe,"STRONG",{});var j9t=s(zFe);b3r=r(j9t,"pegasus"),j9t.forEach(t),v3r=r(BRe," \u2014 "),PU=n(BRe,"A",{href:!0});var D9t=s(PU);F3r=r(D9t,"FlaxPegasusModel"),D9t.forEach(t),T3r=r(BRe," (Pegasus model)"),BRe.forEach(t),M3r=i(ae),iE=n(ae,"LI",{});var PRe=s(iE);QFe=n(PRe,"STRONG",{});var G9t=s(QFe);E3r=r(G9t,"roberta"),G9t.forEach(t),C3r=r(PRe," \u2014 "),IU=n(PRe,"A",{href:!0});var O9t=s(IU);w3r=r(O9t,"FlaxRobertaModel"),O9t.forEach(t),A3r=r(PRe," (RoBERTa model)"),PRe.forEach(t),y3r=i(ae),dE=n(ae,"LI",{});var IRe=s(dE);WFe=n(IRe,"STRONG",{});var V9t=s(WFe);L3r=r(V9t,"roformer"),V9t.forEach(t),x3r=r(IRe," \u2014 "),qU=n(IRe,"A",{href:!0});var X9t=s(qU);$3r=r(X9t,"FlaxRoFormerModel"),X9t.forEach(t),k3r=r(IRe," (RoFormer model)"),IRe.forEach(t),S3r=i(ae),cE=n(ae,"LI",{});var qRe=s(cE);HFe=n(qRe,"STRONG",{});var z9t=s(HFe);R3r=r(z9t,"t5"),z9t.forEach(t),B3r=r(qRe," \u2014 "),NU=n(qRe,"A",{href:!0});var Q9t=s(NU);P3r=r(Q9t,"FlaxT5Model"),Q9t.forEach(t),I3r=r(qRe," (T5 model)"),qRe.forEach(t),q3r=i(ae),fE=n(ae,"LI",{});var NRe=s(fE);UFe=n(NRe,"STRONG",{});var W9t=s(UFe);N3r=r(W9t,"vision-text-dual-encoder"),W9t.forEach(t),j3r=r(NRe," \u2014 "),jU=n(NRe,"A",{href:!0});var H9t=s(jU);D3r=r(H9t,"FlaxVisionTextDualEncoderModel"),H9t.forEach(t),G3r=r(NRe," (VisionTextDualEncoder model)"),NRe.forEach(t),O3r=i(ae),mE=n(ae,"LI",{});var jRe=s(mE);JFe=n(jRe,"STRONG",{});var U9t=s(JFe);V3r=r(U9t,"vit"),U9t.forEach(t),X3r=r(jRe," \u2014 "),DU=n(jRe,"A",{href:!0});var J9t=s(DU);z3r=r(J9t,"FlaxViTModel"),J9t.forEach(t),Q3r=r(jRe," (ViT model)"),jRe.forEach(t),W3r=i(ae),gE=n(ae,"LI",{});var DRe=s(gE);YFe=n(DRe,"STRONG",{});var Y9t=s(YFe);H3r=r(Y9t,"wav2vec2"),Y9t.forEach(t),U3r=r(DRe," \u2014 "),GU=n(DRe,"A",{href:!0});var K9t=s(GU);J3r=r(K9t,"FlaxWav2Vec2Model"),K9t.forEach(t),Y3r=r(DRe," (Wav2Vec2 model)"),DRe.forEach(t),K3r=i(ae),hE=n(ae,"LI",{});var GRe=s(hE);KFe=n(GRe,"STRONG",{});var Z9t=s(KFe);Z3r=r(Z9t,"xglm"),Z9t.forEach(t),ewr=r(GRe," \u2014 "),OU=n(GRe,"A",{href:!0});var eMt=s(OU);owr=r(eMt,"FlaxXGLMModel"),eMt.forEach(t),rwr=r(GRe," (XGLM model)"),GRe.forEach(t),twr=i(ae),pE=n(ae,"LI",{});var ORe=s(pE);ZFe=n(ORe,"STRONG",{});var oMt=s(ZFe);awr=r(oMt,"xlm-roberta"),oMt.forEach(t),nwr=r(ORe," \u2014 "),VU=n(ORe,"A",{href:!0});var rMt=s(VU);swr=r(rMt,"FlaxXLMRobertaModel"),rMt.forEach(t),lwr=r(ORe," (XLM-RoBERTa model)"),ORe.forEach(t),ae.forEach(t),iwr=i(jl),T(uE.$$.fragment,jl),jl.forEach(t),Nl.forEach(t),JIe=i(f),xc=n(f,"H2",{class:!0});var tje=s(xc);_E=n(tje,"A",{id:!0,class:!0,href:!0});var tMt=s(_E);e6e=n(tMt,"SPAN",{});var aMt=s(e6e);T(HL.$$.fragment,aMt),aMt.forEach(t),tMt.forEach(t),dwr=i(tje),o6e=n(tje,"SPAN",{});var nMt=s(o6e);cwr=r(nMt,"FlaxAutoModelForCausalLM"),nMt.forEach(t),tje.forEach(t),YIe=i(f),mr=n(f,"DIV",{class:!0});var Dl=s(mr);T(UL.$$.fragment,Dl),fwr=i(Dl),$c=n(Dl,"P",{});var vZ=s($c);mwr=r(vZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),XU=n(vZ,"A",{href:!0});var sMt=s(XU);gwr=r(sMt,"from_pretrained()"),sMt.forEach(t),hwr=r(vZ," class method or the "),zU=n(vZ,"A",{href:!0});var lMt=s(zU);pwr=r(lMt,"from_config()"),lMt.forEach(t),uwr=r(vZ,` class
method.`),vZ.forEach(t),_wr=i(Dl),JL=n(Dl,"P",{});var aje=s(JL);bwr=r(aje,"This class cannot be instantiated directly using "),r6e=n(aje,"CODE",{});var iMt=s(r6e);vwr=r(iMt,"__init__()"),iMt.forEach(t),Fwr=r(aje," (throws an error)."),aje.forEach(t),Twr=i(Dl),Dt=n(Dl,"DIV",{class:!0});var vw=s(Dt);T(YL.$$.fragment,vw),Mwr=i(vw),t6e=n(vw,"P",{});var dMt=s(t6e);Ewr=r(dMt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),dMt.forEach(t),Cwr=i(vw),kc=n(vw,"P",{});var FZ=s(kc);wwr=r(FZ,`Note:
Loading a model from its configuration file does `),a6e=n(FZ,"STRONG",{});var cMt=s(a6e);Awr=r(cMt,"not"),cMt.forEach(t),ywr=r(FZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),QU=n(FZ,"A",{href:!0});var fMt=s(QU);Lwr=r(fMt,"from_pretrained()"),fMt.forEach(t),xwr=r(FZ," to load the model weights."),FZ.forEach(t),$wr=i(vw),T(bE.$$.fragment,vw),vw.forEach(t),kwr=i(Dl),Dr=n(Dl,"DIV",{class:!0});var Gl=s(Dr);T(KL.$$.fragment,Gl),Swr=i(Gl),n6e=n(Gl,"P",{});var mMt=s(n6e);Rwr=r(mMt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),mMt.forEach(t),Bwr=i(Gl),pn=n(Gl,"P",{});var Fw=s(pn);Pwr=r(Fw,"The model class to instantiate is selected based on the "),s6e=n(Fw,"CODE",{});var gMt=s(s6e);Iwr=r(gMt,"model_type"),gMt.forEach(t),qwr=r(Fw,` property of the config object (either
passed as an argument or loaded from `),l6e=n(Fw,"CODE",{});var hMt=s(l6e);Nwr=r(hMt,"pretrained_model_name_or_path"),hMt.forEach(t),jwr=r(Fw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i6e=n(Fw,"CODE",{});var pMt=s(i6e);Dwr=r(pMt,"pretrained_model_name_or_path"),pMt.forEach(t),Gwr=r(Fw,":"),Fw.forEach(t),Owr=i(Gl),ke=n(Gl,"UL",{});var Oe=s(ke);vE=n(Oe,"LI",{});var VRe=s(vE);d6e=n(VRe,"STRONG",{});var uMt=s(d6e);Vwr=r(uMt,"bart"),uMt.forEach(t),Xwr=r(VRe," \u2014 "),WU=n(VRe,"A",{href:!0});var _Mt=s(WU);zwr=r(_Mt,"FlaxBartForCausalLM"),_Mt.forEach(t),Qwr=r(VRe," (BART model)"),VRe.forEach(t),Wwr=i(Oe),FE=n(Oe,"LI",{});var XRe=s(FE);c6e=n(XRe,"STRONG",{});var bMt=s(c6e);Hwr=r(bMt,"bert"),bMt.forEach(t),Uwr=r(XRe," \u2014 "),HU=n(XRe,"A",{href:!0});var vMt=s(HU);Jwr=r(vMt,"FlaxBertForCausalLM"),vMt.forEach(t),Ywr=r(XRe," (BERT model)"),XRe.forEach(t),Kwr=i(Oe),TE=n(Oe,"LI",{});var zRe=s(TE);f6e=n(zRe,"STRONG",{});var FMt=s(f6e);Zwr=r(FMt,"big_bird"),FMt.forEach(t),eAr=r(zRe," \u2014 "),UU=n(zRe,"A",{href:!0});var TMt=s(UU);oAr=r(TMt,"FlaxBigBirdForCausalLM"),TMt.forEach(t),rAr=r(zRe," (BigBird model)"),zRe.forEach(t),tAr=i(Oe),ME=n(Oe,"LI",{});var QRe=s(ME);m6e=n(QRe,"STRONG",{});var MMt=s(m6e);aAr=r(MMt,"electra"),MMt.forEach(t),nAr=r(QRe," \u2014 "),JU=n(QRe,"A",{href:!0});var EMt=s(JU);sAr=r(EMt,"FlaxElectraForCausalLM"),EMt.forEach(t),lAr=r(QRe," (ELECTRA model)"),QRe.forEach(t),iAr=i(Oe),EE=n(Oe,"LI",{});var WRe=s(EE);g6e=n(WRe,"STRONG",{});var CMt=s(g6e);dAr=r(CMt,"gpt2"),CMt.forEach(t),cAr=r(WRe," \u2014 "),YU=n(WRe,"A",{href:!0});var wMt=s(YU);fAr=r(wMt,"FlaxGPT2LMHeadModel"),wMt.forEach(t),mAr=r(WRe," (OpenAI GPT-2 model)"),WRe.forEach(t),gAr=i(Oe),CE=n(Oe,"LI",{});var HRe=s(CE);h6e=n(HRe,"STRONG",{});var AMt=s(h6e);hAr=r(AMt,"gpt_neo"),AMt.forEach(t),pAr=r(HRe," \u2014 "),KU=n(HRe,"A",{href:!0});var yMt=s(KU);uAr=r(yMt,"FlaxGPTNeoForCausalLM"),yMt.forEach(t),_Ar=r(HRe," (GPT Neo model)"),HRe.forEach(t),bAr=i(Oe),wE=n(Oe,"LI",{});var URe=s(wE);p6e=n(URe,"STRONG",{});var LMt=s(p6e);vAr=r(LMt,"gptj"),LMt.forEach(t),FAr=r(URe," \u2014 "),ZU=n(URe,"A",{href:!0});var xMt=s(ZU);TAr=r(xMt,"FlaxGPTJForCausalLM"),xMt.forEach(t),MAr=r(URe," (GPT-J model)"),URe.forEach(t),EAr=i(Oe),AE=n(Oe,"LI",{});var JRe=s(AE);u6e=n(JRe,"STRONG",{});var $Mt=s(u6e);CAr=r($Mt,"roberta"),$Mt.forEach(t),wAr=r(JRe," \u2014 "),eJ=n(JRe,"A",{href:!0});var kMt=s(eJ);AAr=r(kMt,"FlaxRobertaForCausalLM"),kMt.forEach(t),yAr=r(JRe," (RoBERTa model)"),JRe.forEach(t),LAr=i(Oe),yE=n(Oe,"LI",{});var YRe=s(yE);_6e=n(YRe,"STRONG",{});var SMt=s(_6e);xAr=r(SMt,"xglm"),SMt.forEach(t),$Ar=r(YRe," \u2014 "),oJ=n(YRe,"A",{href:!0});var RMt=s(oJ);kAr=r(RMt,"FlaxXGLMForCausalLM"),RMt.forEach(t),SAr=r(YRe," (XGLM model)"),YRe.forEach(t),Oe.forEach(t),RAr=i(Gl),T(LE.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),KIe=i(f),Sc=n(f,"H2",{class:!0});var nje=s(Sc);xE=n(nje,"A",{id:!0,class:!0,href:!0});var BMt=s(xE);b6e=n(BMt,"SPAN",{});var PMt=s(b6e);T(ZL.$$.fragment,PMt),PMt.forEach(t),BMt.forEach(t),BAr=i(nje),v6e=n(nje,"SPAN",{});var IMt=s(v6e);PAr=r(IMt,"FlaxAutoModelForPreTraining"),IMt.forEach(t),nje.forEach(t),ZIe=i(f),gr=n(f,"DIV",{class:!0});var Ol=s(gr);T(ex.$$.fragment,Ol),IAr=i(Ol),Rc=n(Ol,"P",{});var TZ=s(Rc);qAr=r(TZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rJ=n(TZ,"A",{href:!0});var qMt=s(rJ);NAr=r(qMt,"from_pretrained()"),qMt.forEach(t),jAr=r(TZ," class method or the "),tJ=n(TZ,"A",{href:!0});var NMt=s(tJ);DAr=r(NMt,"from_config()"),NMt.forEach(t),GAr=r(TZ,` class
method.`),TZ.forEach(t),OAr=i(Ol),ox=n(Ol,"P",{});var sje=s(ox);VAr=r(sje,"This class cannot be instantiated directly using "),F6e=n(sje,"CODE",{});var jMt=s(F6e);XAr=r(jMt,"__init__()"),jMt.forEach(t),zAr=r(sje," (throws an error)."),sje.forEach(t),QAr=i(Ol),Gt=n(Ol,"DIV",{class:!0});var Tw=s(Gt);T(rx.$$.fragment,Tw),WAr=i(Tw),T6e=n(Tw,"P",{});var DMt=s(T6e);HAr=r(DMt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),DMt.forEach(t),UAr=i(Tw),Bc=n(Tw,"P",{});var MZ=s(Bc);JAr=r(MZ,`Note:
Loading a model from its configuration file does `),M6e=n(MZ,"STRONG",{});var GMt=s(M6e);YAr=r(GMt,"not"),GMt.forEach(t),KAr=r(MZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),aJ=n(MZ,"A",{href:!0});var OMt=s(aJ);ZAr=r(OMt,"from_pretrained()"),OMt.forEach(t),e0r=r(MZ," to load the model weights."),MZ.forEach(t),o0r=i(Tw),T($E.$$.fragment,Tw),Tw.forEach(t),r0r=i(Ol),Gr=n(Ol,"DIV",{class:!0});var Vl=s(Gr);T(tx.$$.fragment,Vl),t0r=i(Vl),E6e=n(Vl,"P",{});var VMt=s(E6e);a0r=r(VMt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),VMt.forEach(t),n0r=i(Vl),un=n(Vl,"P",{});var Mw=s(un);s0r=r(Mw,"The model class to instantiate is selected based on the "),C6e=n(Mw,"CODE",{});var XMt=s(C6e);l0r=r(XMt,"model_type"),XMt.forEach(t),i0r=r(Mw,` property of the config object (either
passed as an argument or loaded from `),w6e=n(Mw,"CODE",{});var zMt=s(w6e);d0r=r(zMt,"pretrained_model_name_or_path"),zMt.forEach(t),c0r=r(Mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A6e=n(Mw,"CODE",{});var QMt=s(A6e);f0r=r(QMt,"pretrained_model_name_or_path"),QMt.forEach(t),m0r=r(Mw,":"),Mw.forEach(t),g0r=i(Vl),Me=n(Vl,"UL",{});var we=s(Me);kE=n(we,"LI",{});var KRe=s(kE);y6e=n(KRe,"STRONG",{});var WMt=s(y6e);h0r=r(WMt,"albert"),WMt.forEach(t),p0r=r(KRe," \u2014 "),nJ=n(KRe,"A",{href:!0});var HMt=s(nJ);u0r=r(HMt,"FlaxAlbertForPreTraining"),HMt.forEach(t),_0r=r(KRe," (ALBERT model)"),KRe.forEach(t),b0r=i(we),SE=n(we,"LI",{});var ZRe=s(SE);L6e=n(ZRe,"STRONG",{});var UMt=s(L6e);v0r=r(UMt,"bart"),UMt.forEach(t),F0r=r(ZRe," \u2014 "),sJ=n(ZRe,"A",{href:!0});var JMt=s(sJ);T0r=r(JMt,"FlaxBartForConditionalGeneration"),JMt.forEach(t),M0r=r(ZRe," (BART model)"),ZRe.forEach(t),E0r=i(we),RE=n(we,"LI",{});var eBe=s(RE);x6e=n(eBe,"STRONG",{});var YMt=s(x6e);C0r=r(YMt,"bert"),YMt.forEach(t),w0r=r(eBe," \u2014 "),lJ=n(eBe,"A",{href:!0});var KMt=s(lJ);A0r=r(KMt,"FlaxBertForPreTraining"),KMt.forEach(t),y0r=r(eBe," (BERT model)"),eBe.forEach(t),L0r=i(we),BE=n(we,"LI",{});var oBe=s(BE);$6e=n(oBe,"STRONG",{});var ZMt=s($6e);x0r=r(ZMt,"big_bird"),ZMt.forEach(t),$0r=r(oBe," \u2014 "),iJ=n(oBe,"A",{href:!0});var e4t=s(iJ);k0r=r(e4t,"FlaxBigBirdForPreTraining"),e4t.forEach(t),S0r=r(oBe," (BigBird model)"),oBe.forEach(t),R0r=i(we),PE=n(we,"LI",{});var rBe=s(PE);k6e=n(rBe,"STRONG",{});var o4t=s(k6e);B0r=r(o4t,"electra"),o4t.forEach(t),P0r=r(rBe," \u2014 "),dJ=n(rBe,"A",{href:!0});var r4t=s(dJ);I0r=r(r4t,"FlaxElectraForPreTraining"),r4t.forEach(t),q0r=r(rBe," (ELECTRA model)"),rBe.forEach(t),N0r=i(we),IE=n(we,"LI",{});var tBe=s(IE);S6e=n(tBe,"STRONG",{});var t4t=s(S6e);j0r=r(t4t,"mbart"),t4t.forEach(t),D0r=r(tBe," \u2014 "),cJ=n(tBe,"A",{href:!0});var a4t=s(cJ);G0r=r(a4t,"FlaxMBartForConditionalGeneration"),a4t.forEach(t),O0r=r(tBe," (mBART model)"),tBe.forEach(t),V0r=i(we),qE=n(we,"LI",{});var aBe=s(qE);R6e=n(aBe,"STRONG",{});var n4t=s(R6e);X0r=r(n4t,"mt5"),n4t.forEach(t),z0r=r(aBe," \u2014 "),fJ=n(aBe,"A",{href:!0});var s4t=s(fJ);Q0r=r(s4t,"FlaxMT5ForConditionalGeneration"),s4t.forEach(t),W0r=r(aBe," (mT5 model)"),aBe.forEach(t),H0r=i(we),NE=n(we,"LI",{});var nBe=s(NE);B6e=n(nBe,"STRONG",{});var l4t=s(B6e);U0r=r(l4t,"roberta"),l4t.forEach(t),J0r=r(nBe," \u2014 "),mJ=n(nBe,"A",{href:!0});var i4t=s(mJ);Y0r=r(i4t,"FlaxRobertaForMaskedLM"),i4t.forEach(t),K0r=r(nBe," (RoBERTa model)"),nBe.forEach(t),Z0r=i(we),jE=n(we,"LI",{});var sBe=s(jE);P6e=n(sBe,"STRONG",{});var d4t=s(P6e);eyr=r(d4t,"roformer"),d4t.forEach(t),oyr=r(sBe," \u2014 "),gJ=n(sBe,"A",{href:!0});var c4t=s(gJ);ryr=r(c4t,"FlaxRoFormerForMaskedLM"),c4t.forEach(t),tyr=r(sBe," (RoFormer model)"),sBe.forEach(t),ayr=i(we),DE=n(we,"LI",{});var lBe=s(DE);I6e=n(lBe,"STRONG",{});var f4t=s(I6e);nyr=r(f4t,"t5"),f4t.forEach(t),syr=r(lBe," \u2014 "),hJ=n(lBe,"A",{href:!0});var m4t=s(hJ);lyr=r(m4t,"FlaxT5ForConditionalGeneration"),m4t.forEach(t),iyr=r(lBe," (T5 model)"),lBe.forEach(t),dyr=i(we),GE=n(we,"LI",{});var iBe=s(GE);q6e=n(iBe,"STRONG",{});var g4t=s(q6e);cyr=r(g4t,"wav2vec2"),g4t.forEach(t),fyr=r(iBe," \u2014 "),pJ=n(iBe,"A",{href:!0});var h4t=s(pJ);myr=r(h4t,"FlaxWav2Vec2ForPreTraining"),h4t.forEach(t),gyr=r(iBe," (Wav2Vec2 model)"),iBe.forEach(t),hyr=i(we),OE=n(we,"LI",{});var dBe=s(OE);N6e=n(dBe,"STRONG",{});var p4t=s(N6e);pyr=r(p4t,"xlm-roberta"),p4t.forEach(t),uyr=r(dBe," \u2014 "),uJ=n(dBe,"A",{href:!0});var u4t=s(uJ);_yr=r(u4t,"FlaxXLMRobertaForMaskedLM"),u4t.forEach(t),byr=r(dBe," (XLM-RoBERTa model)"),dBe.forEach(t),we.forEach(t),vyr=i(Vl),T(VE.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),eqe=i(f),Pc=n(f,"H2",{class:!0});var lje=s(Pc);XE=n(lje,"A",{id:!0,class:!0,href:!0});var _4t=s(XE);j6e=n(_4t,"SPAN",{});var b4t=s(j6e);T(ax.$$.fragment,b4t),b4t.forEach(t),_4t.forEach(t),Fyr=i(lje),D6e=n(lje,"SPAN",{});var v4t=s(D6e);Tyr=r(v4t,"FlaxAutoModelForMaskedLM"),v4t.forEach(t),lje.forEach(t),oqe=i(f),hr=n(f,"DIV",{class:!0});var Xl=s(hr);T(nx.$$.fragment,Xl),Myr=i(Xl),Ic=n(Xl,"P",{});var EZ=s(Ic);Eyr=r(EZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),_J=n(EZ,"A",{href:!0});var F4t=s(_J);Cyr=r(F4t,"from_pretrained()"),F4t.forEach(t),wyr=r(EZ," class method or the "),bJ=n(EZ,"A",{href:!0});var T4t=s(bJ);Ayr=r(T4t,"from_config()"),T4t.forEach(t),yyr=r(EZ,` class
method.`),EZ.forEach(t),Lyr=i(Xl),sx=n(Xl,"P",{});var ije=s(sx);xyr=r(ije,"This class cannot be instantiated directly using "),G6e=n(ije,"CODE",{});var M4t=s(G6e);$yr=r(M4t,"__init__()"),M4t.forEach(t),kyr=r(ije," (throws an error)."),ije.forEach(t),Syr=i(Xl),Ot=n(Xl,"DIV",{class:!0});var Ew=s(Ot);T(lx.$$.fragment,Ew),Ryr=i(Ew),O6e=n(Ew,"P",{});var E4t=s(O6e);Byr=r(E4t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),E4t.forEach(t),Pyr=i(Ew),qc=n(Ew,"P",{});var CZ=s(qc);Iyr=r(CZ,`Note:
Loading a model from its configuration file does `),V6e=n(CZ,"STRONG",{});var C4t=s(V6e);qyr=r(C4t,"not"),C4t.forEach(t),Nyr=r(CZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(CZ,"A",{href:!0});var w4t=s(vJ);jyr=r(w4t,"from_pretrained()"),w4t.forEach(t),Dyr=r(CZ," to load the model weights."),CZ.forEach(t),Gyr=i(Ew),T(zE.$$.fragment,Ew),Ew.forEach(t),Oyr=i(Xl),Or=n(Xl,"DIV",{class:!0});var zl=s(Or);T(ix.$$.fragment,zl),Vyr=i(zl),X6e=n(zl,"P",{});var A4t=s(X6e);Xyr=r(A4t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),A4t.forEach(t),zyr=i(zl),_n=n(zl,"P",{});var Cw=s(_n);Qyr=r(Cw,"The model class to instantiate is selected based on the "),z6e=n(Cw,"CODE",{});var y4t=s(z6e);Wyr=r(y4t,"model_type"),y4t.forEach(t),Hyr=r(Cw,` property of the config object (either
passed as an argument or loaded from `),Q6e=n(Cw,"CODE",{});var L4t=s(Q6e);Uyr=r(L4t,"pretrained_model_name_or_path"),L4t.forEach(t),Jyr=r(Cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W6e=n(Cw,"CODE",{});var x4t=s(W6e);Yyr=r(x4t,"pretrained_model_name_or_path"),x4t.forEach(t),Kyr=r(Cw,":"),Cw.forEach(t),Zyr=i(zl),Le=n(zl,"UL",{});var Be=s(Le);QE=n(Be,"LI",{});var cBe=s(QE);H6e=n(cBe,"STRONG",{});var $4t=s(H6e);eLr=r($4t,"albert"),$4t.forEach(t),oLr=r(cBe," \u2014 "),FJ=n(cBe,"A",{href:!0});var k4t=s(FJ);rLr=r(k4t,"FlaxAlbertForMaskedLM"),k4t.forEach(t),tLr=r(cBe," (ALBERT model)"),cBe.forEach(t),aLr=i(Be),WE=n(Be,"LI",{});var fBe=s(WE);U6e=n(fBe,"STRONG",{});var S4t=s(U6e);nLr=r(S4t,"bart"),S4t.forEach(t),sLr=r(fBe," \u2014 "),TJ=n(fBe,"A",{href:!0});var R4t=s(TJ);lLr=r(R4t,"FlaxBartForConditionalGeneration"),R4t.forEach(t),iLr=r(fBe," (BART model)"),fBe.forEach(t),dLr=i(Be),HE=n(Be,"LI",{});var mBe=s(HE);J6e=n(mBe,"STRONG",{});var B4t=s(J6e);cLr=r(B4t,"bert"),B4t.forEach(t),fLr=r(mBe," \u2014 "),MJ=n(mBe,"A",{href:!0});var P4t=s(MJ);mLr=r(P4t,"FlaxBertForMaskedLM"),P4t.forEach(t),gLr=r(mBe," (BERT model)"),mBe.forEach(t),hLr=i(Be),UE=n(Be,"LI",{});var gBe=s(UE);Y6e=n(gBe,"STRONG",{});var I4t=s(Y6e);pLr=r(I4t,"big_bird"),I4t.forEach(t),uLr=r(gBe," \u2014 "),EJ=n(gBe,"A",{href:!0});var q4t=s(EJ);_Lr=r(q4t,"FlaxBigBirdForMaskedLM"),q4t.forEach(t),bLr=r(gBe," (BigBird model)"),gBe.forEach(t),vLr=i(Be),JE=n(Be,"LI",{});var hBe=s(JE);K6e=n(hBe,"STRONG",{});var N4t=s(K6e);FLr=r(N4t,"distilbert"),N4t.forEach(t),TLr=r(hBe," \u2014 "),CJ=n(hBe,"A",{href:!0});var j4t=s(CJ);MLr=r(j4t,"FlaxDistilBertForMaskedLM"),j4t.forEach(t),ELr=r(hBe," (DistilBERT model)"),hBe.forEach(t),CLr=i(Be),YE=n(Be,"LI",{});var pBe=s(YE);Z6e=n(pBe,"STRONG",{});var D4t=s(Z6e);wLr=r(D4t,"electra"),D4t.forEach(t),ALr=r(pBe," \u2014 "),wJ=n(pBe,"A",{href:!0});var G4t=s(wJ);yLr=r(G4t,"FlaxElectraForMaskedLM"),G4t.forEach(t),LLr=r(pBe," (ELECTRA model)"),pBe.forEach(t),xLr=i(Be),KE=n(Be,"LI",{});var uBe=s(KE);eTe=n(uBe,"STRONG",{});var O4t=s(eTe);$Lr=r(O4t,"mbart"),O4t.forEach(t),kLr=r(uBe," \u2014 "),AJ=n(uBe,"A",{href:!0});var V4t=s(AJ);SLr=r(V4t,"FlaxMBartForConditionalGeneration"),V4t.forEach(t),RLr=r(uBe," (mBART model)"),uBe.forEach(t),BLr=i(Be),ZE=n(Be,"LI",{});var _Be=s(ZE);oTe=n(_Be,"STRONG",{});var X4t=s(oTe);PLr=r(X4t,"roberta"),X4t.forEach(t),ILr=r(_Be," \u2014 "),yJ=n(_Be,"A",{href:!0});var z4t=s(yJ);qLr=r(z4t,"FlaxRobertaForMaskedLM"),z4t.forEach(t),NLr=r(_Be," (RoBERTa model)"),_Be.forEach(t),jLr=i(Be),e5=n(Be,"LI",{});var bBe=s(e5);rTe=n(bBe,"STRONG",{});var Q4t=s(rTe);DLr=r(Q4t,"roformer"),Q4t.forEach(t),GLr=r(bBe," \u2014 "),LJ=n(bBe,"A",{href:!0});var W4t=s(LJ);OLr=r(W4t,"FlaxRoFormerForMaskedLM"),W4t.forEach(t),VLr=r(bBe," (RoFormer model)"),bBe.forEach(t),XLr=i(Be),o5=n(Be,"LI",{});var vBe=s(o5);tTe=n(vBe,"STRONG",{});var H4t=s(tTe);zLr=r(H4t,"xlm-roberta"),H4t.forEach(t),QLr=r(vBe," \u2014 "),xJ=n(vBe,"A",{href:!0});var U4t=s(xJ);WLr=r(U4t,"FlaxXLMRobertaForMaskedLM"),U4t.forEach(t),HLr=r(vBe," (XLM-RoBERTa model)"),vBe.forEach(t),Be.forEach(t),ULr=i(zl),T(r5.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),rqe=i(f),Nc=n(f,"H2",{class:!0});var dje=s(Nc);t5=n(dje,"A",{id:!0,class:!0,href:!0});var J4t=s(t5);aTe=n(J4t,"SPAN",{});var Y4t=s(aTe);T(dx.$$.fragment,Y4t),Y4t.forEach(t),J4t.forEach(t),JLr=i(dje),nTe=n(dje,"SPAN",{});var K4t=s(nTe);YLr=r(K4t,"FlaxAutoModelForSeq2SeqLM"),K4t.forEach(t),dje.forEach(t),tqe=i(f),pr=n(f,"DIV",{class:!0});var Ql=s(pr);T(cx.$$.fragment,Ql),KLr=i(Ql),jc=n(Ql,"P",{});var wZ=s(jc);ZLr=r(wZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$J=n(wZ,"A",{href:!0});var Z4t=s($J);exr=r(Z4t,"from_pretrained()"),Z4t.forEach(t),oxr=r(wZ," class method or the "),kJ=n(wZ,"A",{href:!0});var eEt=s(kJ);rxr=r(eEt,"from_config()"),eEt.forEach(t),txr=r(wZ,` class
method.`),wZ.forEach(t),axr=i(Ql),fx=n(Ql,"P",{});var cje=s(fx);nxr=r(cje,"This class cannot be instantiated directly using "),sTe=n(cje,"CODE",{});var oEt=s(sTe);sxr=r(oEt,"__init__()"),oEt.forEach(t),lxr=r(cje," (throws an error)."),cje.forEach(t),ixr=i(Ql),Vt=n(Ql,"DIV",{class:!0});var ww=s(Vt);T(mx.$$.fragment,ww),dxr=i(ww),lTe=n(ww,"P",{});var rEt=s(lTe);cxr=r(rEt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),rEt.forEach(t),fxr=i(ww),Dc=n(ww,"P",{});var AZ=s(Dc);mxr=r(AZ,`Note:
Loading a model from its configuration file does `),iTe=n(AZ,"STRONG",{});var tEt=s(iTe);gxr=r(tEt,"not"),tEt.forEach(t),hxr=r(AZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=n(AZ,"A",{href:!0});var aEt=s(SJ);pxr=r(aEt,"from_pretrained()"),aEt.forEach(t),uxr=r(AZ," to load the model weights."),AZ.forEach(t),_xr=i(ww),T(a5.$$.fragment,ww),ww.forEach(t),bxr=i(Ql),Vr=n(Ql,"DIV",{class:!0});var Wl=s(Vr);T(gx.$$.fragment,Wl),vxr=i(Wl),dTe=n(Wl,"P",{});var nEt=s(dTe);Fxr=r(nEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nEt.forEach(t),Txr=i(Wl),bn=n(Wl,"P",{});var Aw=s(bn);Mxr=r(Aw,"The model class to instantiate is selected based on the "),cTe=n(Aw,"CODE",{});var sEt=s(cTe);Exr=r(sEt,"model_type"),sEt.forEach(t),Cxr=r(Aw,` property of the config object (either
passed as an argument or loaded from `),fTe=n(Aw,"CODE",{});var lEt=s(fTe);wxr=r(lEt,"pretrained_model_name_or_path"),lEt.forEach(t),Axr=r(Aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mTe=n(Aw,"CODE",{});var iEt=s(mTe);yxr=r(iEt,"pretrained_model_name_or_path"),iEt.forEach(t),Lxr=r(Aw,":"),Aw.forEach(t),xxr=i(Wl),Se=n(Wl,"UL",{});var Ve=s(Se);n5=n(Ve,"LI",{});var FBe=s(n5);gTe=n(FBe,"STRONG",{});var dEt=s(gTe);$xr=r(dEt,"bart"),dEt.forEach(t),kxr=r(FBe," \u2014 "),RJ=n(FBe,"A",{href:!0});var cEt=s(RJ);Sxr=r(cEt,"FlaxBartForConditionalGeneration"),cEt.forEach(t),Rxr=r(FBe," (BART model)"),FBe.forEach(t),Bxr=i(Ve),s5=n(Ve,"LI",{});var TBe=s(s5);hTe=n(TBe,"STRONG",{});var fEt=s(hTe);Pxr=r(fEt,"blenderbot"),fEt.forEach(t),Ixr=r(TBe," \u2014 "),BJ=n(TBe,"A",{href:!0});var mEt=s(BJ);qxr=r(mEt,"FlaxBlenderbotForConditionalGeneration"),mEt.forEach(t),Nxr=r(TBe," (Blenderbot model)"),TBe.forEach(t),jxr=i(Ve),l5=n(Ve,"LI",{});var MBe=s(l5);pTe=n(MBe,"STRONG",{});var gEt=s(pTe);Dxr=r(gEt,"blenderbot-small"),gEt.forEach(t),Gxr=r(MBe," \u2014 "),PJ=n(MBe,"A",{href:!0});var hEt=s(PJ);Oxr=r(hEt,"FlaxBlenderbotSmallForConditionalGeneration"),hEt.forEach(t),Vxr=r(MBe," (BlenderbotSmall model)"),MBe.forEach(t),Xxr=i(Ve),i5=n(Ve,"LI",{});var EBe=s(i5);uTe=n(EBe,"STRONG",{});var pEt=s(uTe);zxr=r(pEt,"encoder-decoder"),pEt.forEach(t),Qxr=r(EBe," \u2014 "),IJ=n(EBe,"A",{href:!0});var uEt=s(IJ);Wxr=r(uEt,"FlaxEncoderDecoderModel"),uEt.forEach(t),Hxr=r(EBe," (Encoder decoder model)"),EBe.forEach(t),Uxr=i(Ve),d5=n(Ve,"LI",{});var CBe=s(d5);_Te=n(CBe,"STRONG",{});var _Et=s(_Te);Jxr=r(_Et,"marian"),_Et.forEach(t),Yxr=r(CBe," \u2014 "),qJ=n(CBe,"A",{href:!0});var bEt=s(qJ);Kxr=r(bEt,"FlaxMarianMTModel"),bEt.forEach(t),Zxr=r(CBe," (Marian model)"),CBe.forEach(t),e7r=i(Ve),c5=n(Ve,"LI",{});var wBe=s(c5);bTe=n(wBe,"STRONG",{});var vEt=s(bTe);o7r=r(vEt,"mbart"),vEt.forEach(t),r7r=r(wBe," \u2014 "),NJ=n(wBe,"A",{href:!0});var FEt=s(NJ);t7r=r(FEt,"FlaxMBartForConditionalGeneration"),FEt.forEach(t),a7r=r(wBe," (mBART model)"),wBe.forEach(t),n7r=i(Ve),f5=n(Ve,"LI",{});var ABe=s(f5);vTe=n(ABe,"STRONG",{});var TEt=s(vTe);s7r=r(TEt,"mt5"),TEt.forEach(t),l7r=r(ABe," \u2014 "),jJ=n(ABe,"A",{href:!0});var MEt=s(jJ);i7r=r(MEt,"FlaxMT5ForConditionalGeneration"),MEt.forEach(t),d7r=r(ABe," (mT5 model)"),ABe.forEach(t),c7r=i(Ve),m5=n(Ve,"LI",{});var yBe=s(m5);FTe=n(yBe,"STRONG",{});var EEt=s(FTe);f7r=r(EEt,"pegasus"),EEt.forEach(t),m7r=r(yBe," \u2014 "),DJ=n(yBe,"A",{href:!0});var CEt=s(DJ);g7r=r(CEt,"FlaxPegasusForConditionalGeneration"),CEt.forEach(t),h7r=r(yBe," (Pegasus model)"),yBe.forEach(t),p7r=i(Ve),g5=n(Ve,"LI",{});var LBe=s(g5);TTe=n(LBe,"STRONG",{});var wEt=s(TTe);u7r=r(wEt,"t5"),wEt.forEach(t),_7r=r(LBe," \u2014 "),GJ=n(LBe,"A",{href:!0});var AEt=s(GJ);b7r=r(AEt,"FlaxT5ForConditionalGeneration"),AEt.forEach(t),v7r=r(LBe," (T5 model)"),LBe.forEach(t),Ve.forEach(t),F7r=i(Wl),T(h5.$$.fragment,Wl),Wl.forEach(t),Ql.forEach(t),aqe=i(f),Gc=n(f,"H2",{class:!0});var fje=s(Gc);p5=n(fje,"A",{id:!0,class:!0,href:!0});var yEt=s(p5);MTe=n(yEt,"SPAN",{});var LEt=s(MTe);T(hx.$$.fragment,LEt),LEt.forEach(t),yEt.forEach(t),T7r=i(fje),ETe=n(fje,"SPAN",{});var xEt=s(ETe);M7r=r(xEt,"FlaxAutoModelForSequenceClassification"),xEt.forEach(t),fje.forEach(t),nqe=i(f),ur=n(f,"DIV",{class:!0});var Hl=s(ur);T(px.$$.fragment,Hl),E7r=i(Hl),Oc=n(Hl,"P",{});var yZ=s(Oc);C7r=r(yZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),OJ=n(yZ,"A",{href:!0});var $Et=s(OJ);w7r=r($Et,"from_pretrained()"),$Et.forEach(t),A7r=r(yZ," class method or the "),VJ=n(yZ,"A",{href:!0});var kEt=s(VJ);y7r=r(kEt,"from_config()"),kEt.forEach(t),L7r=r(yZ,` class
method.`),yZ.forEach(t),x7r=i(Hl),ux=n(Hl,"P",{});var mje=s(ux);$7r=r(mje,"This class cannot be instantiated directly using "),CTe=n(mje,"CODE",{});var SEt=s(CTe);k7r=r(SEt,"__init__()"),SEt.forEach(t),S7r=r(mje," (throws an error)."),mje.forEach(t),R7r=i(Hl),Xt=n(Hl,"DIV",{class:!0});var yw=s(Xt);T(_x.$$.fragment,yw),B7r=i(yw),wTe=n(yw,"P",{});var REt=s(wTe);P7r=r(REt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),REt.forEach(t),I7r=i(yw),Vc=n(yw,"P",{});var LZ=s(Vc);q7r=r(LZ,`Note:
Loading a model from its configuration file does `),ATe=n(LZ,"STRONG",{});var BEt=s(ATe);N7r=r(BEt,"not"),BEt.forEach(t),j7r=r(LZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XJ=n(LZ,"A",{href:!0});var PEt=s(XJ);D7r=r(PEt,"from_pretrained()"),PEt.forEach(t),G7r=r(LZ," to load the model weights."),LZ.forEach(t),O7r=i(yw),T(u5.$$.fragment,yw),yw.forEach(t),V7r=i(Hl),Xr=n(Hl,"DIV",{class:!0});var Ul=s(Xr);T(bx.$$.fragment,Ul),X7r=i(Ul),yTe=n(Ul,"P",{});var IEt=s(yTe);z7r=r(IEt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),IEt.forEach(t),Q7r=i(Ul),vn=n(Ul,"P",{});var Lw=s(vn);W7r=r(Lw,"The model class to instantiate is selected based on the "),LTe=n(Lw,"CODE",{});var qEt=s(LTe);H7r=r(qEt,"model_type"),qEt.forEach(t),U7r=r(Lw,` property of the config object (either
passed as an argument or loaded from `),xTe=n(Lw,"CODE",{});var NEt=s(xTe);J7r=r(NEt,"pretrained_model_name_or_path"),NEt.forEach(t),Y7r=r(Lw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Te=n(Lw,"CODE",{});var jEt=s($Te);K7r=r(jEt,"pretrained_model_name_or_path"),jEt.forEach(t),Z7r=r(Lw,":"),Lw.forEach(t),e$r=i(Ul),xe=n(Ul,"UL",{});var Pe=s(xe);_5=n(Pe,"LI",{});var xBe=s(_5);kTe=n(xBe,"STRONG",{});var DEt=s(kTe);o$r=r(DEt,"albert"),DEt.forEach(t),r$r=r(xBe," \u2014 "),zJ=n(xBe,"A",{href:!0});var GEt=s(zJ);t$r=r(GEt,"FlaxAlbertForSequenceClassification"),GEt.forEach(t),a$r=r(xBe," (ALBERT model)"),xBe.forEach(t),n$r=i(Pe),b5=n(Pe,"LI",{});var $Be=s(b5);STe=n($Be,"STRONG",{});var OEt=s(STe);s$r=r(OEt,"bart"),OEt.forEach(t),l$r=r($Be," \u2014 "),QJ=n($Be,"A",{href:!0});var VEt=s(QJ);i$r=r(VEt,"FlaxBartForSequenceClassification"),VEt.forEach(t),d$r=r($Be," (BART model)"),$Be.forEach(t),c$r=i(Pe),v5=n(Pe,"LI",{});var kBe=s(v5);RTe=n(kBe,"STRONG",{});var XEt=s(RTe);f$r=r(XEt,"bert"),XEt.forEach(t),m$r=r(kBe," \u2014 "),WJ=n(kBe,"A",{href:!0});var zEt=s(WJ);g$r=r(zEt,"FlaxBertForSequenceClassification"),zEt.forEach(t),h$r=r(kBe," (BERT model)"),kBe.forEach(t),p$r=i(Pe),F5=n(Pe,"LI",{});var SBe=s(F5);BTe=n(SBe,"STRONG",{});var QEt=s(BTe);u$r=r(QEt,"big_bird"),QEt.forEach(t),_$r=r(SBe," \u2014 "),HJ=n(SBe,"A",{href:!0});var WEt=s(HJ);b$r=r(WEt,"FlaxBigBirdForSequenceClassification"),WEt.forEach(t),v$r=r(SBe," (BigBird model)"),SBe.forEach(t),F$r=i(Pe),T5=n(Pe,"LI",{});var RBe=s(T5);PTe=n(RBe,"STRONG",{});var HEt=s(PTe);T$r=r(HEt,"distilbert"),HEt.forEach(t),M$r=r(RBe," \u2014 "),UJ=n(RBe,"A",{href:!0});var UEt=s(UJ);E$r=r(UEt,"FlaxDistilBertForSequenceClassification"),UEt.forEach(t),C$r=r(RBe," (DistilBERT model)"),RBe.forEach(t),w$r=i(Pe),M5=n(Pe,"LI",{});var BBe=s(M5);ITe=n(BBe,"STRONG",{});var JEt=s(ITe);A$r=r(JEt,"electra"),JEt.forEach(t),y$r=r(BBe," \u2014 "),JJ=n(BBe,"A",{href:!0});var YEt=s(JJ);L$r=r(YEt,"FlaxElectraForSequenceClassification"),YEt.forEach(t),x$r=r(BBe," (ELECTRA model)"),BBe.forEach(t),$$r=i(Pe),E5=n(Pe,"LI",{});var PBe=s(E5);qTe=n(PBe,"STRONG",{});var KEt=s(qTe);k$r=r(KEt,"mbart"),KEt.forEach(t),S$r=r(PBe," \u2014 "),YJ=n(PBe,"A",{href:!0});var ZEt=s(YJ);R$r=r(ZEt,"FlaxMBartForSequenceClassification"),ZEt.forEach(t),B$r=r(PBe," (mBART model)"),PBe.forEach(t),P$r=i(Pe),C5=n(Pe,"LI",{});var IBe=s(C5);NTe=n(IBe,"STRONG",{});var e5t=s(NTe);I$r=r(e5t,"roberta"),e5t.forEach(t),q$r=r(IBe," \u2014 "),KJ=n(IBe,"A",{href:!0});var o5t=s(KJ);N$r=r(o5t,"FlaxRobertaForSequenceClassification"),o5t.forEach(t),j$r=r(IBe," (RoBERTa model)"),IBe.forEach(t),D$r=i(Pe),w5=n(Pe,"LI",{});var qBe=s(w5);jTe=n(qBe,"STRONG",{});var r5t=s(jTe);G$r=r(r5t,"roformer"),r5t.forEach(t),O$r=r(qBe," \u2014 "),ZJ=n(qBe,"A",{href:!0});var t5t=s(ZJ);V$r=r(t5t,"FlaxRoFormerForSequenceClassification"),t5t.forEach(t),X$r=r(qBe," (RoFormer model)"),qBe.forEach(t),z$r=i(Pe),A5=n(Pe,"LI",{});var NBe=s(A5);DTe=n(NBe,"STRONG",{});var a5t=s(DTe);Q$r=r(a5t,"xlm-roberta"),a5t.forEach(t),W$r=r(NBe," \u2014 "),eY=n(NBe,"A",{href:!0});var n5t=s(eY);H$r=r(n5t,"FlaxXLMRobertaForSequenceClassification"),n5t.forEach(t),U$r=r(NBe," (XLM-RoBERTa model)"),NBe.forEach(t),Pe.forEach(t),J$r=i(Ul),T(y5.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),sqe=i(f),Xc=n(f,"H2",{class:!0});var gje=s(Xc);L5=n(gje,"A",{id:!0,class:!0,href:!0});var s5t=s(L5);GTe=n(s5t,"SPAN",{});var l5t=s(GTe);T(vx.$$.fragment,l5t),l5t.forEach(t),s5t.forEach(t),Y$r=i(gje),OTe=n(gje,"SPAN",{});var i5t=s(OTe);K$r=r(i5t,"FlaxAutoModelForQuestionAnswering"),i5t.forEach(t),gje.forEach(t),lqe=i(f),_r=n(f,"DIV",{class:!0});var Jl=s(_r);T(Fx.$$.fragment,Jl),Z$r=i(Jl),zc=n(Jl,"P",{});var xZ=s(zc);ekr=r(xZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),oY=n(xZ,"A",{href:!0});var d5t=s(oY);okr=r(d5t,"from_pretrained()"),d5t.forEach(t),rkr=r(xZ," class method or the "),rY=n(xZ,"A",{href:!0});var c5t=s(rY);tkr=r(c5t,"from_config()"),c5t.forEach(t),akr=r(xZ,` class
method.`),xZ.forEach(t),nkr=i(Jl),Tx=n(Jl,"P",{});var hje=s(Tx);skr=r(hje,"This class cannot be instantiated directly using "),VTe=n(hje,"CODE",{});var f5t=s(VTe);lkr=r(f5t,"__init__()"),f5t.forEach(t),ikr=r(hje," (throws an error)."),hje.forEach(t),dkr=i(Jl),zt=n(Jl,"DIV",{class:!0});var xw=s(zt);T(Mx.$$.fragment,xw),ckr=i(xw),XTe=n(xw,"P",{});var m5t=s(XTe);fkr=r(m5t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),m5t.forEach(t),mkr=i(xw),Qc=n(xw,"P",{});var $Z=s(Qc);gkr=r($Z,`Note:
Loading a model from its configuration file does `),zTe=n($Z,"STRONG",{});var g5t=s(zTe);hkr=r(g5t,"not"),g5t.forEach(t),pkr=r($Z,` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=n($Z,"A",{href:!0});var h5t=s(tY);ukr=r(h5t,"from_pretrained()"),h5t.forEach(t),_kr=r($Z," to load the model weights."),$Z.forEach(t),bkr=i(xw),T(x5.$$.fragment,xw),xw.forEach(t),vkr=i(Jl),zr=n(Jl,"DIV",{class:!0});var Yl=s(zr);T(Ex.$$.fragment,Yl),Fkr=i(Yl),QTe=n(Yl,"P",{});var p5t=s(QTe);Tkr=r(p5t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),p5t.forEach(t),Mkr=i(Yl),Fn=n(Yl,"P",{});var $w=s(Fn);Ekr=r($w,"The model class to instantiate is selected based on the "),WTe=n($w,"CODE",{});var u5t=s(WTe);Ckr=r(u5t,"model_type"),u5t.forEach(t),wkr=r($w,` property of the config object (either
passed as an argument or loaded from `),HTe=n($w,"CODE",{});var _5t=s(HTe);Akr=r(_5t,"pretrained_model_name_or_path"),_5t.forEach(t),ykr=r($w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UTe=n($w,"CODE",{});var b5t=s(UTe);Lkr=r(b5t,"pretrained_model_name_or_path"),b5t.forEach(t),xkr=r($w,":"),$w.forEach(t),$kr=i(Yl),$e=n(Yl,"UL",{});var Ie=s($e);$5=n(Ie,"LI",{});var jBe=s($5);JTe=n(jBe,"STRONG",{});var v5t=s(JTe);kkr=r(v5t,"albert"),v5t.forEach(t),Skr=r(jBe," \u2014 "),aY=n(jBe,"A",{href:!0});var F5t=s(aY);Rkr=r(F5t,"FlaxAlbertForQuestionAnswering"),F5t.forEach(t),Bkr=r(jBe," (ALBERT model)"),jBe.forEach(t),Pkr=i(Ie),k5=n(Ie,"LI",{});var DBe=s(k5);YTe=n(DBe,"STRONG",{});var T5t=s(YTe);Ikr=r(T5t,"bart"),T5t.forEach(t),qkr=r(DBe," \u2014 "),nY=n(DBe,"A",{href:!0});var M5t=s(nY);Nkr=r(M5t,"FlaxBartForQuestionAnswering"),M5t.forEach(t),jkr=r(DBe," (BART model)"),DBe.forEach(t),Dkr=i(Ie),S5=n(Ie,"LI",{});var GBe=s(S5);KTe=n(GBe,"STRONG",{});var E5t=s(KTe);Gkr=r(E5t,"bert"),E5t.forEach(t),Okr=r(GBe," \u2014 "),sY=n(GBe,"A",{href:!0});var C5t=s(sY);Vkr=r(C5t,"FlaxBertForQuestionAnswering"),C5t.forEach(t),Xkr=r(GBe," (BERT model)"),GBe.forEach(t),zkr=i(Ie),R5=n(Ie,"LI",{});var OBe=s(R5);ZTe=n(OBe,"STRONG",{});var w5t=s(ZTe);Qkr=r(w5t,"big_bird"),w5t.forEach(t),Wkr=r(OBe," \u2014 "),lY=n(OBe,"A",{href:!0});var A5t=s(lY);Hkr=r(A5t,"FlaxBigBirdForQuestionAnswering"),A5t.forEach(t),Ukr=r(OBe," (BigBird model)"),OBe.forEach(t),Jkr=i(Ie),B5=n(Ie,"LI",{});var VBe=s(B5);e9e=n(VBe,"STRONG",{});var y5t=s(e9e);Ykr=r(y5t,"distilbert"),y5t.forEach(t),Kkr=r(VBe," \u2014 "),iY=n(VBe,"A",{href:!0});var L5t=s(iY);Zkr=r(L5t,"FlaxDistilBertForQuestionAnswering"),L5t.forEach(t),eSr=r(VBe," (DistilBERT model)"),VBe.forEach(t),oSr=i(Ie),P5=n(Ie,"LI",{});var XBe=s(P5);o9e=n(XBe,"STRONG",{});var x5t=s(o9e);rSr=r(x5t,"electra"),x5t.forEach(t),tSr=r(XBe," \u2014 "),dY=n(XBe,"A",{href:!0});var $5t=s(dY);aSr=r($5t,"FlaxElectraForQuestionAnswering"),$5t.forEach(t),nSr=r(XBe," (ELECTRA model)"),XBe.forEach(t),sSr=i(Ie),I5=n(Ie,"LI",{});var zBe=s(I5);r9e=n(zBe,"STRONG",{});var k5t=s(r9e);lSr=r(k5t,"mbart"),k5t.forEach(t),iSr=r(zBe," \u2014 "),cY=n(zBe,"A",{href:!0});var S5t=s(cY);dSr=r(S5t,"FlaxMBartForQuestionAnswering"),S5t.forEach(t),cSr=r(zBe," (mBART model)"),zBe.forEach(t),fSr=i(Ie),q5=n(Ie,"LI",{});var QBe=s(q5);t9e=n(QBe,"STRONG",{});var R5t=s(t9e);mSr=r(R5t,"roberta"),R5t.forEach(t),gSr=r(QBe," \u2014 "),fY=n(QBe,"A",{href:!0});var B5t=s(fY);hSr=r(B5t,"FlaxRobertaForQuestionAnswering"),B5t.forEach(t),pSr=r(QBe," (RoBERTa model)"),QBe.forEach(t),uSr=i(Ie),N5=n(Ie,"LI",{});var WBe=s(N5);a9e=n(WBe,"STRONG",{});var P5t=s(a9e);_Sr=r(P5t,"roformer"),P5t.forEach(t),bSr=r(WBe," \u2014 "),mY=n(WBe,"A",{href:!0});var I5t=s(mY);vSr=r(I5t,"FlaxRoFormerForQuestionAnswering"),I5t.forEach(t),FSr=r(WBe," (RoFormer model)"),WBe.forEach(t),TSr=i(Ie),j5=n(Ie,"LI",{});var HBe=s(j5);n9e=n(HBe,"STRONG",{});var q5t=s(n9e);MSr=r(q5t,"xlm-roberta"),q5t.forEach(t),ESr=r(HBe," \u2014 "),gY=n(HBe,"A",{href:!0});var N5t=s(gY);CSr=r(N5t,"FlaxXLMRobertaForQuestionAnswering"),N5t.forEach(t),wSr=r(HBe," (XLM-RoBERTa model)"),HBe.forEach(t),Ie.forEach(t),ASr=i(Yl),T(D5.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),iqe=i(f),Wc=n(f,"H2",{class:!0});var pje=s(Wc);G5=n(pje,"A",{id:!0,class:!0,href:!0});var j5t=s(G5);s9e=n(j5t,"SPAN",{});var D5t=s(s9e);T(Cx.$$.fragment,D5t),D5t.forEach(t),j5t.forEach(t),ySr=i(pje),l9e=n(pje,"SPAN",{});var G5t=s(l9e);LSr=r(G5t,"FlaxAutoModelForTokenClassification"),G5t.forEach(t),pje.forEach(t),dqe=i(f),br=n(f,"DIV",{class:!0});var Kl=s(br);T(wx.$$.fragment,Kl),xSr=i(Kl),Hc=n(Kl,"P",{});var kZ=s(Hc);$Sr=r(kZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),hY=n(kZ,"A",{href:!0});var O5t=s(hY);kSr=r(O5t,"from_pretrained()"),O5t.forEach(t),SSr=r(kZ," class method or the "),pY=n(kZ,"A",{href:!0});var V5t=s(pY);RSr=r(V5t,"from_config()"),V5t.forEach(t),BSr=r(kZ,` class
method.`),kZ.forEach(t),PSr=i(Kl),Ax=n(Kl,"P",{});var uje=s(Ax);ISr=r(uje,"This class cannot be instantiated directly using "),i9e=n(uje,"CODE",{});var X5t=s(i9e);qSr=r(X5t,"__init__()"),X5t.forEach(t),NSr=r(uje," (throws an error)."),uje.forEach(t),jSr=i(Kl),Qt=n(Kl,"DIV",{class:!0});var kw=s(Qt);T(yx.$$.fragment,kw),DSr=i(kw),d9e=n(kw,"P",{});var z5t=s(d9e);GSr=r(z5t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),z5t.forEach(t),OSr=i(kw),Uc=n(kw,"P",{});var SZ=s(Uc);VSr=r(SZ,`Note:
Loading a model from its configuration file does `),c9e=n(SZ,"STRONG",{});var Q5t=s(c9e);XSr=r(Q5t,"not"),Q5t.forEach(t),zSr=r(SZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),uY=n(SZ,"A",{href:!0});var W5t=s(uY);QSr=r(W5t,"from_pretrained()"),W5t.forEach(t),WSr=r(SZ," to load the model weights."),SZ.forEach(t),HSr=i(kw),T(O5.$$.fragment,kw),kw.forEach(t),USr=i(Kl),Qr=n(Kl,"DIV",{class:!0});var Zl=s(Qr);T(Lx.$$.fragment,Zl),JSr=i(Zl),f9e=n(Zl,"P",{});var H5t=s(f9e);YSr=r(H5t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),H5t.forEach(t),KSr=i(Zl),Tn=n(Zl,"P",{});var Sw=s(Tn);ZSr=r(Sw,"The model class to instantiate is selected based on the "),m9e=n(Sw,"CODE",{});var U5t=s(m9e);eRr=r(U5t,"model_type"),U5t.forEach(t),oRr=r(Sw,` property of the config object (either
passed as an argument or loaded from `),g9e=n(Sw,"CODE",{});var J5t=s(g9e);rRr=r(J5t,"pretrained_model_name_or_path"),J5t.forEach(t),tRr=r(Sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h9e=n(Sw,"CODE",{});var Y5t=s(h9e);aRr=r(Y5t,"pretrained_model_name_or_path"),Y5t.forEach(t),nRr=r(Sw,":"),Sw.forEach(t),sRr=i(Zl),De=n(Zl,"UL",{});var Fo=s(De);V5=n(Fo,"LI",{});var UBe=s(V5);p9e=n(UBe,"STRONG",{});var K5t=s(p9e);lRr=r(K5t,"albert"),K5t.forEach(t),iRr=r(UBe," \u2014 "),_Y=n(UBe,"A",{href:!0});var Z5t=s(_Y);dRr=r(Z5t,"FlaxAlbertForTokenClassification"),Z5t.forEach(t),cRr=r(UBe," (ALBERT model)"),UBe.forEach(t),fRr=i(Fo),X5=n(Fo,"LI",{});var JBe=s(X5);u9e=n(JBe,"STRONG",{});var eCt=s(u9e);mRr=r(eCt,"bert"),eCt.forEach(t),gRr=r(JBe," \u2014 "),bY=n(JBe,"A",{href:!0});var oCt=s(bY);hRr=r(oCt,"FlaxBertForTokenClassification"),oCt.forEach(t),pRr=r(JBe," (BERT model)"),JBe.forEach(t),uRr=i(Fo),z5=n(Fo,"LI",{});var YBe=s(z5);_9e=n(YBe,"STRONG",{});var rCt=s(_9e);_Rr=r(rCt,"big_bird"),rCt.forEach(t),bRr=r(YBe," \u2014 "),vY=n(YBe,"A",{href:!0});var tCt=s(vY);vRr=r(tCt,"FlaxBigBirdForTokenClassification"),tCt.forEach(t),FRr=r(YBe," (BigBird model)"),YBe.forEach(t),TRr=i(Fo),Q5=n(Fo,"LI",{});var KBe=s(Q5);b9e=n(KBe,"STRONG",{});var aCt=s(b9e);MRr=r(aCt,"distilbert"),aCt.forEach(t),ERr=r(KBe," \u2014 "),FY=n(KBe,"A",{href:!0});var nCt=s(FY);CRr=r(nCt,"FlaxDistilBertForTokenClassification"),nCt.forEach(t),wRr=r(KBe," (DistilBERT model)"),KBe.forEach(t),ARr=i(Fo),W5=n(Fo,"LI",{});var ZBe=s(W5);v9e=n(ZBe,"STRONG",{});var sCt=s(v9e);yRr=r(sCt,"electra"),sCt.forEach(t),LRr=r(ZBe," \u2014 "),TY=n(ZBe,"A",{href:!0});var lCt=s(TY);xRr=r(lCt,"FlaxElectraForTokenClassification"),lCt.forEach(t),$Rr=r(ZBe," (ELECTRA model)"),ZBe.forEach(t),kRr=i(Fo),H5=n(Fo,"LI",{});var ePe=s(H5);F9e=n(ePe,"STRONG",{});var iCt=s(F9e);SRr=r(iCt,"roberta"),iCt.forEach(t),RRr=r(ePe," \u2014 "),MY=n(ePe,"A",{href:!0});var dCt=s(MY);BRr=r(dCt,"FlaxRobertaForTokenClassification"),dCt.forEach(t),PRr=r(ePe," (RoBERTa model)"),ePe.forEach(t),IRr=i(Fo),U5=n(Fo,"LI",{});var oPe=s(U5);T9e=n(oPe,"STRONG",{});var cCt=s(T9e);qRr=r(cCt,"roformer"),cCt.forEach(t),NRr=r(oPe," \u2014 "),EY=n(oPe,"A",{href:!0});var fCt=s(EY);jRr=r(fCt,"FlaxRoFormerForTokenClassification"),fCt.forEach(t),DRr=r(oPe," (RoFormer model)"),oPe.forEach(t),GRr=i(Fo),J5=n(Fo,"LI",{});var rPe=s(J5);M9e=n(rPe,"STRONG",{});var mCt=s(M9e);ORr=r(mCt,"xlm-roberta"),mCt.forEach(t),VRr=r(rPe," \u2014 "),CY=n(rPe,"A",{href:!0});var gCt=s(CY);XRr=r(gCt,"FlaxXLMRobertaForTokenClassification"),gCt.forEach(t),zRr=r(rPe," (XLM-RoBERTa model)"),rPe.forEach(t),Fo.forEach(t),QRr=i(Zl),T(Y5.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),cqe=i(f),Jc=n(f,"H2",{class:!0});var _je=s(Jc);K5=n(_je,"A",{id:!0,class:!0,href:!0});var hCt=s(K5);E9e=n(hCt,"SPAN",{});var pCt=s(E9e);T(xx.$$.fragment,pCt),pCt.forEach(t),hCt.forEach(t),WRr=i(_je),C9e=n(_je,"SPAN",{});var uCt=s(C9e);HRr=r(uCt,"FlaxAutoModelForMultipleChoice"),uCt.forEach(t),_je.forEach(t),fqe=i(f),vr=n(f,"DIV",{class:!0});var ei=s(vr);T($x.$$.fragment,ei),URr=i(ei),Yc=n(ei,"P",{});var RZ=s(Yc);JRr=r(RZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),wY=n(RZ,"A",{href:!0});var _Ct=s(wY);YRr=r(_Ct,"from_pretrained()"),_Ct.forEach(t),KRr=r(RZ," class method or the "),AY=n(RZ,"A",{href:!0});var bCt=s(AY);ZRr=r(bCt,"from_config()"),bCt.forEach(t),eBr=r(RZ,` class
method.`),RZ.forEach(t),oBr=i(ei),kx=n(ei,"P",{});var bje=s(kx);rBr=r(bje,"This class cannot be instantiated directly using "),w9e=n(bje,"CODE",{});var vCt=s(w9e);tBr=r(vCt,"__init__()"),vCt.forEach(t),aBr=r(bje," (throws an error)."),bje.forEach(t),nBr=i(ei),Wt=n(ei,"DIV",{class:!0});var Rw=s(Wt);T(Sx.$$.fragment,Rw),sBr=i(Rw),A9e=n(Rw,"P",{});var FCt=s(A9e);lBr=r(FCt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),FCt.forEach(t),iBr=i(Rw),Kc=n(Rw,"P",{});var BZ=s(Kc);dBr=r(BZ,`Note:
Loading a model from its configuration file does `),y9e=n(BZ,"STRONG",{});var TCt=s(y9e);cBr=r(TCt,"not"),TCt.forEach(t),fBr=r(BZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=n(BZ,"A",{href:!0});var MCt=s(yY);mBr=r(MCt,"from_pretrained()"),MCt.forEach(t),gBr=r(BZ," to load the model weights."),BZ.forEach(t),hBr=i(Rw),T(Z5.$$.fragment,Rw),Rw.forEach(t),pBr=i(ei),Wr=n(ei,"DIV",{class:!0});var oi=s(Wr);T(Rx.$$.fragment,oi),uBr=i(oi),L9e=n(oi,"P",{});var ECt=s(L9e);_Br=r(ECt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ECt.forEach(t),bBr=i(oi),Mn=n(oi,"P",{});var Bw=s(Mn);vBr=r(Bw,"The model class to instantiate is selected based on the "),x9e=n(Bw,"CODE",{});var CCt=s(x9e);FBr=r(CCt,"model_type"),CCt.forEach(t),TBr=r(Bw,` property of the config object (either
passed as an argument or loaded from `),$9e=n(Bw,"CODE",{});var wCt=s($9e);MBr=r(wCt,"pretrained_model_name_or_path"),wCt.forEach(t),EBr=r(Bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k9e=n(Bw,"CODE",{});var ACt=s(k9e);CBr=r(ACt,"pretrained_model_name_or_path"),ACt.forEach(t),wBr=r(Bw,":"),Bw.forEach(t),ABr=i(oi),Ge=n(oi,"UL",{});var To=s(Ge);eC=n(To,"LI",{});var tPe=s(eC);S9e=n(tPe,"STRONG",{});var yCt=s(S9e);yBr=r(yCt,"albert"),yCt.forEach(t),LBr=r(tPe," \u2014 "),LY=n(tPe,"A",{href:!0});var LCt=s(LY);xBr=r(LCt,"FlaxAlbertForMultipleChoice"),LCt.forEach(t),$Br=r(tPe," (ALBERT model)"),tPe.forEach(t),kBr=i(To),oC=n(To,"LI",{});var aPe=s(oC);R9e=n(aPe,"STRONG",{});var xCt=s(R9e);SBr=r(xCt,"bert"),xCt.forEach(t),RBr=r(aPe," \u2014 "),xY=n(aPe,"A",{href:!0});var $Ct=s(xY);BBr=r($Ct,"FlaxBertForMultipleChoice"),$Ct.forEach(t),PBr=r(aPe," (BERT model)"),aPe.forEach(t),IBr=i(To),rC=n(To,"LI",{});var nPe=s(rC);B9e=n(nPe,"STRONG",{});var kCt=s(B9e);qBr=r(kCt,"big_bird"),kCt.forEach(t),NBr=r(nPe," \u2014 "),$Y=n(nPe,"A",{href:!0});var SCt=s($Y);jBr=r(SCt,"FlaxBigBirdForMultipleChoice"),SCt.forEach(t),DBr=r(nPe," (BigBird model)"),nPe.forEach(t),GBr=i(To),tC=n(To,"LI",{});var sPe=s(tC);P9e=n(sPe,"STRONG",{});var RCt=s(P9e);OBr=r(RCt,"distilbert"),RCt.forEach(t),VBr=r(sPe," \u2014 "),kY=n(sPe,"A",{href:!0});var BCt=s(kY);XBr=r(BCt,"FlaxDistilBertForMultipleChoice"),BCt.forEach(t),zBr=r(sPe," (DistilBERT model)"),sPe.forEach(t),QBr=i(To),aC=n(To,"LI",{});var lPe=s(aC);I9e=n(lPe,"STRONG",{});var PCt=s(I9e);WBr=r(PCt,"electra"),PCt.forEach(t),HBr=r(lPe," \u2014 "),SY=n(lPe,"A",{href:!0});var ICt=s(SY);UBr=r(ICt,"FlaxElectraForMultipleChoice"),ICt.forEach(t),JBr=r(lPe," (ELECTRA model)"),lPe.forEach(t),YBr=i(To),nC=n(To,"LI",{});var iPe=s(nC);q9e=n(iPe,"STRONG",{});var qCt=s(q9e);KBr=r(qCt,"roberta"),qCt.forEach(t),ZBr=r(iPe," \u2014 "),RY=n(iPe,"A",{href:!0});var NCt=s(RY);ePr=r(NCt,"FlaxRobertaForMultipleChoice"),NCt.forEach(t),oPr=r(iPe," (RoBERTa model)"),iPe.forEach(t),rPr=i(To),sC=n(To,"LI",{});var dPe=s(sC);N9e=n(dPe,"STRONG",{});var jCt=s(N9e);tPr=r(jCt,"roformer"),jCt.forEach(t),aPr=r(dPe," \u2014 "),BY=n(dPe,"A",{href:!0});var DCt=s(BY);nPr=r(DCt,"FlaxRoFormerForMultipleChoice"),DCt.forEach(t),sPr=r(dPe," (RoFormer model)"),dPe.forEach(t),lPr=i(To),lC=n(To,"LI",{});var cPe=s(lC);j9e=n(cPe,"STRONG",{});var GCt=s(j9e);iPr=r(GCt,"xlm-roberta"),GCt.forEach(t),dPr=r(cPe," \u2014 "),PY=n(cPe,"A",{href:!0});var OCt=s(PY);cPr=r(OCt,"FlaxXLMRobertaForMultipleChoice"),OCt.forEach(t),fPr=r(cPe," (XLM-RoBERTa model)"),cPe.forEach(t),To.forEach(t),mPr=i(oi),T(iC.$$.fragment,oi),oi.forEach(t),ei.forEach(t),mqe=i(f),Zc=n(f,"H2",{class:!0});var vje=s(Zc);dC=n(vje,"A",{id:!0,class:!0,href:!0});var VCt=s(dC);D9e=n(VCt,"SPAN",{});var XCt=s(D9e);T(Bx.$$.fragment,XCt),XCt.forEach(t),VCt.forEach(t),gPr=i(vje),G9e=n(vje,"SPAN",{});var zCt=s(G9e);hPr=r(zCt,"FlaxAutoModelForNextSentencePrediction"),zCt.forEach(t),vje.forEach(t),gqe=i(f),Fr=n(f,"DIV",{class:!0});var ri=s(Fr);T(Px.$$.fragment,ri),pPr=i(ri),ef=n(ri,"P",{});var PZ=s(ef);uPr=r(PZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),IY=n(PZ,"A",{href:!0});var QCt=s(IY);_Pr=r(QCt,"from_pretrained()"),QCt.forEach(t),bPr=r(PZ," class method or the "),qY=n(PZ,"A",{href:!0});var WCt=s(qY);vPr=r(WCt,"from_config()"),WCt.forEach(t),FPr=r(PZ,` class
method.`),PZ.forEach(t),TPr=i(ri),Ix=n(ri,"P",{});var Fje=s(Ix);MPr=r(Fje,"This class cannot be instantiated directly using "),O9e=n(Fje,"CODE",{});var HCt=s(O9e);EPr=r(HCt,"__init__()"),HCt.forEach(t),CPr=r(Fje," (throws an error)."),Fje.forEach(t),wPr=i(ri),Ht=n(ri,"DIV",{class:!0});var Pw=s(Ht);T(qx.$$.fragment,Pw),APr=i(Pw),V9e=n(Pw,"P",{});var UCt=s(V9e);yPr=r(UCt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),UCt.forEach(t),LPr=i(Pw),of=n(Pw,"P",{});var IZ=s(of);xPr=r(IZ,`Note:
Loading a model from its configuration file does `),X9e=n(IZ,"STRONG",{});var JCt=s(X9e);$Pr=r(JCt,"not"),JCt.forEach(t),kPr=r(IZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),NY=n(IZ,"A",{href:!0});var YCt=s(NY);SPr=r(YCt,"from_pretrained()"),YCt.forEach(t),RPr=r(IZ," to load the model weights."),IZ.forEach(t),BPr=i(Pw),T(cC.$$.fragment,Pw),Pw.forEach(t),PPr=i(ri),Hr=n(ri,"DIV",{class:!0});var ti=s(Hr);T(Nx.$$.fragment,ti),IPr=i(ti),z9e=n(ti,"P",{});var KCt=s(z9e);qPr=r(KCt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),KCt.forEach(t),NPr=i(ti),En=n(ti,"P",{});var Iw=s(En);jPr=r(Iw,"The model class to instantiate is selected based on the "),Q9e=n(Iw,"CODE",{});var ZCt=s(Q9e);DPr=r(ZCt,"model_type"),ZCt.forEach(t),GPr=r(Iw,` property of the config object (either
passed as an argument or loaded from `),W9e=n(Iw,"CODE",{});var e3t=s(W9e);OPr=r(e3t,"pretrained_model_name_or_path"),e3t.forEach(t),VPr=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H9e=n(Iw,"CODE",{});var o3t=s(H9e);XPr=r(o3t,"pretrained_model_name_or_path"),o3t.forEach(t),zPr=r(Iw,":"),Iw.forEach(t),QPr=i(ti),U9e=n(ti,"UL",{});var r3t=s(U9e);fC=n(r3t,"LI",{});var fPe=s(fC);J9e=n(fPe,"STRONG",{});var t3t=s(J9e);WPr=r(t3t,"bert"),t3t.forEach(t),HPr=r(fPe," \u2014 "),jY=n(fPe,"A",{href:!0});var a3t=s(jY);UPr=r(a3t,"FlaxBertForNextSentencePrediction"),a3t.forEach(t),JPr=r(fPe," (BERT model)"),fPe.forEach(t),r3t.forEach(t),YPr=i(ti),T(mC.$$.fragment,ti),ti.forEach(t),ri.forEach(t),hqe=i(f),rf=n(f,"H2",{class:!0});var Tje=s(rf);gC=n(Tje,"A",{id:!0,class:!0,href:!0});var n3t=s(gC);Y9e=n(n3t,"SPAN",{});var s3t=s(Y9e);T(jx.$$.fragment,s3t),s3t.forEach(t),n3t.forEach(t),KPr=i(Tje),K9e=n(Tje,"SPAN",{});var l3t=s(K9e);ZPr=r(l3t,"FlaxAutoModelForImageClassification"),l3t.forEach(t),Tje.forEach(t),pqe=i(f),Tr=n(f,"DIV",{class:!0});var ai=s(Tr);T(Dx.$$.fragment,ai),eIr=i(ai),tf=n(ai,"P",{});var qZ=s(tf);oIr=r(qZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),DY=n(qZ,"A",{href:!0});var i3t=s(DY);rIr=r(i3t,"from_pretrained()"),i3t.forEach(t),tIr=r(qZ," class method or the "),GY=n(qZ,"A",{href:!0});var d3t=s(GY);aIr=r(d3t,"from_config()"),d3t.forEach(t),nIr=r(qZ,` class
method.`),qZ.forEach(t),sIr=i(ai),Gx=n(ai,"P",{});var Mje=s(Gx);lIr=r(Mje,"This class cannot be instantiated directly using "),Z9e=n(Mje,"CODE",{});var c3t=s(Z9e);iIr=r(c3t,"__init__()"),c3t.forEach(t),dIr=r(Mje," (throws an error)."),Mje.forEach(t),cIr=i(ai),Ut=n(ai,"DIV",{class:!0});var qw=s(Ut);T(Ox.$$.fragment,qw),fIr=i(qw),eMe=n(qw,"P",{});var f3t=s(eMe);mIr=r(f3t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),f3t.forEach(t),gIr=i(qw),af=n(qw,"P",{});var NZ=s(af);hIr=r(NZ,`Note:
Loading a model from its configuration file does `),oMe=n(NZ,"STRONG",{});var m3t=s(oMe);pIr=r(m3t,"not"),m3t.forEach(t),uIr=r(NZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),OY=n(NZ,"A",{href:!0});var g3t=s(OY);_Ir=r(g3t,"from_pretrained()"),g3t.forEach(t),bIr=r(NZ," to load the model weights."),NZ.forEach(t),vIr=i(qw),T(hC.$$.fragment,qw),qw.forEach(t),FIr=i(ai),Ur=n(ai,"DIV",{class:!0});var ni=s(Ur);T(Vx.$$.fragment,ni),TIr=i(ni),rMe=n(ni,"P",{});var h3t=s(rMe);MIr=r(h3t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),h3t.forEach(t),EIr=i(ni),Cn=n(ni,"P",{});var Nw=s(Cn);CIr=r(Nw,"The model class to instantiate is selected based on the "),tMe=n(Nw,"CODE",{});var p3t=s(tMe);wIr=r(p3t,"model_type"),p3t.forEach(t),AIr=r(Nw,` property of the config object (either
passed as an argument or loaded from `),aMe=n(Nw,"CODE",{});var u3t=s(aMe);yIr=r(u3t,"pretrained_model_name_or_path"),u3t.forEach(t),LIr=r(Nw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=n(Nw,"CODE",{});var _3t=s(nMe);xIr=r(_3t,"pretrained_model_name_or_path"),_3t.forEach(t),$Ir=r(Nw,":"),Nw.forEach(t),kIr=i(ni),Xx=n(ni,"UL",{});var Eje=s(Xx);pC=n(Eje,"LI",{});var mPe=s(pC);sMe=n(mPe,"STRONG",{});var b3t=s(sMe);SIr=r(b3t,"beit"),b3t.forEach(t),RIr=r(mPe," \u2014 "),VY=n(mPe,"A",{href:!0});var v3t=s(VY);BIr=r(v3t,"FlaxBeitForImageClassification"),v3t.forEach(t),PIr=r(mPe," (BEiT model)"),mPe.forEach(t),IIr=i(Eje),uC=n(Eje,"LI",{});var gPe=s(uC);lMe=n(gPe,"STRONG",{});var F3t=s(lMe);qIr=r(F3t,"vit"),F3t.forEach(t),NIr=r(gPe," \u2014 "),XY=n(gPe,"A",{href:!0});var T3t=s(XY);jIr=r(T3t,"FlaxViTForImageClassification"),T3t.forEach(t),DIr=r(gPe," (ViT model)"),gPe.forEach(t),Eje.forEach(t),GIr=i(ni),T(_C.$$.fragment,ni),ni.forEach(t),ai.forEach(t),uqe=i(f),nf=n(f,"H2",{class:!0});var Cje=s(nf);bC=n(Cje,"A",{id:!0,class:!0,href:!0});var M3t=s(bC);iMe=n(M3t,"SPAN",{});var E3t=s(iMe);T(zx.$$.fragment,E3t),E3t.forEach(t),M3t.forEach(t),OIr=i(Cje),dMe=n(Cje,"SPAN",{});var C3t=s(dMe);VIr=r(C3t,"FlaxAutoModelForVision2Seq"),C3t.forEach(t),Cje.forEach(t),_qe=i(f),Mr=n(f,"DIV",{class:!0});var si=s(Mr);T(Qx.$$.fragment,si),XIr=i(si),sf=n(si,"P",{});var jZ=s(sf);zIr=r(jZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),zY=n(jZ,"A",{href:!0});var w3t=s(zY);QIr=r(w3t,"from_pretrained()"),w3t.forEach(t),WIr=r(jZ," class method or the "),QY=n(jZ,"A",{href:!0});var A3t=s(QY);HIr=r(A3t,"from_config()"),A3t.forEach(t),UIr=r(jZ,` class
method.`),jZ.forEach(t),JIr=i(si),Wx=n(si,"P",{});var wje=s(Wx);YIr=r(wje,"This class cannot be instantiated directly using "),cMe=n(wje,"CODE",{});var y3t=s(cMe);KIr=r(y3t,"__init__()"),y3t.forEach(t),ZIr=r(wje," (throws an error)."),wje.forEach(t),eqr=i(si),Jt=n(si,"DIV",{class:!0});var jw=s(Jt);T(Hx.$$.fragment,jw),oqr=i(jw),fMe=n(jw,"P",{});var L3t=s(fMe);rqr=r(L3t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),L3t.forEach(t),tqr=i(jw),lf=n(jw,"P",{});var DZ=s(lf);aqr=r(DZ,`Note:
Loading a model from its configuration file does `),mMe=n(DZ,"STRONG",{});var x3t=s(mMe);nqr=r(x3t,"not"),x3t.forEach(t),sqr=r(DZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),WY=n(DZ,"A",{href:!0});var $3t=s(WY);lqr=r($3t,"from_pretrained()"),$3t.forEach(t),iqr=r(DZ," to load the model weights."),DZ.forEach(t),dqr=i(jw),T(vC.$$.fragment,jw),jw.forEach(t),cqr=i(si),Jr=n(si,"DIV",{class:!0});var li=s(Jr);T(Ux.$$.fragment,li),fqr=i(li),gMe=n(li,"P",{});var k3t=s(gMe);mqr=r(k3t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),k3t.forEach(t),gqr=i(li),wn=n(li,"P",{});var Dw=s(wn);hqr=r(Dw,"The model class to instantiate is selected based on the "),hMe=n(Dw,"CODE",{});var S3t=s(hMe);pqr=r(S3t,"model_type"),S3t.forEach(t),uqr=r(Dw,` property of the config object (either
passed as an argument or loaded from `),pMe=n(Dw,"CODE",{});var R3t=s(pMe);_qr=r(R3t,"pretrained_model_name_or_path"),R3t.forEach(t),bqr=r(Dw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uMe=n(Dw,"CODE",{});var B3t=s(uMe);vqr=r(B3t,"pretrained_model_name_or_path"),B3t.forEach(t),Fqr=r(Dw,":"),Dw.forEach(t),Tqr=i(li),_Me=n(li,"UL",{});var P3t=s(_Me);FC=n(P3t,"LI",{});var hPe=s(FC);bMe=n(hPe,"STRONG",{});var I3t=s(bMe);Mqr=r(I3t,"vision-encoder-decoder"),I3t.forEach(t),Eqr=r(hPe," \u2014 "),HY=n(hPe,"A",{href:!0});var q3t=s(HY);Cqr=r(q3t,"FlaxVisionEncoderDecoderModel"),q3t.forEach(t),wqr=r(hPe," (Vision Encoder decoder model)"),hPe.forEach(t),P3t.forEach(t),Aqr=i(li),T(TC.$$.fragment,li),li.forEach(t),si.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(GAt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(yn,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.AutoConfig"),c(xn,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.AutoModel"),c($n,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.AutoTokenizer"),c(hi,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertModel"),c(uf,"id","extending-the-auto-classes"),c(uf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uf,"href","#extending-the-auto-classes"),c(pi,"class","relative group"),c(bf,"id","transformers.AutoConfig"),c(bf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bf,"href","#transformers.AutoConfig"),c(ui,"class","relative group"),c(h$,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(p$,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertConfig"),c(u$,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig"),c(_$,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitConfig"),c(b$,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertConfig"),c(v$,"href","/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(F$,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdConfig"),c(T$,"href","/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(M$,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(E$,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(C$,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertConfig"),c(w$,"href","/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineConfig"),c(A$,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPConfig"),c(y$,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertConfig"),c(L$,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextConfig"),c(x$,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLConfig"),c($$,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(k$,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(S$,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(R$,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaConfig"),c(B$,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(P$,"href","/docs/transformers/pr_16988/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(I$,"href","/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTConfig"),c(q$,"href","/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrConfig"),c(N$,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertConfig"),c(j$,"href","/docs/transformers/pr_16988/en/model_doc/dpr#transformers.DPRConfig"),c(D$,"href","/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTConfig"),c(G$,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraConfig"),c(O$,"href","/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(V$,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertConfig"),c(X$,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetConfig"),c(z$,"href","/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTConfig"),c(Q$,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelConfig"),c(W$,"href","/docs/transformers/pr_16988/en/model_doc/glpn#transformers.GLPNConfig"),c(H$,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Config"),c(U$,"href","/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(J$,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJConfig"),c(Y$,"href","/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertConfig"),c(K$,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertConfig"),c(Z$,"href","/docs/transformers/pr_16988/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(ek,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(ok,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(rk,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDConfig"),c(tk,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerConfig"),c(ak,"href","/docs/transformers/pr_16988/en/model_doc/luke#transformers.LukeConfig"),c(nk,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertConfig"),c(sk,"href","/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100Config"),c(lk,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianConfig"),c(ik,"href","/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(dk,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartConfig"),c(ck,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(fk,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(mk,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetConfig"),c(gk,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Config"),c(hk,"href","/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(pk,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(uk,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusConfig"),c(_k,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverConfig"),c(bk,"href","/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartConfig"),c(vk,"href","/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(Fk,"href","/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(Tk,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(Mk,"href","/docs/transformers/pr_16988/en/model_doc/rag#transformers.RagConfig"),c(Ek,"href","/docs/transformers/pr_16988/en/model_doc/realm#transformers.RealmConfig"),c(Ck,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerConfig"),c(wk,"href","/docs/transformers/pr_16988/en/model_doc/regnet#transformers.RegNetConfig"),c(Ak,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertConfig"),c(yk,"href","/docs/transformers/pr_16988/en/model_doc/resnet#transformers.ResNetConfig"),c(Lk,"href","/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertConfig"),c(xk,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaConfig"),c($k,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerConfig"),c(kk,"href","/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerConfig"),c(Sk,"href","/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWConfig"),c(Rk,"href","/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDConfig"),c(Bk,"href","/docs/transformers/pr_16988/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(Pk,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(Ik,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(qk,"href","/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterConfig"),c(Nk,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(jk,"href","/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinConfig"),c(Dk,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Config"),c(Gk,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasConfig"),c(Ok,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartConfig"),c(Vk,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(Xk,"href","/docs/transformers/pr_16988/en/model_doc/trocr#transformers.TrOCRConfig"),c(zk,"href","/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(Qk,"href","/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(Wk,"href","/docs/transformers/pr_16988/en/model_doc/van#transformers.VanConfig"),c(Hk,"href","/docs/transformers/pr_16988/en/model_doc/vilt#transformers.ViltConfig"),c(Uk,"href","/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(Jk,"href","/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(Yk,"href","/docs/transformers/pr_16988/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(Kk,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTConfig"),c(Zk,"href","/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(eS,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(oS,"href","/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMConfig"),c(rS,"href","/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMConfig"),c(tS,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMConfig"),c(aS,"href","/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(nS,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(sS,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(lS,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetConfig"),c(iS,"href","/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosConfig"),c(dS,"href","/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ug,"id","transformers.AutoTokenizer"),c(ug,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ug,"href","#transformers.AutoTokenizer"),c(bi,"class","relative group"),c(cS,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(fS,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertTokenizer"),c(mS,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(gS,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartTokenizer"),c(hS,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartTokenizerFast"),c(pS,"href","/docs/transformers/pr_16988/en/model_doc/barthez#transformers.BarthezTokenizer"),c(uS,"href","/docs/transformers/pr_16988/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(_S,"href","/docs/transformers/pr_16988/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(bS,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizer"),c(vS,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizerFast"),c(FS,"href","/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(TS,"href","/docs/transformers/pr_16988/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(MS,"href","/docs/transformers/pr_16988/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(ES,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(CS,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(wS,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(AS,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(yS,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(LS,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(xS,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c($S,"href","/docs/transformers/pr_16988/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(kS,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertTokenizer"),c(SS,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(RS,"href","/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineTokenizer"),c(BS,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPTokenizer"),c(PS,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(IS,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(qS,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(NS,"href","/docs/transformers/pr_16988/en/model_doc/cpm#transformers.CpmTokenizer"),c(jS,"href","/docs/transformers/pr_16988/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(DS,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(GS,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizer"),c(OS,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(VS,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaTokenizer"),c(XS,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(zS,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(QS,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(WS,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(HS,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(US,"href","/docs/transformers/pr_16988/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(JS,"href","/docs/transformers/pr_16988/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(YS,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraTokenizer"),c(KS,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(ZS,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(eR,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetTokenizer"),c(oR,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(rR,"href","/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(tR,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelTokenizer"),c(aR,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(nR,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(sR,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(lR,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iR,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(dR,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(cR,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(fR,"href","/docs/transformers/pr_16988/en/model_doc/herbert#transformers.HerbertTokenizer"),c(mR,"href","/docs/transformers/pr_16988/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(gR,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(hR,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizer"),c(pR,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(uR,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(_R,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(bR,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(vR,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(FR,"href","/docs/transformers/pr_16988/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(TR,"href","/docs/transformers/pr_16988/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(MR,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDTokenizer"),c(ER,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDTokenizerFast"),c(CR,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerTokenizer"),c(wR,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(AR,"href","/docs/transformers/pr_16988/en/model_doc/luke#transformers.LukeTokenizer"),c(yR,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(LR,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(xR,"href","/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c($R,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianTokenizer"),c(kR,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartTokenizer"),c(SR,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(RR,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(BR,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(PR,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizer"),c(IR,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizerFast"),c(qR,"href","/docs/transformers/pr_16988/en/model_doc/mluke#transformers.MLukeTokenizer"),c(NR,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(jR,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(DR,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(GR,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(OR,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.T5Tokenizer"),c(VR,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.T5TokenizerFast"),c(XR,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertTokenizer"),c(zR,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(QR,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(WR,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(HR,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(UR,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(JR,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(YR,"href","/docs/transformers/pr_16988/en/model_doc/phobert#transformers.PhobertTokenizer"),c(KR,"href","/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartTokenizer"),c(ZR,"href","/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(eB,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizer"),c(oB,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizerFast"),c(rB,"href","/docs/transformers/pr_16988/en/model_doc/rag#transformers.RagTokenizer"),c(tB,"href","/docs/transformers/pr_16988/en/model_doc/realm#transformers.RealmTokenizer"),c(aB,"href","/docs/transformers/pr_16988/en/model_doc/realm#transformers.RealmTokenizerFast"),c(nB,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerTokenizer"),c(sB,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(lB,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertTokenizer"),c(iB,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(dB,"href","/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(cB,"href","/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(fB,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizer"),c(mB,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(gB,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(hB,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(pB,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(uB,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(_B,"href","/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterTokenizer"),c(bB,"href","/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(vB,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(FB,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(TB,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.T5Tokenizer"),c(MB,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.T5TokenizerFast"),c(EB,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasTokenizer"),c(CB,"href","/docs/transformers/pr_16988/en/model_doc/tapex#transformers.TapexTokenizer"),c(wB,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(AB,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizer"),c(yB,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertTokenizerFast"),c(LB,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(xB,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c($B,"href","/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMTokenizer"),c(kB,"href","/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(SB,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMTokenizer"),c(RB,"href","/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(BB,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(PB,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(IB,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizer"),c(qB,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(NB,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(jB,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(DB,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertTokenizer"),c(GB,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hg,"id","transformers.AutoFeatureExtractor"),c(Hg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hg,"href","#transformers.AutoFeatureExtractor"),c(vi,"class","relative group"),c(OB,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(VB,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(XB,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(zB,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(QB,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(WB,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(HB,"href","/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(UB,"href","/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(JB,"href","/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(YB,"href","/docs/transformers/pr_16988/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(KB,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(ZB,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(eP,"href","/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(oP,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(rP,"href","/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(tP,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(aP,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(nP,"href","/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(sP,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(lP,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(iP,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dP,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(cP,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(fP,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(mP,"href","/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Th,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mh,"id","transformers.AutoProcessor"),c(Mh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mh,"href","#transformers.AutoProcessor"),c(Fi,"class","relative group"),c(gP,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(hP,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPProcessor"),c(pP,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(uP,"href","/docs/transformers/pr_16988/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(_P,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(bP,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(vP,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(FP,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(TP,"href","/docs/transformers/pr_16988/en/model_doc/trocr#transformers.TrOCRProcessor"),c(MP,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(EP,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(CP,"href","/docs/transformers/pr_16988/en/model_doc/vilt#transformers.ViltProcessor"),c(wP,"href","/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(AP,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(yP,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dh,"id","transformers.AutoModel"),c(Dh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Dh,"href","#transformers.AutoModel"),c(Mi,"class","relative group"),c(LP,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xP,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($P,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kP,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertModel"),c(SP,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartModel"),c(RP,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitModel"),c(BP,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertModel"),c(PP,"href","/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(IP,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdModel"),c(qP,"href","/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(NP,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(jP,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(DP,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertModel"),c(GP,"href","/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineModel"),c(OP,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.CLIPModel"),c(VP,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertModel"),c(XP,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextModel"),c(zP,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLModel"),c(QP,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(WP,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(HP,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(UP,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaModel"),c(JP,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(YP,"href","/docs/transformers/pr_16988/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(KP,"href","/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTModel"),c(ZP,"href","/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrModel"),c(eI,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertModel"),c(oI,"href","/docs/transformers/pr_16988/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(rI,"href","/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTModel"),c(tI,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraModel"),c(aI,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertModel"),c(nI,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetModel"),c(sI,"href","/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTModel"),c(lI,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelModel"),c(iI,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelBaseModel"),c(dI,"href","/docs/transformers/pr_16988/en/model_doc/glpn#transformers.GLPNModel"),c(cI,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2Model"),c(fI,"href","/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(mI,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJModel"),c(gI,"href","/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertModel"),c(hI,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertModel"),c(pI,"href","/docs/transformers/pr_16988/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(uI,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(_I,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(bI,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDModel"),c(vI,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerModel"),c(FI,"href","/docs/transformers/pr_16988/en/model_doc/luke#transformers.LukeModel"),c(TI,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertModel"),c(MI,"href","/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100Model"),c(EI,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianModel"),c(CI,"href","/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerModel"),c(wI,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartModel"),c(AI,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(yI,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertModel"),c(LI,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetModel"),c(xI,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5Model"),c($I,"href","/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerModel"),c(kI,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(SI,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusModel"),c(RI,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverModel"),c(BI,"href","/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartModel"),c(PI,"href","/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerModel"),c(II,"href","/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(qI,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertModel"),c(NI,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerModel"),c(jI,"href","/docs/transformers/pr_16988/en/model_doc/regnet#transformers.RegNetModel"),c(DI,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertModel"),c(GI,"href","/docs/transformers/pr_16988/en/model_doc/resnet#transformers.ResNetModel"),c(OI,"href","/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertModel"),c(VI,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaModel"),c(XI,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerModel"),c(zI,"href","/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerModel"),c(QI,"href","/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWModel"),c(WI,"href","/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDModel"),c(HI,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(UI,"href","/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterModel"),c(JI,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(YI,"href","/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinModel"),c(KI,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5Model"),c(ZI,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasModel"),c(eq,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(oq,"href","/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechModel"),c(rq,"href","/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(tq,"href","/docs/transformers/pr_16988/en/model_doc/van#transformers.VanModel"),c(aq,"href","/docs/transformers/pr_16988/en/model_doc/vilt#transformers.ViltModel"),c(nq,"href","/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(sq,"href","/docs/transformers/pr_16988/en/model_doc/visual_bert#transformers.VisualBertModel"),c(lq,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTModel"),c(iq,"href","/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(dq,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(cq,"href","/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMModel"),c(fq,"href","/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMModel"),c(mq,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMModel"),c(gq,"href","/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(hq,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(pq,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(uq,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetModel"),c(_q,"href","/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosModel"),c(bq,"href","/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoModel"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoModelForPreTraining"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoModelForPreTraining"),c(wi,"class","relative group"),c(vq,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fq,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tq,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mq,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForPreTraining"),c(Eq,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Cq,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForPreTraining"),c(wq,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(Aq,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(yq,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Lq,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(xq,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c($q,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(kq,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Sq,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForPreTraining"),c(Rq,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Bq,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForPreTraining"),c(Pq,"href","/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(Iq,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(qq,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Nq,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(jq,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(Dq,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(Gq,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(Oq,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(Vq,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(Xq,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(zq,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Qq,"href","/docs/transformers/pr_16988/en/model_doc/retribert#transformers.RetriBertModel"),c(Wq,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(Hq,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(Uq,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(Jq,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(Yq,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(Kq,"href","/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(Zq,"href","/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(eN,"href","/docs/transformers/pr_16988/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(oN,"href","/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(rN,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(tN,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(aN,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(nN,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(sN,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v_,"id","transformers.AutoModelForCausalLM"),c(v_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v_,"href","#transformers.AutoModelForCausalLM"),c(Li,"class","relative group"),c(lN,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iN,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dN,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cN,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForCausalLM"),c(fN,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertLMHeadModel"),c(mN,"href","/docs/transformers/pr_16988/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(gN,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(hN,"href","/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(pN,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(uN,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(_N,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(bN,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(vN,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(FN,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForCausalLM"),c(TN,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(MN,"href","/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(EN,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(CN,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianForCausalLM"),c(wN,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForCausalLM"),c(AN,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(yN,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(LN,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(xN,"href","/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartForCausalLM"),c($N,"href","/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(kN,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(SN,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(RN,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(BN,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(PN,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(IN,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(qN,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(NN,"href","/docs/transformers/pr_16988/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(jN,"href","/docs/transformers/pr_16988/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(DN,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(GN,"href","/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(ON,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(VN,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(XN,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a1,"id","transformers.AutoModelForMaskedLM"),c(a1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a1,"href","#transformers.AutoModelForMaskedLM"),c(ki,"class","relative group"),c(zN,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QN,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WN,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HN,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(UN,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(JN,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForMaskedLM"),c(YN,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(KN,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(ZN,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(ej,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(oj,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(rj,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(tj,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(aj,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(nj,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(sj,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(lj,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(ij,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(dj,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(cj,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(fj,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(mj,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(gj,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(hj,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(pj,"href","/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(uj,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(_j,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(bj,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(vj,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(Fj,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(Tj,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(Mj,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(Ej,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(Cj,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(wj,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(Aj,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(yj,"href","/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V1,"id","transformers.AutoModelForSeq2SeqLM"),c(V1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V1,"href","#transformers.AutoModelForSeq2SeqLM"),c(Bi,"class","relative group"),c(Lj,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xj,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($j,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kj,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Sj,"href","/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(Rj,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(Bj,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(Pj,"href","/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(Ij,"href","/docs/transformers/pr_16988/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(qj,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(Nj,"href","/docs/transformers/pr_16988/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(jj,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.MarianMTModel"),c(Dj,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(Gj,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(Oj,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(Vj,"href","/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(Xj,"href","/docs/transformers/pr_16988/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(zj,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(Qj,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Wj,"href","/docs/transformers/pr_16988/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c8,"id","transformers.AutoModelForSequenceClassification"),c(c8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c8,"href","#transformers.AutoModelForSequenceClassification"),c(qi,"class","relative group"),c(Hj,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uj,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jj,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yj,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(Kj,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForSequenceClassification"),c(Zj,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForSequenceClassification"),c(eD,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(oD,"href","/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(rD,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(tD,"href","/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(aD,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(nD,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(sD,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(lD,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(iD,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(dD,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(cD,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(fD,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(mD,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(gD,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(hD,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(pD,"href","/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(uD,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(_D,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(bD,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(vD,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(FD,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDForSequenceClassification"),c(TD,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(MD,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(ED,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(CD,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(wD,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(AD,"href","/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(yD,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(LD,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(xD,"href","/docs/transformers/pr_16988/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c($D,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(kD,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(SD,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(RD,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(BD,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(PD,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(ID,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(qD,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForSequenceClassification"),c(ND,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(jD,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(DD,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(GD,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(OD,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(VD,"href","/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lb,"id","transformers.AutoModelForMultipleChoice"),c(lb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lb,"href","#transformers.AutoModelForMultipleChoice"),c(Di,"class","relative group"),c(XD,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zD,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QD,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WD,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(HD,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForMultipleChoice"),c(UD,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(JD,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(YD,"href","/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(KD,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(ZD,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(eG,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(oG,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(rG,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(tG,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(aG,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(nG,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(sG,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(lG,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(iG,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(dG,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(cG,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(fG,"href","/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(mG,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(gG,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(hG,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(pG,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(uG,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(_G,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(bG,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(vG,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(FG,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(TG,"href","/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Db,"id","transformers.AutoModelForNextSentencePrediction"),c(Db,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Db,"href","#transformers.AutoModelForNextSentencePrediction"),c(Vi,"class","relative group"),c(MG,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EG,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CG,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wG,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(AG,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(yG,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(LG,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(xG,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ub,"id","transformers.AutoModelForTokenClassification"),c(Ub,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ub,"href","#transformers.AutoModelForTokenClassification"),c(Qi,"class","relative group"),c($G,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kG,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SG,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RG,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(BG,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForTokenClassification"),c(PG,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(IG,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(qG,"href","/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForTokenClassification"),c(NG,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(jG,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(DG,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(GG,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(OG,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(VG,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(XG,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(zG,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(QG,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(WG,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(HG,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(UG,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(JG,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(YG,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(KG,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(ZG,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(eO,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(oO,"href","/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(rO,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(tO,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(aO,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(nO,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(sO,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(lO,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(iO,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(dO,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(cO,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(fO,"href","/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S2,"id","transformers.AutoModelForQuestionAnswering"),c(S2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S2,"href","#transformers.AutoModelForQuestionAnswering"),c(Ui,"class","relative group"),c(mO,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gO,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hO,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pO,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(uO,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(_O,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(bO,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(vO,"href","/docs/transformers/pr_16988/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(FO,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(TO,"href","/docs/transformers/pr_16988/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(MO,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(EO,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(CO,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(wO,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(AO,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(yO,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(LO,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(xO,"href","/docs/transformers/pr_16988/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c($O,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(kO,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(SO,"href","/docs/transformers/pr_16988/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(RO,"href","/docs/transformers/pr_16988/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(BO,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(PO,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(IO,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(qO,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(NO,"href","/docs/transformers/pr_16988/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(jO,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(DO,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(GO,"href","/docs/transformers/pr_16988/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(OO,"href","/docs/transformers/pr_16988/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(VO,"href","/docs/transformers/pr_16988/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(XO,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(zO,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(QO,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(WO,"href","/docs/transformers/pr_16988/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(HO,"href","/docs/transformers/pr_16988/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(UO,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(JO,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(YO,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(KO,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(ZO,"href","/docs/transformers/pr_16988/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tv,"id","transformers.AutoModelForTableQuestionAnswering"),c(Tv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Tv,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Ki,"class","relative group"),c(eV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tV,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Av,"id","transformers.AutoModelForImageClassification"),c(Av,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Av,"href","#transformers.AutoModelForImageClassification"),c(od,"class","relative group"),c(aV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lV,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitForImageClassification"),c(iV,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(dV,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(cV,"href","/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTForImageClassification"),c(fV,"href","/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(mV,"href","/docs/transformers/pr_16988/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(gV,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(hV,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(pV,"href","/docs/transformers/pr_16988/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(uV,"href","/docs/transformers/pr_16988/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(_V,"href","/docs/transformers/pr_16988/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(bV,"href","/docs/transformers/pr_16988/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(vV,"href","/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(FV,"href","/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinForImageClassification"),c(TV,"href","/docs/transformers/pr_16988/en/model_doc/van#transformers.VanForImageClassification"),c(MV,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTForImageClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gv,"id","transformers.AutoModelForVision2Seq"),c(Gv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gv,"href","#transformers.AutoModelForVision2Seq"),c(ad,"class","relative group"),c(EV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AV,"href","/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qv,"id","transformers.AutoModelForAudioClassification"),c(Qv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Qv,"href","#transformers.AutoModelForAudioClassification"),c(ld,"class","relative group"),c(yV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($V,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(kV,"href","/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(SV,"href","/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(RV,"href","/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(BV,"href","/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(PV,"href","/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(IV,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(qV,"href","/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aF,"id","transformers.AutoModelForAudioFrameClassification"),c(aF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aF,"href","#transformers.AutoModelForAudioFrameClassification"),c(cd,"class","relative group"),c(NV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GV,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(OV,"href","/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(VV,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(XV,"href","/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mF,"id","transformers.AutoModelForCTC"),c(mF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mF,"href","#transformers.AutoModelForCTC"),c(gd,"class","relative group"),c(zV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WV,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HV,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(UV,"href","/docs/transformers/pr_16988/en/model_doc/hubert#transformers.HubertForCTC"),c(JV,"href","/docs/transformers/pr_16988/en/model_doc/sew#transformers.SEWForCTC"),c(YV,"href","/docs/transformers/pr_16988/en/model_doc/sew-d#transformers.SEWDForCTC"),c(KV,"href","/docs/transformers/pr_16988/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(ZV,"href","/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(eX,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(oX,"href","/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForCTC"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(CF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(ud,"class","relative group"),c(rX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nX,"href","/docs/transformers/pr_16988/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(sX,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($F,"id","transformers.AutoModelForAudioXVector"),c($F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($F,"href","#transformers.AutoModelForAudioXVector"),c(vd,"class","relative group"),c(lX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cX,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(fX,"href","/docs/transformers/pr_16988/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(mX,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(gX,"href","/docs/transformers/pr_16988/en/model_doc/wavlm#transformers.WavLMForXVector"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NF,"id","transformers.AutoModelForMaskedImageModeling"),c(NF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(NF,"href","#transformers.AutoModelForMaskedImageModeling"),c(Md,"class","relative group"),c(hX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_X,"href","/docs/transformers/pr_16988/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(bX,"href","/docs/transformers/pr_16988/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(vX,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zF,"id","transformers.AutoModelForObjectDetection"),c(zF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zF,"href","#transformers.AutoModelForObjectDetection"),c(Ad,"class","relative group"),c(FX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EX,"href","/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrForObjectDetection"),c(CX,"href","/docs/transformers/pr_16988/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YF,"id","transformers.AutoModelForImageSegmentation"),c(YF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YF,"href","#transformers.AutoModelForImageSegmentation"),c(xd,"class","relative group"),c(wX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LX,"href","/docs/transformers/pr_16988/en/model_doc/detr#transformers.DetrForSegmentation"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r6,"id","transformers.AutoModelForSemanticSegmentation"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.AutoModelForSemanticSegmentation"),c(Sd,"class","relative group"),c(xX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($X,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SX,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(RX,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(BX,"href","/docs/transformers/pr_16988/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(PX,"href","/docs/transformers/pr_16988/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c6,"id","transformers.AutoModelForInstanceSegmentation"),c(c6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c6,"href","#transformers.AutoModelForInstanceSegmentation"),c(Pd,"class","relative group"),c(IX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jX,"href","/docs/transformers/pr_16988/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p6,"id","transformers.TFAutoModel"),c(p6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p6,"href","#transformers.TFAutoModel"),c(Nd,"class","relative group"),c(DX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OX,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VX,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertModel"),c(XX,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.TFBartModel"),c(zX,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertModel"),c(QX,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(WX,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(HX,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertModel"),c(UX,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.TFCLIPModel"),c(JX,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertModel"),c(YX,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.TFConvNextModel"),c(KX,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLModel"),c(ZX,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(ez,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaModel"),c(oz,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(rz,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(tz,"href","/docs/transformers/pr_16988/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(az,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraModel"),c(nz,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(sz,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelModel"),c(lz,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(iz,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2Model"),c(dz,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJModel"),c(cz,"href","/docs/transformers/pr_16988/en/model_doc/hubert#transformers.TFHubertModel"),c(fz,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(mz,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.TFLEDModel"),c(gz,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerModel"),c(hz,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.TFLxmertModel"),c(pz,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.TFMarianModel"),c(uz,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.TFMBartModel"),c(_z,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(bz,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetModel"),c(vz,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.TFMT5Model"),c(Fz,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(Tz,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.TFPegasusModel"),c(Mz,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertModel"),c(Ez,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaModel"),c(Cz,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerModel"),c(wz,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(Az,"href","/docs/transformers/pr_16988/en/model_doc/swin#transformers.TFSwinModel"),c(yz,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.TFT5Model"),c(Lz,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasModel"),c(xz,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c($z,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.TFViTModel"),c(kz,"href","/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(Sz,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(Rz,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMModel"),c(Bz,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(Pz,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dT,"id","transformers.TFAutoModelForPreTraining"),c(dT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dT,"href","#transformers.TFAutoModelForPreTraining"),c(Gd,"class","relative group"),c(Iz,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qz,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nz,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jz,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(Dz,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Gz,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForPreTraining"),c(Oz,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Vz,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(Xz,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(zz,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(Qz,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Wz,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(Hz,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Uz,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Jz,"href","/docs/transformers/pr_16988/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(Yz,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(Kz,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Zz,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(eQ,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(oQ,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(rQ,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(tQ,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(aQ,"href","/docs/transformers/pr_16988/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(nQ,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(sQ,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(lQ,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PT,"id","transformers.TFAutoModelForCausalLM"),c(PT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PT,"href","#transformers.TFAutoModelForCausalLM"),c(Xd,"class","relative group"),c(iQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(mQ,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(gQ,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(hQ,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(pQ,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(uQ,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(_Q,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(bQ,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(vQ,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(FQ,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(TQ,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(MQ,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JT,"id","transformers.TFAutoModelForImageClassification"),c(JT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JT,"href","#transformers.TFAutoModelForImageClassification"),c(Wd,"class","relative group"),c(EQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AQ,"href","/docs/transformers/pr_16988/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(yQ,"href","/docs/transformers/pr_16988/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(LQ,"href","/docs/transformers/pr_16988/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(xQ,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t9,"id","transformers.TFAutoModelForMaskedLM"),c(t9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t9,"href","#transformers.TFAutoModelForMaskedLM"),c(Jd,"class","relative group"),c($Q,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RQ,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(BQ,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(PQ,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(IQ,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(qQ,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(NQ,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(jQ,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(DQ,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(GQ,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(OQ,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(VQ,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(XQ,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(zQ,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(QQ,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(WQ,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(HQ,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(UQ,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(JQ,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(YQ,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(KQ,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A9,"id","transformers.TFAutoModelForSeq2SeqLM"),c(A9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A9,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(Zd,"class","relative group"),c(ZQ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rW,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(tW,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(aW,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(nW,"href","/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(sW,"href","/docs/transformers/pr_16988/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(lW,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.TFMarianMTModel"),c(iW,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(dW,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(cW,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(fW,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j9,"id","transformers.TFAutoModelForSequenceClassification"),c(j9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j9,"href","#transformers.TFAutoModelForSequenceClassification"),c(rc,"class","relative group"),c(mW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pW,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(uW,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(_W,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(bW,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(vW,"href","/docs/transformers/pr_16988/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(FW,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(TW,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(MW,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(EW,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(CW,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(wW,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(AW,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(yW,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(LW,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(xW,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c($W,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(kW,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(SW,"href","/docs/transformers/pr_16988/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(RW,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(BW,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(PW,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(IW,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(qW,"href","/docs/transformers/pr_16988/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(NW,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(jW,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(DW,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hM,"id","transformers.TFAutoModelForMultipleChoice"),c(hM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hM,"href","#transformers.TFAutoModelForMultipleChoice"),c(nc,"class","relative group"),c(GW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(zW,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(QW,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(WW,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(HW,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(UW,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(JW,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(YW,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(KW,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(ZW,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(eH,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(oH,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(rH,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(tH,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(aH,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(nH,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(sH,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BM,"id","transformers.TFAutoModelForNextSentencePrediction"),c(BM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BM,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(ic,"class","relative group"),c(lH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cH,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(fH,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jM,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(jM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jM,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(fc,"class","relative group"),c(mH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pH,"href","/docs/transformers/pr_16988/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VM,"id","transformers.TFAutoModelForTokenClassification"),c(VM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VM,"href","#transformers.TFAutoModelForTokenClassification"),c(hc,"class","relative group"),c(uH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_H,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vH,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(FH,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(TH,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(MH,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(EH,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(CH,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(wH,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(AH,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(yH,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(LH,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(xH,"href","/docs/transformers/pr_16988/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c($H,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(kH,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(SH,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(RH,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(BH,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(PH,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(IH,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(qH,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(NH,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m4,"id","transformers.TFAutoModelForQuestionAnswering"),c(m4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m4,"href","#transformers.TFAutoModelForQuestionAnswering"),c(_c,"class","relative group"),c(jH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GH,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OH,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(VH,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(XH,"href","/docs/transformers/pr_16988/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(zH,"href","/docs/transformers/pr_16988/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(QH,"href","/docs/transformers/pr_16988/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(WH,"href","/docs/transformers/pr_16988/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(HH,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(UH,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(JH,"href","/docs/transformers/pr_16988/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(YH,"href","/docs/transformers/pr_16988/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(KH,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(ZH,"href","/docs/transformers/pr_16988/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(eU,"href","/docs/transformers/pr_16988/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(oU,"href","/docs/transformers/pr_16988/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(rU,"href","/docs/transformers/pr_16988/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(tU,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(aU,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(nU,"href","/docs/transformers/pr_16988/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(sU,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(lU,"href","/docs/transformers/pr_16988/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P4,"id","transformers.TFAutoModelForVision2Seq"),c(P4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P4,"href","#transformers.TFAutoModelForVision2Seq"),c(Fc,"class","relative group"),c(iU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fU,"href","/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j4,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(j4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j4,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Ec,"class","relative group"),c(mU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pU,"href","/docs/transformers/pr_16988/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V4,"id","transformers.FlaxAutoModel"),c(V4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V4,"href","#transformers.FlaxAutoModel"),c(Ac,"class","relative group"),c(uU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_U,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vU,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertModel"),c(FU,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartModel"),c(TU,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.FlaxBeitModel"),c(MU,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertModel"),c(EU,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(CU,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(wU,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(AU,"href","/docs/transformers/pr_16988/en/model_doc/clip#transformers.FlaxCLIPModel"),c(yU,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(LU,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraModel"),c(xU,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c($U,"href","/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(kU,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(SU,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.FlaxMarianModel"),c(RU,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartModel"),c(BU,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.FlaxMT5Model"),c(PU,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(IU,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(qU,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(NU,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.FlaxT5Model"),c(jU,"href","/docs/transformers/pr_16988/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(DU,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.FlaxViTModel"),c(GU,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(OU,"href","/docs/transformers/pr_16988/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(VU,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_E,"id","transformers.FlaxAutoModelForCausalLM"),c(_E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_E,"href","#transformers.FlaxAutoModelForCausalLM"),c(xc,"class","relative group"),c(XU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QU,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WU,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(HU,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(UU,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(JU,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(YU,"href","/docs/transformers/pr_16988/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(KU,"href","/docs/transformers/pr_16988/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(ZU,"href","/docs/transformers/pr_16988/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(eJ,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(oJ,"href","/docs/transformers/pr_16988/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xE,"id","transformers.FlaxAutoModelForPreTraining"),c(xE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xE,"href","#transformers.FlaxAutoModelForPreTraining"),c(Sc,"class","relative group"),c(rJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nJ,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(sJ,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(lJ,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(iJ,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(dJ,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(cJ,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(fJ,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(mJ,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(gJ,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(hJ,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(pJ,"href","/docs/transformers/pr_16988/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(uJ,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XE,"id","transformers.FlaxAutoModelForMaskedLM"),c(XE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XE,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Pc,"class","relative group"),c(_J,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(TJ,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(MJ,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(EJ,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(CJ,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(wJ,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(AJ,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(yJ,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(LJ,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(xJ,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t5,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(t5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t5,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Nc,"class","relative group"),c($J,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RJ,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(BJ,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(PJ,"href","/docs/transformers/pr_16988/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(IJ,"href","/docs/transformers/pr_16988/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(qJ,"href","/docs/transformers/pr_16988/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(NJ,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(jJ,"href","/docs/transformers/pr_16988/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(DJ,"href","/docs/transformers/pr_16988/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(GJ,"href","/docs/transformers/pr_16988/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p5,"id","transformers.FlaxAutoModelForSequenceClassification"),c(p5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p5,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Gc,"class","relative group"),c(OJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XJ,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zJ,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(QJ,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(WJ,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(HJ,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(UJ,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(JJ,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(YJ,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(KJ,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(ZJ,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(eY,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L5,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(L5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L5,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Xc,"class","relative group"),c(oY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aY,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(nY,"href","/docs/transformers/pr_16988/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(sY,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(lY,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(iY,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(dY,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(cY,"href","/docs/transformers/pr_16988/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(fY,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(mY,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(gY,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G5,"id","transformers.FlaxAutoModelForTokenClassification"),c(G5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G5,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Wc,"class","relative group"),c(hY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_Y,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(bY,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(vY,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(FY,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(TY,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(MY,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(EY,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(CY,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K5,"id","transformers.FlaxAutoModelForMultipleChoice"),c(K5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K5,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(Jc,"class","relative group"),c(wY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LY,"href","/docs/transformers/pr_16988/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(xY,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c($Y,"href","/docs/transformers/pr_16988/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(kY,"href","/docs/transformers/pr_16988/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(SY,"href","/docs/transformers/pr_16988/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(RY,"href","/docs/transformers/pr_16988/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(BY,"href","/docs/transformers/pr_16988/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(PY,"href","/docs/transformers/pr_16988/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dC,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dC,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Zc,"class","relative group"),c(IY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jY,"href","/docs/transformers/pr_16988/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gC,"id","transformers.FlaxAutoModelForImageClassification"),c(gC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gC,"href","#transformers.FlaxAutoModelForImageClassification"),c(rf,"class","relative group"),c(DY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VY,"href","/docs/transformers/pr_16988/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(XY,"href","/docs/transformers/pr_16988/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bC,"id","transformers.FlaxAutoModelForVision2Seq"),c(bC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bC,"href","#transformers.FlaxAutoModelForVision2Seq"),c(nf,"class","relative group"),c(zY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WY,"href","/docs/transformers/pr_16988/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HY,"href","/docs/transformers/pr_16988/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Mo),e(Mo,ii),b(f,mf,_),b(f,et,_),e(et,di),e(et,ci),e(ci,Gw),e(et,gf),b(f,qe,_),b(f,Xe,_),e(Xe,fi),e(Xe,yn),e(yn,Ow),e(Xe,Ln),e(Xe,xn),e(xn,Vw),e(Xe,mi),e(Xe,$n),e($n,Xw),e(Xe,gi),b(f,hf,_),M(Ma,f,_),b(f,ze,_),b(f,Ae,_),e(Ae,i$),e(Ae,hi),e(hi,d$),e(Ae,c$),b(f,Eo,_),b(f,Ea,_),e(Ea,f$),e(Ea,pf),e(pf,m$),e(Ea,Aje),b(f,pPe,_),b(f,pi,_),e(pi,uf),e(uf,GZ),M(zw,GZ,null),e(pi,yje),e(pi,OZ),e(OZ,Lje),b(f,uPe,_),b(f,kn,_),e(kn,xje),e(kn,VZ),e(VZ,$je),e(kn,kje),e(kn,XZ),e(XZ,Sje),e(kn,Rje),b(f,_Pe,_),M(Qw,f,_),b(f,bPe,_),b(f,g$,_),e(g$,Bje),b(f,vPe,_),M(_f,f,_),b(f,FPe,_),b(f,ui,_),e(ui,bf),e(bf,zZ),M(Ww,zZ,null),e(ui,Pje),e(ui,QZ),e(QZ,Ije),b(f,TPe,_),b(f,Co,_),M(Hw,Co,null),e(Co,qje),e(Co,Uw),e(Uw,Nje),e(Uw,h$),e(h$,jje),e(Uw,Dje),e(Co,Gje),e(Co,Jw),e(Jw,Oje),e(Jw,WZ),e(WZ,Vje),e(Jw,Xje),e(Co,zje),e(Co,Er),M(Yw,Er,null),e(Er,Qje),e(Er,HZ),e(HZ,Wje),e(Er,Hje),e(Er,_i),e(_i,Uje),e(_i,UZ),e(UZ,Jje),e(_i,Yje),e(_i,JZ),e(JZ,Kje),e(_i,Zje),e(Er,eDe),e(Er,y),e(y,vf),e(vf,YZ),e(YZ,oDe),e(vf,rDe),e(vf,p$),e(p$,tDe),e(vf,aDe),e(y,nDe),e(y,Ff),e(Ff,KZ),e(KZ,sDe),e(Ff,lDe),e(Ff,u$),e(u$,iDe),e(Ff,dDe),e(y,cDe),e(y,Tf),e(Tf,ZZ),e(ZZ,fDe),e(Tf,mDe),e(Tf,_$),e(_$,gDe),e(Tf,hDe),e(y,pDe),e(y,Mf),e(Mf,eee),e(eee,uDe),e(Mf,_De),e(Mf,b$),e(b$,bDe),e(Mf,vDe),e(y,FDe),e(y,Ef),e(Ef,oee),e(oee,TDe),e(Ef,MDe),e(Ef,v$),e(v$,EDe),e(Ef,CDe),e(y,wDe),e(y,Cf),e(Cf,ree),e(ree,ADe),e(Cf,yDe),e(Cf,F$),e(F$,LDe),e(Cf,xDe),e(y,$De),e(y,wf),e(wf,tee),e(tee,kDe),e(wf,SDe),e(wf,T$),e(T$,RDe),e(wf,BDe),e(y,PDe),e(y,Af),e(Af,aee),e(aee,IDe),e(Af,qDe),e(Af,M$),e(M$,NDe),e(Af,jDe),e(y,DDe),e(y,yf),e(yf,nee),e(nee,GDe),e(yf,ODe),e(yf,E$),e(E$,VDe),e(yf,XDe),e(y,zDe),e(y,Lf),e(Lf,see),e(see,QDe),e(Lf,WDe),e(Lf,C$),e(C$,HDe),e(Lf,UDe),e(y,JDe),e(y,xf),e(xf,lee),e(lee,YDe),e(xf,KDe),e(xf,w$),e(w$,ZDe),e(xf,eGe),e(y,oGe),e(y,$f),e($f,iee),e(iee,rGe),e($f,tGe),e($f,A$),e(A$,aGe),e($f,nGe),e(y,sGe),e(y,kf),e(kf,dee),e(dee,lGe),e(kf,iGe),e(kf,y$),e(y$,dGe),e(kf,cGe),e(y,fGe),e(y,Sf),e(Sf,cee),e(cee,mGe),e(Sf,gGe),e(Sf,L$),e(L$,hGe),e(Sf,pGe),e(y,uGe),e(y,Rf),e(Rf,fee),e(fee,_Ge),e(Rf,bGe),e(Rf,x$),e(x$,vGe),e(Rf,FGe),e(y,TGe),e(y,Bf),e(Bf,mee),e(mee,MGe),e(Bf,EGe),e(Bf,$$),e($$,CGe),e(Bf,wGe),e(y,AGe),e(y,Pf),e(Pf,gee),e(gee,yGe),e(Pf,LGe),e(Pf,k$),e(k$,xGe),e(Pf,$Ge),e(y,kGe),e(y,If),e(If,hee),e(hee,SGe),e(If,RGe),e(If,S$),e(S$,BGe),e(If,PGe),e(y,IGe),e(y,qf),e(qf,pee),e(pee,qGe),e(qf,NGe),e(qf,R$),e(R$,jGe),e(qf,DGe),e(y,GGe),e(y,Nf),e(Nf,uee),e(uee,OGe),e(Nf,VGe),e(Nf,B$),e(B$,XGe),e(Nf,zGe),e(y,QGe),e(y,jf),e(jf,_ee),e(_ee,WGe),e(jf,HGe),e(jf,P$),e(P$,UGe),e(jf,JGe),e(y,YGe),e(y,Df),e(Df,bee),e(bee,KGe),e(Df,ZGe),e(Df,I$),e(I$,eOe),e(Df,oOe),e(y,rOe),e(y,Gf),e(Gf,vee),e(vee,tOe),e(Gf,aOe),e(Gf,q$),e(q$,nOe),e(Gf,sOe),e(y,lOe),e(y,Of),e(Of,Fee),e(Fee,iOe),e(Of,dOe),e(Of,N$),e(N$,cOe),e(Of,fOe),e(y,mOe),e(y,Vf),e(Vf,Tee),e(Tee,gOe),e(Vf,hOe),e(Vf,j$),e(j$,pOe),e(Vf,uOe),e(y,_Oe),e(y,Xf),e(Xf,Mee),e(Mee,bOe),e(Xf,vOe),e(Xf,D$),e(D$,FOe),e(Xf,TOe),e(y,MOe),e(y,zf),e(zf,Eee),e(Eee,EOe),e(zf,COe),e(zf,G$),e(G$,wOe),e(zf,AOe),e(y,yOe),e(y,Qf),e(Qf,Cee),e(Cee,LOe),e(Qf,xOe),e(Qf,O$),e(O$,$Oe),e(Qf,kOe),e(y,SOe),e(y,Wf),e(Wf,wee),e(wee,ROe),e(Wf,BOe),e(Wf,V$),e(V$,POe),e(Wf,IOe),e(y,qOe),e(y,Hf),e(Hf,Aee),e(Aee,NOe),e(Hf,jOe),e(Hf,X$),e(X$,DOe),e(Hf,GOe),e(y,OOe),e(y,Uf),e(Uf,yee),e(yee,VOe),e(Uf,XOe),e(Uf,z$),e(z$,zOe),e(Uf,QOe),e(y,WOe),e(y,Jf),e(Jf,Lee),e(Lee,HOe),e(Jf,UOe),e(Jf,Q$),e(Q$,JOe),e(Jf,YOe),e(y,KOe),e(y,Yf),e(Yf,xee),e(xee,ZOe),e(Yf,eVe),e(Yf,W$),e(W$,oVe),e(Yf,rVe),e(y,tVe),e(y,Kf),e(Kf,$ee),e($ee,aVe),e(Kf,nVe),e(Kf,H$),e(H$,sVe),e(Kf,lVe),e(y,iVe),e(y,Zf),e(Zf,kee),e(kee,dVe),e(Zf,cVe),e(Zf,U$),e(U$,fVe),e(Zf,mVe),e(y,gVe),e(y,em),e(em,See),e(See,hVe),e(em,pVe),e(em,J$),e(J$,uVe),e(em,_Ve),e(y,bVe),e(y,om),e(om,Ree),e(Ree,vVe),e(om,FVe),e(om,Y$),e(Y$,TVe),e(om,MVe),e(y,EVe),e(y,rm),e(rm,Bee),e(Bee,CVe),e(rm,wVe),e(rm,K$),e(K$,AVe),e(rm,yVe),e(y,LVe),e(y,tm),e(tm,Pee),e(Pee,xVe),e(tm,$Ve),e(tm,Z$),e(Z$,kVe),e(tm,SVe),e(y,RVe),e(y,am),e(am,Iee),e(Iee,BVe),e(am,PVe),e(am,ek),e(ek,IVe),e(am,qVe),e(y,NVe),e(y,nm),e(nm,qee),e(qee,jVe),e(nm,DVe),e(nm,ok),e(ok,GVe),e(nm,OVe),e(y,VVe),e(y,sm),e(sm,Nee),e(Nee,XVe),e(sm,zVe),e(sm,rk),e(rk,QVe),e(sm,WVe),e(y,HVe),e(y,lm),e(lm,jee),e(jee,UVe),e(lm,JVe),e(lm,tk),e(tk,YVe),e(lm,KVe),e(y,ZVe),e(y,im),e(im,Dee),e(Dee,eXe),e(im,oXe),e(im,ak),e(ak,rXe),e(im,tXe),e(y,aXe),e(y,dm),e(dm,Gee),e(Gee,nXe),e(dm,sXe),e(dm,nk),e(nk,lXe),e(dm,iXe),e(y,dXe),e(y,cm),e(cm,Oee),e(Oee,cXe),e(cm,fXe),e(cm,sk),e(sk,mXe),e(cm,gXe),e(y,hXe),e(y,fm),e(fm,Vee),e(Vee,pXe),e(fm,uXe),e(fm,lk),e(lk,_Xe),e(fm,bXe),e(y,vXe),e(y,mm),e(mm,Xee),e(Xee,FXe),e(mm,TXe),e(mm,ik),e(ik,MXe),e(mm,EXe),e(y,CXe),e(y,gm),e(gm,zee),e(zee,wXe),e(gm,AXe),e(gm,dk),e(dk,yXe),e(gm,LXe),e(y,xXe),e(y,hm),e(hm,Qee),e(Qee,$Xe),e(hm,kXe),e(hm,ck),e(ck,SXe),e(hm,RXe),e(y,BXe),e(y,pm),e(pm,Wee),e(Wee,PXe),e(pm,IXe),e(pm,fk),e(fk,qXe),e(pm,NXe),e(y,jXe),e(y,um),e(um,Hee),e(Hee,DXe),e(um,GXe),e(um,mk),e(mk,OXe),e(um,VXe),e(y,XXe),e(y,_m),e(_m,Uee),e(Uee,zXe),e(_m,QXe),e(_m,gk),e(gk,WXe),e(_m,HXe),e(y,UXe),e(y,bm),e(bm,Jee),e(Jee,JXe),e(bm,YXe),e(bm,hk),e(hk,KXe),e(bm,ZXe),e(y,eze),e(y,vm),e(vm,Yee),e(Yee,oze),e(vm,rze),e(vm,pk),e(pk,tze),e(vm,aze),e(y,nze),e(y,Fm),e(Fm,Kee),e(Kee,sze),e(Fm,lze),e(Fm,uk),e(uk,ize),e(Fm,dze),e(y,cze),e(y,Tm),e(Tm,Zee),e(Zee,fze),e(Tm,mze),e(Tm,_k),e(_k,gze),e(Tm,hze),e(y,pze),e(y,Mm),e(Mm,eoe),e(eoe,uze),e(Mm,_ze),e(Mm,bk),e(bk,bze),e(Mm,vze),e(y,Fze),e(y,Em),e(Em,ooe),e(ooe,Tze),e(Em,Mze),e(Em,vk),e(vk,Eze),e(Em,Cze),e(y,wze),e(y,Cm),e(Cm,roe),e(roe,Aze),e(Cm,yze),e(Cm,Fk),e(Fk,Lze),e(Cm,xze),e(y,$ze),e(y,wm),e(wm,toe),e(toe,kze),e(wm,Sze),e(wm,Tk),e(Tk,Rze),e(wm,Bze),e(y,Pze),e(y,Am),e(Am,aoe),e(aoe,Ize),e(Am,qze),e(Am,Mk),e(Mk,Nze),e(Am,jze),e(y,Dze),e(y,ym),e(ym,noe),e(noe,Gze),e(ym,Oze),e(ym,Ek),e(Ek,Vze),e(ym,Xze),e(y,zze),e(y,Lm),e(Lm,soe),e(soe,Qze),e(Lm,Wze),e(Lm,Ck),e(Ck,Hze),e(Lm,Uze),e(y,Jze),e(y,xm),e(xm,loe),e(loe,Yze),e(xm,Kze),e(xm,wk),e(wk,Zze),e(xm,eQe),e(y,oQe),e(y,$m),e($m,ioe),e(ioe,rQe),e($m,tQe),e($m,Ak),e(Ak,aQe),e($m,nQe),e(y,sQe),e(y,km),e(km,doe),e(doe,lQe),e(km,iQe),e(km,yk),e(yk,dQe),e(km,cQe),e(y,fQe),e(y,Sm),e(Sm,coe),e(coe,mQe),e(Sm,gQe),e(Sm,Lk),e(Lk,hQe),e(Sm,pQe),e(y,uQe),e(y,Rm),e(Rm,foe),e(foe,_Qe),e(Rm,bQe),e(Rm,xk),e(xk,vQe),e(Rm,FQe),e(y,TQe),e(y,Bm),e(Bm,moe),e(moe,MQe),e(Bm,EQe),e(Bm,$k),e($k,CQe),e(Bm,wQe),e(y,AQe),e(y,Pm),e(Pm,goe),e(goe,yQe),e(Pm,LQe),e(Pm,kk),e(kk,xQe),e(Pm,$Qe),e(y,kQe),e(y,Im),e(Im,hoe),e(hoe,SQe),e(Im,RQe),e(Im,Sk),e(Sk,BQe),e(Im,PQe),e(y,IQe),e(y,qm),e(qm,poe),e(poe,qQe),e(qm,NQe),e(qm,Rk),e(Rk,jQe),e(qm,DQe),e(y,GQe),e(y,Nm),e(Nm,uoe),e(uoe,OQe),e(Nm,VQe),e(Nm,Bk),e(Bk,XQe),e(Nm,zQe),e(y,QQe),e(y,jm),e(jm,_oe),e(_oe,WQe),e(jm,HQe),e(jm,Pk),e(Pk,UQe),e(jm,JQe),e(y,YQe),e(y,Dm),e(Dm,boe),e(boe,KQe),e(Dm,ZQe),e(Dm,Ik),e(Ik,eWe),e(Dm,oWe),e(y,rWe),e(y,Gm),e(Gm,voe),e(voe,tWe),e(Gm,aWe),e(Gm,qk),e(qk,nWe),e(Gm,sWe),e(y,lWe),e(y,Om),e(Om,Foe),e(Foe,iWe),e(Om,dWe),e(Om,Nk),e(Nk,cWe),e(Om,fWe),e(y,mWe),e(y,Vm),e(Vm,Toe),e(Toe,gWe),e(Vm,hWe),e(Vm,jk),e(jk,pWe),e(Vm,uWe),e(y,_We),e(y,Xm),e(Xm,Moe),e(Moe,bWe),e(Xm,vWe),e(Xm,Dk),e(Dk,FWe),e(Xm,TWe),e(y,MWe),e(y,zm),e(zm,Eoe),e(Eoe,EWe),e(zm,CWe),e(zm,Gk),e(Gk,wWe),e(zm,AWe),e(y,yWe),e(y,Qm),e(Qm,Coe),e(Coe,LWe),e(Qm,xWe),e(Qm,Ok),e(Ok,$We),e(Qm,kWe),e(y,SWe),e(y,Wm),e(Wm,woe),e(woe,RWe),e(Wm,BWe),e(Wm,Vk),e(Vk,PWe),e(Wm,IWe),e(y,qWe),e(y,Hm),e(Hm,Aoe),e(Aoe,NWe),e(Hm,jWe),e(Hm,Xk),e(Xk,DWe),e(Hm,GWe),e(y,OWe),e(y,Um),e(Um,yoe),e(yoe,VWe),e(Um,XWe),e(Um,zk),e(zk,zWe),e(Um,QWe),e(y,WWe),e(y,Jm),e(Jm,Loe),e(Loe,HWe),e(Jm,UWe),e(Jm,Qk),e(Qk,JWe),e(Jm,YWe),e(y,KWe),e(y,Ym),e(Ym,xoe),e(xoe,ZWe),e(Ym,eHe),e(Ym,Wk),e(Wk,oHe),e(Ym,rHe),e(y,tHe),e(y,Km),e(Km,$oe),e($oe,aHe),e(Km,nHe),e(Km,Hk),e(Hk,sHe),e(Km,lHe),e(y,iHe),e(y,Zm),e(Zm,koe),e(koe,dHe),e(Zm,cHe),e(Zm,Uk),e(Uk,fHe),e(Zm,mHe),e(y,gHe),e(y,eg),e(eg,Soe),e(Soe,hHe),e(eg,pHe),e(eg,Jk),e(Jk,uHe),e(eg,_He),e(y,bHe),e(y,og),e(og,Roe),e(Roe,vHe),e(og,FHe),e(og,Yk),e(Yk,THe),e(og,MHe),e(y,EHe),e(y,rg),e(rg,Boe),e(Boe,CHe),e(rg,wHe),e(rg,Kk),e(Kk,AHe),e(rg,yHe),e(y,LHe),e(y,tg),e(tg,Poe),e(Poe,xHe),e(tg,$He),e(tg,Zk),e(Zk,kHe),e(tg,SHe),e(y,RHe),e(y,ag),e(ag,Ioe),e(Ioe,BHe),e(ag,PHe),e(ag,eS),e(eS,IHe),e(ag,qHe),e(y,NHe),e(y,ng),e(ng,qoe),e(qoe,jHe),e(ng,DHe),e(ng,oS),e(oS,GHe),e(ng,OHe),e(y,VHe),e(y,sg),e(sg,Noe),e(Noe,XHe),e(sg,zHe),e(sg,rS),e(rS,QHe),e(sg,WHe),e(y,HHe),e(y,lg),e(lg,joe),e(joe,UHe),e(lg,JHe),e(lg,tS),e(tS,YHe),e(lg,KHe),e(y,ZHe),e(y,ig),e(ig,Doe),e(Doe,eUe),e(ig,oUe),e(ig,aS),e(aS,rUe),e(ig,tUe),e(y,aUe),e(y,dg),e(dg,Goe),e(Goe,nUe),e(dg,sUe),e(dg,nS),e(nS,lUe),e(dg,iUe),e(y,dUe),e(y,cg),e(cg,Ooe),e(Ooe,cUe),e(cg,fUe),e(cg,sS),e(sS,mUe),e(cg,gUe),e(y,hUe),e(y,fg),e(fg,Voe),e(Voe,pUe),e(fg,uUe),e(fg,lS),e(lS,_Ue),e(fg,bUe),e(y,vUe),e(y,mg),e(mg,Xoe),e(Xoe,FUe),e(mg,TUe),e(mg,iS),e(iS,MUe),e(mg,EUe),e(y,CUe),e(y,gg),e(gg,zoe),e(zoe,wUe),e(gg,AUe),e(gg,dS),e(dS,yUe),e(gg,LUe),e(Er,xUe),M(hg,Er,null),e(Co,$Ue),e(Co,pg),M(Kw,pg,null),e(pg,kUe),e(pg,Qoe),e(Qoe,SUe),b(f,MPe,_),b(f,bi,_),e(bi,ug),e(ug,Woe),M(Zw,Woe,null),e(bi,RUe),e(bi,Hoe),e(Hoe,BUe),b(f,EPe,_),b(f,wo,_),M(eA,wo,null),e(wo,PUe),e(wo,oA),e(oA,IUe),e(oA,cS),e(cS,qUe),e(oA,NUe),e(wo,jUe),e(wo,rA),e(rA,DUe),e(rA,Uoe),e(Uoe,GUe),e(rA,OUe),e(wo,VUe),e(wo,Cr),M(tA,Cr,null),e(Cr,XUe),e(Cr,Joe),e(Joe,zUe),e(Cr,QUe),e(Cr,Ca),e(Ca,WUe),e(Ca,Yoe),e(Yoe,HUe),e(Ca,UUe),e(Ca,Koe),e(Koe,JUe),e(Ca,YUe),e(Ca,Zoe),e(Zoe,KUe),e(Ca,ZUe),e(Cr,eJe),e(Cr,k),e(k,Sn),e(Sn,ere),e(ere,oJe),e(Sn,rJe),e(Sn,fS),e(fS,tJe),e(Sn,aJe),e(Sn,mS),e(mS,nJe),e(Sn,sJe),e(k,lJe),e(k,Rn),e(Rn,ore),e(ore,iJe),e(Rn,dJe),e(Rn,gS),e(gS,cJe),e(Rn,fJe),e(Rn,hS),e(hS,mJe),e(Rn,gJe),e(k,hJe),e(k,Bn),e(Bn,rre),e(rre,pJe),e(Bn,uJe),e(Bn,pS),e(pS,_Je),e(Bn,bJe),e(Bn,uS),e(uS,vJe),e(Bn,FJe),e(k,TJe),e(k,_g),e(_g,tre),e(tre,MJe),e(_g,EJe),e(_g,_S),e(_S,CJe),e(_g,wJe),e(k,AJe),e(k,Pn),e(Pn,are),e(are,yJe),e(Pn,LJe),e(Pn,bS),e(bS,xJe),e(Pn,$Je),e(Pn,vS),e(vS,kJe),e(Pn,SJe),e(k,RJe),e(k,bg),e(bg,nre),e(nre,BJe),e(bg,PJe),e(bg,FS),e(FS,IJe),e(bg,qJe),e(k,NJe),e(k,vg),e(vg,sre),e(sre,jJe),e(vg,DJe),e(vg,TS),e(TS,GJe),e(vg,OJe),e(k,VJe),e(k,Fg),e(Fg,lre),e(lre,XJe),e(Fg,zJe),e(Fg,MS),e(MS,QJe),e(Fg,WJe),e(k,HJe),e(k,In),e(In,ire),e(ire,UJe),e(In,JJe),e(In,ES),e(ES,YJe),e(In,KJe),e(In,CS),e(CS,ZJe),e(In,eYe),e(k,oYe),e(k,qn),e(qn,dre),e(dre,rYe),e(qn,tYe),e(qn,wS),e(wS,aYe),e(qn,nYe),e(qn,AS),e(AS,sYe),e(qn,lYe),e(k,iYe),e(k,Nn),e(Nn,cre),e(cre,dYe),e(Nn,cYe),e(Nn,yS),e(yS,fYe),e(Nn,mYe),e(Nn,LS),e(LS,gYe),e(Nn,hYe),e(k,pYe),e(k,Tg),e(Tg,fre),e(fre,uYe),e(Tg,_Ye),e(Tg,xS),e(xS,bYe),e(Tg,vYe),e(k,FYe),e(k,Mg),e(Mg,mre),e(mre,TYe),e(Mg,MYe),e(Mg,$S),e($S,EYe),e(Mg,CYe),e(k,wYe),e(k,jn),e(jn,gre),e(gre,AYe),e(jn,yYe),e(jn,kS),e(kS,LYe),e(jn,xYe),e(jn,SS),e(SS,$Ye),e(jn,kYe),e(k,SYe),e(k,Eg),e(Eg,hre),e(hre,RYe),e(Eg,BYe),e(Eg,RS),e(RS,PYe),e(Eg,IYe),e(k,qYe),e(k,Dn),e(Dn,pre),e(pre,NYe),e(Dn,jYe),e(Dn,BS),e(BS,DYe),e(Dn,GYe),e(Dn,PS),e(PS,OYe),e(Dn,VYe),e(k,XYe),e(k,Gn),e(Gn,ure),e(ure,zYe),e(Gn,QYe),e(Gn,IS),e(IS,WYe),e(Gn,HYe),e(Gn,qS),e(qS,UYe),e(Gn,JYe),e(k,YYe),e(k,On),e(On,_re),e(_re,KYe),e(On,ZYe),e(On,NS),e(NS,eKe),e(On,oKe),e(On,jS),e(jS,rKe),e(On,tKe),e(k,aKe),e(k,Cg),e(Cg,bre),e(bre,nKe),e(Cg,sKe),e(Cg,DS),e(DS,lKe),e(Cg,iKe),e(k,dKe),e(k,Vn),e(Vn,vre),e(vre,cKe),e(Vn,fKe),e(Vn,GS),e(GS,mKe),e(Vn,gKe),e(Vn,OS),e(OS,hKe),e(Vn,pKe),e(k,uKe),e(k,Xn),e(Xn,Fre),e(Fre,_Ke),e(Xn,bKe),e(Xn,VS),e(VS,vKe),e(Xn,FKe),e(Xn,XS),e(XS,TKe),e(Xn,MKe),e(k,EKe),e(k,zn),e(zn,Tre),e(Tre,CKe),e(zn,wKe),e(zn,zS),e(zS,AKe),e(zn,yKe),e(zn,QS),e(QS,LKe),e(zn,xKe),e(k,$Ke),e(k,Qn),e(Qn,Mre),e(Mre,kKe),e(Qn,SKe),e(Qn,WS),e(WS,RKe),e(Qn,BKe),e(Qn,HS),e(HS,PKe),e(Qn,IKe),e(k,qKe),e(k,Wn),e(Wn,Ere),e(Ere,NKe),e(Wn,jKe),e(Wn,US),e(US,DKe),e(Wn,GKe),e(Wn,JS),e(JS,OKe),e(Wn,VKe),e(k,XKe),e(k,Hn),e(Hn,Cre),e(Cre,zKe),e(Hn,QKe),e(Hn,YS),e(YS,WKe),e(Hn,HKe),e(Hn,KS),e(KS,UKe),e(Hn,JKe),e(k,YKe),e(k,wg),e(wg,wre),e(wre,KKe),e(wg,ZKe),e(wg,ZS),e(ZS,eZe),e(wg,oZe),e(k,rZe),e(k,Un),e(Un,Are),e(Are,tZe),e(Un,aZe),e(Un,eR),e(eR,nZe),e(Un,sZe),e(Un,oR),e(oR,lZe),e(Un,iZe),e(k,dZe),e(k,Ag),e(Ag,yre),e(yre,cZe),e(Ag,fZe),e(Ag,rR),e(rR,mZe),e(Ag,gZe),e(k,hZe),e(k,Jn),e(Jn,Lre),e(Lre,pZe),e(Jn,uZe),e(Jn,tR),e(tR,_Ze),e(Jn,bZe),e(Jn,aR),e(aR,vZe),e(Jn,FZe),e(k,TZe),e(k,Yn),e(Yn,xre),e(xre,MZe),e(Yn,EZe),e(Yn,nR),e(nR,CZe),e(Yn,wZe),e(Yn,sR),e(sR,AZe),e(Yn,yZe),e(k,LZe),e(k,Kn),e(Kn,$re),e($re,xZe),e(Kn,$Ze),e(Kn,lR),e(lR,kZe),e(Kn,SZe),e(Kn,iR),e(iR,RZe),e(Kn,BZe),e(k,PZe),e(k,Zn),e(Zn,kre),e(kre,IZe),e(Zn,qZe),e(Zn,dR),e(dR,NZe),e(Zn,jZe),e(Zn,cR),e(cR,DZe),e(Zn,GZe),e(k,OZe),e(k,es),e(es,Sre),e(Sre,VZe),e(es,XZe),e(es,fR),e(fR,zZe),e(es,QZe),e(es,mR),e(mR,WZe),e(es,HZe),e(k,UZe),e(k,yg),e(yg,Rre),e(Rre,JZe),e(yg,YZe),e(yg,gR),e(gR,KZe),e(yg,ZZe),e(k,eeo),e(k,os),e(os,Bre),e(Bre,oeo),e(os,reo),e(os,hR),e(hR,teo),e(os,aeo),e(os,pR),e(pR,neo),e(os,seo),e(k,leo),e(k,rs),e(rs,Pre),e(Pre,ieo),e(rs,deo),e(rs,uR),e(uR,ceo),e(rs,feo),e(rs,_R),e(_R,meo),e(rs,geo),e(k,heo),e(k,ts),e(ts,Ire),e(Ire,peo),e(ts,ueo),e(ts,bR),e(bR,_eo),e(ts,beo),e(ts,vR),e(vR,veo),e(ts,Feo),e(k,Teo),e(k,as),e(as,qre),e(qre,Meo),e(as,Eeo),e(as,FR),e(FR,Ceo),e(as,weo),e(as,TR),e(TR,Aeo),e(as,yeo),e(k,Leo),e(k,ns),e(ns,Nre),e(Nre,xeo),e(ns,$eo),e(ns,MR),e(MR,keo),e(ns,Seo),e(ns,ER),e(ER,Reo),e(ns,Beo),e(k,Peo),e(k,ss),e(ss,jre),e(jre,Ieo),e(ss,qeo),e(ss,CR),e(CR,Neo),e(ss,jeo),e(ss,wR),e(wR,Deo),e(ss,Geo),e(k,Oeo),e(k,Lg),e(Lg,Dre),e(Dre,Veo),e(Lg,Xeo),e(Lg,AR),e(AR,zeo),e(Lg,Qeo),e(k,Weo),e(k,ls),e(ls,Gre),e(Gre,Heo),e(ls,Ueo),e(ls,yR),e(yR,Jeo),e(ls,Yeo),e(ls,LR),e(LR,Keo),e(ls,Zeo),e(k,eoo),e(k,xg),e(xg,Ore),e(Ore,ooo),e(xg,roo),e(xg,xR),e(xR,too),e(xg,aoo),e(k,noo),e(k,$g),e($g,Vre),e(Vre,soo),e($g,loo),e($g,$R),e($R,ioo),e($g,doo),e(k,coo),e(k,is),e(is,Xre),e(Xre,foo),e(is,moo),e(is,kR),e(kR,goo),e(is,hoo),e(is,SR),e(SR,poo),e(is,uoo),e(k,_oo),e(k,ds),e(ds,zre),e(zre,boo),e(ds,voo),e(ds,RR),e(RR,Foo),e(ds,Too),e(ds,BR),e(BR,Moo),e(ds,Eoo),e(k,Coo),e(k,cs),e(cs,Qre),e(Qre,woo),e(cs,Aoo),e(cs,PR),e(PR,yoo),e(cs,Loo),e(cs,IR),e(IR,xoo),e(cs,$oo),e(k,koo),e(k,kg),e(kg,Wre),e(Wre,Soo),e(kg,Roo),e(kg,qR),e(qR,Boo),e(kg,Poo),e(k,Ioo),e(k,fs),e(fs,Hre),e(Hre,qoo),e(fs,Noo),e(fs,NR),e(NR,joo),e(fs,Doo),e(fs,jR),e(jR,Goo),e(fs,Ooo),e(k,Voo),e(k,ms),e(ms,Ure),e(Ure,Xoo),e(ms,zoo),e(ms,DR),e(DR,Qoo),e(ms,Woo),e(ms,GR),e(GR,Hoo),e(ms,Uoo),e(k,Joo),e(k,gs),e(gs,Jre),e(Jre,Yoo),e(gs,Koo),e(gs,OR),e(OR,Zoo),e(gs,ero),e(gs,VR),e(VR,oro),e(gs,rro),e(k,tro),e(k,hs),e(hs,Yre),e(Yre,aro),e(hs,nro),e(hs,XR),e(XR,sro),e(hs,lro),e(hs,zR),e(zR,iro),e(hs,dro),e(k,cro),e(k,ps),e(ps,Kre),e(Kre,fro),e(ps,mro),e(ps,QR),e(QR,gro),e(ps,hro),e(ps,WR),e(WR,pro),e(ps,uro),e(k,_ro),e(k,us),e(us,Zre),e(Zre,bro),e(us,vro),e(us,HR),e(HR,Fro),e(us,Tro),e(us,UR),e(UR,Mro),e(us,Ero),e(k,Cro),e(k,Sg),e(Sg,ete),e(ete,wro),e(Sg,Aro),e(Sg,JR),e(JR,yro),e(Sg,Lro),e(k,xro),e(k,Rg),e(Rg,ote),e(ote,$ro),e(Rg,kro),e(Rg,YR),e(YR,Sro),e(Rg,Rro),e(k,Bro),e(k,Bg),e(Bg,rte),e(rte,Pro),e(Bg,Iro),e(Bg,KR),e(KR,qro),e(Bg,Nro),e(k,jro),e(k,Pg),e(Pg,tte),e(tte,Dro),e(Pg,Gro),e(Pg,ZR),e(ZR,Oro),e(Pg,Vro),e(k,Xro),e(k,_s),e(_s,ate),e(ate,zro),e(_s,Qro),e(_s,eB),e(eB,Wro),e(_s,Hro),e(_s,oB),e(oB,Uro),e(_s,Jro),e(k,Yro),e(k,Ig),e(Ig,nte),e(nte,Kro),e(Ig,Zro),e(Ig,rB),e(rB,eto),e(Ig,oto),e(k,rto),e(k,bs),e(bs,ste),e(ste,tto),e(bs,ato),e(bs,tB),e(tB,nto),e(bs,sto),e(bs,aB),e(aB,lto),e(bs,ito),e(k,dto),e(k,vs),e(vs,lte),e(lte,cto),e(vs,fto),e(vs,nB),e(nB,mto),e(vs,gto),e(vs,sB),e(sB,hto),e(vs,pto),e(k,uto),e(k,Fs),e(Fs,ite),e(ite,_to),e(Fs,bto),e(Fs,lB),e(lB,vto),e(Fs,Fto),e(Fs,iB),e(iB,Tto),e(Fs,Mto),e(k,Eto),e(k,Ts),e(Ts,dte),e(dte,Cto),e(Ts,wto),e(Ts,dB),e(dB,Ato),e(Ts,yto),e(Ts,cB),e(cB,Lto),e(Ts,xto),e(k,$to),e(k,Ms),e(Ms,cte),e(cte,kto),e(Ms,Sto),e(Ms,fB),e(fB,Rto),e(Ms,Bto),e(Ms,mB),e(mB,Pto),e(Ms,Ito),e(k,qto),e(k,Es),e(Es,fte),e(fte,Nto),e(Es,jto),e(Es,gB),e(gB,Dto),e(Es,Gto),e(Es,hB),e(hB,Oto),e(Es,Vto),e(k,Xto),e(k,qg),e(qg,mte),e(mte,zto),e(qg,Qto),e(qg,pB),e(pB,Wto),e(qg,Hto),e(k,Uto),e(k,Ng),e(Ng,gte),e(gte,Jto),e(Ng,Yto),e(Ng,uB),e(uB,Kto),e(Ng,Zto),e(k,eao),e(k,Cs),e(Cs,hte),e(hte,oao),e(Cs,rao),e(Cs,_B),e(_B,tao),e(Cs,aao),e(Cs,bB),e(bB,nao),e(Cs,sao),e(k,lao),e(k,ws),e(ws,pte),e(pte,iao),e(ws,dao),e(ws,vB),e(vB,cao),e(ws,fao),e(ws,FB),e(FB,mao),e(ws,gao),e(k,hao),e(k,As),e(As,ute),e(ute,pao),e(As,uao),e(As,TB),e(TB,_ao),e(As,bao),e(As,MB),e(MB,vao),e(As,Fao),e(k,Tao),e(k,jg),e(jg,_te),e(_te,Mao),e(jg,Eao),e(jg,EB),e(EB,Cao),e(jg,wao),e(k,Aao),e(k,Dg),e(Dg,bte),e(bte,yao),e(Dg,Lao),e(Dg,CB),e(CB,xao),e(Dg,$ao),e(k,kao),e(k,Gg),e(Gg,vte),e(vte,Sao),e(Gg,Rao),e(Gg,wB),e(wB,Bao),e(Gg,Pao),e(k,Iao),e(k,ys),e(ys,Fte),e(Fte,qao),e(ys,Nao),e(ys,AB),e(AB,jao),e(ys,Dao),e(ys,yB),e(yB,Gao),e(ys,Oao),e(k,Vao),e(k,Og),e(Og,Tte),e(Tte,Xao),e(Og,zao),e(Og,LB),e(LB,Qao),e(Og,Wao),e(k,Hao),e(k,Vg),e(Vg,Mte),e(Mte,Uao),e(Vg,Jao),e(Vg,xB),e(xB,Yao),e(Vg,Kao),e(k,Zao),e(k,Ls),e(Ls,Ete),e(Ete,eno),e(Ls,ono),e(Ls,$B),e($B,rno),e(Ls,tno),e(Ls,kB),e(kB,ano),e(Ls,nno),e(k,sno),e(k,Xg),e(Xg,Cte),e(Cte,lno),e(Xg,ino),e(Xg,SB),e(SB,dno),e(Xg,cno),e(k,fno),e(k,zg),e(zg,wte),e(wte,mno),e(zg,gno),e(zg,RB),e(RB,hno),e(zg,pno),e(k,uno),e(k,xs),e(xs,Ate),e(Ate,_no),e(xs,bno),e(xs,BB),e(BB,vno),e(xs,Fno),e(xs,PB),e(PB,Tno),e(xs,Mno),e(k,Eno),e(k,$s),e($s,yte),e(yte,Cno),e($s,wno),e($s,IB),e(IB,Ano),e($s,yno),e($s,qB),e(qB,Lno),e($s,xno),e(k,$no),e(k,ks),e(ks,Lte),e(Lte,kno),e(ks,Sno),e(ks,NB),e(NB,Rno),e(ks,Bno),e(ks,jB),e(jB,Pno),e(ks,Ino),e(k,qno),e(k,Ss),e(Ss,xte),e(xte,Nno),e(Ss,jno),e(Ss,DB),e(DB,Dno),e(Ss,Gno),e(Ss,GB),e(GB,Ono),e(Ss,Vno),e(Cr,Xno),M(Qg,Cr,null),e(wo,zno),e(wo,Wg),M(aA,Wg,null),e(Wg,Qno),e(Wg,$te),e($te,Wno),b(f,CPe,_),b(f,vi,_),e(vi,Hg),e(Hg,kte),M(nA,kte,null),e(vi,Hno),e(vi,Ste),e(Ste,Uno),b(f,wPe,_),b(f,Ao,_),M(sA,Ao,null),e(Ao,Jno),e(Ao,lA),e(lA,Yno),e(lA,OB),e(OB,Kno),e(lA,Zno),e(Ao,eso),e(Ao,iA),e(iA,oso),e(iA,Rte),e(Rte,rso),e(iA,tso),e(Ao,aso),e(Ao,Qe),M(dA,Qe,null),e(Qe,nso),e(Qe,Bte),e(Bte,sso),e(Qe,lso),e(Qe,wa),e(wa,iso),e(wa,Pte),e(Pte,dso),e(wa,cso),e(wa,Ite),e(Ite,fso),e(wa,mso),e(wa,qte),e(qte,gso),e(wa,hso),e(Qe,pso),e(Qe,te),e(te,Ug),e(Ug,Nte),e(Nte,uso),e(Ug,_so),e(Ug,VB),e(VB,bso),e(Ug,vso),e(te,Fso),e(te,Jg),e(Jg,jte),e(jte,Tso),e(Jg,Mso),e(Jg,XB),e(XB,Eso),e(Jg,Cso),e(te,wso),e(te,Yg),e(Yg,Dte),e(Dte,Aso),e(Yg,yso),e(Yg,zB),e(zB,Lso),e(Yg,xso),e(te,$so),e(te,Kg),e(Kg,Gte),e(Gte,kso),e(Kg,Sso),e(Kg,QB),e(QB,Rso),e(Kg,Bso),e(te,Pso),e(te,Zg),e(Zg,Ote),e(Ote,Iso),e(Zg,qso),e(Zg,WB),e(WB,Nso),e(Zg,jso),e(te,Dso),e(te,eh),e(eh,Vte),e(Vte,Gso),e(eh,Oso),e(eh,HB),e(HB,Vso),e(eh,Xso),e(te,zso),e(te,oh),e(oh,Xte),e(Xte,Qso),e(oh,Wso),e(oh,UB),e(UB,Hso),e(oh,Uso),e(te,Jso),e(te,rh),e(rh,zte),e(zte,Yso),e(rh,Kso),e(rh,JB),e(JB,Zso),e(rh,elo),e(te,olo),e(te,th),e(th,Qte),e(Qte,rlo),e(th,tlo),e(th,YB),e(YB,alo),e(th,nlo),e(te,slo),e(te,ah),e(ah,Wte),e(Wte,llo),e(ah,ilo),e(ah,KB),e(KB,dlo),e(ah,clo),e(te,flo),e(te,nh),e(nh,Hte),e(Hte,mlo),e(nh,glo),e(nh,ZB),e(ZB,hlo),e(nh,plo),e(te,ulo),e(te,sh),e(sh,Ute),e(Ute,_lo),e(sh,blo),e(sh,eP),e(eP,vlo),e(sh,Flo),e(te,Tlo),e(te,lh),e(lh,Jte),e(Jte,Mlo),e(lh,Elo),e(lh,oP),e(oP,Clo),e(lh,wlo),e(te,Alo),e(te,ih),e(ih,Yte),e(Yte,ylo),e(ih,Llo),e(ih,rP),e(rP,xlo),e(ih,$lo),e(te,klo),e(te,dh),e(dh,Kte),e(Kte,Slo),e(dh,Rlo),e(dh,tP),e(tP,Blo),e(dh,Plo),e(te,Ilo),e(te,ch),e(ch,Zte),e(Zte,qlo),e(ch,Nlo),e(ch,aP),e(aP,jlo),e(ch,Dlo),e(te,Glo),e(te,fh),e(fh,eae),e(eae,Olo),e(fh,Vlo),e(fh,nP),e(nP,Xlo),e(fh,zlo),e(te,Qlo),e(te,mh),e(mh,oae),e(oae,Wlo),e(mh,Hlo),e(mh,sP),e(sP,Ulo),e(mh,Jlo),e(te,Ylo),e(te,gh),e(gh,rae),e(rae,Klo),e(gh,Zlo),e(gh,lP),e(lP,eio),e(gh,oio),e(te,rio),e(te,hh),e(hh,tae),e(tae,tio),e(hh,aio),e(hh,iP),e(iP,nio),e(hh,sio),e(te,lio),e(te,ph),e(ph,aae),e(aae,iio),e(ph,dio),e(ph,dP),e(dP,cio),e(ph,fio),e(te,mio),e(te,uh),e(uh,nae),e(nae,gio),e(uh,hio),e(uh,cP),e(cP,pio),e(uh,uio),e(te,_io),e(te,_h),e(_h,sae),e(sae,bio),e(_h,vio),e(_h,fP),e(fP,Fio),e(_h,Tio),e(te,Mio),e(te,bh),e(bh,lae),e(lae,Eio),e(bh,Cio),e(bh,mP),e(mP,wio),e(bh,Aio),e(Qe,yio),M(vh,Qe,null),e(Qe,Lio),M(Fh,Qe,null),e(Ao,xio),e(Ao,Th),M(cA,Th,null),e(Th,$io),e(Th,iae),e(iae,kio),b(f,APe,_),b(f,Fi,_),e(Fi,Mh),e(Mh,dae),M(fA,dae,null),e(Fi,Sio),e(Fi,cae),e(cae,Rio),b(f,yPe,_),b(f,yo,_),M(mA,yo,null),e(yo,Bio),e(yo,gA),e(gA,Pio),e(gA,gP),e(gP,Iio),e(gA,qio),e(yo,Nio),e(yo,hA),e(hA,jio),e(hA,fae),e(fae,Dio),e(hA,Gio),e(yo,Oio),e(yo,We),M(pA,We,null),e(We,Vio),e(We,mae),e(mae,Xio),e(We,zio),e(We,Ti),e(Ti,Qio),e(Ti,gae),e(gae,Wio),e(Ti,Hio),e(Ti,hae),e(hae,Uio),e(Ti,Jio),e(We,Yio),e(We,be),e(be,Eh),e(Eh,pae),e(pae,Kio),e(Eh,Zio),e(Eh,hP),e(hP,edo),e(Eh,odo),e(be,rdo),e(be,Ch),e(Ch,uae),e(uae,tdo),e(Ch,ado),e(Ch,pP),e(pP,ndo),e(Ch,sdo),e(be,ldo),e(be,wh),e(wh,_ae),e(_ae,ido),e(wh,ddo),e(wh,uP),e(uP,cdo),e(wh,fdo),e(be,mdo),e(be,Ah),e(Ah,bae),e(bae,gdo),e(Ah,hdo),e(Ah,_P),e(_P,pdo),e(Ah,udo),e(be,_do),e(be,yh),e(yh,vae),e(vae,bdo),e(yh,vdo),e(yh,bP),e(bP,Fdo),e(yh,Tdo),e(be,Mdo),e(be,Lh),e(Lh,Fae),e(Fae,Edo),e(Lh,Cdo),e(Lh,vP),e(vP,wdo),e(Lh,Ado),e(be,ydo),e(be,xh),e(xh,Tae),e(Tae,Ldo),e(xh,xdo),e(xh,FP),e(FP,$do),e(xh,kdo),e(be,Sdo),e(be,$h),e($h,Mae),e(Mae,Rdo),e($h,Bdo),e($h,TP),e(TP,Pdo),e($h,Ido),e(be,qdo),e(be,kh),e(kh,Eae),e(Eae,Ndo),e(kh,jdo),e(kh,MP),e(MP,Ddo),e(kh,Gdo),e(be,Odo),e(be,Sh),e(Sh,Cae),e(Cae,Vdo),e(Sh,Xdo),e(Sh,EP),e(EP,zdo),e(Sh,Qdo),e(be,Wdo),e(be,Rh),e(Rh,wae),e(wae,Hdo),e(Rh,Udo),e(Rh,CP),e(CP,Jdo),e(Rh,Ydo),e(be,Kdo),e(be,Bh),e(Bh,Aae),e(Aae,Zdo),e(Bh,eco),e(Bh,wP),e(wP,oco),e(Bh,rco),e(be,tco),e(be,Ph),e(Ph,yae),e(yae,aco),e(Ph,nco),e(Ph,AP),e(AP,sco),e(Ph,lco),e(be,ico),e(be,Ih),e(Ih,Lae),e(Lae,dco),e(Ih,cco),e(Ih,yP),e(yP,fco),e(Ih,mco),e(We,gco),M(qh,We,null),e(We,hco),M(Nh,We,null),e(yo,pco),e(yo,jh),M(uA,jh,null),e(jh,uco),e(jh,xae),e(xae,_co),b(f,LPe,_),b(f,Mi,_),e(Mi,Dh),e(Dh,$ae),M(_A,$ae,null),e(Mi,bco),e(Mi,kae),e(kae,vco),b(f,xPe,_),b(f,Lo,_),M(bA,Lo,null),e(Lo,Fco),e(Lo,Ei),e(Ei,Tco),e(Ei,LP),e(LP,Mco),e(Ei,Eco),e(Ei,xP),e(xP,Cco),e(Ei,wco),e(Lo,Aco),e(Lo,vA),e(vA,yco),e(vA,Sae),e(Sae,Lco),e(vA,xco),e(Lo,$co),e(Lo,ot),M(FA,ot,null),e(ot,kco),e(ot,Rae),e(Rae,Sco),e(ot,Rco),e(ot,Ci),e(Ci,Bco),e(Ci,Bae),e(Bae,Pco),e(Ci,Ico),e(Ci,$P),e($P,qco),e(Ci,Nco),e(ot,jco),M(Gh,ot,null),e(Lo,Dco),e(Lo,He),M(TA,He,null),e(He,Gco),e(He,Pae),e(Pae,Oco),e(He,Vco),e(He,Aa),e(Aa,Xco),e(Aa,Iae),e(Iae,zco),e(Aa,Qco),e(Aa,qae),e(qae,Wco),e(Aa,Hco),e(Aa,Nae),e(Nae,Uco),e(Aa,Jco),e(He,Yco),e(He,x),e(x,Oh),e(Oh,jae),e(jae,Kco),e(Oh,Zco),e(Oh,kP),e(kP,efo),e(Oh,ofo),e(x,rfo),e(x,Vh),e(Vh,Dae),e(Dae,tfo),e(Vh,afo),e(Vh,SP),e(SP,nfo),e(Vh,sfo),e(x,lfo),e(x,Xh),e(Xh,Gae),e(Gae,ifo),e(Xh,dfo),e(Xh,RP),e(RP,cfo),e(Xh,ffo),e(x,mfo),e(x,zh),e(zh,Oae),e(Oae,gfo),e(zh,hfo),e(zh,BP),e(BP,pfo),e(zh,ufo),e(x,_fo),e(x,Qh),e(Qh,Vae),e(Vae,bfo),e(Qh,vfo),e(Qh,PP),e(PP,Ffo),e(Qh,Tfo),e(x,Mfo),e(x,Wh),e(Wh,Xae),e(Xae,Efo),e(Wh,Cfo),e(Wh,IP),e(IP,wfo),e(Wh,Afo),e(x,yfo),e(x,Hh),e(Hh,zae),e(zae,Lfo),e(Hh,xfo),e(Hh,qP),e(qP,$fo),e(Hh,kfo),e(x,Sfo),e(x,Uh),e(Uh,Qae),e(Qae,Rfo),e(Uh,Bfo),e(Uh,NP),e(NP,Pfo),e(Uh,Ifo),e(x,qfo),e(x,Jh),e(Jh,Wae),e(Wae,Nfo),e(Jh,jfo),e(Jh,jP),e(jP,Dfo),e(Jh,Gfo),e(x,Ofo),e(x,Yh),e(Yh,Hae),e(Hae,Vfo),e(Yh,Xfo),e(Yh,DP),e(DP,zfo),e(Yh,Qfo),e(x,Wfo),e(x,Kh),e(Kh,Uae),e(Uae,Hfo),e(Kh,Ufo),e(Kh,GP),e(GP,Jfo),e(Kh,Yfo),e(x,Kfo),e(x,Zh),e(Zh,Jae),e(Jae,Zfo),e(Zh,emo),e(Zh,OP),e(OP,omo),e(Zh,rmo),e(x,tmo),e(x,ep),e(ep,Yae),e(Yae,amo),e(ep,nmo),e(ep,VP),e(VP,smo),e(ep,lmo),e(x,imo),e(x,op),e(op,Kae),e(Kae,dmo),e(op,cmo),e(op,XP),e(XP,fmo),e(op,mmo),e(x,gmo),e(x,rp),e(rp,Zae),e(Zae,hmo),e(rp,pmo),e(rp,zP),e(zP,umo),e(rp,_mo),e(x,bmo),e(x,tp),e(tp,ene),e(ene,vmo),e(tp,Fmo),e(tp,QP),e(QP,Tmo),e(tp,Mmo),e(x,Emo),e(x,ap),e(ap,one),e(one,Cmo),e(ap,wmo),e(ap,WP),e(WP,Amo),e(ap,ymo),e(x,Lmo),e(x,np),e(np,rne),e(rne,xmo),e(np,$mo),e(np,HP),e(HP,kmo),e(np,Smo),e(x,Rmo),e(x,sp),e(sp,tne),e(tne,Bmo),e(sp,Pmo),e(sp,UP),e(UP,Imo),e(sp,qmo),e(x,Nmo),e(x,lp),e(lp,ane),e(ane,jmo),e(lp,Dmo),e(lp,JP),e(JP,Gmo),e(lp,Omo),e(x,Vmo),e(x,ip),e(ip,nne),e(nne,Xmo),e(ip,zmo),e(ip,YP),e(YP,Qmo),e(ip,Wmo),e(x,Hmo),e(x,dp),e(dp,sne),e(sne,Umo),e(dp,Jmo),e(dp,KP),e(KP,Ymo),e(dp,Kmo),e(x,Zmo),e(x,cp),e(cp,lne),e(lne,ego),e(cp,ogo),e(cp,ZP),e(ZP,rgo),e(cp,tgo),e(x,ago),e(x,fp),e(fp,ine),e(ine,ngo),e(fp,sgo),e(fp,eI),e(eI,lgo),e(fp,igo),e(x,dgo),e(x,mp),e(mp,dne),e(dne,cgo),e(mp,fgo),e(mp,oI),e(oI,mgo),e(mp,ggo),e(x,hgo),e(x,gp),e(gp,cne),e(cne,pgo),e(gp,ugo),e(gp,rI),e(rI,_go),e(gp,bgo),e(x,vgo),e(x,hp),e(hp,fne),e(fne,Fgo),e(hp,Tgo),e(hp,tI),e(tI,Mgo),e(hp,Ego),e(x,Cgo),e(x,pp),e(pp,mne),e(mne,wgo),e(pp,Ago),e(pp,aI),e(aI,ygo),e(pp,Lgo),e(x,xgo),e(x,up),e(up,gne),e(gne,$go),e(up,kgo),e(up,nI),e(nI,Sgo),e(up,Rgo),e(x,Bgo),e(x,_p),e(_p,hne),e(hne,Pgo),e(_p,Igo),e(_p,sI),e(sI,qgo),e(_p,Ngo),e(x,jgo),e(x,Rs),e(Rs,pne),e(pne,Dgo),e(Rs,Ggo),e(Rs,lI),e(lI,Ogo),e(Rs,Vgo),e(Rs,iI),e(iI,Xgo),e(Rs,zgo),e(x,Qgo),e(x,bp),e(bp,une),e(une,Wgo),e(bp,Hgo),e(bp,dI),e(dI,Ugo),e(bp,Jgo),e(x,Ygo),e(x,vp),e(vp,_ne),e(_ne,Kgo),e(vp,Zgo),e(vp,cI),e(cI,eho),e(vp,oho),e(x,rho),e(x,Fp),e(Fp,bne),e(bne,tho),e(Fp,aho),e(Fp,fI),e(fI,nho),e(Fp,sho),e(x,lho),e(x,Tp),e(Tp,vne),e(vne,iho),e(Tp,dho),e(Tp,mI),e(mI,cho),e(Tp,fho),e(x,mho),e(x,Mp),e(Mp,Fne),e(Fne,gho),e(Mp,hho),e(Mp,gI),e(gI,pho),e(Mp,uho),e(x,_ho),e(x,Ep),e(Ep,Tne),e(Tne,bho),e(Ep,vho),e(Ep,hI),e(hI,Fho),e(Ep,Tho),e(x,Mho),e(x,Cp),e(Cp,Mne),e(Mne,Eho),e(Cp,Cho),e(Cp,pI),e(pI,who),e(Cp,Aho),e(x,yho),e(x,wp),e(wp,Ene),e(Ene,Lho),e(wp,xho),e(wp,uI),e(uI,$ho),e(wp,kho),e(x,Sho),e(x,Ap),e(Ap,Cne),e(Cne,Rho),e(Ap,Bho),e(Ap,_I),e(_I,Pho),e(Ap,Iho),e(x,qho),e(x,yp),e(yp,wne),e(wne,Nho),e(yp,jho),e(yp,bI),e(bI,Dho),e(yp,Gho),e(x,Oho),e(x,Lp),e(Lp,Ane),e(Ane,Vho),e(Lp,Xho),e(Lp,vI),e(vI,zho),e(Lp,Qho),e(x,Who),e(x,xp),e(xp,yne),e(yne,Hho),e(xp,Uho),e(xp,FI),e(FI,Jho),e(xp,Yho),e(x,Kho),e(x,$p),e($p,Lne),e(Lne,Zho),e($p,epo),e($p,TI),e(TI,opo),e($p,rpo),e(x,tpo),e(x,kp),e(kp,xne),e(xne,apo),e(kp,npo),e(kp,MI),e(MI,spo),e(kp,lpo),e(x,ipo),e(x,Sp),e(Sp,$ne),e($ne,dpo),e(Sp,cpo),e(Sp,EI),e(EI,fpo),e(Sp,mpo),e(x,gpo),e(x,Rp),e(Rp,kne),e(kne,hpo),e(Rp,ppo),e(Rp,CI),e(CI,upo),e(Rp,_po),e(x,bpo),e(x,Bp),e(Bp,Sne),e(Sne,vpo),e(Bp,Fpo),e(Bp,wI),e(wI,Tpo),e(Bp,Mpo),e(x,Epo),e(x,Pp),e(Pp,Rne),e(Rne,Cpo),e(Pp,wpo),e(Pp,AI),e(AI,Apo),e(Pp,ypo),e(x,Lpo),e(x,Ip),e(Ip,Bne),e(Bne,xpo),e(Ip,$po),e(Ip,yI),e(yI,kpo),e(Ip,Spo),e(x,Rpo),e(x,qp),e(qp,Pne),e(Pne,Bpo),e(qp,Ppo),e(qp,LI),e(LI,Ipo),e(qp,qpo),e(x,Npo),e(x,Np),e(Np,Ine),e(Ine,jpo),e(Np,Dpo),e(Np,xI),e(xI,Gpo),e(Np,Opo),e(x,Vpo),e(x,jp),e(jp,qne),e(qne,Xpo),e(jp,zpo),e(jp,$I),e($I,Qpo),e(jp,Wpo),e(x,Hpo),e(x,Dp),e(Dp,Nne),e(Nne,Upo),e(Dp,Jpo),e(Dp,kI),e(kI,Ypo),e(Dp,Kpo),e(x,Zpo),e(x,Gp),e(Gp,jne),e(jne,euo),e(Gp,ouo),e(Gp,SI),e(SI,ruo),e(Gp,tuo),e(x,auo),e(x,Op),e(Op,Dne),e(Dne,nuo),e(Op,suo),e(Op,RI),e(RI,luo),e(Op,iuo),e(x,duo),e(x,Vp),e(Vp,Gne),e(Gne,cuo),e(Vp,fuo),e(Vp,BI),e(BI,muo),e(Vp,guo),e(x,huo),e(x,Xp),e(Xp,One),e(One,puo),e(Xp,uuo),e(Xp,PI),e(PI,_uo),e(Xp,buo),e(x,vuo),e(x,zp),e(zp,Vne),e(Vne,Fuo),e(zp,Tuo),e(zp,II),e(II,Muo),e(zp,Euo),e(x,Cuo),e(x,Qp),e(Qp,Xne),e(Xne,wuo),e(Qp,Auo),e(Qp,qI),e(qI,yuo),e(Qp,Luo),e(x,xuo),e(x,Wp),e(Wp,zne),e(zne,$uo),e(Wp,kuo),e(Wp,NI),e(NI,Suo),e(Wp,Ruo),e(x,Buo),e(x,Hp),e(Hp,Qne),e(Qne,Puo),e(Hp,Iuo),e(Hp,jI),e(jI,quo),e(Hp,Nuo),e(x,juo),e(x,Up),e(Up,Wne),e(Wne,Duo),e(Up,Guo),e(Up,DI),e(DI,Ouo),e(Up,Vuo),e(x,Xuo),e(x,Jp),e(Jp,Hne),e(Hne,zuo),e(Jp,Quo),e(Jp,GI),e(GI,Wuo),e(Jp,Huo),e(x,Uuo),e(x,Yp),e(Yp,Une),e(Une,Juo),e(Yp,Yuo),e(Yp,OI),e(OI,Kuo),e(Yp,Zuo),e(x,e_o),e(x,Kp),e(Kp,Jne),e(Jne,o_o),e(Kp,r_o),e(Kp,VI),e(VI,t_o),e(Kp,a_o),e(x,n_o),e(x,Zp),e(Zp,Yne),e(Yne,s_o),e(Zp,l_o),e(Zp,XI),e(XI,i_o),e(Zp,d_o),e(x,c_o),e(x,eu),e(eu,Kne),e(Kne,f_o),e(eu,m_o),e(eu,zI),e(zI,g_o),e(eu,h_o),e(x,p_o),e(x,ou),e(ou,Zne),e(Zne,u_o),e(ou,__o),e(ou,QI),e(QI,b_o),e(ou,v_o),e(x,F_o),e(x,ru),e(ru,ese),e(ese,T_o),e(ru,M_o),e(ru,WI),e(WI,E_o),e(ru,C_o),e(x,w_o),e(x,tu),e(tu,ose),e(ose,A_o),e(tu,y_o),e(tu,HI),e(HI,L_o),e(tu,x_o),e(x,$_o),e(x,au),e(au,rse),e(rse,k_o),e(au,S_o),e(au,UI),e(UI,R_o),e(au,B_o),e(x,P_o),e(x,nu),e(nu,tse),e(tse,I_o),e(nu,q_o),e(nu,JI),e(JI,N_o),e(nu,j_o),e(x,D_o),e(x,su),e(su,ase),e(ase,G_o),e(su,O_o),e(su,YI),e(YI,V_o),e(su,X_o),e(x,z_o),e(x,lu),e(lu,nse),e(nse,Q_o),e(lu,W_o),e(lu,KI),e(KI,H_o),e(lu,U_o),e(x,J_o),e(x,iu),e(iu,sse),e(sse,Y_o),e(iu,K_o),e(iu,ZI),e(ZI,Z_o),e(iu,e1o),e(x,o1o),e(x,du),e(du,lse),e(lse,r1o),e(du,t1o),e(du,eq),e(eq,a1o),e(du,n1o),e(x,s1o),e(x,cu),e(cu,ise),e(ise,l1o),e(cu,i1o),e(cu,oq),e(oq,d1o),e(cu,c1o),e(x,f1o),e(x,fu),e(fu,dse),e(dse,m1o),e(fu,g1o),e(fu,rq),e(rq,h1o),e(fu,p1o),e(x,u1o),e(x,mu),e(mu,cse),e(cse,_1o),e(mu,b1o),e(mu,tq),e(tq,v1o),e(mu,F1o),e(x,T1o),e(x,gu),e(gu,fse),e(fse,M1o),e(gu,E1o),e(gu,aq),e(aq,C1o),e(gu,w1o),e(x,A1o),e(x,hu),e(hu,mse),e(mse,y1o),e(hu,L1o),e(hu,nq),e(nq,x1o),e(hu,$1o),e(x,k1o),e(x,pu),e(pu,gse),e(gse,S1o),e(pu,R1o),e(pu,sq),e(sq,B1o),e(pu,P1o),e(x,I1o),e(x,uu),e(uu,hse),e(hse,q1o),e(uu,N1o),e(uu,lq),e(lq,j1o),e(uu,D1o),e(x,G1o),e(x,_u),e(_u,pse),e(pse,O1o),e(_u,V1o),e(_u,iq),e(iq,X1o),e(_u,z1o),e(x,Q1o),e(x,bu),e(bu,use),e(use,W1o),e(bu,H1o),e(bu,dq),e(dq,U1o),e(bu,J1o),e(x,Y1o),e(x,vu),e(vu,_se),e(_se,K1o),e(vu,Z1o),e(vu,cq),e(cq,e8o),e(vu,o8o),e(x,r8o),e(x,Fu),e(Fu,bse),e(bse,t8o),e(Fu,a8o),e(Fu,fq),e(fq,n8o),e(Fu,s8o),e(x,l8o),e(x,Tu),e(Tu,vse),e(vse,i8o),e(Tu,d8o),e(Tu,mq),e(mq,c8o),e(Tu,f8o),e(x,m8o),e(x,Mu),e(Mu,Fse),e(Fse,g8o),e(Mu,h8o),e(Mu,gq),e(gq,p8o),e(Mu,u8o),e(x,_8o),e(x,Eu),e(Eu,Tse),e(Tse,b8o),e(Eu,v8o),e(Eu,hq),e(hq,F8o),e(Eu,T8o),e(x,M8o),e(x,Cu),e(Cu,Mse),e(Mse,E8o),e(Cu,C8o),e(Cu,pq),e(pq,w8o),e(Cu,A8o),e(x,y8o),e(x,wu),e(wu,Ese),e(Ese,L8o),e(wu,x8o),e(wu,uq),e(uq,$8o),e(wu,k8o),e(x,S8o),e(x,Au),e(Au,Cse),e(Cse,R8o),e(Au,B8o),e(Au,_q),e(_q,P8o),e(Au,I8o),e(x,q8o),e(x,yu),e(yu,wse),e(wse,N8o),e(yu,j8o),e(yu,bq),e(bq,D8o),e(yu,G8o),e(He,O8o),e(He,Lu),e(Lu,V8o),e(Lu,Ase),e(Ase,X8o),e(Lu,z8o),e(Lu,yse),e(yse,Q8o),e(He,W8o),M(xu,He,null),b(f,$Pe,_),b(f,wi,_),e(wi,$u),e($u,Lse),M(MA,Lse,null),e(wi,H8o),e(wi,xse),e(xse,U8o),b(f,kPe,_),b(f,xo,_),M(EA,xo,null),e(xo,J8o),e(xo,Ai),e(Ai,Y8o),e(Ai,vq),e(vq,K8o),e(Ai,Z8o),e(Ai,Fq),e(Fq,ebo),e(Ai,obo),e(xo,rbo),e(xo,CA),e(CA,tbo),e(CA,$se),e($se,abo),e(CA,nbo),e(xo,sbo),e(xo,rt),M(wA,rt,null),e(rt,lbo),e(rt,kse),e(kse,ibo),e(rt,dbo),e(rt,yi),e(yi,cbo),e(yi,Sse),e(Sse,fbo),e(yi,mbo),e(yi,Tq),e(Tq,gbo),e(yi,hbo),e(rt,pbo),M(ku,rt,null),e(xo,ubo),e(xo,Ue),M(AA,Ue,null),e(Ue,_bo),e(Ue,Rse),e(Rse,bbo),e(Ue,vbo),e(Ue,ya),e(ya,Fbo),e(ya,Bse),e(Bse,Tbo),e(ya,Mbo),e(ya,Pse),e(Pse,Ebo),e(ya,Cbo),e(ya,Ise),e(Ise,wbo),e(ya,Abo),e(Ue,ybo),e(Ue,G),e(G,Su),e(Su,qse),e(qse,Lbo),e(Su,xbo),e(Su,Mq),e(Mq,$bo),e(Su,kbo),e(G,Sbo),e(G,Ru),e(Ru,Nse),e(Nse,Rbo),e(Ru,Bbo),e(Ru,Eq),e(Eq,Pbo),e(Ru,Ibo),e(G,qbo),e(G,Bu),e(Bu,jse),e(jse,Nbo),e(Bu,jbo),e(Bu,Cq),e(Cq,Dbo),e(Bu,Gbo),e(G,Obo),e(G,Pu),e(Pu,Dse),e(Dse,Vbo),e(Pu,Xbo),e(Pu,wq),e(wq,zbo),e(Pu,Qbo),e(G,Wbo),e(G,Iu),e(Iu,Gse),e(Gse,Hbo),e(Iu,Ubo),e(Iu,Aq),e(Aq,Jbo),e(Iu,Ybo),e(G,Kbo),e(G,qu),e(qu,Ose),e(Ose,Zbo),e(qu,e2o),e(qu,yq),e(yq,o2o),e(qu,r2o),e(G,t2o),e(G,Nu),e(Nu,Vse),e(Vse,a2o),e(Nu,n2o),e(Nu,Lq),e(Lq,s2o),e(Nu,l2o),e(G,i2o),e(G,ju),e(ju,Xse),e(Xse,d2o),e(ju,c2o),e(ju,xq),e(xq,f2o),e(ju,m2o),e(G,g2o),e(G,Du),e(Du,zse),e(zse,h2o),e(Du,p2o),e(Du,$q),e($q,u2o),e(Du,_2o),e(G,b2o),e(G,Gu),e(Gu,Qse),e(Qse,v2o),e(Gu,F2o),e(Gu,kq),e(kq,T2o),e(Gu,M2o),e(G,E2o),e(G,Ou),e(Ou,Wse),e(Wse,C2o),e(Ou,w2o),e(Ou,Sq),e(Sq,A2o),e(Ou,y2o),e(G,L2o),e(G,Vu),e(Vu,Hse),e(Hse,x2o),e(Vu,$2o),e(Vu,Rq),e(Rq,k2o),e(Vu,S2o),e(G,R2o),e(G,Xu),e(Xu,Use),e(Use,B2o),e(Xu,P2o),e(Xu,Bq),e(Bq,I2o),e(Xu,q2o),e(G,N2o),e(G,zu),e(zu,Jse),e(Jse,j2o),e(zu,D2o),e(zu,Pq),e(Pq,G2o),e(zu,O2o),e(G,V2o),e(G,Qu),e(Qu,Yse),e(Yse,X2o),e(Qu,z2o),e(Qu,Iq),e(Iq,Q2o),e(Qu,W2o),e(G,H2o),e(G,Wu),e(Wu,Kse),e(Kse,U2o),e(Wu,J2o),e(Wu,qq),e(qq,Y2o),e(Wu,K2o),e(G,Z2o),e(G,Hu),e(Hu,Zse),e(Zse,evo),e(Hu,ovo),e(Hu,Nq),e(Nq,rvo),e(Hu,tvo),e(G,avo),e(G,Uu),e(Uu,ele),e(ele,nvo),e(Uu,svo),e(Uu,jq),e(jq,lvo),e(Uu,ivo),e(G,dvo),e(G,Ju),e(Ju,ole),e(ole,cvo),e(Ju,fvo),e(Ju,Dq),e(Dq,mvo),e(Ju,gvo),e(G,hvo),e(G,Yu),e(Yu,rle),e(rle,pvo),e(Yu,uvo),e(Yu,Gq),e(Gq,_vo),e(Yu,bvo),e(G,vvo),e(G,Ku),e(Ku,tle),e(tle,Fvo),e(Ku,Tvo),e(Ku,Oq),e(Oq,Mvo),e(Ku,Evo),e(G,Cvo),e(G,Zu),e(Zu,ale),e(ale,wvo),e(Zu,Avo),e(Zu,Vq),e(Vq,yvo),e(Zu,Lvo),e(G,xvo),e(G,e_),e(e_,nle),e(nle,$vo),e(e_,kvo),e(e_,Xq),e(Xq,Svo),e(e_,Rvo),e(G,Bvo),e(G,o_),e(o_,sle),e(sle,Pvo),e(o_,Ivo),e(o_,zq),e(zq,qvo),e(o_,Nvo),e(G,jvo),e(G,r_),e(r_,lle),e(lle,Dvo),e(r_,Gvo),e(r_,Qq),e(Qq,Ovo),e(r_,Vvo),e(G,Xvo),e(G,t_),e(t_,ile),e(ile,zvo),e(t_,Qvo),e(t_,Wq),e(Wq,Wvo),e(t_,Hvo),e(G,Uvo),e(G,a_),e(a_,dle),e(dle,Jvo),e(a_,Yvo),e(a_,Hq),e(Hq,Kvo),e(a_,Zvo),e(G,eFo),e(G,n_),e(n_,cle),e(cle,oFo),e(n_,rFo),e(n_,Uq),e(Uq,tFo),e(n_,aFo),e(G,nFo),e(G,s_),e(s_,fle),e(fle,sFo),e(s_,lFo),e(s_,Jq),e(Jq,iFo),e(s_,dFo),e(G,cFo),e(G,l_),e(l_,mle),e(mle,fFo),e(l_,mFo),e(l_,Yq),e(Yq,gFo),e(l_,hFo),e(G,pFo),e(G,i_),e(i_,gle),e(gle,uFo),e(i_,_Fo),e(i_,Kq),e(Kq,bFo),e(i_,vFo),e(G,FFo),e(G,d_),e(d_,hle),e(hle,TFo),e(d_,MFo),e(d_,Zq),e(Zq,EFo),e(d_,CFo),e(G,wFo),e(G,c_),e(c_,ple),e(ple,AFo),e(c_,yFo),e(c_,eN),e(eN,LFo),e(c_,xFo),e(G,$Fo),e(G,f_),e(f_,ule),e(ule,kFo),e(f_,SFo),e(f_,oN),e(oN,RFo),e(f_,BFo),e(G,PFo),e(G,m_),e(m_,_le),e(_le,IFo),e(m_,qFo),e(m_,rN),e(rN,NFo),e(m_,jFo),e(G,DFo),e(G,g_),e(g_,ble),e(ble,GFo),e(g_,OFo),e(g_,tN),e(tN,VFo),e(g_,XFo),e(G,zFo),e(G,h_),e(h_,vle),e(vle,QFo),e(h_,WFo),e(h_,aN),e(aN,HFo),e(h_,UFo),e(G,JFo),e(G,p_),e(p_,Fle),e(Fle,YFo),e(p_,KFo),e(p_,nN),e(nN,ZFo),e(p_,e6o),e(G,o6o),e(G,u_),e(u_,Tle),e(Tle,r6o),e(u_,t6o),e(u_,sN),e(sN,a6o),e(u_,n6o),e(Ue,s6o),e(Ue,__),e(__,l6o),e(__,Mle),e(Mle,i6o),e(__,d6o),e(__,Ele),e(Ele,c6o),e(Ue,f6o),M(b_,Ue,null),b(f,SPe,_),b(f,Li,_),e(Li,v_),e(v_,Cle),M(yA,Cle,null),e(Li,m6o),e(Li,wle),e(wle,g6o),b(f,RPe,_),b(f,$o,_),M(LA,$o,null),e($o,h6o),e($o,xi),e(xi,p6o),e(xi,lN),e(lN,u6o),e(xi,_6o),e(xi,iN),e(iN,b6o),e(xi,v6o),e($o,F6o),e($o,xA),e(xA,T6o),e(xA,Ale),e(Ale,M6o),e(xA,E6o),e($o,C6o),e($o,tt),M($A,tt,null),e(tt,w6o),e(tt,yle),e(yle,A6o),e(tt,y6o),e(tt,$i),e($i,L6o),e($i,Lle),e(Lle,x6o),e($i,$6o),e($i,dN),e(dN,k6o),e($i,S6o),e(tt,R6o),M(F_,tt,null),e($o,B6o),e($o,Je),M(kA,Je,null),e(Je,P6o),e(Je,xle),e(xle,I6o),e(Je,q6o),e(Je,La),e(La,N6o),e(La,$le),e($le,j6o),e(La,D6o),e(La,kle),e(kle,G6o),e(La,O6o),e(La,Sle),e(Sle,V6o),e(La,X6o),e(Je,z6o),e(Je,z),e(z,T_),e(T_,Rle),e(Rle,Q6o),e(T_,W6o),e(T_,cN),e(cN,H6o),e(T_,U6o),e(z,J6o),e(z,M_),e(M_,Ble),e(Ble,Y6o),e(M_,K6o),e(M_,fN),e(fN,Z6o),e(M_,eTo),e(z,oTo),e(z,E_),e(E_,Ple),e(Ple,rTo),e(E_,tTo),e(E_,mN),e(mN,aTo),e(E_,nTo),e(z,sTo),e(z,C_),e(C_,Ile),e(Ile,lTo),e(C_,iTo),e(C_,gN),e(gN,dTo),e(C_,cTo),e(z,fTo),e(z,w_),e(w_,qle),e(qle,mTo),e(w_,gTo),e(w_,hN),e(hN,hTo),e(w_,pTo),e(z,uTo),e(z,A_),e(A_,Nle),e(Nle,_To),e(A_,bTo),e(A_,pN),e(pN,vTo),e(A_,FTo),e(z,TTo),e(z,y_),e(y_,jle),e(jle,MTo),e(y_,ETo),e(y_,uN),e(uN,CTo),e(y_,wTo),e(z,ATo),e(z,L_),e(L_,Dle),e(Dle,yTo),e(L_,LTo),e(L_,_N),e(_N,xTo),e(L_,$To),e(z,kTo),e(z,x_),e(x_,Gle),e(Gle,STo),e(x_,RTo),e(x_,bN),e(bN,BTo),e(x_,PTo),e(z,ITo),e(z,$_),e($_,Ole),e(Ole,qTo),e($_,NTo),e($_,vN),e(vN,jTo),e($_,DTo),e(z,GTo),e(z,k_),e(k_,Vle),e(Vle,OTo),e(k_,VTo),e(k_,FN),e(FN,XTo),e(k_,zTo),e(z,QTo),e(z,S_),e(S_,Xle),e(Xle,WTo),e(S_,HTo),e(S_,TN),e(TN,UTo),e(S_,JTo),e(z,YTo),e(z,R_),e(R_,zle),e(zle,KTo),e(R_,ZTo),e(R_,MN),e(MN,e9o),e(R_,o9o),e(z,r9o),e(z,B_),e(B_,Qle),e(Qle,t9o),e(B_,a9o),e(B_,EN),e(EN,n9o),e(B_,s9o),e(z,l9o),e(z,P_),e(P_,Wle),e(Wle,i9o),e(P_,d9o),e(P_,CN),e(CN,c9o),e(P_,f9o),e(z,m9o),e(z,I_),e(I_,Hle),e(Hle,g9o),e(I_,h9o),e(I_,wN),e(wN,p9o),e(I_,u9o),e(z,_9o),e(z,q_),e(q_,Ule),e(Ule,b9o),e(q_,v9o),e(q_,AN),e(AN,F9o),e(q_,T9o),e(z,M9o),e(z,N_),e(N_,Jle),e(Jle,E9o),e(N_,C9o),e(N_,yN),e(yN,w9o),e(N_,A9o),e(z,y9o),e(z,j_),e(j_,Yle),e(Yle,L9o),e(j_,x9o),e(j_,LN),e(LN,$9o),e(j_,k9o),e(z,S9o),e(z,D_),e(D_,Kle),e(Kle,R9o),e(D_,B9o),e(D_,xN),e(xN,P9o),e(D_,I9o),e(z,q9o),e(z,G_),e(G_,Zle),e(Zle,N9o),e(G_,j9o),e(G_,$N),e($N,D9o),e(G_,G9o),e(z,O9o),e(z,O_),e(O_,eie),e(eie,V9o),e(O_,X9o),e(O_,kN),e(kN,z9o),e(O_,Q9o),e(z,W9o),e(z,V_),e(V_,oie),e(oie,H9o),e(V_,U9o),e(V_,SN),e(SN,J9o),e(V_,Y9o),e(z,K9o),e(z,X_),e(X_,rie),e(rie,Z9o),e(X_,eMo),e(X_,RN),e(RN,oMo),e(X_,rMo),e(z,tMo),e(z,z_),e(z_,tie),e(tie,aMo),e(z_,nMo),e(z_,BN),e(BN,sMo),e(z_,lMo),e(z,iMo),e(z,Q_),e(Q_,aie),e(aie,dMo),e(Q_,cMo),e(Q_,PN),e(PN,fMo),e(Q_,mMo),e(z,gMo),e(z,W_),e(W_,nie),e(nie,hMo),e(W_,pMo),e(W_,IN),e(IN,uMo),e(W_,_Mo),e(z,bMo),e(z,H_),e(H_,sie),e(sie,vMo),e(H_,FMo),e(H_,qN),e(qN,TMo),e(H_,MMo),e(z,EMo),e(z,U_),e(U_,lie),e(lie,CMo),e(U_,wMo),e(U_,NN),e(NN,AMo),e(U_,yMo),e(z,LMo),e(z,J_),e(J_,iie),e(iie,xMo),e(J_,$Mo),e(J_,jN),e(jN,kMo),e(J_,SMo),e(z,RMo),e(z,Y_),e(Y_,die),e(die,BMo),e(Y_,PMo),e(Y_,DN),e(DN,IMo),e(Y_,qMo),e(z,NMo),e(z,K_),e(K_,cie),e(cie,jMo),e(K_,DMo),e(K_,GN),e(GN,GMo),e(K_,OMo),e(z,VMo),e(z,Z_),e(Z_,fie),e(fie,XMo),e(Z_,zMo),e(Z_,ON),e(ON,QMo),e(Z_,WMo),e(z,HMo),e(z,e1),e(e1,mie),e(mie,UMo),e(e1,JMo),e(e1,VN),e(VN,YMo),e(e1,KMo),e(z,ZMo),e(z,o1),e(o1,gie),e(gie,e4o),e(o1,o4o),e(o1,XN),e(XN,r4o),e(o1,t4o),e(Je,a4o),e(Je,r1),e(r1,n4o),e(r1,hie),e(hie,s4o),e(r1,l4o),e(r1,pie),e(pie,i4o),e(Je,d4o),M(t1,Je,null),b(f,BPe,_),b(f,ki,_),e(ki,a1),e(a1,uie),M(SA,uie,null),e(ki,c4o),e(ki,_ie),e(_ie,f4o),b(f,PPe,_),b(f,ko,_),M(RA,ko,null),e(ko,m4o),e(ko,Si),e(Si,g4o),e(Si,zN),e(zN,h4o),e(Si,p4o),e(Si,QN),e(QN,u4o),e(Si,_4o),e(ko,b4o),e(ko,BA),e(BA,v4o),e(BA,bie),e(bie,F4o),e(BA,T4o),e(ko,M4o),e(ko,at),M(PA,at,null),e(at,E4o),e(at,vie),e(vie,C4o),e(at,w4o),e(at,Ri),e(Ri,A4o),e(Ri,Fie),e(Fie,y4o),e(Ri,L4o),e(Ri,WN),e(WN,x4o),e(Ri,$4o),e(at,k4o),M(n1,at,null),e(ko,S4o),e(ko,Ye),M(IA,Ye,null),e(Ye,R4o),e(Ye,Tie),e(Tie,B4o),e(Ye,P4o),e(Ye,xa),e(xa,I4o),e(xa,Mie),e(Mie,q4o),e(xa,N4o),e(xa,Eie),e(Eie,j4o),e(xa,D4o),e(xa,Cie),e(Cie,G4o),e(xa,O4o),e(Ye,V4o),e(Ye,Q),e(Q,s1),e(s1,wie),e(wie,X4o),e(s1,z4o),e(s1,HN),e(HN,Q4o),e(s1,W4o),e(Q,H4o),e(Q,l1),e(l1,Aie),e(Aie,U4o),e(l1,J4o),e(l1,UN),e(UN,Y4o),e(l1,K4o),e(Q,Z4o),e(Q,i1),e(i1,yie),e(yie,eEo),e(i1,oEo),e(i1,JN),e(JN,rEo),e(i1,tEo),e(Q,aEo),e(Q,d1),e(d1,Lie),e(Lie,nEo),e(d1,sEo),e(d1,YN),e(YN,lEo),e(d1,iEo),e(Q,dEo),e(Q,c1),e(c1,xie),e(xie,cEo),e(c1,fEo),e(c1,KN),e(KN,mEo),e(c1,gEo),e(Q,hEo),e(Q,f1),e(f1,$ie),e($ie,pEo),e(f1,uEo),e(f1,ZN),e(ZN,_Eo),e(f1,bEo),e(Q,vEo),e(Q,m1),e(m1,kie),e(kie,FEo),e(m1,TEo),e(m1,ej),e(ej,MEo),e(m1,EEo),e(Q,CEo),e(Q,g1),e(g1,Sie),e(Sie,wEo),e(g1,AEo),e(g1,oj),e(oj,yEo),e(g1,LEo),e(Q,xEo),e(Q,h1),e(h1,Rie),e(Rie,$Eo),e(h1,kEo),e(h1,rj),e(rj,SEo),e(h1,REo),e(Q,BEo),e(Q,p1),e(p1,Bie),e(Bie,PEo),e(p1,IEo),e(p1,tj),e(tj,qEo),e(p1,NEo),e(Q,jEo),e(Q,u1),e(u1,Pie),e(Pie,DEo),e(u1,GEo),e(u1,aj),e(aj,OEo),e(u1,VEo),e(Q,XEo),e(Q,_1),e(_1,Iie),e(Iie,zEo),e(_1,QEo),e(_1,nj),e(nj,WEo),e(_1,HEo),e(Q,UEo),e(Q,b1),e(b1,qie),e(qie,JEo),e(b1,YEo),e(b1,sj),e(sj,KEo),e(b1,ZEo),e(Q,e5o),e(Q,v1),e(v1,Nie),e(Nie,o5o),e(v1,r5o),e(v1,lj),e(lj,t5o),e(v1,a5o),e(Q,n5o),e(Q,F1),e(F1,jie),e(jie,s5o),e(F1,l5o),e(F1,ij),e(ij,i5o),e(F1,d5o),e(Q,c5o),e(Q,T1),e(T1,Die),e(Die,f5o),e(T1,m5o),e(T1,dj),e(dj,g5o),e(T1,h5o),e(Q,p5o),e(Q,M1),e(M1,Gie),e(Gie,u5o),e(M1,_5o),e(M1,cj),e(cj,b5o),e(M1,v5o),e(Q,F5o),e(Q,E1),e(E1,Oie),e(Oie,T5o),e(E1,M5o),e(E1,fj),e(fj,E5o),e(E1,C5o),e(Q,w5o),e(Q,C1),e(C1,Vie),e(Vie,A5o),e(C1,y5o),e(C1,mj),e(mj,L5o),e(C1,x5o),e(Q,$5o),e(Q,w1),e(w1,Xie),e(Xie,k5o),e(w1,S5o),e(w1,gj),e(gj,R5o),e(w1,B5o),e(Q,P5o),e(Q,A1),e(A1,zie),e(zie,I5o),e(A1,q5o),e(A1,hj),e(hj,N5o),e(A1,j5o),e(Q,D5o),e(Q,y1),e(y1,Qie),e(Qie,G5o),e(y1,O5o),e(y1,pj),e(pj,V5o),e(y1,X5o),e(Q,z5o),e(Q,L1),e(L1,Wie),e(Wie,Q5o),e(L1,W5o),e(L1,uj),e(uj,H5o),e(L1,U5o),e(Q,J5o),e(Q,x1),e(x1,Hie),e(Hie,Y5o),e(x1,K5o),e(x1,_j),e(_j,Z5o),e(x1,eCo),e(Q,oCo),e(Q,$1),e($1,Uie),e(Uie,rCo),e($1,tCo),e($1,bj),e(bj,aCo),e($1,nCo),e(Q,sCo),e(Q,k1),e(k1,Jie),e(Jie,lCo),e(k1,iCo),e(k1,vj),e(vj,dCo),e(k1,cCo),e(Q,fCo),e(Q,S1),e(S1,Yie),e(Yie,mCo),e(S1,gCo),e(S1,Fj),e(Fj,hCo),e(S1,pCo),e(Q,uCo),e(Q,R1),e(R1,Kie),e(Kie,_Co),e(R1,bCo),e(R1,Tj),e(Tj,vCo),e(R1,FCo),e(Q,TCo),e(Q,B1),e(B1,Zie),e(Zie,MCo),e(B1,ECo),e(B1,Mj),e(Mj,CCo),e(B1,wCo),e(Q,ACo),e(Q,P1),e(P1,ede),e(ede,yCo),e(P1,LCo),e(P1,Ej),e(Ej,xCo),e(P1,$Co),e(Q,kCo),e(Q,I1),e(I1,ode),e(ode,SCo),e(I1,RCo),e(I1,rde),e(rde,BCo),e(I1,PCo),e(Q,ICo),e(Q,q1),e(q1,tde),e(tde,qCo),e(q1,NCo),e(q1,Cj),e(Cj,jCo),e(q1,DCo),e(Q,GCo),e(Q,N1),e(N1,ade),e(ade,OCo),e(N1,VCo),e(N1,wj),e(wj,XCo),e(N1,zCo),e(Q,QCo),e(Q,j1),e(j1,nde),e(nde,WCo),e(j1,HCo),e(j1,Aj),e(Aj,UCo),e(j1,JCo),e(Q,YCo),e(Q,D1),e(D1,sde),e(sde,KCo),e(D1,ZCo),e(D1,yj),e(yj,e3o),e(D1,o3o),e(Ye,r3o),e(Ye,G1),e(G1,t3o),e(G1,lde),e(lde,a3o),e(G1,n3o),e(G1,ide),e(ide,s3o),e(Ye,l3o),M(O1,Ye,null),b(f,IPe,_),b(f,Bi,_),e(Bi,V1),e(V1,dde),M(qA,dde,null),e(Bi,i3o),e(Bi,cde),e(cde,d3o),b(f,qPe,_),b(f,So,_),M(NA,So,null),e(So,c3o),e(So,Pi),e(Pi,f3o),e(Pi,Lj),e(Lj,m3o),e(Pi,g3o),e(Pi,xj),e(xj,h3o),e(Pi,p3o),e(So,u3o),e(So,jA),e(jA,_3o),e(jA,fde),e(fde,b3o),e(jA,v3o),e(So,F3o),e(So,nt),M(DA,nt,null),e(nt,T3o),e(nt,mde),e(mde,M3o),e(nt,E3o),e(nt,Ii),e(Ii,C3o),e(Ii,gde),e(gde,w3o),e(Ii,A3o),e(Ii,$j),e($j,y3o),e(Ii,L3o),e(nt,x3o),M(X1,nt,null),e(So,$3o),e(So,Ke),M(GA,Ke,null),e(Ke,k3o),e(Ke,hde),e(hde,S3o),e(Ke,R3o),e(Ke,$a),e($a,B3o),e($a,pde),e(pde,P3o),e($a,I3o),e($a,ude),e(ude,q3o),e($a,N3o),e($a,_de),e(_de,j3o),e($a,D3o),e(Ke,G3o),e(Ke,he),e(he,z1),e(z1,bde),e(bde,O3o),e(z1,V3o),e(z1,kj),e(kj,X3o),e(z1,z3o),e(he,Q3o),e(he,Q1),e(Q1,vde),e(vde,W3o),e(Q1,H3o),e(Q1,Sj),e(Sj,U3o),e(Q1,J3o),e(he,Y3o),e(he,W1),e(W1,Fde),e(Fde,K3o),e(W1,Z3o),e(W1,Rj),e(Rj,ewo),e(W1,owo),e(he,rwo),e(he,H1),e(H1,Tde),e(Tde,two),e(H1,awo),e(H1,Bj),e(Bj,nwo),e(H1,swo),e(he,lwo),e(he,U1),e(U1,Mde),e(Mde,iwo),e(U1,dwo),e(U1,Pj),e(Pj,cwo),e(U1,fwo),e(he,mwo),e(he,J1),e(J1,Ede),e(Ede,gwo),e(J1,hwo),e(J1,Ij),e(Ij,pwo),e(J1,uwo),e(he,_wo),e(he,Y1),e(Y1,Cde),e(Cde,bwo),e(Y1,vwo),e(Y1,qj),e(qj,Fwo),e(Y1,Two),e(he,Mwo),e(he,K1),e(K1,wde),e(wde,Ewo),e(K1,Cwo),e(K1,Nj),e(Nj,wwo),e(K1,Awo),e(he,ywo),e(he,Z1),e(Z1,Ade),e(Ade,Lwo),e(Z1,xwo),e(Z1,jj),e(jj,$wo),e(Z1,kwo),e(he,Swo),e(he,e8),e(e8,yde),e(yde,Rwo),e(e8,Bwo),e(e8,Dj),e(Dj,Pwo),e(e8,Iwo),e(he,qwo),e(he,o8),e(o8,Lde),e(Lde,Nwo),e(o8,jwo),e(o8,Gj),e(Gj,Dwo),e(o8,Gwo),e(he,Owo),e(he,r8),e(r8,xde),e(xde,Vwo),e(r8,Xwo),e(r8,Oj),e(Oj,zwo),e(r8,Qwo),e(he,Wwo),e(he,t8),e(t8,$de),e($de,Hwo),e(t8,Uwo),e(t8,Vj),e(Vj,Jwo),e(t8,Ywo),e(he,Kwo),e(he,a8),e(a8,kde),e(kde,Zwo),e(a8,eAo),e(a8,Xj),e(Xj,oAo),e(a8,rAo),e(he,tAo),e(he,n8),e(n8,Sde),e(Sde,aAo),e(n8,nAo),e(n8,zj),e(zj,sAo),e(n8,lAo),e(he,iAo),e(he,s8),e(s8,Rde),e(Rde,dAo),e(s8,cAo),e(s8,Qj),e(Qj,fAo),e(s8,mAo),e(he,gAo),e(he,l8),e(l8,Bde),e(Bde,hAo),e(l8,pAo),e(l8,Wj),e(Wj,uAo),e(l8,_Ao),e(Ke,bAo),e(Ke,i8),e(i8,vAo),e(i8,Pde),e(Pde,FAo),e(i8,TAo),e(i8,Ide),e(Ide,MAo),e(Ke,EAo),M(d8,Ke,null),b(f,NPe,_),b(f,qi,_),e(qi,c8),e(c8,qde),M(OA,qde,null),e(qi,CAo),e(qi,Nde),e(Nde,wAo),b(f,jPe,_),b(f,Ro,_),M(VA,Ro,null),e(Ro,AAo),e(Ro,Ni),e(Ni,yAo),e(Ni,Hj),e(Hj,LAo),e(Ni,xAo),e(Ni,Uj),e(Uj,$Ao),e(Ni,kAo),e(Ro,SAo),e(Ro,XA),e(XA,RAo),e(XA,jde),e(jde,BAo),e(XA,PAo),e(Ro,IAo),e(Ro,st),M(zA,st,null),e(st,qAo),e(st,Dde),e(Dde,NAo),e(st,jAo),e(st,ji),e(ji,DAo),e(ji,Gde),e(Gde,GAo),e(ji,OAo),e(ji,Jj),e(Jj,VAo),e(ji,XAo),e(st,zAo),M(f8,st,null),e(Ro,QAo),e(Ro,Ze),M(QA,Ze,null),e(Ze,WAo),e(Ze,Ode),e(Ode,HAo),e(Ze,UAo),e(Ze,ka),e(ka,JAo),e(ka,Vde),e(Vde,YAo),e(ka,KAo),e(ka,Xde),e(Xde,ZAo),e(ka,e0o),e(ka,zde),e(zde,o0o),e(ka,r0o),e(Ze,t0o),e(Ze,q),e(q,m8),e(m8,Qde),e(Qde,a0o),e(m8,n0o),e(m8,Yj),e(Yj,s0o),e(m8,l0o),e(q,i0o),e(q,g8),e(g8,Wde),e(Wde,d0o),e(g8,c0o),e(g8,Kj),e(Kj,f0o),e(g8,m0o),e(q,g0o),e(q,h8),e(h8,Hde),e(Hde,h0o),e(h8,p0o),e(h8,Zj),e(Zj,u0o),e(h8,_0o),e(q,b0o),e(q,p8),e(p8,Ude),e(Ude,v0o),e(p8,F0o),e(p8,eD),e(eD,T0o),e(p8,M0o),e(q,E0o),e(q,u8),e(u8,Jde),e(Jde,C0o),e(u8,w0o),e(u8,oD),e(oD,A0o),e(u8,y0o),e(q,L0o),e(q,_8),e(_8,Yde),e(Yde,x0o),e(_8,$0o),e(_8,rD),e(rD,k0o),e(_8,S0o),e(q,R0o),e(q,b8),e(b8,Kde),e(Kde,B0o),e(b8,P0o),e(b8,tD),e(tD,I0o),e(b8,q0o),e(q,N0o),e(q,v8),e(v8,Zde),e(Zde,j0o),e(v8,D0o),e(v8,aD),e(aD,G0o),e(v8,O0o),e(q,V0o),e(q,F8),e(F8,ece),e(ece,X0o),e(F8,z0o),e(F8,nD),e(nD,Q0o),e(F8,W0o),e(q,H0o),e(q,T8),e(T8,oce),e(oce,U0o),e(T8,J0o),e(T8,sD),e(sD,Y0o),e(T8,K0o),e(q,Z0o),e(q,M8),e(M8,rce),e(rce,eyo),e(M8,oyo),e(M8,lD),e(lD,ryo),e(M8,tyo),e(q,ayo),e(q,E8),e(E8,tce),e(tce,nyo),e(E8,syo),e(E8,iD),e(iD,lyo),e(E8,iyo),e(q,dyo),e(q,C8),e(C8,ace),e(ace,cyo),e(C8,fyo),e(C8,dD),e(dD,myo),e(C8,gyo),e(q,hyo),e(q,w8),e(w8,nce),e(nce,pyo),e(w8,uyo),e(w8,cD),e(cD,_yo),e(w8,byo),e(q,vyo),e(q,A8),e(A8,sce),e(sce,Fyo),e(A8,Tyo),e(A8,fD),e(fD,Myo),e(A8,Eyo),e(q,Cyo),e(q,y8),e(y8,lce),e(lce,wyo),e(y8,Ayo),e(y8,mD),e(mD,yyo),e(y8,Lyo),e(q,xyo),e(q,L8),e(L8,ice),e(ice,$yo),e(L8,kyo),e(L8,gD),e(gD,Syo),e(L8,Ryo),e(q,Byo),e(q,x8),e(x8,dce),e(dce,Pyo),e(x8,Iyo),e(x8,hD),e(hD,qyo),e(x8,Nyo),e(q,jyo),e(q,$8),e($8,cce),e(cce,Dyo),e($8,Gyo),e($8,pD),e(pD,Oyo),e($8,Vyo),e(q,Xyo),e(q,k8),e(k8,fce),e(fce,zyo),e(k8,Qyo),e(k8,uD),e(uD,Wyo),e(k8,Hyo),e(q,Uyo),e(q,S8),e(S8,mce),e(mce,Jyo),e(S8,Yyo),e(S8,_D),e(_D,Kyo),e(S8,Zyo),e(q,eLo),e(q,R8),e(R8,gce),e(gce,oLo),e(R8,rLo),e(R8,bD),e(bD,tLo),e(R8,aLo),e(q,nLo),e(q,B8),e(B8,hce),e(hce,sLo),e(B8,lLo),e(B8,vD),e(vD,iLo),e(B8,dLo),e(q,cLo),e(q,P8),e(P8,pce),e(pce,fLo),e(P8,mLo),e(P8,FD),e(FD,gLo),e(P8,hLo),e(q,pLo),e(q,I8),e(I8,uce),e(uce,uLo),e(I8,_Lo),e(I8,TD),e(TD,bLo),e(I8,vLo),e(q,FLo),e(q,q8),e(q8,_ce),e(_ce,TLo),e(q8,MLo),e(q8,MD),e(MD,ELo),e(q8,CLo),e(q,wLo),e(q,N8),e(N8,bce),e(bce,ALo),e(N8,yLo),e(N8,ED),e(ED,LLo),e(N8,xLo),e(q,$Lo),e(q,j8),e(j8,vce),e(vce,kLo),e(j8,SLo),e(j8,CD),e(CD,RLo),e(j8,BLo),e(q,PLo),e(q,D8),e(D8,Fce),e(Fce,ILo),e(D8,qLo),e(D8,wD),e(wD,NLo),e(D8,jLo),e(q,DLo),e(q,G8),e(G8,Tce),e(Tce,GLo),e(G8,OLo),e(G8,AD),e(AD,VLo),e(G8,XLo),e(q,zLo),e(q,O8),e(O8,Mce),e(Mce,QLo),e(O8,WLo),e(O8,yD),e(yD,HLo),e(O8,ULo),e(q,JLo),e(q,V8),e(V8,Ece),e(Ece,YLo),e(V8,KLo),e(V8,LD),e(LD,ZLo),e(V8,exo),e(q,oxo),e(q,X8),e(X8,Cce),e(Cce,rxo),e(X8,txo),e(X8,xD),e(xD,axo),e(X8,nxo),e(q,sxo),e(q,z8),e(z8,wce),e(wce,lxo),e(z8,ixo),e(z8,$D),e($D,dxo),e(z8,cxo),e(q,fxo),e(q,Q8),e(Q8,Ace),e(Ace,mxo),e(Q8,gxo),e(Q8,kD),e(kD,hxo),e(Q8,pxo),e(q,uxo),e(q,W8),e(W8,yce),e(yce,_xo),e(W8,bxo),e(W8,SD),e(SD,vxo),e(W8,Fxo),e(q,Txo),e(q,H8),e(H8,Lce),e(Lce,Mxo),e(H8,Exo),e(H8,RD),e(RD,Cxo),e(H8,wxo),e(q,Axo),e(q,U8),e(U8,xce),e(xce,yxo),e(U8,Lxo),e(U8,BD),e(BD,xxo),e(U8,$xo),e(q,kxo),e(q,J8),e(J8,$ce),e($ce,Sxo),e(J8,Rxo),e(J8,PD),e(PD,Bxo),e(J8,Pxo),e(q,Ixo),e(q,Y8),e(Y8,kce),e(kce,qxo),e(Y8,Nxo),e(Y8,ID),e(ID,jxo),e(Y8,Dxo),e(q,Gxo),e(q,K8),e(K8,Sce),e(Sce,Oxo),e(K8,Vxo),e(K8,qD),e(qD,Xxo),e(K8,zxo),e(q,Qxo),e(q,Z8),e(Z8,Rce),e(Rce,Wxo),e(Z8,Hxo),e(Z8,ND),e(ND,Uxo),e(Z8,Jxo),e(q,Yxo),e(q,eb),e(eb,Bce),e(Bce,Kxo),e(eb,Zxo),e(eb,jD),e(jD,e7o),e(eb,o7o),e(q,r7o),e(q,ob),e(ob,Pce),e(Pce,t7o),e(ob,a7o),e(ob,DD),e(DD,n7o),e(ob,s7o),e(q,l7o),e(q,rb),e(rb,Ice),e(Ice,i7o),e(rb,d7o),e(rb,GD),e(GD,c7o),e(rb,f7o),e(q,m7o),e(q,tb),e(tb,qce),e(qce,g7o),e(tb,h7o),e(tb,OD),e(OD,p7o),e(tb,u7o),e(q,_7o),e(q,ab),e(ab,Nce),e(Nce,b7o),e(ab,v7o),e(ab,VD),e(VD,F7o),e(ab,T7o),e(Ze,M7o),e(Ze,nb),e(nb,E7o),e(nb,jce),e(jce,C7o),e(nb,w7o),e(nb,Dce),e(Dce,A7o),e(Ze,y7o),M(sb,Ze,null),b(f,DPe,_),b(f,Di,_),e(Di,lb),e(lb,Gce),M(WA,Gce,null),e(Di,L7o),e(Di,Oce),e(Oce,x7o),b(f,GPe,_),b(f,Bo,_),M(HA,Bo,null),e(Bo,$7o),e(Bo,Gi),e(Gi,k7o),e(Gi,XD),e(XD,S7o),e(Gi,R7o),e(Gi,zD),e(zD,B7o),e(Gi,P7o),e(Bo,I7o),e(Bo,UA),e(UA,q7o),e(UA,Vce),e(Vce,N7o),e(UA,j7o),e(Bo,D7o),e(Bo,lt),M(JA,lt,null),e(lt,G7o),e(lt,Xce),e(Xce,O7o),e(lt,V7o),e(lt,Oi),e(Oi,X7o),e(Oi,zce),e(zce,z7o),e(Oi,Q7o),e(Oi,QD),e(QD,W7o),e(Oi,H7o),e(lt,U7o),M(ib,lt,null),e(Bo,J7o),e(Bo,eo),M(YA,eo,null),e(eo,Y7o),e(eo,Qce),e(Qce,K7o),e(eo,Z7o),e(eo,Sa),e(Sa,e$o),e(Sa,Wce),e(Wce,o$o),e(Sa,r$o),e(Sa,Hce),e(Hce,t$o),e(Sa,a$o),e(Sa,Uce),e(Uce,n$o),e(Sa,s$o),e(eo,l$o),e(eo,Y),e(Y,db),e(db,Jce),e(Jce,i$o),e(db,d$o),e(db,WD),e(WD,c$o),e(db,f$o),e(Y,m$o),e(Y,cb),e(cb,Yce),e(Yce,g$o),e(cb,h$o),e(cb,HD),e(HD,p$o),e(cb,u$o),e(Y,_$o),e(Y,fb),e(fb,Kce),e(Kce,b$o),e(fb,v$o),e(fb,UD),e(UD,F$o),e(fb,T$o),e(Y,M$o),e(Y,mb),e(mb,Zce),e(Zce,E$o),e(mb,C$o),e(mb,JD),e(JD,w$o),e(mb,A$o),e(Y,y$o),e(Y,gb),e(gb,efe),e(efe,L$o),e(gb,x$o),e(gb,YD),e(YD,$$o),e(gb,k$o),e(Y,S$o),e(Y,hb),e(hb,ofe),e(ofe,R$o),e(hb,B$o),e(hb,KD),e(KD,P$o),e(hb,I$o),e(Y,q$o),e(Y,pb),e(pb,rfe),e(rfe,N$o),e(pb,j$o),e(pb,ZD),e(ZD,D$o),e(pb,G$o),e(Y,O$o),e(Y,ub),e(ub,tfe),e(tfe,V$o),e(ub,X$o),e(ub,eG),e(eG,z$o),e(ub,Q$o),e(Y,W$o),e(Y,_b),e(_b,afe),e(afe,H$o),e(_b,U$o),e(_b,oG),e(oG,J$o),e(_b,Y$o),e(Y,K$o),e(Y,bb),e(bb,nfe),e(nfe,Z$o),e(bb,eko),e(bb,rG),e(rG,oko),e(bb,rko),e(Y,tko),e(Y,vb),e(vb,sfe),e(sfe,ako),e(vb,nko),e(vb,tG),e(tG,sko),e(vb,lko),e(Y,iko),e(Y,Fb),e(Fb,lfe),e(lfe,dko),e(Fb,cko),e(Fb,aG),e(aG,fko),e(Fb,mko),e(Y,gko),e(Y,Tb),e(Tb,ife),e(ife,hko),e(Tb,pko),e(Tb,nG),e(nG,uko),e(Tb,_ko),e(Y,bko),e(Y,Mb),e(Mb,dfe),e(dfe,vko),e(Mb,Fko),e(Mb,sG),e(sG,Tko),e(Mb,Mko),e(Y,Eko),e(Y,Eb),e(Eb,cfe),e(cfe,Cko),e(Eb,wko),e(Eb,lG),e(lG,Ako),e(Eb,yko),e(Y,Lko),e(Y,Cb),e(Cb,ffe),e(ffe,xko),e(Cb,$ko),e(Cb,iG),e(iG,kko),e(Cb,Sko),e(Y,Rko),e(Y,wb),e(wb,mfe),e(mfe,Bko),e(wb,Pko),e(wb,dG),e(dG,Iko),e(wb,qko),e(Y,Nko),e(Y,Ab),e(Ab,gfe),e(gfe,jko),e(Ab,Dko),e(Ab,cG),e(cG,Gko),e(Ab,Oko),e(Y,Vko),e(Y,yb),e(yb,hfe),e(hfe,Xko),e(yb,zko),e(yb,fG),e(fG,Qko),e(yb,Wko),e(Y,Hko),e(Y,Lb),e(Lb,pfe),e(pfe,Uko),e(Lb,Jko),e(Lb,mG),e(mG,Yko),e(Lb,Kko),e(Y,Zko),e(Y,xb),e(xb,ufe),e(ufe,eSo),e(xb,oSo),e(xb,gG),e(gG,rSo),e(xb,tSo),e(Y,aSo),e(Y,$b),e($b,_fe),e(_fe,nSo),e($b,sSo),e($b,hG),e(hG,lSo),e($b,iSo),e(Y,dSo),e(Y,kb),e(kb,bfe),e(bfe,cSo),e(kb,fSo),e(kb,pG),e(pG,mSo),e(kb,gSo),e(Y,hSo),e(Y,Sb),e(Sb,vfe),e(vfe,pSo),e(Sb,uSo),e(Sb,uG),e(uG,_So),e(Sb,bSo),e(Y,vSo),e(Y,Rb),e(Rb,Ffe),e(Ffe,FSo),e(Rb,TSo),e(Rb,_G),e(_G,MSo),e(Rb,ESo),e(Y,CSo),e(Y,Bb),e(Bb,Tfe),e(Tfe,wSo),e(Bb,ASo),e(Bb,bG),e(bG,ySo),e(Bb,LSo),e(Y,xSo),e(Y,Pb),e(Pb,Mfe),e(Mfe,$So),e(Pb,kSo),e(Pb,vG),e(vG,SSo),e(Pb,RSo),e(Y,BSo),e(Y,Ib),e(Ib,Efe),e(Efe,PSo),e(Ib,ISo),e(Ib,FG),e(FG,qSo),e(Ib,NSo),e(Y,jSo),e(Y,qb),e(qb,Cfe),e(Cfe,DSo),e(qb,GSo),e(qb,TG),e(TG,OSo),e(qb,VSo),e(eo,XSo),e(eo,Nb),e(Nb,zSo),e(Nb,wfe),e(wfe,QSo),e(Nb,WSo),e(Nb,Afe),e(Afe,HSo),e(eo,USo),M(jb,eo,null),b(f,OPe,_),b(f,Vi,_),e(Vi,Db),e(Db,yfe),M(KA,yfe,null),e(Vi,JSo),e(Vi,Lfe),e(Lfe,YSo),b(f,VPe,_),b(f,Po,_),M(ZA,Po,null),e(Po,KSo),e(Po,Xi),e(Xi,ZSo),e(Xi,MG),e(MG,eRo),e(Xi,oRo),e(Xi,EG),e(EG,rRo),e(Xi,tRo),e(Po,aRo),e(Po,e0),e(e0,nRo),e(e0,xfe),e(xfe,sRo),e(e0,lRo),e(Po,iRo),e(Po,it),M(o0,it,null),e(it,dRo),e(it,$fe),e($fe,cRo),e(it,fRo),e(it,zi),e(zi,mRo),e(zi,kfe),e(kfe,gRo),e(zi,hRo),e(zi,CG),e(CG,pRo),e(zi,uRo),e(it,_Ro),M(Gb,it,null),e(Po,bRo),e(Po,oo),M(r0,oo,null),e(oo,vRo),e(oo,Sfe),e(Sfe,FRo),e(oo,TRo),e(oo,Ra),e(Ra,MRo),e(Ra,Rfe),e(Rfe,ERo),e(Ra,CRo),e(Ra,Bfe),e(Bfe,wRo),e(Ra,ARo),e(Ra,Pfe),e(Pfe,yRo),e(Ra,LRo),e(oo,xRo),e(oo,Yr),e(Yr,Ob),e(Ob,Ife),e(Ife,$Ro),e(Ob,kRo),e(Ob,wG),e(wG,SRo),e(Ob,RRo),e(Yr,BRo),e(Yr,Vb),e(Vb,qfe),e(qfe,PRo),e(Vb,IRo),e(Vb,AG),e(AG,qRo),e(Vb,NRo),e(Yr,jRo),e(Yr,Xb),e(Xb,Nfe),e(Nfe,DRo),e(Xb,GRo),e(Xb,yG),e(yG,ORo),e(Xb,VRo),e(Yr,XRo),e(Yr,zb),e(zb,jfe),e(jfe,zRo),e(zb,QRo),e(zb,LG),e(LG,WRo),e(zb,HRo),e(Yr,URo),e(Yr,Qb),e(Qb,Dfe),e(Dfe,JRo),e(Qb,YRo),e(Qb,xG),e(xG,KRo),e(Qb,ZRo),e(oo,eBo),e(oo,Wb),e(Wb,oBo),e(Wb,Gfe),e(Gfe,rBo),e(Wb,tBo),e(Wb,Ofe),e(Ofe,aBo),e(oo,nBo),M(Hb,oo,null),b(f,XPe,_),b(f,Qi,_),e(Qi,Ub),e(Ub,Vfe),M(t0,Vfe,null),e(Qi,sBo),e(Qi,Xfe),e(Xfe,lBo),b(f,zPe,_),b(f,Io,_),M(a0,Io,null),e(Io,iBo),e(Io,Wi),e(Wi,dBo),e(Wi,$G),e($G,cBo),e(Wi,fBo),e(Wi,kG),e(kG,mBo),e(Wi,gBo),e(Io,hBo),e(Io,n0),e(n0,pBo),e(n0,zfe),e(zfe,uBo),e(n0,_Bo),e(Io,bBo),e(Io,dt),M(s0,dt,null),e(dt,vBo),e(dt,Qfe),e(Qfe,FBo),e(dt,TBo),e(dt,Hi),e(Hi,MBo),e(Hi,Wfe),e(Wfe,EBo),e(Hi,CBo),e(Hi,SG),e(SG,wBo),e(Hi,ABo),e(dt,yBo),M(Jb,dt,null),e(Io,LBo),e(Io,ro),M(l0,ro,null),e(ro,xBo),e(ro,Hfe),e(Hfe,$Bo),e(ro,kBo),e(ro,Ba),e(Ba,SBo),e(Ba,Ufe),e(Ufe,RBo),e(Ba,BBo),e(Ba,Jfe),e(Jfe,PBo),e(Ba,IBo),e(Ba,Yfe),e(Yfe,qBo),e(Ba,NBo),e(ro,jBo),e(ro,U),e(U,Yb),e(Yb,Kfe),e(Kfe,DBo),e(Yb,GBo),e(Yb,RG),e(RG,OBo),e(Yb,VBo),e(U,XBo),e(U,Kb),e(Kb,Zfe),e(Zfe,zBo),e(Kb,QBo),e(Kb,BG),e(BG,WBo),e(Kb,HBo),e(U,UBo),e(U,Zb),e(Zb,eme),e(eme,JBo),e(Zb,YBo),e(Zb,PG),e(PG,KBo),e(Zb,ZBo),e(U,ePo),e(U,e2),e(e2,ome),e(ome,oPo),e(e2,rPo),e(e2,IG),e(IG,tPo),e(e2,aPo),e(U,nPo),e(U,o2),e(o2,rme),e(rme,sPo),e(o2,lPo),e(o2,qG),e(qG,iPo),e(o2,dPo),e(U,cPo),e(U,r2),e(r2,tme),e(tme,fPo),e(r2,mPo),e(r2,NG),e(NG,gPo),e(r2,hPo),e(U,pPo),e(U,t2),e(t2,ame),e(ame,uPo),e(t2,_Po),e(t2,jG),e(jG,bPo),e(t2,vPo),e(U,FPo),e(U,a2),e(a2,nme),e(nme,TPo),e(a2,MPo),e(a2,DG),e(DG,EPo),e(a2,CPo),e(U,wPo),e(U,n2),e(n2,sme),e(sme,APo),e(n2,yPo),e(n2,GG),e(GG,LPo),e(n2,xPo),e(U,$Po),e(U,s2),e(s2,lme),e(lme,kPo),e(s2,SPo),e(s2,OG),e(OG,RPo),e(s2,BPo),e(U,PPo),e(U,l2),e(l2,ime),e(ime,IPo),e(l2,qPo),e(l2,VG),e(VG,NPo),e(l2,jPo),e(U,DPo),e(U,i2),e(i2,dme),e(dme,GPo),e(i2,OPo),e(i2,XG),e(XG,VPo),e(i2,XPo),e(U,zPo),e(U,d2),e(d2,cme),e(cme,QPo),e(d2,WPo),e(d2,zG),e(zG,HPo),e(d2,UPo),e(U,JPo),e(U,c2),e(c2,fme),e(fme,YPo),e(c2,KPo),e(c2,QG),e(QG,ZPo),e(c2,eIo),e(U,oIo),e(U,f2),e(f2,mme),e(mme,rIo),e(f2,tIo),e(f2,WG),e(WG,aIo),e(f2,nIo),e(U,sIo),e(U,m2),e(m2,gme),e(gme,lIo),e(m2,iIo),e(m2,HG),e(HG,dIo),e(m2,cIo),e(U,fIo),e(U,g2),e(g2,hme),e(hme,mIo),e(g2,gIo),e(g2,UG),e(UG,hIo),e(g2,pIo),e(U,uIo),e(U,h2),e(h2,pme),e(pme,_Io),e(h2,bIo),e(h2,JG),e(JG,vIo),e(h2,FIo),e(U,TIo),e(U,p2),e(p2,ume),e(ume,MIo),e(p2,EIo),e(p2,YG),e(YG,CIo),e(p2,wIo),e(U,AIo),e(U,u2),e(u2,_me),e(_me,yIo),e(u2,LIo),e(u2,KG),e(KG,xIo),e(u2,$Io),e(U,kIo),e(U,_2),e(_2,bme),e(bme,SIo),e(_2,RIo),e(_2,ZG),e(ZG,BIo),e(_2,PIo),e(U,IIo),e(U,b2),e(b2,vme),e(vme,qIo),e(b2,NIo),e(b2,eO),e(eO,jIo),e(b2,DIo),e(U,GIo),e(U,v2),e(v2,Fme),e(Fme,OIo),e(v2,VIo),e(v2,oO),e(oO,XIo),e(v2,zIo),e(U,QIo),e(U,F2),e(F2,Tme),e(Tme,WIo),e(F2,HIo),e(F2,rO),e(rO,UIo),e(F2,JIo),e(U,YIo),e(U,T2),e(T2,Mme),e(Mme,KIo),e(T2,ZIo),e(T2,tO),e(tO,eqo),e(T2,oqo),e(U,rqo),e(U,M2),e(M2,Eme),e(Eme,tqo),e(M2,aqo),e(M2,aO),e(aO,nqo),e(M2,sqo),e(U,lqo),e(U,E2),e(E2,Cme),e(Cme,iqo),e(E2,dqo),e(E2,nO),e(nO,cqo),e(E2,fqo),e(U,mqo),e(U,C2),e(C2,wme),e(wme,gqo),e(C2,hqo),e(C2,sO),e(sO,pqo),e(C2,uqo),e(U,_qo),e(U,w2),e(w2,Ame),e(Ame,bqo),e(w2,vqo),e(w2,lO),e(lO,Fqo),e(w2,Tqo),e(U,Mqo),e(U,A2),e(A2,yme),e(yme,Eqo),e(A2,Cqo),e(A2,iO),e(iO,wqo),e(A2,Aqo),e(U,yqo),e(U,y2),e(y2,Lme),e(Lme,Lqo),e(y2,xqo),e(y2,dO),e(dO,$qo),e(y2,kqo),e(U,Sqo),e(U,L2),e(L2,xme),e(xme,Rqo),e(L2,Bqo),e(L2,cO),e(cO,Pqo),e(L2,Iqo),e(U,qqo),e(U,x2),e(x2,$me),e($me,Nqo),e(x2,jqo),e(x2,fO),e(fO,Dqo),e(x2,Gqo),e(ro,Oqo),e(ro,$2),e($2,Vqo),e($2,kme),e(kme,Xqo),e($2,zqo),e($2,Sme),e(Sme,Qqo),e(ro,Wqo),M(k2,ro,null),b(f,QPe,_),b(f,Ui,_),e(Ui,S2),e(S2,Rme),M(i0,Rme,null),e(Ui,Hqo),e(Ui,Bme),e(Bme,Uqo),b(f,WPe,_),b(f,qo,_),M(d0,qo,null),e(qo,Jqo),e(qo,Ji),e(Ji,Yqo),e(Ji,mO),e(mO,Kqo),e(Ji,Zqo),e(Ji,gO),e(gO,eNo),e(Ji,oNo),e(qo,rNo),e(qo,c0),e(c0,tNo),e(c0,Pme),e(Pme,aNo),e(c0,nNo),e(qo,sNo),e(qo,ct),M(f0,ct,null),e(ct,lNo),e(ct,Ime),e(Ime,iNo),e(ct,dNo),e(ct,Yi),e(Yi,cNo),e(Yi,qme),e(qme,fNo),e(Yi,mNo),e(Yi,hO),e(hO,gNo),e(Yi,hNo),e(ct,pNo),M(R2,ct,null),e(qo,uNo),e(qo,to),M(m0,to,null),e(to,_No),e(to,Nme),e(Nme,bNo),e(to,vNo),e(to,Pa),e(Pa,FNo),e(Pa,jme),e(jme,TNo),e(Pa,MNo),e(Pa,Dme),e(Dme,ENo),e(Pa,CNo),e(Pa,Gme),e(Gme,wNo),e(Pa,ANo),e(to,yNo),e(to,O),e(O,B2),e(B2,Ome),e(Ome,LNo),e(B2,xNo),e(B2,pO),e(pO,$No),e(B2,kNo),e(O,SNo),e(O,P2),e(P2,Vme),e(Vme,RNo),e(P2,BNo),e(P2,uO),e(uO,PNo),e(P2,INo),e(O,qNo),e(O,I2),e(I2,Xme),e(Xme,NNo),e(I2,jNo),e(I2,_O),e(_O,DNo),e(I2,GNo),e(O,ONo),e(O,q2),e(q2,zme),e(zme,VNo),e(q2,XNo),e(q2,bO),e(bO,zNo),e(q2,QNo),e(O,WNo),e(O,N2),e(N2,Qme),e(Qme,HNo),e(N2,UNo),e(N2,vO),e(vO,JNo),e(N2,YNo),e(O,KNo),e(O,j2),e(j2,Wme),e(Wme,ZNo),e(j2,ejo),e(j2,FO),e(FO,ojo),e(j2,rjo),e(O,tjo),e(O,D2),e(D2,Hme),e(Hme,ajo),e(D2,njo),e(D2,TO),e(TO,sjo),e(D2,ljo),e(O,ijo),e(O,G2),e(G2,Ume),e(Ume,djo),e(G2,cjo),e(G2,MO),e(MO,fjo),e(G2,mjo),e(O,gjo),e(O,O2),e(O2,Jme),e(Jme,hjo),e(O2,pjo),e(O2,EO),e(EO,ujo),e(O2,_jo),e(O,bjo),e(O,V2),e(V2,Yme),e(Yme,vjo),e(V2,Fjo),e(V2,CO),e(CO,Tjo),e(V2,Mjo),e(O,Ejo),e(O,X2),e(X2,Kme),e(Kme,Cjo),e(X2,wjo),e(X2,wO),e(wO,Ajo),e(X2,yjo),e(O,Ljo),e(O,z2),e(z2,Zme),e(Zme,xjo),e(z2,$jo),e(z2,AO),e(AO,kjo),e(z2,Sjo),e(O,Rjo),e(O,Q2),e(Q2,ege),e(ege,Bjo),e(Q2,Pjo),e(Q2,yO),e(yO,Ijo),e(Q2,qjo),e(O,Njo),e(O,W2),e(W2,oge),e(oge,jjo),e(W2,Djo),e(W2,LO),e(LO,Gjo),e(W2,Ojo),e(O,Vjo),e(O,H2),e(H2,rge),e(rge,Xjo),e(H2,zjo),e(H2,xO),e(xO,Qjo),e(H2,Wjo),e(O,Hjo),e(O,U2),e(U2,tge),e(tge,Ujo),e(U2,Jjo),e(U2,$O),e($O,Yjo),e(U2,Kjo),e(O,Zjo),e(O,J2),e(J2,age),e(age,eDo),e(J2,oDo),e(J2,kO),e(kO,rDo),e(J2,tDo),e(O,aDo),e(O,Y2),e(Y2,nge),e(nge,nDo),e(Y2,sDo),e(Y2,SO),e(SO,lDo),e(Y2,iDo),e(O,dDo),e(O,K2),e(K2,sge),e(sge,cDo),e(K2,fDo),e(K2,RO),e(RO,mDo),e(K2,gDo),e(O,hDo),e(O,Z2),e(Z2,lge),e(lge,pDo),e(Z2,uDo),e(Z2,BO),e(BO,_Do),e(Z2,bDo),e(O,vDo),e(O,ev),e(ev,ige),e(ige,FDo),e(ev,TDo),e(ev,PO),e(PO,MDo),e(ev,EDo),e(O,CDo),e(O,ov),e(ov,dge),e(dge,wDo),e(ov,ADo),e(ov,IO),e(IO,yDo),e(ov,LDo),e(O,xDo),e(O,rv),e(rv,cge),e(cge,$Do),e(rv,kDo),e(rv,qO),e(qO,SDo),e(rv,RDo),e(O,BDo),e(O,tv),e(tv,fge),e(fge,PDo),e(tv,IDo),e(tv,NO),e(NO,qDo),e(tv,NDo),e(O,jDo),e(O,av),e(av,mge),e(mge,DDo),e(av,GDo),e(av,jO),e(jO,ODo),e(av,VDo),e(O,XDo),e(O,nv),e(nv,gge),e(gge,zDo),e(nv,QDo),e(nv,DO),e(DO,WDo),e(nv,HDo),e(O,UDo),e(O,sv),e(sv,hge),e(hge,JDo),e(sv,YDo),e(sv,GO),e(GO,KDo),e(sv,ZDo),e(O,eGo),e(O,lv),e(lv,pge),e(pge,oGo),e(lv,rGo),e(lv,OO),e(OO,tGo),e(lv,aGo),e(O,nGo),e(O,iv),e(iv,uge),e(uge,sGo),e(iv,lGo),e(iv,VO),e(VO,iGo),e(iv,dGo),e(O,cGo),e(O,dv),e(dv,_ge),e(_ge,fGo),e(dv,mGo),e(dv,XO),e(XO,gGo),e(dv,hGo),e(O,pGo),e(O,cv),e(cv,bge),e(bge,uGo),e(cv,_Go),e(cv,zO),e(zO,bGo),e(cv,vGo),e(O,FGo),e(O,fv),e(fv,vge),e(vge,TGo),e(fv,MGo),e(fv,QO),e(QO,EGo),e(fv,CGo),e(O,wGo),e(O,mv),e(mv,Fge),e(Fge,AGo),e(mv,yGo),e(mv,WO),e(WO,LGo),e(mv,xGo),e(O,$Go),e(O,gv),e(gv,Tge),e(Tge,kGo),e(gv,SGo),e(gv,HO),e(HO,RGo),e(gv,BGo),e(O,PGo),e(O,hv),e(hv,Mge),e(Mge,IGo),e(hv,qGo),e(hv,UO),e(UO,NGo),e(hv,jGo),e(O,DGo),e(O,pv),e(pv,Ege),e(Ege,GGo),e(pv,OGo),e(pv,JO),e(JO,VGo),e(pv,XGo),e(O,zGo),e(O,uv),e(uv,Cge),e(Cge,QGo),e(uv,WGo),e(uv,YO),e(YO,HGo),e(uv,UGo),e(O,JGo),e(O,_v),e(_v,wge),e(wge,YGo),e(_v,KGo),e(_v,KO),e(KO,ZGo),e(_v,eOo),e(O,oOo),e(O,bv),e(bv,Age),e(Age,rOo),e(bv,tOo),e(bv,ZO),e(ZO,aOo),e(bv,nOo),e(to,sOo),e(to,vv),e(vv,lOo),e(vv,yge),e(yge,iOo),e(vv,dOo),e(vv,Lge),e(Lge,cOo),e(to,fOo),M(Fv,to,null),b(f,HPe,_),b(f,Ki,_),e(Ki,Tv),e(Tv,xge),M(g0,xge,null),e(Ki,mOo),e(Ki,$ge),e($ge,gOo),b(f,UPe,_),b(f,No,_),M(h0,No,null),e(No,hOo),e(No,Zi),e(Zi,pOo),e(Zi,eV),e(eV,uOo),e(Zi,_Oo),e(Zi,oV),e(oV,bOo),e(Zi,vOo),e(No,FOo),e(No,p0),e(p0,TOo),e(p0,kge),e(kge,MOo),e(p0,EOo),e(No,COo),e(No,ft),M(u0,ft,null),e(ft,wOo),e(ft,Sge),e(Sge,AOo),e(ft,yOo),e(ft,ed),e(ed,LOo),e(ed,Rge),e(Rge,xOo),e(ed,$Oo),e(ed,rV),e(rV,kOo),e(ed,SOo),e(ft,ROo),M(Mv,ft,null),e(No,BOo),e(No,ao),M(_0,ao,null),e(ao,POo),e(ao,Bge),e(Bge,IOo),e(ao,qOo),e(ao,Ia),e(Ia,NOo),e(Ia,Pge),e(Pge,jOo),e(Ia,DOo),e(Ia,Ige),e(Ige,GOo),e(Ia,OOo),e(Ia,qge),e(qge,VOo),e(Ia,XOo),e(ao,zOo),e(ao,Nge),e(Nge,Ev),e(Ev,jge),e(jge,QOo),e(Ev,WOo),e(Ev,tV),e(tV,HOo),e(Ev,UOo),e(ao,JOo),e(ao,Cv),e(Cv,YOo),e(Cv,Dge),e(Dge,KOo),e(Cv,ZOo),e(Cv,Gge),e(Gge,eVo),e(ao,oVo),M(wv,ao,null),b(f,JPe,_),b(f,od,_),e(od,Av),e(Av,Oge),M(b0,Oge,null),e(od,rVo),e(od,Vge),e(Vge,tVo),b(f,YPe,_),b(f,jo,_),M(v0,jo,null),e(jo,aVo),e(jo,rd),e(rd,nVo),e(rd,aV),e(aV,sVo),e(rd,lVo),e(rd,nV),e(nV,iVo),e(rd,dVo),e(jo,cVo),e(jo,F0),e(F0,fVo),e(F0,Xge),e(Xge,mVo),e(F0,gVo),e(jo,hVo),e(jo,mt),M(T0,mt,null),e(mt,pVo),e(mt,zge),e(zge,uVo),e(mt,_Vo),e(mt,td),e(td,bVo),e(td,Qge),e(Qge,vVo),e(td,FVo),e(td,sV),e(sV,TVo),e(td,MVo),e(mt,EVo),M(yv,mt,null),e(jo,CVo),e(jo,no),M(M0,no,null),e(no,wVo),e(no,Wge),e(Wge,AVo),e(no,yVo),e(no,qa),e(qa,LVo),e(qa,Hge),e(Hge,xVo),e(qa,$Vo),e(qa,Uge),e(Uge,kVo),e(qa,SVo),e(qa,Jge),e(Jge,RVo),e(qa,BVo),e(no,PVo),e(no,ve),e(ve,Lv),e(Lv,Yge),e(Yge,IVo),e(Lv,qVo),e(Lv,lV),e(lV,NVo),e(Lv,jVo),e(ve,DVo),e(ve,xv),e(xv,Kge),e(Kge,GVo),e(xv,OVo),e(xv,iV),e(iV,VVo),e(xv,XVo),e(ve,zVo),e(ve,$v),e($v,Zge),e(Zge,QVo),e($v,WVo),e($v,dV),e(dV,HVo),e($v,UVo),e(ve,JVo),e(ve,Bs),e(Bs,ehe),e(ehe,YVo),e(Bs,KVo),e(Bs,cV),e(cV,ZVo),e(Bs,eXo),e(Bs,fV),e(fV,oXo),e(Bs,rXo),e(ve,tXo),e(ve,kv),e(kv,ohe),e(ohe,aXo),e(kv,nXo),e(kv,mV),e(mV,sXo),e(kv,lXo),e(ve,iXo),e(ve,gt),e(gt,rhe),e(rhe,dXo),e(gt,cXo),e(gt,gV),e(gV,fXo),e(gt,mXo),e(gt,hV),e(hV,gXo),e(gt,hXo),e(gt,pV),e(pV,pXo),e(gt,uXo),e(ve,_Xo),e(ve,Sv),e(Sv,the),e(the,bXo),e(Sv,vXo),e(Sv,uV),e(uV,FXo),e(Sv,TXo),e(ve,MXo),e(ve,Rv),e(Rv,ahe),e(ahe,EXo),e(Rv,CXo),e(Rv,_V),e(_V,wXo),e(Rv,AXo),e(ve,yXo),e(ve,Bv),e(Bv,nhe),e(nhe,LXo),e(Bv,xXo),e(Bv,bV),e(bV,$Xo),e(Bv,kXo),e(ve,SXo),e(ve,Pv),e(Pv,she),e(she,RXo),e(Pv,BXo),e(Pv,vV),e(vV,PXo),e(Pv,IXo),e(ve,qXo),e(ve,Iv),e(Iv,lhe),e(lhe,NXo),e(Iv,jXo),e(Iv,FV),e(FV,DXo),e(Iv,GXo),e(ve,OXo),e(ve,qv),e(qv,ihe),e(ihe,VXo),e(qv,XXo),e(qv,TV),e(TV,zXo),e(qv,QXo),e(ve,WXo),e(ve,Nv),e(Nv,dhe),e(dhe,HXo),e(Nv,UXo),e(Nv,MV),e(MV,JXo),e(Nv,YXo),e(no,KXo),e(no,jv),e(jv,ZXo),e(jv,che),e(che,ezo),e(jv,ozo),e(jv,fhe),e(fhe,rzo),e(no,tzo),M(Dv,no,null),b(f,KPe,_),b(f,ad,_),e(ad,Gv),e(Gv,mhe),M(E0,mhe,null),e(ad,azo),e(ad,ghe),e(ghe,nzo),b(f,ZPe,_),b(f,Do,_),M(C0,Do,null),e(Do,szo),e(Do,nd),e(nd,lzo),e(nd,EV),e(EV,izo),e(nd,dzo),e(nd,CV),e(CV,czo),e(nd,fzo),e(Do,mzo),e(Do,w0),e(w0,gzo),e(w0,hhe),e(hhe,hzo),e(w0,pzo),e(Do,uzo),e(Do,ht),M(A0,ht,null),e(ht,_zo),e(ht,phe),e(phe,bzo),e(ht,vzo),e(ht,sd),e(sd,Fzo),e(sd,uhe),e(uhe,Tzo),e(sd,Mzo),e(sd,wV),e(wV,Ezo),e(sd,Czo),e(ht,wzo),M(Ov,ht,null),e(Do,Azo),e(Do,so),M(y0,so,null),e(so,yzo),e(so,_he),e(_he,Lzo),e(so,xzo),e(so,Na),e(Na,$zo),e(Na,bhe),e(bhe,kzo),e(Na,Szo),e(Na,vhe),e(vhe,Rzo),e(Na,Bzo),e(Na,Fhe),e(Fhe,Pzo),e(Na,Izo),e(so,qzo),e(so,The),e(The,Vv),e(Vv,Mhe),e(Mhe,Nzo),e(Vv,jzo),e(Vv,AV),e(AV,Dzo),e(Vv,Gzo),e(so,Ozo),e(so,Xv),e(Xv,Vzo),e(Xv,Ehe),e(Ehe,Xzo),e(Xv,zzo),e(Xv,Che),e(Che,Qzo),e(so,Wzo),M(zv,so,null),b(f,eIe,_),b(f,ld,_),e(ld,Qv),e(Qv,whe),M(L0,whe,null),e(ld,Hzo),e(ld,Ahe),e(Ahe,Uzo),b(f,oIe,_),b(f,Go,_),M(x0,Go,null),e(Go,Jzo),e(Go,id),e(id,Yzo),e(id,yV),e(yV,Kzo),e(id,Zzo),e(id,LV),e(LV,eQo),e(id,oQo),e(Go,rQo),e(Go,$0),e($0,tQo),e($0,yhe),e(yhe,aQo),e($0,nQo),e(Go,sQo),e(Go,pt),M(k0,pt,null),e(pt,lQo),e(pt,Lhe),e(Lhe,iQo),e(pt,dQo),e(pt,dd),e(dd,cQo),e(dd,xhe),e(xhe,fQo),e(dd,mQo),e(dd,xV),e(xV,gQo),e(dd,hQo),e(pt,pQo),M(Wv,pt,null),e(Go,uQo),e(Go,lo),M(S0,lo,null),e(lo,_Qo),e(lo,$he),e($he,bQo),e(lo,vQo),e(lo,ja),e(ja,FQo),e(ja,khe),e(khe,TQo),e(ja,MQo),e(ja,She),e(She,EQo),e(ja,CQo),e(ja,Rhe),e(Rhe,wQo),e(ja,AQo),e(lo,yQo),e(lo,Ne),e(Ne,Hv),e(Hv,Bhe),e(Bhe,LQo),e(Hv,xQo),e(Hv,$V),e($V,$Qo),e(Hv,kQo),e(Ne,SQo),e(Ne,Uv),e(Uv,Phe),e(Phe,RQo),e(Uv,BQo),e(Uv,kV),e(kV,PQo),e(Uv,IQo),e(Ne,qQo),e(Ne,Jv),e(Jv,Ihe),e(Ihe,NQo),e(Jv,jQo),e(Jv,SV),e(SV,DQo),e(Jv,GQo),e(Ne,OQo),e(Ne,Yv),e(Yv,qhe),e(qhe,VQo),e(Yv,XQo),e(Yv,RV),e(RV,zQo),e(Yv,QQo),e(Ne,WQo),e(Ne,Kv),e(Kv,Nhe),e(Nhe,HQo),e(Kv,UQo),e(Kv,BV),e(BV,JQo),e(Kv,YQo),e(Ne,KQo),e(Ne,Zv),e(Zv,jhe),e(jhe,ZQo),e(Zv,eWo),e(Zv,PV),e(PV,oWo),e(Zv,rWo),e(Ne,tWo),e(Ne,eF),e(eF,Dhe),e(Dhe,aWo),e(eF,nWo),e(eF,IV),e(IV,sWo),e(eF,lWo),e(Ne,iWo),e(Ne,oF),e(oF,Ghe),e(Ghe,dWo),e(oF,cWo),e(oF,qV),e(qV,fWo),e(oF,mWo),e(lo,gWo),e(lo,rF),e(rF,hWo),e(rF,Ohe),e(Ohe,pWo),e(rF,uWo),e(rF,Vhe),e(Vhe,_Wo),e(lo,bWo),M(tF,lo,null),b(f,rIe,_),b(f,cd,_),e(cd,aF),e(aF,Xhe),M(R0,Xhe,null),e(cd,vWo),e(cd,zhe),e(zhe,FWo),b(f,tIe,_),b(f,Oo,_),M(B0,Oo,null),e(Oo,TWo),e(Oo,fd),e(fd,MWo),e(fd,NV),e(NV,EWo),e(fd,CWo),e(fd,jV),e(jV,wWo),e(fd,AWo),e(Oo,yWo),e(Oo,P0),e(P0,LWo),e(P0,Qhe),e(Qhe,xWo),e(P0,$Wo),e(Oo,kWo),e(Oo,ut),M(I0,ut,null),e(ut,SWo),e(ut,Whe),e(Whe,RWo),e(ut,BWo),e(ut,md),e(md,PWo),e(md,Hhe),e(Hhe,IWo),e(md,qWo),e(md,DV),e(DV,NWo),e(md,jWo),e(ut,DWo),M(nF,ut,null),e(Oo,GWo),e(Oo,io),M(q0,io,null),e(io,OWo),e(io,Uhe),e(Uhe,VWo),e(io,XWo),e(io,Da),e(Da,zWo),e(Da,Jhe),e(Jhe,QWo),e(Da,WWo),e(Da,Yhe),e(Yhe,HWo),e(Da,UWo),e(Da,Khe),e(Khe,JWo),e(Da,YWo),e(io,KWo),e(io,Ga),e(Ga,sF),e(sF,Zhe),e(Zhe,ZWo),e(sF,eHo),e(sF,GV),e(GV,oHo),e(sF,rHo),e(Ga,tHo),e(Ga,lF),e(lF,epe),e(epe,aHo),e(lF,nHo),e(lF,OV),e(OV,sHo),e(lF,lHo),e(Ga,iHo),e(Ga,iF),e(iF,ope),e(ope,dHo),e(iF,cHo),e(iF,VV),e(VV,fHo),e(iF,mHo),e(Ga,gHo),e(Ga,dF),e(dF,rpe),e(rpe,hHo),e(dF,pHo),e(dF,XV),e(XV,uHo),e(dF,_Ho),e(io,bHo),e(io,cF),e(cF,vHo),e(cF,tpe),e(tpe,FHo),e(cF,THo),e(cF,ape),e(ape,MHo),e(io,EHo),M(fF,io,null),b(f,aIe,_),b(f,gd,_),e(gd,mF),e(mF,npe),M(N0,npe,null),e(gd,CHo),e(gd,spe),e(spe,wHo),b(f,nIe,_),b(f,Vo,_),M(j0,Vo,null),e(Vo,AHo),e(Vo,hd),e(hd,yHo),e(hd,zV),e(zV,LHo),e(hd,xHo),e(hd,QV),e(QV,$Ho),e(hd,kHo),e(Vo,SHo),e(Vo,D0),e(D0,RHo),e(D0,lpe),e(lpe,BHo),e(D0,PHo),e(Vo,IHo),e(Vo,_t),M(G0,_t,null),e(_t,qHo),e(_t,ipe),e(ipe,NHo),e(_t,jHo),e(_t,pd),e(pd,DHo),e(pd,dpe),e(dpe,GHo),e(pd,OHo),e(pd,WV),e(WV,VHo),e(pd,XHo),e(_t,zHo),M(gF,_t,null),e(Vo,QHo),e(Vo,co),M(O0,co,null),e(co,WHo),e(co,cpe),e(cpe,HHo),e(co,UHo),e(co,Oa),e(Oa,JHo),e(Oa,fpe),e(fpe,YHo),e(Oa,KHo),e(Oa,mpe),e(mpe,ZHo),e(Oa,eUo),e(Oa,gpe),e(gpe,oUo),e(Oa,rUo),e(co,tUo),e(co,je),e(je,hF),e(hF,hpe),e(hpe,aUo),e(hF,nUo),e(hF,HV),e(HV,sUo),e(hF,lUo),e(je,iUo),e(je,pF),e(pF,ppe),e(ppe,dUo),e(pF,cUo),e(pF,UV),e(UV,fUo),e(pF,mUo),e(je,gUo),e(je,uF),e(uF,upe),e(upe,hUo),e(uF,pUo),e(uF,JV),e(JV,uUo),e(uF,_Uo),e(je,bUo),e(je,_F),e(_F,_pe),e(_pe,vUo),e(_F,FUo),e(_F,YV),e(YV,TUo),e(_F,MUo),e(je,EUo),e(je,bF),e(bF,bpe),e(bpe,CUo),e(bF,wUo),e(bF,KV),e(KV,AUo),e(bF,yUo),e(je,LUo),e(je,vF),e(vF,vpe),e(vpe,xUo),e(vF,$Uo),e(vF,ZV),e(ZV,kUo),e(vF,SUo),e(je,RUo),e(je,FF),e(FF,Fpe),e(Fpe,BUo),e(FF,PUo),e(FF,eX),e(eX,IUo),e(FF,qUo),e(je,NUo),e(je,TF),e(TF,Tpe),e(Tpe,jUo),e(TF,DUo),e(TF,oX),e(oX,GUo),e(TF,OUo),e(co,VUo),e(co,MF),e(MF,XUo),e(MF,Mpe),e(Mpe,zUo),e(MF,QUo),e(MF,Epe),e(Epe,WUo),e(co,HUo),M(EF,co,null),b(f,sIe,_),b(f,ud,_),e(ud,CF),e(CF,Cpe),M(V0,Cpe,null),e(ud,UUo),e(ud,wpe),e(wpe,JUo),b(f,lIe,_),b(f,Xo,_),M(X0,Xo,null),e(Xo,YUo),e(Xo,_d),e(_d,KUo),e(_d,rX),e(rX,ZUo),e(_d,eJo),e(_d,tX),e(tX,oJo),e(_d,rJo),e(Xo,tJo),e(Xo,z0),e(z0,aJo),e(z0,Ape),e(Ape,nJo),e(z0,sJo),e(Xo,lJo),e(Xo,bt),M(Q0,bt,null),e(bt,iJo),e(bt,ype),e(ype,dJo),e(bt,cJo),e(bt,bd),e(bd,fJo),e(bd,Lpe),e(Lpe,mJo),e(bd,gJo),e(bd,aX),e(aX,hJo),e(bd,pJo),e(bt,uJo),M(wF,bt,null),e(Xo,_Jo),e(Xo,fo),M(W0,fo,null),e(fo,bJo),e(fo,xpe),e(xpe,vJo),e(fo,FJo),e(fo,Va),e(Va,TJo),e(Va,$pe),e($pe,MJo),e(Va,EJo),e(Va,kpe),e(kpe,CJo),e(Va,wJo),e(Va,Spe),e(Spe,AJo),e(Va,yJo),e(fo,LJo),e(fo,H0),e(H0,AF),e(AF,Rpe),e(Rpe,xJo),e(AF,$Jo),e(AF,nX),e(nX,kJo),e(AF,SJo),e(H0,RJo),e(H0,yF),e(yF,Bpe),e(Bpe,BJo),e(yF,PJo),e(yF,sX),e(sX,IJo),e(yF,qJo),e(fo,NJo),e(fo,LF),e(LF,jJo),e(LF,Ppe),e(Ppe,DJo),e(LF,GJo),e(LF,Ipe),e(Ipe,OJo),e(fo,VJo),M(xF,fo,null),b(f,iIe,_),b(f,vd,_),e(vd,$F),e($F,qpe),M(U0,qpe,null),e(vd,XJo),e(vd,Npe),e(Npe,zJo),b(f,dIe,_),b(f,zo,_),M(J0,zo,null),e(zo,QJo),e(zo,Fd),e(Fd,WJo),e(Fd,lX),e(lX,HJo),e(Fd,UJo),e(Fd,iX),e(iX,JJo),e(Fd,YJo),e(zo,KJo),e(zo,Y0),e(Y0,ZJo),e(Y0,jpe),e(jpe,eYo),e(Y0,oYo),e(zo,rYo),e(zo,vt),M(K0,vt,null),e(vt,tYo),e(vt,Dpe),e(Dpe,aYo),e(vt,nYo),e(vt,Td),e(Td,sYo),e(Td,Gpe),e(Gpe,lYo),e(Td,iYo),e(Td,dX),e(dX,dYo),e(Td,cYo),e(vt,fYo),M(kF,vt,null),e(zo,mYo),e(zo,mo),M(Z0,mo,null),e(mo,gYo),e(mo,Ope),e(Ope,hYo),e(mo,pYo),e(mo,Xa),e(Xa,uYo),e(Xa,Vpe),e(Vpe,_Yo),e(Xa,bYo),e(Xa,Xpe),e(Xpe,vYo),e(Xa,FYo),e(Xa,zpe),e(zpe,TYo),e(Xa,MYo),e(mo,EYo),e(mo,za),e(za,SF),e(SF,Qpe),e(Qpe,CYo),e(SF,wYo),e(SF,cX),e(cX,AYo),e(SF,yYo),e(za,LYo),e(za,RF),e(RF,Wpe),e(Wpe,xYo),e(RF,$Yo),e(RF,fX),e(fX,kYo),e(RF,SYo),e(za,RYo),e(za,BF),e(BF,Hpe),e(Hpe,BYo),e(BF,PYo),e(BF,mX),e(mX,IYo),e(BF,qYo),e(za,NYo),e(za,PF),e(PF,Upe),e(Upe,jYo),e(PF,DYo),e(PF,gX),e(gX,GYo),e(PF,OYo),e(mo,VYo),e(mo,IF),e(IF,XYo),e(IF,Jpe),e(Jpe,zYo),e(IF,QYo),e(IF,Ype),e(Ype,WYo),e(mo,HYo),M(qF,mo,null),b(f,cIe,_),b(f,Md,_),e(Md,NF),e(NF,Kpe),M(ey,Kpe,null),e(Md,UYo),e(Md,Zpe),e(Zpe,JYo),b(f,fIe,_),b(f,Qo,_),M(oy,Qo,null),e(Qo,YYo),e(Qo,Ed),e(Ed,KYo),e(Ed,hX),e(hX,ZYo),e(Ed,eKo),e(Ed,pX),e(pX,oKo),e(Ed,rKo),e(Qo,tKo),e(Qo,ry),e(ry,aKo),e(ry,eue),e(eue,nKo),e(ry,sKo),e(Qo,lKo),e(Qo,Ft),M(ty,Ft,null),e(Ft,iKo),e(Ft,oue),e(oue,dKo),e(Ft,cKo),e(Ft,Cd),e(Cd,fKo),e(Cd,rue),e(rue,mKo),e(Cd,gKo),e(Cd,uX),e(uX,hKo),e(Cd,pKo),e(Ft,uKo),M(jF,Ft,null),e(Qo,_Ko),e(Qo,go),M(ay,go,null),e(go,bKo),e(go,tue),e(tue,vKo),e(go,FKo),e(go,Qa),e(Qa,TKo),e(Qa,aue),e(aue,MKo),e(Qa,EKo),e(Qa,nue),e(nue,CKo),e(Qa,wKo),e(Qa,sue),e(sue,AKo),e(Qa,yKo),e(go,LKo),e(go,wd),e(wd,DF),e(DF,lue),e(lue,xKo),e(DF,$Ko),e(DF,_X),e(_X,kKo),e(DF,SKo),e(wd,RKo),e(wd,GF),e(GF,iue),e(iue,BKo),e(GF,PKo),e(GF,bX),e(bX,IKo),e(GF,qKo),e(wd,NKo),e(wd,OF),e(OF,due),e(due,jKo),e(OF,DKo),e(OF,vX),e(vX,GKo),e(OF,OKo),e(go,VKo),e(go,VF),e(VF,XKo),e(VF,cue),e(cue,zKo),e(VF,QKo),e(VF,fue),e(fue,WKo),e(go,HKo),M(XF,go,null),b(f,mIe,_),b(f,Ad,_),e(Ad,zF),e(zF,mue),M(ny,mue,null),e(Ad,UKo),e(Ad,gue),e(gue,JKo),b(f,gIe,_),b(f,Wo,_),M(sy,Wo,null),e(Wo,YKo),e(Wo,yd),e(yd,KKo),e(yd,FX),e(FX,ZKo),e(yd,eZo),e(yd,TX),e(TX,oZo),e(yd,rZo),e(Wo,tZo),e(Wo,ly),e(ly,aZo),e(ly,hue),e(hue,nZo),e(ly,sZo),e(Wo,lZo),e(Wo,Tt),M(iy,Tt,null),e(Tt,iZo),e(Tt,pue),e(pue,dZo),e(Tt,cZo),e(Tt,Ld),e(Ld,fZo),e(Ld,uue),e(uue,mZo),e(Ld,gZo),e(Ld,MX),e(MX,hZo),e(Ld,pZo),e(Tt,uZo),M(QF,Tt,null),e(Wo,_Zo),e(Wo,ho),M(dy,ho,null),e(ho,bZo),e(ho,_ue),e(_ue,vZo),e(ho,FZo),e(ho,Wa),e(Wa,TZo),e(Wa,bue),e(bue,MZo),e(Wa,EZo),e(Wa,vue),e(vue,CZo),e(Wa,wZo),e(Wa,Fue),e(Fue,AZo),e(Wa,yZo),e(ho,LZo),e(ho,cy),e(cy,WF),e(WF,Tue),e(Tue,xZo),e(WF,$Zo),e(WF,EX),e(EX,kZo),e(WF,SZo),e(cy,RZo),e(cy,HF),e(HF,Mue),e(Mue,BZo),e(HF,PZo),e(HF,CX),e(CX,IZo),e(HF,qZo),e(ho,NZo),e(ho,UF),e(UF,jZo),e(UF,Eue),e(Eue,DZo),e(UF,GZo),e(UF,Cue),e(Cue,OZo),e(ho,VZo),M(JF,ho,null),b(f,hIe,_),b(f,xd,_),e(xd,YF),e(YF,wue),M(fy,wue,null),e(xd,XZo),e(xd,Aue),e(Aue,zZo),b(f,pIe,_),b(f,Ho,_),M(my,Ho,null),e(Ho,QZo),e(Ho,$d),e($d,WZo),e($d,wX),e(wX,HZo),e($d,UZo),e($d,AX),e(AX,JZo),e($d,YZo),e(Ho,KZo),e(Ho,gy),e(gy,ZZo),e(gy,yue),e(yue,eer),e(gy,oer),e(Ho,rer),e(Ho,Mt),M(hy,Mt,null),e(Mt,ter),e(Mt,Lue),e(Lue,aer),e(Mt,ner),e(Mt,kd),e(kd,ser),e(kd,xue),e(xue,ler),e(kd,ier),e(kd,yX),e(yX,der),e(kd,cer),e(Mt,fer),M(KF,Mt,null),e(Ho,mer),e(Ho,po),M(py,po,null),e(po,ger),e(po,$ue),e($ue,her),e(po,per),e(po,Ha),e(Ha,uer),e(Ha,kue),e(kue,_er),e(Ha,ber),e(Ha,Sue),e(Sue,ver),e(Ha,Fer),e(Ha,Rue),e(Rue,Ter),e(Ha,Mer),e(po,Eer),e(po,Bue),e(Bue,ZF),e(ZF,Pue),e(Pue,Cer),e(ZF,wer),e(ZF,LX),e(LX,Aer),e(ZF,yer),e(po,Ler),e(po,e6),e(e6,xer),e(e6,Iue),e(Iue,$er),e(e6,ker),e(e6,que),e(que,Ser),e(po,Rer),M(o6,po,null),b(f,uIe,_),b(f,Sd,_),e(Sd,r6),e(r6,Nue),M(uy,Nue,null),e(Sd,Ber),e(Sd,jue),e(jue,Per),b(f,_Ie,_),b(f,Uo,_),M(_y,Uo,null),e(Uo,Ier),e(Uo,Rd),e(Rd,qer),e(Rd,xX),e(xX,Ner),e(Rd,jer),e(Rd,$X),e($X,Der),e(Rd,Ger),e(Uo,Oer),e(Uo,by),e(by,Ver),e(by,Due),e(Due,Xer),e(by,zer),e(Uo,Qer),e(Uo,Et),M(vy,Et,null),e(Et,Wer),e(Et,Gue),e(Gue,Her),e(Et,Uer),e(Et,Bd),e(Bd,Jer),e(Bd,Oue),e(Oue,Yer),e(Bd,Ker),e(Bd,kX),e(kX,Zer),e(Bd,eor),e(Et,oor),M(t6,Et,null),e(Uo,ror),e(Uo,uo),M(Fy,uo,null),e(uo,tor),e(uo,Vue),e(Vue,aor),e(uo,nor),e(uo,Ua),e(Ua,sor),e(Ua,Xue),e(Xue,lor),e(Ua,ior),e(Ua,zue),e(zue,dor),e(Ua,cor),e(Ua,Que),e(Que,mor),e(Ua,gor),e(uo,hor),e(uo,Ja),e(Ja,a6),e(a6,Wue),e(Wue,por),e(a6,uor),e(a6,SX),e(SX,_or),e(a6,bor),e(Ja,vor),e(Ja,n6),e(n6,Hue),e(Hue,For),e(n6,Tor),e(n6,RX),e(RX,Mor),e(n6,Eor),e(Ja,Cor),e(Ja,s6),e(s6,Uue),e(Uue,wor),e(s6,Aor),e(s6,BX),e(BX,yor),e(s6,Lor),e(Ja,xor),e(Ja,l6),e(l6,Jue),e(Jue,$or),e(l6,kor),e(l6,PX),e(PX,Sor),e(l6,Ror),e(uo,Bor),e(uo,i6),e(i6,Por),e(i6,Yue),e(Yue,Ior),e(i6,qor),e(i6,Kue),e(Kue,Nor),e(uo,jor),M(d6,uo,null),b(f,bIe,_),b(f,Pd,_),e(Pd,c6),e(c6,Zue),M(Ty,Zue,null),e(Pd,Dor),e(Pd,e_e),e(e_e,Gor),b(f,vIe,_),b(f,Jo,_),M(My,Jo,null),e(Jo,Oor),e(Jo,Id),e(Id,Vor),e(Id,IX),e(IX,Xor),e(Id,zor),e(Id,qX),e(qX,Qor),e(Id,Wor),e(Jo,Hor),e(Jo,Ey),e(Ey,Uor),e(Ey,o_e),e(o_e,Jor),e(Ey,Yor),e(Jo,Kor),e(Jo,Ct),M(Cy,Ct,null),e(Ct,Zor),e(Ct,r_e),e(r_e,err),e(Ct,orr),e(Ct,qd),e(qd,rrr),e(qd,t_e),e(t_e,trr),e(qd,arr),e(qd,NX),e(NX,nrr),e(qd,srr),e(Ct,lrr),M(f6,Ct,null),e(Jo,irr),e(Jo,_o),M(wy,_o,null),e(_o,drr),e(_o,a_e),e(a_e,crr),e(_o,frr),e(_o,Ya),e(Ya,mrr),e(Ya,n_e),e(n_e,grr),e(Ya,hrr),e(Ya,s_e),e(s_e,prr),e(Ya,urr),e(Ya,l_e),e(l_e,_rr),e(Ya,brr),e(_o,vrr),e(_o,i_e),e(i_e,m6),e(m6,d_e),e(d_e,Frr),e(m6,Trr),e(m6,jX),e(jX,Mrr),e(m6,Err),e(_o,Crr),e(_o,g6),e(g6,wrr),e(g6,c_e),e(c_e,Arr),e(g6,yrr),e(g6,f_e),e(f_e,Lrr),e(_o,xrr),M(h6,_o,null),b(f,FIe,_),b(f,Nd,_),e(Nd,p6),e(p6,m_e),M(Ay,m_e,null),e(Nd,$rr),e(Nd,g_e),e(g_e,krr),b(f,TIe,_),b(f,Yo,_),M(yy,Yo,null),e(Yo,Srr),e(Yo,jd),e(jd,Rrr),e(jd,DX),e(DX,Brr),e(jd,Prr),e(jd,GX),e(GX,Irr),e(jd,qrr),e(Yo,Nrr),e(Yo,Ly),e(Ly,jrr),e(Ly,h_e),e(h_e,Drr),e(Ly,Grr),e(Yo,Orr),e(Yo,wt),M(xy,wt,null),e(wt,Vrr),e(wt,p_e),e(p_e,Xrr),e(wt,zrr),e(wt,Dd),e(Dd,Qrr),e(Dd,u_e),e(u_e,Wrr),e(Dd,Hrr),e(Dd,OX),e(OX,Urr),e(Dd,Jrr),e(wt,Yrr),M(u6,wt,null),e(Yo,Krr),e(Yo,wr),M($y,wr,null),e(wr,Zrr),e(wr,__e),e(__e,etr),e(wr,otr),e(wr,Ka),e(Ka,rtr),e(Ka,b_e),e(b_e,ttr),e(Ka,atr),e(Ka,v_e),e(v_e,ntr),e(Ka,str),e(Ka,F_e),e(F_e,ltr),e(Ka,itr),e(wr,dtr),e(wr,N),e(N,_6),e(_6,T_e),e(T_e,ctr),e(_6,ftr),e(_6,VX),e(VX,mtr),e(_6,gtr),e(N,htr),e(N,b6),e(b6,M_e),e(M_e,ptr),e(b6,utr),e(b6,XX),e(XX,_tr),e(b6,btr),e(N,vtr),e(N,v6),e(v6,E_e),e(E_e,Ftr),e(v6,Ttr),e(v6,zX),e(zX,Mtr),e(v6,Etr),e(N,Ctr),e(N,F6),e(F6,C_e),e(C_e,wtr),e(F6,Atr),e(F6,QX),e(QX,ytr),e(F6,Ltr),e(N,xtr),e(N,T6),e(T6,w_e),e(w_e,$tr),e(T6,ktr),e(T6,WX),e(WX,Str),e(T6,Rtr),e(N,Btr),e(N,M6),e(M6,A_e),e(A_e,Ptr),e(M6,Itr),e(M6,HX),e(HX,qtr),e(M6,Ntr),e(N,jtr),e(N,E6),e(E6,y_e),e(y_e,Dtr),e(E6,Gtr),e(E6,UX),e(UX,Otr),e(E6,Vtr),e(N,Xtr),e(N,C6),e(C6,L_e),e(L_e,ztr),e(C6,Qtr),e(C6,JX),e(JX,Wtr),e(C6,Htr),e(N,Utr),e(N,w6),e(w6,x_e),e(x_e,Jtr),e(w6,Ytr),e(w6,YX),e(YX,Ktr),e(w6,Ztr),e(N,ear),e(N,A6),e(A6,$_e),e($_e,oar),e(A6,rar),e(A6,KX),e(KX,tar),e(A6,aar),e(N,nar),e(N,y6),e(y6,k_e),e(k_e,sar),e(y6,lar),e(y6,ZX),e(ZX,iar),e(y6,dar),e(N,car),e(N,L6),e(L6,S_e),e(S_e,far),e(L6,mar),e(L6,ez),e(ez,gar),e(L6,har),e(N,par),e(N,x6),e(x6,R_e),e(R_e,uar),e(x6,_ar),e(x6,oz),e(oz,bar),e(x6,Far),e(N,Tar),e(N,$6),e($6,B_e),e(B_e,Mar),e($6,Ear),e($6,rz),e(rz,Car),e($6,war),e(N,Aar),e(N,k6),e(k6,P_e),e(P_e,yar),e(k6,Lar),e(k6,tz),e(tz,xar),e(k6,$ar),e(N,kar),e(N,S6),e(S6,I_e),e(I_e,Sar),e(S6,Rar),e(S6,az),e(az,Bar),e(S6,Par),e(N,Iar),e(N,R6),e(R6,q_e),e(q_e,qar),e(R6,Nar),e(R6,nz),e(nz,jar),e(R6,Dar),e(N,Gar),e(N,Ps),e(Ps,N_e),e(N_e,Oar),e(Ps,Var),e(Ps,sz),e(sz,Xar),e(Ps,zar),e(Ps,lz),e(lz,Qar),e(Ps,War),e(N,Har),e(N,B6),e(B6,j_e),e(j_e,Uar),e(B6,Jar),e(B6,iz),e(iz,Yar),e(B6,Kar),e(N,Zar),e(N,P6),e(P6,D_e),e(D_e,enr),e(P6,onr),e(P6,dz),e(dz,rnr),e(P6,tnr),e(N,anr),e(N,I6),e(I6,G_e),e(G_e,nnr),e(I6,snr),e(I6,cz),e(cz,lnr),e(I6,inr),e(N,dnr),e(N,q6),e(q6,O_e),e(O_e,cnr),e(q6,fnr),e(q6,fz),e(fz,mnr),e(q6,gnr),e(N,hnr),e(N,N6),e(N6,V_e),e(V_e,pnr),e(N6,unr),e(N6,mz),e(mz,_nr),e(N6,bnr),e(N,vnr),e(N,j6),e(j6,X_e),e(X_e,Fnr),e(j6,Tnr),e(j6,gz),e(gz,Mnr),e(j6,Enr),e(N,Cnr),e(N,D6),e(D6,z_e),e(z_e,wnr),e(D6,Anr),e(D6,hz),e(hz,ynr),e(D6,Lnr),e(N,xnr),e(N,G6),e(G6,Q_e),e(Q_e,$nr),e(G6,knr),e(G6,pz),e(pz,Snr),e(G6,Rnr),e(N,Bnr),e(N,O6),e(O6,W_e),e(W_e,Pnr),e(O6,Inr),e(O6,uz),e(uz,qnr),e(O6,Nnr),e(N,jnr),e(N,V6),e(V6,H_e),e(H_e,Dnr),e(V6,Gnr),e(V6,_z),e(_z,Onr),e(V6,Vnr),e(N,Xnr),e(N,X6),e(X6,U_e),e(U_e,znr),e(X6,Qnr),e(X6,bz),e(bz,Wnr),e(X6,Hnr),e(N,Unr),e(N,z6),e(z6,J_e),e(J_e,Jnr),e(z6,Ynr),e(z6,vz),e(vz,Knr),e(z6,Znr),e(N,esr),e(N,Q6),e(Q6,Y_e),e(Y_e,osr),e(Q6,rsr),e(Q6,Fz),e(Fz,tsr),e(Q6,asr),e(N,nsr),e(N,W6),e(W6,K_e),e(K_e,ssr),e(W6,lsr),e(W6,Tz),e(Tz,isr),e(W6,dsr),e(N,csr),e(N,H6),e(H6,Z_e),e(Z_e,fsr),e(H6,msr),e(H6,Mz),e(Mz,gsr),e(H6,hsr),e(N,psr),e(N,U6),e(U6,e1e),e(e1e,usr),e(U6,_sr),e(U6,Ez),e(Ez,bsr),e(U6,vsr),e(N,Fsr),e(N,J6),e(J6,o1e),e(o1e,Tsr),e(J6,Msr),e(J6,Cz),e(Cz,Esr),e(J6,Csr),e(N,wsr),e(N,Y6),e(Y6,r1e),e(r1e,Asr),e(Y6,ysr),e(Y6,wz),e(wz,Lsr),e(Y6,xsr),e(N,$sr),e(N,K6),e(K6,t1e),e(t1e,ksr),e(K6,Ssr),e(K6,Az),e(Az,Rsr),e(K6,Bsr),e(N,Psr),e(N,Z6),e(Z6,a1e),e(a1e,Isr),e(Z6,qsr),e(Z6,yz),e(yz,Nsr),e(Z6,jsr),e(N,Dsr),e(N,eT),e(eT,n1e),e(n1e,Gsr),e(eT,Osr),e(eT,Lz),e(Lz,Vsr),e(eT,Xsr),e(N,zsr),e(N,oT),e(oT,s1e),e(s1e,Qsr),e(oT,Wsr),e(oT,xz),e(xz,Hsr),e(oT,Usr),e(N,Jsr),e(N,rT),e(rT,l1e),e(l1e,Ysr),e(rT,Ksr),e(rT,$z),e($z,Zsr),e(rT,elr),e(N,olr),e(N,tT),e(tT,i1e),e(i1e,rlr),e(tT,tlr),e(tT,kz),e(kz,alr),e(tT,nlr),e(N,slr),e(N,aT),e(aT,d1e),e(d1e,llr),e(aT,ilr),e(aT,Sz),e(Sz,dlr),e(aT,clr),e(N,flr),e(N,nT),e(nT,c1e),e(c1e,mlr),e(nT,glr),e(nT,Rz),e(Rz,hlr),e(nT,plr),e(N,ulr),e(N,sT),e(sT,f1e),e(f1e,_lr),e(sT,blr),e(sT,Bz),e(Bz,vlr),e(sT,Flr),e(N,Tlr),e(N,lT),e(lT,m1e),e(m1e,Mlr),e(lT,Elr),e(lT,Pz),e(Pz,Clr),e(lT,wlr),e(wr,Alr),M(iT,wr,null),b(f,MIe,_),b(f,Gd,_),e(Gd,dT),e(dT,g1e),M(ky,g1e,null),e(Gd,ylr),e(Gd,h1e),e(h1e,Llr),b(f,EIe,_),b(f,Ko,_),M(Sy,Ko,null),e(Ko,xlr),e(Ko,Od),e(Od,$lr),e(Od,Iz),e(Iz,klr),e(Od,Slr),e(Od,qz),e(qz,Rlr),e(Od,Blr),e(Ko,Plr),e(Ko,Ry),e(Ry,Ilr),e(Ry,p1e),e(p1e,qlr),e(Ry,Nlr),e(Ko,jlr),e(Ko,At),M(By,At,null),e(At,Dlr),e(At,u1e),e(u1e,Glr),e(At,Olr),e(At,Vd),e(Vd,Vlr),e(Vd,_1e),e(_1e,Xlr),e(Vd,zlr),e(Vd,Nz),e(Nz,Qlr),e(Vd,Wlr),e(At,Hlr),M(cT,At,null),e(Ko,Ulr),e(Ko,Ar),M(Py,Ar,null),e(Ar,Jlr),e(Ar,b1e),e(b1e,Ylr),e(Ar,Klr),e(Ar,Za),e(Za,Zlr),e(Za,v1e),e(v1e,eir),e(Za,oir),e(Za,F1e),e(F1e,rir),e(Za,tir),e(Za,T1e),e(T1e,air),e(Za,nir),e(Ar,sir),e(Ar,ne),e(ne,fT),e(fT,M1e),e(M1e,lir),e(fT,iir),e(fT,jz),e(jz,dir),e(fT,cir),e(ne,fir),e(ne,mT),e(mT,E1e),e(E1e,mir),e(mT,gir),e(mT,Dz),e(Dz,hir),e(mT,pir),e(ne,uir),e(ne,gT),e(gT,C1e),e(C1e,_ir),e(gT,bir),e(gT,Gz),e(Gz,vir),e(gT,Fir),e(ne,Tir),e(ne,hT),e(hT,w1e),e(w1e,Mir),e(hT,Eir),e(hT,Oz),e(Oz,Cir),e(hT,wir),e(ne,Air),e(ne,pT),e(pT,A1e),e(A1e,yir),e(pT,Lir),e(pT,Vz),e(Vz,xir),e(pT,$ir),e(ne,kir),e(ne,uT),e(uT,y1e),e(y1e,Sir),e(uT,Rir),e(uT,Xz),e(Xz,Bir),e(uT,Pir),e(ne,Iir),e(ne,_T),e(_T,L1e),e(L1e,qir),e(_T,Nir),e(_T,zz),e(zz,jir),e(_T,Dir),e(ne,Gir),e(ne,bT),e(bT,x1e),e(x1e,Oir),e(bT,Vir),e(bT,Qz),e(Qz,Xir),e(bT,zir),e(ne,Qir),e(ne,vT),e(vT,$1e),e($1e,Wir),e(vT,Hir),e(vT,Wz),e(Wz,Uir),e(vT,Jir),e(ne,Yir),e(ne,FT),e(FT,k1e),e(k1e,Kir),e(FT,Zir),e(FT,Hz),e(Hz,edr),e(FT,odr),e(ne,rdr),e(ne,TT),e(TT,S1e),e(S1e,tdr),e(TT,adr),e(TT,Uz),e(Uz,ndr),e(TT,sdr),e(ne,ldr),e(ne,MT),e(MT,R1e),e(R1e,idr),e(MT,ddr),e(MT,Jz),e(Jz,cdr),e(MT,fdr),e(ne,mdr),e(ne,ET),e(ET,B1e),e(B1e,gdr),e(ET,hdr),e(ET,Yz),e(Yz,pdr),e(ET,udr),e(ne,_dr),e(ne,CT),e(CT,P1e),e(P1e,bdr),e(CT,vdr),e(CT,Kz),e(Kz,Fdr),e(CT,Tdr),e(ne,Mdr),e(ne,wT),e(wT,I1e),e(I1e,Edr),e(wT,Cdr),e(wT,Zz),e(Zz,wdr),e(wT,Adr),e(ne,ydr),e(ne,AT),e(AT,q1e),e(q1e,Ldr),e(AT,xdr),e(AT,eQ),e(eQ,$dr),e(AT,kdr),e(ne,Sdr),e(ne,yT),e(yT,N1e),e(N1e,Rdr),e(yT,Bdr),e(yT,oQ),e(oQ,Pdr),e(yT,Idr),e(ne,qdr),e(ne,LT),e(LT,j1e),e(j1e,Ndr),e(LT,jdr),e(LT,rQ),e(rQ,Ddr),e(LT,Gdr),e(ne,Odr),e(ne,xT),e(xT,D1e),e(D1e,Vdr),e(xT,Xdr),e(xT,tQ),e(tQ,zdr),e(xT,Qdr),e(ne,Wdr),e(ne,$T),e($T,G1e),e(G1e,Hdr),e($T,Udr),e($T,aQ),e(aQ,Jdr),e($T,Ydr),e(ne,Kdr),e(ne,kT),e(kT,O1e),e(O1e,Zdr),e(kT,ecr),e(kT,nQ),e(nQ,ocr),e(kT,rcr),e(ne,tcr),e(ne,ST),e(ST,V1e),e(V1e,acr),e(ST,ncr),e(ST,sQ),e(sQ,scr),e(ST,lcr),e(ne,icr),e(ne,RT),e(RT,X1e),e(X1e,dcr),e(RT,ccr),e(RT,lQ),e(lQ,fcr),e(RT,mcr),e(Ar,gcr),M(BT,Ar,null),b(f,CIe,_),b(f,Xd,_),e(Xd,PT),e(PT,z1e),M(Iy,z1e,null),e(Xd,hcr),e(Xd,Q1e),e(Q1e,pcr),b(f,wIe,_),b(f,Zo,_),M(qy,Zo,null),e(Zo,ucr),e(Zo,zd),e(zd,_cr),e(zd,iQ),e(iQ,bcr),e(zd,vcr),e(zd,dQ),e(dQ,Fcr),e(zd,Tcr),e(Zo,Mcr),e(Zo,Ny),e(Ny,Ecr),e(Ny,W1e),e(W1e,Ccr),e(Ny,wcr),e(Zo,Acr),e(Zo,yt),M(jy,yt,null),e(yt,ycr),e(yt,H1e),e(H1e,Lcr),e(yt,xcr),e(yt,Qd),e(Qd,$cr),e(Qd,U1e),e(U1e,kcr),e(Qd,Scr),e(Qd,cQ),e(cQ,Rcr),e(Qd,Bcr),e(yt,Pcr),M(IT,yt,null),e(Zo,Icr),e(Zo,yr),M(Dy,yr,null),e(yr,qcr),e(yr,J1e),e(J1e,Ncr),e(yr,jcr),e(yr,en),e(en,Dcr),e(en,Y1e),e(Y1e,Gcr),e(en,Ocr),e(en,K1e),e(K1e,Vcr),e(en,Xcr),e(en,Z1e),e(Z1e,zcr),e(en,Qcr),e(yr,Wcr),e(yr,Te),e(Te,qT),e(qT,e8e),e(e8e,Hcr),e(qT,Ucr),e(qT,fQ),e(fQ,Jcr),e(qT,Ycr),e(Te,Kcr),e(Te,NT),e(NT,o8e),e(o8e,Zcr),e(NT,efr),e(NT,mQ),e(mQ,ofr),e(NT,rfr),e(Te,tfr),e(Te,jT),e(jT,r8e),e(r8e,afr),e(jT,nfr),e(jT,gQ),e(gQ,sfr),e(jT,lfr),e(Te,ifr),e(Te,DT),e(DT,t8e),e(t8e,dfr),e(DT,cfr),e(DT,hQ),e(hQ,ffr),e(DT,mfr),e(Te,gfr),e(Te,GT),e(GT,a8e),e(a8e,hfr),e(GT,pfr),e(GT,pQ),e(pQ,ufr),e(GT,_fr),e(Te,bfr),e(Te,OT),e(OT,n8e),e(n8e,vfr),e(OT,Ffr),e(OT,uQ),e(uQ,Tfr),e(OT,Mfr),e(Te,Efr),e(Te,VT),e(VT,s8e),e(s8e,Cfr),e(VT,wfr),e(VT,_Q),e(_Q,Afr),e(VT,yfr),e(Te,Lfr),e(Te,XT),e(XT,l8e),e(l8e,xfr),e(XT,$fr),e(XT,bQ),e(bQ,kfr),e(XT,Sfr),e(Te,Rfr),e(Te,zT),e(zT,i8e),e(i8e,Bfr),e(zT,Pfr),e(zT,vQ),e(vQ,Ifr),e(zT,qfr),e(Te,Nfr),e(Te,QT),e(QT,d8e),e(d8e,jfr),e(QT,Dfr),e(QT,FQ),e(FQ,Gfr),e(QT,Ofr),e(Te,Vfr),e(Te,WT),e(WT,c8e),e(c8e,Xfr),e(WT,zfr),e(WT,TQ),e(TQ,Qfr),e(WT,Wfr),e(Te,Hfr),e(Te,HT),e(HT,f8e),e(f8e,Ufr),e(HT,Jfr),e(HT,MQ),e(MQ,Yfr),e(HT,Kfr),e(yr,Zfr),M(UT,yr,null),b(f,AIe,_),b(f,Wd,_),e(Wd,JT),e(JT,m8e),M(Gy,m8e,null),e(Wd,emr),e(Wd,g8e),e(g8e,omr),b(f,yIe,_),b(f,er,_),M(Oy,er,null),e(er,rmr),e(er,Hd),e(Hd,tmr),e(Hd,EQ),e(EQ,amr),e(Hd,nmr),e(Hd,CQ),e(CQ,smr),e(Hd,lmr),e(er,imr),e(er,Vy),e(Vy,dmr),e(Vy,h8e),e(h8e,cmr),e(Vy,fmr),e(er,mmr),e(er,Lt),M(Xy,Lt,null),e(Lt,gmr),e(Lt,p8e),e(p8e,hmr),e(Lt,pmr),e(Lt,Ud),e(Ud,umr),e(Ud,u8e),e(u8e,_mr),e(Ud,bmr),e(Ud,wQ),e(wQ,vmr),e(Ud,Fmr),e(Lt,Tmr),M(YT,Lt,null),e(er,Mmr),e(er,Lr),M(zy,Lr,null),e(Lr,Emr),e(Lr,_8e),e(_8e,Cmr),e(Lr,wmr),e(Lr,on),e(on,Amr),e(on,b8e),e(b8e,ymr),e(on,Lmr),e(on,v8e),e(v8e,xmr),e(on,$mr),e(on,F8e),e(F8e,kmr),e(on,Smr),e(Lr,Rmr),e(Lr,rn),e(rn,KT),e(KT,T8e),e(T8e,Bmr),e(KT,Pmr),e(KT,AQ),e(AQ,Imr),e(KT,qmr),e(rn,Nmr),e(rn,ZT),e(ZT,M8e),e(M8e,jmr),e(ZT,Dmr),e(ZT,yQ),e(yQ,Gmr),e(ZT,Omr),e(rn,Vmr),e(rn,e9),e(e9,E8e),e(E8e,Xmr),e(e9,zmr),e(e9,LQ),e(LQ,Qmr),e(e9,Wmr),e(rn,Hmr),e(rn,o9),e(o9,C8e),e(C8e,Umr),e(o9,Jmr),e(o9,xQ),e(xQ,Ymr),e(o9,Kmr),e(Lr,Zmr),M(r9,Lr,null),b(f,LIe,_),b(f,Jd,_),e(Jd,t9),e(t9,w8e),M(Qy,w8e,null),e(Jd,egr),e(Jd,A8e),e(A8e,ogr),b(f,xIe,_),b(f,or,_),M(Wy,or,null),e(or,rgr),e(or,Yd),e(Yd,tgr),e(Yd,$Q),e($Q,agr),e(Yd,ngr),e(Yd,kQ),e(kQ,sgr),e(Yd,lgr),e(or,igr),e(or,Hy),e(Hy,dgr),e(Hy,y8e),e(y8e,cgr),e(Hy,fgr),e(or,mgr),e(or,xt),M(Uy,xt,null),e(xt,ggr),e(xt,L8e),e(L8e,hgr),e(xt,pgr),e(xt,Kd),e(Kd,ugr),e(Kd,x8e),e(x8e,_gr),e(Kd,bgr),e(Kd,SQ),e(SQ,vgr),e(Kd,Fgr),e(xt,Tgr),M(a9,xt,null),e(or,Mgr),e(or,xr),M(Jy,xr,null),e(xr,Egr),e(xr,$8e),e($8e,Cgr),e(xr,wgr),e(xr,tn),e(tn,Agr),e(tn,k8e),e(k8e,ygr),e(tn,Lgr),e(tn,S8e),e(S8e,xgr),e(tn,$gr),e(tn,R8e),e(R8e,kgr),e(tn,Sgr),e(xr,Rgr),e(xr,ie),e(ie,n9),e(n9,B8e),e(B8e,Bgr),e(n9,Pgr),e(n9,RQ),e(RQ,Igr),e(n9,qgr),e(ie,Ngr),e(ie,s9),e(s9,P8e),e(P8e,jgr),e(s9,Dgr),e(s9,BQ),e(BQ,Ggr),e(s9,Ogr),e(ie,Vgr),e(ie,l9),e(l9,I8e),e(I8e,Xgr),e(l9,zgr),e(l9,PQ),e(PQ,Qgr),e(l9,Wgr),e(ie,Hgr),e(ie,i9),e(i9,q8e),e(q8e,Ugr),e(i9,Jgr),e(i9,IQ),e(IQ,Ygr),e(i9,Kgr),e(ie,Zgr),e(ie,d9),e(d9,N8e),e(N8e,ehr),e(d9,ohr),e(d9,qQ),e(qQ,rhr),e(d9,thr),e(ie,ahr),e(ie,c9),e(c9,j8e),e(j8e,nhr),e(c9,shr),e(c9,NQ),e(NQ,lhr),e(c9,ihr),e(ie,dhr),e(ie,f9),e(f9,D8e),e(D8e,chr),e(f9,fhr),e(f9,jQ),e(jQ,mhr),e(f9,ghr),e(ie,hhr),e(ie,m9),e(m9,G8e),e(G8e,phr),e(m9,uhr),e(m9,DQ),e(DQ,_hr),e(m9,bhr),e(ie,vhr),e(ie,g9),e(g9,O8e),e(O8e,Fhr),e(g9,Thr),e(g9,GQ),e(GQ,Mhr),e(g9,Ehr),e(ie,Chr),e(ie,h9),e(h9,V8e),e(V8e,whr),e(h9,Ahr),e(h9,OQ),e(OQ,yhr),e(h9,Lhr),e(ie,xhr),e(ie,p9),e(p9,X8e),e(X8e,$hr),e(p9,khr),e(p9,VQ),e(VQ,Shr),e(p9,Rhr),e(ie,Bhr),e(ie,u9),e(u9,z8e),e(z8e,Phr),e(u9,Ihr),e(u9,XQ),e(XQ,qhr),e(u9,Nhr),e(ie,jhr),e(ie,_9),e(_9,Q8e),e(Q8e,Dhr),e(_9,Ghr),e(_9,zQ),e(zQ,Ohr),e(_9,Vhr),e(ie,Xhr),e(ie,b9),e(b9,W8e),e(W8e,zhr),e(b9,Qhr),e(b9,QQ),e(QQ,Whr),e(b9,Hhr),e(ie,Uhr),e(ie,v9),e(v9,H8e),e(H8e,Jhr),e(v9,Yhr),e(v9,WQ),e(WQ,Khr),e(v9,Zhr),e(ie,epr),e(ie,F9),e(F9,U8e),e(U8e,opr),e(F9,rpr),e(F9,HQ),e(HQ,tpr),e(F9,apr),e(ie,npr),e(ie,T9),e(T9,J8e),e(J8e,spr),e(T9,lpr),e(T9,UQ),e(UQ,ipr),e(T9,dpr),e(ie,cpr),e(ie,M9),e(M9,Y8e),e(Y8e,fpr),e(M9,mpr),e(M9,JQ),e(JQ,gpr),e(M9,hpr),e(ie,ppr),e(ie,E9),e(E9,K8e),e(K8e,upr),e(E9,_pr),e(E9,YQ),e(YQ,bpr),e(E9,vpr),e(ie,Fpr),e(ie,C9),e(C9,Z8e),e(Z8e,Tpr),e(C9,Mpr),e(C9,KQ),e(KQ,Epr),e(C9,Cpr),e(xr,wpr),M(w9,xr,null),b(f,$Ie,_),b(f,Zd,_),e(Zd,A9),e(A9,ebe),M(Yy,ebe,null),e(Zd,Apr),e(Zd,obe),e(obe,ypr),b(f,kIe,_),b(f,rr,_),M(Ky,rr,null),e(rr,Lpr),e(rr,ec),e(ec,xpr),e(ec,ZQ),e(ZQ,$pr),e(ec,kpr),e(ec,eW),e(eW,Spr),e(ec,Rpr),e(rr,Bpr),e(rr,Zy),e(Zy,Ppr),e(Zy,rbe),e(rbe,Ipr),e(Zy,qpr),e(rr,Npr),e(rr,$t),M(eL,$t,null),e($t,jpr),e($t,tbe),e(tbe,Dpr),e($t,Gpr),e($t,oc),e(oc,Opr),e(oc,abe),e(abe,Vpr),e(oc,Xpr),e(oc,oW),e(oW,zpr),e(oc,Qpr),e($t,Wpr),M(y9,$t,null),e(rr,Hpr),e(rr,$r),M(oL,$r,null),e($r,Upr),e($r,nbe),e(nbe,Jpr),e($r,Ypr),e($r,an),e(an,Kpr),e(an,sbe),e(sbe,Zpr),e(an,eur),e(an,lbe),e(lbe,our),e(an,rur),e(an,ibe),e(ibe,tur),e(an,aur),e($r,nur),e($r,ye),e(ye,L9),e(L9,dbe),e(dbe,sur),e(L9,lur),e(L9,rW),e(rW,iur),e(L9,dur),e(ye,cur),e(ye,x9),e(x9,cbe),e(cbe,fur),e(x9,mur),e(x9,tW),e(tW,gur),e(x9,hur),e(ye,pur),e(ye,$9),e($9,fbe),e(fbe,uur),e($9,_ur),e($9,aW),e(aW,bur),e($9,vur),e(ye,Fur),e(ye,k9),e(k9,mbe),e(mbe,Tur),e(k9,Mur),e(k9,nW),e(nW,Eur),e(k9,Cur),e(ye,wur),e(ye,S9),e(S9,gbe),e(gbe,Aur),e(S9,yur),e(S9,sW),e(sW,Lur),e(S9,xur),e(ye,$ur),e(ye,R9),e(R9,hbe),e(hbe,kur),e(R9,Sur),e(R9,lW),e(lW,Rur),e(R9,Bur),e(ye,Pur),e(ye,B9),e(B9,pbe),e(pbe,Iur),e(B9,qur),e(B9,iW),e(iW,Nur),e(B9,jur),e(ye,Dur),e(ye,P9),e(P9,ube),e(ube,Gur),e(P9,Our),e(P9,dW),e(dW,Vur),e(P9,Xur),e(ye,zur),e(ye,I9),e(I9,_be),e(_be,Qur),e(I9,Wur),e(I9,cW),e(cW,Hur),e(I9,Uur),e(ye,Jur),e(ye,q9),e(q9,bbe),e(bbe,Yur),e(q9,Kur),e(q9,fW),e(fW,Zur),e(q9,e_r),e($r,o_r),M(N9,$r,null),b(f,SIe,_),b(f,rc,_),e(rc,j9),e(j9,vbe),M(rL,vbe,null),e(rc,r_r),e(rc,Fbe),e(Fbe,t_r),b(f,RIe,_),b(f,tr,_),M(tL,tr,null),e(tr,a_r),e(tr,tc),e(tc,n_r),e(tc,mW),e(mW,s_r),e(tc,l_r),e(tc,gW),e(gW,i_r),e(tc,d_r),e(tr,c_r),e(tr,aL),e(aL,f_r),e(aL,Tbe),e(Tbe,m_r),e(aL,g_r),e(tr,h_r),e(tr,kt),M(nL,kt,null),e(kt,p_r),e(kt,Mbe),e(Mbe,u_r),e(kt,__r),e(kt,ac),e(ac,b_r),e(ac,Ebe),e(Ebe,v_r),e(ac,F_r),e(ac,hW),e(hW,T_r),e(ac,M_r),e(kt,E_r),M(D9,kt,null),e(tr,C_r),e(tr,kr),M(sL,kr,null),e(kr,w_r),e(kr,Cbe),e(Cbe,A_r),e(kr,y_r),e(kr,nn),e(nn,L_r),e(nn,wbe),e(wbe,x_r),e(nn,$_r),e(nn,Abe),e(Abe,k_r),e(nn,S_r),e(nn,ybe),e(ybe,R_r),e(nn,B_r),e(kr,P_r),e(kr,Z),e(Z,G9),e(G9,Lbe),e(Lbe,I_r),e(G9,q_r),e(G9,pW),e(pW,N_r),e(G9,j_r),e(Z,D_r),e(Z,O9),e(O9,xbe),e(xbe,G_r),e(O9,O_r),e(O9,uW),e(uW,V_r),e(O9,X_r),e(Z,z_r),e(Z,V9),e(V9,$be),e($be,Q_r),e(V9,W_r),e(V9,_W),e(_W,H_r),e(V9,U_r),e(Z,J_r),e(Z,X9),e(X9,kbe),e(kbe,Y_r),e(X9,K_r),e(X9,bW),e(bW,Z_r),e(X9,e1r),e(Z,o1r),e(Z,z9),e(z9,Sbe),e(Sbe,r1r),e(z9,t1r),e(z9,vW),e(vW,a1r),e(z9,n1r),e(Z,s1r),e(Z,Q9),e(Q9,Rbe),e(Rbe,l1r),e(Q9,i1r),e(Q9,FW),e(FW,d1r),e(Q9,c1r),e(Z,f1r),e(Z,W9),e(W9,Bbe),e(Bbe,m1r),e(W9,g1r),e(W9,TW),e(TW,h1r),e(W9,p1r),e(Z,u1r),e(Z,H9),e(H9,Pbe),e(Pbe,_1r),e(H9,b1r),e(H9,MW),e(MW,v1r),e(H9,F1r),e(Z,T1r),e(Z,U9),e(U9,Ibe),e(Ibe,M1r),e(U9,E1r),e(U9,EW),e(EW,C1r),e(U9,w1r),e(Z,A1r),e(Z,J9),e(J9,qbe),e(qbe,y1r),e(J9,L1r),e(J9,CW),e(CW,x1r),e(J9,$1r),e(Z,k1r),e(Z,Y9),e(Y9,Nbe),e(Nbe,S1r),e(Y9,R1r),e(Y9,wW),e(wW,B1r),e(Y9,P1r),e(Z,I1r),e(Z,K9),e(K9,jbe),e(jbe,q1r),e(K9,N1r),e(K9,AW),e(AW,j1r),e(K9,D1r),e(Z,G1r),e(Z,Z9),e(Z9,Dbe),e(Dbe,O1r),e(Z9,V1r),e(Z9,yW),e(yW,X1r),e(Z9,z1r),e(Z,Q1r),e(Z,eM),e(eM,Gbe),e(Gbe,W1r),e(eM,H1r),e(eM,LW),e(LW,U1r),e(eM,J1r),e(Z,Y1r),e(Z,oM),e(oM,Obe),e(Obe,K1r),e(oM,Z1r),e(oM,xW),e(xW,e8r),e(oM,o8r),e(Z,r8r),e(Z,rM),e(rM,Vbe),e(Vbe,t8r),e(rM,a8r),e(rM,$W),e($W,n8r),e(rM,s8r),e(Z,l8r),e(Z,tM),e(tM,Xbe),e(Xbe,i8r),e(tM,d8r),e(tM,kW),e(kW,c8r),e(tM,f8r),e(Z,m8r),e(Z,aM),e(aM,zbe),e(zbe,g8r),e(aM,h8r),e(aM,SW),e(SW,p8r),e(aM,u8r),e(Z,_8r),e(Z,nM),e(nM,Qbe),e(Qbe,b8r),e(nM,v8r),e(nM,RW),e(RW,F8r),e(nM,T8r),e(Z,M8r),e(Z,sM),e(sM,Wbe),e(Wbe,E8r),e(sM,C8r),e(sM,BW),e(BW,w8r),e(sM,A8r),e(Z,y8r),e(Z,lM),e(lM,Hbe),e(Hbe,L8r),e(lM,x8r),e(lM,PW),e(PW,$8r),e(lM,k8r),e(Z,S8r),e(Z,iM),e(iM,Ube),e(Ube,R8r),e(iM,B8r),e(iM,IW),e(IW,P8r),e(iM,I8r),e(Z,q8r),e(Z,dM),e(dM,Jbe),e(Jbe,N8r),e(dM,j8r),e(dM,qW),e(qW,D8r),e(dM,G8r),e(Z,O8r),e(Z,cM),e(cM,Ybe),e(Ybe,V8r),e(cM,X8r),e(cM,NW),e(NW,z8r),e(cM,Q8r),e(Z,W8r),e(Z,fM),e(fM,Kbe),e(Kbe,H8r),e(fM,U8r),e(fM,jW),e(jW,J8r),e(fM,Y8r),e(Z,K8r),e(Z,mM),e(mM,Zbe),e(Zbe,Z8r),e(mM,ebr),e(mM,DW),e(DW,obr),e(mM,rbr),e(kr,tbr),M(gM,kr,null),b(f,BIe,_),b(f,nc,_),e(nc,hM),e(hM,e2e),M(lL,e2e,null),e(nc,abr),e(nc,o2e),e(o2e,nbr),b(f,PIe,_),b(f,ar,_),M(iL,ar,null),e(ar,sbr),e(ar,sc),e(sc,lbr),e(sc,GW),e(GW,ibr),e(sc,dbr),e(sc,OW),e(OW,cbr),e(sc,fbr),e(ar,mbr),e(ar,dL),e(dL,gbr),e(dL,r2e),e(r2e,hbr),e(dL,pbr),e(ar,ubr),e(ar,St),M(cL,St,null),e(St,_br),e(St,t2e),e(t2e,bbr),e(St,vbr),e(St,lc),e(lc,Fbr),e(lc,a2e),e(a2e,Tbr),e(lc,Mbr),e(lc,VW),e(VW,Ebr),e(lc,Cbr),e(St,wbr),M(pM,St,null),e(ar,Abr),e(ar,Sr),M(fL,Sr,null),e(Sr,ybr),e(Sr,n2e),e(n2e,Lbr),e(Sr,xbr),e(Sr,sn),e(sn,$br),e(sn,s2e),e(s2e,kbr),e(sn,Sbr),e(sn,l2e),e(l2e,Rbr),e(sn,Bbr),e(sn,i2e),e(i2e,Pbr),e(sn,Ibr),e(Sr,qbr),e(Sr,pe),e(pe,uM),e(uM,d2e),e(d2e,Nbr),e(uM,jbr),e(uM,XW),e(XW,Dbr),e(uM,Gbr),e(pe,Obr),e(pe,_M),e(_M,c2e),e(c2e,Vbr),e(_M,Xbr),e(_M,zW),e(zW,zbr),e(_M,Qbr),e(pe,Wbr),e(pe,bM),e(bM,f2e),e(f2e,Hbr),e(bM,Ubr),e(bM,QW),e(QW,Jbr),e(bM,Ybr),e(pe,Kbr),e(pe,vM),e(vM,m2e),e(m2e,Zbr),e(vM,e2r),e(vM,WW),e(WW,o2r),e(vM,r2r),e(pe,t2r),e(pe,FM),e(FM,g2e),e(g2e,a2r),e(FM,n2r),e(FM,HW),e(HW,s2r),e(FM,l2r),e(pe,i2r),e(pe,TM),e(TM,h2e),e(h2e,d2r),e(TM,c2r),e(TM,UW),e(UW,f2r),e(TM,m2r),e(pe,g2r),e(pe,MM),e(MM,p2e),e(p2e,h2r),e(MM,p2r),e(MM,JW),e(JW,u2r),e(MM,_2r),e(pe,b2r),e(pe,EM),e(EM,u2e),e(u2e,v2r),e(EM,F2r),e(EM,YW),e(YW,T2r),e(EM,M2r),e(pe,E2r),e(pe,CM),e(CM,_2e),e(_2e,C2r),e(CM,w2r),e(CM,KW),e(KW,A2r),e(CM,y2r),e(pe,L2r),e(pe,wM),e(wM,b2e),e(b2e,x2r),e(wM,$2r),e(wM,ZW),e(ZW,k2r),e(wM,S2r),e(pe,R2r),e(pe,AM),e(AM,v2e),e(v2e,B2r),e(AM,P2r),e(AM,eH),e(eH,I2r),e(AM,q2r),e(pe,N2r),e(pe,yM),e(yM,F2e),e(F2e,j2r),e(yM,D2r),e(yM,oH),e(oH,G2r),e(yM,O2r),e(pe,V2r),e(pe,LM),e(LM,T2e),e(T2e,X2r),e(LM,z2r),e(LM,rH),e(rH,Q2r),e(LM,W2r),e(pe,H2r),e(pe,xM),e(xM,M2e),e(M2e,U2r),e(xM,J2r),e(xM,tH),e(tH,Y2r),e(xM,K2r),e(pe,Z2r),e(pe,$M),e($M,E2e),e(E2e,evr),e($M,ovr),e($M,aH),e(aH,rvr),e($M,tvr),e(pe,avr),e(pe,kM),e(kM,C2e),e(C2e,nvr),e(kM,svr),e(kM,nH),e(nH,lvr),e(kM,ivr),e(pe,dvr),e(pe,SM),e(SM,w2e),e(w2e,cvr),e(SM,fvr),e(SM,sH),e(sH,mvr),e(SM,gvr),e(Sr,hvr),M(RM,Sr,null),b(f,IIe,_),b(f,ic,_),e(ic,BM),e(BM,A2e),M(mL,A2e,null),e(ic,pvr),e(ic,y2e),e(y2e,uvr),b(f,qIe,_),b(f,nr,_),M(gL,nr,null),e(nr,_vr),e(nr,dc),e(dc,bvr),e(dc,lH),e(lH,vvr),e(dc,Fvr),e(dc,iH),e(iH,Tvr),e(dc,Mvr),e(nr,Evr),e(nr,hL),e(hL,Cvr),e(hL,L2e),e(L2e,wvr),e(hL,Avr),e(nr,yvr),e(nr,Rt),M(pL,Rt,null),e(Rt,Lvr),e(Rt,x2e),e(x2e,xvr),e(Rt,$vr),e(Rt,cc),e(cc,kvr),e(cc,$2e),e($2e,Svr),e(cc,Rvr),e(cc,dH),e(dH,Bvr),e(cc,Pvr),e(Rt,Ivr),M(PM,Rt,null),e(nr,qvr),e(nr,Rr),M(uL,Rr,null),e(Rr,Nvr),e(Rr,k2e),e(k2e,jvr),e(Rr,Dvr),e(Rr,ln),e(ln,Gvr),e(ln,S2e),e(S2e,Ovr),e(ln,Vvr),e(ln,R2e),e(R2e,Xvr),e(ln,zvr),e(ln,B2e),e(B2e,Qvr),e(ln,Wvr),e(Rr,Hvr),e(Rr,_L),e(_L,IM),e(IM,P2e),e(P2e,Uvr),e(IM,Jvr),e(IM,cH),e(cH,Yvr),e(IM,Kvr),e(_L,Zvr),e(_L,qM),e(qM,I2e),e(I2e,eFr),e(qM,oFr),e(qM,fH),e(fH,rFr),e(qM,tFr),e(Rr,aFr),M(NM,Rr,null),b(f,NIe,_),b(f,fc,_),e(fc,jM),e(jM,q2e),M(bL,q2e,null),e(fc,nFr),e(fc,N2e),e(N2e,sFr),b(f,jIe,_),b(f,sr,_),M(vL,sr,null),e(sr,lFr),e(sr,mc),e(mc,iFr),e(mc,mH),e(mH,dFr),e(mc,cFr),e(mc,gH),e(gH,fFr),e(mc,mFr),e(sr,gFr),e(sr,FL),e(FL,hFr),e(FL,j2e),e(j2e,pFr),e(FL,uFr),e(sr,_Fr),e(sr,Bt),M(TL,Bt,null),e(Bt,bFr),e(Bt,D2e),e(D2e,vFr),e(Bt,FFr),e(Bt,gc),e(gc,TFr),e(gc,G2e),e(G2e,MFr),e(gc,EFr),e(gc,hH),e(hH,CFr),e(gc,wFr),e(Bt,AFr),M(DM,Bt,null),e(sr,yFr),e(sr,Br),M(ML,Br,null),e(Br,LFr),e(Br,O2e),e(O2e,xFr),e(Br,$Fr),e(Br,dn),e(dn,kFr),e(dn,V2e),e(V2e,SFr),e(dn,RFr),e(dn,X2e),e(X2e,BFr),e(dn,PFr),e(dn,z2e),e(z2e,IFr),e(dn,qFr),e(Br,NFr),e(Br,Q2e),e(Q2e,GM),e(GM,W2e),e(W2e,jFr),e(GM,DFr),e(GM,pH),e(pH,GFr),e(GM,OFr),e(Br,VFr),M(OM,Br,null),b(f,DIe,_),b(f,hc,_),e(hc,VM),e(VM,H2e),M(EL,H2e,null),e(hc,XFr),e(hc,U2e),e(U2e,zFr),b(f,GIe,_),b(f,lr,_),M(CL,lr,null),e(lr,QFr),e(lr,pc),e(pc,WFr),e(pc,uH),e(uH,HFr),e(pc,UFr),e(pc,_H),e(_H,JFr),e(pc,YFr),e(lr,KFr),e(lr,wL),e(wL,ZFr),e(wL,J2e),e(J2e,e6r),e(wL,o6r),e(lr,r6r),e(lr,Pt),M(AL,Pt,null),e(Pt,t6r),e(Pt,Y2e),e(Y2e,a6r),e(Pt,n6r),e(Pt,uc),e(uc,s6r),e(uc,K2e),e(K2e,l6r),e(uc,i6r),e(uc,bH),e(bH,d6r),e(uc,c6r),e(Pt,f6r),M(XM,Pt,null),e(lr,m6r),e(lr,Pr),M(yL,Pr,null),e(Pr,g6r),e(Pr,Z2e),e(Z2e,h6r),e(Pr,p6r),e(Pr,cn),e(cn,u6r),e(cn,eve),e(eve,_6r),e(cn,b6r),e(cn,ove),e(ove,v6r),e(cn,F6r),e(cn,rve),e(rve,T6r),e(cn,M6r),e(Pr,E6r),e(Pr,de),e(de,zM),e(zM,tve),e(tve,C6r),e(zM,w6r),e(zM,vH),e(vH,A6r),e(zM,y6r),e(de,L6r),e(de,QM),e(QM,ave),e(ave,x6r),e(QM,$6r),e(QM,FH),e(FH,k6r),e(QM,S6r),e(de,R6r),e(de,WM),e(WM,nve),e(nve,B6r),e(WM,P6r),e(WM,TH),e(TH,I6r),e(WM,q6r),e(de,N6r),e(de,HM),e(HM,sve),e(sve,j6r),e(HM,D6r),e(HM,MH),e(MH,G6r),e(HM,O6r),e(de,V6r),e(de,UM),e(UM,lve),e(lve,X6r),e(UM,z6r),e(UM,EH),e(EH,Q6r),e(UM,W6r),e(de,H6r),e(de,JM),e(JM,ive),e(ive,U6r),e(JM,J6r),e(JM,CH),e(CH,Y6r),e(JM,K6r),e(de,Z6r),e(de,YM),e(YM,dve),e(dve,eTr),e(YM,oTr),e(YM,wH),e(wH,rTr),e(YM,tTr),e(de,aTr),e(de,KM),e(KM,cve),e(cve,nTr),e(KM,sTr),e(KM,AH),e(AH,lTr),e(KM,iTr),e(de,dTr),e(de,ZM),e(ZM,fve),e(fve,cTr),e(ZM,fTr),e(ZM,yH),e(yH,mTr),e(ZM,gTr),e(de,hTr),e(de,e4),e(e4,mve),e(mve,pTr),e(e4,uTr),e(e4,LH),e(LH,_Tr),e(e4,bTr),e(de,vTr),e(de,o4),e(o4,gve),e(gve,FTr),e(o4,TTr),e(o4,xH),e(xH,MTr),e(o4,ETr),e(de,CTr),e(de,r4),e(r4,hve),e(hve,wTr),e(r4,ATr),e(r4,$H),e($H,yTr),e(r4,LTr),e(de,xTr),e(de,t4),e(t4,pve),e(pve,$Tr),e(t4,kTr),e(t4,kH),e(kH,STr),e(t4,RTr),e(de,BTr),e(de,a4),e(a4,uve),e(uve,PTr),e(a4,ITr),e(a4,SH),e(SH,qTr),e(a4,NTr),e(de,jTr),e(de,n4),e(n4,_ve),e(_ve,DTr),e(n4,GTr),e(n4,RH),e(RH,OTr),e(n4,VTr),e(de,XTr),e(de,s4),e(s4,bve),e(bve,zTr),e(s4,QTr),e(s4,BH),e(BH,WTr),e(s4,HTr),e(de,UTr),e(de,l4),e(l4,vve),e(vve,JTr),e(l4,YTr),e(l4,PH),e(PH,KTr),e(l4,ZTr),e(de,e9r),e(de,i4),e(i4,Fve),e(Fve,o9r),e(i4,r9r),e(i4,IH),e(IH,t9r),e(i4,a9r),e(de,n9r),e(de,d4),e(d4,Tve),e(Tve,s9r),e(d4,l9r),e(d4,qH),e(qH,i9r),e(d4,d9r),e(de,c9r),e(de,c4),e(c4,Mve),e(Mve,f9r),e(c4,m9r),e(c4,NH),e(NH,g9r),e(c4,h9r),e(Pr,p9r),M(f4,Pr,null),b(f,OIe,_),b(f,_c,_),e(_c,m4),e(m4,Eve),M(LL,Eve,null),e(_c,u9r),e(_c,Cve),e(Cve,_9r),b(f,VIe,_),b(f,ir,_),M(xL,ir,null),e(ir,b9r),e(ir,bc),e(bc,v9r),e(bc,jH),e(jH,F9r),e(bc,T9r),e(bc,DH),e(DH,M9r),e(bc,E9r),e(ir,C9r),e(ir,$L),e($L,w9r),e($L,wve),e(wve,A9r),e($L,y9r),e(ir,L9r),e(ir,It),M(kL,It,null),e(It,x9r),e(It,Ave),e(Ave,$9r),e(It,k9r),e(It,vc),e(vc,S9r),e(vc,yve),e(yve,R9r),e(vc,B9r),e(vc,GH),e(GH,P9r),e(vc,I9r),e(It,q9r),M(g4,It,null),e(ir,N9r),e(ir,Ir),M(SL,Ir,null),e(Ir,j9r),e(Ir,Lve),e(Lve,D9r),e(Ir,G9r),e(Ir,fn),e(fn,O9r),e(fn,xve),e(xve,V9r),e(fn,X9r),e(fn,$ve),e($ve,z9r),e(fn,Q9r),e(fn,kve),e(kve,W9r),e(fn,H9r),e(Ir,U9r),e(Ir,ce),e(ce,h4),e(h4,Sve),e(Sve,J9r),e(h4,Y9r),e(h4,OH),e(OH,K9r),e(h4,Z9r),e(ce,eMr),e(ce,p4),e(p4,Rve),e(Rve,oMr),e(p4,rMr),e(p4,VH),e(VH,tMr),e(p4,aMr),e(ce,nMr),e(ce,u4),e(u4,Bve),e(Bve,sMr),e(u4,lMr),e(u4,XH),e(XH,iMr),e(u4,dMr),e(ce,cMr),e(ce,_4),e(_4,Pve),e(Pve,fMr),e(_4,mMr),e(_4,zH),e(zH,gMr),e(_4,hMr),e(ce,pMr),e(ce,b4),e(b4,Ive),e(Ive,uMr),e(b4,_Mr),e(b4,QH),e(QH,bMr),e(b4,vMr),e(ce,FMr),e(ce,v4),e(v4,qve),e(qve,TMr),e(v4,MMr),e(v4,WH),e(WH,EMr),e(v4,CMr),e(ce,wMr),e(ce,F4),e(F4,Nve),e(Nve,AMr),e(F4,yMr),e(F4,HH),e(HH,LMr),e(F4,xMr),e(ce,$Mr),e(ce,T4),e(T4,jve),e(jve,kMr),e(T4,SMr),e(T4,UH),e(UH,RMr),e(T4,BMr),e(ce,PMr),e(ce,M4),e(M4,Dve),e(Dve,IMr),e(M4,qMr),e(M4,JH),e(JH,NMr),e(M4,jMr),e(ce,DMr),e(ce,E4),e(E4,Gve),e(Gve,GMr),e(E4,OMr),e(E4,YH),e(YH,VMr),e(E4,XMr),e(ce,zMr),e(ce,C4),e(C4,Ove),e(Ove,QMr),e(C4,WMr),e(C4,KH),e(KH,HMr),e(C4,UMr),e(ce,JMr),e(ce,w4),e(w4,Vve),e(Vve,YMr),e(w4,KMr),e(w4,ZH),e(ZH,ZMr),e(w4,e4r),e(ce,o4r),e(ce,A4),e(A4,Xve),e(Xve,r4r),e(A4,t4r),e(A4,eU),e(eU,a4r),e(A4,n4r),e(ce,s4r),e(ce,y4),e(y4,zve),e(zve,l4r),e(y4,i4r),e(y4,oU),e(oU,d4r),e(y4,c4r),e(ce,f4r),e(ce,L4),e(L4,Qve),e(Qve,m4r),e(L4,g4r),e(L4,rU),e(rU,h4r),e(L4,p4r),e(ce,u4r),e(ce,x4),e(x4,Wve),e(Wve,_4r),e(x4,b4r),e(x4,tU),e(tU,v4r),e(x4,F4r),e(ce,T4r),e(ce,$4),e($4,Hve),e(Hve,M4r),e($4,E4r),e($4,aU),e(aU,C4r),e($4,w4r),e(ce,A4r),e(ce,k4),e(k4,Uve),e(Uve,y4r),e(k4,L4r),e(k4,nU),e(nU,x4r),e(k4,$4r),e(ce,k4r),e(ce,S4),e(S4,Jve),e(Jve,S4r),e(S4,R4r),e(S4,sU),e(sU,B4r),e(S4,P4r),e(ce,I4r),e(ce,R4),e(R4,Yve),e(Yve,q4r),e(R4,N4r),e(R4,lU),e(lU,j4r),e(R4,D4r),e(Ir,G4r),M(B4,Ir,null),b(f,XIe,_),b(f,Fc,_),e(Fc,P4),e(P4,Kve),M(RL,Kve,null),e(Fc,O4r),e(Fc,Zve),e(Zve,V4r),b(f,zIe,_),b(f,dr,_),M(BL,dr,null),e(dr,X4r),e(dr,Tc),e(Tc,z4r),e(Tc,iU),e(iU,Q4r),e(Tc,W4r),e(Tc,dU),e(dU,H4r),e(Tc,U4r),e(dr,J4r),e(dr,PL),e(PL,Y4r),e(PL,eFe),e(eFe,K4r),e(PL,Z4r),e(dr,eEr),e(dr,qt),M(IL,qt,null),e(qt,oEr),e(qt,oFe),e(oFe,rEr),e(qt,tEr),e(qt,Mc),e(Mc,aEr),e(Mc,rFe),e(rFe,nEr),e(Mc,sEr),e(Mc,cU),e(cU,lEr),e(Mc,iEr),e(qt,dEr),M(I4,qt,null),e(dr,cEr),e(dr,qr),M(qL,qr,null),e(qr,fEr),e(qr,tFe),e(tFe,mEr),e(qr,gEr),e(qr,mn),e(mn,hEr),e(mn,aFe),e(aFe,pEr),e(mn,uEr),e(mn,nFe),e(nFe,_Er),e(mn,bEr),e(mn,sFe),e(sFe,vEr),e(mn,FEr),e(qr,TEr),e(qr,lFe),e(lFe,q4),e(q4,iFe),e(iFe,MEr),e(q4,EEr),e(q4,fU),e(fU,CEr),e(q4,wEr),e(qr,AEr),M(N4,qr,null),b(f,QIe,_),b(f,Ec,_),e(Ec,j4),e(j4,dFe),M(NL,dFe,null),e(Ec,yEr),e(Ec,cFe),e(cFe,LEr),b(f,WIe,_),b(f,cr,_),M(jL,cr,null),e(cr,xEr),e(cr,Cc),e(Cc,$Er),e(Cc,mU),e(mU,kEr),e(Cc,SEr),e(Cc,gU),e(gU,REr),e(Cc,BEr),e(cr,PEr),e(cr,DL),e(DL,IEr),e(DL,fFe),e(fFe,qEr),e(DL,NEr),e(cr,jEr),e(cr,Nt),M(GL,Nt,null),e(Nt,DEr),e(Nt,mFe),e(mFe,GEr),e(Nt,OEr),e(Nt,wc),e(wc,VEr),e(wc,gFe),e(gFe,XEr),e(wc,zEr),e(wc,hU),e(hU,QEr),e(wc,WEr),e(Nt,HEr),M(D4,Nt,null),e(cr,UEr),e(cr,Nr),M(OL,Nr,null),e(Nr,JEr),e(Nr,hFe),e(hFe,YEr),e(Nr,KEr),e(Nr,gn),e(gn,ZEr),e(gn,pFe),e(pFe,e5r),e(gn,o5r),e(gn,uFe),e(uFe,r5r),e(gn,t5r),e(gn,_Fe),e(_Fe,a5r),e(gn,n5r),e(Nr,s5r),e(Nr,bFe),e(bFe,G4),e(G4,vFe),e(vFe,l5r),e(G4,i5r),e(G4,pU),e(pU,d5r),e(G4,c5r),e(Nr,f5r),M(O4,Nr,null),b(f,HIe,_),b(f,Ac,_),e(Ac,V4),e(V4,FFe),M(VL,FFe,null),e(Ac,m5r),e(Ac,TFe),e(TFe,g5r),b(f,UIe,_),b(f,fr,_),M(XL,fr,null),e(fr,h5r),e(fr,yc),e(yc,p5r),e(yc,uU),e(uU,u5r),e(yc,_5r),e(yc,_U),e(_U,b5r),e(yc,v5r),e(fr,F5r),e(fr,zL),e(zL,T5r),e(zL,MFe),e(MFe,M5r),e(zL,E5r),e(fr,C5r),e(fr,jt),M(QL,jt,null),e(jt,w5r),e(jt,EFe),e(EFe,A5r),e(jt,y5r),e(jt,Lc),e(Lc,L5r),e(Lc,CFe),e(CFe,x5r),e(Lc,$5r),e(Lc,bU),e(bU,k5r),e(Lc,S5r),e(jt,R5r),M(X4,jt,null),e(fr,B5r),e(fr,jr),M(WL,jr,null),e(jr,P5r),e(jr,wFe),e(wFe,I5r),e(jr,q5r),e(jr,hn),e(hn,N5r),e(hn,AFe),e(AFe,j5r),e(hn,D5r),e(hn,yFe),e(yFe,G5r),e(hn,O5r),e(hn,LFe),e(LFe,V5r),e(hn,X5r),e(jr,z5r),e(jr,oe),e(oe,z4),e(z4,xFe),e(xFe,Q5r),e(z4,W5r),e(z4,vU),e(vU,H5r),e(z4,U5r),e(oe,J5r),e(oe,Q4),e(Q4,$Fe),e($Fe,Y5r),e(Q4,K5r),e(Q4,FU),e(FU,Z5r),e(Q4,eCr),e(oe,oCr),e(oe,W4),e(W4,kFe),e(kFe,rCr),e(W4,tCr),e(W4,TU),e(TU,aCr),e(W4,nCr),e(oe,sCr),e(oe,H4),e(H4,SFe),e(SFe,lCr),e(H4,iCr),e(H4,MU),e(MU,dCr),e(H4,cCr),e(oe,fCr),e(oe,U4),e(U4,RFe),e(RFe,mCr),e(U4,gCr),e(U4,EU),e(EU,hCr),e(U4,pCr),e(oe,uCr),e(oe,J4),e(J4,BFe),e(BFe,_Cr),e(J4,bCr),e(J4,CU),e(CU,vCr),e(J4,FCr),e(oe,TCr),e(oe,Y4),e(Y4,PFe),e(PFe,MCr),e(Y4,ECr),e(Y4,wU),e(wU,CCr),e(Y4,wCr),e(oe,ACr),e(oe,K4),e(K4,IFe),e(IFe,yCr),e(K4,LCr),e(K4,AU),e(AU,xCr),e(K4,$Cr),e(oe,kCr),e(oe,Z4),e(Z4,qFe),e(qFe,SCr),e(Z4,RCr),e(Z4,yU),e(yU,BCr),e(Z4,PCr),e(oe,ICr),e(oe,eE),e(eE,NFe),e(NFe,qCr),e(eE,NCr),e(eE,LU),e(LU,jCr),e(eE,DCr),e(oe,GCr),e(oe,oE),e(oE,jFe),e(jFe,OCr),e(oE,VCr),e(oE,xU),e(xU,XCr),e(oE,zCr),e(oe,QCr),e(oe,rE),e(rE,DFe),e(DFe,WCr),e(rE,HCr),e(rE,$U),e($U,UCr),e(rE,JCr),e(oe,YCr),e(oe,tE),e(tE,GFe),e(GFe,KCr),e(tE,ZCr),e(tE,kU),e(kU,e3r),e(tE,o3r),e(oe,r3r),e(oe,aE),e(aE,OFe),e(OFe,t3r),e(aE,a3r),e(aE,SU),e(SU,n3r),e(aE,s3r),e(oe,l3r),e(oe,nE),e(nE,VFe),e(VFe,i3r),e(nE,d3r),e(nE,RU),e(RU,c3r),e(nE,f3r),e(oe,m3r),e(oe,sE),e(sE,XFe),e(XFe,g3r),e(sE,h3r),e(sE,BU),e(BU,p3r),e(sE,u3r),e(oe,_3r),e(oe,lE),e(lE,zFe),e(zFe,b3r),e(lE,v3r),e(lE,PU),e(PU,F3r),e(lE,T3r),e(oe,M3r),e(oe,iE),e(iE,QFe),e(QFe,E3r),e(iE,C3r),e(iE,IU),e(IU,w3r),e(iE,A3r),e(oe,y3r),e(oe,dE),e(dE,WFe),e(WFe,L3r),e(dE,x3r),e(dE,qU),e(qU,$3r),e(dE,k3r),e(oe,S3r),e(oe,cE),e(cE,HFe),e(HFe,R3r),e(cE,B3r),e(cE,NU),e(NU,P3r),e(cE,I3r),e(oe,q3r),e(oe,fE),e(fE,UFe),e(UFe,N3r),e(fE,j3r),e(fE,jU),e(jU,D3r),e(fE,G3r),e(oe,O3r),e(oe,mE),e(mE,JFe),e(JFe,V3r),e(mE,X3r),e(mE,DU),e(DU,z3r),e(mE,Q3r),e(oe,W3r),e(oe,gE),e(gE,YFe),e(YFe,H3r),e(gE,U3r),e(gE,GU),e(GU,J3r),e(gE,Y3r),e(oe,K3r),e(oe,hE),e(hE,KFe),e(KFe,Z3r),e(hE,ewr),e(hE,OU),e(OU,owr),e(hE,rwr),e(oe,twr),e(oe,pE),e(pE,ZFe),e(ZFe,awr),e(pE,nwr),e(pE,VU),e(VU,swr),e(pE,lwr),e(jr,iwr),M(uE,jr,null),b(f,JIe,_),b(f,xc,_),e(xc,_E),e(_E,e6e),M(HL,e6e,null),e(xc,dwr),e(xc,o6e),e(o6e,cwr),b(f,YIe,_),b(f,mr,_),M(UL,mr,null),e(mr,fwr),e(mr,$c),e($c,mwr),e($c,XU),e(XU,gwr),e($c,hwr),e($c,zU),e(zU,pwr),e($c,uwr),e(mr,_wr),e(mr,JL),e(JL,bwr),e(JL,r6e),e(r6e,vwr),e(JL,Fwr),e(mr,Twr),e(mr,Dt),M(YL,Dt,null),e(Dt,Mwr),e(Dt,t6e),e(t6e,Ewr),e(Dt,Cwr),e(Dt,kc),e(kc,wwr),e(kc,a6e),e(a6e,Awr),e(kc,ywr),e(kc,QU),e(QU,Lwr),e(kc,xwr),e(Dt,$wr),M(bE,Dt,null),e(mr,kwr),e(mr,Dr),M(KL,Dr,null),e(Dr,Swr),e(Dr,n6e),e(n6e,Rwr),e(Dr,Bwr),e(Dr,pn),e(pn,Pwr),e(pn,s6e),e(s6e,Iwr),e(pn,qwr),e(pn,l6e),e(l6e,Nwr),e(pn,jwr),e(pn,i6e),e(i6e,Dwr),e(pn,Gwr),e(Dr,Owr),e(Dr,ke),e(ke,vE),e(vE,d6e),e(d6e,Vwr),e(vE,Xwr),e(vE,WU),e(WU,zwr),e(vE,Qwr),e(ke,Wwr),e(ke,FE),e(FE,c6e),e(c6e,Hwr),e(FE,Uwr),e(FE,HU),e(HU,Jwr),e(FE,Ywr),e(ke,Kwr),e(ke,TE),e(TE,f6e),e(f6e,Zwr),e(TE,eAr),e(TE,UU),e(UU,oAr),e(TE,rAr),e(ke,tAr),e(ke,ME),e(ME,m6e),e(m6e,aAr),e(ME,nAr),e(ME,JU),e(JU,sAr),e(ME,lAr),e(ke,iAr),e(ke,EE),e(EE,g6e),e(g6e,dAr),e(EE,cAr),e(EE,YU),e(YU,fAr),e(EE,mAr),e(ke,gAr),e(ke,CE),e(CE,h6e),e(h6e,hAr),e(CE,pAr),e(CE,KU),e(KU,uAr),e(CE,_Ar),e(ke,bAr),e(ke,wE),e(wE,p6e),e(p6e,vAr),e(wE,FAr),e(wE,ZU),e(ZU,TAr),e(wE,MAr),e(ke,EAr),e(ke,AE),e(AE,u6e),e(u6e,CAr),e(AE,wAr),e(AE,eJ),e(eJ,AAr),e(AE,yAr),e(ke,LAr),e(ke,yE),e(yE,_6e),e(_6e,xAr),e(yE,$Ar),e(yE,oJ),e(oJ,kAr),e(yE,SAr),e(Dr,RAr),M(LE,Dr,null),b(f,KIe,_),b(f,Sc,_),e(Sc,xE),e(xE,b6e),M(ZL,b6e,null),e(Sc,BAr),e(Sc,v6e),e(v6e,PAr),b(f,ZIe,_),b(f,gr,_),M(ex,gr,null),e(gr,IAr),e(gr,Rc),e(Rc,qAr),e(Rc,rJ),e(rJ,NAr),e(Rc,jAr),e(Rc,tJ),e(tJ,DAr),e(Rc,GAr),e(gr,OAr),e(gr,ox),e(ox,VAr),e(ox,F6e),e(F6e,XAr),e(ox,zAr),e(gr,QAr),e(gr,Gt),M(rx,Gt,null),e(Gt,WAr),e(Gt,T6e),e(T6e,HAr),e(Gt,UAr),e(Gt,Bc),e(Bc,JAr),e(Bc,M6e),e(M6e,YAr),e(Bc,KAr),e(Bc,aJ),e(aJ,ZAr),e(Bc,e0r),e(Gt,o0r),M($E,Gt,null),e(gr,r0r),e(gr,Gr),M(tx,Gr,null),e(Gr,t0r),e(Gr,E6e),e(E6e,a0r),e(Gr,n0r),e(Gr,un),e(un,s0r),e(un,C6e),e(C6e,l0r),e(un,i0r),e(un,w6e),e(w6e,d0r),e(un,c0r),e(un,A6e),e(A6e,f0r),e(un,m0r),e(Gr,g0r),e(Gr,Me),e(Me,kE),e(kE,y6e),e(y6e,h0r),e(kE,p0r),e(kE,nJ),e(nJ,u0r),e(kE,_0r),e(Me,b0r),e(Me,SE),e(SE,L6e),e(L6e,v0r),e(SE,F0r),e(SE,sJ),e(sJ,T0r),e(SE,M0r),e(Me,E0r),e(Me,RE),e(RE,x6e),e(x6e,C0r),e(RE,w0r),e(RE,lJ),e(lJ,A0r),e(RE,y0r),e(Me,L0r),e(Me,BE),e(BE,$6e),e($6e,x0r),e(BE,$0r),e(BE,iJ),e(iJ,k0r),e(BE,S0r),e(Me,R0r),e(Me,PE),e(PE,k6e),e(k6e,B0r),e(PE,P0r),e(PE,dJ),e(dJ,I0r),e(PE,q0r),e(Me,N0r),e(Me,IE),e(IE,S6e),e(S6e,j0r),e(IE,D0r),e(IE,cJ),e(cJ,G0r),e(IE,O0r),e(Me,V0r),e(Me,qE),e(qE,R6e),e(R6e,X0r),e(qE,z0r),e(qE,fJ),e(fJ,Q0r),e(qE,W0r),e(Me,H0r),e(Me,NE),e(NE,B6e),e(B6e,U0r),e(NE,J0r),e(NE,mJ),e(mJ,Y0r),e(NE,K0r),e(Me,Z0r),e(Me,jE),e(jE,P6e),e(P6e,eyr),e(jE,oyr),e(jE,gJ),e(gJ,ryr),e(jE,tyr),e(Me,ayr),e(Me,DE),e(DE,I6e),e(I6e,nyr),e(DE,syr),e(DE,hJ),e(hJ,lyr),e(DE,iyr),e(Me,dyr),e(Me,GE),e(GE,q6e),e(q6e,cyr),e(GE,fyr),e(GE,pJ),e(pJ,myr),e(GE,gyr),e(Me,hyr),e(Me,OE),e(OE,N6e),e(N6e,pyr),e(OE,uyr),e(OE,uJ),e(uJ,_yr),e(OE,byr),e(Gr,vyr),M(VE,Gr,null),b(f,eqe,_),b(f,Pc,_),e(Pc,XE),e(XE,j6e),M(ax,j6e,null),e(Pc,Fyr),e(Pc,D6e),e(D6e,Tyr),b(f,oqe,_),b(f,hr,_),M(nx,hr,null),e(hr,Myr),e(hr,Ic),e(Ic,Eyr),e(Ic,_J),e(_J,Cyr),e(Ic,wyr),e(Ic,bJ),e(bJ,Ayr),e(Ic,yyr),e(hr,Lyr),e(hr,sx),e(sx,xyr),e(sx,G6e),e(G6e,$yr),e(sx,kyr),e(hr,Syr),e(hr,Ot),M(lx,Ot,null),e(Ot,Ryr),e(Ot,O6e),e(O6e,Byr),e(Ot,Pyr),e(Ot,qc),e(qc,Iyr),e(qc,V6e),e(V6e,qyr),e(qc,Nyr),e(qc,vJ),e(vJ,jyr),e(qc,Dyr),e(Ot,Gyr),M(zE,Ot,null),e(hr,Oyr),e(hr,Or),M(ix,Or,null),e(Or,Vyr),e(Or,X6e),e(X6e,Xyr),e(Or,zyr),e(Or,_n),e(_n,Qyr),e(_n,z6e),e(z6e,Wyr),e(_n,Hyr),e(_n,Q6e),e(Q6e,Uyr),e(_n,Jyr),e(_n,W6e),e(W6e,Yyr),e(_n,Kyr),e(Or,Zyr),e(Or,Le),e(Le,QE),e(QE,H6e),e(H6e,eLr),e(QE,oLr),e(QE,FJ),e(FJ,rLr),e(QE,tLr),e(Le,aLr),e(Le,WE),e(WE,U6e),e(U6e,nLr),e(WE,sLr),e(WE,TJ),e(TJ,lLr),e(WE,iLr),e(Le,dLr),e(Le,HE),e(HE,J6e),e(J6e,cLr),e(HE,fLr),e(HE,MJ),e(MJ,mLr),e(HE,gLr),e(Le,hLr),e(Le,UE),e(UE,Y6e),e(Y6e,pLr),e(UE,uLr),e(UE,EJ),e(EJ,_Lr),e(UE,bLr),e(Le,vLr),e(Le,JE),e(JE,K6e),e(K6e,FLr),e(JE,TLr),e(JE,CJ),e(CJ,MLr),e(JE,ELr),e(Le,CLr),e(Le,YE),e(YE,Z6e),e(Z6e,wLr),e(YE,ALr),e(YE,wJ),e(wJ,yLr),e(YE,LLr),e(Le,xLr),e(Le,KE),e(KE,eTe),e(eTe,$Lr),e(KE,kLr),e(KE,AJ),e(AJ,SLr),e(KE,RLr),e(Le,BLr),e(Le,ZE),e(ZE,oTe),e(oTe,PLr),e(ZE,ILr),e(ZE,yJ),e(yJ,qLr),e(ZE,NLr),e(Le,jLr),e(Le,e5),e(e5,rTe),e(rTe,DLr),e(e5,GLr),e(e5,LJ),e(LJ,OLr),e(e5,VLr),e(Le,XLr),e(Le,o5),e(o5,tTe),e(tTe,zLr),e(o5,QLr),e(o5,xJ),e(xJ,WLr),e(o5,HLr),e(Or,ULr),M(r5,Or,null),b(f,rqe,_),b(f,Nc,_),e(Nc,t5),e(t5,aTe),M(dx,aTe,null),e(Nc,JLr),e(Nc,nTe),e(nTe,YLr),b(f,tqe,_),b(f,pr,_),M(cx,pr,null),e(pr,KLr),e(pr,jc),e(jc,ZLr),e(jc,$J),e($J,exr),e(jc,oxr),e(jc,kJ),e(kJ,rxr),e(jc,txr),e(pr,axr),e(pr,fx),e(fx,nxr),e(fx,sTe),e(sTe,sxr),e(fx,lxr),e(pr,ixr),e(pr,Vt),M(mx,Vt,null),e(Vt,dxr),e(Vt,lTe),e(lTe,cxr),e(Vt,fxr),e(Vt,Dc),e(Dc,mxr),e(Dc,iTe),e(iTe,gxr),e(Dc,hxr),e(Dc,SJ),e(SJ,pxr),e(Dc,uxr),e(Vt,_xr),M(a5,Vt,null),e(pr,bxr),e(pr,Vr),M(gx,Vr,null),e(Vr,vxr),e(Vr,dTe),e(dTe,Fxr),e(Vr,Txr),e(Vr,bn),e(bn,Mxr),e(bn,cTe),e(cTe,Exr),e(bn,Cxr),e(bn,fTe),e(fTe,wxr),e(bn,Axr),e(bn,mTe),e(mTe,yxr),e(bn,Lxr),e(Vr,xxr),e(Vr,Se),e(Se,n5),e(n5,gTe),e(gTe,$xr),e(n5,kxr),e(n5,RJ),e(RJ,Sxr),e(n5,Rxr),e(Se,Bxr),e(Se,s5),e(s5,hTe),e(hTe,Pxr),e(s5,Ixr),e(s5,BJ),e(BJ,qxr),e(s5,Nxr),e(Se,jxr),e(Se,l5),e(l5,pTe),e(pTe,Dxr),e(l5,Gxr),e(l5,PJ),e(PJ,Oxr),e(l5,Vxr),e(Se,Xxr),e(Se,i5),e(i5,uTe),e(uTe,zxr),e(i5,Qxr),e(i5,IJ),e(IJ,Wxr),e(i5,Hxr),e(Se,Uxr),e(Se,d5),e(d5,_Te),e(_Te,Jxr),e(d5,Yxr),e(d5,qJ),e(qJ,Kxr),e(d5,Zxr),e(Se,e7r),e(Se,c5),e(c5,bTe),e(bTe,o7r),e(c5,r7r),e(c5,NJ),e(NJ,t7r),e(c5,a7r),e(Se,n7r),e(Se,f5),e(f5,vTe),e(vTe,s7r),e(f5,l7r),e(f5,jJ),e(jJ,i7r),e(f5,d7r),e(Se,c7r),e(Se,m5),e(m5,FTe),e(FTe,f7r),e(m5,m7r),e(m5,DJ),e(DJ,g7r),e(m5,h7r),e(Se,p7r),e(Se,g5),e(g5,TTe),e(TTe,u7r),e(g5,_7r),e(g5,GJ),e(GJ,b7r),e(g5,v7r),e(Vr,F7r),M(h5,Vr,null),b(f,aqe,_),b(f,Gc,_),e(Gc,p5),e(p5,MTe),M(hx,MTe,null),e(Gc,T7r),e(Gc,ETe),e(ETe,M7r),b(f,nqe,_),b(f,ur,_),M(px,ur,null),e(ur,E7r),e(ur,Oc),e(Oc,C7r),e(Oc,OJ),e(OJ,w7r),e(Oc,A7r),e(Oc,VJ),e(VJ,y7r),e(Oc,L7r),e(ur,x7r),e(ur,ux),e(ux,$7r),e(ux,CTe),e(CTe,k7r),e(ux,S7r),e(ur,R7r),e(ur,Xt),M(_x,Xt,null),e(Xt,B7r),e(Xt,wTe),e(wTe,P7r),e(Xt,I7r),e(Xt,Vc),e(Vc,q7r),e(Vc,ATe),e(ATe,N7r),e(Vc,j7r),e(Vc,XJ),e(XJ,D7r),e(Vc,G7r),e(Xt,O7r),M(u5,Xt,null),e(ur,V7r),e(ur,Xr),M(bx,Xr,null),e(Xr,X7r),e(Xr,yTe),e(yTe,z7r),e(Xr,Q7r),e(Xr,vn),e(vn,W7r),e(vn,LTe),e(LTe,H7r),e(vn,U7r),e(vn,xTe),e(xTe,J7r),e(vn,Y7r),e(vn,$Te),e($Te,K7r),e(vn,Z7r),e(Xr,e$r),e(Xr,xe),e(xe,_5),e(_5,kTe),e(kTe,o$r),e(_5,r$r),e(_5,zJ),e(zJ,t$r),e(_5,a$r),e(xe,n$r),e(xe,b5),e(b5,STe),e(STe,s$r),e(b5,l$r),e(b5,QJ),e(QJ,i$r),e(b5,d$r),e(xe,c$r),e(xe,v5),e(v5,RTe),e(RTe,f$r),e(v5,m$r),e(v5,WJ),e(WJ,g$r),e(v5,h$r),e(xe,p$r),e(xe,F5),e(F5,BTe),e(BTe,u$r),e(F5,_$r),e(F5,HJ),e(HJ,b$r),e(F5,v$r),e(xe,F$r),e(xe,T5),e(T5,PTe),e(PTe,T$r),e(T5,M$r),e(T5,UJ),e(UJ,E$r),e(T5,C$r),e(xe,w$r),e(xe,M5),e(M5,ITe),e(ITe,A$r),e(M5,y$r),e(M5,JJ),e(JJ,L$r),e(M5,x$r),e(xe,$$r),e(xe,E5),e(E5,qTe),e(qTe,k$r),e(E5,S$r),e(E5,YJ),e(YJ,R$r),e(E5,B$r),e(xe,P$r),e(xe,C5),e(C5,NTe),e(NTe,I$r),e(C5,q$r),e(C5,KJ),e(KJ,N$r),e(C5,j$r),e(xe,D$r),e(xe,w5),e(w5,jTe),e(jTe,G$r),e(w5,O$r),e(w5,ZJ),e(ZJ,V$r),e(w5,X$r),e(xe,z$r),e(xe,A5),e(A5,DTe),e(DTe,Q$r),e(A5,W$r),e(A5,eY),e(eY,H$r),e(A5,U$r),e(Xr,J$r),M(y5,Xr,null),b(f,sqe,_),b(f,Xc,_),e(Xc,L5),e(L5,GTe),M(vx,GTe,null),e(Xc,Y$r),e(Xc,OTe),e(OTe,K$r),b(f,lqe,_),b(f,_r,_),M(Fx,_r,null),e(_r,Z$r),e(_r,zc),e(zc,ekr),e(zc,oY),e(oY,okr),e(zc,rkr),e(zc,rY),e(rY,tkr),e(zc,akr),e(_r,nkr),e(_r,Tx),e(Tx,skr),e(Tx,VTe),e(VTe,lkr),e(Tx,ikr),e(_r,dkr),e(_r,zt),M(Mx,zt,null),e(zt,ckr),e(zt,XTe),e(XTe,fkr),e(zt,mkr),e(zt,Qc),e(Qc,gkr),e(Qc,zTe),e(zTe,hkr),e(Qc,pkr),e(Qc,tY),e(tY,ukr),e(Qc,_kr),e(zt,bkr),M(x5,zt,null),e(_r,vkr),e(_r,zr),M(Ex,zr,null),e(zr,Fkr),e(zr,QTe),e(QTe,Tkr),e(zr,Mkr),e(zr,Fn),e(Fn,Ekr),e(Fn,WTe),e(WTe,Ckr),e(Fn,wkr),e(Fn,HTe),e(HTe,Akr),e(Fn,ykr),e(Fn,UTe),e(UTe,Lkr),e(Fn,xkr),e(zr,$kr),e(zr,$e),e($e,$5),e($5,JTe),e(JTe,kkr),e($5,Skr),e($5,aY),e(aY,Rkr),e($5,Bkr),e($e,Pkr),e($e,k5),e(k5,YTe),e(YTe,Ikr),e(k5,qkr),e(k5,nY),e(nY,Nkr),e(k5,jkr),e($e,Dkr),e($e,S5),e(S5,KTe),e(KTe,Gkr),e(S5,Okr),e(S5,sY),e(sY,Vkr),e(S5,Xkr),e($e,zkr),e($e,R5),e(R5,ZTe),e(ZTe,Qkr),e(R5,Wkr),e(R5,lY),e(lY,Hkr),e(R5,Ukr),e($e,Jkr),e($e,B5),e(B5,e9e),e(e9e,Ykr),e(B5,Kkr),e(B5,iY),e(iY,Zkr),e(B5,eSr),e($e,oSr),e($e,P5),e(P5,o9e),e(o9e,rSr),e(P5,tSr),e(P5,dY),e(dY,aSr),e(P5,nSr),e($e,sSr),e($e,I5),e(I5,r9e),e(r9e,lSr),e(I5,iSr),e(I5,cY),e(cY,dSr),e(I5,cSr),e($e,fSr),e($e,q5),e(q5,t9e),e(t9e,mSr),e(q5,gSr),e(q5,fY),e(fY,hSr),e(q5,pSr),e($e,uSr),e($e,N5),e(N5,a9e),e(a9e,_Sr),e(N5,bSr),e(N5,mY),e(mY,vSr),e(N5,FSr),e($e,TSr),e($e,j5),e(j5,n9e),e(n9e,MSr),e(j5,ESr),e(j5,gY),e(gY,CSr),e(j5,wSr),e(zr,ASr),M(D5,zr,null),b(f,iqe,_),b(f,Wc,_),e(Wc,G5),e(G5,s9e),M(Cx,s9e,null),e(Wc,ySr),e(Wc,l9e),e(l9e,LSr),b(f,dqe,_),b(f,br,_),M(wx,br,null),e(br,xSr),e(br,Hc),e(Hc,$Sr),e(Hc,hY),e(hY,kSr),e(Hc,SSr),e(Hc,pY),e(pY,RSr),e(Hc,BSr),e(br,PSr),e(br,Ax),e(Ax,ISr),e(Ax,i9e),e(i9e,qSr),e(Ax,NSr),e(br,jSr),e(br,Qt),M(yx,Qt,null),e(Qt,DSr),e(Qt,d9e),e(d9e,GSr),e(Qt,OSr),e(Qt,Uc),e(Uc,VSr),e(Uc,c9e),e(c9e,XSr),e(Uc,zSr),e(Uc,uY),e(uY,QSr),e(Uc,WSr),e(Qt,HSr),M(O5,Qt,null),e(br,USr),e(br,Qr),M(Lx,Qr,null),e(Qr,JSr),e(Qr,f9e),e(f9e,YSr),e(Qr,KSr),e(Qr,Tn),e(Tn,ZSr),e(Tn,m9e),e(m9e,eRr),e(Tn,oRr),e(Tn,g9e),e(g9e,rRr),e(Tn,tRr),e(Tn,h9e),e(h9e,aRr),e(Tn,nRr),e(Qr,sRr),e(Qr,De),e(De,V5),e(V5,p9e),e(p9e,lRr),e(V5,iRr),e(V5,_Y),e(_Y,dRr),e(V5,cRr),e(De,fRr),e(De,X5),e(X5,u9e),e(u9e,mRr),e(X5,gRr),e(X5,bY),e(bY,hRr),e(X5,pRr),e(De,uRr),e(De,z5),e(z5,_9e),e(_9e,_Rr),e(z5,bRr),e(z5,vY),e(vY,vRr),e(z5,FRr),e(De,TRr),e(De,Q5),e(Q5,b9e),e(b9e,MRr),e(Q5,ERr),e(Q5,FY),e(FY,CRr),e(Q5,wRr),e(De,ARr),e(De,W5),e(W5,v9e),e(v9e,yRr),e(W5,LRr),e(W5,TY),e(TY,xRr),e(W5,$Rr),e(De,kRr),e(De,H5),e(H5,F9e),e(F9e,SRr),e(H5,RRr),e(H5,MY),e(MY,BRr),e(H5,PRr),e(De,IRr),e(De,U5),e(U5,T9e),e(T9e,qRr),e(U5,NRr),e(U5,EY),e(EY,jRr),e(U5,DRr),e(De,GRr),e(De,J5),e(J5,M9e),e(M9e,ORr),e(J5,VRr),e(J5,CY),e(CY,XRr),e(J5,zRr),e(Qr,QRr),M(Y5,Qr,null),b(f,cqe,_),b(f,Jc,_),e(Jc,K5),e(K5,E9e),M(xx,E9e,null),e(Jc,WRr),e(Jc,C9e),e(C9e,HRr),b(f,fqe,_),b(f,vr,_),M($x,vr,null),e(vr,URr),e(vr,Yc),e(Yc,JRr),e(Yc,wY),e(wY,YRr),e(Yc,KRr),e(Yc,AY),e(AY,ZRr),e(Yc,eBr),e(vr,oBr),e(vr,kx),e(kx,rBr),e(kx,w9e),e(w9e,tBr),e(kx,aBr),e(vr,nBr),e(vr,Wt),M(Sx,Wt,null),e(Wt,sBr),e(Wt,A9e),e(A9e,lBr),e(Wt,iBr),e(Wt,Kc),e(Kc,dBr),e(Kc,y9e),e(y9e,cBr),e(Kc,fBr),e(Kc,yY),e(yY,mBr),e(Kc,gBr),e(Wt,hBr),M(Z5,Wt,null),e(vr,pBr),e(vr,Wr),M(Rx,Wr,null),e(Wr,uBr),e(Wr,L9e),e(L9e,_Br),e(Wr,bBr),e(Wr,Mn),e(Mn,vBr),e(Mn,x9e),e(x9e,FBr),e(Mn,TBr),e(Mn,$9e),e($9e,MBr),e(Mn,EBr),e(Mn,k9e),e(k9e,CBr),e(Mn,wBr),e(Wr,ABr),e(Wr,Ge),e(Ge,eC),e(eC,S9e),e(S9e,yBr),e(eC,LBr),e(eC,LY),e(LY,xBr),e(eC,$Br),e(Ge,kBr),e(Ge,oC),e(oC,R9e),e(R9e,SBr),e(oC,RBr),e(oC,xY),e(xY,BBr),e(oC,PBr),e(Ge,IBr),e(Ge,rC),e(rC,B9e),e(B9e,qBr),e(rC,NBr),e(rC,$Y),e($Y,jBr),e(rC,DBr),e(Ge,GBr),e(Ge,tC),e(tC,P9e),e(P9e,OBr),e(tC,VBr),e(tC,kY),e(kY,XBr),e(tC,zBr),e(Ge,QBr),e(Ge,aC),e(aC,I9e),e(I9e,WBr),e(aC,HBr),e(aC,SY),e(SY,UBr),e(aC,JBr),e(Ge,YBr),e(Ge,nC),e(nC,q9e),e(q9e,KBr),e(nC,ZBr),e(nC,RY),e(RY,ePr),e(nC,oPr),e(Ge,rPr),e(Ge,sC),e(sC,N9e),e(N9e,tPr),e(sC,aPr),e(sC,BY),e(BY,nPr),e(sC,sPr),e(Ge,lPr),e(Ge,lC),e(lC,j9e),e(j9e,iPr),e(lC,dPr),e(lC,PY),e(PY,cPr),e(lC,fPr),e(Wr,mPr),M(iC,Wr,null),b(f,mqe,_),b(f,Zc,_),e(Zc,dC),e(dC,D9e),M(Bx,D9e,null),e(Zc,gPr),e(Zc,G9e),e(G9e,hPr),b(f,gqe,_),b(f,Fr,_),M(Px,Fr,null),e(Fr,pPr),e(Fr,ef),e(ef,uPr),e(ef,IY),e(IY,_Pr),e(ef,bPr),e(ef,qY),e(qY,vPr),e(ef,FPr),e(Fr,TPr),e(Fr,Ix),e(Ix,MPr),e(Ix,O9e),e(O9e,EPr),e(Ix,CPr),e(Fr,wPr),e(Fr,Ht),M(qx,Ht,null),e(Ht,APr),e(Ht,V9e),e(V9e,yPr),e(Ht,LPr),e(Ht,of),e(of,xPr),e(of,X9e),e(X9e,$Pr),e(of,kPr),e(of,NY),e(NY,SPr),e(of,RPr),e(Ht,BPr),M(cC,Ht,null),e(Fr,PPr),e(Fr,Hr),M(Nx,Hr,null),e(Hr,IPr),e(Hr,z9e),e(z9e,qPr),e(Hr,NPr),e(Hr,En),e(En,jPr),e(En,Q9e),e(Q9e,DPr),e(En,GPr),e(En,W9e),e(W9e,OPr),e(En,VPr),e(En,H9e),e(H9e,XPr),e(En,zPr),e(Hr,QPr),e(Hr,U9e),e(U9e,fC),e(fC,J9e),e(J9e,WPr),e(fC,HPr),e(fC,jY),e(jY,UPr),e(fC,JPr),e(Hr,YPr),M(mC,Hr,null),b(f,hqe,_),b(f,rf,_),e(rf,gC),e(gC,Y9e),M(jx,Y9e,null),e(rf,KPr),e(rf,K9e),e(K9e,ZPr),b(f,pqe,_),b(f,Tr,_),M(Dx,Tr,null),e(Tr,eIr),e(Tr,tf),e(tf,oIr),e(tf,DY),e(DY,rIr),e(tf,tIr),e(tf,GY),e(GY,aIr),e(tf,nIr),e(Tr,sIr),e(Tr,Gx),e(Gx,lIr),e(Gx,Z9e),e(Z9e,iIr),e(Gx,dIr),e(Tr,cIr),e(Tr,Ut),M(Ox,Ut,null),e(Ut,fIr),e(Ut,eMe),e(eMe,mIr),e(Ut,gIr),e(Ut,af),e(af,hIr),e(af,oMe),e(oMe,pIr),e(af,uIr),e(af,OY),e(OY,_Ir),e(af,bIr),e(Ut,vIr),M(hC,Ut,null),e(Tr,FIr),e(Tr,Ur),M(Vx,Ur,null),e(Ur,TIr),e(Ur,rMe),e(rMe,MIr),e(Ur,EIr),e(Ur,Cn),e(Cn,CIr),e(Cn,tMe),e(tMe,wIr),e(Cn,AIr),e(Cn,aMe),e(aMe,yIr),e(Cn,LIr),e(Cn,nMe),e(nMe,xIr),e(Cn,$Ir),e(Ur,kIr),e(Ur,Xx),e(Xx,pC),e(pC,sMe),e(sMe,SIr),e(pC,RIr),e(pC,VY),e(VY,BIr),e(pC,PIr),e(Xx,IIr),e(Xx,uC),e(uC,lMe),e(lMe,qIr),e(uC,NIr),e(uC,XY),e(XY,jIr),e(uC,DIr),e(Ur,GIr),M(_C,Ur,null),b(f,uqe,_),b(f,nf,_),e(nf,bC),e(bC,iMe),M(zx,iMe,null),e(nf,OIr),e(nf,dMe),e(dMe,VIr),b(f,_qe,_),b(f,Mr,_),M(Qx,Mr,null),e(Mr,XIr),e(Mr,sf),e(sf,zIr),e(sf,zY),e(zY,QIr),e(sf,WIr),e(sf,QY),e(QY,HIr),e(sf,UIr),e(Mr,JIr),e(Mr,Wx),e(Wx,YIr),e(Wx,cMe),e(cMe,KIr),e(Wx,ZIr),e(Mr,eqr),e(Mr,Jt),M(Hx,Jt,null),e(Jt,oqr),e(Jt,fMe),e(fMe,rqr),e(Jt,tqr),e(Jt,lf),e(lf,aqr),e(lf,mMe),e(mMe,nqr),e(lf,sqr),e(lf,WY),e(WY,lqr),e(lf,iqr),e(Jt,dqr),M(vC,Jt,null),e(Mr,cqr),e(Mr,Jr),M(Ux,Jr,null),e(Jr,fqr),e(Jr,gMe),e(gMe,mqr),e(Jr,gqr),e(Jr,wn),e(wn,hqr),e(wn,hMe),e(hMe,pqr),e(wn,uqr),e(wn,pMe),e(pMe,_qr),e(wn,bqr),e(wn,uMe),e(uMe,vqr),e(wn,Fqr),e(Jr,Tqr),e(Jr,_Me),e(_Me,FC),e(FC,bMe),e(bMe,Mqr),e(FC,Eqr),e(FC,HY),e(HY,Cqr),e(FC,wqr),e(Jr,Aqr),M(TC,Jr,null),bqe=!0},p(f,[_]){const Jx={};_&2&&(Jx.$$scope={dirty:_,ctx:f}),_f.$set(Jx);const vMe={};_&2&&(vMe.$$scope={dirty:_,ctx:f}),hg.$set(vMe);const FMe={};_&2&&(FMe.$$scope={dirty:_,ctx:f}),Qg.$set(FMe);const TMe={};_&2&&(TMe.$$scope={dirty:_,ctx:f}),vh.$set(TMe);const Yx={};_&2&&(Yx.$$scope={dirty:_,ctx:f}),Fh.$set(Yx);const MMe={};_&2&&(MMe.$$scope={dirty:_,ctx:f}),qh.$set(MMe);const An={};_&2&&(An.$$scope={dirty:_,ctx:f}),Nh.$set(An);const EMe={};_&2&&(EMe.$$scope={dirty:_,ctx:f}),Gh.$set(EMe);const CMe={};_&2&&(CMe.$$scope={dirty:_,ctx:f}),xu.$set(CMe);const wMe={};_&2&&(wMe.$$scope={dirty:_,ctx:f}),ku.$set(wMe);const Kx={};_&2&&(Kx.$$scope={dirty:_,ctx:f}),b_.$set(Kx);const AMe={};_&2&&(AMe.$$scope={dirty:_,ctx:f}),F_.$set(AMe);const Zx={};_&2&&(Zx.$$scope={dirty:_,ctx:f}),t1.$set(Zx);const yMe={};_&2&&(yMe.$$scope={dirty:_,ctx:f}),n1.$set(yMe);const e7={};_&2&&(e7.$$scope={dirty:_,ctx:f}),O1.$set(e7);const LMe={};_&2&&(LMe.$$scope={dirty:_,ctx:f}),X1.$set(LMe);const xMe={};_&2&&(xMe.$$scope={dirty:_,ctx:f}),d8.$set(xMe);const $Me={};_&2&&($Me.$$scope={dirty:_,ctx:f}),f8.$set($Me);const df={};_&2&&(df.$$scope={dirty:_,ctx:f}),sb.$set(df);const kMe={};_&2&&(kMe.$$scope={dirty:_,ctx:f}),ib.$set(kMe);const SMe={};_&2&&(SMe.$$scope={dirty:_,ctx:f}),jb.$set(SMe);const RMe={};_&2&&(RMe.$$scope={dirty:_,ctx:f}),Gb.$set(RMe);const o7={};_&2&&(o7.$$scope={dirty:_,ctx:f}),Hb.$set(o7);const BMe={};_&2&&(BMe.$$scope={dirty:_,ctx:f}),Jb.$set(BMe);const PMe={};_&2&&(PMe.$$scope={dirty:_,ctx:f}),k2.$set(PMe);const IMe={};_&2&&(IMe.$$scope={dirty:_,ctx:f}),R2.$set(IMe);const Kr={};_&2&&(Kr.$$scope={dirty:_,ctx:f}),Fv.$set(Kr);const r7={};_&2&&(r7.$$scope={dirty:_,ctx:f}),Mv.$set(r7);const qMe={};_&2&&(qMe.$$scope={dirty:_,ctx:f}),wv.$set(qMe);const t7={};_&2&&(t7.$$scope={dirty:_,ctx:f}),yv.$set(t7);const NMe={};_&2&&(NMe.$$scope={dirty:_,ctx:f}),Dv.$set(NMe);const Zr={};_&2&&(Zr.$$scope={dirty:_,ctx:f}),Ov.$set(Zr);const jMe={};_&2&&(jMe.$$scope={dirty:_,ctx:f}),zv.$set(jMe);const cf={};_&2&&(cf.$$scope={dirty:_,ctx:f}),Wv.$set(cf);const DMe={};_&2&&(DMe.$$scope={dirty:_,ctx:f}),tF.$set(DMe);const GMe={};_&2&&(GMe.$$scope={dirty:_,ctx:f}),nF.$set(GMe);const L={};_&2&&(L.$$scope={dirty:_,ctx:f}),fF.$set(L);const MC={};_&2&&(MC.$$scope={dirty:_,ctx:f}),gF.$set(MC);const OMe={};_&2&&(OMe.$$scope={dirty:_,ctx:f}),EF.$set(OMe);const VMe={};_&2&&(VMe.$$scope={dirty:_,ctx:f}),wF.$set(VMe);const EC={};_&2&&(EC.$$scope={dirty:_,ctx:f}),xF.$set(EC);const XMe={};_&2&&(XMe.$$scope={dirty:_,ctx:f}),kF.$set(XMe);const zMe={};_&2&&(zMe.$$scope={dirty:_,ctx:f}),qF.$set(zMe);const CC={};_&2&&(CC.$$scope={dirty:_,ctx:f}),jF.$set(CC);const QMe={};_&2&&(QMe.$$scope={dirty:_,ctx:f}),XF.$set(QMe);const WMe={};_&2&&(WMe.$$scope={dirty:_,ctx:f}),QF.$set(WMe);const wC={};_&2&&(wC.$$scope={dirty:_,ctx:f}),JF.$set(wC);const HMe={};_&2&&(HMe.$$scope={dirty:_,ctx:f}),KF.$set(HMe);const UMe={};_&2&&(UMe.$$scope={dirty:_,ctx:f}),o6.$set(UMe);const AC={};_&2&&(AC.$$scope={dirty:_,ctx:f}),t6.$set(AC);const JMe={};_&2&&(JMe.$$scope={dirty:_,ctx:f}),d6.$set(JMe);const YMe={};_&2&&(YMe.$$scope={dirty:_,ctx:f}),f6.$set(YMe);const yC={};_&2&&(yC.$$scope={dirty:_,ctx:f}),h6.$set(yC);const KMe={};_&2&&(KMe.$$scope={dirty:_,ctx:f}),u6.$set(KMe);const ZMe={};_&2&&(ZMe.$$scope={dirty:_,ctx:f}),iT.$set(ZMe);const LC={};_&2&&(LC.$$scope={dirty:_,ctx:f}),cT.$set(LC);const e4e={};_&2&&(e4e.$$scope={dirty:_,ctx:f}),BT.$set(e4e);const o4e={};_&2&&(o4e.$$scope={dirty:_,ctx:f}),IT.$set(o4e);const xC={};_&2&&(xC.$$scope={dirty:_,ctx:f}),UT.$set(xC);const r4e={};_&2&&(r4e.$$scope={dirty:_,ctx:f}),YT.$set(r4e);const t4e={};_&2&&(t4e.$$scope={dirty:_,ctx:f}),r9.$set(t4e);const $C={};_&2&&($C.$$scope={dirty:_,ctx:f}),a9.$set($C);const a4e={};_&2&&(a4e.$$scope={dirty:_,ctx:f}),w9.$set(a4e);const n4e={};_&2&&(n4e.$$scope={dirty:_,ctx:f}),y9.$set(n4e);const kC={};_&2&&(kC.$$scope={dirty:_,ctx:f}),N9.$set(kC);const s4e={};_&2&&(s4e.$$scope={dirty:_,ctx:f}),D9.$set(s4e);const l4e={};_&2&&(l4e.$$scope={dirty:_,ctx:f}),gM.$set(l4e);const SC={};_&2&&(SC.$$scope={dirty:_,ctx:f}),pM.$set(SC);const i4e={};_&2&&(i4e.$$scope={dirty:_,ctx:f}),RM.$set(i4e);const d4e={};_&2&&(d4e.$$scope={dirty:_,ctx:f}),PM.$set(d4e);const RC={};_&2&&(RC.$$scope={dirty:_,ctx:f}),NM.$set(RC);const c4e={};_&2&&(c4e.$$scope={dirty:_,ctx:f}),DM.$set(c4e);const f4e={};_&2&&(f4e.$$scope={dirty:_,ctx:f}),OM.$set(f4e);const BC={};_&2&&(BC.$$scope={dirty:_,ctx:f}),XM.$set(BC);const m4e={};_&2&&(m4e.$$scope={dirty:_,ctx:f}),f4.$set(m4e);const g4e={};_&2&&(g4e.$$scope={dirty:_,ctx:f}),g4.$set(g4e);const PC={};_&2&&(PC.$$scope={dirty:_,ctx:f}),B4.$set(PC);const h4e={};_&2&&(h4e.$$scope={dirty:_,ctx:f}),I4.$set(h4e);const p4e={};_&2&&(p4e.$$scope={dirty:_,ctx:f}),N4.$set(p4e);const IC={};_&2&&(IC.$$scope={dirty:_,ctx:f}),D4.$set(IC);const u4e={};_&2&&(u4e.$$scope={dirty:_,ctx:f}),O4.$set(u4e);const _4e={};_&2&&(_4e.$$scope={dirty:_,ctx:f}),X4.$set(_4e);const qC={};_&2&&(qC.$$scope={dirty:_,ctx:f}),uE.$set(qC);const b4e={};_&2&&(b4e.$$scope={dirty:_,ctx:f}),bE.$set(b4e);const v4e={};_&2&&(v4e.$$scope={dirty:_,ctx:f}),LE.$set(v4e);const NC={};_&2&&(NC.$$scope={dirty:_,ctx:f}),$E.$set(NC);const F4e={};_&2&&(F4e.$$scope={dirty:_,ctx:f}),VE.$set(F4e);const T4e={};_&2&&(T4e.$$scope={dirty:_,ctx:f}),zE.$set(T4e);const jC={};_&2&&(jC.$$scope={dirty:_,ctx:f}),r5.$set(jC);const M4e={};_&2&&(M4e.$$scope={dirty:_,ctx:f}),a5.$set(M4e);const E4e={};_&2&&(E4e.$$scope={dirty:_,ctx:f}),h5.$set(E4e);const DC={};_&2&&(DC.$$scope={dirty:_,ctx:f}),u5.$set(DC);const C4e={};_&2&&(C4e.$$scope={dirty:_,ctx:f}),y5.$set(C4e);const w4e={};_&2&&(w4e.$$scope={dirty:_,ctx:f}),x5.$set(w4e);const GC={};_&2&&(GC.$$scope={dirty:_,ctx:f}),D5.$set(GC);const A4e={};_&2&&(A4e.$$scope={dirty:_,ctx:f}),O5.$set(A4e);const y4e={};_&2&&(y4e.$$scope={dirty:_,ctx:f}),Y5.$set(y4e);const OC={};_&2&&(OC.$$scope={dirty:_,ctx:f}),Z5.$set(OC);const L4e={};_&2&&(L4e.$$scope={dirty:_,ctx:f}),iC.$set(L4e);const x4e={};_&2&&(x4e.$$scope={dirty:_,ctx:f}),cC.$set(x4e);const VC={};_&2&&(VC.$$scope={dirty:_,ctx:f}),mC.$set(VC);const $4e={};_&2&&($4e.$$scope={dirty:_,ctx:f}),hC.$set($4e);const k4e={};_&2&&(k4e.$$scope={dirty:_,ctx:f}),_C.$set(k4e);const XC={};_&2&&(XC.$$scope={dirty:_,ctx:f}),vC.$set(XC);const S4e={};_&2&&(S4e.$$scope={dirty:_,ctx:f}),TC.$set(S4e)},i(f){bqe||(E(d.$$.fragment,f),E(Ma.$$.fragment,f),E(zw.$$.fragment,f),E(Qw.$$.fragment,f),E(_f.$$.fragment,f),E(Ww.$$.fragment,f),E(Hw.$$.fragment,f),E(Yw.$$.fragment,f),E(hg.$$.fragment,f),E(Kw.$$.fragment,f),E(Zw.$$.fragment,f),E(eA.$$.fragment,f),E(tA.$$.fragment,f),E(Qg.$$.fragment,f),E(aA.$$.fragment,f),E(nA.$$.fragment,f),E(sA.$$.fragment,f),E(dA.$$.fragment,f),E(vh.$$.fragment,f),E(Fh.$$.fragment,f),E(cA.$$.fragment,f),E(fA.$$.fragment,f),E(mA.$$.fragment,f),E(pA.$$.fragment,f),E(qh.$$.fragment,f),E(Nh.$$.fragment,f),E(uA.$$.fragment,f),E(_A.$$.fragment,f),E(bA.$$.fragment,f),E(FA.$$.fragment,f),E(Gh.$$.fragment,f),E(TA.$$.fragment,f),E(xu.$$.fragment,f),E(MA.$$.fragment,f),E(EA.$$.fragment,f),E(wA.$$.fragment,f),E(ku.$$.fragment,f),E(AA.$$.fragment,f),E(b_.$$.fragment,f),E(yA.$$.fragment,f),E(LA.$$.fragment,f),E($A.$$.fragment,f),E(F_.$$.fragment,f),E(kA.$$.fragment,f),E(t1.$$.fragment,f),E(SA.$$.fragment,f),E(RA.$$.fragment,f),E(PA.$$.fragment,f),E(n1.$$.fragment,f),E(IA.$$.fragment,f),E(O1.$$.fragment,f),E(qA.$$.fragment,f),E(NA.$$.fragment,f),E(DA.$$.fragment,f),E(X1.$$.fragment,f),E(GA.$$.fragment,f),E(d8.$$.fragment,f),E(OA.$$.fragment,f),E(VA.$$.fragment,f),E(zA.$$.fragment,f),E(f8.$$.fragment,f),E(QA.$$.fragment,f),E(sb.$$.fragment,f),E(WA.$$.fragment,f),E(HA.$$.fragment,f),E(JA.$$.fragment,f),E(ib.$$.fragment,f),E(YA.$$.fragment,f),E(jb.$$.fragment,f),E(KA.$$.fragment,f),E(ZA.$$.fragment,f),E(o0.$$.fragment,f),E(Gb.$$.fragment,f),E(r0.$$.fragment,f),E(Hb.$$.fragment,f),E(t0.$$.fragment,f),E(a0.$$.fragment,f),E(s0.$$.fragment,f),E(Jb.$$.fragment,f),E(l0.$$.fragment,f),E(k2.$$.fragment,f),E(i0.$$.fragment,f),E(d0.$$.fragment,f),E(f0.$$.fragment,f),E(R2.$$.fragment,f),E(m0.$$.fragment,f),E(Fv.$$.fragment,f),E(g0.$$.fragment,f),E(h0.$$.fragment,f),E(u0.$$.fragment,f),E(Mv.$$.fragment,f),E(_0.$$.fragment,f),E(wv.$$.fragment,f),E(b0.$$.fragment,f),E(v0.$$.fragment,f),E(T0.$$.fragment,f),E(yv.$$.fragment,f),E(M0.$$.fragment,f),E(Dv.$$.fragment,f),E(E0.$$.fragment,f),E(C0.$$.fragment,f),E(A0.$$.fragment,f),E(Ov.$$.fragment,f),E(y0.$$.fragment,f),E(zv.$$.fragment,f),E(L0.$$.fragment,f),E(x0.$$.fragment,f),E(k0.$$.fragment,f),E(Wv.$$.fragment,f),E(S0.$$.fragment,f),E(tF.$$.fragment,f),E(R0.$$.fragment,f),E(B0.$$.fragment,f),E(I0.$$.fragment,f),E(nF.$$.fragment,f),E(q0.$$.fragment,f),E(fF.$$.fragment,f),E(N0.$$.fragment,f),E(j0.$$.fragment,f),E(G0.$$.fragment,f),E(gF.$$.fragment,f),E(O0.$$.fragment,f),E(EF.$$.fragment,f),E(V0.$$.fragment,f),E(X0.$$.fragment,f),E(Q0.$$.fragment,f),E(wF.$$.fragment,f),E(W0.$$.fragment,f),E(xF.$$.fragment,f),E(U0.$$.fragment,f),E(J0.$$.fragment,f),E(K0.$$.fragment,f),E(kF.$$.fragment,f),E(Z0.$$.fragment,f),E(qF.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ty.$$.fragment,f),E(jF.$$.fragment,f),E(ay.$$.fragment,f),E(XF.$$.fragment,f),E(ny.$$.fragment,f),E(sy.$$.fragment,f),E(iy.$$.fragment,f),E(QF.$$.fragment,f),E(dy.$$.fragment,f),E(JF.$$.fragment,f),E(fy.$$.fragment,f),E(my.$$.fragment,f),E(hy.$$.fragment,f),E(KF.$$.fragment,f),E(py.$$.fragment,f),E(o6.$$.fragment,f),E(uy.$$.fragment,f),E(_y.$$.fragment,f),E(vy.$$.fragment,f),E(t6.$$.fragment,f),E(Fy.$$.fragment,f),E(d6.$$.fragment,f),E(Ty.$$.fragment,f),E(My.$$.fragment,f),E(Cy.$$.fragment,f),E(f6.$$.fragment,f),E(wy.$$.fragment,f),E(h6.$$.fragment,f),E(Ay.$$.fragment,f),E(yy.$$.fragment,f),E(xy.$$.fragment,f),E(u6.$$.fragment,f),E($y.$$.fragment,f),E(iT.$$.fragment,f),E(ky.$$.fragment,f),E(Sy.$$.fragment,f),E(By.$$.fragment,f),E(cT.$$.fragment,f),E(Py.$$.fragment,f),E(BT.$$.fragment,f),E(Iy.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(IT.$$.fragment,f),E(Dy.$$.fragment,f),E(UT.$$.fragment,f),E(Gy.$$.fragment,f),E(Oy.$$.fragment,f),E(Xy.$$.fragment,f),E(YT.$$.fragment,f),E(zy.$$.fragment,f),E(r9.$$.fragment,f),E(Qy.$$.fragment,f),E(Wy.$$.fragment,f),E(Uy.$$.fragment,f),E(a9.$$.fragment,f),E(Jy.$$.fragment,f),E(w9.$$.fragment,f),E(Yy.$$.fragment,f),E(Ky.$$.fragment,f),E(eL.$$.fragment,f),E(y9.$$.fragment,f),E(oL.$$.fragment,f),E(N9.$$.fragment,f),E(rL.$$.fragment,f),E(tL.$$.fragment,f),E(nL.$$.fragment,f),E(D9.$$.fragment,f),E(sL.$$.fragment,f),E(gM.$$.fragment,f),E(lL.$$.fragment,f),E(iL.$$.fragment,f),E(cL.$$.fragment,f),E(pM.$$.fragment,f),E(fL.$$.fragment,f),E(RM.$$.fragment,f),E(mL.$$.fragment,f),E(gL.$$.fragment,f),E(pL.$$.fragment,f),E(PM.$$.fragment,f),E(uL.$$.fragment,f),E(NM.$$.fragment,f),E(bL.$$.fragment,f),E(vL.$$.fragment,f),E(TL.$$.fragment,f),E(DM.$$.fragment,f),E(ML.$$.fragment,f),E(OM.$$.fragment,f),E(EL.$$.fragment,f),E(CL.$$.fragment,f),E(AL.$$.fragment,f),E(XM.$$.fragment,f),E(yL.$$.fragment,f),E(f4.$$.fragment,f),E(LL.$$.fragment,f),E(xL.$$.fragment,f),E(kL.$$.fragment,f),E(g4.$$.fragment,f),E(SL.$$.fragment,f),E(B4.$$.fragment,f),E(RL.$$.fragment,f),E(BL.$$.fragment,f),E(IL.$$.fragment,f),E(I4.$$.fragment,f),E(qL.$$.fragment,f),E(N4.$$.fragment,f),E(NL.$$.fragment,f),E(jL.$$.fragment,f),E(GL.$$.fragment,f),E(D4.$$.fragment,f),E(OL.$$.fragment,f),E(O4.$$.fragment,f),E(VL.$$.fragment,f),E(XL.$$.fragment,f),E(QL.$$.fragment,f),E(X4.$$.fragment,f),E(WL.$$.fragment,f),E(uE.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(YL.$$.fragment,f),E(bE.$$.fragment,f),E(KL.$$.fragment,f),E(LE.$$.fragment,f),E(ZL.$$.fragment,f),E(ex.$$.fragment,f),E(rx.$$.fragment,f),E($E.$$.fragment,f),E(tx.$$.fragment,f),E(VE.$$.fragment,f),E(ax.$$.fragment,f),E(nx.$$.fragment,f),E(lx.$$.fragment,f),E(zE.$$.fragment,f),E(ix.$$.fragment,f),E(r5.$$.fragment,f),E(dx.$$.fragment,f),E(cx.$$.fragment,f),E(mx.$$.fragment,f),E(a5.$$.fragment,f),E(gx.$$.fragment,f),E(h5.$$.fragment,f),E(hx.$$.fragment,f),E(px.$$.fragment,f),E(_x.$$.fragment,f),E(u5.$$.fragment,f),E(bx.$$.fragment,f),E(y5.$$.fragment,f),E(vx.$$.fragment,f),E(Fx.$$.fragment,f),E(Mx.$$.fragment,f),E(x5.$$.fragment,f),E(Ex.$$.fragment,f),E(D5.$$.fragment,f),E(Cx.$$.fragment,f),E(wx.$$.fragment,f),E(yx.$$.fragment,f),E(O5.$$.fragment,f),E(Lx.$$.fragment,f),E(Y5.$$.fragment,f),E(xx.$$.fragment,f),E($x.$$.fragment,f),E(Sx.$$.fragment,f),E(Z5.$$.fragment,f),E(Rx.$$.fragment,f),E(iC.$$.fragment,f),E(Bx.$$.fragment,f),E(Px.$$.fragment,f),E(qx.$$.fragment,f),E(cC.$$.fragment,f),E(Nx.$$.fragment,f),E(mC.$$.fragment,f),E(jx.$$.fragment,f),E(Dx.$$.fragment,f),E(Ox.$$.fragment,f),E(hC.$$.fragment,f),E(Vx.$$.fragment,f),E(_C.$$.fragment,f),E(zx.$$.fragment,f),E(Qx.$$.fragment,f),E(Hx.$$.fragment,f),E(vC.$$.fragment,f),E(Ux.$$.fragment,f),E(TC.$$.fragment,f),bqe=!0)},o(f){C(d.$$.fragment,f),C(Ma.$$.fragment,f),C(zw.$$.fragment,f),C(Qw.$$.fragment,f),C(_f.$$.fragment,f),C(Ww.$$.fragment,f),C(Hw.$$.fragment,f),C(Yw.$$.fragment,f),C(hg.$$.fragment,f),C(Kw.$$.fragment,f),C(Zw.$$.fragment,f),C(eA.$$.fragment,f),C(tA.$$.fragment,f),C(Qg.$$.fragment,f),C(aA.$$.fragment,f),C(nA.$$.fragment,f),C(sA.$$.fragment,f),C(dA.$$.fragment,f),C(vh.$$.fragment,f),C(Fh.$$.fragment,f),C(cA.$$.fragment,f),C(fA.$$.fragment,f),C(mA.$$.fragment,f),C(pA.$$.fragment,f),C(qh.$$.fragment,f),C(Nh.$$.fragment,f),C(uA.$$.fragment,f),C(_A.$$.fragment,f),C(bA.$$.fragment,f),C(FA.$$.fragment,f),C(Gh.$$.fragment,f),C(TA.$$.fragment,f),C(xu.$$.fragment,f),C(MA.$$.fragment,f),C(EA.$$.fragment,f),C(wA.$$.fragment,f),C(ku.$$.fragment,f),C(AA.$$.fragment,f),C(b_.$$.fragment,f),C(yA.$$.fragment,f),C(LA.$$.fragment,f),C($A.$$.fragment,f),C(F_.$$.fragment,f),C(kA.$$.fragment,f),C(t1.$$.fragment,f),C(SA.$$.fragment,f),C(RA.$$.fragment,f),C(PA.$$.fragment,f),C(n1.$$.fragment,f),C(IA.$$.fragment,f),C(O1.$$.fragment,f),C(qA.$$.fragment,f),C(NA.$$.fragment,f),C(DA.$$.fragment,f),C(X1.$$.fragment,f),C(GA.$$.fragment,f),C(d8.$$.fragment,f),C(OA.$$.fragment,f),C(VA.$$.fragment,f),C(zA.$$.fragment,f),C(f8.$$.fragment,f),C(QA.$$.fragment,f),C(sb.$$.fragment,f),C(WA.$$.fragment,f),C(HA.$$.fragment,f),C(JA.$$.fragment,f),C(ib.$$.fragment,f),C(YA.$$.fragment,f),C(jb.$$.fragment,f),C(KA.$$.fragment,f),C(ZA.$$.fragment,f),C(o0.$$.fragment,f),C(Gb.$$.fragment,f),C(r0.$$.fragment,f),C(Hb.$$.fragment,f),C(t0.$$.fragment,f),C(a0.$$.fragment,f),C(s0.$$.fragment,f),C(Jb.$$.fragment,f),C(l0.$$.fragment,f),C(k2.$$.fragment,f),C(i0.$$.fragment,f),C(d0.$$.fragment,f),C(f0.$$.fragment,f),C(R2.$$.fragment,f),C(m0.$$.fragment,f),C(Fv.$$.fragment,f),C(g0.$$.fragment,f),C(h0.$$.fragment,f),C(u0.$$.fragment,f),C(Mv.$$.fragment,f),C(_0.$$.fragment,f),C(wv.$$.fragment,f),C(b0.$$.fragment,f),C(v0.$$.fragment,f),C(T0.$$.fragment,f),C(yv.$$.fragment,f),C(M0.$$.fragment,f),C(Dv.$$.fragment,f),C(E0.$$.fragment,f),C(C0.$$.fragment,f),C(A0.$$.fragment,f),C(Ov.$$.fragment,f),C(y0.$$.fragment,f),C(zv.$$.fragment,f),C(L0.$$.fragment,f),C(x0.$$.fragment,f),C(k0.$$.fragment,f),C(Wv.$$.fragment,f),C(S0.$$.fragment,f),C(tF.$$.fragment,f),C(R0.$$.fragment,f),C(B0.$$.fragment,f),C(I0.$$.fragment,f),C(nF.$$.fragment,f),C(q0.$$.fragment,f),C(fF.$$.fragment,f),C(N0.$$.fragment,f),C(j0.$$.fragment,f),C(G0.$$.fragment,f),C(gF.$$.fragment,f),C(O0.$$.fragment,f),C(EF.$$.fragment,f),C(V0.$$.fragment,f),C(X0.$$.fragment,f),C(Q0.$$.fragment,f),C(wF.$$.fragment,f),C(W0.$$.fragment,f),C(xF.$$.fragment,f),C(U0.$$.fragment,f),C(J0.$$.fragment,f),C(K0.$$.fragment,f),C(kF.$$.fragment,f),C(Z0.$$.fragment,f),C(qF.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ty.$$.fragment,f),C(jF.$$.fragment,f),C(ay.$$.fragment,f),C(XF.$$.fragment,f),C(ny.$$.fragment,f),C(sy.$$.fragment,f),C(iy.$$.fragment,f),C(QF.$$.fragment,f),C(dy.$$.fragment,f),C(JF.$$.fragment,f),C(fy.$$.fragment,f),C(my.$$.fragment,f),C(hy.$$.fragment,f),C(KF.$$.fragment,f),C(py.$$.fragment,f),C(o6.$$.fragment,f),C(uy.$$.fragment,f),C(_y.$$.fragment,f),C(vy.$$.fragment,f),C(t6.$$.fragment,f),C(Fy.$$.fragment,f),C(d6.$$.fragment,f),C(Ty.$$.fragment,f),C(My.$$.fragment,f),C(Cy.$$.fragment,f),C(f6.$$.fragment,f),C(wy.$$.fragment,f),C(h6.$$.fragment,f),C(Ay.$$.fragment,f),C(yy.$$.fragment,f),C(xy.$$.fragment,f),C(u6.$$.fragment,f),C($y.$$.fragment,f),C(iT.$$.fragment,f),C(ky.$$.fragment,f),C(Sy.$$.fragment,f),C(By.$$.fragment,f),C(cT.$$.fragment,f),C(Py.$$.fragment,f),C(BT.$$.fragment,f),C(Iy.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(IT.$$.fragment,f),C(Dy.$$.fragment,f),C(UT.$$.fragment,f),C(Gy.$$.fragment,f),C(Oy.$$.fragment,f),C(Xy.$$.fragment,f),C(YT.$$.fragment,f),C(zy.$$.fragment,f),C(r9.$$.fragment,f),C(Qy.$$.fragment,f),C(Wy.$$.fragment,f),C(Uy.$$.fragment,f),C(a9.$$.fragment,f),C(Jy.$$.fragment,f),C(w9.$$.fragment,f),C(Yy.$$.fragment,f),C(Ky.$$.fragment,f),C(eL.$$.fragment,f),C(y9.$$.fragment,f),C(oL.$$.fragment,f),C(N9.$$.fragment,f),C(rL.$$.fragment,f),C(tL.$$.fragment,f),C(nL.$$.fragment,f),C(D9.$$.fragment,f),C(sL.$$.fragment,f),C(gM.$$.fragment,f),C(lL.$$.fragment,f),C(iL.$$.fragment,f),C(cL.$$.fragment,f),C(pM.$$.fragment,f),C(fL.$$.fragment,f),C(RM.$$.fragment,f),C(mL.$$.fragment,f),C(gL.$$.fragment,f),C(pL.$$.fragment,f),C(PM.$$.fragment,f),C(uL.$$.fragment,f),C(NM.$$.fragment,f),C(bL.$$.fragment,f),C(vL.$$.fragment,f),C(TL.$$.fragment,f),C(DM.$$.fragment,f),C(ML.$$.fragment,f),C(OM.$$.fragment,f),C(EL.$$.fragment,f),C(CL.$$.fragment,f),C(AL.$$.fragment,f),C(XM.$$.fragment,f),C(yL.$$.fragment,f),C(f4.$$.fragment,f),C(LL.$$.fragment,f),C(xL.$$.fragment,f),C(kL.$$.fragment,f),C(g4.$$.fragment,f),C(SL.$$.fragment,f),C(B4.$$.fragment,f),C(RL.$$.fragment,f),C(BL.$$.fragment,f),C(IL.$$.fragment,f),C(I4.$$.fragment,f),C(qL.$$.fragment,f),C(N4.$$.fragment,f),C(NL.$$.fragment,f),C(jL.$$.fragment,f),C(GL.$$.fragment,f),C(D4.$$.fragment,f),C(OL.$$.fragment,f),C(O4.$$.fragment,f),C(VL.$$.fragment,f),C(XL.$$.fragment,f),C(QL.$$.fragment,f),C(X4.$$.fragment,f),C(WL.$$.fragment,f),C(uE.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(YL.$$.fragment,f),C(bE.$$.fragment,f),C(KL.$$.fragment,f),C(LE.$$.fragment,f),C(ZL.$$.fragment,f),C(ex.$$.fragment,f),C(rx.$$.fragment,f),C($E.$$.fragment,f),C(tx.$$.fragment,f),C(VE.$$.fragment,f),C(ax.$$.fragment,f),C(nx.$$.fragment,f),C(lx.$$.fragment,f),C(zE.$$.fragment,f),C(ix.$$.fragment,f),C(r5.$$.fragment,f),C(dx.$$.fragment,f),C(cx.$$.fragment,f),C(mx.$$.fragment,f),C(a5.$$.fragment,f),C(gx.$$.fragment,f),C(h5.$$.fragment,f),C(hx.$$.fragment,f),C(px.$$.fragment,f),C(_x.$$.fragment,f),C(u5.$$.fragment,f),C(bx.$$.fragment,f),C(y5.$$.fragment,f),C(vx.$$.fragment,f),C(Fx.$$.fragment,f),C(Mx.$$.fragment,f),C(x5.$$.fragment,f),C(Ex.$$.fragment,f),C(D5.$$.fragment,f),C(Cx.$$.fragment,f),C(wx.$$.fragment,f),C(yx.$$.fragment,f),C(O5.$$.fragment,f),C(Lx.$$.fragment,f),C(Y5.$$.fragment,f),C(xx.$$.fragment,f),C($x.$$.fragment,f),C(Sx.$$.fragment,f),C(Z5.$$.fragment,f),C(Rx.$$.fragment,f),C(iC.$$.fragment,f),C(Bx.$$.fragment,f),C(Px.$$.fragment,f),C(qx.$$.fragment,f),C(cC.$$.fragment,f),C(Nx.$$.fragment,f),C(mC.$$.fragment,f),C(jx.$$.fragment,f),C(Dx.$$.fragment,f),C(Ox.$$.fragment,f),C(hC.$$.fragment,f),C(Vx.$$.fragment,f),C(_C.$$.fragment,f),C(zx.$$.fragment,f),C(Qx.$$.fragment,f),C(Hx.$$.fragment,f),C(vC.$$.fragment,f),C(Ux.$$.fragment,f),C(TC.$$.fragment,f),bqe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(mf),f&&t(et),f&&t(qe),f&&t(Xe),f&&t(hf),w(Ma,f),f&&t(ze),f&&t(Ae),f&&t(Eo),f&&t(Ea),f&&t(pPe),f&&t(pi),w(zw),f&&t(uPe),f&&t(kn),f&&t(_Pe),w(Qw,f),f&&t(bPe),f&&t(g$),f&&t(vPe),w(_f,f),f&&t(FPe),f&&t(ui),w(Ww),f&&t(TPe),f&&t(Co),w(Hw),w(Yw),w(hg),w(Kw),f&&t(MPe),f&&t(bi),w(Zw),f&&t(EPe),f&&t(wo),w(eA),w(tA),w(Qg),w(aA),f&&t(CPe),f&&t(vi),w(nA),f&&t(wPe),f&&t(Ao),w(sA),w(dA),w(vh),w(Fh),w(cA),f&&t(APe),f&&t(Fi),w(fA),f&&t(yPe),f&&t(yo),w(mA),w(pA),w(qh),w(Nh),w(uA),f&&t(LPe),f&&t(Mi),w(_A),f&&t(xPe),f&&t(Lo),w(bA),w(FA),w(Gh),w(TA),w(xu),f&&t($Pe),f&&t(wi),w(MA),f&&t(kPe),f&&t(xo),w(EA),w(wA),w(ku),w(AA),w(b_),f&&t(SPe),f&&t(Li),w(yA),f&&t(RPe),f&&t($o),w(LA),w($A),w(F_),w(kA),w(t1),f&&t(BPe),f&&t(ki),w(SA),f&&t(PPe),f&&t(ko),w(RA),w(PA),w(n1),w(IA),w(O1),f&&t(IPe),f&&t(Bi),w(qA),f&&t(qPe),f&&t(So),w(NA),w(DA),w(X1),w(GA),w(d8),f&&t(NPe),f&&t(qi),w(OA),f&&t(jPe),f&&t(Ro),w(VA),w(zA),w(f8),w(QA),w(sb),f&&t(DPe),f&&t(Di),w(WA),f&&t(GPe),f&&t(Bo),w(HA),w(JA),w(ib),w(YA),w(jb),f&&t(OPe),f&&t(Vi),w(KA),f&&t(VPe),f&&t(Po),w(ZA),w(o0),w(Gb),w(r0),w(Hb),f&&t(XPe),f&&t(Qi),w(t0),f&&t(zPe),f&&t(Io),w(a0),w(s0),w(Jb),w(l0),w(k2),f&&t(QPe),f&&t(Ui),w(i0),f&&t(WPe),f&&t(qo),w(d0),w(f0),w(R2),w(m0),w(Fv),f&&t(HPe),f&&t(Ki),w(g0),f&&t(UPe),f&&t(No),w(h0),w(u0),w(Mv),w(_0),w(wv),f&&t(JPe),f&&t(od),w(b0),f&&t(YPe),f&&t(jo),w(v0),w(T0),w(yv),w(M0),w(Dv),f&&t(KPe),f&&t(ad),w(E0),f&&t(ZPe),f&&t(Do),w(C0),w(A0),w(Ov),w(y0),w(zv),f&&t(eIe),f&&t(ld),w(L0),f&&t(oIe),f&&t(Go),w(x0),w(k0),w(Wv),w(S0),w(tF),f&&t(rIe),f&&t(cd),w(R0),f&&t(tIe),f&&t(Oo),w(B0),w(I0),w(nF),w(q0),w(fF),f&&t(aIe),f&&t(gd),w(N0),f&&t(nIe),f&&t(Vo),w(j0),w(G0),w(gF),w(O0),w(EF),f&&t(sIe),f&&t(ud),w(V0),f&&t(lIe),f&&t(Xo),w(X0),w(Q0),w(wF),w(W0),w(xF),f&&t(iIe),f&&t(vd),w(U0),f&&t(dIe),f&&t(zo),w(J0),w(K0),w(kF),w(Z0),w(qF),f&&t(cIe),f&&t(Md),w(ey),f&&t(fIe),f&&t(Qo),w(oy),w(ty),w(jF),w(ay),w(XF),f&&t(mIe),f&&t(Ad),w(ny),f&&t(gIe),f&&t(Wo),w(sy),w(iy),w(QF),w(dy),w(JF),f&&t(hIe),f&&t(xd),w(fy),f&&t(pIe),f&&t(Ho),w(my),w(hy),w(KF),w(py),w(o6),f&&t(uIe),f&&t(Sd),w(uy),f&&t(_Ie),f&&t(Uo),w(_y),w(vy),w(t6),w(Fy),w(d6),f&&t(bIe),f&&t(Pd),w(Ty),f&&t(vIe),f&&t(Jo),w(My),w(Cy),w(f6),w(wy),w(h6),f&&t(FIe),f&&t(Nd),w(Ay),f&&t(TIe),f&&t(Yo),w(yy),w(xy),w(u6),w($y),w(iT),f&&t(MIe),f&&t(Gd),w(ky),f&&t(EIe),f&&t(Ko),w(Sy),w(By),w(cT),w(Py),w(BT),f&&t(CIe),f&&t(Xd),w(Iy),f&&t(wIe),f&&t(Zo),w(qy),w(jy),w(IT),w(Dy),w(UT),f&&t(AIe),f&&t(Wd),w(Gy),f&&t(yIe),f&&t(er),w(Oy),w(Xy),w(YT),w(zy),w(r9),f&&t(LIe),f&&t(Jd),w(Qy),f&&t(xIe),f&&t(or),w(Wy),w(Uy),w(a9),w(Jy),w(w9),f&&t($Ie),f&&t(Zd),w(Yy),f&&t(kIe),f&&t(rr),w(Ky),w(eL),w(y9),w(oL),w(N9),f&&t(SIe),f&&t(rc),w(rL),f&&t(RIe),f&&t(tr),w(tL),w(nL),w(D9),w(sL),w(gM),f&&t(BIe),f&&t(nc),w(lL),f&&t(PIe),f&&t(ar),w(iL),w(cL),w(pM),w(fL),w(RM),f&&t(IIe),f&&t(ic),w(mL),f&&t(qIe),f&&t(nr),w(gL),w(pL),w(PM),w(uL),w(NM),f&&t(NIe),f&&t(fc),w(bL),f&&t(jIe),f&&t(sr),w(vL),w(TL),w(DM),w(ML),w(OM),f&&t(DIe),f&&t(hc),w(EL),f&&t(GIe),f&&t(lr),w(CL),w(AL),w(XM),w(yL),w(f4),f&&t(OIe),f&&t(_c),w(LL),f&&t(VIe),f&&t(ir),w(xL),w(kL),w(g4),w(SL),w(B4),f&&t(XIe),f&&t(Fc),w(RL),f&&t(zIe),f&&t(dr),w(BL),w(IL),w(I4),w(qL),w(N4),f&&t(QIe),f&&t(Ec),w(NL),f&&t(WIe),f&&t(cr),w(jL),w(GL),w(D4),w(OL),w(O4),f&&t(HIe),f&&t(Ac),w(VL),f&&t(UIe),f&&t(fr),w(XL),w(QL),w(X4),w(WL),w(uE),f&&t(JIe),f&&t(xc),w(HL),f&&t(YIe),f&&t(mr),w(UL),w(YL),w(bE),w(KL),w(LE),f&&t(KIe),f&&t(Sc),w(ZL),f&&t(ZIe),f&&t(gr),w(ex),w(rx),w($E),w(tx),w(VE),f&&t(eqe),f&&t(Pc),w(ax),f&&t(oqe),f&&t(hr),w(nx),w(lx),w(zE),w(ix),w(r5),f&&t(rqe),f&&t(Nc),w(dx),f&&t(tqe),f&&t(pr),w(cx),w(mx),w(a5),w(gx),w(h5),f&&t(aqe),f&&t(Gc),w(hx),f&&t(nqe),f&&t(ur),w(px),w(_x),w(u5),w(bx),w(y5),f&&t(sqe),f&&t(Xc),w(vx),f&&t(lqe),f&&t(_r),w(Fx),w(Mx),w(x5),w(Ex),w(D5),f&&t(iqe),f&&t(Wc),w(Cx),f&&t(dqe),f&&t(br),w(wx),w(yx),w(O5),w(Lx),w(Y5),f&&t(cqe),f&&t(Jc),w(xx),f&&t(fqe),f&&t(vr),w($x),w(Sx),w(Z5),w(Rx),w(iC),f&&t(mqe),f&&t(Zc),w(Bx),f&&t(gqe),f&&t(Fr),w(Px),w(qx),w(cC),w(Nx),w(mC),f&&t(hqe),f&&t(rf),w(jx),f&&t(pqe),f&&t(Tr),w(Dx),w(Ox),w(hC),w(Vx),w(_C),f&&t(uqe),f&&t(nf),w(zx),f&&t(_qe),f&&t(Mr),w(Qx),w(Hx),w(vC),w(Ux),w(TC)}}}const GAt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function OAt(A){return O3t(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class UAt extends N3t{constructor(g){super();j3t(this,g,OAt,DAt,D3t,{})}}export{UAt as default,GAt as metadata};
