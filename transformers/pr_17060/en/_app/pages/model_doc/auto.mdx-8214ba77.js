import{S as zyt,i as Qyt,s as Wyt,e as a,k as l,w as F,t as o,M as Hyt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,F as e,g as b,y as M,q as E,o as C,B as w,v as Uyt,L as I}from"../../chunks/vendor-6b77c823.js";import{T as tDr}from"../../chunks/Tip-39098574.js";import{D as R}from"../../chunks/Docstring-1088f2fb.js";import{C as B}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as oe}from"../../chunks/IconCopyLink-7a11ce68.js";import{E as P}from"../../chunks/ExampleCodeBlock-5212b321.js";function Jyt(L){let g,v,p,m,u,d,h,Mo,ii,gf,et,di,ci,oA,hf,qe,Xe,fi,An,rA,yn,Ln,tA,mi,xn,aA,gi,pf,Ma;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),ii=a("code"),gf=o("model_type"),et=o(" attribute is set to the same key you use when registering the config (here "),di=a("code"),ci=o('"new-model"'),oA=o(")."),hf=l(),qe=a("p"),Xe=o("Likewise, if your "),fi=a("code"),An=o("NewModel"),rA=o(" is a subclass of "),yn=a("a"),Ln=o("PreTrainedModel"),tA=o(`, make sure its
`),mi=a("code"),xn=o("config_class"),aA=o(` attribute is set to the same class you use when registering the model (here
`),gi=a("code"),pf=o("NewModelConfig"),Ma=o(")."),this.h()},l(ze){g=n(ze,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var E$=s(p);m=r(E$,"NewModelConfig"),E$.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var hi=s(d);h=r(hi,"PretrainedConfig"),hi.forEach(t),Mo=r(Ae,`, make sure its
`),ii=n(Ae,"CODE",{});var C$=s(ii);gf=r(C$,"model_type"),C$.forEach(t),et=r(Ae," attribute is set to the same key you use when registering the config (here "),di=n(Ae,"CODE",{});var w$=s(di);ci=r(w$,'"new-model"'),w$.forEach(t),oA=r(Ae,")."),Ae.forEach(t),hf=i(ze),qe=n(ze,"P",{});var Eo=s(qe);Xe=r(Eo,"Likewise, if your "),fi=n(Eo,"CODE",{});var Ea=s(fi);An=r(Ea,"NewModel"),Ea.forEach(t),rA=r(Eo," is a subclass of "),yn=n(Eo,"A",{href:!0});var A$=s(yn);Ln=r(A$,"PreTrainedModel"),A$.forEach(t),tA=r(Eo,`, make sure its
`),mi=n(Eo,"CODE",{});var uf=s(mi);xn=r(uf,"config_class"),uf.forEach(t),aA=r(Eo,` attribute is set to the same class you use when registering the model (here
`),gi=n(Eo,"CODE",{});var y$=s(gi);pf=r(y$,"NewModelConfig"),y$.forEach(t),Ma=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(yn,"href","/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel")},m(ze,Ae){b(ze,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Mo),e(g,ii),e(ii,gf),e(g,et),e(g,di),e(di,ci),e(g,oA),b(ze,hf,Ae),b(ze,qe,Ae),e(qe,Xe),e(qe,fi),e(fi,An),e(qe,rA),e(qe,yn),e(yn,Ln),e(qe,tA),e(qe,mi),e(mi,xn),e(qe,aA),e(qe,gi),e(gi,pf),e(qe,Ma)},d(ze){ze&&t(g),ze&&t(hf),ze&&t(qe)}}}function Yyt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kyt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zyt(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function eLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oLt(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function rLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Lt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ELt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ALt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Lt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ILt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ULt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZLt(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function e8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function o8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function r8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function t8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function a8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function n8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function s8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function l8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function i8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function d8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function c8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function f8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function m8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function g8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function h8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function p8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function u8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function b8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function v8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function F8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function T8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function M8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function E8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function C8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function w8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function A8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function y8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function L8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function x8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function k8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function S8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function R8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function B8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function P8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function I8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function q8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function N8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function j8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function D8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function G8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function O8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function V8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function X8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function z8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Q8t(L){let g,v,p,m,u;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function W8t(L){let g,v,p,m,u,d,h,Mo,ii,gf,et,di,ci,oA,hf,qe,Xe,fi,An,rA,yn,Ln,tA,mi,xn,aA,gi,pf,Ma,ze,Ae,E$,hi,C$,w$,Eo,Ea,A$,uf,y$,RDe,MIe,pi,_f,bee,nA,BDe,vee,PDe,EIe,$n,IDe,Fee,qDe,NDe,Tee,jDe,DDe,CIe,sA,wIe,L$,GDe,AIe,bf,yIe,ui,vf,Mee,lA,ODe,Eee,VDe,LIe,Co,iA,XDe,dA,zDe,x$,QDe,WDe,HDe,cA,UDe,Cee,JDe,YDe,KDe,Er,fA,ZDe,wee,eGe,oGe,_i,rGe,Aee,tGe,aGe,yee,nGe,sGe,lGe,A,Ff,Lee,iGe,dGe,$$,cGe,fGe,mGe,Tf,xee,gGe,hGe,k$,pGe,uGe,_Ge,Mf,$ee,bGe,vGe,S$,FGe,TGe,MGe,Ef,kee,EGe,CGe,R$,wGe,AGe,yGe,Cf,See,LGe,xGe,B$,$Ge,kGe,SGe,wf,Ree,RGe,BGe,P$,PGe,IGe,qGe,Af,Bee,NGe,jGe,I$,DGe,GGe,OGe,yf,Pee,VGe,XGe,q$,zGe,QGe,WGe,Lf,Iee,HGe,UGe,N$,JGe,YGe,KGe,xf,qee,ZGe,eOe,j$,oOe,rOe,tOe,$f,Nee,aOe,nOe,D$,sOe,lOe,iOe,kf,jee,dOe,cOe,G$,fOe,mOe,gOe,Sf,Dee,hOe,pOe,O$,uOe,_Oe,bOe,Rf,Gee,vOe,FOe,V$,TOe,MOe,EOe,Bf,Oee,COe,wOe,X$,AOe,yOe,LOe,Pf,Vee,xOe,$Oe,z$,kOe,SOe,ROe,If,Xee,BOe,POe,Q$,IOe,qOe,NOe,qf,zee,jOe,DOe,W$,GOe,OOe,VOe,Nf,Qee,XOe,zOe,H$,QOe,WOe,HOe,jf,Wee,UOe,JOe,U$,YOe,KOe,ZOe,Df,Hee,eVe,oVe,J$,rVe,tVe,aVe,Gf,Uee,nVe,sVe,Y$,lVe,iVe,dVe,Of,Jee,cVe,fVe,K$,mVe,gVe,hVe,Vf,Yee,pVe,uVe,Z$,_Ve,bVe,vVe,Xf,Kee,FVe,TVe,ek,MVe,EVe,CVe,zf,Zee,wVe,AVe,ok,yVe,LVe,xVe,Qf,eoe,$Ve,kVe,rk,SVe,RVe,BVe,Wf,ooe,PVe,IVe,tk,qVe,NVe,jVe,Hf,roe,DVe,GVe,ak,OVe,VVe,XVe,Uf,toe,zVe,QVe,nk,WVe,HVe,UVe,Jf,aoe,JVe,YVe,sk,KVe,ZVe,eXe,Yf,noe,oXe,rXe,lk,tXe,aXe,nXe,Kf,soe,sXe,lXe,ik,iXe,dXe,cXe,Zf,loe,fXe,mXe,dk,gXe,hXe,pXe,em,ioe,uXe,_Xe,ck,bXe,vXe,FXe,om,doe,TXe,MXe,fk,EXe,CXe,wXe,rm,coe,AXe,yXe,mk,LXe,xXe,$Xe,tm,foe,kXe,SXe,gk,RXe,BXe,PXe,am,moe,IXe,qXe,hk,NXe,jXe,DXe,nm,goe,GXe,OXe,pk,VXe,XXe,zXe,sm,hoe,QXe,WXe,uk,HXe,UXe,JXe,lm,poe,YXe,KXe,_k,ZXe,eze,oze,im,uoe,rze,tze,bk,aze,nze,sze,dm,_oe,lze,ize,vk,dze,cze,fze,cm,boe,mze,gze,Fk,hze,pze,uze,fm,voe,_ze,bze,Tk,vze,Fze,Tze,mm,Foe,Mze,Eze,Mk,Cze,wze,Aze,gm,Toe,yze,Lze,Ek,xze,$ze,kze,hm,Moe,Sze,Rze,Ck,Bze,Pze,Ize,pm,Eoe,qze,Nze,wk,jze,Dze,Gze,um,Coe,Oze,Vze,Ak,Xze,zze,Qze,_m,woe,Wze,Hze,yk,Uze,Jze,Yze,bm,Aoe,Kze,Zze,Lk,eQe,oQe,rQe,vm,yoe,tQe,aQe,xk,nQe,sQe,lQe,Fm,Loe,iQe,dQe,$k,cQe,fQe,mQe,Tm,xoe,gQe,hQe,kk,pQe,uQe,_Qe,Mm,$oe,bQe,vQe,Sk,FQe,TQe,MQe,Em,koe,EQe,CQe,Rk,wQe,AQe,yQe,Cm,Soe,LQe,xQe,Bk,$Qe,kQe,SQe,wm,Roe,RQe,BQe,Pk,PQe,IQe,qQe,Am,Boe,NQe,jQe,Ik,DQe,GQe,OQe,ym,Poe,VQe,XQe,qk,zQe,QQe,WQe,Lm,Ioe,HQe,UQe,Nk,JQe,YQe,KQe,xm,qoe,ZQe,eWe,jk,oWe,rWe,tWe,$m,Noe,aWe,nWe,Dk,sWe,lWe,iWe,km,joe,dWe,cWe,Gk,fWe,mWe,gWe,Sm,Doe,hWe,pWe,Ok,uWe,_We,bWe,Rm,Goe,vWe,FWe,Vk,TWe,MWe,EWe,Bm,Ooe,CWe,wWe,Xk,AWe,yWe,LWe,Pm,Voe,xWe,$We,zk,kWe,SWe,RWe,Im,Xoe,BWe,PWe,Qk,IWe,qWe,NWe,qm,zoe,jWe,DWe,Wk,GWe,OWe,VWe,Nm,Qoe,XWe,zWe,Hk,QWe,WWe,HWe,jm,Woe,UWe,JWe,Uk,YWe,KWe,ZWe,Dm,Hoe,eHe,oHe,Jk,rHe,tHe,aHe,Gm,Uoe,nHe,sHe,Yk,lHe,iHe,dHe,Om,Joe,cHe,fHe,Kk,mHe,gHe,hHe,Vm,Yoe,pHe,uHe,Zk,_He,bHe,vHe,Xm,Koe,FHe,THe,eS,MHe,EHe,CHe,zm,Zoe,wHe,AHe,oS,yHe,LHe,xHe,Qm,ere,$He,kHe,rS,SHe,RHe,BHe,Wm,ore,PHe,IHe,tS,qHe,NHe,jHe,Hm,rre,DHe,GHe,aS,OHe,VHe,XHe,Um,tre,zHe,QHe,nS,WHe,HHe,UHe,Jm,are,JHe,YHe,sS,KHe,ZHe,eUe,Ym,nre,oUe,rUe,lS,tUe,aUe,nUe,Km,sre,sUe,lUe,iS,iUe,dUe,cUe,Zm,lre,fUe,mUe,dS,gUe,hUe,pUe,eg,ire,uUe,_Ue,cS,bUe,vUe,FUe,og,dre,TUe,MUe,fS,EUe,CUe,wUe,rg,cre,AUe,yUe,mS,LUe,xUe,$Ue,tg,fre,kUe,SUe,gS,RUe,BUe,PUe,ag,mre,IUe,qUe,hS,NUe,jUe,DUe,ng,gre,GUe,OUe,pS,VUe,XUe,zUe,sg,hre,QUe,WUe,uS,HUe,UUe,JUe,lg,pre,YUe,KUe,_S,ZUe,eJe,oJe,ig,ure,rJe,tJe,bS,aJe,nJe,sJe,dg,_re,lJe,iJe,vS,dJe,cJe,fJe,cg,bre,mJe,gJe,FS,hJe,pJe,uJe,fg,vre,_Je,bJe,TS,vJe,FJe,TJe,mg,Fre,MJe,EJe,MS,CJe,wJe,AJe,gg,Tre,yJe,LJe,ES,xJe,$Je,kJe,hg,Mre,SJe,RJe,CS,BJe,PJe,IJe,pg,Ere,qJe,NJe,wS,jJe,DJe,GJe,ug,Cre,OJe,VJe,AS,XJe,zJe,QJe,_g,wre,WJe,HJe,yS,UJe,JJe,YJe,bg,KJe,vg,mA,ZJe,Are,eYe,xIe,bi,Fg,yre,gA,oYe,Lre,rYe,$Ie,wo,hA,tYe,pA,aYe,LS,nYe,sYe,lYe,uA,iYe,xre,dYe,cYe,fYe,Cr,_A,mYe,$re,gYe,hYe,Ca,pYe,kre,uYe,_Ye,Sre,bYe,vYe,Rre,FYe,TYe,MYe,k,kn,Bre,EYe,CYe,xS,wYe,AYe,$S,yYe,LYe,xYe,Sn,Pre,$Ye,kYe,kS,SYe,RYe,SS,BYe,PYe,IYe,Rn,Ire,qYe,NYe,RS,jYe,DYe,BS,GYe,OYe,VYe,Tg,qre,XYe,zYe,PS,QYe,WYe,HYe,Bn,Nre,UYe,JYe,IS,YYe,KYe,qS,ZYe,eKe,oKe,Mg,jre,rKe,tKe,NS,aKe,nKe,sKe,Eg,Dre,lKe,iKe,jS,dKe,cKe,fKe,Cg,Gre,mKe,gKe,DS,hKe,pKe,uKe,Pn,Ore,_Ke,bKe,GS,vKe,FKe,OS,TKe,MKe,EKe,In,Vre,CKe,wKe,VS,AKe,yKe,XS,LKe,xKe,$Ke,qn,Xre,kKe,SKe,zS,RKe,BKe,QS,PKe,IKe,qKe,wg,zre,NKe,jKe,WS,DKe,GKe,OKe,Ag,Qre,VKe,XKe,HS,zKe,QKe,WKe,Nn,Wre,HKe,UKe,US,JKe,YKe,JS,KKe,ZKe,eZe,yg,Hre,oZe,rZe,YS,tZe,aZe,nZe,jn,Ure,sZe,lZe,KS,iZe,dZe,ZS,cZe,fZe,mZe,Dn,Jre,gZe,hZe,eR,pZe,uZe,oR,_Ze,bZe,vZe,Gn,Yre,FZe,TZe,rR,MZe,EZe,tR,CZe,wZe,AZe,Lg,Kre,yZe,LZe,aR,xZe,$Ze,kZe,On,Zre,SZe,RZe,nR,BZe,PZe,sR,IZe,qZe,NZe,Vn,ete,jZe,DZe,lR,GZe,OZe,iR,VZe,XZe,zZe,Xn,ote,QZe,WZe,dR,HZe,UZe,cR,JZe,YZe,KZe,zn,rte,ZZe,eeo,fR,oeo,reo,mR,teo,aeo,neo,Qn,tte,seo,leo,gR,ieo,deo,hR,ceo,feo,meo,Wn,ate,geo,heo,pR,peo,ueo,uR,_eo,beo,veo,xg,nte,Feo,Teo,_R,Meo,Eeo,Ceo,Hn,ste,weo,Aeo,bR,yeo,Leo,vR,xeo,$eo,keo,$g,lte,Seo,Reo,FR,Beo,Peo,Ieo,Un,ite,qeo,Neo,TR,jeo,Deo,MR,Geo,Oeo,Veo,Jn,dte,Xeo,zeo,ER,Qeo,Weo,CR,Heo,Ueo,Jeo,Yn,cte,Yeo,Keo,wR,Zeo,eoo,AR,ooo,roo,too,Kn,fte,aoo,noo,yR,soo,loo,LR,ioo,doo,coo,Zn,mte,foo,moo,xR,goo,hoo,$R,poo,uoo,_oo,kg,gte,boo,voo,kR,Foo,Too,Moo,es,hte,Eoo,Coo,SR,woo,Aoo,RR,yoo,Loo,xoo,os,pte,$oo,koo,BR,Soo,Roo,PR,Boo,Poo,Ioo,rs,ute,qoo,Noo,IR,joo,Doo,qR,Goo,Ooo,Voo,ts,_te,Xoo,zoo,NR,Qoo,Woo,jR,Hoo,Uoo,Joo,as,bte,Yoo,Koo,DR,Zoo,ero,GR,oro,rro,tro,ns,vte,aro,nro,OR,sro,lro,VR,iro,dro,cro,ss,Fte,fro,mro,XR,gro,hro,zR,pro,uro,_ro,Sg,Tte,bro,vro,QR,Fro,Tro,Mro,ls,Mte,Ero,Cro,WR,wro,Aro,HR,yro,Lro,xro,Rg,Ete,$ro,kro,UR,Sro,Rro,Bro,Bg,Cte,Pro,Iro,JR,qro,Nro,jro,is,wte,Dro,Gro,YR,Oro,Vro,KR,Xro,zro,Qro,ds,Ate,Wro,Hro,ZR,Uro,Jro,eB,Yro,Kro,Zro,cs,yte,eto,oto,oB,rto,tto,rB,ato,nto,sto,Pg,Lte,lto,ito,tB,dto,cto,fto,fs,xte,mto,gto,aB,hto,pto,nB,uto,_to,bto,ms,$te,vto,Fto,sB,Tto,Mto,lB,Eto,Cto,wto,gs,kte,Ato,yto,iB,Lto,xto,dB,$to,kto,Sto,hs,Ste,Rto,Bto,cB,Pto,Ito,fB,qto,Nto,jto,ps,Rte,Dto,Gto,mB,Oto,Vto,gB,Xto,zto,Qto,Ig,Bte,Wto,Hto,hB,Uto,Jto,Yto,us,Pte,Kto,Zto,pB,eao,oao,uB,rao,tao,aao,qg,Ite,nao,sao,_B,lao,iao,dao,Ng,qte,cao,fao,bB,mao,gao,hao,jg,Nte,pao,uao,vB,_ao,bao,vao,Dg,jte,Fao,Tao,FB,Mao,Eao,Cao,_s,Dte,wao,Aao,TB,yao,Lao,MB,xao,$ao,kao,Gg,Gte,Sao,Rao,EB,Bao,Pao,Iao,bs,Ote,qao,Nao,CB,jao,Dao,wB,Gao,Oao,Vao,vs,Vte,Xao,zao,AB,Qao,Wao,yB,Hao,Uao,Jao,Fs,Xte,Yao,Kao,LB,Zao,eno,xB,ono,rno,tno,Ts,zte,ano,nno,$B,sno,lno,kB,ino,dno,cno,Ms,Qte,fno,mno,SB,gno,hno,RB,pno,uno,_no,Es,Wte,bno,vno,BB,Fno,Tno,PB,Mno,Eno,Cno,Og,Hte,wno,Ano,IB,yno,Lno,xno,Vg,Ute,$no,kno,qB,Sno,Rno,Bno,Cs,Jte,Pno,Ino,NB,qno,Nno,jB,jno,Dno,Gno,ws,Yte,Ono,Vno,DB,Xno,zno,GB,Qno,Wno,Hno,As,Kte,Uno,Jno,OB,Yno,Kno,VB,Zno,eso,oso,Xg,Zte,rso,tso,XB,aso,nso,sso,zg,eae,lso,iso,zB,dso,cso,fso,Qg,oae,mso,gso,QB,hso,pso,uso,ys,rae,_so,bso,WB,vso,Fso,HB,Tso,Mso,Eso,Wg,tae,Cso,wso,UB,Aso,yso,Lso,Hg,aae,xso,$so,JB,kso,Sso,Rso,Ls,nae,Bso,Pso,YB,Iso,qso,KB,Nso,jso,Dso,Ug,sae,Gso,Oso,ZB,Vso,Xso,zso,Jg,lae,Qso,Wso,eP,Hso,Uso,Jso,xs,iae,Yso,Kso,oP,Zso,elo,rP,olo,rlo,tlo,$s,dae,alo,nlo,tP,slo,llo,aP,ilo,dlo,clo,ks,cae,flo,mlo,nP,glo,hlo,sP,plo,ulo,_lo,Ss,fae,blo,vlo,lP,Flo,Tlo,iP,Mlo,Elo,Clo,Yg,wlo,Kg,bA,Alo,mae,ylo,kIe,vi,Zg,gae,vA,Llo,hae,xlo,SIe,Ao,FA,$lo,TA,klo,dP,Slo,Rlo,Blo,MA,Plo,pae,Ilo,qlo,Nlo,Qe,EA,jlo,uae,Dlo,Glo,wa,Olo,_ae,Vlo,Xlo,bae,zlo,Qlo,vae,Wlo,Hlo,Ulo,Z,eh,Fae,Jlo,Ylo,cP,Klo,Zlo,eio,oh,Tae,oio,rio,fP,tio,aio,nio,rh,Mae,sio,lio,mP,iio,dio,cio,th,Eae,fio,mio,gP,gio,hio,pio,ah,Cae,uio,_io,hP,bio,vio,Fio,nh,wae,Tio,Mio,pP,Eio,Cio,wio,sh,Aae,Aio,yio,uP,Lio,xio,$io,lh,yae,kio,Sio,_P,Rio,Bio,Pio,ih,Lae,Iio,qio,bP,Nio,jio,Dio,dh,xae,Gio,Oio,vP,Vio,Xio,zio,ch,$ae,Qio,Wio,FP,Hio,Uio,Jio,fh,kae,Yio,Kio,TP,Zio,edo,odo,mh,Sae,rdo,tdo,MP,ado,ndo,sdo,gh,Rae,ldo,ido,EP,ddo,cdo,fdo,hh,Bae,mdo,gdo,CP,hdo,pdo,udo,ph,Pae,_do,bdo,wP,vdo,Fdo,Tdo,uh,Iae,Mdo,Edo,AP,Cdo,wdo,Ado,_h,qae,ydo,Ldo,yP,xdo,$do,kdo,bh,Nae,Sdo,Rdo,LP,Bdo,Pdo,Ido,vh,jae,qdo,Ndo,xP,jdo,Ddo,Gdo,Fh,Dae,Odo,Vdo,$P,Xdo,zdo,Qdo,Th,Gae,Wdo,Hdo,kP,Udo,Jdo,Ydo,Mh,Oae,Kdo,Zdo,SP,eco,oco,rco,Eh,Vae,tco,aco,RP,nco,sco,lco,Ch,Xae,ico,dco,BP,cco,fco,mco,wh,zae,gco,hco,PP,pco,uco,_co,Ah,bco,yh,vco,Lh,CA,Fco,Qae,Tco,RIe,Fi,xh,Wae,wA,Mco,Hae,Eco,BIe,yo,AA,Cco,yA,wco,IP,Aco,yco,Lco,LA,xco,Uae,$co,kco,Sco,We,xA,Rco,Jae,Bco,Pco,Ti,Ico,Yae,qco,Nco,Kae,jco,Dco,Gco,ue,$h,Zae,Oco,Vco,qP,Xco,zco,Qco,kh,ene,Wco,Hco,one,Uco,Jco,Yco,Sh,rne,Kco,Zco,NP,efo,ofo,rfo,Rh,tne,tfo,afo,jP,nfo,sfo,lfo,Bh,ane,ifo,dfo,DP,cfo,ffo,mfo,Ph,nne,gfo,hfo,GP,pfo,ufo,_fo,Ih,sne,bfo,vfo,OP,Ffo,Tfo,Mfo,qh,lne,Efo,Cfo,VP,wfo,Afo,yfo,Nh,ine,Lfo,xfo,XP,$fo,kfo,Sfo,jh,dne,Rfo,Bfo,zP,Pfo,Ifo,qfo,Dh,cne,Nfo,jfo,QP,Dfo,Gfo,Ofo,Gh,fne,Vfo,Xfo,WP,zfo,Qfo,Wfo,Oh,mne,Hfo,Ufo,HP,Jfo,Yfo,Kfo,Vh,gne,Zfo,emo,UP,omo,rmo,tmo,Xh,hne,amo,nmo,JP,smo,lmo,imo,zh,pne,dmo,cmo,YP,fmo,mmo,gmo,Qh,hmo,Wh,pmo,Hh,$A,umo,une,_mo,PIe,Mi,Uh,_ne,kA,bmo,bne,vmo,IIe,Lo,SA,Fmo,Ei,Tmo,KP,Mmo,Emo,ZP,Cmo,wmo,Amo,RA,ymo,vne,Lmo,xmo,$mo,ot,BA,kmo,Fne,Smo,Rmo,Ci,Bmo,Tne,Pmo,Imo,eI,qmo,Nmo,jmo,Jh,Dmo,He,PA,Gmo,Mne,Omo,Vmo,Aa,Xmo,Ene,zmo,Qmo,Cne,Wmo,Hmo,wne,Umo,Jmo,Ymo,x,Yh,Ane,Kmo,Zmo,oI,ego,ogo,rgo,Kh,yne,tgo,ago,rI,ngo,sgo,lgo,Zh,Lne,igo,dgo,tI,cgo,fgo,mgo,ep,xne,ggo,hgo,aI,pgo,ugo,_go,op,$ne,bgo,vgo,nI,Fgo,Tgo,Mgo,rp,kne,Ego,Cgo,sI,wgo,Ago,ygo,tp,Sne,Lgo,xgo,lI,$go,kgo,Sgo,ap,Rne,Rgo,Bgo,iI,Pgo,Igo,qgo,np,Bne,Ngo,jgo,dI,Dgo,Ggo,Ogo,sp,Pne,Vgo,Xgo,cI,zgo,Qgo,Wgo,lp,Ine,Hgo,Ugo,fI,Jgo,Ygo,Kgo,ip,qne,Zgo,eho,mI,oho,rho,tho,dp,Nne,aho,nho,gI,sho,lho,iho,cp,jne,dho,cho,hI,fho,mho,gho,fp,Dne,hho,pho,pI,uho,_ho,bho,mp,Gne,vho,Fho,uI,Tho,Mho,Eho,gp,One,Cho,who,_I,Aho,yho,Lho,hp,Vne,xho,$ho,bI,kho,Sho,Rho,pp,Xne,Bho,Pho,vI,Iho,qho,Nho,up,zne,jho,Dho,FI,Gho,Oho,Vho,_p,Qne,Xho,zho,TI,Qho,Who,Hho,bp,Wne,Uho,Jho,MI,Yho,Kho,Zho,vp,Hne,epo,opo,EI,rpo,tpo,apo,Fp,Une,npo,spo,CI,lpo,ipo,dpo,Tp,Jne,cpo,fpo,wI,mpo,gpo,hpo,Mp,Yne,ppo,upo,AI,_po,bpo,vpo,Ep,Kne,Fpo,Tpo,yI,Mpo,Epo,Cpo,Cp,Zne,wpo,Apo,LI,ypo,Lpo,xpo,wp,ese,$po,kpo,xI,Spo,Rpo,Bpo,Ap,ose,Ppo,Ipo,$I,qpo,Npo,jpo,yp,rse,Dpo,Gpo,kI,Opo,Vpo,Xpo,Rs,tse,zpo,Qpo,SI,Wpo,Hpo,RI,Upo,Jpo,Ypo,Lp,ase,Kpo,Zpo,BI,euo,ouo,ruo,xp,nse,tuo,auo,PI,nuo,suo,luo,$p,sse,iuo,duo,II,cuo,fuo,muo,kp,lse,guo,huo,qI,puo,uuo,_uo,Sp,ise,buo,vuo,NI,Fuo,Tuo,Muo,Rp,dse,Euo,Cuo,jI,wuo,Auo,yuo,Bp,cse,Luo,xuo,DI,$uo,kuo,Suo,Pp,fse,Ruo,Buo,GI,Puo,Iuo,quo,Ip,mse,Nuo,juo,OI,Duo,Guo,Ouo,qp,gse,Vuo,Xuo,VI,zuo,Quo,Wuo,Np,hse,Huo,Uuo,XI,Juo,Yuo,Kuo,jp,pse,Zuo,e_o,zI,o_o,r_o,t_o,Dp,use,a_o,n_o,QI,s_o,l_o,i_o,Gp,_se,d_o,c_o,WI,f_o,m_o,g_o,Op,bse,h_o,p_o,HI,u_o,__o,b_o,Vp,vse,v_o,F_o,UI,T_o,M_o,E_o,Xp,Fse,C_o,w_o,JI,A_o,y_o,L_o,zp,Tse,x_o,$_o,YI,k_o,S_o,R_o,Qp,Mse,B_o,P_o,KI,I_o,q_o,N_o,Wp,Ese,j_o,D_o,ZI,G_o,O_o,V_o,Hp,Cse,X_o,z_o,eq,Q_o,W_o,H_o,Up,wse,U_o,J_o,oq,Y_o,K_o,Z_o,Jp,Ase,e0o,o0o,rq,r0o,t0o,a0o,Yp,yse,n0o,s0o,tq,l0o,i0o,d0o,Kp,Lse,c0o,f0o,aq,m0o,g0o,h0o,Zp,xse,p0o,u0o,nq,_0o,b0o,v0o,eu,$se,F0o,T0o,sq,M0o,E0o,C0o,ou,kse,w0o,A0o,lq,y0o,L0o,x0o,ru,Sse,$0o,k0o,iq,S0o,R0o,B0o,tu,Rse,P0o,I0o,dq,q0o,N0o,j0o,au,Bse,D0o,G0o,cq,O0o,V0o,X0o,nu,Pse,z0o,Q0o,fq,W0o,H0o,U0o,su,Ise,J0o,Y0o,mq,K0o,Z0o,e1o,lu,qse,o1o,r1o,gq,t1o,a1o,n1o,iu,Nse,s1o,l1o,hq,i1o,d1o,c1o,du,jse,f1o,m1o,pq,g1o,h1o,p1o,cu,Dse,u1o,_1o,uq,b1o,v1o,F1o,fu,Gse,T1o,M1o,_q,E1o,C1o,w1o,mu,Ose,A1o,y1o,bq,L1o,x1o,$1o,gu,Vse,k1o,S1o,vq,R1o,B1o,P1o,hu,Xse,I1o,q1o,Fq,N1o,j1o,D1o,pu,zse,G1o,O1o,Tq,V1o,X1o,z1o,uu,Qse,Q1o,W1o,Mq,H1o,U1o,J1o,_u,Wse,Y1o,K1o,Eq,Z1o,ebo,obo,bu,Hse,rbo,tbo,Cq,abo,nbo,sbo,vu,Use,lbo,ibo,wq,dbo,cbo,fbo,Fu,Jse,mbo,gbo,Aq,hbo,pbo,ubo,Tu,Yse,_bo,bbo,yq,vbo,Fbo,Tbo,Mu,Kse,Mbo,Ebo,Lq,Cbo,wbo,Abo,Eu,Zse,ybo,Lbo,xq,xbo,$bo,kbo,Cu,ele,Sbo,Rbo,$q,Bbo,Pbo,Ibo,wu,ole,qbo,Nbo,kq,jbo,Dbo,Gbo,Au,rle,Obo,Vbo,Sq,Xbo,zbo,Qbo,yu,tle,Wbo,Hbo,Rq,Ubo,Jbo,Ybo,Lu,ale,Kbo,Zbo,Bq,e2o,o2o,r2o,xu,nle,t2o,a2o,Pq,n2o,s2o,l2o,$u,sle,i2o,d2o,Iq,c2o,f2o,m2o,ku,lle,g2o,h2o,qq,p2o,u2o,_2o,Su,ile,b2o,v2o,Nq,F2o,T2o,M2o,Ru,dle,E2o,C2o,jq,w2o,A2o,y2o,Bu,cle,L2o,x2o,Dq,$2o,k2o,S2o,Pu,fle,R2o,B2o,Gq,P2o,I2o,q2o,Iu,mle,N2o,j2o,Oq,D2o,G2o,O2o,qu,gle,V2o,X2o,Vq,z2o,Q2o,W2o,Nu,hle,H2o,U2o,Xq,J2o,Y2o,K2o,ju,ple,Z2o,evo,zq,ovo,rvo,tvo,Du,avo,ule,nvo,svo,_le,lvo,ivo,Gu,qIe,wi,Ou,ble,IA,dvo,vle,cvo,NIe,xo,qA,fvo,Ai,mvo,Qq,gvo,hvo,Wq,pvo,uvo,_vo,NA,bvo,Fle,vvo,Fvo,Tvo,rt,jA,Mvo,Tle,Evo,Cvo,yi,wvo,Mle,Avo,yvo,Hq,Lvo,xvo,$vo,Vu,kvo,Ue,DA,Svo,Ele,Rvo,Bvo,ya,Pvo,Cle,Ivo,qvo,wle,Nvo,jvo,Ale,Dvo,Gvo,Ovo,G,Xu,yle,Vvo,Xvo,Uq,zvo,Qvo,Wvo,zu,Lle,Hvo,Uvo,Jq,Jvo,Yvo,Kvo,Qu,xle,Zvo,eFo,Yq,oFo,rFo,tFo,Wu,$le,aFo,nFo,Kq,sFo,lFo,iFo,Hu,kle,dFo,cFo,Zq,fFo,mFo,gFo,Uu,Sle,hFo,pFo,eN,uFo,_Fo,bFo,Ju,Rle,vFo,FFo,oN,TFo,MFo,EFo,Yu,Ble,CFo,wFo,rN,AFo,yFo,LFo,Ku,Ple,xFo,$Fo,tN,kFo,SFo,RFo,Zu,Ile,BFo,PFo,aN,IFo,qFo,NFo,e_,qle,jFo,DFo,nN,GFo,OFo,VFo,o_,Nle,XFo,zFo,sN,QFo,WFo,HFo,r_,jle,UFo,JFo,lN,YFo,KFo,ZFo,t_,Dle,e6o,o6o,iN,r6o,t6o,a6o,a_,Gle,n6o,s6o,dN,l6o,i6o,d6o,n_,Ole,c6o,f6o,cN,m6o,g6o,h6o,s_,Vle,p6o,u6o,fN,_6o,b6o,v6o,l_,Xle,F6o,T6o,mN,M6o,E6o,C6o,i_,zle,w6o,A6o,gN,y6o,L6o,x6o,d_,Qle,$6o,k6o,hN,S6o,R6o,B6o,c_,Wle,P6o,I6o,pN,q6o,N6o,j6o,f_,Hle,D6o,G6o,uN,O6o,V6o,X6o,m_,Ule,z6o,Q6o,_N,W6o,H6o,U6o,g_,Jle,J6o,Y6o,bN,K6o,Z6o,eTo,h_,Yle,oTo,rTo,vN,tTo,aTo,nTo,p_,Kle,sTo,lTo,FN,iTo,dTo,cTo,u_,Zle,fTo,mTo,TN,gTo,hTo,pTo,__,eie,uTo,_To,MN,bTo,vTo,FTo,b_,oie,TTo,MTo,EN,ETo,CTo,wTo,v_,rie,ATo,yTo,CN,LTo,xTo,$To,F_,tie,kTo,STo,wN,RTo,BTo,PTo,T_,aie,ITo,qTo,AN,NTo,jTo,DTo,M_,nie,GTo,OTo,yN,VTo,XTo,zTo,E_,sie,QTo,WTo,LN,HTo,UTo,JTo,C_,lie,YTo,KTo,xN,ZTo,e7o,o7o,w_,iie,r7o,t7o,$N,a7o,n7o,s7o,A_,die,l7o,i7o,kN,d7o,c7o,f7o,y_,cie,m7o,g7o,SN,h7o,p7o,u7o,L_,fie,_7o,b7o,RN,v7o,F7o,T7o,x_,mie,M7o,E7o,BN,C7o,w7o,A7o,$_,y7o,gie,L7o,x7o,hie,$7o,k7o,k_,jIe,Li,S_,pie,GA,S7o,uie,R7o,DIe,$o,OA,B7o,xi,P7o,PN,I7o,q7o,IN,N7o,j7o,D7o,VA,G7o,_ie,O7o,V7o,X7o,tt,XA,z7o,bie,Q7o,W7o,$i,H7o,vie,U7o,J7o,qN,Y7o,K7o,Z7o,R_,eMo,Je,zA,oMo,Fie,rMo,tMo,La,aMo,Tie,nMo,sMo,Mie,lMo,iMo,Eie,dMo,cMo,fMo,z,B_,Cie,mMo,gMo,NN,hMo,pMo,uMo,P_,wie,_Mo,bMo,jN,vMo,FMo,TMo,I_,Aie,MMo,EMo,DN,CMo,wMo,AMo,q_,yie,yMo,LMo,GN,xMo,$Mo,kMo,N_,Lie,SMo,RMo,ON,BMo,PMo,IMo,j_,xie,qMo,NMo,VN,jMo,DMo,GMo,D_,$ie,OMo,VMo,XN,XMo,zMo,QMo,G_,kie,WMo,HMo,zN,UMo,JMo,YMo,O_,Sie,KMo,ZMo,QN,e4o,o4o,r4o,V_,Rie,t4o,a4o,WN,n4o,s4o,l4o,X_,Bie,i4o,d4o,HN,c4o,f4o,m4o,z_,Pie,g4o,h4o,UN,p4o,u4o,_4o,Q_,Iie,b4o,v4o,JN,F4o,T4o,M4o,W_,qie,E4o,C4o,YN,w4o,A4o,y4o,H_,Nie,L4o,x4o,KN,$4o,k4o,S4o,U_,jie,R4o,B4o,ZN,P4o,I4o,q4o,J_,Die,N4o,j4o,ej,D4o,G4o,O4o,Y_,Gie,V4o,X4o,oj,z4o,Q4o,W4o,K_,Oie,H4o,U4o,rj,J4o,Y4o,K4o,Z_,Vie,Z4o,eEo,tj,oEo,rEo,tEo,e0,Xie,aEo,nEo,aj,sEo,lEo,iEo,o0,zie,dEo,cEo,nj,fEo,mEo,gEo,r0,Qie,hEo,pEo,sj,uEo,_Eo,bEo,t0,Wie,vEo,FEo,lj,TEo,MEo,EEo,a0,Hie,CEo,wEo,ij,AEo,yEo,LEo,n0,Uie,xEo,$Eo,dj,kEo,SEo,REo,s0,Jie,BEo,PEo,cj,IEo,qEo,NEo,l0,Yie,jEo,DEo,fj,GEo,OEo,VEo,i0,Kie,XEo,zEo,mj,QEo,WEo,HEo,d0,Zie,UEo,JEo,gj,YEo,KEo,ZEo,c0,ede,e5o,o5o,hj,r5o,t5o,a5o,f0,ode,n5o,s5o,pj,l5o,i5o,d5o,m0,rde,c5o,f5o,uj,m5o,g5o,h5o,g0,tde,p5o,u5o,_j,_5o,b5o,v5o,h0,ade,F5o,T5o,bj,M5o,E5o,C5o,p0,nde,w5o,A5o,vj,y5o,L5o,x5o,u0,$5o,sde,k5o,S5o,lde,R5o,B5o,_0,GIe,ki,b0,ide,QA,P5o,dde,I5o,OIe,ko,WA,q5o,Si,N5o,Fj,j5o,D5o,Tj,G5o,O5o,V5o,HA,X5o,cde,z5o,Q5o,W5o,at,UA,H5o,fde,U5o,J5o,Ri,Y5o,mde,K5o,Z5o,Mj,eCo,oCo,rCo,v0,tCo,Ye,JA,aCo,gde,nCo,sCo,xa,lCo,hde,iCo,dCo,pde,cCo,fCo,ude,mCo,gCo,hCo,Q,F0,_de,pCo,uCo,Ej,_Co,bCo,vCo,T0,bde,FCo,TCo,Cj,MCo,ECo,CCo,M0,vde,wCo,ACo,wj,yCo,LCo,xCo,E0,Fde,$Co,kCo,Aj,SCo,RCo,BCo,C0,Tde,PCo,ICo,yj,qCo,NCo,jCo,w0,Mde,DCo,GCo,Lj,OCo,VCo,XCo,A0,Ede,zCo,QCo,xj,WCo,HCo,UCo,y0,Cde,JCo,YCo,$j,KCo,ZCo,e3o,L0,wde,o3o,r3o,kj,t3o,a3o,n3o,x0,Ade,s3o,l3o,Sj,i3o,d3o,c3o,$0,yde,f3o,m3o,Rj,g3o,h3o,p3o,k0,Lde,u3o,_3o,Bj,b3o,v3o,F3o,S0,xde,T3o,M3o,Pj,E3o,C3o,w3o,R0,$de,A3o,y3o,Ij,L3o,x3o,$3o,B0,kde,k3o,S3o,qj,R3o,B3o,P3o,P0,Sde,I3o,q3o,Nj,N3o,j3o,D3o,I0,Rde,G3o,O3o,jj,V3o,X3o,z3o,q0,Bde,Q3o,W3o,Dj,H3o,U3o,J3o,N0,Pde,Y3o,K3o,Gj,Z3o,ewo,owo,j0,Ide,rwo,two,Oj,awo,nwo,swo,D0,qde,lwo,iwo,Vj,dwo,cwo,fwo,G0,Nde,mwo,gwo,Xj,hwo,pwo,uwo,O0,jde,_wo,bwo,zj,vwo,Fwo,Two,V0,Dde,Mwo,Ewo,Qj,Cwo,wwo,Awo,X0,Gde,ywo,Lwo,Wj,xwo,$wo,kwo,z0,Ode,Swo,Rwo,Hj,Bwo,Pwo,Iwo,Q0,Vde,qwo,Nwo,Uj,jwo,Dwo,Gwo,W0,Xde,Owo,Vwo,Jj,Xwo,zwo,Qwo,H0,zde,Wwo,Hwo,Yj,Uwo,Jwo,Ywo,U0,Qde,Kwo,Zwo,Kj,eAo,oAo,rAo,J0,Wde,tAo,aAo,Hde,nAo,sAo,lAo,Y0,Ude,iAo,dAo,Zj,cAo,fAo,mAo,K0,Jde,gAo,hAo,eD,pAo,uAo,_Ao,Z0,Yde,bAo,vAo,oD,FAo,TAo,MAo,e1,Kde,EAo,CAo,rD,wAo,AAo,yAo,o1,LAo,Zde,xAo,$Ao,ece,kAo,SAo,r1,VIe,Bi,t1,oce,YA,RAo,rce,BAo,XIe,So,KA,PAo,Pi,IAo,tD,qAo,NAo,aD,jAo,DAo,GAo,ZA,OAo,tce,VAo,XAo,zAo,nt,ey,QAo,ace,WAo,HAo,Ii,UAo,nce,JAo,YAo,nD,KAo,ZAo,eyo,a1,oyo,Ke,oy,ryo,sce,tyo,ayo,$a,nyo,lce,syo,lyo,ice,iyo,dyo,dce,cyo,fyo,myo,he,n1,cce,gyo,hyo,sD,pyo,uyo,_yo,s1,fce,byo,vyo,lD,Fyo,Tyo,Myo,l1,mce,Eyo,Cyo,iD,wyo,Ayo,yyo,i1,gce,Lyo,xyo,dD,$yo,kyo,Syo,d1,hce,Ryo,Byo,cD,Pyo,Iyo,qyo,c1,pce,Nyo,jyo,fD,Dyo,Gyo,Oyo,f1,uce,Vyo,Xyo,mD,zyo,Qyo,Wyo,m1,_ce,Hyo,Uyo,gD,Jyo,Yyo,Kyo,g1,bce,Zyo,eLo,hD,oLo,rLo,tLo,h1,vce,aLo,nLo,pD,sLo,lLo,iLo,p1,Fce,dLo,cLo,uD,fLo,mLo,gLo,u1,Tce,hLo,pLo,_D,uLo,_Lo,bLo,_1,Mce,vLo,FLo,bD,TLo,MLo,ELo,b1,Ece,CLo,wLo,vD,ALo,yLo,LLo,v1,Cce,xLo,$Lo,FD,kLo,SLo,RLo,F1,wce,BLo,PLo,TD,ILo,qLo,NLo,T1,Ace,jLo,DLo,MD,GLo,OLo,VLo,M1,XLo,yce,zLo,QLo,Lce,WLo,HLo,E1,zIe,qi,C1,xce,ry,ULo,$ce,JLo,QIe,Ro,ty,YLo,Ni,KLo,ED,ZLo,e8o,CD,o8o,r8o,t8o,ay,a8o,kce,n8o,s8o,l8o,st,ny,i8o,Sce,d8o,c8o,ji,f8o,Rce,m8o,g8o,wD,h8o,p8o,u8o,w1,_8o,Ze,sy,b8o,Bce,v8o,F8o,ka,T8o,Pce,M8o,E8o,Ice,C8o,w8o,qce,A8o,y8o,L8o,q,A1,Nce,x8o,$8o,AD,k8o,S8o,R8o,y1,jce,B8o,P8o,yD,I8o,q8o,N8o,L1,Dce,j8o,D8o,LD,G8o,O8o,V8o,x1,Gce,X8o,z8o,xD,Q8o,W8o,H8o,$1,Oce,U8o,J8o,$D,Y8o,K8o,Z8o,k1,Vce,exo,oxo,kD,rxo,txo,axo,S1,Xce,nxo,sxo,SD,lxo,ixo,dxo,R1,zce,cxo,fxo,RD,mxo,gxo,hxo,B1,Qce,pxo,uxo,BD,_xo,bxo,vxo,P1,Wce,Fxo,Txo,PD,Mxo,Exo,Cxo,I1,Hce,wxo,Axo,ID,yxo,Lxo,xxo,q1,Uce,$xo,kxo,qD,Sxo,Rxo,Bxo,N1,Jce,Pxo,Ixo,ND,qxo,Nxo,jxo,j1,Yce,Dxo,Gxo,jD,Oxo,Vxo,Xxo,D1,Kce,zxo,Qxo,DD,Wxo,Hxo,Uxo,G1,Zce,Jxo,Yxo,GD,Kxo,Zxo,e9o,O1,efe,o9o,r9o,OD,t9o,a9o,n9o,V1,ofe,s9o,l9o,VD,i9o,d9o,c9o,X1,rfe,f9o,m9o,XD,g9o,h9o,p9o,z1,tfe,u9o,_9o,zD,b9o,v9o,F9o,Q1,afe,T9o,M9o,QD,E9o,C9o,w9o,W1,nfe,A9o,y9o,WD,L9o,x9o,$9o,H1,sfe,k9o,S9o,HD,R9o,B9o,P9o,U1,lfe,I9o,q9o,UD,N9o,j9o,D9o,J1,ife,G9o,O9o,JD,V9o,X9o,z9o,Y1,dfe,Q9o,W9o,YD,H9o,U9o,J9o,K1,cfe,Y9o,K9o,KD,Z9o,e$o,o$o,Z1,ffe,r$o,t$o,ZD,a$o,n$o,s$o,eb,mfe,l$o,i$o,eG,d$o,c$o,f$o,ob,gfe,m$o,g$o,oG,h$o,p$o,u$o,rb,hfe,_$o,b$o,rG,v$o,F$o,T$o,tb,pfe,M$o,E$o,tG,C$o,w$o,A$o,ab,ufe,y$o,L$o,aG,x$o,$$o,k$o,nb,_fe,S$o,R$o,nG,B$o,P$o,I$o,sb,bfe,q$o,N$o,sG,j$o,D$o,G$o,lb,vfe,O$o,V$o,lG,X$o,z$o,Q$o,ib,Ffe,W$o,H$o,iG,U$o,J$o,Y$o,db,Tfe,K$o,Z$o,dG,eko,oko,rko,cb,Mfe,tko,ako,cG,nko,sko,lko,fb,Efe,iko,dko,fG,cko,fko,mko,mb,Cfe,gko,hko,mG,pko,uko,_ko,gb,wfe,bko,vko,gG,Fko,Tko,Mko,hb,Afe,Eko,Cko,hG,wko,Ako,yko,pb,yfe,Lko,xko,pG,$ko,kko,Sko,ub,Lfe,Rko,Bko,uG,Pko,Iko,qko,_b,xfe,Nko,jko,_G,Dko,Gko,Oko,bb,$fe,Vko,Xko,bG,zko,Qko,Wko,vb,kfe,Hko,Uko,vG,Jko,Yko,Kko,Fb,Zko,Sfe,eSo,oSo,Rfe,rSo,tSo,Tb,WIe,Di,Mb,Bfe,ly,aSo,Pfe,nSo,HIe,Bo,iy,sSo,Gi,lSo,FG,iSo,dSo,TG,cSo,fSo,mSo,dy,gSo,Ife,hSo,pSo,uSo,lt,cy,_So,qfe,bSo,vSo,Oi,FSo,Nfe,TSo,MSo,MG,ESo,CSo,wSo,Eb,ASo,eo,fy,ySo,jfe,LSo,xSo,Sa,$So,Dfe,kSo,SSo,Gfe,RSo,BSo,Ofe,PSo,ISo,qSo,Y,Cb,Vfe,NSo,jSo,EG,DSo,GSo,OSo,wb,Xfe,VSo,XSo,CG,zSo,QSo,WSo,Ab,zfe,HSo,USo,wG,JSo,YSo,KSo,yb,Qfe,ZSo,eRo,AG,oRo,rRo,tRo,Lb,Wfe,aRo,nRo,yG,sRo,lRo,iRo,xb,Hfe,dRo,cRo,LG,fRo,mRo,gRo,$b,Ufe,hRo,pRo,xG,uRo,_Ro,bRo,kb,Jfe,vRo,FRo,$G,TRo,MRo,ERo,Sb,Yfe,CRo,wRo,kG,ARo,yRo,LRo,Rb,Kfe,xRo,$Ro,SG,kRo,SRo,RRo,Bb,Zfe,BRo,PRo,RG,IRo,qRo,NRo,Pb,eme,jRo,DRo,BG,GRo,ORo,VRo,Ib,ome,XRo,zRo,PG,QRo,WRo,HRo,qb,rme,URo,JRo,IG,YRo,KRo,ZRo,Nb,tme,eBo,oBo,qG,rBo,tBo,aBo,jb,ame,nBo,sBo,NG,lBo,iBo,dBo,Db,nme,cBo,fBo,jG,mBo,gBo,hBo,Gb,sme,pBo,uBo,DG,_Bo,bBo,vBo,Ob,lme,FBo,TBo,GG,MBo,EBo,CBo,Vb,ime,wBo,ABo,OG,yBo,LBo,xBo,Xb,dme,$Bo,kBo,VG,SBo,RBo,BBo,zb,cme,PBo,IBo,XG,qBo,NBo,jBo,Qb,fme,DBo,GBo,zG,OBo,VBo,XBo,Wb,mme,zBo,QBo,QG,WBo,HBo,UBo,Hb,gme,JBo,YBo,WG,KBo,ZBo,ePo,Ub,hme,oPo,rPo,HG,tPo,aPo,nPo,Jb,pme,sPo,lPo,UG,iPo,dPo,cPo,Yb,ume,fPo,mPo,JG,gPo,hPo,pPo,Kb,_me,uPo,_Po,YG,bPo,vPo,FPo,Zb,TPo,bme,MPo,EPo,vme,CPo,wPo,e2,UIe,Vi,o2,Fme,my,APo,Tme,yPo,JIe,Po,gy,LPo,Xi,xPo,KG,$Po,kPo,ZG,SPo,RPo,BPo,hy,PPo,Mme,IPo,qPo,NPo,it,py,jPo,Eme,DPo,GPo,zi,OPo,Cme,VPo,XPo,eO,zPo,QPo,WPo,r2,HPo,oo,uy,UPo,wme,JPo,YPo,Ra,KPo,Ame,ZPo,eIo,yme,oIo,rIo,Lme,tIo,aIo,nIo,Yr,t2,xme,sIo,lIo,oO,iIo,dIo,cIo,a2,$me,fIo,mIo,rO,gIo,hIo,pIo,n2,kme,uIo,_Io,tO,bIo,vIo,FIo,s2,Sme,TIo,MIo,aO,EIo,CIo,wIo,l2,Rme,AIo,yIo,nO,LIo,xIo,$Io,i2,kIo,Bme,SIo,RIo,Pme,BIo,PIo,d2,YIe,Qi,c2,Ime,_y,IIo,qme,qIo,KIe,Io,by,NIo,Wi,jIo,sO,DIo,GIo,lO,OIo,VIo,XIo,vy,zIo,Nme,QIo,WIo,HIo,dt,Fy,UIo,jme,JIo,YIo,Hi,KIo,Dme,ZIo,eqo,iO,oqo,rqo,tqo,f2,aqo,ro,Ty,nqo,Gme,sqo,lqo,Ba,iqo,Ome,dqo,cqo,Vme,fqo,mqo,Xme,gqo,hqo,pqo,H,m2,zme,uqo,_qo,dO,bqo,vqo,Fqo,g2,Qme,Tqo,Mqo,cO,Eqo,Cqo,wqo,h2,Wme,Aqo,yqo,fO,Lqo,xqo,$qo,p2,Hme,kqo,Sqo,mO,Rqo,Bqo,Pqo,u2,Ume,Iqo,qqo,gO,Nqo,jqo,Dqo,_2,Jme,Gqo,Oqo,hO,Vqo,Xqo,zqo,b2,Yme,Qqo,Wqo,pO,Hqo,Uqo,Jqo,v2,Kme,Yqo,Kqo,uO,Zqo,eNo,oNo,F2,Zme,rNo,tNo,_O,aNo,nNo,sNo,T2,ege,lNo,iNo,bO,dNo,cNo,fNo,M2,oge,mNo,gNo,vO,hNo,pNo,uNo,E2,rge,_No,bNo,FO,vNo,FNo,TNo,C2,tge,MNo,ENo,TO,CNo,wNo,ANo,w2,age,yNo,LNo,MO,xNo,$No,kNo,A2,nge,SNo,RNo,EO,BNo,PNo,INo,y2,sge,qNo,NNo,CO,jNo,DNo,GNo,L2,lge,ONo,VNo,wO,XNo,zNo,QNo,x2,ige,WNo,HNo,AO,UNo,JNo,YNo,$2,dge,KNo,ZNo,yO,ejo,ojo,rjo,k2,cge,tjo,ajo,LO,njo,sjo,ljo,S2,fge,ijo,djo,xO,cjo,fjo,mjo,R2,mge,gjo,hjo,$O,pjo,ujo,_jo,B2,gge,bjo,vjo,kO,Fjo,Tjo,Mjo,P2,hge,Ejo,Cjo,SO,wjo,Ajo,yjo,I2,pge,Ljo,xjo,RO,$jo,kjo,Sjo,q2,uge,Rjo,Bjo,BO,Pjo,Ijo,qjo,N2,_ge,Njo,jjo,PO,Djo,Gjo,Ojo,j2,bge,Vjo,Xjo,IO,zjo,Qjo,Wjo,D2,vge,Hjo,Ujo,qO,Jjo,Yjo,Kjo,G2,Fge,Zjo,eDo,NO,oDo,rDo,tDo,O2,Tge,aDo,nDo,jO,sDo,lDo,iDo,V2,Mge,dDo,cDo,DO,fDo,mDo,gDo,X2,Ege,hDo,pDo,GO,uDo,_Do,bDo,z2,Cge,vDo,FDo,OO,TDo,MDo,EDo,Q2,CDo,wge,wDo,ADo,Age,yDo,LDo,W2,ZIe,Ui,H2,yge,My,xDo,Lge,$Do,eqe,qo,Ey,kDo,Ji,SDo,VO,RDo,BDo,XO,PDo,IDo,qDo,Cy,NDo,xge,jDo,DDo,GDo,ct,wy,ODo,$ge,VDo,XDo,Yi,zDo,kge,QDo,WDo,zO,HDo,UDo,JDo,U2,YDo,to,Ay,KDo,Sge,ZDo,eGo,Pa,oGo,Rge,rGo,tGo,Bge,aGo,nGo,Pge,sGo,lGo,iGo,O,J2,Ige,dGo,cGo,QO,fGo,mGo,gGo,Y2,qge,hGo,pGo,WO,uGo,_Go,bGo,K2,Nge,vGo,FGo,HO,TGo,MGo,EGo,Z2,jge,CGo,wGo,UO,AGo,yGo,LGo,ev,Dge,xGo,$Go,JO,kGo,SGo,RGo,ov,Gge,BGo,PGo,YO,IGo,qGo,NGo,rv,Oge,jGo,DGo,KO,GGo,OGo,VGo,tv,Vge,XGo,zGo,ZO,QGo,WGo,HGo,av,Xge,UGo,JGo,eV,YGo,KGo,ZGo,nv,zge,eOo,oOo,oV,rOo,tOo,aOo,sv,Qge,nOo,sOo,rV,lOo,iOo,dOo,lv,Wge,cOo,fOo,tV,mOo,gOo,hOo,iv,Hge,pOo,uOo,aV,_Oo,bOo,vOo,dv,Uge,FOo,TOo,nV,MOo,EOo,COo,cv,Jge,wOo,AOo,sV,yOo,LOo,xOo,fv,Yge,$Oo,kOo,lV,SOo,ROo,BOo,mv,Kge,POo,IOo,iV,qOo,NOo,jOo,gv,Zge,DOo,GOo,dV,OOo,VOo,XOo,hv,ehe,zOo,QOo,cV,WOo,HOo,UOo,pv,ohe,JOo,YOo,fV,KOo,ZOo,eVo,uv,rhe,oVo,rVo,mV,tVo,aVo,nVo,_v,the,sVo,lVo,gV,iVo,dVo,cVo,bv,ahe,fVo,mVo,hV,gVo,hVo,pVo,vv,nhe,uVo,_Vo,pV,bVo,vVo,FVo,Fv,she,TVo,MVo,uV,EVo,CVo,wVo,Tv,lhe,AVo,yVo,_V,LVo,xVo,$Vo,Mv,ihe,kVo,SVo,bV,RVo,BVo,PVo,Ev,dhe,IVo,qVo,vV,NVo,jVo,DVo,Cv,che,GVo,OVo,FV,VVo,XVo,zVo,wv,fhe,QVo,WVo,TV,HVo,UVo,JVo,Av,mhe,YVo,KVo,MV,ZVo,eXo,oXo,yv,ghe,rXo,tXo,EV,aXo,nXo,sXo,Lv,hhe,lXo,iXo,CV,dXo,cXo,fXo,xv,phe,mXo,gXo,wV,hXo,pXo,uXo,$v,uhe,_Xo,bXo,AV,vXo,FXo,TXo,kv,_he,MXo,EXo,yV,CXo,wXo,AXo,Sv,bhe,yXo,LXo,LV,xXo,$Xo,kXo,Rv,vhe,SXo,RXo,xV,BXo,PXo,IXo,Bv,Fhe,qXo,NXo,$V,jXo,DXo,GXo,Pv,The,OXo,VXo,kV,XXo,zXo,QXo,Iv,WXo,Mhe,HXo,UXo,Ehe,JXo,YXo,qv,oqe,Ki,Nv,Che,yy,KXo,whe,ZXo,rqe,No,Ly,ezo,Zi,ozo,SV,rzo,tzo,RV,azo,nzo,szo,xy,lzo,Ahe,izo,dzo,czo,ft,$y,fzo,yhe,mzo,gzo,ed,hzo,Lhe,pzo,uzo,BV,_zo,bzo,vzo,jv,Fzo,ao,ky,Tzo,xhe,Mzo,Ezo,Ia,Czo,$he,wzo,Azo,khe,yzo,Lzo,She,xzo,$zo,kzo,Rhe,Dv,Bhe,Szo,Rzo,PV,Bzo,Pzo,Izo,Gv,qzo,Phe,Nzo,jzo,Ihe,Dzo,Gzo,Ov,tqe,od,Vv,qhe,Sy,Ozo,Nhe,Vzo,aqe,jo,Ry,Xzo,rd,zzo,IV,Qzo,Wzo,qV,Hzo,Uzo,Jzo,By,Yzo,jhe,Kzo,Zzo,eQo,mt,Py,oQo,Dhe,rQo,tQo,td,aQo,Ghe,nQo,sQo,NV,lQo,iQo,dQo,Xv,cQo,no,Iy,fQo,Ohe,mQo,gQo,qa,hQo,Vhe,pQo,uQo,Xhe,_Qo,bQo,zhe,vQo,FQo,TQo,Fe,zv,Qhe,MQo,EQo,jV,CQo,wQo,AQo,Qv,Whe,yQo,LQo,DV,xQo,$Qo,kQo,Wv,Hhe,SQo,RQo,GV,BQo,PQo,IQo,Bs,Uhe,qQo,NQo,OV,jQo,DQo,VV,GQo,OQo,VQo,Hv,Jhe,XQo,zQo,XV,QQo,WQo,HQo,gt,Yhe,UQo,JQo,zV,YQo,KQo,QV,ZQo,eWo,WV,oWo,rWo,tWo,Uv,Khe,aWo,nWo,HV,sWo,lWo,iWo,Jv,Zhe,dWo,cWo,UV,fWo,mWo,gWo,Yv,epe,hWo,pWo,JV,uWo,_Wo,bWo,Kv,ope,vWo,FWo,YV,TWo,MWo,EWo,Zv,rpe,CWo,wWo,KV,AWo,yWo,LWo,eF,tpe,xWo,$Wo,ZV,kWo,SWo,RWo,oF,ape,BWo,PWo,eX,IWo,qWo,NWo,rF,jWo,npe,DWo,GWo,spe,OWo,VWo,tF,nqe,ad,aF,lpe,qy,XWo,ipe,zWo,sqe,Do,Ny,QWo,nd,WWo,oX,HWo,UWo,rX,JWo,YWo,KWo,jy,ZWo,dpe,eHo,oHo,rHo,ht,Dy,tHo,cpe,aHo,nHo,sd,sHo,fpe,lHo,iHo,tX,dHo,cHo,fHo,nF,mHo,so,Gy,gHo,mpe,hHo,pHo,Na,uHo,gpe,_Ho,bHo,hpe,vHo,FHo,ppe,THo,MHo,EHo,upe,sF,_pe,CHo,wHo,aX,AHo,yHo,LHo,lF,xHo,bpe,$Ho,kHo,vpe,SHo,RHo,iF,lqe,ld,dF,Fpe,Oy,BHo,Tpe,PHo,iqe,Go,Vy,IHo,id,qHo,nX,NHo,jHo,sX,DHo,GHo,OHo,Xy,VHo,Mpe,XHo,zHo,QHo,pt,zy,WHo,Epe,HHo,UHo,dd,JHo,Cpe,YHo,KHo,lX,ZHo,eUo,oUo,cF,rUo,lo,Qy,tUo,wpe,aUo,nUo,ja,sUo,Ape,lUo,iUo,ype,dUo,cUo,Lpe,fUo,mUo,gUo,Ne,fF,xpe,hUo,pUo,iX,uUo,_Uo,bUo,mF,$pe,vUo,FUo,dX,TUo,MUo,EUo,gF,kpe,CUo,wUo,cX,AUo,yUo,LUo,hF,Spe,xUo,$Uo,fX,kUo,SUo,RUo,pF,Rpe,BUo,PUo,mX,IUo,qUo,NUo,uF,Bpe,jUo,DUo,gX,GUo,OUo,VUo,_F,Ppe,XUo,zUo,hX,QUo,WUo,HUo,bF,Ipe,UUo,JUo,pX,YUo,KUo,ZUo,vF,eJo,qpe,oJo,rJo,Npe,tJo,aJo,FF,dqe,cd,TF,jpe,Wy,nJo,Dpe,sJo,cqe,Oo,Hy,lJo,fd,iJo,uX,dJo,cJo,_X,fJo,mJo,gJo,Uy,hJo,Gpe,pJo,uJo,_Jo,ut,Jy,bJo,Ope,vJo,FJo,md,TJo,Vpe,MJo,EJo,bX,CJo,wJo,AJo,MF,yJo,io,Yy,LJo,Xpe,xJo,$Jo,Da,kJo,zpe,SJo,RJo,Qpe,BJo,PJo,Wpe,IJo,qJo,NJo,Ga,EF,Hpe,jJo,DJo,vX,GJo,OJo,VJo,CF,Upe,XJo,zJo,FX,QJo,WJo,HJo,wF,Jpe,UJo,JJo,TX,YJo,KJo,ZJo,AF,Ype,eYo,oYo,MX,rYo,tYo,aYo,yF,nYo,Kpe,sYo,lYo,Zpe,iYo,dYo,LF,fqe,gd,xF,eue,Ky,cYo,oue,fYo,mqe,Vo,Zy,mYo,hd,gYo,EX,hYo,pYo,CX,uYo,_Yo,bYo,eL,vYo,rue,FYo,TYo,MYo,_t,oL,EYo,tue,CYo,wYo,pd,AYo,aue,yYo,LYo,wX,xYo,$Yo,kYo,$F,SYo,co,rL,RYo,nue,BYo,PYo,Oa,IYo,sue,qYo,NYo,lue,jYo,DYo,iue,GYo,OYo,VYo,je,kF,due,XYo,zYo,AX,QYo,WYo,HYo,SF,cue,UYo,JYo,yX,YYo,KYo,ZYo,RF,fue,eKo,oKo,LX,rKo,tKo,aKo,BF,mue,nKo,sKo,xX,lKo,iKo,dKo,PF,gue,cKo,fKo,$X,mKo,gKo,hKo,IF,hue,pKo,uKo,kX,_Ko,bKo,vKo,qF,pue,FKo,TKo,SX,MKo,EKo,CKo,NF,uue,wKo,AKo,RX,yKo,LKo,xKo,jF,$Ko,_ue,kKo,SKo,bue,RKo,BKo,DF,gqe,ud,GF,vue,tL,PKo,Fue,IKo,hqe,Xo,aL,qKo,_d,NKo,BX,jKo,DKo,PX,GKo,OKo,VKo,nL,XKo,Tue,zKo,QKo,WKo,bt,sL,HKo,Mue,UKo,JKo,bd,YKo,Eue,KKo,ZKo,IX,eZo,oZo,rZo,OF,tZo,fo,lL,aZo,Cue,nZo,sZo,Va,lZo,wue,iZo,dZo,Aue,cZo,fZo,yue,mZo,gZo,hZo,iL,VF,Lue,pZo,uZo,qX,_Zo,bZo,vZo,XF,xue,FZo,TZo,NX,MZo,EZo,CZo,zF,wZo,$ue,AZo,yZo,kue,LZo,xZo,QF,pqe,vd,WF,Sue,dL,$Zo,Rue,kZo,uqe,zo,cL,SZo,Fd,RZo,jX,BZo,PZo,DX,IZo,qZo,NZo,fL,jZo,Bue,DZo,GZo,OZo,vt,mL,VZo,Pue,XZo,zZo,Td,QZo,Iue,WZo,HZo,GX,UZo,JZo,YZo,HF,KZo,mo,gL,ZZo,que,eer,oer,Xa,rer,Nue,ter,aer,jue,ner,ser,Due,ler,ier,der,za,UF,Gue,cer,fer,OX,mer,ger,her,JF,Oue,per,uer,VX,_er,ber,ver,YF,Vue,Fer,Ter,XX,Mer,Eer,Cer,KF,Xue,wer,Aer,zX,yer,Ler,xer,ZF,$er,zue,ker,Ser,Que,Rer,Ber,e6,_qe,Md,o6,Wue,hL,Per,Hue,Ier,bqe,Qo,pL,qer,Ed,Ner,QX,jer,Der,WX,Ger,Oer,Ver,uL,Xer,Uue,zer,Qer,Wer,Ft,_L,Her,Jue,Uer,Jer,Cd,Yer,Yue,Ker,Zer,HX,eor,oor,ror,r6,tor,go,bL,aor,Kue,nor,sor,Qa,lor,Zue,ior,dor,e_e,cor,mor,o_e,gor,hor,por,wd,t6,r_e,uor,_or,UX,bor,vor,For,a6,t_e,Tor,Mor,JX,Eor,Cor,wor,n6,a_e,Aor,yor,YX,Lor,xor,$or,s6,kor,n_e,Sor,Ror,s_e,Bor,Por,l6,vqe,Ad,i6,l_e,vL,Ior,i_e,qor,Fqe,Wo,FL,Nor,yd,jor,KX,Dor,Gor,ZX,Oor,Vor,Xor,TL,zor,d_e,Qor,Wor,Hor,Tt,ML,Uor,c_e,Jor,Yor,Ld,Kor,f_e,Zor,err,ez,orr,rrr,trr,d6,arr,ho,EL,nrr,m_e,srr,lrr,Wa,irr,g_e,drr,crr,h_e,frr,mrr,p_e,grr,hrr,prr,CL,c6,u_e,urr,_rr,oz,brr,vrr,Frr,f6,__e,Trr,Mrr,rz,Err,Crr,wrr,m6,Arr,b_e,yrr,Lrr,v_e,xrr,$rr,g6,Tqe,xd,h6,F_e,wL,krr,T_e,Srr,Mqe,Ho,AL,Rrr,$d,Brr,tz,Prr,Irr,az,qrr,Nrr,jrr,yL,Drr,M_e,Grr,Orr,Vrr,Mt,LL,Xrr,E_e,zrr,Qrr,kd,Wrr,C_e,Hrr,Urr,nz,Jrr,Yrr,Krr,p6,Zrr,po,xL,etr,w_e,otr,rtr,Ha,ttr,A_e,atr,ntr,y_e,str,ltr,L_e,itr,dtr,ctr,x_e,u6,$_e,ftr,mtr,sz,gtr,htr,ptr,_6,utr,k_e,_tr,btr,S_e,vtr,Ftr,b6,Eqe,Sd,v6,R_e,$L,Ttr,B_e,Mtr,Cqe,Uo,kL,Etr,Rd,Ctr,lz,wtr,Atr,iz,ytr,Ltr,xtr,SL,$tr,P_e,ktr,Str,Rtr,Et,RL,Btr,I_e,Ptr,Itr,Bd,qtr,q_e,Ntr,jtr,dz,Dtr,Gtr,Otr,F6,Vtr,uo,BL,Xtr,N_e,ztr,Qtr,Ua,Wtr,j_e,Htr,Utr,D_e,Jtr,Ytr,G_e,Ktr,Ztr,ear,Ja,T6,O_e,oar,rar,cz,tar,aar,nar,M6,V_e,sar,lar,fz,iar,dar,car,E6,X_e,far,mar,mz,gar,har,par,C6,z_e,uar,_ar,gz,bar,Far,Tar,w6,Mar,Q_e,Ear,Car,W_e,war,Aar,A6,wqe,Pd,y6,H_e,PL,yar,U_e,Lar,Aqe,Jo,IL,xar,Id,$ar,hz,kar,Sar,pz,Rar,Bar,Par,qL,Iar,J_e,qar,Nar,jar,Ct,NL,Dar,Y_e,Gar,Oar,qd,Var,K_e,Xar,zar,uz,Qar,War,Har,L6,Uar,_o,jL,Jar,Z_e,Yar,Kar,Ya,Zar,e0e,enr,onr,o0e,rnr,tnr,r0e,anr,nnr,snr,t0e,x6,a0e,lnr,inr,_z,dnr,cnr,fnr,$6,mnr,n0e,gnr,hnr,s0e,pnr,unr,k6,yqe,Nd,S6,l0e,DL,_nr,i0e,bnr,Lqe,Yo,GL,vnr,jd,Fnr,bz,Tnr,Mnr,vz,Enr,Cnr,wnr,OL,Anr,d0e,ynr,Lnr,xnr,wt,VL,$nr,c0e,knr,Snr,Dd,Rnr,f0e,Bnr,Pnr,Fz,Inr,qnr,Nnr,R6,jnr,wr,XL,Dnr,m0e,Gnr,Onr,Ka,Vnr,g0e,Xnr,znr,h0e,Qnr,Wnr,p0e,Hnr,Unr,Jnr,j,B6,u0e,Ynr,Knr,Tz,Znr,esr,osr,P6,_0e,rsr,tsr,Mz,asr,nsr,ssr,I6,b0e,lsr,isr,Ez,dsr,csr,fsr,q6,v0e,msr,gsr,Cz,hsr,psr,usr,N6,F0e,_sr,bsr,wz,vsr,Fsr,Tsr,j6,T0e,Msr,Esr,Az,Csr,wsr,Asr,D6,M0e,ysr,Lsr,yz,xsr,$sr,ksr,G6,E0e,Ssr,Rsr,Lz,Bsr,Psr,Isr,O6,C0e,qsr,Nsr,xz,jsr,Dsr,Gsr,V6,w0e,Osr,Vsr,$z,Xsr,zsr,Qsr,X6,A0e,Wsr,Hsr,kz,Usr,Jsr,Ysr,z6,y0e,Ksr,Zsr,Sz,elr,olr,rlr,Q6,L0e,tlr,alr,Rz,nlr,slr,llr,W6,x0e,ilr,dlr,Bz,clr,flr,mlr,H6,$0e,glr,hlr,Pz,plr,ulr,_lr,U6,k0e,blr,vlr,Iz,Flr,Tlr,Mlr,J6,S0e,Elr,Clr,qz,wlr,Alr,ylr,Ps,R0e,Llr,xlr,Nz,$lr,klr,jz,Slr,Rlr,Blr,Y6,B0e,Plr,Ilr,Dz,qlr,Nlr,jlr,K6,P0e,Dlr,Glr,Gz,Olr,Vlr,Xlr,Z6,I0e,zlr,Qlr,Oz,Wlr,Hlr,Ulr,eT,q0e,Jlr,Ylr,Vz,Klr,Zlr,eir,oT,N0e,oir,rir,Xz,tir,air,nir,rT,j0e,sir,lir,zz,iir,dir,cir,tT,D0e,fir,mir,Qz,gir,hir,pir,aT,G0e,uir,_ir,Wz,bir,vir,Fir,nT,O0e,Tir,Mir,Hz,Eir,Cir,wir,sT,V0e,Air,yir,Uz,Lir,xir,$ir,lT,X0e,kir,Sir,Jz,Rir,Bir,Pir,iT,z0e,Iir,qir,Yz,Nir,jir,Dir,dT,Q0e,Gir,Oir,Kz,Vir,Xir,zir,cT,W0e,Qir,Wir,Zz,Hir,Uir,Jir,fT,H0e,Yir,Kir,eQ,Zir,edr,odr,mT,U0e,rdr,tdr,oQ,adr,ndr,sdr,gT,J0e,ldr,idr,rQ,ddr,cdr,fdr,hT,Y0e,mdr,gdr,tQ,hdr,pdr,udr,pT,K0e,_dr,bdr,aQ,vdr,Fdr,Tdr,uT,Z0e,Mdr,Edr,nQ,Cdr,wdr,Adr,_T,e1e,ydr,Ldr,sQ,xdr,$dr,kdr,bT,o1e,Sdr,Rdr,lQ,Bdr,Pdr,Idr,vT,r1e,qdr,Ndr,iQ,jdr,Ddr,Gdr,FT,t1e,Odr,Vdr,dQ,Xdr,zdr,Qdr,TT,a1e,Wdr,Hdr,cQ,Udr,Jdr,Ydr,MT,n1e,Kdr,Zdr,fQ,ecr,ocr,rcr,ET,s1e,tcr,acr,mQ,ncr,scr,lcr,CT,xqe,Gd,wT,l1e,zL,icr,i1e,dcr,$qe,Ko,QL,ccr,Od,fcr,gQ,mcr,gcr,hQ,hcr,pcr,ucr,WL,_cr,d1e,bcr,vcr,Fcr,At,HL,Tcr,c1e,Mcr,Ecr,Vd,Ccr,f1e,wcr,Acr,pQ,ycr,Lcr,xcr,AT,$cr,Ar,UL,kcr,m1e,Scr,Rcr,Za,Bcr,g1e,Pcr,Icr,h1e,qcr,Ncr,p1e,jcr,Dcr,Gcr,se,yT,u1e,Ocr,Vcr,uQ,Xcr,zcr,Qcr,LT,_1e,Wcr,Hcr,_Q,Ucr,Jcr,Ycr,xT,b1e,Kcr,Zcr,bQ,efr,ofr,rfr,$T,v1e,tfr,afr,vQ,nfr,sfr,lfr,kT,F1e,ifr,dfr,FQ,cfr,ffr,mfr,ST,T1e,gfr,hfr,TQ,pfr,ufr,_fr,RT,M1e,bfr,vfr,MQ,Ffr,Tfr,Mfr,BT,E1e,Efr,Cfr,EQ,wfr,Afr,yfr,PT,C1e,Lfr,xfr,CQ,$fr,kfr,Sfr,IT,w1e,Rfr,Bfr,wQ,Pfr,Ifr,qfr,qT,A1e,Nfr,jfr,AQ,Dfr,Gfr,Ofr,NT,y1e,Vfr,Xfr,yQ,zfr,Qfr,Wfr,jT,L1e,Hfr,Ufr,LQ,Jfr,Yfr,Kfr,DT,x1e,Zfr,emr,xQ,omr,rmr,tmr,GT,$1e,amr,nmr,$Q,smr,lmr,imr,OT,k1e,dmr,cmr,kQ,fmr,mmr,gmr,VT,S1e,hmr,pmr,SQ,umr,_mr,bmr,XT,R1e,vmr,Fmr,RQ,Tmr,Mmr,Emr,zT,B1e,Cmr,wmr,BQ,Amr,ymr,Lmr,QT,P1e,xmr,$mr,PQ,kmr,Smr,Rmr,WT,I1e,Bmr,Pmr,IQ,Imr,qmr,Nmr,HT,q1e,jmr,Dmr,qQ,Gmr,Omr,Vmr,UT,N1e,Xmr,zmr,NQ,Qmr,Wmr,Hmr,JT,kqe,Xd,YT,j1e,JL,Umr,D1e,Jmr,Sqe,Zo,YL,Ymr,zd,Kmr,jQ,Zmr,egr,DQ,ogr,rgr,tgr,KL,agr,G1e,ngr,sgr,lgr,yt,ZL,igr,O1e,dgr,cgr,Qd,fgr,V1e,mgr,ggr,GQ,hgr,pgr,ugr,KT,_gr,yr,e8,bgr,X1e,vgr,Fgr,en,Tgr,z1e,Mgr,Egr,Q1e,Cgr,wgr,W1e,Agr,ygr,Lgr,Te,ZT,H1e,xgr,$gr,OQ,kgr,Sgr,Rgr,e7,U1e,Bgr,Pgr,VQ,Igr,qgr,Ngr,o7,J1e,jgr,Dgr,XQ,Ggr,Ogr,Vgr,r7,Y1e,Xgr,zgr,zQ,Qgr,Wgr,Hgr,t7,K1e,Ugr,Jgr,QQ,Ygr,Kgr,Zgr,a7,Z1e,ehr,ohr,WQ,rhr,thr,ahr,n7,ebe,nhr,shr,HQ,lhr,ihr,dhr,s7,obe,chr,fhr,UQ,mhr,ghr,hhr,l7,rbe,phr,uhr,JQ,_hr,bhr,vhr,i7,tbe,Fhr,Thr,YQ,Mhr,Ehr,Chr,d7,abe,whr,Ahr,KQ,yhr,Lhr,xhr,c7,nbe,$hr,khr,ZQ,Shr,Rhr,Bhr,f7,Rqe,Wd,m7,sbe,o8,Phr,lbe,Ihr,Bqe,er,r8,qhr,Hd,Nhr,eW,jhr,Dhr,oW,Ghr,Ohr,Vhr,t8,Xhr,ibe,zhr,Qhr,Whr,Lt,a8,Hhr,dbe,Uhr,Jhr,Ud,Yhr,cbe,Khr,Zhr,rW,epr,opr,rpr,g7,tpr,Lr,n8,apr,fbe,npr,spr,on,lpr,mbe,ipr,dpr,gbe,cpr,fpr,hbe,mpr,gpr,hpr,Jd,h7,pbe,ppr,upr,tW,_pr,bpr,vpr,p7,ube,Fpr,Tpr,aW,Mpr,Epr,Cpr,u7,_be,wpr,Apr,nW,ypr,Lpr,xpr,_7,Pqe,Yd,b7,bbe,s8,$pr,vbe,kpr,Iqe,or,l8,Spr,Kd,Rpr,sW,Bpr,Ppr,lW,Ipr,qpr,Npr,i8,jpr,Fbe,Dpr,Gpr,Opr,xt,d8,Vpr,Tbe,Xpr,zpr,Zd,Qpr,Mbe,Wpr,Hpr,iW,Upr,Jpr,Ypr,v7,Kpr,xr,c8,Zpr,Ebe,eur,our,rn,rur,Cbe,tur,aur,wbe,nur,sur,Abe,lur,iur,dur,ie,F7,ybe,cur,fur,dW,mur,gur,hur,T7,Lbe,pur,uur,cW,_ur,bur,vur,M7,xbe,Fur,Tur,fW,Mur,Eur,Cur,E7,$be,wur,Aur,mW,yur,Lur,xur,C7,kbe,$ur,kur,gW,Sur,Rur,Bur,w7,Sbe,Pur,Iur,hW,qur,Nur,jur,A7,Rbe,Dur,Gur,pW,Our,Vur,Xur,y7,Bbe,zur,Qur,uW,Wur,Hur,Uur,L7,Pbe,Jur,Yur,_W,Kur,Zur,e_r,x7,Ibe,o_r,r_r,bW,t_r,a_r,n_r,$7,qbe,s_r,l_r,vW,i_r,d_r,c_r,k7,Nbe,f_r,m_r,FW,g_r,h_r,p_r,S7,jbe,u_r,__r,TW,b_r,v_r,F_r,R7,Dbe,T_r,M_r,MW,E_r,C_r,w_r,B7,Gbe,A_r,y_r,EW,L_r,x_r,$_r,P7,Obe,k_r,S_r,CW,R_r,B_r,P_r,I7,Vbe,I_r,q_r,wW,N_r,j_r,D_r,q7,Xbe,G_r,O_r,AW,V_r,X_r,z_r,N7,zbe,Q_r,W_r,yW,H_r,U_r,J_r,j7,Qbe,Y_r,K_r,LW,Z_r,e0r,o0r,D7,qqe,ec,G7,Wbe,f8,r0r,Hbe,t0r,Nqe,rr,m8,a0r,oc,n0r,xW,s0r,l0r,$W,i0r,d0r,c0r,g8,f0r,Ube,m0r,g0r,h0r,$t,h8,p0r,Jbe,u0r,_0r,rc,b0r,Ybe,v0r,F0r,kW,T0r,M0r,E0r,O7,C0r,$r,p8,w0r,Kbe,A0r,y0r,tn,L0r,Zbe,x0r,$0r,e2e,k0r,S0r,o2e,R0r,B0r,P0r,ye,V7,r2e,I0r,q0r,SW,N0r,j0r,D0r,X7,t2e,G0r,O0r,RW,V0r,X0r,z0r,z7,a2e,Q0r,W0r,BW,H0r,U0r,J0r,Q7,n2e,Y0r,K0r,PW,Z0r,e1r,o1r,W7,s2e,r1r,t1r,IW,a1r,n1r,s1r,H7,l2e,l1r,i1r,qW,d1r,c1r,f1r,U7,i2e,m1r,g1r,NW,h1r,p1r,u1r,J7,d2e,_1r,b1r,jW,v1r,F1r,T1r,Y7,c2e,M1r,E1r,DW,C1r,w1r,A1r,K7,f2e,y1r,L1r,GW,x1r,$1r,k1r,Z7,jqe,tc,eM,m2e,u8,S1r,g2e,R1r,Dqe,tr,_8,B1r,ac,P1r,OW,I1r,q1r,VW,N1r,j1r,D1r,b8,G1r,h2e,O1r,V1r,X1r,kt,v8,z1r,p2e,Q1r,W1r,nc,H1r,u2e,U1r,J1r,XW,Y1r,K1r,Z1r,oM,ebr,kr,F8,obr,_2e,rbr,tbr,an,abr,b2e,nbr,sbr,v2e,lbr,ibr,F2e,dbr,cbr,fbr,ee,rM,T2e,mbr,gbr,zW,hbr,pbr,ubr,tM,M2e,_br,bbr,QW,vbr,Fbr,Tbr,aM,E2e,Mbr,Ebr,WW,Cbr,wbr,Abr,nM,C2e,ybr,Lbr,HW,xbr,$br,kbr,sM,w2e,Sbr,Rbr,UW,Bbr,Pbr,Ibr,lM,A2e,qbr,Nbr,JW,jbr,Dbr,Gbr,iM,y2e,Obr,Vbr,YW,Xbr,zbr,Qbr,dM,L2e,Wbr,Hbr,KW,Ubr,Jbr,Ybr,cM,x2e,Kbr,Zbr,ZW,e2r,o2r,r2r,fM,$2e,t2r,a2r,eH,n2r,s2r,l2r,mM,k2e,i2r,d2r,oH,c2r,f2r,m2r,gM,S2e,g2r,h2r,rH,p2r,u2r,_2r,hM,R2e,b2r,v2r,tH,F2r,T2r,M2r,pM,B2e,E2r,C2r,aH,w2r,A2r,y2r,uM,P2e,L2r,x2r,nH,$2r,k2r,S2r,_M,I2e,R2r,B2r,sH,P2r,I2r,q2r,bM,q2e,N2r,j2r,lH,D2r,G2r,O2r,vM,N2e,V2r,X2r,iH,z2r,Q2r,W2r,FM,j2e,H2r,U2r,dH,J2r,Y2r,K2r,TM,D2e,Z2r,evr,cH,ovr,rvr,tvr,MM,G2e,avr,nvr,fH,svr,lvr,ivr,EM,O2e,dvr,cvr,mH,fvr,mvr,gvr,CM,V2e,hvr,pvr,gH,uvr,_vr,bvr,wM,X2e,vvr,Fvr,hH,Tvr,Mvr,Evr,AM,z2e,Cvr,wvr,pH,Avr,yvr,Lvr,yM,Q2e,xvr,$vr,uH,kvr,Svr,Rvr,LM,Gqe,sc,xM,W2e,T8,Bvr,H2e,Pvr,Oqe,ar,M8,Ivr,lc,qvr,_H,Nvr,jvr,bH,Dvr,Gvr,Ovr,E8,Vvr,U2e,Xvr,zvr,Qvr,St,C8,Wvr,J2e,Hvr,Uvr,ic,Jvr,Y2e,Yvr,Kvr,vH,Zvr,eFr,oFr,$M,rFr,Sr,w8,tFr,K2e,aFr,nFr,nn,sFr,Z2e,lFr,iFr,eve,dFr,cFr,ove,fFr,mFr,gFr,pe,kM,rve,hFr,pFr,FH,uFr,_Fr,bFr,SM,tve,vFr,FFr,TH,TFr,MFr,EFr,RM,ave,CFr,wFr,MH,AFr,yFr,LFr,BM,nve,xFr,$Fr,EH,kFr,SFr,RFr,PM,sve,BFr,PFr,CH,IFr,qFr,NFr,IM,lve,jFr,DFr,wH,GFr,OFr,VFr,qM,ive,XFr,zFr,AH,QFr,WFr,HFr,NM,dve,UFr,JFr,yH,YFr,KFr,ZFr,jM,cve,e6r,o6r,LH,r6r,t6r,a6r,DM,fve,n6r,s6r,xH,l6r,i6r,d6r,GM,mve,c6r,f6r,$H,m6r,g6r,h6r,OM,gve,p6r,u6r,kH,_6r,b6r,v6r,VM,hve,F6r,T6r,SH,M6r,E6r,C6r,XM,pve,w6r,A6r,RH,y6r,L6r,x6r,zM,uve,$6r,k6r,BH,S6r,R6r,B6r,QM,_ve,P6r,I6r,PH,q6r,N6r,j6r,WM,bve,D6r,G6r,IH,O6r,V6r,X6r,HM,Vqe,dc,UM,vve,A8,z6r,Fve,Q6r,Xqe,nr,y8,W6r,cc,H6r,qH,U6r,J6r,NH,Y6r,K6r,Z6r,L8,eTr,Tve,oTr,rTr,tTr,Rt,x8,aTr,Mve,nTr,sTr,fc,lTr,Eve,iTr,dTr,jH,cTr,fTr,mTr,JM,gTr,Rr,$8,hTr,Cve,pTr,uTr,sn,_Tr,wve,bTr,vTr,Ave,FTr,TTr,yve,MTr,ETr,CTr,k8,YM,Lve,wTr,ATr,DH,yTr,LTr,xTr,KM,xve,$Tr,kTr,GH,STr,RTr,BTr,ZM,zqe,mc,e4,$ve,S8,PTr,kve,ITr,Qqe,sr,R8,qTr,gc,NTr,OH,jTr,DTr,VH,GTr,OTr,VTr,B8,XTr,Sve,zTr,QTr,WTr,Bt,P8,HTr,Rve,UTr,JTr,hc,YTr,Bve,KTr,ZTr,XH,e7r,o7r,r7r,o4,t7r,Br,I8,a7r,Pve,n7r,s7r,ln,l7r,Ive,i7r,d7r,qve,c7r,f7r,Nve,m7r,g7r,h7r,jve,r4,Dve,p7r,u7r,zH,_7r,b7r,v7r,t4,Wqe,pc,a4,Gve,q8,F7r,Ove,T7r,Hqe,lr,N8,M7r,uc,E7r,QH,C7r,w7r,WH,A7r,y7r,L7r,j8,x7r,Vve,$7r,k7r,S7r,Pt,D8,R7r,Xve,B7r,P7r,_c,I7r,zve,q7r,N7r,HH,j7r,D7r,G7r,n4,O7r,Pr,G8,V7r,Qve,X7r,z7r,dn,Q7r,Wve,W7r,H7r,Hve,U7r,J7r,Uve,Y7r,K7r,Z7r,de,s4,Jve,eMr,oMr,UH,rMr,tMr,aMr,l4,Yve,nMr,sMr,JH,lMr,iMr,dMr,i4,Kve,cMr,fMr,YH,mMr,gMr,hMr,d4,Zve,pMr,uMr,KH,_Mr,bMr,vMr,c4,eFe,FMr,TMr,ZH,MMr,EMr,CMr,f4,oFe,wMr,AMr,eU,yMr,LMr,xMr,m4,rFe,$Mr,kMr,oU,SMr,RMr,BMr,g4,tFe,PMr,IMr,rU,qMr,NMr,jMr,h4,aFe,DMr,GMr,tU,OMr,VMr,XMr,p4,nFe,zMr,QMr,aU,WMr,HMr,UMr,u4,sFe,JMr,YMr,nU,KMr,ZMr,e4r,_4,lFe,o4r,r4r,sU,t4r,a4r,n4r,b4,iFe,s4r,l4r,lU,i4r,d4r,c4r,v4,dFe,f4r,m4r,iU,g4r,h4r,p4r,F4,cFe,u4r,_4r,dU,b4r,v4r,F4r,T4,fFe,T4r,M4r,cU,E4r,C4r,w4r,M4,mFe,A4r,y4r,fU,L4r,x4r,$4r,E4,gFe,k4r,S4r,mU,R4r,B4r,P4r,C4,hFe,I4r,q4r,gU,N4r,j4r,D4r,w4,pFe,G4r,O4r,hU,V4r,X4r,z4r,A4,Uqe,bc,y4,uFe,O8,Q4r,_Fe,W4r,Jqe,ir,V8,H4r,vc,U4r,pU,J4r,Y4r,uU,K4r,Z4r,eEr,X8,oEr,bFe,rEr,tEr,aEr,It,z8,nEr,vFe,sEr,lEr,Fc,iEr,FFe,dEr,cEr,_U,fEr,mEr,gEr,L4,hEr,Ir,Q8,pEr,TFe,uEr,_Er,cn,bEr,MFe,vEr,FEr,EFe,TEr,MEr,CFe,EEr,CEr,wEr,ce,x4,wFe,AEr,yEr,bU,LEr,xEr,$Er,$4,AFe,kEr,SEr,vU,REr,BEr,PEr,k4,yFe,IEr,qEr,FU,NEr,jEr,DEr,S4,LFe,GEr,OEr,TU,VEr,XEr,zEr,R4,xFe,QEr,WEr,MU,HEr,UEr,JEr,B4,$Fe,YEr,KEr,EU,ZEr,e5r,o5r,P4,kFe,r5r,t5r,CU,a5r,n5r,s5r,I4,SFe,l5r,i5r,wU,d5r,c5r,f5r,q4,RFe,m5r,g5r,AU,h5r,p5r,u5r,N4,BFe,_5r,b5r,yU,v5r,F5r,T5r,j4,PFe,M5r,E5r,LU,C5r,w5r,A5r,D4,IFe,y5r,L5r,xU,x5r,$5r,k5r,G4,qFe,S5r,R5r,$U,B5r,P5r,I5r,O4,NFe,q5r,N5r,kU,j5r,D5r,G5r,V4,jFe,O5r,V5r,SU,X5r,z5r,Q5r,X4,DFe,W5r,H5r,RU,U5r,J5r,Y5r,z4,GFe,K5r,Z5r,BU,eCr,oCr,rCr,Q4,OFe,tCr,aCr,PU,nCr,sCr,lCr,W4,VFe,iCr,dCr,IU,cCr,fCr,mCr,H4,XFe,gCr,hCr,qU,pCr,uCr,_Cr,U4,Yqe,Tc,J4,zFe,W8,bCr,QFe,vCr,Kqe,dr,H8,FCr,Mc,TCr,NU,MCr,ECr,jU,CCr,wCr,ACr,U8,yCr,WFe,LCr,xCr,$Cr,qt,J8,kCr,HFe,SCr,RCr,Ec,BCr,UFe,PCr,ICr,DU,qCr,NCr,jCr,Y4,DCr,qr,Y8,GCr,JFe,OCr,VCr,fn,XCr,YFe,zCr,QCr,KFe,WCr,HCr,ZFe,UCr,JCr,YCr,e6e,K4,o6e,KCr,ZCr,GU,e3r,o3r,r3r,Z4,Zqe,Cc,eE,r6e,K8,t3r,t6e,a3r,eNe,cr,Z8,n3r,wc,s3r,OU,l3r,i3r,VU,d3r,c3r,f3r,ex,m3r,a6e,g3r,h3r,p3r,Nt,ox,u3r,n6e,_3r,b3r,Ac,v3r,s6e,F3r,T3r,XU,M3r,E3r,C3r,oE,w3r,Nr,rx,A3r,l6e,y3r,L3r,mn,x3r,i6e,$3r,k3r,d6e,S3r,R3r,c6e,B3r,P3r,I3r,f6e,rE,m6e,q3r,N3r,zU,j3r,D3r,G3r,tE,oNe,yc,aE,g6e,tx,O3r,h6e,V3r,rNe,fr,ax,X3r,Lc,z3r,QU,Q3r,W3r,WU,H3r,U3r,J3r,nx,Y3r,p6e,K3r,Z3r,ewr,jt,sx,owr,u6e,rwr,twr,xc,awr,_6e,nwr,swr,HU,lwr,iwr,dwr,nE,cwr,jr,lx,fwr,b6e,mwr,gwr,gn,hwr,v6e,pwr,uwr,F6e,_wr,bwr,T6e,vwr,Fwr,Twr,re,sE,M6e,Mwr,Ewr,UU,Cwr,wwr,Awr,lE,E6e,ywr,Lwr,JU,xwr,$wr,kwr,iE,C6e,Swr,Rwr,YU,Bwr,Pwr,Iwr,dE,w6e,qwr,Nwr,KU,jwr,Dwr,Gwr,cE,A6e,Owr,Vwr,ZU,Xwr,zwr,Qwr,fE,y6e,Wwr,Hwr,eJ,Uwr,Jwr,Ywr,mE,L6e,Kwr,Zwr,oJ,eAr,oAr,rAr,gE,x6e,tAr,aAr,rJ,nAr,sAr,lAr,hE,$6e,iAr,dAr,tJ,cAr,fAr,mAr,pE,k6e,gAr,hAr,aJ,pAr,uAr,_Ar,uE,S6e,bAr,vAr,nJ,FAr,TAr,MAr,_E,R6e,EAr,CAr,sJ,wAr,AAr,yAr,bE,B6e,LAr,xAr,lJ,$Ar,kAr,SAr,vE,P6e,RAr,BAr,iJ,PAr,IAr,qAr,FE,I6e,NAr,jAr,dJ,DAr,GAr,OAr,TE,q6e,VAr,XAr,cJ,zAr,QAr,WAr,ME,N6e,HAr,UAr,fJ,JAr,YAr,KAr,EE,j6e,ZAr,eyr,mJ,oyr,ryr,tyr,CE,D6e,ayr,nyr,gJ,syr,lyr,iyr,wE,G6e,dyr,cyr,hJ,fyr,myr,gyr,AE,O6e,hyr,pyr,pJ,uyr,_yr,byr,yE,V6e,vyr,Fyr,uJ,Tyr,Myr,Eyr,LE,X6e,Cyr,wyr,_J,Ayr,yyr,Lyr,xE,z6e,xyr,$yr,bJ,kyr,Syr,Ryr,$E,Q6e,Byr,Pyr,vJ,Iyr,qyr,Nyr,kE,tNe,$c,SE,W6e,ix,jyr,H6e,Dyr,aNe,mr,dx,Gyr,kc,Oyr,FJ,Vyr,Xyr,TJ,zyr,Qyr,Wyr,cx,Hyr,U6e,Uyr,Jyr,Yyr,Dt,fx,Kyr,J6e,Zyr,eLr,Sc,oLr,Y6e,rLr,tLr,MJ,aLr,nLr,sLr,RE,lLr,Dr,mx,iLr,K6e,dLr,cLr,hn,fLr,Z6e,mLr,gLr,eTe,hLr,pLr,oTe,uLr,_Lr,bLr,ke,BE,rTe,vLr,FLr,EJ,TLr,MLr,ELr,PE,tTe,CLr,wLr,CJ,ALr,yLr,LLr,IE,aTe,xLr,$Lr,wJ,kLr,SLr,RLr,qE,nTe,BLr,PLr,AJ,ILr,qLr,NLr,NE,sTe,jLr,DLr,yJ,GLr,OLr,VLr,jE,lTe,XLr,zLr,LJ,QLr,WLr,HLr,DE,iTe,ULr,JLr,xJ,YLr,KLr,ZLr,GE,dTe,e8r,o8r,$J,r8r,t8r,a8r,OE,cTe,n8r,s8r,kJ,l8r,i8r,d8r,VE,nNe,Rc,XE,fTe,gx,c8r,mTe,f8r,sNe,gr,hx,m8r,Bc,g8r,SJ,h8r,p8r,RJ,u8r,_8r,b8r,px,v8r,gTe,F8r,T8r,M8r,Gt,ux,E8r,hTe,C8r,w8r,Pc,A8r,pTe,y8r,L8r,BJ,x8r,$8r,k8r,zE,S8r,Gr,_x,R8r,uTe,B8r,P8r,pn,I8r,_Te,q8r,N8r,bTe,j8r,D8r,vTe,G8r,O8r,V8r,Me,QE,FTe,X8r,z8r,PJ,Q8r,W8r,H8r,WE,TTe,U8r,J8r,IJ,Y8r,K8r,Z8r,HE,MTe,exr,oxr,qJ,rxr,txr,axr,UE,ETe,nxr,sxr,NJ,lxr,ixr,dxr,JE,CTe,cxr,fxr,jJ,mxr,gxr,hxr,YE,wTe,pxr,uxr,DJ,_xr,bxr,vxr,KE,ATe,Fxr,Txr,GJ,Mxr,Exr,Cxr,ZE,yTe,wxr,Axr,OJ,yxr,Lxr,xxr,e5,LTe,$xr,kxr,VJ,Sxr,Rxr,Bxr,o5,xTe,Pxr,Ixr,XJ,qxr,Nxr,jxr,r5,$Te,Dxr,Gxr,zJ,Oxr,Vxr,Xxr,t5,kTe,zxr,Qxr,QJ,Wxr,Hxr,Uxr,a5,lNe,Ic,n5,STe,bx,Jxr,RTe,Yxr,iNe,hr,vx,Kxr,qc,Zxr,WJ,e9r,o9r,HJ,r9r,t9r,a9r,Fx,n9r,BTe,s9r,l9r,i9r,Ot,Tx,d9r,PTe,c9r,f9r,Nc,m9r,ITe,g9r,h9r,UJ,p9r,u9r,_9r,s5,b9r,Or,Mx,v9r,qTe,F9r,T9r,un,M9r,NTe,E9r,C9r,jTe,w9r,A9r,DTe,y9r,L9r,x9r,Le,l5,GTe,$9r,k9r,JJ,S9r,R9r,B9r,i5,OTe,P9r,I9r,YJ,q9r,N9r,j9r,d5,VTe,D9r,G9r,KJ,O9r,V9r,X9r,c5,XTe,z9r,Q9r,ZJ,W9r,H9r,U9r,f5,zTe,J9r,Y9r,eY,K9r,Z9r,e$r,m5,QTe,o$r,r$r,oY,t$r,a$r,n$r,g5,WTe,s$r,l$r,rY,i$r,d$r,c$r,h5,HTe,f$r,m$r,tY,g$r,h$r,p$r,p5,UTe,u$r,_$r,aY,b$r,v$r,F$r,u5,JTe,T$r,M$r,nY,E$r,C$r,w$r,_5,dNe,jc,b5,YTe,Ex,A$r,KTe,y$r,cNe,pr,Cx,L$r,Dc,x$r,sY,$$r,k$r,lY,S$r,R$r,B$r,wx,P$r,ZTe,I$r,q$r,N$r,Vt,Ax,j$r,e7e,D$r,G$r,Gc,O$r,o7e,V$r,X$r,iY,z$r,Q$r,W$r,v5,H$r,Vr,yx,U$r,r7e,J$r,Y$r,_n,K$r,t7e,Z$r,ekr,a7e,okr,rkr,n7e,tkr,akr,nkr,Se,F5,s7e,skr,lkr,dY,ikr,dkr,ckr,T5,l7e,fkr,mkr,cY,gkr,hkr,pkr,M5,i7e,ukr,_kr,fY,bkr,vkr,Fkr,E5,d7e,Tkr,Mkr,mY,Ekr,Ckr,wkr,C5,c7e,Akr,ykr,gY,Lkr,xkr,$kr,w5,f7e,kkr,Skr,hY,Rkr,Bkr,Pkr,A5,m7e,Ikr,qkr,pY,Nkr,jkr,Dkr,y5,g7e,Gkr,Okr,uY,Vkr,Xkr,zkr,L5,h7e,Qkr,Wkr,_Y,Hkr,Ukr,Jkr,x5,fNe,Oc,$5,p7e,Lx,Ykr,u7e,Kkr,mNe,ur,xx,Zkr,Vc,eSr,bY,oSr,rSr,vY,tSr,aSr,nSr,$x,sSr,_7e,lSr,iSr,dSr,Xt,kx,cSr,b7e,fSr,mSr,Xc,gSr,v7e,hSr,pSr,FY,uSr,_Sr,bSr,k5,vSr,Xr,Sx,FSr,F7e,TSr,MSr,bn,ESr,T7e,CSr,wSr,M7e,ASr,ySr,E7e,LSr,xSr,$Sr,xe,S5,C7e,kSr,SSr,TY,RSr,BSr,PSr,R5,w7e,ISr,qSr,MY,NSr,jSr,DSr,B5,A7e,GSr,OSr,EY,VSr,XSr,zSr,P5,y7e,QSr,WSr,CY,HSr,USr,JSr,I5,L7e,YSr,KSr,wY,ZSr,eRr,oRr,q5,x7e,rRr,tRr,AY,aRr,nRr,sRr,N5,$7e,lRr,iRr,yY,dRr,cRr,fRr,j5,k7e,mRr,gRr,LY,hRr,pRr,uRr,D5,S7e,_Rr,bRr,xY,vRr,FRr,TRr,G5,R7e,MRr,ERr,$Y,CRr,wRr,ARr,O5,gNe,zc,V5,B7e,Rx,yRr,P7e,LRr,hNe,_r,Bx,xRr,Qc,$Rr,kY,kRr,SRr,SY,RRr,BRr,PRr,Px,IRr,I7e,qRr,NRr,jRr,zt,Ix,DRr,q7e,GRr,ORr,Wc,VRr,N7e,XRr,zRr,RY,QRr,WRr,HRr,X5,URr,zr,qx,JRr,j7e,YRr,KRr,vn,ZRr,D7e,eBr,oBr,G7e,rBr,tBr,O7e,aBr,nBr,sBr,$e,z5,V7e,lBr,iBr,BY,dBr,cBr,fBr,Q5,X7e,mBr,gBr,PY,hBr,pBr,uBr,W5,z7e,_Br,bBr,IY,vBr,FBr,TBr,H5,Q7e,MBr,EBr,qY,CBr,wBr,ABr,U5,W7e,yBr,LBr,NY,xBr,$Br,kBr,J5,H7e,SBr,RBr,jY,BBr,PBr,IBr,Y5,U7e,qBr,NBr,DY,jBr,DBr,GBr,K5,J7e,OBr,VBr,GY,XBr,zBr,QBr,Z5,Y7e,WBr,HBr,OY,UBr,JBr,YBr,eC,K7e,KBr,ZBr,VY,ePr,oPr,rPr,oC,pNe,Hc,rC,Z7e,Nx,tPr,eMe,aPr,uNe,br,jx,nPr,Uc,sPr,XY,lPr,iPr,zY,dPr,cPr,fPr,Dx,mPr,oMe,gPr,hPr,pPr,Qt,Gx,uPr,rMe,_Pr,bPr,Jc,vPr,tMe,FPr,TPr,QY,MPr,EPr,CPr,tC,wPr,Qr,Ox,APr,aMe,yPr,LPr,Fn,xPr,nMe,$Pr,kPr,sMe,SPr,RPr,lMe,BPr,PPr,IPr,De,aC,iMe,qPr,NPr,WY,jPr,DPr,GPr,nC,dMe,OPr,VPr,HY,XPr,zPr,QPr,sC,cMe,WPr,HPr,UY,UPr,JPr,YPr,lC,fMe,KPr,ZPr,JY,eIr,oIr,rIr,iC,mMe,tIr,aIr,YY,nIr,sIr,lIr,dC,gMe,iIr,dIr,KY,cIr,fIr,mIr,cC,hMe,gIr,hIr,ZY,pIr,uIr,_Ir,fC,pMe,bIr,vIr,eK,FIr,TIr,MIr,mC,_Ne,Yc,gC,uMe,Vx,EIr,_Me,CIr,bNe,vr,Xx,wIr,Kc,AIr,oK,yIr,LIr,rK,xIr,$Ir,kIr,zx,SIr,bMe,RIr,BIr,PIr,Wt,Qx,IIr,vMe,qIr,NIr,Zc,jIr,FMe,DIr,GIr,tK,OIr,VIr,XIr,hC,zIr,Wr,Wx,QIr,TMe,WIr,HIr,Tn,UIr,MMe,JIr,YIr,EMe,KIr,ZIr,CMe,eqr,oqr,rqr,Ge,pC,wMe,tqr,aqr,aK,nqr,sqr,lqr,uC,AMe,iqr,dqr,nK,cqr,fqr,mqr,_C,yMe,gqr,hqr,sK,pqr,uqr,_qr,bC,LMe,bqr,vqr,lK,Fqr,Tqr,Mqr,vC,xMe,Eqr,Cqr,iK,wqr,Aqr,yqr,FC,$Me,Lqr,xqr,dK,$qr,kqr,Sqr,TC,kMe,Rqr,Bqr,cK,Pqr,Iqr,qqr,MC,SMe,Nqr,jqr,fK,Dqr,Gqr,Oqr,EC,vNe,ef,CC,RMe,Hx,Vqr,BMe,Xqr,FNe,Fr,Ux,zqr,of,Qqr,mK,Wqr,Hqr,gK,Uqr,Jqr,Yqr,Jx,Kqr,PMe,Zqr,eNr,oNr,Ht,Yx,rNr,IMe,tNr,aNr,rf,nNr,qMe,sNr,lNr,hK,iNr,dNr,cNr,wC,fNr,Hr,Kx,mNr,NMe,gNr,hNr,Mn,pNr,jMe,uNr,_Nr,DMe,bNr,vNr,GMe,FNr,TNr,MNr,OMe,AC,VMe,ENr,CNr,pK,wNr,ANr,yNr,yC,TNe,tf,LC,XMe,Zx,LNr,zMe,xNr,MNe,Tr,e9,$Nr,af,kNr,uK,SNr,RNr,_K,BNr,PNr,INr,o9,qNr,QMe,NNr,jNr,DNr,Ut,r9,GNr,WMe,ONr,VNr,nf,XNr,HMe,zNr,QNr,bK,WNr,HNr,UNr,xC,JNr,Ur,t9,YNr,UMe,KNr,ZNr,En,ejr,JMe,ojr,rjr,YMe,tjr,ajr,KMe,njr,sjr,ljr,a9,$C,ZMe,ijr,djr,vK,cjr,fjr,mjr,kC,e4e,gjr,hjr,FK,pjr,ujr,_jr,SC,ENe,sf,RC,o4e,n9,bjr,r4e,vjr,CNe,Mr,s9,Fjr,lf,Tjr,TK,Mjr,Ejr,MK,Cjr,wjr,Ajr,l9,yjr,t4e,Ljr,xjr,$jr,Jt,i9,kjr,a4e,Sjr,Rjr,df,Bjr,n4e,Pjr,Ijr,EK,qjr,Njr,jjr,BC,Djr,Jr,d9,Gjr,s4e,Ojr,Vjr,Cn,Xjr,l4e,zjr,Qjr,i4e,Wjr,Hjr,d4e,Ujr,Jjr,Yjr,c4e,PC,f4e,Kjr,Zjr,CK,eDr,oDr,rDr,IC,wNe;return d=new oe({}),Ma=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),nA=new oe({}),sA=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),bf=new tDr({props:{warning:!0,$$slots:{default:[Jyt]},$$scope:{ctx:L}}}),lA=new oe({}),iA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/configuration_auto.py#L574"}}),fA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/configuration_auto.py#L597"}}),bg=new P({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Yyt]},$$scope:{ctx:L}}}),mA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/configuration_auto.py#L719"}}),gA=new oe({}),hA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/tokenization_auto.py#L379"}}),_A=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17060/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/tokenization_auto.py#L393"}}),Yg=new P({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Kyt]},$$scope:{ctx:L}}}),bA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/tokenization_auto.py#L589"}}),vA=new oe({}),FA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/feature_extraction_auto.py#L179"}}),EA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17060/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),Ah=new tDr({props:{$$slots:{default:[Zyt]},$$scope:{ctx:L}}}),yh=new P({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[eLt]},$$scope:{ctx:L}}}),CA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/feature_extraction_auto.py#L320"}}),wA=new oe({}),AA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/processing_auto.py#L78"}}),xA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/processing_auto.py#L92"}}),Qh=new tDr({props:{$$slots:{default:[oLt]},$$scope:{ctx:L}}}),Wh=new P({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[rLt]},$$scope:{ctx:L}}}),$A=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/processing_auto.py#L245"}}),kA=new oe({}),SA=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L725"}}),BA=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),Jh=new P({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[tLt]},$$scope:{ctx:L}}}),PA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),Gu=new P({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[aLt]},$$scope:{ctx:L}}}),IA=new oe({}),qA=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L732"}}),jA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),Vu=new P({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[nLt]},$$scope:{ctx:L}}}),DA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),k_=new P({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[sLt]},$$scope:{ctx:L}}}),GA=new oe({}),OA=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L747"}}),XA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),R_=new P({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[lLt]},$$scope:{ctx:L}}}),zA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),_0=new P({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[iLt]},$$scope:{ctx:L}}}),QA=new oe({}),WA=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L754"}}),UA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),v0=new P({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[dLt]},$$scope:{ctx:L}}}),JA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),r1=new P({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[cLt]},$$scope:{ctx:L}}}),YA=new oe({}),KA=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L761"}}),ey=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),a1=new P({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[fLt]},$$scope:{ctx:L}}}),oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),E1=new P({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[mLt]},$$scope:{ctx:L}}}),ry=new oe({}),ty=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L770"}}),ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),w1=new P({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[gLt]},$$scope:{ctx:L}}}),sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),Tb=new P({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[hLt]},$$scope:{ctx:L}}}),ly=new oe({}),iy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L804"}}),cy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),Eb=new P({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[pLt]},$$scope:{ctx:L}}}),fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),e2=new P({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[uLt]},$$scope:{ctx:L}}}),my=new oe({}),gy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L811"}}),py=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),r2=new P({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[_Lt]},$$scope:{ctx:L}}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),d2=new P({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[bLt]},$$scope:{ctx:L}}}),_y=new oe({}),by=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L797"}}),Fy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),f2=new P({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[vLt]},$$scope:{ctx:L}}}),Ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),W2=new P({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[FLt]},$$scope:{ctx:L}}}),My=new oe({}),Ey=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L779"}}),wy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),U2=new P({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[TLt]},$$scope:{ctx:L}}}),Ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),qv=new P({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[MLt]},$$scope:{ctx:L}}}),yy=new oe({}),Ly=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L786"}}),$y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),jv=new P({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[ELt]},$$scope:{ctx:L}}}),ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),Ov=new P({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[CLt]},$$scope:{ctx:L}}}),Sy=new oe({}),Ry=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L820"}}),Py=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),Xv=new P({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[wLt]},$$scope:{ctx:L}}}),Iy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),tF=new P({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[ALt]},$$scope:{ctx:L}}}),qy=new oe({}),Ny=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L859"}}),Dy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),nF=new P({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[yLt]},$$scope:{ctx:L}}}),Gy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),iF=new P({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[LLt]},$$scope:{ctx:L}}}),Oy=new oe({}),Vy=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L866"}}),zy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),cF=new P({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[xLt]},$$scope:{ctx:L}}}),Qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),FF=new P({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[$Lt]},$$scope:{ctx:L}}}),Wy=new oe({}),Hy=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L889"}}),Jy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),MF=new P({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[kLt]},$$scope:{ctx:L}}}),Yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),LF=new P({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[SLt]},$$scope:{ctx:L}}}),Ky=new oe({}),Zy=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L873"}}),oL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),$F=new P({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[RLt]},$$scope:{ctx:L}}}),rL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),DF=new P({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[BLt]},$$scope:{ctx:L}}}),tL=new oe({}),aL=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L880"}}),sL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),OF=new P({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[PLt]},$$scope:{ctx:L}}}),lL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),QF=new P({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[ILt]},$$scope:{ctx:L}}}),dL=new oe({}),cL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L898"}}),mL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),HF=new P({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[qLt]},$$scope:{ctx:L}}}),gL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),e6=new P({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[NLt]},$$scope:{ctx:L}}}),hL=new oe({}),pL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L905"}}),_L=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),r6=new P({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[jLt]},$$scope:{ctx:L}}}),bL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),l6=new P({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[DLt]},$$scope:{ctx:L}}}),vL=new oe({}),FL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L852"}}),ML=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),d6=new P({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[GLt]},$$scope:{ctx:L}}}),EL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),g6=new P({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[OLt]},$$scope:{ctx:L}}}),wL=new oe({}),AL=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L827"}}),LL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),p6=new P({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[VLt]},$$scope:{ctx:L}}}),xL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),b6=new P({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[XLt]},$$scope:{ctx:L}}}),$L=new oe({}),kL=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L834"}}),RL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),F6=new P({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[zLt]},$$scope:{ctx:L}}}),BL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),A6=new P({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[QLt]},$$scope:{ctx:L}}}),PL=new oe({}),IL=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_auto.py#L843"}}),NL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),L6=new P({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[WLt]},$$scope:{ctx:L}}}),jL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),k6=new P({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[HLt]},$$scope:{ctx:L}}}),DL=new oe({}),GL=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L383"}}),VL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),R6=new P({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[ULt]},$$scope:{ctx:L}}}),XL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),CT=new P({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[JLt]},$$scope:{ctx:L}}}),zL=new oe({}),QL=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L390"}}),HL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),AT=new P({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[YLt]},$$scope:{ctx:L}}}),UL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),JT=new P({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[KLt]},$$scope:{ctx:L}}}),JL=new oe({}),YL=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L405"}}),ZL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),KT=new P({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[ZLt]},$$scope:{ctx:L}}}),e8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),f7=new P({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[e8t]},$$scope:{ctx:L}}}),o8=new oe({}),r8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L412"}}),a8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),g7=new P({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[o8t]},$$scope:{ctx:L}}}),n8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),_7=new P({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[r8t]},$$scope:{ctx:L}}}),s8=new oe({}),l8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),d8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),v7=new P({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[t8t]},$$scope:{ctx:L}}}),c8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),D7=new P({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[a8t]},$$scope:{ctx:L}}}),f8=new oe({}),m8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L435"}}),h8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),O7=new P({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[n8t]},$$scope:{ctx:L}}}),p8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),Z7=new P({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[s8t]},$$scope:{ctx:L}}}),u8=new oe({}),_8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),v8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),oM=new P({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[l8t]},$$scope:{ctx:L}}}),F8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),LM=new P({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[i8t]},$$scope:{ctx:L}}}),T8=new oe({}),M8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),C8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),$M=new P({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[d8t]},$$scope:{ctx:L}}}),w8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),HM=new P({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[c8t]},$$scope:{ctx:L}}}),A8=new oe({}),y8=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L487"}}),x8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),JM=new P({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[f8t]},$$scope:{ctx:L}}}),$8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new P({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[m8t]},$$scope:{ctx:L}}}),S8=new oe({}),R8=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L460"}}),P8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),o4=new P({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[g8t]},$$scope:{ctx:L}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),t4=new P({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[h8t]},$$scope:{ctx:L}}}),q8=new oe({}),N8=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),D8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),n4=new P({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[p8t]},$$scope:{ctx:L}}}),G8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),A4=new P({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[u8t]},$$scope:{ctx:L}}}),O8=new oe({}),V8=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L453"}}),z8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),L4=new P({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[_8t]},$$scope:{ctx:L}}}),Q8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),U4=new P({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[b8t]},$$scope:{ctx:L}}}),W8=new oe({}),H8=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L421"}}),J8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),Y4=new P({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[v8t]},$$scope:{ctx:L}}}),Y8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),Z4=new P({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[F8t]},$$scope:{ctx:L}}}),K8=new oe({}),Z8=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_tf_auto.py#L496"}}),ox=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),oE=new P({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[T8t]},$$scope:{ctx:L}}}),rx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),tE=new P({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[M8t]},$$scope:{ctx:L}}}),tx=new oe({}),ax=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L241"}}),sx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),nE=new P({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[E8t]},$$scope:{ctx:L}}}),lx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),kE=new P({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[C8t]},$$scope:{ctx:L}}}),ix=new oe({}),dx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),fx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),RE=new P({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[w8t]},$$scope:{ctx:L}}}),mx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),VE=new P({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[A8t]},$$scope:{ctx:L}}}),gx=new oe({}),hx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),ux=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),zE=new P({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[y8t]},$$scope:{ctx:L}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new P({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[L8t]},$$scope:{ctx:L}}}),bx=new oe({}),vx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L262"}}),Tx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new P({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[x8t]},$$scope:{ctx:L}}}),Mx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),_5=new P({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[$8t]},$$scope:{ctx:L}}}),Ex=new oe({}),Cx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L269"}}),Ax=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),v5=new P({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[k8t]},$$scope:{ctx:L}}}),yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),x5=new P({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[S8t]},$$scope:{ctx:L}}}),Lx=new oe({}),xx=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L278"}}),kx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),k5=new P({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[R8t]},$$scope:{ctx:L}}}),Sx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),O5=new P({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[B8t]},$$scope:{ctx:L}}}),Rx=new oe({}),Bx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L287"}}),Ix=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),X5=new P({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[P8t]},$$scope:{ctx:L}}}),qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),oC=new P({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[I8t]},$$scope:{ctx:L}}}),Nx=new oe({}),jx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L294"}}),Gx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),tC=new P({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[q8t]},$$scope:{ctx:L}}}),Ox=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new P({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[N8t]},$$scope:{ctx:L}}}),Vx=new oe({}),Xx=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L303"}}),Qx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),hC=new P({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[j8t]},$$scope:{ctx:L}}}),Wx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),EC=new P({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[D8t]},$$scope:{ctx:L}}}),Hx=new oe({}),Ux=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),Yx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),wC=new P({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[G8t]},$$scope:{ctx:L}}}),Kx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),yC=new P({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[O8t]},$$scope:{ctx:L}}}),Zx=new oe({}),e9=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L319"}}),r9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),xC=new P({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[V8t]},$$scope:{ctx:L}}}),t9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),SC=new P({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[X8t]},$$scope:{ctx:L}}}),n9=new oe({}),s9=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/modeling_flax_auto.py#L328"}}),i9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L389"}}),BC=new P({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[z8t]},$$scope:{ctx:L}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17060/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17060/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17060/src/transformers/models/auto/auto_factory.py#L417"}}),IC=new P({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Q8t]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),ii=o("Auto Classes"),gf=l(),et=a("p"),di=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ci=a("code"),oA=o("from_pretrained()"),hf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),qe=l(),Xe=a("p"),fi=o("Instantiating one of "),An=a("a"),rA=o("AutoConfig"),yn=o(", "),Ln=a("a"),tA=o("AutoModel"),mi=o(`, and
`),xn=a("a"),aA=o("AutoTokenizer"),gi=o(" will directly create a class of the relevant architecture. For instance"),pf=l(),F(Ma.$$.fragment),ze=l(),Ae=a("p"),E$=o("will create a model that is an instance of "),hi=a("a"),C$=o("BertModel"),w$=o("."),Eo=l(),Ea=a("p"),A$=o("There is one class of "),uf=a("code"),y$=o("AutoModel"),RDe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),MIe=l(),pi=a("h2"),_f=a("a"),bee=a("span"),F(nA.$$.fragment),BDe=l(),vee=a("span"),PDe=o("Extending the Auto Classes"),EIe=l(),$n=a("p"),IDe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Fee=a("code"),qDe=o("NewModel"),NDe=o(", make sure you have a "),Tee=a("code"),jDe=o("NewModelConfig"),DDe=o(` then you can add those to the auto
classes like this:`),CIe=l(),F(sA.$$.fragment),wIe=l(),L$=a("p"),GDe=o("You will then be able to use the auto classes like you would usually do!"),AIe=l(),F(bf.$$.fragment),yIe=l(),ui=a("h2"),vf=a("a"),Mee=a("span"),F(lA.$$.fragment),ODe=l(),Eee=a("span"),VDe=o("AutoConfig"),LIe=l(),Co=a("div"),F(iA.$$.fragment),XDe=l(),dA=a("p"),zDe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),x$=a("a"),QDe=o("from_pretrained()"),WDe=o(" class method."),HDe=l(),cA=a("p"),UDe=o("This class cannot be instantiated directly using "),Cee=a("code"),JDe=o("__init__()"),YDe=o(" (throws an error)."),KDe=l(),Er=a("div"),F(fA.$$.fragment),ZDe=l(),wee=a("p"),eGe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),oGe=l(),_i=a("p"),rGe=o("The configuration class to instantiate is selected based on the "),Aee=a("code"),tGe=o("model_type"),aGe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),yee=a("code"),nGe=o("pretrained_model_name_or_path"),sGe=o(":"),lGe=l(),A=a("ul"),Ff=a("li"),Lee=a("strong"),iGe=o("albert"),dGe=o(" \u2014 "),$$=a("a"),cGe=o("AlbertConfig"),fGe=o(" (ALBERT model)"),mGe=l(),Tf=a("li"),xee=a("strong"),gGe=o("bart"),hGe=o(" \u2014 "),k$=a("a"),pGe=o("BartConfig"),uGe=o(" (BART model)"),_Ge=l(),Mf=a("li"),$ee=a("strong"),bGe=o("beit"),vGe=o(" \u2014 "),S$=a("a"),FGe=o("BeitConfig"),TGe=o(" (BEiT model)"),MGe=l(),Ef=a("li"),kee=a("strong"),EGe=o("bert"),CGe=o(" \u2014 "),R$=a("a"),wGe=o("BertConfig"),AGe=o(" (BERT model)"),yGe=l(),Cf=a("li"),See=a("strong"),LGe=o("bert-generation"),xGe=o(" \u2014 "),B$=a("a"),$Ge=o("BertGenerationConfig"),kGe=o(" (Bert Generation model)"),SGe=l(),wf=a("li"),Ree=a("strong"),RGe=o("big_bird"),BGe=o(" \u2014 "),P$=a("a"),PGe=o("BigBirdConfig"),IGe=o(" (BigBird model)"),qGe=l(),Af=a("li"),Bee=a("strong"),NGe=o("bigbird_pegasus"),jGe=o(" \u2014 "),I$=a("a"),DGe=o("BigBirdPegasusConfig"),GGe=o(" (BigBirdPegasus model)"),OGe=l(),yf=a("li"),Pee=a("strong"),VGe=o("blenderbot"),XGe=o(" \u2014 "),q$=a("a"),zGe=o("BlenderbotConfig"),QGe=o(" (Blenderbot model)"),WGe=l(),Lf=a("li"),Iee=a("strong"),HGe=o("blenderbot-small"),UGe=o(" \u2014 "),N$=a("a"),JGe=o("BlenderbotSmallConfig"),YGe=o(" (BlenderbotSmall model)"),KGe=l(),xf=a("li"),qee=a("strong"),ZGe=o("camembert"),eOe=o(" \u2014 "),j$=a("a"),oOe=o("CamembertConfig"),rOe=o(" (CamemBERT model)"),tOe=l(),$f=a("li"),Nee=a("strong"),aOe=o("canine"),nOe=o(" \u2014 "),D$=a("a"),sOe=o("CanineConfig"),lOe=o(" (Canine model)"),iOe=l(),kf=a("li"),jee=a("strong"),dOe=o("clip"),cOe=o(" \u2014 "),G$=a("a"),fOe=o("CLIPConfig"),mOe=o(" (CLIP model)"),gOe=l(),Sf=a("li"),Dee=a("strong"),hOe=o("convbert"),pOe=o(" \u2014 "),O$=a("a"),uOe=o("ConvBertConfig"),_Oe=o(" (ConvBERT model)"),bOe=l(),Rf=a("li"),Gee=a("strong"),vOe=o("convnext"),FOe=o(" \u2014 "),V$=a("a"),TOe=o("ConvNextConfig"),MOe=o(" (ConvNext model)"),EOe=l(),Bf=a("li"),Oee=a("strong"),COe=o("ctrl"),wOe=o(" \u2014 "),X$=a("a"),AOe=o("CTRLConfig"),yOe=o(" (CTRL model)"),LOe=l(),Pf=a("li"),Vee=a("strong"),xOe=o("data2vec-audio"),$Oe=o(" \u2014 "),z$=a("a"),kOe=o("Data2VecAudioConfig"),SOe=o(" (Data2VecAudio model)"),ROe=l(),If=a("li"),Xee=a("strong"),BOe=o("data2vec-text"),POe=o(" \u2014 "),Q$=a("a"),IOe=o("Data2VecTextConfig"),qOe=o(" (Data2VecText model)"),NOe=l(),qf=a("li"),zee=a("strong"),jOe=o("data2vec-vision"),DOe=o(" \u2014 "),W$=a("a"),GOe=o("Data2VecVisionConfig"),OOe=o(" (Data2VecVision model)"),VOe=l(),Nf=a("li"),Qee=a("strong"),XOe=o("deberta"),zOe=o(" \u2014 "),H$=a("a"),QOe=o("DebertaConfig"),WOe=o(" (DeBERTa model)"),HOe=l(),jf=a("li"),Wee=a("strong"),UOe=o("deberta-v2"),JOe=o(" \u2014 "),U$=a("a"),YOe=o("DebertaV2Config"),KOe=o(" (DeBERTa-v2 model)"),ZOe=l(),Df=a("li"),Hee=a("strong"),eVe=o("decision_transformer"),oVe=o(" \u2014 "),J$=a("a"),rVe=o("DecisionTransformerConfig"),tVe=o(" (Decision Transformer model)"),aVe=l(),Gf=a("li"),Uee=a("strong"),nVe=o("deit"),sVe=o(" \u2014 "),Y$=a("a"),lVe=o("DeiTConfig"),iVe=o(" (DeiT model)"),dVe=l(),Of=a("li"),Jee=a("strong"),cVe=o("detr"),fVe=o(" \u2014 "),K$=a("a"),mVe=o("DetrConfig"),gVe=o(" (DETR model)"),hVe=l(),Vf=a("li"),Yee=a("strong"),pVe=o("distilbert"),uVe=o(" \u2014 "),Z$=a("a"),_Ve=o("DistilBertConfig"),bVe=o(" (DistilBERT model)"),vVe=l(),Xf=a("li"),Kee=a("strong"),FVe=o("dpr"),TVe=o(" \u2014 "),ek=a("a"),MVe=o("DPRConfig"),EVe=o(" (DPR model)"),CVe=l(),zf=a("li"),Zee=a("strong"),wVe=o("dpt"),AVe=o(" \u2014 "),ok=a("a"),yVe=o("DPTConfig"),LVe=o(" (DPT model)"),xVe=l(),Qf=a("li"),eoe=a("strong"),$Ve=o("electra"),kVe=o(" \u2014 "),rk=a("a"),SVe=o("ElectraConfig"),RVe=o(" (ELECTRA model)"),BVe=l(),Wf=a("li"),ooe=a("strong"),PVe=o("encoder-decoder"),IVe=o(" \u2014 "),tk=a("a"),qVe=o("EncoderDecoderConfig"),NVe=o(" (Encoder decoder model)"),jVe=l(),Hf=a("li"),roe=a("strong"),DVe=o("flaubert"),GVe=o(" \u2014 "),ak=a("a"),OVe=o("FlaubertConfig"),VVe=o(" (FlauBERT model)"),XVe=l(),Uf=a("li"),toe=a("strong"),zVe=o("flava"),QVe=o(" \u2014 "),nk=a("a"),WVe=o("FlavaConfig"),HVe=o(" (Flava model)"),UVe=l(),Jf=a("li"),aoe=a("strong"),JVe=o("fnet"),YVe=o(" \u2014 "),sk=a("a"),KVe=o("FNetConfig"),ZVe=o(" (FNet model)"),eXe=l(),Yf=a("li"),noe=a("strong"),oXe=o("fsmt"),rXe=o(" \u2014 "),lk=a("a"),tXe=o("FSMTConfig"),aXe=o(" (FairSeq Machine-Translation model)"),nXe=l(),Kf=a("li"),soe=a("strong"),sXe=o("funnel"),lXe=o(" \u2014 "),ik=a("a"),iXe=o("FunnelConfig"),dXe=o(" (Funnel Transformer model)"),cXe=l(),Zf=a("li"),loe=a("strong"),fXe=o("glpn"),mXe=o(" \u2014 "),dk=a("a"),gXe=o("GLPNConfig"),hXe=o(" (GLPN model)"),pXe=l(),em=a("li"),ioe=a("strong"),uXe=o("gpt2"),_Xe=o(" \u2014 "),ck=a("a"),bXe=o("GPT2Config"),vXe=o(" (OpenAI GPT-2 model)"),FXe=l(),om=a("li"),doe=a("strong"),TXe=o("gpt_neo"),MXe=o(" \u2014 "),fk=a("a"),EXe=o("GPTNeoConfig"),CXe=o(" (GPT Neo model)"),wXe=l(),rm=a("li"),coe=a("strong"),AXe=o("gptj"),yXe=o(" \u2014 "),mk=a("a"),LXe=o("GPTJConfig"),xXe=o(" (GPT-J model)"),$Xe=l(),tm=a("li"),foe=a("strong"),kXe=o("hubert"),SXe=o(" \u2014 "),gk=a("a"),RXe=o("HubertConfig"),BXe=o(" (Hubert model)"),PXe=l(),am=a("li"),moe=a("strong"),IXe=o("ibert"),qXe=o(" \u2014 "),hk=a("a"),NXe=o("IBertConfig"),jXe=o(" (I-BERT model)"),DXe=l(),nm=a("li"),goe=a("strong"),GXe=o("imagegpt"),OXe=o(" \u2014 "),pk=a("a"),VXe=o("ImageGPTConfig"),XXe=o(" (ImageGPT model)"),zXe=l(),sm=a("li"),hoe=a("strong"),QXe=o("layoutlm"),WXe=o(" \u2014 "),uk=a("a"),HXe=o("LayoutLMConfig"),UXe=o(" (LayoutLM model)"),JXe=l(),lm=a("li"),poe=a("strong"),YXe=o("layoutlmv2"),KXe=o(" \u2014 "),_k=a("a"),ZXe=o("LayoutLMv2Config"),eze=o(" (LayoutLMv2 model)"),oze=l(),im=a("li"),uoe=a("strong"),rze=o("layoutlmv3"),tze=o(" \u2014 "),bk=a("a"),aze=o("LayoutLMv3Config"),nze=o(" (LayoutLMv3 model)"),sze=l(),dm=a("li"),_oe=a("strong"),lze=o("led"),ize=o(" \u2014 "),vk=a("a"),dze=o("LEDConfig"),cze=o(" (LED model)"),fze=l(),cm=a("li"),boe=a("strong"),mze=o("longformer"),gze=o(" \u2014 "),Fk=a("a"),hze=o("LongformerConfig"),pze=o(" (Longformer model)"),uze=l(),fm=a("li"),voe=a("strong"),_ze=o("luke"),bze=o(" \u2014 "),Tk=a("a"),vze=o("LukeConfig"),Fze=o(" (LUKE model)"),Tze=l(),mm=a("li"),Foe=a("strong"),Mze=o("lxmert"),Eze=o(" \u2014 "),Mk=a("a"),Cze=o("LxmertConfig"),wze=o(" (LXMERT model)"),Aze=l(),gm=a("li"),Toe=a("strong"),yze=o("m2m_100"),Lze=o(" \u2014 "),Ek=a("a"),xze=o("M2M100Config"),$ze=o(" (M2M100 model)"),kze=l(),hm=a("li"),Moe=a("strong"),Sze=o("marian"),Rze=o(" \u2014 "),Ck=a("a"),Bze=o("MarianConfig"),Pze=o(" (Marian model)"),Ize=l(),pm=a("li"),Eoe=a("strong"),qze=o("maskformer"),Nze=o(" \u2014 "),wk=a("a"),jze=o("MaskFormerConfig"),Dze=o(" (MaskFormer model)"),Gze=l(),um=a("li"),Coe=a("strong"),Oze=o("mbart"),Vze=o(" \u2014 "),Ak=a("a"),Xze=o("MBartConfig"),zze=o(" (mBART model)"),Qze=l(),_m=a("li"),woe=a("strong"),Wze=o("megatron-bert"),Hze=o(" \u2014 "),yk=a("a"),Uze=o("MegatronBertConfig"),Jze=o(" (MegatronBert model)"),Yze=l(),bm=a("li"),Aoe=a("strong"),Kze=o("mobilebert"),Zze=o(" \u2014 "),Lk=a("a"),eQe=o("MobileBertConfig"),oQe=o(" (MobileBERT model)"),rQe=l(),vm=a("li"),yoe=a("strong"),tQe=o("mpnet"),aQe=o(" \u2014 "),xk=a("a"),nQe=o("MPNetConfig"),sQe=o(" (MPNet model)"),lQe=l(),Fm=a("li"),Loe=a("strong"),iQe=o("mt5"),dQe=o(" \u2014 "),$k=a("a"),cQe=o("MT5Config"),fQe=o(" (mT5 model)"),mQe=l(),Tm=a("li"),xoe=a("strong"),gQe=o("nystromformer"),hQe=o(" \u2014 "),kk=a("a"),pQe=o("NystromformerConfig"),uQe=o(" (Nystromformer model)"),_Qe=l(),Mm=a("li"),$oe=a("strong"),bQe=o("openai-gpt"),vQe=o(" \u2014 "),Sk=a("a"),FQe=o("OpenAIGPTConfig"),TQe=o(" (OpenAI GPT model)"),MQe=l(),Em=a("li"),koe=a("strong"),EQe=o("opt"),CQe=o(" \u2014 "),Rk=a("a"),wQe=o("OPTConfig"),AQe=o(" (OPT model)"),yQe=l(),Cm=a("li"),Soe=a("strong"),LQe=o("pegasus"),xQe=o(" \u2014 "),Bk=a("a"),$Qe=o("PegasusConfig"),kQe=o(" (Pegasus model)"),SQe=l(),wm=a("li"),Roe=a("strong"),RQe=o("perceiver"),BQe=o(" \u2014 "),Pk=a("a"),PQe=o("PerceiverConfig"),IQe=o(" (Perceiver model)"),qQe=l(),Am=a("li"),Boe=a("strong"),NQe=o("plbart"),jQe=o(" \u2014 "),Ik=a("a"),DQe=o("PLBartConfig"),GQe=o(" (PLBart model)"),OQe=l(),ym=a("li"),Poe=a("strong"),VQe=o("poolformer"),XQe=o(" \u2014 "),qk=a("a"),zQe=o("PoolFormerConfig"),QQe=o(" (PoolFormer model)"),WQe=l(),Lm=a("li"),Ioe=a("strong"),HQe=o("prophetnet"),UQe=o(" \u2014 "),Nk=a("a"),JQe=o("ProphetNetConfig"),YQe=o(" (ProphetNet model)"),KQe=l(),xm=a("li"),qoe=a("strong"),ZQe=o("qdqbert"),eWe=o(" \u2014 "),jk=a("a"),oWe=o("QDQBertConfig"),rWe=o(" (QDQBert model)"),tWe=l(),$m=a("li"),Noe=a("strong"),aWe=o("rag"),nWe=o(" \u2014 "),Dk=a("a"),sWe=o("RagConfig"),lWe=o(" (RAG model)"),iWe=l(),km=a("li"),joe=a("strong"),dWe=o("realm"),cWe=o(" \u2014 "),Gk=a("a"),fWe=o("RealmConfig"),mWe=o(" (Realm model)"),gWe=l(),Sm=a("li"),Doe=a("strong"),hWe=o("reformer"),pWe=o(" \u2014 "),Ok=a("a"),uWe=o("ReformerConfig"),_We=o(" (Reformer model)"),bWe=l(),Rm=a("li"),Goe=a("strong"),vWe=o("regnet"),FWe=o(" \u2014 "),Vk=a("a"),TWe=o("RegNetConfig"),MWe=o(" (RegNet model)"),EWe=l(),Bm=a("li"),Ooe=a("strong"),CWe=o("rembert"),wWe=o(" \u2014 "),Xk=a("a"),AWe=o("RemBertConfig"),yWe=o(" (RemBERT model)"),LWe=l(),Pm=a("li"),Voe=a("strong"),xWe=o("resnet"),$We=o(" \u2014 "),zk=a("a"),kWe=o("ResNetConfig"),SWe=o(" (ResNet model)"),RWe=l(),Im=a("li"),Xoe=a("strong"),BWe=o("retribert"),PWe=o(" \u2014 "),Qk=a("a"),IWe=o("RetriBertConfig"),qWe=o(" (RetriBERT model)"),NWe=l(),qm=a("li"),zoe=a("strong"),jWe=o("roberta"),DWe=o(" \u2014 "),Wk=a("a"),GWe=o("RobertaConfig"),OWe=o(" (RoBERTa model)"),VWe=l(),Nm=a("li"),Qoe=a("strong"),XWe=o("roformer"),zWe=o(" \u2014 "),Hk=a("a"),QWe=o("RoFormerConfig"),WWe=o(" (RoFormer model)"),HWe=l(),jm=a("li"),Woe=a("strong"),UWe=o("segformer"),JWe=o(" \u2014 "),Uk=a("a"),YWe=o("SegformerConfig"),KWe=o(" (SegFormer model)"),ZWe=l(),Dm=a("li"),Hoe=a("strong"),eHe=o("sew"),oHe=o(" \u2014 "),Jk=a("a"),rHe=o("SEWConfig"),tHe=o(" (SEW model)"),aHe=l(),Gm=a("li"),Uoe=a("strong"),nHe=o("sew-d"),sHe=o(" \u2014 "),Yk=a("a"),lHe=o("SEWDConfig"),iHe=o(" (SEW-D model)"),dHe=l(),Om=a("li"),Joe=a("strong"),cHe=o("speech-encoder-decoder"),fHe=o(" \u2014 "),Kk=a("a"),mHe=o("SpeechEncoderDecoderConfig"),gHe=o(" (Speech Encoder decoder model)"),hHe=l(),Vm=a("li"),Yoe=a("strong"),pHe=o("speech_to_text"),uHe=o(" \u2014 "),Zk=a("a"),_He=o("Speech2TextConfig"),bHe=o(" (Speech2Text model)"),vHe=l(),Xm=a("li"),Koe=a("strong"),FHe=o("speech_to_text_2"),THe=o(" \u2014 "),eS=a("a"),MHe=o("Speech2Text2Config"),EHe=o(" (Speech2Text2 model)"),CHe=l(),zm=a("li"),Zoe=a("strong"),wHe=o("splinter"),AHe=o(" \u2014 "),oS=a("a"),yHe=o("SplinterConfig"),LHe=o(" (Splinter model)"),xHe=l(),Qm=a("li"),ere=a("strong"),$He=o("squeezebert"),kHe=o(" \u2014 "),rS=a("a"),SHe=o("SqueezeBertConfig"),RHe=o(" (SqueezeBERT model)"),BHe=l(),Wm=a("li"),ore=a("strong"),PHe=o("swin"),IHe=o(" \u2014 "),tS=a("a"),qHe=o("SwinConfig"),NHe=o(" (Swin model)"),jHe=l(),Hm=a("li"),rre=a("strong"),DHe=o("t5"),GHe=o(" \u2014 "),aS=a("a"),OHe=o("T5Config"),VHe=o(" (T5 model)"),XHe=l(),Um=a("li"),tre=a("strong"),zHe=o("tapas"),QHe=o(" \u2014 "),nS=a("a"),WHe=o("TapasConfig"),HHe=o(" (TAPAS model)"),UHe=l(),Jm=a("li"),are=a("strong"),JHe=o("tapex"),YHe=o(" \u2014 "),sS=a("a"),KHe=o("BartConfig"),ZHe=o(" (TAPEX model)"),eUe=l(),Ym=a("li"),nre=a("strong"),oUe=o("transfo-xl"),rUe=o(" \u2014 "),lS=a("a"),tUe=o("TransfoXLConfig"),aUe=o(" (Transformer-XL model)"),nUe=l(),Km=a("li"),sre=a("strong"),sUe=o("trocr"),lUe=o(" \u2014 "),iS=a("a"),iUe=o("TrOCRConfig"),dUe=o(" (TrOCR model)"),cUe=l(),Zm=a("li"),lre=a("strong"),fUe=o("unispeech"),mUe=o(" \u2014 "),dS=a("a"),gUe=o("UniSpeechConfig"),hUe=o(" (UniSpeech model)"),pUe=l(),eg=a("li"),ire=a("strong"),uUe=o("unispeech-sat"),_Ue=o(" \u2014 "),cS=a("a"),bUe=o("UniSpeechSatConfig"),vUe=o(" (UniSpeechSat model)"),FUe=l(),og=a("li"),dre=a("strong"),TUe=o("van"),MUe=o(" \u2014 "),fS=a("a"),EUe=o("VanConfig"),CUe=o(" (VAN model)"),wUe=l(),rg=a("li"),cre=a("strong"),AUe=o("vilt"),yUe=o(" \u2014 "),mS=a("a"),LUe=o("ViltConfig"),xUe=o(" (ViLT model)"),$Ue=l(),tg=a("li"),fre=a("strong"),kUe=o("vision-encoder-decoder"),SUe=o(" \u2014 "),gS=a("a"),RUe=o("VisionEncoderDecoderConfig"),BUe=o(" (Vision Encoder decoder model)"),PUe=l(),ag=a("li"),mre=a("strong"),IUe=o("vision-text-dual-encoder"),qUe=o(" \u2014 "),hS=a("a"),NUe=o("VisionTextDualEncoderConfig"),jUe=o(" (VisionTextDualEncoder model)"),DUe=l(),ng=a("li"),gre=a("strong"),GUe=o("visual_bert"),OUe=o(" \u2014 "),pS=a("a"),VUe=o("VisualBertConfig"),XUe=o(" (VisualBert model)"),zUe=l(),sg=a("li"),hre=a("strong"),QUe=o("vit"),WUe=o(" \u2014 "),uS=a("a"),HUe=o("ViTConfig"),UUe=o(" (ViT model)"),JUe=l(),lg=a("li"),pre=a("strong"),YUe=o("vit_mae"),KUe=o(" \u2014 "),_S=a("a"),ZUe=o("ViTMAEConfig"),eJe=o(" (ViTMAE model)"),oJe=l(),ig=a("li"),ure=a("strong"),rJe=o("wav2vec2"),tJe=o(" \u2014 "),bS=a("a"),aJe=o("Wav2Vec2Config"),nJe=o(" (Wav2Vec2 model)"),sJe=l(),dg=a("li"),_re=a("strong"),lJe=o("wavlm"),iJe=o(" \u2014 "),vS=a("a"),dJe=o("WavLMConfig"),cJe=o(" (WavLM model)"),fJe=l(),cg=a("li"),bre=a("strong"),mJe=o("xglm"),gJe=o(" \u2014 "),FS=a("a"),hJe=o("XGLMConfig"),pJe=o(" (XGLM model)"),uJe=l(),fg=a("li"),vre=a("strong"),_Je=o("xlm"),bJe=o(" \u2014 "),TS=a("a"),vJe=o("XLMConfig"),FJe=o(" (XLM model)"),TJe=l(),mg=a("li"),Fre=a("strong"),MJe=o("xlm-prophetnet"),EJe=o(" \u2014 "),MS=a("a"),CJe=o("XLMProphetNetConfig"),wJe=o(" (XLMProphetNet model)"),AJe=l(),gg=a("li"),Tre=a("strong"),yJe=o("xlm-roberta"),LJe=o(" \u2014 "),ES=a("a"),xJe=o("XLMRobertaConfig"),$Je=o(" (XLM-RoBERTa model)"),kJe=l(),hg=a("li"),Mre=a("strong"),SJe=o("xlm-roberta-xl"),RJe=o(" \u2014 "),CS=a("a"),BJe=o("XLMRobertaXLConfig"),PJe=o(" (XLM-RoBERTa-XL model)"),IJe=l(),pg=a("li"),Ere=a("strong"),qJe=o("xlnet"),NJe=o(" \u2014 "),wS=a("a"),jJe=o("XLNetConfig"),DJe=o(" (XLNet model)"),GJe=l(),ug=a("li"),Cre=a("strong"),OJe=o("yolos"),VJe=o(" \u2014 "),AS=a("a"),XJe=o("YolosConfig"),zJe=o(" (YOLOS model)"),QJe=l(),_g=a("li"),wre=a("strong"),WJe=o("yoso"),HJe=o(" \u2014 "),yS=a("a"),UJe=o("YosoConfig"),JJe=o(" (YOSO model)"),YJe=l(),F(bg.$$.fragment),KJe=l(),vg=a("div"),F(mA.$$.fragment),ZJe=l(),Are=a("p"),eYe=o("Register a new configuration for this class."),xIe=l(),bi=a("h2"),Fg=a("a"),yre=a("span"),F(gA.$$.fragment),oYe=l(),Lre=a("span"),rYe=o("AutoTokenizer"),$Ie=l(),wo=a("div"),F(hA.$$.fragment),tYe=l(),pA=a("p"),aYe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),LS=a("a"),nYe=o("AutoTokenizer.from_pretrained()"),sYe=o(" class method."),lYe=l(),uA=a("p"),iYe=o("This class cannot be instantiated directly using "),xre=a("code"),dYe=o("__init__()"),cYe=o(" (throws an error)."),fYe=l(),Cr=a("div"),F(_A.$$.fragment),mYe=l(),$re=a("p"),gYe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),hYe=l(),Ca=a("p"),pYe=o("The tokenizer class to instantiate is selected based on the "),kre=a("code"),uYe=o("model_type"),_Ye=o(` property of the config object (either
passed as an argument or loaded from `),Sre=a("code"),bYe=o("pretrained_model_name_or_path"),vYe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rre=a("code"),FYe=o("pretrained_model_name_or_path"),TYe=o(":"),MYe=l(),k=a("ul"),kn=a("li"),Bre=a("strong"),EYe=o("albert"),CYe=o(" \u2014 "),xS=a("a"),wYe=o("AlbertTokenizer"),AYe=o(" or "),$S=a("a"),yYe=o("AlbertTokenizerFast"),LYe=o(" (ALBERT model)"),xYe=l(),Sn=a("li"),Pre=a("strong"),$Ye=o("bart"),kYe=o(" \u2014 "),kS=a("a"),SYe=o("BartTokenizer"),RYe=o(" or "),SS=a("a"),BYe=o("BartTokenizerFast"),PYe=o(" (BART model)"),IYe=l(),Rn=a("li"),Ire=a("strong"),qYe=o("barthez"),NYe=o(" \u2014 "),RS=a("a"),jYe=o("BarthezTokenizer"),DYe=o(" or "),BS=a("a"),GYe=o("BarthezTokenizerFast"),OYe=o(" (BARThez model)"),VYe=l(),Tg=a("li"),qre=a("strong"),XYe=o("bartpho"),zYe=o(" \u2014 "),PS=a("a"),QYe=o("BartphoTokenizer"),WYe=o(" (BARTpho model)"),HYe=l(),Bn=a("li"),Nre=a("strong"),UYe=o("bert"),JYe=o(" \u2014 "),IS=a("a"),YYe=o("BertTokenizer"),KYe=o(" or "),qS=a("a"),ZYe=o("BertTokenizerFast"),eKe=o(" (BERT model)"),oKe=l(),Mg=a("li"),jre=a("strong"),rKe=o("bert-generation"),tKe=o(" \u2014 "),NS=a("a"),aKe=o("BertGenerationTokenizer"),nKe=o(" (Bert Generation model)"),sKe=l(),Eg=a("li"),Dre=a("strong"),lKe=o("bert-japanese"),iKe=o(" \u2014 "),jS=a("a"),dKe=o("BertJapaneseTokenizer"),cKe=o(" (BertJapanese model)"),fKe=l(),Cg=a("li"),Gre=a("strong"),mKe=o("bertweet"),gKe=o(" \u2014 "),DS=a("a"),hKe=o("BertweetTokenizer"),pKe=o(" (Bertweet model)"),uKe=l(),Pn=a("li"),Ore=a("strong"),_Ke=o("big_bird"),bKe=o(" \u2014 "),GS=a("a"),vKe=o("BigBirdTokenizer"),FKe=o(" or "),OS=a("a"),TKe=o("BigBirdTokenizerFast"),MKe=o(" (BigBird model)"),EKe=l(),In=a("li"),Vre=a("strong"),CKe=o("bigbird_pegasus"),wKe=o(" \u2014 "),VS=a("a"),AKe=o("PegasusTokenizer"),yKe=o(" or "),XS=a("a"),LKe=o("PegasusTokenizerFast"),xKe=o(" (BigBirdPegasus model)"),$Ke=l(),qn=a("li"),Xre=a("strong"),kKe=o("blenderbot"),SKe=o(" \u2014 "),zS=a("a"),RKe=o("BlenderbotTokenizer"),BKe=o(" or "),QS=a("a"),PKe=o("BlenderbotTokenizerFast"),IKe=o(" (Blenderbot model)"),qKe=l(),wg=a("li"),zre=a("strong"),NKe=o("blenderbot-small"),jKe=o(" \u2014 "),WS=a("a"),DKe=o("BlenderbotSmallTokenizer"),GKe=o(" (BlenderbotSmall model)"),OKe=l(),Ag=a("li"),Qre=a("strong"),VKe=o("byt5"),XKe=o(" \u2014 "),HS=a("a"),zKe=o("ByT5Tokenizer"),QKe=o(" (ByT5 model)"),WKe=l(),Nn=a("li"),Wre=a("strong"),HKe=o("camembert"),UKe=o(" \u2014 "),US=a("a"),JKe=o("CamembertTokenizer"),YKe=o(" or "),JS=a("a"),KKe=o("CamembertTokenizerFast"),ZKe=o(" (CamemBERT model)"),eZe=l(),yg=a("li"),Hre=a("strong"),oZe=o("canine"),rZe=o(" \u2014 "),YS=a("a"),tZe=o("CanineTokenizer"),aZe=o(" (Canine model)"),nZe=l(),jn=a("li"),Ure=a("strong"),sZe=o("clip"),lZe=o(" \u2014 "),KS=a("a"),iZe=o("CLIPTokenizer"),dZe=o(" or "),ZS=a("a"),cZe=o("CLIPTokenizerFast"),fZe=o(" (CLIP model)"),mZe=l(),Dn=a("li"),Jre=a("strong"),gZe=o("convbert"),hZe=o(" \u2014 "),eR=a("a"),pZe=o("ConvBertTokenizer"),uZe=o(" or "),oR=a("a"),_Ze=o("ConvBertTokenizerFast"),bZe=o(" (ConvBERT model)"),vZe=l(),Gn=a("li"),Yre=a("strong"),FZe=o("cpm"),TZe=o(" \u2014 "),rR=a("a"),MZe=o("CpmTokenizer"),EZe=o(" or "),tR=a("a"),CZe=o("CpmTokenizerFast"),wZe=o(" (CPM model)"),AZe=l(),Lg=a("li"),Kre=a("strong"),yZe=o("ctrl"),LZe=o(" \u2014 "),aR=a("a"),xZe=o("CTRLTokenizer"),$Ze=o(" (CTRL model)"),kZe=l(),On=a("li"),Zre=a("strong"),SZe=o("data2vec-text"),RZe=o(" \u2014 "),nR=a("a"),BZe=o("RobertaTokenizer"),PZe=o(" or "),sR=a("a"),IZe=o("RobertaTokenizerFast"),qZe=o(" (Data2VecText model)"),NZe=l(),Vn=a("li"),ete=a("strong"),jZe=o("deberta"),DZe=o(" \u2014 "),lR=a("a"),GZe=o("DebertaTokenizer"),OZe=o(" or "),iR=a("a"),VZe=o("DebertaTokenizerFast"),XZe=o(" (DeBERTa model)"),zZe=l(),Xn=a("li"),ote=a("strong"),QZe=o("deberta-v2"),WZe=o(" \u2014 "),dR=a("a"),HZe=o("DebertaV2Tokenizer"),UZe=o(" or "),cR=a("a"),JZe=o("DebertaV2TokenizerFast"),YZe=o(" (DeBERTa-v2 model)"),KZe=l(),zn=a("li"),rte=a("strong"),ZZe=o("distilbert"),eeo=o(" \u2014 "),fR=a("a"),oeo=o("DistilBertTokenizer"),reo=o(" or "),mR=a("a"),teo=o("DistilBertTokenizerFast"),aeo=o(" (DistilBERT model)"),neo=l(),Qn=a("li"),tte=a("strong"),seo=o("dpr"),leo=o(" \u2014 "),gR=a("a"),ieo=o("DPRQuestionEncoderTokenizer"),deo=o(" or "),hR=a("a"),ceo=o("DPRQuestionEncoderTokenizerFast"),feo=o(" (DPR model)"),meo=l(),Wn=a("li"),ate=a("strong"),geo=o("electra"),heo=o(" \u2014 "),pR=a("a"),peo=o("ElectraTokenizer"),ueo=o(" or "),uR=a("a"),_eo=o("ElectraTokenizerFast"),beo=o(" (ELECTRA model)"),veo=l(),xg=a("li"),nte=a("strong"),Feo=o("flaubert"),Teo=o(" \u2014 "),_R=a("a"),Meo=o("FlaubertTokenizer"),Eeo=o(" (FlauBERT model)"),Ceo=l(),Hn=a("li"),ste=a("strong"),weo=o("fnet"),Aeo=o(" \u2014 "),bR=a("a"),yeo=o("FNetTokenizer"),Leo=o(" or "),vR=a("a"),xeo=o("FNetTokenizerFast"),$eo=o(" (FNet model)"),keo=l(),$g=a("li"),lte=a("strong"),Seo=o("fsmt"),Reo=o(" \u2014 "),FR=a("a"),Beo=o("FSMTTokenizer"),Peo=o(" (FairSeq Machine-Translation model)"),Ieo=l(),Un=a("li"),ite=a("strong"),qeo=o("funnel"),Neo=o(" \u2014 "),TR=a("a"),jeo=o("FunnelTokenizer"),Deo=o(" or "),MR=a("a"),Geo=o("FunnelTokenizerFast"),Oeo=o(" (Funnel Transformer model)"),Veo=l(),Jn=a("li"),dte=a("strong"),Xeo=o("gpt2"),zeo=o(" \u2014 "),ER=a("a"),Qeo=o("GPT2Tokenizer"),Weo=o(" or "),CR=a("a"),Heo=o("GPT2TokenizerFast"),Ueo=o(" (OpenAI GPT-2 model)"),Jeo=l(),Yn=a("li"),cte=a("strong"),Yeo=o("gpt_neo"),Keo=o(" \u2014 "),wR=a("a"),Zeo=o("GPT2Tokenizer"),eoo=o(" or "),AR=a("a"),ooo=o("GPT2TokenizerFast"),roo=o(" (GPT Neo model)"),too=l(),Kn=a("li"),fte=a("strong"),aoo=o("gptj"),noo=o(" \u2014 "),yR=a("a"),soo=o("GPT2Tokenizer"),loo=o(" or "),LR=a("a"),ioo=o("GPT2TokenizerFast"),doo=o(" (GPT-J model)"),coo=l(),Zn=a("li"),mte=a("strong"),foo=o("herbert"),moo=o(" \u2014 "),xR=a("a"),goo=o("HerbertTokenizer"),hoo=o(" or "),$R=a("a"),poo=o("HerbertTokenizerFast"),uoo=o(" (HerBERT model)"),_oo=l(),kg=a("li"),gte=a("strong"),boo=o("hubert"),voo=o(" \u2014 "),kR=a("a"),Foo=o("Wav2Vec2CTCTokenizer"),Too=o(" (Hubert model)"),Moo=l(),es=a("li"),hte=a("strong"),Eoo=o("ibert"),Coo=o(" \u2014 "),SR=a("a"),woo=o("RobertaTokenizer"),Aoo=o(" or "),RR=a("a"),yoo=o("RobertaTokenizerFast"),Loo=o(" (I-BERT model)"),xoo=l(),os=a("li"),pte=a("strong"),$oo=o("layoutlm"),koo=o(" \u2014 "),BR=a("a"),Soo=o("LayoutLMTokenizer"),Roo=o(" or "),PR=a("a"),Boo=o("LayoutLMTokenizerFast"),Poo=o(" (LayoutLM model)"),Ioo=l(),rs=a("li"),ute=a("strong"),qoo=o("layoutlmv2"),Noo=o(" \u2014 "),IR=a("a"),joo=o("LayoutLMv2Tokenizer"),Doo=o(" or "),qR=a("a"),Goo=o("LayoutLMv2TokenizerFast"),Ooo=o(" (LayoutLMv2 model)"),Voo=l(),ts=a("li"),_te=a("strong"),Xoo=o("layoutlmv3"),zoo=o(" \u2014 "),NR=a("a"),Qoo=o("LayoutLMv3Tokenizer"),Woo=o(" or "),jR=a("a"),Hoo=o("LayoutLMv3TokenizerFast"),Uoo=o(" (LayoutLMv3 model)"),Joo=l(),as=a("li"),bte=a("strong"),Yoo=o("layoutxlm"),Koo=o(" \u2014 "),DR=a("a"),Zoo=o("LayoutXLMTokenizer"),ero=o(" or "),GR=a("a"),oro=o("LayoutXLMTokenizerFast"),rro=o(" (LayoutXLM model)"),tro=l(),ns=a("li"),vte=a("strong"),aro=o("led"),nro=o(" \u2014 "),OR=a("a"),sro=o("LEDTokenizer"),lro=o(" or "),VR=a("a"),iro=o("LEDTokenizerFast"),dro=o(" (LED model)"),cro=l(),ss=a("li"),Fte=a("strong"),fro=o("longformer"),mro=o(" \u2014 "),XR=a("a"),gro=o("LongformerTokenizer"),hro=o(" or "),zR=a("a"),pro=o("LongformerTokenizerFast"),uro=o(" (Longformer model)"),_ro=l(),Sg=a("li"),Tte=a("strong"),bro=o("luke"),vro=o(" \u2014 "),QR=a("a"),Fro=o("LukeTokenizer"),Tro=o(" (LUKE model)"),Mro=l(),ls=a("li"),Mte=a("strong"),Ero=o("lxmert"),Cro=o(" \u2014 "),WR=a("a"),wro=o("LxmertTokenizer"),Aro=o(" or "),HR=a("a"),yro=o("LxmertTokenizerFast"),Lro=o(" (LXMERT model)"),xro=l(),Rg=a("li"),Ete=a("strong"),$ro=o("m2m_100"),kro=o(" \u2014 "),UR=a("a"),Sro=o("M2M100Tokenizer"),Rro=o(" (M2M100 model)"),Bro=l(),Bg=a("li"),Cte=a("strong"),Pro=o("marian"),Iro=o(" \u2014 "),JR=a("a"),qro=o("MarianTokenizer"),Nro=o(" (Marian model)"),jro=l(),is=a("li"),wte=a("strong"),Dro=o("mbart"),Gro=o(" \u2014 "),YR=a("a"),Oro=o("MBartTokenizer"),Vro=o(" or "),KR=a("a"),Xro=o("MBartTokenizerFast"),zro=o(" (mBART model)"),Qro=l(),ds=a("li"),Ate=a("strong"),Wro=o("mbart50"),Hro=o(" \u2014 "),ZR=a("a"),Uro=o("MBart50Tokenizer"),Jro=o(" or "),eB=a("a"),Yro=o("MBart50TokenizerFast"),Kro=o(" (mBART-50 model)"),Zro=l(),cs=a("li"),yte=a("strong"),eto=o("megatron-bert"),oto=o(" \u2014 "),oB=a("a"),rto=o("BertTokenizer"),tto=o(" or "),rB=a("a"),ato=o("BertTokenizerFast"),nto=o(" (MegatronBert model)"),sto=l(),Pg=a("li"),Lte=a("strong"),lto=o("mluke"),ito=o(" \u2014 "),tB=a("a"),dto=o("MLukeTokenizer"),cto=o(" (mLUKE model)"),fto=l(),fs=a("li"),xte=a("strong"),mto=o("mobilebert"),gto=o(" \u2014 "),aB=a("a"),hto=o("MobileBertTokenizer"),pto=o(" or "),nB=a("a"),uto=o("MobileBertTokenizerFast"),_to=o(" (MobileBERT model)"),bto=l(),ms=a("li"),$te=a("strong"),vto=o("mpnet"),Fto=o(" \u2014 "),sB=a("a"),Tto=o("MPNetTokenizer"),Mto=o(" or "),lB=a("a"),Eto=o("MPNetTokenizerFast"),Cto=o(" (MPNet model)"),wto=l(),gs=a("li"),kte=a("strong"),Ato=o("mt5"),yto=o(" \u2014 "),iB=a("a"),Lto=o("MT5Tokenizer"),xto=o(" or "),dB=a("a"),$to=o("MT5TokenizerFast"),kto=o(" (mT5 model)"),Sto=l(),hs=a("li"),Ste=a("strong"),Rto=o("nystromformer"),Bto=o(" \u2014 "),cB=a("a"),Pto=o("AlbertTokenizer"),Ito=o(" or "),fB=a("a"),qto=o("AlbertTokenizerFast"),Nto=o(" (Nystromformer model)"),jto=l(),ps=a("li"),Rte=a("strong"),Dto=o("openai-gpt"),Gto=o(" \u2014 "),mB=a("a"),Oto=o("OpenAIGPTTokenizer"),Vto=o(" or "),gB=a("a"),Xto=o("OpenAIGPTTokenizerFast"),zto=o(" (OpenAI GPT model)"),Qto=l(),Ig=a("li"),Bte=a("strong"),Wto=o("opt"),Hto=o(" \u2014 "),hB=a("a"),Uto=o("GPT2Tokenizer"),Jto=o(" (OPT model)"),Yto=l(),us=a("li"),Pte=a("strong"),Kto=o("pegasus"),Zto=o(" \u2014 "),pB=a("a"),eao=o("PegasusTokenizer"),oao=o(" or "),uB=a("a"),rao=o("PegasusTokenizerFast"),tao=o(" (Pegasus model)"),aao=l(),qg=a("li"),Ite=a("strong"),nao=o("perceiver"),sao=o(" \u2014 "),_B=a("a"),lao=o("PerceiverTokenizer"),iao=o(" (Perceiver model)"),dao=l(),Ng=a("li"),qte=a("strong"),cao=o("phobert"),fao=o(" \u2014 "),bB=a("a"),mao=o("PhobertTokenizer"),gao=o(" (PhoBERT model)"),hao=l(),jg=a("li"),Nte=a("strong"),pao=o("plbart"),uao=o(" \u2014 "),vB=a("a"),_ao=o("PLBartTokenizer"),bao=o(" (PLBart model)"),vao=l(),Dg=a("li"),jte=a("strong"),Fao=o("prophetnet"),Tao=o(" \u2014 "),FB=a("a"),Mao=o("ProphetNetTokenizer"),Eao=o(" (ProphetNet model)"),Cao=l(),_s=a("li"),Dte=a("strong"),wao=o("qdqbert"),Aao=o(" \u2014 "),TB=a("a"),yao=o("BertTokenizer"),Lao=o(" or "),MB=a("a"),xao=o("BertTokenizerFast"),$ao=o(" (QDQBert model)"),kao=l(),Gg=a("li"),Gte=a("strong"),Sao=o("rag"),Rao=o(" \u2014 "),EB=a("a"),Bao=o("RagTokenizer"),Pao=o(" (RAG model)"),Iao=l(),bs=a("li"),Ote=a("strong"),qao=o("realm"),Nao=o(" \u2014 "),CB=a("a"),jao=o("RealmTokenizer"),Dao=o(" or "),wB=a("a"),Gao=o("RealmTokenizerFast"),Oao=o(" (Realm model)"),Vao=l(),vs=a("li"),Vte=a("strong"),Xao=o("reformer"),zao=o(" \u2014 "),AB=a("a"),Qao=o("ReformerTokenizer"),Wao=o(" or "),yB=a("a"),Hao=o("ReformerTokenizerFast"),Uao=o(" (Reformer model)"),Jao=l(),Fs=a("li"),Xte=a("strong"),Yao=o("rembert"),Kao=o(" \u2014 "),LB=a("a"),Zao=o("RemBertTokenizer"),eno=o(" or "),xB=a("a"),ono=o("RemBertTokenizerFast"),rno=o(" (RemBERT model)"),tno=l(),Ts=a("li"),zte=a("strong"),ano=o("retribert"),nno=o(" \u2014 "),$B=a("a"),sno=o("RetriBertTokenizer"),lno=o(" or "),kB=a("a"),ino=o("RetriBertTokenizerFast"),dno=o(" (RetriBERT model)"),cno=l(),Ms=a("li"),Qte=a("strong"),fno=o("roberta"),mno=o(" \u2014 "),SB=a("a"),gno=o("RobertaTokenizer"),hno=o(" or "),RB=a("a"),pno=o("RobertaTokenizerFast"),uno=o(" (RoBERTa model)"),_no=l(),Es=a("li"),Wte=a("strong"),bno=o("roformer"),vno=o(" \u2014 "),BB=a("a"),Fno=o("RoFormerTokenizer"),Tno=o(" or "),PB=a("a"),Mno=o("RoFormerTokenizerFast"),Eno=o(" (RoFormer model)"),Cno=l(),Og=a("li"),Hte=a("strong"),wno=o("speech_to_text"),Ano=o(" \u2014 "),IB=a("a"),yno=o("Speech2TextTokenizer"),Lno=o(" (Speech2Text model)"),xno=l(),Vg=a("li"),Ute=a("strong"),$no=o("speech_to_text_2"),kno=o(" \u2014 "),qB=a("a"),Sno=o("Speech2Text2Tokenizer"),Rno=o(" (Speech2Text2 model)"),Bno=l(),Cs=a("li"),Jte=a("strong"),Pno=o("splinter"),Ino=o(" \u2014 "),NB=a("a"),qno=o("SplinterTokenizer"),Nno=o(" or "),jB=a("a"),jno=o("SplinterTokenizerFast"),Dno=o(" (Splinter model)"),Gno=l(),ws=a("li"),Yte=a("strong"),Ono=o("squeezebert"),Vno=o(" \u2014 "),DB=a("a"),Xno=o("SqueezeBertTokenizer"),zno=o(" or "),GB=a("a"),Qno=o("SqueezeBertTokenizerFast"),Wno=o(" (SqueezeBERT model)"),Hno=l(),As=a("li"),Kte=a("strong"),Uno=o("t5"),Jno=o(" \u2014 "),OB=a("a"),Yno=o("T5Tokenizer"),Kno=o(" or "),VB=a("a"),Zno=o("T5TokenizerFast"),eso=o(" (T5 model)"),oso=l(),Xg=a("li"),Zte=a("strong"),rso=o("tapas"),tso=o(" \u2014 "),XB=a("a"),aso=o("TapasTokenizer"),nso=o(" (TAPAS model)"),sso=l(),zg=a("li"),eae=a("strong"),lso=o("tapex"),iso=o(" \u2014 "),zB=a("a"),dso=o("TapexTokenizer"),cso=o(" (TAPEX model)"),fso=l(),Qg=a("li"),oae=a("strong"),mso=o("transfo-xl"),gso=o(" \u2014 "),QB=a("a"),hso=o("TransfoXLTokenizer"),pso=o(" (Transformer-XL model)"),uso=l(),ys=a("li"),rae=a("strong"),_so=o("visual_bert"),bso=o(" \u2014 "),WB=a("a"),vso=o("BertTokenizer"),Fso=o(" or "),HB=a("a"),Tso=o("BertTokenizerFast"),Mso=o(" (VisualBert model)"),Eso=l(),Wg=a("li"),tae=a("strong"),Cso=o("wav2vec2"),wso=o(" \u2014 "),UB=a("a"),Aso=o("Wav2Vec2CTCTokenizer"),yso=o(" (Wav2Vec2 model)"),Lso=l(),Hg=a("li"),aae=a("strong"),xso=o("wav2vec2_phoneme"),$so=o(" \u2014 "),JB=a("a"),kso=o("Wav2Vec2PhonemeCTCTokenizer"),Sso=o(" (Wav2Vec2Phoneme model)"),Rso=l(),Ls=a("li"),nae=a("strong"),Bso=o("xglm"),Pso=o(" \u2014 "),YB=a("a"),Iso=o("XGLMTokenizer"),qso=o(" or "),KB=a("a"),Nso=o("XGLMTokenizerFast"),jso=o(" (XGLM model)"),Dso=l(),Ug=a("li"),sae=a("strong"),Gso=o("xlm"),Oso=o(" \u2014 "),ZB=a("a"),Vso=o("XLMTokenizer"),Xso=o(" (XLM model)"),zso=l(),Jg=a("li"),lae=a("strong"),Qso=o("xlm-prophetnet"),Wso=o(" \u2014 "),eP=a("a"),Hso=o("XLMProphetNetTokenizer"),Uso=o(" (XLMProphetNet model)"),Jso=l(),xs=a("li"),iae=a("strong"),Yso=o("xlm-roberta"),Kso=o(" \u2014 "),oP=a("a"),Zso=o("XLMRobertaTokenizer"),elo=o(" or "),rP=a("a"),olo=o("XLMRobertaTokenizerFast"),rlo=o(" (XLM-RoBERTa model)"),tlo=l(),$s=a("li"),dae=a("strong"),alo=o("xlm-roberta-xl"),nlo=o(" \u2014 "),tP=a("a"),slo=o("RobertaTokenizer"),llo=o(" or "),aP=a("a"),ilo=o("RobertaTokenizerFast"),dlo=o(" (XLM-RoBERTa-XL model)"),clo=l(),ks=a("li"),cae=a("strong"),flo=o("xlnet"),mlo=o(" \u2014 "),nP=a("a"),glo=o("XLNetTokenizer"),hlo=o(" or "),sP=a("a"),plo=o("XLNetTokenizerFast"),ulo=o(" (XLNet model)"),_lo=l(),Ss=a("li"),fae=a("strong"),blo=o("yoso"),vlo=o(" \u2014 "),lP=a("a"),Flo=o("AlbertTokenizer"),Tlo=o(" or "),iP=a("a"),Mlo=o("AlbertTokenizerFast"),Elo=o(" (YOSO model)"),Clo=l(),F(Yg.$$.fragment),wlo=l(),Kg=a("div"),F(bA.$$.fragment),Alo=l(),mae=a("p"),ylo=o("Register a new tokenizer in this mapping."),kIe=l(),vi=a("h2"),Zg=a("a"),gae=a("span"),F(vA.$$.fragment),Llo=l(),hae=a("span"),xlo=o("AutoFeatureExtractor"),SIe=l(),Ao=a("div"),F(FA.$$.fragment),$lo=l(),TA=a("p"),klo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),dP=a("a"),Slo=o("AutoFeatureExtractor.from_pretrained()"),Rlo=o(" class method."),Blo=l(),MA=a("p"),Plo=o("This class cannot be instantiated directly using "),pae=a("code"),Ilo=o("__init__()"),qlo=o(" (throws an error)."),Nlo=l(),Qe=a("div"),F(EA.$$.fragment),jlo=l(),uae=a("p"),Dlo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Glo=l(),wa=a("p"),Olo=o("The feature extractor class to instantiate is selected based on the "),_ae=a("code"),Vlo=o("model_type"),Xlo=o(` property of the config object
(either passed as an argument or loaded from `),bae=a("code"),zlo=o("pretrained_model_name_or_path"),Qlo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),vae=a("code"),Wlo=o("pretrained_model_name_or_path"),Hlo=o(":"),Ulo=l(),Z=a("ul"),eh=a("li"),Fae=a("strong"),Jlo=o("beit"),Ylo=o(" \u2014 "),cP=a("a"),Klo=o("BeitFeatureExtractor"),Zlo=o(" (BEiT model)"),eio=l(),oh=a("li"),Tae=a("strong"),oio=o("clip"),rio=o(" \u2014 "),fP=a("a"),tio=o("CLIPFeatureExtractor"),aio=o(" (CLIP model)"),nio=l(),rh=a("li"),Mae=a("strong"),sio=o("convnext"),lio=o(" \u2014 "),mP=a("a"),iio=o("ConvNextFeatureExtractor"),dio=o(" (ConvNext model)"),cio=l(),th=a("li"),Eae=a("strong"),fio=o("data2vec-audio"),mio=o(" \u2014 "),gP=a("a"),gio=o("Wav2Vec2FeatureExtractor"),hio=o(" (Data2VecAudio model)"),pio=l(),ah=a("li"),Cae=a("strong"),uio=o("data2vec-vision"),_io=o(" \u2014 "),hP=a("a"),bio=o("BeitFeatureExtractor"),vio=o(" (Data2VecVision model)"),Fio=l(),nh=a("li"),wae=a("strong"),Tio=o("deit"),Mio=o(" \u2014 "),pP=a("a"),Eio=o("DeiTFeatureExtractor"),Cio=o(" (DeiT model)"),wio=l(),sh=a("li"),Aae=a("strong"),Aio=o("detr"),yio=o(" \u2014 "),uP=a("a"),Lio=o("DetrFeatureExtractor"),xio=o(" (DETR model)"),$io=l(),lh=a("li"),yae=a("strong"),kio=o("dpt"),Sio=o(" \u2014 "),_P=a("a"),Rio=o("DPTFeatureExtractor"),Bio=o(" (DPT model)"),Pio=l(),ih=a("li"),Lae=a("strong"),Iio=o("flava"),qio=o(" \u2014 "),bP=a("a"),Nio=o("FlavaFeatureExtractor"),jio=o(" (Flava model)"),Dio=l(),dh=a("li"),xae=a("strong"),Gio=o("glpn"),Oio=o(" \u2014 "),vP=a("a"),Vio=o("GLPNFeatureExtractor"),Xio=o(" (GLPN model)"),zio=l(),ch=a("li"),$ae=a("strong"),Qio=o("hubert"),Wio=o(" \u2014 "),FP=a("a"),Hio=o("Wav2Vec2FeatureExtractor"),Uio=o(" (Hubert model)"),Jio=l(),fh=a("li"),kae=a("strong"),Yio=o("layoutlmv2"),Kio=o(" \u2014 "),TP=a("a"),Zio=o("LayoutLMv2FeatureExtractor"),edo=o(" (LayoutLMv2 model)"),odo=l(),mh=a("li"),Sae=a("strong"),rdo=o("layoutlmv3"),tdo=o(" \u2014 "),MP=a("a"),ado=o("LayoutLMv3FeatureExtractor"),ndo=o(" (LayoutLMv3 model)"),sdo=l(),gh=a("li"),Rae=a("strong"),ldo=o("maskformer"),ido=o(" \u2014 "),EP=a("a"),ddo=o("MaskFormerFeatureExtractor"),cdo=o(" (MaskFormer model)"),fdo=l(),hh=a("li"),Bae=a("strong"),mdo=o("perceiver"),gdo=o(" \u2014 "),CP=a("a"),hdo=o("PerceiverFeatureExtractor"),pdo=o(" (Perceiver model)"),udo=l(),ph=a("li"),Pae=a("strong"),_do=o("poolformer"),bdo=o(" \u2014 "),wP=a("a"),vdo=o("PoolFormerFeatureExtractor"),Fdo=o(" (PoolFormer model)"),Tdo=l(),uh=a("li"),Iae=a("strong"),Mdo=o("regnet"),Edo=o(" \u2014 "),AP=a("a"),Cdo=o("ConvNextFeatureExtractor"),wdo=o(" (RegNet model)"),Ado=l(),_h=a("li"),qae=a("strong"),ydo=o("resnet"),Ldo=o(" \u2014 "),yP=a("a"),xdo=o("ConvNextFeatureExtractor"),$do=o(" (ResNet model)"),kdo=l(),bh=a("li"),Nae=a("strong"),Sdo=o("segformer"),Rdo=o(" \u2014 "),LP=a("a"),Bdo=o("SegformerFeatureExtractor"),Pdo=o(" (SegFormer model)"),Ido=l(),vh=a("li"),jae=a("strong"),qdo=o("speech_to_text"),Ndo=o(" \u2014 "),xP=a("a"),jdo=o("Speech2TextFeatureExtractor"),Ddo=o(" (Speech2Text model)"),Gdo=l(),Fh=a("li"),Dae=a("strong"),Odo=o("swin"),Vdo=o(" \u2014 "),$P=a("a"),Xdo=o("ViTFeatureExtractor"),zdo=o(" (Swin model)"),Qdo=l(),Th=a("li"),Gae=a("strong"),Wdo=o("van"),Hdo=o(" \u2014 "),kP=a("a"),Udo=o("ConvNextFeatureExtractor"),Jdo=o(" (VAN model)"),Ydo=l(),Mh=a("li"),Oae=a("strong"),Kdo=o("vit"),Zdo=o(" \u2014 "),SP=a("a"),eco=o("ViTFeatureExtractor"),oco=o(" (ViT model)"),rco=l(),Eh=a("li"),Vae=a("strong"),tco=o("vit_mae"),aco=o(" \u2014 "),RP=a("a"),nco=o("ViTFeatureExtractor"),sco=o(" (ViTMAE model)"),lco=l(),Ch=a("li"),Xae=a("strong"),ico=o("wav2vec2"),dco=o(" \u2014 "),BP=a("a"),cco=o("Wav2Vec2FeatureExtractor"),fco=o(" (Wav2Vec2 model)"),mco=l(),wh=a("li"),zae=a("strong"),gco=o("yolos"),hco=o(" \u2014 "),PP=a("a"),pco=o("YolosFeatureExtractor"),uco=o(" (YOLOS model)"),_co=l(),F(Ah.$$.fragment),bco=l(),F(yh.$$.fragment),vco=l(),Lh=a("div"),F(CA.$$.fragment),Fco=l(),Qae=a("p"),Tco=o("Register a new feature extractor for this class."),RIe=l(),Fi=a("h2"),xh=a("a"),Wae=a("span"),F(wA.$$.fragment),Mco=l(),Hae=a("span"),Eco=o("AutoProcessor"),BIe=l(),yo=a("div"),F(AA.$$.fragment),Cco=l(),yA=a("p"),wco=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),IP=a("a"),Aco=o("AutoProcessor.from_pretrained()"),yco=o(" class method."),Lco=l(),LA=a("p"),xco=o("This class cannot be instantiated directly using "),Uae=a("code"),$co=o("__init__()"),kco=o(" (throws an error)."),Sco=l(),We=a("div"),F(xA.$$.fragment),Rco=l(),Jae=a("p"),Bco=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Pco=l(),Ti=a("p"),Ico=o("The processor class to instantiate is selected based on the "),Yae=a("code"),qco=o("model_type"),Nco=o(` property of the config object (either
passed as an argument or loaded from `),Kae=a("code"),jco=o("pretrained_model_name_or_path"),Dco=o(" if possible):"),Gco=l(),ue=a("ul"),$h=a("li"),Zae=a("strong"),Oco=o("clip"),Vco=o(" \u2014 "),qP=a("a"),Xco=o("CLIPProcessor"),zco=o(" (CLIP model)"),Qco=l(),kh=a("li"),ene=a("strong"),Wco=o("flava"),Hco=o(" \u2014 "),one=a("code"),Uco=o("FLAVAProcessor"),Jco=o(" (Flava model)"),Yco=l(),Sh=a("li"),rne=a("strong"),Kco=o("layoutlmv2"),Zco=o(" \u2014 "),NP=a("a"),efo=o("LayoutLMv2Processor"),ofo=o(" (LayoutLMv2 model)"),rfo=l(),Rh=a("li"),tne=a("strong"),tfo=o("layoutlmv3"),afo=o(" \u2014 "),jP=a("a"),nfo=o("LayoutLMv3Processor"),sfo=o(" (LayoutLMv3 model)"),lfo=l(),Bh=a("li"),ane=a("strong"),ifo=o("layoutxlm"),dfo=o(" \u2014 "),DP=a("a"),cfo=o("LayoutXLMProcessor"),ffo=o(" (LayoutXLM model)"),mfo=l(),Ph=a("li"),nne=a("strong"),gfo=o("sew"),hfo=o(" \u2014 "),GP=a("a"),pfo=o("Wav2Vec2Processor"),ufo=o(" (SEW model)"),_fo=l(),Ih=a("li"),sne=a("strong"),bfo=o("sew-d"),vfo=o(" \u2014 "),OP=a("a"),Ffo=o("Wav2Vec2Processor"),Tfo=o(" (SEW-D model)"),Mfo=l(),qh=a("li"),lne=a("strong"),Efo=o("speech_to_text"),Cfo=o(" \u2014 "),VP=a("a"),wfo=o("Speech2TextProcessor"),Afo=o(" (Speech2Text model)"),yfo=l(),Nh=a("li"),ine=a("strong"),Lfo=o("speech_to_text_2"),xfo=o(" \u2014 "),XP=a("a"),$fo=o("Speech2Text2Processor"),kfo=o(" (Speech2Text2 model)"),Sfo=l(),jh=a("li"),dne=a("strong"),Rfo=o("trocr"),Bfo=o(" \u2014 "),zP=a("a"),Pfo=o("TrOCRProcessor"),Ifo=o(" (TrOCR model)"),qfo=l(),Dh=a("li"),cne=a("strong"),Nfo=o("unispeech"),jfo=o(" \u2014 "),QP=a("a"),Dfo=o("Wav2Vec2Processor"),Gfo=o(" (UniSpeech model)"),Ofo=l(),Gh=a("li"),fne=a("strong"),Vfo=o("unispeech-sat"),Xfo=o(" \u2014 "),WP=a("a"),zfo=o("Wav2Vec2Processor"),Qfo=o(" (UniSpeechSat model)"),Wfo=l(),Oh=a("li"),mne=a("strong"),Hfo=o("vilt"),Ufo=o(" \u2014 "),HP=a("a"),Jfo=o("ViltProcessor"),Yfo=o(" (ViLT model)"),Kfo=l(),Vh=a("li"),gne=a("strong"),Zfo=o("vision-text-dual-encoder"),emo=o(" \u2014 "),UP=a("a"),omo=o("VisionTextDualEncoderProcessor"),rmo=o(" (VisionTextDualEncoder model)"),tmo=l(),Xh=a("li"),hne=a("strong"),amo=o("wav2vec2"),nmo=o(" \u2014 "),JP=a("a"),smo=o("Wav2Vec2Processor"),lmo=o(" (Wav2Vec2 model)"),imo=l(),zh=a("li"),pne=a("strong"),dmo=o("wavlm"),cmo=o(" \u2014 "),YP=a("a"),fmo=o("Wav2Vec2Processor"),mmo=o(" (WavLM model)"),gmo=l(),F(Qh.$$.fragment),hmo=l(),F(Wh.$$.fragment),pmo=l(),Hh=a("div"),F($A.$$.fragment),umo=l(),une=a("p"),_mo=o("Register a new processor for this class."),PIe=l(),Mi=a("h2"),Uh=a("a"),_ne=a("span"),F(kA.$$.fragment),bmo=l(),bne=a("span"),vmo=o("AutoModel"),IIe=l(),Lo=a("div"),F(SA.$$.fragment),Fmo=l(),Ei=a("p"),Tmo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),KP=a("a"),Mmo=o("from_pretrained()"),Emo=o(" class method or the "),ZP=a("a"),Cmo=o("from_config()"),wmo=o(` class
method.`),Amo=l(),RA=a("p"),ymo=o("This class cannot be instantiated directly using "),vne=a("code"),Lmo=o("__init__()"),xmo=o(" (throws an error)."),$mo=l(),ot=a("div"),F(BA.$$.fragment),kmo=l(),Fne=a("p"),Smo=o("Instantiates one of the base model classes of the library from a configuration."),Rmo=l(),Ci=a("p"),Bmo=o(`Note:
Loading a model from its configuration file does `),Tne=a("strong"),Pmo=o("not"),Imo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eI=a("a"),qmo=o("from_pretrained()"),Nmo=o(" to load the model weights."),jmo=l(),F(Jh.$$.fragment),Dmo=l(),He=a("div"),F(PA.$$.fragment),Gmo=l(),Mne=a("p"),Omo=o("Instantiate one of the base model classes of the library from a pretrained model."),Vmo=l(),Aa=a("p"),Xmo=o("The model class to instantiate is selected based on the "),Ene=a("code"),zmo=o("model_type"),Qmo=o(` property of the config object (either
passed as an argument or loaded from `),Cne=a("code"),Wmo=o("pretrained_model_name_or_path"),Hmo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wne=a("code"),Umo=o("pretrained_model_name_or_path"),Jmo=o(":"),Ymo=l(),x=a("ul"),Yh=a("li"),Ane=a("strong"),Kmo=o("albert"),Zmo=o(" \u2014 "),oI=a("a"),ego=o("AlbertModel"),ogo=o(" (ALBERT model)"),rgo=l(),Kh=a("li"),yne=a("strong"),tgo=o("bart"),ago=o(" \u2014 "),rI=a("a"),ngo=o("BartModel"),sgo=o(" (BART model)"),lgo=l(),Zh=a("li"),Lne=a("strong"),igo=o("beit"),dgo=o(" \u2014 "),tI=a("a"),cgo=o("BeitModel"),fgo=o(" (BEiT model)"),mgo=l(),ep=a("li"),xne=a("strong"),ggo=o("bert"),hgo=o(" \u2014 "),aI=a("a"),pgo=o("BertModel"),ugo=o(" (BERT model)"),_go=l(),op=a("li"),$ne=a("strong"),bgo=o("bert-generation"),vgo=o(" \u2014 "),nI=a("a"),Fgo=o("BertGenerationEncoder"),Tgo=o(" (Bert Generation model)"),Mgo=l(),rp=a("li"),kne=a("strong"),Ego=o("big_bird"),Cgo=o(" \u2014 "),sI=a("a"),wgo=o("BigBirdModel"),Ago=o(" (BigBird model)"),ygo=l(),tp=a("li"),Sne=a("strong"),Lgo=o("bigbird_pegasus"),xgo=o(" \u2014 "),lI=a("a"),$go=o("BigBirdPegasusModel"),kgo=o(" (BigBirdPegasus model)"),Sgo=l(),ap=a("li"),Rne=a("strong"),Rgo=o("blenderbot"),Bgo=o(" \u2014 "),iI=a("a"),Pgo=o("BlenderbotModel"),Igo=o(" (Blenderbot model)"),qgo=l(),np=a("li"),Bne=a("strong"),Ngo=o("blenderbot-small"),jgo=o(" \u2014 "),dI=a("a"),Dgo=o("BlenderbotSmallModel"),Ggo=o(" (BlenderbotSmall model)"),Ogo=l(),sp=a("li"),Pne=a("strong"),Vgo=o("camembert"),Xgo=o(" \u2014 "),cI=a("a"),zgo=o("CamembertModel"),Qgo=o(" (CamemBERT model)"),Wgo=l(),lp=a("li"),Ine=a("strong"),Hgo=o("canine"),Ugo=o(" \u2014 "),fI=a("a"),Jgo=o("CanineModel"),Ygo=o(" (Canine model)"),Kgo=l(),ip=a("li"),qne=a("strong"),Zgo=o("clip"),eho=o(" \u2014 "),mI=a("a"),oho=o("CLIPModel"),rho=o(" (CLIP model)"),tho=l(),dp=a("li"),Nne=a("strong"),aho=o("convbert"),nho=o(" \u2014 "),gI=a("a"),sho=o("ConvBertModel"),lho=o(" (ConvBERT model)"),iho=l(),cp=a("li"),jne=a("strong"),dho=o("convnext"),cho=o(" \u2014 "),hI=a("a"),fho=o("ConvNextModel"),mho=o(" (ConvNext model)"),gho=l(),fp=a("li"),Dne=a("strong"),hho=o("ctrl"),pho=o(" \u2014 "),pI=a("a"),uho=o("CTRLModel"),_ho=o(" (CTRL model)"),bho=l(),mp=a("li"),Gne=a("strong"),vho=o("data2vec-audio"),Fho=o(" \u2014 "),uI=a("a"),Tho=o("Data2VecAudioModel"),Mho=o(" (Data2VecAudio model)"),Eho=l(),gp=a("li"),One=a("strong"),Cho=o("data2vec-text"),who=o(" \u2014 "),_I=a("a"),Aho=o("Data2VecTextModel"),yho=o(" (Data2VecText model)"),Lho=l(),hp=a("li"),Vne=a("strong"),xho=o("data2vec-vision"),$ho=o(" \u2014 "),bI=a("a"),kho=o("Data2VecVisionModel"),Sho=o(" (Data2VecVision model)"),Rho=l(),pp=a("li"),Xne=a("strong"),Bho=o("deberta"),Pho=o(" \u2014 "),vI=a("a"),Iho=o("DebertaModel"),qho=o(" (DeBERTa model)"),Nho=l(),up=a("li"),zne=a("strong"),jho=o("deberta-v2"),Dho=o(" \u2014 "),FI=a("a"),Gho=o("DebertaV2Model"),Oho=o(" (DeBERTa-v2 model)"),Vho=l(),_p=a("li"),Qne=a("strong"),Xho=o("decision_transformer"),zho=o(" \u2014 "),TI=a("a"),Qho=o("DecisionTransformerModel"),Who=o(" (Decision Transformer model)"),Hho=l(),bp=a("li"),Wne=a("strong"),Uho=o("deit"),Jho=o(" \u2014 "),MI=a("a"),Yho=o("DeiTModel"),Kho=o(" (DeiT model)"),Zho=l(),vp=a("li"),Hne=a("strong"),epo=o("detr"),opo=o(" \u2014 "),EI=a("a"),rpo=o("DetrModel"),tpo=o(" (DETR model)"),apo=l(),Fp=a("li"),Une=a("strong"),npo=o("distilbert"),spo=o(" \u2014 "),CI=a("a"),lpo=o("DistilBertModel"),ipo=o(" (DistilBERT model)"),dpo=l(),Tp=a("li"),Jne=a("strong"),cpo=o("dpr"),fpo=o(" \u2014 "),wI=a("a"),mpo=o("DPRQuestionEncoder"),gpo=o(" (DPR model)"),hpo=l(),Mp=a("li"),Yne=a("strong"),ppo=o("dpt"),upo=o(" \u2014 "),AI=a("a"),_po=o("DPTModel"),bpo=o(" (DPT model)"),vpo=l(),Ep=a("li"),Kne=a("strong"),Fpo=o("electra"),Tpo=o(" \u2014 "),yI=a("a"),Mpo=o("ElectraModel"),Epo=o(" (ELECTRA model)"),Cpo=l(),Cp=a("li"),Zne=a("strong"),wpo=o("flaubert"),Apo=o(" \u2014 "),LI=a("a"),ypo=o("FlaubertModel"),Lpo=o(" (FlauBERT model)"),xpo=l(),wp=a("li"),ese=a("strong"),$po=o("flava"),kpo=o(" \u2014 "),xI=a("a"),Spo=o("FlavaModel"),Rpo=o(" (Flava model)"),Bpo=l(),Ap=a("li"),ose=a("strong"),Ppo=o("fnet"),Ipo=o(" \u2014 "),$I=a("a"),qpo=o("FNetModel"),Npo=o(" (FNet model)"),jpo=l(),yp=a("li"),rse=a("strong"),Dpo=o("fsmt"),Gpo=o(" \u2014 "),kI=a("a"),Opo=o("FSMTModel"),Vpo=o(" (FairSeq Machine-Translation model)"),Xpo=l(),Rs=a("li"),tse=a("strong"),zpo=o("funnel"),Qpo=o(" \u2014 "),SI=a("a"),Wpo=o("FunnelModel"),Hpo=o(" or "),RI=a("a"),Upo=o("FunnelBaseModel"),Jpo=o(" (Funnel Transformer model)"),Ypo=l(),Lp=a("li"),ase=a("strong"),Kpo=o("glpn"),Zpo=o(" \u2014 "),BI=a("a"),euo=o("GLPNModel"),ouo=o(" (GLPN model)"),ruo=l(),xp=a("li"),nse=a("strong"),tuo=o("gpt2"),auo=o(" \u2014 "),PI=a("a"),nuo=o("GPT2Model"),suo=o(" (OpenAI GPT-2 model)"),luo=l(),$p=a("li"),sse=a("strong"),iuo=o("gpt_neo"),duo=o(" \u2014 "),II=a("a"),cuo=o("GPTNeoModel"),fuo=o(" (GPT Neo model)"),muo=l(),kp=a("li"),lse=a("strong"),guo=o("gptj"),huo=o(" \u2014 "),qI=a("a"),puo=o("GPTJModel"),uuo=o(" (GPT-J model)"),_uo=l(),Sp=a("li"),ise=a("strong"),buo=o("hubert"),vuo=o(" \u2014 "),NI=a("a"),Fuo=o("HubertModel"),Tuo=o(" (Hubert model)"),Muo=l(),Rp=a("li"),dse=a("strong"),Euo=o("ibert"),Cuo=o(" \u2014 "),jI=a("a"),wuo=o("IBertModel"),Auo=o(" (I-BERT model)"),yuo=l(),Bp=a("li"),cse=a("strong"),Luo=o("imagegpt"),xuo=o(" \u2014 "),DI=a("a"),$uo=o("ImageGPTModel"),kuo=o(" (ImageGPT model)"),Suo=l(),Pp=a("li"),fse=a("strong"),Ruo=o("layoutlm"),Buo=o(" \u2014 "),GI=a("a"),Puo=o("LayoutLMModel"),Iuo=o(" (LayoutLM model)"),quo=l(),Ip=a("li"),mse=a("strong"),Nuo=o("layoutlmv2"),juo=o(" \u2014 "),OI=a("a"),Duo=o("LayoutLMv2Model"),Guo=o(" (LayoutLMv2 model)"),Ouo=l(),qp=a("li"),gse=a("strong"),Vuo=o("layoutlmv3"),Xuo=o(" \u2014 "),VI=a("a"),zuo=o("LayoutLMv3Model"),Quo=o(" (LayoutLMv3 model)"),Wuo=l(),Np=a("li"),hse=a("strong"),Huo=o("led"),Uuo=o(" \u2014 "),XI=a("a"),Juo=o("LEDModel"),Yuo=o(" (LED model)"),Kuo=l(),jp=a("li"),pse=a("strong"),Zuo=o("longformer"),e_o=o(" \u2014 "),zI=a("a"),o_o=o("LongformerModel"),r_o=o(" (Longformer model)"),t_o=l(),Dp=a("li"),use=a("strong"),a_o=o("luke"),n_o=o(" \u2014 "),QI=a("a"),s_o=o("LukeModel"),l_o=o(" (LUKE model)"),i_o=l(),Gp=a("li"),_se=a("strong"),d_o=o("lxmert"),c_o=o(" \u2014 "),WI=a("a"),f_o=o("LxmertModel"),m_o=o(" (LXMERT model)"),g_o=l(),Op=a("li"),bse=a("strong"),h_o=o("m2m_100"),p_o=o(" \u2014 "),HI=a("a"),u_o=o("M2M100Model"),__o=o(" (M2M100 model)"),b_o=l(),Vp=a("li"),vse=a("strong"),v_o=o("marian"),F_o=o(" \u2014 "),UI=a("a"),T_o=o("MarianModel"),M_o=o(" (Marian model)"),E_o=l(),Xp=a("li"),Fse=a("strong"),C_o=o("maskformer"),w_o=o(" \u2014 "),JI=a("a"),A_o=o("MaskFormerModel"),y_o=o(" (MaskFormer model)"),L_o=l(),zp=a("li"),Tse=a("strong"),x_o=o("mbart"),$_o=o(" \u2014 "),YI=a("a"),k_o=o("MBartModel"),S_o=o(" (mBART model)"),R_o=l(),Qp=a("li"),Mse=a("strong"),B_o=o("megatron-bert"),P_o=o(" \u2014 "),KI=a("a"),I_o=o("MegatronBertModel"),q_o=o(" (MegatronBert model)"),N_o=l(),Wp=a("li"),Ese=a("strong"),j_o=o("mobilebert"),D_o=o(" \u2014 "),ZI=a("a"),G_o=o("MobileBertModel"),O_o=o(" (MobileBERT model)"),V_o=l(),Hp=a("li"),Cse=a("strong"),X_o=o("mpnet"),z_o=o(" \u2014 "),eq=a("a"),Q_o=o("MPNetModel"),W_o=o(" (MPNet model)"),H_o=l(),Up=a("li"),wse=a("strong"),U_o=o("mt5"),J_o=o(" \u2014 "),oq=a("a"),Y_o=o("MT5Model"),K_o=o(" (mT5 model)"),Z_o=l(),Jp=a("li"),Ase=a("strong"),e0o=o("nystromformer"),o0o=o(" \u2014 "),rq=a("a"),r0o=o("NystromformerModel"),t0o=o(" (Nystromformer model)"),a0o=l(),Yp=a("li"),yse=a("strong"),n0o=o("openai-gpt"),s0o=o(" \u2014 "),tq=a("a"),l0o=o("OpenAIGPTModel"),i0o=o(" (OpenAI GPT model)"),d0o=l(),Kp=a("li"),Lse=a("strong"),c0o=o("opt"),f0o=o(" \u2014 "),aq=a("a"),m0o=o("OPTModel"),g0o=o(" (OPT model)"),h0o=l(),Zp=a("li"),xse=a("strong"),p0o=o("pegasus"),u0o=o(" \u2014 "),nq=a("a"),_0o=o("PegasusModel"),b0o=o(" (Pegasus model)"),v0o=l(),eu=a("li"),$se=a("strong"),F0o=o("perceiver"),T0o=o(" \u2014 "),sq=a("a"),M0o=o("PerceiverModel"),E0o=o(" (Perceiver model)"),C0o=l(),ou=a("li"),kse=a("strong"),w0o=o("plbart"),A0o=o(" \u2014 "),lq=a("a"),y0o=o("PLBartModel"),L0o=o(" (PLBart model)"),x0o=l(),ru=a("li"),Sse=a("strong"),$0o=o("poolformer"),k0o=o(" \u2014 "),iq=a("a"),S0o=o("PoolFormerModel"),R0o=o(" (PoolFormer model)"),B0o=l(),tu=a("li"),Rse=a("strong"),P0o=o("prophetnet"),I0o=o(" \u2014 "),dq=a("a"),q0o=o("ProphetNetModel"),N0o=o(" (ProphetNet model)"),j0o=l(),au=a("li"),Bse=a("strong"),D0o=o("qdqbert"),G0o=o(" \u2014 "),cq=a("a"),O0o=o("QDQBertModel"),V0o=o(" (QDQBert model)"),X0o=l(),nu=a("li"),Pse=a("strong"),z0o=o("reformer"),Q0o=o(" \u2014 "),fq=a("a"),W0o=o("ReformerModel"),H0o=o(" (Reformer model)"),U0o=l(),su=a("li"),Ise=a("strong"),J0o=o("regnet"),Y0o=o(" \u2014 "),mq=a("a"),K0o=o("RegNetModel"),Z0o=o(" (RegNet model)"),e1o=l(),lu=a("li"),qse=a("strong"),o1o=o("rembert"),r1o=o(" \u2014 "),gq=a("a"),t1o=o("RemBertModel"),a1o=o(" (RemBERT model)"),n1o=l(),iu=a("li"),Nse=a("strong"),s1o=o("resnet"),l1o=o(" \u2014 "),hq=a("a"),i1o=o("ResNetModel"),d1o=o(" (ResNet model)"),c1o=l(),du=a("li"),jse=a("strong"),f1o=o("retribert"),m1o=o(" \u2014 "),pq=a("a"),g1o=o("RetriBertModel"),h1o=o(" (RetriBERT model)"),p1o=l(),cu=a("li"),Dse=a("strong"),u1o=o("roberta"),_1o=o(" \u2014 "),uq=a("a"),b1o=o("RobertaModel"),v1o=o(" (RoBERTa model)"),F1o=l(),fu=a("li"),Gse=a("strong"),T1o=o("roformer"),M1o=o(" \u2014 "),_q=a("a"),E1o=o("RoFormerModel"),C1o=o(" (RoFormer model)"),w1o=l(),mu=a("li"),Ose=a("strong"),A1o=o("segformer"),y1o=o(" \u2014 "),bq=a("a"),L1o=o("SegformerModel"),x1o=o(" (SegFormer model)"),$1o=l(),gu=a("li"),Vse=a("strong"),k1o=o("sew"),S1o=o(" \u2014 "),vq=a("a"),R1o=o("SEWModel"),B1o=o(" (SEW model)"),P1o=l(),hu=a("li"),Xse=a("strong"),I1o=o("sew-d"),q1o=o(" \u2014 "),Fq=a("a"),N1o=o("SEWDModel"),j1o=o(" (SEW-D model)"),D1o=l(),pu=a("li"),zse=a("strong"),G1o=o("speech_to_text"),O1o=o(" \u2014 "),Tq=a("a"),V1o=o("Speech2TextModel"),X1o=o(" (Speech2Text model)"),z1o=l(),uu=a("li"),Qse=a("strong"),Q1o=o("splinter"),W1o=o(" \u2014 "),Mq=a("a"),H1o=o("SplinterModel"),U1o=o(" (Splinter model)"),J1o=l(),_u=a("li"),Wse=a("strong"),Y1o=o("squeezebert"),K1o=o(" \u2014 "),Eq=a("a"),Z1o=o("SqueezeBertModel"),ebo=o(" (SqueezeBERT model)"),obo=l(),bu=a("li"),Hse=a("strong"),rbo=o("swin"),tbo=o(" \u2014 "),Cq=a("a"),abo=o("SwinModel"),nbo=o(" (Swin model)"),sbo=l(),vu=a("li"),Use=a("strong"),lbo=o("t5"),ibo=o(" \u2014 "),wq=a("a"),dbo=o("T5Model"),cbo=o(" (T5 model)"),fbo=l(),Fu=a("li"),Jse=a("strong"),mbo=o("tapas"),gbo=o(" \u2014 "),Aq=a("a"),hbo=o("TapasModel"),pbo=o(" (TAPAS model)"),ubo=l(),Tu=a("li"),Yse=a("strong"),_bo=o("transfo-xl"),bbo=o(" \u2014 "),yq=a("a"),vbo=o("TransfoXLModel"),Fbo=o(" (Transformer-XL model)"),Tbo=l(),Mu=a("li"),Kse=a("strong"),Mbo=o("unispeech"),Ebo=o(" \u2014 "),Lq=a("a"),Cbo=o("UniSpeechModel"),wbo=o(" (UniSpeech model)"),Abo=l(),Eu=a("li"),Zse=a("strong"),ybo=o("unispeech-sat"),Lbo=o(" \u2014 "),xq=a("a"),xbo=o("UniSpeechSatModel"),$bo=o(" (UniSpeechSat model)"),kbo=l(),Cu=a("li"),ele=a("strong"),Sbo=o("van"),Rbo=o(" \u2014 "),$q=a("a"),Bbo=o("VanModel"),Pbo=o(" (VAN model)"),Ibo=l(),wu=a("li"),ole=a("strong"),qbo=o("vilt"),Nbo=o(" \u2014 "),kq=a("a"),jbo=o("ViltModel"),Dbo=o(" (ViLT model)"),Gbo=l(),Au=a("li"),rle=a("strong"),Obo=o("vision-text-dual-encoder"),Vbo=o(" \u2014 "),Sq=a("a"),Xbo=o("VisionTextDualEncoderModel"),zbo=o(" (VisionTextDualEncoder model)"),Qbo=l(),yu=a("li"),tle=a("strong"),Wbo=o("visual_bert"),Hbo=o(" \u2014 "),Rq=a("a"),Ubo=o("VisualBertModel"),Jbo=o(" (VisualBert model)"),Ybo=l(),Lu=a("li"),ale=a("strong"),Kbo=o("vit"),Zbo=o(" \u2014 "),Bq=a("a"),e2o=o("ViTModel"),o2o=o(" (ViT model)"),r2o=l(),xu=a("li"),nle=a("strong"),t2o=o("vit_mae"),a2o=o(" \u2014 "),Pq=a("a"),n2o=o("ViTMAEModel"),s2o=o(" (ViTMAE model)"),l2o=l(),$u=a("li"),sle=a("strong"),i2o=o("wav2vec2"),d2o=o(" \u2014 "),Iq=a("a"),c2o=o("Wav2Vec2Model"),f2o=o(" (Wav2Vec2 model)"),m2o=l(),ku=a("li"),lle=a("strong"),g2o=o("wavlm"),h2o=o(" \u2014 "),qq=a("a"),p2o=o("WavLMModel"),u2o=o(" (WavLM model)"),_2o=l(),Su=a("li"),ile=a("strong"),b2o=o("xglm"),v2o=o(" \u2014 "),Nq=a("a"),F2o=o("XGLMModel"),T2o=o(" (XGLM model)"),M2o=l(),Ru=a("li"),dle=a("strong"),E2o=o("xlm"),C2o=o(" \u2014 "),jq=a("a"),w2o=o("XLMModel"),A2o=o(" (XLM model)"),y2o=l(),Bu=a("li"),cle=a("strong"),L2o=o("xlm-prophetnet"),x2o=o(" \u2014 "),Dq=a("a"),$2o=o("XLMProphetNetModel"),k2o=o(" (XLMProphetNet model)"),S2o=l(),Pu=a("li"),fle=a("strong"),R2o=o("xlm-roberta"),B2o=o(" \u2014 "),Gq=a("a"),P2o=o("XLMRobertaModel"),I2o=o(" (XLM-RoBERTa model)"),q2o=l(),Iu=a("li"),mle=a("strong"),N2o=o("xlm-roberta-xl"),j2o=o(" \u2014 "),Oq=a("a"),D2o=o("XLMRobertaXLModel"),G2o=o(" (XLM-RoBERTa-XL model)"),O2o=l(),qu=a("li"),gle=a("strong"),V2o=o("xlnet"),X2o=o(" \u2014 "),Vq=a("a"),z2o=o("XLNetModel"),Q2o=o(" (XLNet model)"),W2o=l(),Nu=a("li"),hle=a("strong"),H2o=o("yolos"),U2o=o(" \u2014 "),Xq=a("a"),J2o=o("YolosModel"),Y2o=o(" (YOLOS model)"),K2o=l(),ju=a("li"),ple=a("strong"),Z2o=o("yoso"),evo=o(" \u2014 "),zq=a("a"),ovo=o("YosoModel"),rvo=o(" (YOSO model)"),tvo=l(),Du=a("p"),avo=o("The model is set in evaluation mode by default using "),ule=a("code"),nvo=o("model.eval()"),svo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_le=a("code"),lvo=o("model.train()"),ivo=l(),F(Gu.$$.fragment),qIe=l(),wi=a("h2"),Ou=a("a"),ble=a("span"),F(IA.$$.fragment),dvo=l(),vle=a("span"),cvo=o("AutoModelForPreTraining"),NIe=l(),xo=a("div"),F(qA.$$.fragment),fvo=l(),Ai=a("p"),mvo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Qq=a("a"),gvo=o("from_pretrained()"),hvo=o(" class method or the "),Wq=a("a"),pvo=o("from_config()"),uvo=o(` class
method.`),_vo=l(),NA=a("p"),bvo=o("This class cannot be instantiated directly using "),Fle=a("code"),vvo=o("__init__()"),Fvo=o(" (throws an error)."),Tvo=l(),rt=a("div"),F(jA.$$.fragment),Mvo=l(),Tle=a("p"),Evo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Cvo=l(),yi=a("p"),wvo=o(`Note:
Loading a model from its configuration file does `),Mle=a("strong"),Avo=o("not"),yvo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hq=a("a"),Lvo=o("from_pretrained()"),xvo=o(" to load the model weights."),$vo=l(),F(Vu.$$.fragment),kvo=l(),Ue=a("div"),F(DA.$$.fragment),Svo=l(),Ele=a("p"),Rvo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Bvo=l(),ya=a("p"),Pvo=o("The model class to instantiate is selected based on the "),Cle=a("code"),Ivo=o("model_type"),qvo=o(` property of the config object (either
passed as an argument or loaded from `),wle=a("code"),Nvo=o("pretrained_model_name_or_path"),jvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ale=a("code"),Dvo=o("pretrained_model_name_or_path"),Gvo=o(":"),Ovo=l(),G=a("ul"),Xu=a("li"),yle=a("strong"),Vvo=o("albert"),Xvo=o(" \u2014 "),Uq=a("a"),zvo=o("AlbertForPreTraining"),Qvo=o(" (ALBERT model)"),Wvo=l(),zu=a("li"),Lle=a("strong"),Hvo=o("bart"),Uvo=o(" \u2014 "),Jq=a("a"),Jvo=o("BartForConditionalGeneration"),Yvo=o(" (BART model)"),Kvo=l(),Qu=a("li"),xle=a("strong"),Zvo=o("bert"),eFo=o(" \u2014 "),Yq=a("a"),oFo=o("BertForPreTraining"),rFo=o(" (BERT model)"),tFo=l(),Wu=a("li"),$le=a("strong"),aFo=o("big_bird"),nFo=o(" \u2014 "),Kq=a("a"),sFo=o("BigBirdForPreTraining"),lFo=o(" (BigBird model)"),iFo=l(),Hu=a("li"),kle=a("strong"),dFo=o("camembert"),cFo=o(" \u2014 "),Zq=a("a"),fFo=o("CamembertForMaskedLM"),mFo=o(" (CamemBERT model)"),gFo=l(),Uu=a("li"),Sle=a("strong"),hFo=o("ctrl"),pFo=o(" \u2014 "),eN=a("a"),uFo=o("CTRLLMHeadModel"),_Fo=o(" (CTRL model)"),bFo=l(),Ju=a("li"),Rle=a("strong"),vFo=o("data2vec-text"),FFo=o(" \u2014 "),oN=a("a"),TFo=o("Data2VecTextForMaskedLM"),MFo=o(" (Data2VecText model)"),EFo=l(),Yu=a("li"),Ble=a("strong"),CFo=o("deberta"),wFo=o(" \u2014 "),rN=a("a"),AFo=o("DebertaForMaskedLM"),yFo=o(" (DeBERTa model)"),LFo=l(),Ku=a("li"),Ple=a("strong"),xFo=o("deberta-v2"),$Fo=o(" \u2014 "),tN=a("a"),kFo=o("DebertaV2ForMaskedLM"),SFo=o(" (DeBERTa-v2 model)"),RFo=l(),Zu=a("li"),Ile=a("strong"),BFo=o("distilbert"),PFo=o(" \u2014 "),aN=a("a"),IFo=o("DistilBertForMaskedLM"),qFo=o(" (DistilBERT model)"),NFo=l(),e_=a("li"),qle=a("strong"),jFo=o("electra"),DFo=o(" \u2014 "),nN=a("a"),GFo=o("ElectraForPreTraining"),OFo=o(" (ELECTRA model)"),VFo=l(),o_=a("li"),Nle=a("strong"),XFo=o("flaubert"),zFo=o(" \u2014 "),sN=a("a"),QFo=o("FlaubertWithLMHeadModel"),WFo=o(" (FlauBERT model)"),HFo=l(),r_=a("li"),jle=a("strong"),UFo=o("flava"),JFo=o(" \u2014 "),lN=a("a"),YFo=o("FlavaForPreTraining"),KFo=o(" (Flava model)"),ZFo=l(),t_=a("li"),Dle=a("strong"),e6o=o("fnet"),o6o=o(" \u2014 "),iN=a("a"),r6o=o("FNetForPreTraining"),t6o=o(" (FNet model)"),a6o=l(),a_=a("li"),Gle=a("strong"),n6o=o("fsmt"),s6o=o(" \u2014 "),dN=a("a"),l6o=o("FSMTForConditionalGeneration"),i6o=o(" (FairSeq Machine-Translation model)"),d6o=l(),n_=a("li"),Ole=a("strong"),c6o=o("funnel"),f6o=o(" \u2014 "),cN=a("a"),m6o=o("FunnelForPreTraining"),g6o=o(" (Funnel Transformer model)"),h6o=l(),s_=a("li"),Vle=a("strong"),p6o=o("gpt2"),u6o=o(" \u2014 "),fN=a("a"),_6o=o("GPT2LMHeadModel"),b6o=o(" (OpenAI GPT-2 model)"),v6o=l(),l_=a("li"),Xle=a("strong"),F6o=o("ibert"),T6o=o(" \u2014 "),mN=a("a"),M6o=o("IBertForMaskedLM"),E6o=o(" (I-BERT model)"),C6o=l(),i_=a("li"),zle=a("strong"),w6o=o("layoutlm"),A6o=o(" \u2014 "),gN=a("a"),y6o=o("LayoutLMForMaskedLM"),L6o=o(" (LayoutLM model)"),x6o=l(),d_=a("li"),Qle=a("strong"),$6o=o("longformer"),k6o=o(" \u2014 "),hN=a("a"),S6o=o("LongformerForMaskedLM"),R6o=o(" (Longformer model)"),B6o=l(),c_=a("li"),Wle=a("strong"),P6o=o("lxmert"),I6o=o(" \u2014 "),pN=a("a"),q6o=o("LxmertForPreTraining"),N6o=o(" (LXMERT model)"),j6o=l(),f_=a("li"),Hle=a("strong"),D6o=o("megatron-bert"),G6o=o(" \u2014 "),uN=a("a"),O6o=o("MegatronBertForPreTraining"),V6o=o(" (MegatronBert model)"),X6o=l(),m_=a("li"),Ule=a("strong"),z6o=o("mobilebert"),Q6o=o(" \u2014 "),_N=a("a"),W6o=o("MobileBertForPreTraining"),H6o=o(" (MobileBERT model)"),U6o=l(),g_=a("li"),Jle=a("strong"),J6o=o("mpnet"),Y6o=o(" \u2014 "),bN=a("a"),K6o=o("MPNetForMaskedLM"),Z6o=o(" (MPNet model)"),eTo=l(),h_=a("li"),Yle=a("strong"),oTo=o("openai-gpt"),rTo=o(" \u2014 "),vN=a("a"),tTo=o("OpenAIGPTLMHeadModel"),aTo=o(" (OpenAI GPT model)"),nTo=l(),p_=a("li"),Kle=a("strong"),sTo=o("retribert"),lTo=o(" \u2014 "),FN=a("a"),iTo=o("RetriBertModel"),dTo=o(" (RetriBERT model)"),cTo=l(),u_=a("li"),Zle=a("strong"),fTo=o("roberta"),mTo=o(" \u2014 "),TN=a("a"),gTo=o("RobertaForMaskedLM"),hTo=o(" (RoBERTa model)"),pTo=l(),__=a("li"),eie=a("strong"),uTo=o("squeezebert"),_To=o(" \u2014 "),MN=a("a"),bTo=o("SqueezeBertForMaskedLM"),vTo=o(" (SqueezeBERT model)"),FTo=l(),b_=a("li"),oie=a("strong"),TTo=o("t5"),MTo=o(" \u2014 "),EN=a("a"),ETo=o("T5ForConditionalGeneration"),CTo=o(" (T5 model)"),wTo=l(),v_=a("li"),rie=a("strong"),ATo=o("tapas"),yTo=o(" \u2014 "),CN=a("a"),LTo=o("TapasForMaskedLM"),xTo=o(" (TAPAS model)"),$To=l(),F_=a("li"),tie=a("strong"),kTo=o("transfo-xl"),STo=o(" \u2014 "),wN=a("a"),RTo=o("TransfoXLLMHeadModel"),BTo=o(" (Transformer-XL model)"),PTo=l(),T_=a("li"),aie=a("strong"),ITo=o("unispeech"),qTo=o(" \u2014 "),AN=a("a"),NTo=o("UniSpeechForPreTraining"),jTo=o(" (UniSpeech model)"),DTo=l(),M_=a("li"),nie=a("strong"),GTo=o("unispeech-sat"),OTo=o(" \u2014 "),yN=a("a"),VTo=o("UniSpeechSatForPreTraining"),XTo=o(" (UniSpeechSat model)"),zTo=l(),E_=a("li"),sie=a("strong"),QTo=o("visual_bert"),WTo=o(" \u2014 "),LN=a("a"),HTo=o("VisualBertForPreTraining"),UTo=o(" (VisualBert model)"),JTo=l(),C_=a("li"),lie=a("strong"),YTo=o("vit_mae"),KTo=o(" \u2014 "),xN=a("a"),ZTo=o("ViTMAEForPreTraining"),e7o=o(" (ViTMAE model)"),o7o=l(),w_=a("li"),iie=a("strong"),r7o=o("wav2vec2"),t7o=o(" \u2014 "),$N=a("a"),a7o=o("Wav2Vec2ForPreTraining"),n7o=o(" (Wav2Vec2 model)"),s7o=l(),A_=a("li"),die=a("strong"),l7o=o("xlm"),i7o=o(" \u2014 "),kN=a("a"),d7o=o("XLMWithLMHeadModel"),c7o=o(" (XLM model)"),f7o=l(),y_=a("li"),cie=a("strong"),m7o=o("xlm-roberta"),g7o=o(" \u2014 "),SN=a("a"),h7o=o("XLMRobertaForMaskedLM"),p7o=o(" (XLM-RoBERTa model)"),u7o=l(),L_=a("li"),fie=a("strong"),_7o=o("xlm-roberta-xl"),b7o=o(" \u2014 "),RN=a("a"),v7o=o("XLMRobertaXLForMaskedLM"),F7o=o(" (XLM-RoBERTa-XL model)"),T7o=l(),x_=a("li"),mie=a("strong"),M7o=o("xlnet"),E7o=o(" \u2014 "),BN=a("a"),C7o=o("XLNetLMHeadModel"),w7o=o(" (XLNet model)"),A7o=l(),$_=a("p"),y7o=o("The model is set in evaluation mode by default using "),gie=a("code"),L7o=o("model.eval()"),x7o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hie=a("code"),$7o=o("model.train()"),k7o=l(),F(k_.$$.fragment),jIe=l(),Li=a("h2"),S_=a("a"),pie=a("span"),F(GA.$$.fragment),S7o=l(),uie=a("span"),R7o=o("AutoModelForCausalLM"),DIe=l(),$o=a("div"),F(OA.$$.fragment),B7o=l(),xi=a("p"),P7o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),PN=a("a"),I7o=o("from_pretrained()"),q7o=o(" class method or the "),IN=a("a"),N7o=o("from_config()"),j7o=o(` class
method.`),D7o=l(),VA=a("p"),G7o=o("This class cannot be instantiated directly using "),_ie=a("code"),O7o=o("__init__()"),V7o=o(" (throws an error)."),X7o=l(),tt=a("div"),F(XA.$$.fragment),z7o=l(),bie=a("p"),Q7o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),W7o=l(),$i=a("p"),H7o=o(`Note:
Loading a model from its configuration file does `),vie=a("strong"),U7o=o("not"),J7o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qN=a("a"),Y7o=o("from_pretrained()"),K7o=o(" to load the model weights."),Z7o=l(),F(R_.$$.fragment),eMo=l(),Je=a("div"),F(zA.$$.fragment),oMo=l(),Fie=a("p"),rMo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),tMo=l(),La=a("p"),aMo=o("The model class to instantiate is selected based on the "),Tie=a("code"),nMo=o("model_type"),sMo=o(` property of the config object (either
passed as an argument or loaded from `),Mie=a("code"),lMo=o("pretrained_model_name_or_path"),iMo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Eie=a("code"),dMo=o("pretrained_model_name_or_path"),cMo=o(":"),fMo=l(),z=a("ul"),B_=a("li"),Cie=a("strong"),mMo=o("bart"),gMo=o(" \u2014 "),NN=a("a"),hMo=o("BartForCausalLM"),pMo=o(" (BART model)"),uMo=l(),P_=a("li"),wie=a("strong"),_Mo=o("bert"),bMo=o(" \u2014 "),jN=a("a"),vMo=o("BertLMHeadModel"),FMo=o(" (BERT model)"),TMo=l(),I_=a("li"),Aie=a("strong"),MMo=o("bert-generation"),EMo=o(" \u2014 "),DN=a("a"),CMo=o("BertGenerationDecoder"),wMo=o(" (Bert Generation model)"),AMo=l(),q_=a("li"),yie=a("strong"),yMo=o("big_bird"),LMo=o(" \u2014 "),GN=a("a"),xMo=o("BigBirdForCausalLM"),$Mo=o(" (BigBird model)"),kMo=l(),N_=a("li"),Lie=a("strong"),SMo=o("bigbird_pegasus"),RMo=o(" \u2014 "),ON=a("a"),BMo=o("BigBirdPegasusForCausalLM"),PMo=o(" (BigBirdPegasus model)"),IMo=l(),j_=a("li"),xie=a("strong"),qMo=o("blenderbot"),NMo=o(" \u2014 "),VN=a("a"),jMo=o("BlenderbotForCausalLM"),DMo=o(" (Blenderbot model)"),GMo=l(),D_=a("li"),$ie=a("strong"),OMo=o("blenderbot-small"),VMo=o(" \u2014 "),XN=a("a"),XMo=o("BlenderbotSmallForCausalLM"),zMo=o(" (BlenderbotSmall model)"),QMo=l(),G_=a("li"),kie=a("strong"),WMo=o("camembert"),HMo=o(" \u2014 "),zN=a("a"),UMo=o("CamembertForCausalLM"),JMo=o(" (CamemBERT model)"),YMo=l(),O_=a("li"),Sie=a("strong"),KMo=o("ctrl"),ZMo=o(" \u2014 "),QN=a("a"),e4o=o("CTRLLMHeadModel"),o4o=o(" (CTRL model)"),r4o=l(),V_=a("li"),Rie=a("strong"),t4o=o("data2vec-text"),a4o=o(" \u2014 "),WN=a("a"),n4o=o("Data2VecTextForCausalLM"),s4o=o(" (Data2VecText model)"),l4o=l(),X_=a("li"),Bie=a("strong"),i4o=o("electra"),d4o=o(" \u2014 "),HN=a("a"),c4o=o("ElectraForCausalLM"),f4o=o(" (ELECTRA model)"),m4o=l(),z_=a("li"),Pie=a("strong"),g4o=o("gpt2"),h4o=o(" \u2014 "),UN=a("a"),p4o=o("GPT2LMHeadModel"),u4o=o(" (OpenAI GPT-2 model)"),_4o=l(),Q_=a("li"),Iie=a("strong"),b4o=o("gpt_neo"),v4o=o(" \u2014 "),JN=a("a"),F4o=o("GPTNeoForCausalLM"),T4o=o(" (GPT Neo model)"),M4o=l(),W_=a("li"),qie=a("strong"),E4o=o("gptj"),C4o=o(" \u2014 "),YN=a("a"),w4o=o("GPTJForCausalLM"),A4o=o(" (GPT-J model)"),y4o=l(),H_=a("li"),Nie=a("strong"),L4o=o("marian"),x4o=o(" \u2014 "),KN=a("a"),$4o=o("MarianForCausalLM"),k4o=o(" (Marian model)"),S4o=l(),U_=a("li"),jie=a("strong"),R4o=o("mbart"),B4o=o(" \u2014 "),ZN=a("a"),P4o=o("MBartForCausalLM"),I4o=o(" (mBART model)"),q4o=l(),J_=a("li"),Die=a("strong"),N4o=o("megatron-bert"),j4o=o(" \u2014 "),ej=a("a"),D4o=o("MegatronBertForCausalLM"),G4o=o(" (MegatronBert model)"),O4o=l(),Y_=a("li"),Gie=a("strong"),V4o=o("openai-gpt"),X4o=o(" \u2014 "),oj=a("a"),z4o=o("OpenAIGPTLMHeadModel"),Q4o=o(" (OpenAI GPT model)"),W4o=l(),K_=a("li"),Oie=a("strong"),H4o=o("opt"),U4o=o(" \u2014 "),rj=a("a"),J4o=o("OPTForCausalLM"),Y4o=o(" (OPT model)"),K4o=l(),Z_=a("li"),Vie=a("strong"),Z4o=o("pegasus"),eEo=o(" \u2014 "),tj=a("a"),oEo=o("PegasusForCausalLM"),rEo=o(" (Pegasus model)"),tEo=l(),e0=a("li"),Xie=a("strong"),aEo=o("plbart"),nEo=o(" \u2014 "),aj=a("a"),sEo=o("PLBartForCausalLM"),lEo=o(" (PLBart model)"),iEo=l(),o0=a("li"),zie=a("strong"),dEo=o("prophetnet"),cEo=o(" \u2014 "),nj=a("a"),fEo=o("ProphetNetForCausalLM"),mEo=o(" (ProphetNet model)"),gEo=l(),r0=a("li"),Qie=a("strong"),hEo=o("qdqbert"),pEo=o(" \u2014 "),sj=a("a"),uEo=o("QDQBertLMHeadModel"),_Eo=o(" (QDQBert model)"),bEo=l(),t0=a("li"),Wie=a("strong"),vEo=o("reformer"),FEo=o(" \u2014 "),lj=a("a"),TEo=o("ReformerModelWithLMHead"),MEo=o(" (Reformer model)"),EEo=l(),a0=a("li"),Hie=a("strong"),CEo=o("rembert"),wEo=o(" \u2014 "),ij=a("a"),AEo=o("RemBertForCausalLM"),yEo=o(" (RemBERT model)"),LEo=l(),n0=a("li"),Uie=a("strong"),xEo=o("roberta"),$Eo=o(" \u2014 "),dj=a("a"),kEo=o("RobertaForCausalLM"),SEo=o(" (RoBERTa model)"),REo=l(),s0=a("li"),Jie=a("strong"),BEo=o("roformer"),PEo=o(" \u2014 "),cj=a("a"),IEo=o("RoFormerForCausalLM"),qEo=o(" (RoFormer model)"),NEo=l(),l0=a("li"),Yie=a("strong"),jEo=o("speech_to_text_2"),DEo=o(" \u2014 "),fj=a("a"),GEo=o("Speech2Text2ForCausalLM"),OEo=o(" (Speech2Text2 model)"),VEo=l(),i0=a("li"),Kie=a("strong"),XEo=o("transfo-xl"),zEo=o(" \u2014 "),mj=a("a"),QEo=o("TransfoXLLMHeadModel"),WEo=o(" (Transformer-XL model)"),HEo=l(),d0=a("li"),Zie=a("strong"),UEo=o("trocr"),JEo=o(" \u2014 "),gj=a("a"),YEo=o("TrOCRForCausalLM"),KEo=o(" (TrOCR model)"),ZEo=l(),c0=a("li"),ede=a("strong"),e5o=o("xglm"),o5o=o(" \u2014 "),hj=a("a"),r5o=o("XGLMForCausalLM"),t5o=o(" (XGLM model)"),a5o=l(),f0=a("li"),ode=a("strong"),n5o=o("xlm"),s5o=o(" \u2014 "),pj=a("a"),l5o=o("XLMWithLMHeadModel"),i5o=o(" (XLM model)"),d5o=l(),m0=a("li"),rde=a("strong"),c5o=o("xlm-prophetnet"),f5o=o(" \u2014 "),uj=a("a"),m5o=o("XLMProphetNetForCausalLM"),g5o=o(" (XLMProphetNet model)"),h5o=l(),g0=a("li"),tde=a("strong"),p5o=o("xlm-roberta"),u5o=o(" \u2014 "),_j=a("a"),_5o=o("XLMRobertaForCausalLM"),b5o=o(" (XLM-RoBERTa model)"),v5o=l(),h0=a("li"),ade=a("strong"),F5o=o("xlm-roberta-xl"),T5o=o(" \u2014 "),bj=a("a"),M5o=o("XLMRobertaXLForCausalLM"),E5o=o(" (XLM-RoBERTa-XL model)"),C5o=l(),p0=a("li"),nde=a("strong"),w5o=o("xlnet"),A5o=o(" \u2014 "),vj=a("a"),y5o=o("XLNetLMHeadModel"),L5o=o(" (XLNet model)"),x5o=l(),u0=a("p"),$5o=o("The model is set in evaluation mode by default using "),sde=a("code"),k5o=o("model.eval()"),S5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lde=a("code"),R5o=o("model.train()"),B5o=l(),F(_0.$$.fragment),GIe=l(),ki=a("h2"),b0=a("a"),ide=a("span"),F(QA.$$.fragment),P5o=l(),dde=a("span"),I5o=o("AutoModelForMaskedLM"),OIe=l(),ko=a("div"),F(WA.$$.fragment),q5o=l(),Si=a("p"),N5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fj=a("a"),j5o=o("from_pretrained()"),D5o=o(" class method or the "),Tj=a("a"),G5o=o("from_config()"),O5o=o(` class
method.`),V5o=l(),HA=a("p"),X5o=o("This class cannot be instantiated directly using "),cde=a("code"),z5o=o("__init__()"),Q5o=o(" (throws an error)."),W5o=l(),at=a("div"),F(UA.$$.fragment),H5o=l(),fde=a("p"),U5o=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),J5o=l(),Ri=a("p"),Y5o=o(`Note:
Loading a model from its configuration file does `),mde=a("strong"),K5o=o("not"),Z5o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mj=a("a"),eCo=o("from_pretrained()"),oCo=o(" to load the model weights."),rCo=l(),F(v0.$$.fragment),tCo=l(),Ye=a("div"),F(JA.$$.fragment),aCo=l(),gde=a("p"),nCo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),sCo=l(),xa=a("p"),lCo=o("The model class to instantiate is selected based on the "),hde=a("code"),iCo=o("model_type"),dCo=o(` property of the config object (either
passed as an argument or loaded from `),pde=a("code"),cCo=o("pretrained_model_name_or_path"),fCo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ude=a("code"),mCo=o("pretrained_model_name_or_path"),gCo=o(":"),hCo=l(),Q=a("ul"),F0=a("li"),_de=a("strong"),pCo=o("albert"),uCo=o(" \u2014 "),Ej=a("a"),_Co=o("AlbertForMaskedLM"),bCo=o(" (ALBERT model)"),vCo=l(),T0=a("li"),bde=a("strong"),FCo=o("bart"),TCo=o(" \u2014 "),Cj=a("a"),MCo=o("BartForConditionalGeneration"),ECo=o(" (BART model)"),CCo=l(),M0=a("li"),vde=a("strong"),wCo=o("bert"),ACo=o(" \u2014 "),wj=a("a"),yCo=o("BertForMaskedLM"),LCo=o(" (BERT model)"),xCo=l(),E0=a("li"),Fde=a("strong"),$Co=o("big_bird"),kCo=o(" \u2014 "),Aj=a("a"),SCo=o("BigBirdForMaskedLM"),RCo=o(" (BigBird model)"),BCo=l(),C0=a("li"),Tde=a("strong"),PCo=o("camembert"),ICo=o(" \u2014 "),yj=a("a"),qCo=o("CamembertForMaskedLM"),NCo=o(" (CamemBERT model)"),jCo=l(),w0=a("li"),Mde=a("strong"),DCo=o("convbert"),GCo=o(" \u2014 "),Lj=a("a"),OCo=o("ConvBertForMaskedLM"),VCo=o(" (ConvBERT model)"),XCo=l(),A0=a("li"),Ede=a("strong"),zCo=o("data2vec-text"),QCo=o(" \u2014 "),xj=a("a"),WCo=o("Data2VecTextForMaskedLM"),HCo=o(" (Data2VecText model)"),UCo=l(),y0=a("li"),Cde=a("strong"),JCo=o("deberta"),YCo=o(" \u2014 "),$j=a("a"),KCo=o("DebertaForMaskedLM"),ZCo=o(" (DeBERTa model)"),e3o=l(),L0=a("li"),wde=a("strong"),o3o=o("deberta-v2"),r3o=o(" \u2014 "),kj=a("a"),t3o=o("DebertaV2ForMaskedLM"),a3o=o(" (DeBERTa-v2 model)"),n3o=l(),x0=a("li"),Ade=a("strong"),s3o=o("distilbert"),l3o=o(" \u2014 "),Sj=a("a"),i3o=o("DistilBertForMaskedLM"),d3o=o(" (DistilBERT model)"),c3o=l(),$0=a("li"),yde=a("strong"),f3o=o("electra"),m3o=o(" \u2014 "),Rj=a("a"),g3o=o("ElectraForMaskedLM"),h3o=o(" (ELECTRA model)"),p3o=l(),k0=a("li"),Lde=a("strong"),u3o=o("flaubert"),_3o=o(" \u2014 "),Bj=a("a"),b3o=o("FlaubertWithLMHeadModel"),v3o=o(" (FlauBERT model)"),F3o=l(),S0=a("li"),xde=a("strong"),T3o=o("fnet"),M3o=o(" \u2014 "),Pj=a("a"),E3o=o("FNetForMaskedLM"),C3o=o(" (FNet model)"),w3o=l(),R0=a("li"),$de=a("strong"),A3o=o("funnel"),y3o=o(" \u2014 "),Ij=a("a"),L3o=o("FunnelForMaskedLM"),x3o=o(" (Funnel Transformer model)"),$3o=l(),B0=a("li"),kde=a("strong"),k3o=o("ibert"),S3o=o(" \u2014 "),qj=a("a"),R3o=o("IBertForMaskedLM"),B3o=o(" (I-BERT model)"),P3o=l(),P0=a("li"),Sde=a("strong"),I3o=o("layoutlm"),q3o=o(" \u2014 "),Nj=a("a"),N3o=o("LayoutLMForMaskedLM"),j3o=o(" (LayoutLM model)"),D3o=l(),I0=a("li"),Rde=a("strong"),G3o=o("longformer"),O3o=o(" \u2014 "),jj=a("a"),V3o=o("LongformerForMaskedLM"),X3o=o(" (Longformer model)"),z3o=l(),q0=a("li"),Bde=a("strong"),Q3o=o("mbart"),W3o=o(" \u2014 "),Dj=a("a"),H3o=o("MBartForConditionalGeneration"),U3o=o(" (mBART model)"),J3o=l(),N0=a("li"),Pde=a("strong"),Y3o=o("megatron-bert"),K3o=o(" \u2014 "),Gj=a("a"),Z3o=o("MegatronBertForMaskedLM"),ewo=o(" (MegatronBert model)"),owo=l(),j0=a("li"),Ide=a("strong"),rwo=o("mobilebert"),two=o(" \u2014 "),Oj=a("a"),awo=o("MobileBertForMaskedLM"),nwo=o(" (MobileBERT model)"),swo=l(),D0=a("li"),qde=a("strong"),lwo=o("mpnet"),iwo=o(" \u2014 "),Vj=a("a"),dwo=o("MPNetForMaskedLM"),cwo=o(" (MPNet model)"),fwo=l(),G0=a("li"),Nde=a("strong"),mwo=o("nystromformer"),gwo=o(" \u2014 "),Xj=a("a"),hwo=o("NystromformerForMaskedLM"),pwo=o(" (Nystromformer model)"),uwo=l(),O0=a("li"),jde=a("strong"),_wo=o("perceiver"),bwo=o(" \u2014 "),zj=a("a"),vwo=o("PerceiverForMaskedLM"),Fwo=o(" (Perceiver model)"),Two=l(),V0=a("li"),Dde=a("strong"),Mwo=o("qdqbert"),Ewo=o(" \u2014 "),Qj=a("a"),Cwo=o("QDQBertForMaskedLM"),wwo=o(" (QDQBert model)"),Awo=l(),X0=a("li"),Gde=a("strong"),ywo=o("reformer"),Lwo=o(" \u2014 "),Wj=a("a"),xwo=o("ReformerForMaskedLM"),$wo=o(" (Reformer model)"),kwo=l(),z0=a("li"),Ode=a("strong"),Swo=o("rembert"),Rwo=o(" \u2014 "),Hj=a("a"),Bwo=o("RemBertForMaskedLM"),Pwo=o(" (RemBERT model)"),Iwo=l(),Q0=a("li"),Vde=a("strong"),qwo=o("roberta"),Nwo=o(" \u2014 "),Uj=a("a"),jwo=o("RobertaForMaskedLM"),Dwo=o(" (RoBERTa model)"),Gwo=l(),W0=a("li"),Xde=a("strong"),Owo=o("roformer"),Vwo=o(" \u2014 "),Jj=a("a"),Xwo=o("RoFormerForMaskedLM"),zwo=o(" (RoFormer model)"),Qwo=l(),H0=a("li"),zde=a("strong"),Wwo=o("squeezebert"),Hwo=o(" \u2014 "),Yj=a("a"),Uwo=o("SqueezeBertForMaskedLM"),Jwo=o(" (SqueezeBERT model)"),Ywo=l(),U0=a("li"),Qde=a("strong"),Kwo=o("tapas"),Zwo=o(" \u2014 "),Kj=a("a"),eAo=o("TapasForMaskedLM"),oAo=o(" (TAPAS model)"),rAo=l(),J0=a("li"),Wde=a("strong"),tAo=o("wav2vec2"),aAo=o(" \u2014 "),Hde=a("code"),nAo=o("Wav2Vec2ForMaskedLM"),sAo=o(" (Wav2Vec2 model)"),lAo=l(),Y0=a("li"),Ude=a("strong"),iAo=o("xlm"),dAo=o(" \u2014 "),Zj=a("a"),cAo=o("XLMWithLMHeadModel"),fAo=o(" (XLM model)"),mAo=l(),K0=a("li"),Jde=a("strong"),gAo=o("xlm-roberta"),hAo=o(" \u2014 "),eD=a("a"),pAo=o("XLMRobertaForMaskedLM"),uAo=o(" (XLM-RoBERTa model)"),_Ao=l(),Z0=a("li"),Yde=a("strong"),bAo=o("xlm-roberta-xl"),vAo=o(" \u2014 "),oD=a("a"),FAo=o("XLMRobertaXLForMaskedLM"),TAo=o(" (XLM-RoBERTa-XL model)"),MAo=l(),e1=a("li"),Kde=a("strong"),EAo=o("yoso"),CAo=o(" \u2014 "),rD=a("a"),wAo=o("YosoForMaskedLM"),AAo=o(" (YOSO model)"),yAo=l(),o1=a("p"),LAo=o("The model is set in evaluation mode by default using "),Zde=a("code"),xAo=o("model.eval()"),$Ao=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ece=a("code"),kAo=o("model.train()"),SAo=l(),F(r1.$$.fragment),VIe=l(),Bi=a("h2"),t1=a("a"),oce=a("span"),F(YA.$$.fragment),RAo=l(),rce=a("span"),BAo=o("AutoModelForSeq2SeqLM"),XIe=l(),So=a("div"),F(KA.$$.fragment),PAo=l(),Pi=a("p"),IAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tD=a("a"),qAo=o("from_pretrained()"),NAo=o(" class method or the "),aD=a("a"),jAo=o("from_config()"),DAo=o(` class
method.`),GAo=l(),ZA=a("p"),OAo=o("This class cannot be instantiated directly using "),tce=a("code"),VAo=o("__init__()"),XAo=o(" (throws an error)."),zAo=l(),nt=a("div"),F(ey.$$.fragment),QAo=l(),ace=a("p"),WAo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),HAo=l(),Ii=a("p"),UAo=o(`Note:
Loading a model from its configuration file does `),nce=a("strong"),JAo=o("not"),YAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nD=a("a"),KAo=o("from_pretrained()"),ZAo=o(" to load the model weights."),eyo=l(),F(a1.$$.fragment),oyo=l(),Ke=a("div"),F(oy.$$.fragment),ryo=l(),sce=a("p"),tyo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ayo=l(),$a=a("p"),nyo=o("The model class to instantiate is selected based on the "),lce=a("code"),syo=o("model_type"),lyo=o(` property of the config object (either
passed as an argument or loaded from `),ice=a("code"),iyo=o("pretrained_model_name_or_path"),dyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dce=a("code"),cyo=o("pretrained_model_name_or_path"),fyo=o(":"),myo=l(),he=a("ul"),n1=a("li"),cce=a("strong"),gyo=o("bart"),hyo=o(" \u2014 "),sD=a("a"),pyo=o("BartForConditionalGeneration"),uyo=o(" (BART model)"),_yo=l(),s1=a("li"),fce=a("strong"),byo=o("bigbird_pegasus"),vyo=o(" \u2014 "),lD=a("a"),Fyo=o("BigBirdPegasusForConditionalGeneration"),Tyo=o(" (BigBirdPegasus model)"),Myo=l(),l1=a("li"),mce=a("strong"),Eyo=o("blenderbot"),Cyo=o(" \u2014 "),iD=a("a"),wyo=o("BlenderbotForConditionalGeneration"),Ayo=o(" (Blenderbot model)"),yyo=l(),i1=a("li"),gce=a("strong"),Lyo=o("blenderbot-small"),xyo=o(" \u2014 "),dD=a("a"),$yo=o("BlenderbotSmallForConditionalGeneration"),kyo=o(" (BlenderbotSmall model)"),Syo=l(),d1=a("li"),hce=a("strong"),Ryo=o("encoder-decoder"),Byo=o(" \u2014 "),cD=a("a"),Pyo=o("EncoderDecoderModel"),Iyo=o(" (Encoder decoder model)"),qyo=l(),c1=a("li"),pce=a("strong"),Nyo=o("fsmt"),jyo=o(" \u2014 "),fD=a("a"),Dyo=o("FSMTForConditionalGeneration"),Gyo=o(" (FairSeq Machine-Translation model)"),Oyo=l(),f1=a("li"),uce=a("strong"),Vyo=o("led"),Xyo=o(" \u2014 "),mD=a("a"),zyo=o("LEDForConditionalGeneration"),Qyo=o(" (LED model)"),Wyo=l(),m1=a("li"),_ce=a("strong"),Hyo=o("m2m_100"),Uyo=o(" \u2014 "),gD=a("a"),Jyo=o("M2M100ForConditionalGeneration"),Yyo=o(" (M2M100 model)"),Kyo=l(),g1=a("li"),bce=a("strong"),Zyo=o("marian"),eLo=o(" \u2014 "),hD=a("a"),oLo=o("MarianMTModel"),rLo=o(" (Marian model)"),tLo=l(),h1=a("li"),vce=a("strong"),aLo=o("mbart"),nLo=o(" \u2014 "),pD=a("a"),sLo=o("MBartForConditionalGeneration"),lLo=o(" (mBART model)"),iLo=l(),p1=a("li"),Fce=a("strong"),dLo=o("mt5"),cLo=o(" \u2014 "),uD=a("a"),fLo=o("MT5ForConditionalGeneration"),mLo=o(" (mT5 model)"),gLo=l(),u1=a("li"),Tce=a("strong"),hLo=o("pegasus"),pLo=o(" \u2014 "),_D=a("a"),uLo=o("PegasusForConditionalGeneration"),_Lo=o(" (Pegasus model)"),bLo=l(),_1=a("li"),Mce=a("strong"),vLo=o("plbart"),FLo=o(" \u2014 "),bD=a("a"),TLo=o("PLBartForConditionalGeneration"),MLo=o(" (PLBart model)"),ELo=l(),b1=a("li"),Ece=a("strong"),CLo=o("prophetnet"),wLo=o(" \u2014 "),vD=a("a"),ALo=o("ProphetNetForConditionalGeneration"),yLo=o(" (ProphetNet model)"),LLo=l(),v1=a("li"),Cce=a("strong"),xLo=o("t5"),$Lo=o(" \u2014 "),FD=a("a"),kLo=o("T5ForConditionalGeneration"),SLo=o(" (T5 model)"),RLo=l(),F1=a("li"),wce=a("strong"),BLo=o("tapex"),PLo=o(" \u2014 "),TD=a("a"),ILo=o("BartForConditionalGeneration"),qLo=o(" (TAPEX model)"),NLo=l(),T1=a("li"),Ace=a("strong"),jLo=o("xlm-prophetnet"),DLo=o(" \u2014 "),MD=a("a"),GLo=o("XLMProphetNetForConditionalGeneration"),OLo=o(" (XLMProphetNet model)"),VLo=l(),M1=a("p"),XLo=o("The model is set in evaluation mode by default using "),yce=a("code"),zLo=o("model.eval()"),QLo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lce=a("code"),WLo=o("model.train()"),HLo=l(),F(E1.$$.fragment),zIe=l(),qi=a("h2"),C1=a("a"),xce=a("span"),F(ry.$$.fragment),ULo=l(),$ce=a("span"),JLo=o("AutoModelForSequenceClassification"),QIe=l(),Ro=a("div"),F(ty.$$.fragment),YLo=l(),Ni=a("p"),KLo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ED=a("a"),ZLo=o("from_pretrained()"),e8o=o(" class method or the "),CD=a("a"),o8o=o("from_config()"),r8o=o(` class
method.`),t8o=l(),ay=a("p"),a8o=o("This class cannot be instantiated directly using "),kce=a("code"),n8o=o("__init__()"),s8o=o(" (throws an error)."),l8o=l(),st=a("div"),F(ny.$$.fragment),i8o=l(),Sce=a("p"),d8o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),c8o=l(),ji=a("p"),f8o=o(`Note:
Loading a model from its configuration file does `),Rce=a("strong"),m8o=o("not"),g8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wD=a("a"),h8o=o("from_pretrained()"),p8o=o(" to load the model weights."),u8o=l(),F(w1.$$.fragment),_8o=l(),Ze=a("div"),F(sy.$$.fragment),b8o=l(),Bce=a("p"),v8o=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),F8o=l(),ka=a("p"),T8o=o("The model class to instantiate is selected based on the "),Pce=a("code"),M8o=o("model_type"),E8o=o(` property of the config object (either
passed as an argument or loaded from `),Ice=a("code"),C8o=o("pretrained_model_name_or_path"),w8o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qce=a("code"),A8o=o("pretrained_model_name_or_path"),y8o=o(":"),L8o=l(),q=a("ul"),A1=a("li"),Nce=a("strong"),x8o=o("albert"),$8o=o(" \u2014 "),AD=a("a"),k8o=o("AlbertForSequenceClassification"),S8o=o(" (ALBERT model)"),R8o=l(),y1=a("li"),jce=a("strong"),B8o=o("bart"),P8o=o(" \u2014 "),yD=a("a"),I8o=o("BartForSequenceClassification"),q8o=o(" (BART model)"),N8o=l(),L1=a("li"),Dce=a("strong"),j8o=o("bert"),D8o=o(" \u2014 "),LD=a("a"),G8o=o("BertForSequenceClassification"),O8o=o(" (BERT model)"),V8o=l(),x1=a("li"),Gce=a("strong"),X8o=o("big_bird"),z8o=o(" \u2014 "),xD=a("a"),Q8o=o("BigBirdForSequenceClassification"),W8o=o(" (BigBird model)"),H8o=l(),$1=a("li"),Oce=a("strong"),U8o=o("bigbird_pegasus"),J8o=o(" \u2014 "),$D=a("a"),Y8o=o("BigBirdPegasusForSequenceClassification"),K8o=o(" (BigBirdPegasus model)"),Z8o=l(),k1=a("li"),Vce=a("strong"),exo=o("camembert"),oxo=o(" \u2014 "),kD=a("a"),rxo=o("CamembertForSequenceClassification"),txo=o(" (CamemBERT model)"),axo=l(),S1=a("li"),Xce=a("strong"),nxo=o("canine"),sxo=o(" \u2014 "),SD=a("a"),lxo=o("CanineForSequenceClassification"),ixo=o(" (Canine model)"),dxo=l(),R1=a("li"),zce=a("strong"),cxo=o("convbert"),fxo=o(" \u2014 "),RD=a("a"),mxo=o("ConvBertForSequenceClassification"),gxo=o(" (ConvBERT model)"),hxo=l(),B1=a("li"),Qce=a("strong"),pxo=o("ctrl"),uxo=o(" \u2014 "),BD=a("a"),_xo=o("CTRLForSequenceClassification"),bxo=o(" (CTRL model)"),vxo=l(),P1=a("li"),Wce=a("strong"),Fxo=o("data2vec-text"),Txo=o(" \u2014 "),PD=a("a"),Mxo=o("Data2VecTextForSequenceClassification"),Exo=o(" (Data2VecText model)"),Cxo=l(),I1=a("li"),Hce=a("strong"),wxo=o("deberta"),Axo=o(" \u2014 "),ID=a("a"),yxo=o("DebertaForSequenceClassification"),Lxo=o(" (DeBERTa model)"),xxo=l(),q1=a("li"),Uce=a("strong"),$xo=o("deberta-v2"),kxo=o(" \u2014 "),qD=a("a"),Sxo=o("DebertaV2ForSequenceClassification"),Rxo=o(" (DeBERTa-v2 model)"),Bxo=l(),N1=a("li"),Jce=a("strong"),Pxo=o("distilbert"),Ixo=o(" \u2014 "),ND=a("a"),qxo=o("DistilBertForSequenceClassification"),Nxo=o(" (DistilBERT model)"),jxo=l(),j1=a("li"),Yce=a("strong"),Dxo=o("electra"),Gxo=o(" \u2014 "),jD=a("a"),Oxo=o("ElectraForSequenceClassification"),Vxo=o(" (ELECTRA model)"),Xxo=l(),D1=a("li"),Kce=a("strong"),zxo=o("flaubert"),Qxo=o(" \u2014 "),DD=a("a"),Wxo=o("FlaubertForSequenceClassification"),Hxo=o(" (FlauBERT model)"),Uxo=l(),G1=a("li"),Zce=a("strong"),Jxo=o("fnet"),Yxo=o(" \u2014 "),GD=a("a"),Kxo=o("FNetForSequenceClassification"),Zxo=o(" (FNet model)"),e9o=l(),O1=a("li"),efe=a("strong"),o9o=o("funnel"),r9o=o(" \u2014 "),OD=a("a"),t9o=o("FunnelForSequenceClassification"),a9o=o(" (Funnel Transformer model)"),n9o=l(),V1=a("li"),ofe=a("strong"),s9o=o("gpt2"),l9o=o(" \u2014 "),VD=a("a"),i9o=o("GPT2ForSequenceClassification"),d9o=o(" (OpenAI GPT-2 model)"),c9o=l(),X1=a("li"),rfe=a("strong"),f9o=o("gpt_neo"),m9o=o(" \u2014 "),XD=a("a"),g9o=o("GPTNeoForSequenceClassification"),h9o=o(" (GPT Neo model)"),p9o=l(),z1=a("li"),tfe=a("strong"),u9o=o("gptj"),_9o=o(" \u2014 "),zD=a("a"),b9o=o("GPTJForSequenceClassification"),v9o=o(" (GPT-J model)"),F9o=l(),Q1=a("li"),afe=a("strong"),T9o=o("ibert"),M9o=o(" \u2014 "),QD=a("a"),E9o=o("IBertForSequenceClassification"),C9o=o(" (I-BERT model)"),w9o=l(),W1=a("li"),nfe=a("strong"),A9o=o("layoutlm"),y9o=o(" \u2014 "),WD=a("a"),L9o=o("LayoutLMForSequenceClassification"),x9o=o(" (LayoutLM model)"),$9o=l(),H1=a("li"),sfe=a("strong"),k9o=o("layoutlmv2"),S9o=o(" \u2014 "),HD=a("a"),R9o=o("LayoutLMv2ForSequenceClassification"),B9o=o(" (LayoutLMv2 model)"),P9o=l(),U1=a("li"),lfe=a("strong"),I9o=o("layoutlmv3"),q9o=o(" \u2014 "),UD=a("a"),N9o=o("LayoutLMv3ForSequenceClassification"),j9o=o(" (LayoutLMv3 model)"),D9o=l(),J1=a("li"),ife=a("strong"),G9o=o("led"),O9o=o(" \u2014 "),JD=a("a"),V9o=o("LEDForSequenceClassification"),X9o=o(" (LED model)"),z9o=l(),Y1=a("li"),dfe=a("strong"),Q9o=o("longformer"),W9o=o(" \u2014 "),YD=a("a"),H9o=o("LongformerForSequenceClassification"),U9o=o(" (Longformer model)"),J9o=l(),K1=a("li"),cfe=a("strong"),Y9o=o("mbart"),K9o=o(" \u2014 "),KD=a("a"),Z9o=o("MBartForSequenceClassification"),e$o=o(" (mBART model)"),o$o=l(),Z1=a("li"),ffe=a("strong"),r$o=o("megatron-bert"),t$o=o(" \u2014 "),ZD=a("a"),a$o=o("MegatronBertForSequenceClassification"),n$o=o(" (MegatronBert model)"),s$o=l(),eb=a("li"),mfe=a("strong"),l$o=o("mobilebert"),i$o=o(" \u2014 "),eG=a("a"),d$o=o("MobileBertForSequenceClassification"),c$o=o(" (MobileBERT model)"),f$o=l(),ob=a("li"),gfe=a("strong"),m$o=o("mpnet"),g$o=o(" \u2014 "),oG=a("a"),h$o=o("MPNetForSequenceClassification"),p$o=o(" (MPNet model)"),u$o=l(),rb=a("li"),hfe=a("strong"),_$o=o("nystromformer"),b$o=o(" \u2014 "),rG=a("a"),v$o=o("NystromformerForSequenceClassification"),F$o=o(" (Nystromformer model)"),T$o=l(),tb=a("li"),pfe=a("strong"),M$o=o("openai-gpt"),E$o=o(" \u2014 "),tG=a("a"),C$o=o("OpenAIGPTForSequenceClassification"),w$o=o(" (OpenAI GPT model)"),A$o=l(),ab=a("li"),ufe=a("strong"),y$o=o("perceiver"),L$o=o(" \u2014 "),aG=a("a"),x$o=o("PerceiverForSequenceClassification"),$$o=o(" (Perceiver model)"),k$o=l(),nb=a("li"),_fe=a("strong"),S$o=o("plbart"),R$o=o(" \u2014 "),nG=a("a"),B$o=o("PLBartForSequenceClassification"),P$o=o(" (PLBart model)"),I$o=l(),sb=a("li"),bfe=a("strong"),q$o=o("qdqbert"),N$o=o(" \u2014 "),sG=a("a"),j$o=o("QDQBertForSequenceClassification"),D$o=o(" (QDQBert model)"),G$o=l(),lb=a("li"),vfe=a("strong"),O$o=o("reformer"),V$o=o(" \u2014 "),lG=a("a"),X$o=o("ReformerForSequenceClassification"),z$o=o(" (Reformer model)"),Q$o=l(),ib=a("li"),Ffe=a("strong"),W$o=o("rembert"),H$o=o(" \u2014 "),iG=a("a"),U$o=o("RemBertForSequenceClassification"),J$o=o(" (RemBERT model)"),Y$o=l(),db=a("li"),Tfe=a("strong"),K$o=o("roberta"),Z$o=o(" \u2014 "),dG=a("a"),eko=o("RobertaForSequenceClassification"),oko=o(" (RoBERTa model)"),rko=l(),cb=a("li"),Mfe=a("strong"),tko=o("roformer"),ako=o(" \u2014 "),cG=a("a"),nko=o("RoFormerForSequenceClassification"),sko=o(" (RoFormer model)"),lko=l(),fb=a("li"),Efe=a("strong"),iko=o("squeezebert"),dko=o(" \u2014 "),fG=a("a"),cko=o("SqueezeBertForSequenceClassification"),fko=o(" (SqueezeBERT model)"),mko=l(),mb=a("li"),Cfe=a("strong"),gko=o("tapas"),hko=o(" \u2014 "),mG=a("a"),pko=o("TapasForSequenceClassification"),uko=o(" (TAPAS model)"),_ko=l(),gb=a("li"),wfe=a("strong"),bko=o("tapex"),vko=o(" \u2014 "),gG=a("a"),Fko=o("BartForSequenceClassification"),Tko=o(" (TAPEX model)"),Mko=l(),hb=a("li"),Afe=a("strong"),Eko=o("transfo-xl"),Cko=o(" \u2014 "),hG=a("a"),wko=o("TransfoXLForSequenceClassification"),Ako=o(" (Transformer-XL model)"),yko=l(),pb=a("li"),yfe=a("strong"),Lko=o("xlm"),xko=o(" \u2014 "),pG=a("a"),$ko=o("XLMForSequenceClassification"),kko=o(" (XLM model)"),Sko=l(),ub=a("li"),Lfe=a("strong"),Rko=o("xlm-roberta"),Bko=o(" \u2014 "),uG=a("a"),Pko=o("XLMRobertaForSequenceClassification"),Iko=o(" (XLM-RoBERTa model)"),qko=l(),_b=a("li"),xfe=a("strong"),Nko=o("xlm-roberta-xl"),jko=o(" \u2014 "),_G=a("a"),Dko=o("XLMRobertaXLForSequenceClassification"),Gko=o(" (XLM-RoBERTa-XL model)"),Oko=l(),bb=a("li"),$fe=a("strong"),Vko=o("xlnet"),Xko=o(" \u2014 "),bG=a("a"),zko=o("XLNetForSequenceClassification"),Qko=o(" (XLNet model)"),Wko=l(),vb=a("li"),kfe=a("strong"),Hko=o("yoso"),Uko=o(" \u2014 "),vG=a("a"),Jko=o("YosoForSequenceClassification"),Yko=o(" (YOSO model)"),Kko=l(),Fb=a("p"),Zko=o("The model is set in evaluation mode by default using "),Sfe=a("code"),eSo=o("model.eval()"),oSo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rfe=a("code"),rSo=o("model.train()"),tSo=l(),F(Tb.$$.fragment),WIe=l(),Di=a("h2"),Mb=a("a"),Bfe=a("span"),F(ly.$$.fragment),aSo=l(),Pfe=a("span"),nSo=o("AutoModelForMultipleChoice"),HIe=l(),Bo=a("div"),F(iy.$$.fragment),sSo=l(),Gi=a("p"),lSo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FG=a("a"),iSo=o("from_pretrained()"),dSo=o(" class method or the "),TG=a("a"),cSo=o("from_config()"),fSo=o(` class
method.`),mSo=l(),dy=a("p"),gSo=o("This class cannot be instantiated directly using "),Ife=a("code"),hSo=o("__init__()"),pSo=o(" (throws an error)."),uSo=l(),lt=a("div"),F(cy.$$.fragment),_So=l(),qfe=a("p"),bSo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vSo=l(),Oi=a("p"),FSo=o(`Note:
Loading a model from its configuration file does `),Nfe=a("strong"),TSo=o("not"),MSo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MG=a("a"),ESo=o("from_pretrained()"),CSo=o(" to load the model weights."),wSo=l(),F(Eb.$$.fragment),ASo=l(),eo=a("div"),F(fy.$$.fragment),ySo=l(),jfe=a("p"),LSo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),xSo=l(),Sa=a("p"),$So=o("The model class to instantiate is selected based on the "),Dfe=a("code"),kSo=o("model_type"),SSo=o(` property of the config object (either
passed as an argument or loaded from `),Gfe=a("code"),RSo=o("pretrained_model_name_or_path"),BSo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ofe=a("code"),PSo=o("pretrained_model_name_or_path"),ISo=o(":"),qSo=l(),Y=a("ul"),Cb=a("li"),Vfe=a("strong"),NSo=o("albert"),jSo=o(" \u2014 "),EG=a("a"),DSo=o("AlbertForMultipleChoice"),GSo=o(" (ALBERT model)"),OSo=l(),wb=a("li"),Xfe=a("strong"),VSo=o("bert"),XSo=o(" \u2014 "),CG=a("a"),zSo=o("BertForMultipleChoice"),QSo=o(" (BERT model)"),WSo=l(),Ab=a("li"),zfe=a("strong"),HSo=o("big_bird"),USo=o(" \u2014 "),wG=a("a"),JSo=o("BigBirdForMultipleChoice"),YSo=o(" (BigBird model)"),KSo=l(),yb=a("li"),Qfe=a("strong"),ZSo=o("camembert"),eRo=o(" \u2014 "),AG=a("a"),oRo=o("CamembertForMultipleChoice"),rRo=o(" (CamemBERT model)"),tRo=l(),Lb=a("li"),Wfe=a("strong"),aRo=o("canine"),nRo=o(" \u2014 "),yG=a("a"),sRo=o("CanineForMultipleChoice"),lRo=o(" (Canine model)"),iRo=l(),xb=a("li"),Hfe=a("strong"),dRo=o("convbert"),cRo=o(" \u2014 "),LG=a("a"),fRo=o("ConvBertForMultipleChoice"),mRo=o(" (ConvBERT model)"),gRo=l(),$b=a("li"),Ufe=a("strong"),hRo=o("data2vec-text"),pRo=o(" \u2014 "),xG=a("a"),uRo=o("Data2VecTextForMultipleChoice"),_Ro=o(" (Data2VecText model)"),bRo=l(),kb=a("li"),Jfe=a("strong"),vRo=o("deberta-v2"),FRo=o(" \u2014 "),$G=a("a"),TRo=o("DebertaV2ForMultipleChoice"),MRo=o(" (DeBERTa-v2 model)"),ERo=l(),Sb=a("li"),Yfe=a("strong"),CRo=o("distilbert"),wRo=o(" \u2014 "),kG=a("a"),ARo=o("DistilBertForMultipleChoice"),yRo=o(" (DistilBERT model)"),LRo=l(),Rb=a("li"),Kfe=a("strong"),xRo=o("electra"),$Ro=o(" \u2014 "),SG=a("a"),kRo=o("ElectraForMultipleChoice"),SRo=o(" (ELECTRA model)"),RRo=l(),Bb=a("li"),Zfe=a("strong"),BRo=o("flaubert"),PRo=o(" \u2014 "),RG=a("a"),IRo=o("FlaubertForMultipleChoice"),qRo=o(" (FlauBERT model)"),NRo=l(),Pb=a("li"),eme=a("strong"),jRo=o("fnet"),DRo=o(" \u2014 "),BG=a("a"),GRo=o("FNetForMultipleChoice"),ORo=o(" (FNet model)"),VRo=l(),Ib=a("li"),ome=a("strong"),XRo=o("funnel"),zRo=o(" \u2014 "),PG=a("a"),QRo=o("FunnelForMultipleChoice"),WRo=o(" (Funnel Transformer model)"),HRo=l(),qb=a("li"),rme=a("strong"),URo=o("ibert"),JRo=o(" \u2014 "),IG=a("a"),YRo=o("IBertForMultipleChoice"),KRo=o(" (I-BERT model)"),ZRo=l(),Nb=a("li"),tme=a("strong"),eBo=o("longformer"),oBo=o(" \u2014 "),qG=a("a"),rBo=o("LongformerForMultipleChoice"),tBo=o(" (Longformer model)"),aBo=l(),jb=a("li"),ame=a("strong"),nBo=o("megatron-bert"),sBo=o(" \u2014 "),NG=a("a"),lBo=o("MegatronBertForMultipleChoice"),iBo=o(" (MegatronBert model)"),dBo=l(),Db=a("li"),nme=a("strong"),cBo=o("mobilebert"),fBo=o(" \u2014 "),jG=a("a"),mBo=o("MobileBertForMultipleChoice"),gBo=o(" (MobileBERT model)"),hBo=l(),Gb=a("li"),sme=a("strong"),pBo=o("mpnet"),uBo=o(" \u2014 "),DG=a("a"),_Bo=o("MPNetForMultipleChoice"),bBo=o(" (MPNet model)"),vBo=l(),Ob=a("li"),lme=a("strong"),FBo=o("nystromformer"),TBo=o(" \u2014 "),GG=a("a"),MBo=o("NystromformerForMultipleChoice"),EBo=o(" (Nystromformer model)"),CBo=l(),Vb=a("li"),ime=a("strong"),wBo=o("qdqbert"),ABo=o(" \u2014 "),OG=a("a"),yBo=o("QDQBertForMultipleChoice"),LBo=o(" (QDQBert model)"),xBo=l(),Xb=a("li"),dme=a("strong"),$Bo=o("rembert"),kBo=o(" \u2014 "),VG=a("a"),SBo=o("RemBertForMultipleChoice"),RBo=o(" (RemBERT model)"),BBo=l(),zb=a("li"),cme=a("strong"),PBo=o("roberta"),IBo=o(" \u2014 "),XG=a("a"),qBo=o("RobertaForMultipleChoice"),NBo=o(" (RoBERTa model)"),jBo=l(),Qb=a("li"),fme=a("strong"),DBo=o("roformer"),GBo=o(" \u2014 "),zG=a("a"),OBo=o("RoFormerForMultipleChoice"),VBo=o(" (RoFormer model)"),XBo=l(),Wb=a("li"),mme=a("strong"),zBo=o("squeezebert"),QBo=o(" \u2014 "),QG=a("a"),WBo=o("SqueezeBertForMultipleChoice"),HBo=o(" (SqueezeBERT model)"),UBo=l(),Hb=a("li"),gme=a("strong"),JBo=o("xlm"),YBo=o(" \u2014 "),WG=a("a"),KBo=o("XLMForMultipleChoice"),ZBo=o(" (XLM model)"),ePo=l(),Ub=a("li"),hme=a("strong"),oPo=o("xlm-roberta"),rPo=o(" \u2014 "),HG=a("a"),tPo=o("XLMRobertaForMultipleChoice"),aPo=o(" (XLM-RoBERTa model)"),nPo=l(),Jb=a("li"),pme=a("strong"),sPo=o("xlm-roberta-xl"),lPo=o(" \u2014 "),UG=a("a"),iPo=o("XLMRobertaXLForMultipleChoice"),dPo=o(" (XLM-RoBERTa-XL model)"),cPo=l(),Yb=a("li"),ume=a("strong"),fPo=o("xlnet"),mPo=o(" \u2014 "),JG=a("a"),gPo=o("XLNetForMultipleChoice"),hPo=o(" (XLNet model)"),pPo=l(),Kb=a("li"),_me=a("strong"),uPo=o("yoso"),_Po=o(" \u2014 "),YG=a("a"),bPo=o("YosoForMultipleChoice"),vPo=o(" (YOSO model)"),FPo=l(),Zb=a("p"),TPo=o("The model is set in evaluation mode by default using "),bme=a("code"),MPo=o("model.eval()"),EPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vme=a("code"),CPo=o("model.train()"),wPo=l(),F(e2.$$.fragment),UIe=l(),Vi=a("h2"),o2=a("a"),Fme=a("span"),F(my.$$.fragment),APo=l(),Tme=a("span"),yPo=o("AutoModelForNextSentencePrediction"),JIe=l(),Po=a("div"),F(gy.$$.fragment),LPo=l(),Xi=a("p"),xPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),KG=a("a"),$Po=o("from_pretrained()"),kPo=o(" class method or the "),ZG=a("a"),SPo=o("from_config()"),RPo=o(` class
method.`),BPo=l(),hy=a("p"),PPo=o("This class cannot be instantiated directly using "),Mme=a("code"),IPo=o("__init__()"),qPo=o(" (throws an error)."),NPo=l(),it=a("div"),F(py.$$.fragment),jPo=l(),Eme=a("p"),DPo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),GPo=l(),zi=a("p"),OPo=o(`Note:
Loading a model from its configuration file does `),Cme=a("strong"),VPo=o("not"),XPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eO=a("a"),zPo=o("from_pretrained()"),QPo=o(" to load the model weights."),WPo=l(),F(r2.$$.fragment),HPo=l(),oo=a("div"),F(uy.$$.fragment),UPo=l(),wme=a("p"),JPo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),YPo=l(),Ra=a("p"),KPo=o("The model class to instantiate is selected based on the "),Ame=a("code"),ZPo=o("model_type"),eIo=o(` property of the config object (either
passed as an argument or loaded from `),yme=a("code"),oIo=o("pretrained_model_name_or_path"),rIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lme=a("code"),tIo=o("pretrained_model_name_or_path"),aIo=o(":"),nIo=l(),Yr=a("ul"),t2=a("li"),xme=a("strong"),sIo=o("bert"),lIo=o(" \u2014 "),oO=a("a"),iIo=o("BertForNextSentencePrediction"),dIo=o(" (BERT model)"),cIo=l(),a2=a("li"),$me=a("strong"),fIo=o("fnet"),mIo=o(" \u2014 "),rO=a("a"),gIo=o("FNetForNextSentencePrediction"),hIo=o(" (FNet model)"),pIo=l(),n2=a("li"),kme=a("strong"),uIo=o("megatron-bert"),_Io=o(" \u2014 "),tO=a("a"),bIo=o("MegatronBertForNextSentencePrediction"),vIo=o(" (MegatronBert model)"),FIo=l(),s2=a("li"),Sme=a("strong"),TIo=o("mobilebert"),MIo=o(" \u2014 "),aO=a("a"),EIo=o("MobileBertForNextSentencePrediction"),CIo=o(" (MobileBERT model)"),wIo=l(),l2=a("li"),Rme=a("strong"),AIo=o("qdqbert"),yIo=o(" \u2014 "),nO=a("a"),LIo=o("QDQBertForNextSentencePrediction"),xIo=o(" (QDQBert model)"),$Io=l(),i2=a("p"),kIo=o("The model is set in evaluation mode by default using "),Bme=a("code"),SIo=o("model.eval()"),RIo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pme=a("code"),BIo=o("model.train()"),PIo=l(),F(d2.$$.fragment),YIe=l(),Qi=a("h2"),c2=a("a"),Ime=a("span"),F(_y.$$.fragment),IIo=l(),qme=a("span"),qIo=o("AutoModelForTokenClassification"),KIe=l(),Io=a("div"),F(by.$$.fragment),NIo=l(),Wi=a("p"),jIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),sO=a("a"),DIo=o("from_pretrained()"),GIo=o(" class method or the "),lO=a("a"),OIo=o("from_config()"),VIo=o(` class
method.`),XIo=l(),vy=a("p"),zIo=o("This class cannot be instantiated directly using "),Nme=a("code"),QIo=o("__init__()"),WIo=o(" (throws an error)."),HIo=l(),dt=a("div"),F(Fy.$$.fragment),UIo=l(),jme=a("p"),JIo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),YIo=l(),Hi=a("p"),KIo=o(`Note:
Loading a model from its configuration file does `),Dme=a("strong"),ZIo=o("not"),eqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=a("a"),oqo=o("from_pretrained()"),rqo=o(" to load the model weights."),tqo=l(),F(f2.$$.fragment),aqo=l(),ro=a("div"),F(Ty.$$.fragment),nqo=l(),Gme=a("p"),sqo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),lqo=l(),Ba=a("p"),iqo=o("The model class to instantiate is selected based on the "),Ome=a("code"),dqo=o("model_type"),cqo=o(` property of the config object (either
passed as an argument or loaded from `),Vme=a("code"),fqo=o("pretrained_model_name_or_path"),mqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xme=a("code"),gqo=o("pretrained_model_name_or_path"),hqo=o(":"),pqo=l(),H=a("ul"),m2=a("li"),zme=a("strong"),uqo=o("albert"),_qo=o(" \u2014 "),dO=a("a"),bqo=o("AlbertForTokenClassification"),vqo=o(" (ALBERT model)"),Fqo=l(),g2=a("li"),Qme=a("strong"),Tqo=o("bert"),Mqo=o(" \u2014 "),cO=a("a"),Eqo=o("BertForTokenClassification"),Cqo=o(" (BERT model)"),wqo=l(),h2=a("li"),Wme=a("strong"),Aqo=o("big_bird"),yqo=o(" \u2014 "),fO=a("a"),Lqo=o("BigBirdForTokenClassification"),xqo=o(" (BigBird model)"),$qo=l(),p2=a("li"),Hme=a("strong"),kqo=o("camembert"),Sqo=o(" \u2014 "),mO=a("a"),Rqo=o("CamembertForTokenClassification"),Bqo=o(" (CamemBERT model)"),Pqo=l(),u2=a("li"),Ume=a("strong"),Iqo=o("canine"),qqo=o(" \u2014 "),gO=a("a"),Nqo=o("CanineForTokenClassification"),jqo=o(" (Canine model)"),Dqo=l(),_2=a("li"),Jme=a("strong"),Gqo=o("convbert"),Oqo=o(" \u2014 "),hO=a("a"),Vqo=o("ConvBertForTokenClassification"),Xqo=o(" (ConvBERT model)"),zqo=l(),b2=a("li"),Yme=a("strong"),Qqo=o("data2vec-text"),Wqo=o(" \u2014 "),pO=a("a"),Hqo=o("Data2VecTextForTokenClassification"),Uqo=o(" (Data2VecText model)"),Jqo=l(),v2=a("li"),Kme=a("strong"),Yqo=o("deberta"),Kqo=o(" \u2014 "),uO=a("a"),Zqo=o("DebertaForTokenClassification"),eNo=o(" (DeBERTa model)"),oNo=l(),F2=a("li"),Zme=a("strong"),rNo=o("deberta-v2"),tNo=o(" \u2014 "),_O=a("a"),aNo=o("DebertaV2ForTokenClassification"),nNo=o(" (DeBERTa-v2 model)"),sNo=l(),T2=a("li"),ege=a("strong"),lNo=o("distilbert"),iNo=o(" \u2014 "),bO=a("a"),dNo=o("DistilBertForTokenClassification"),cNo=o(" (DistilBERT model)"),fNo=l(),M2=a("li"),oge=a("strong"),mNo=o("electra"),gNo=o(" \u2014 "),vO=a("a"),hNo=o("ElectraForTokenClassification"),pNo=o(" (ELECTRA model)"),uNo=l(),E2=a("li"),rge=a("strong"),_No=o("flaubert"),bNo=o(" \u2014 "),FO=a("a"),vNo=o("FlaubertForTokenClassification"),FNo=o(" (FlauBERT model)"),TNo=l(),C2=a("li"),tge=a("strong"),MNo=o("fnet"),ENo=o(" \u2014 "),TO=a("a"),CNo=o("FNetForTokenClassification"),wNo=o(" (FNet model)"),ANo=l(),w2=a("li"),age=a("strong"),yNo=o("funnel"),LNo=o(" \u2014 "),MO=a("a"),xNo=o("FunnelForTokenClassification"),$No=o(" (Funnel Transformer model)"),kNo=l(),A2=a("li"),nge=a("strong"),SNo=o("gpt2"),RNo=o(" \u2014 "),EO=a("a"),BNo=o("GPT2ForTokenClassification"),PNo=o(" (OpenAI GPT-2 model)"),INo=l(),y2=a("li"),sge=a("strong"),qNo=o("ibert"),NNo=o(" \u2014 "),CO=a("a"),jNo=o("IBertForTokenClassification"),DNo=o(" (I-BERT model)"),GNo=l(),L2=a("li"),lge=a("strong"),ONo=o("layoutlm"),VNo=o(" \u2014 "),wO=a("a"),XNo=o("LayoutLMForTokenClassification"),zNo=o(" (LayoutLM model)"),QNo=l(),x2=a("li"),ige=a("strong"),WNo=o("layoutlmv2"),HNo=o(" \u2014 "),AO=a("a"),UNo=o("LayoutLMv2ForTokenClassification"),JNo=o(" (LayoutLMv2 model)"),YNo=l(),$2=a("li"),dge=a("strong"),KNo=o("layoutlmv3"),ZNo=o(" \u2014 "),yO=a("a"),ejo=o("LayoutLMv3ForTokenClassification"),ojo=o(" (LayoutLMv3 model)"),rjo=l(),k2=a("li"),cge=a("strong"),tjo=o("longformer"),ajo=o(" \u2014 "),LO=a("a"),njo=o("LongformerForTokenClassification"),sjo=o(" (Longformer model)"),ljo=l(),S2=a("li"),fge=a("strong"),ijo=o("megatron-bert"),djo=o(" \u2014 "),xO=a("a"),cjo=o("MegatronBertForTokenClassification"),fjo=o(" (MegatronBert model)"),mjo=l(),R2=a("li"),mge=a("strong"),gjo=o("mobilebert"),hjo=o(" \u2014 "),$O=a("a"),pjo=o("MobileBertForTokenClassification"),ujo=o(" (MobileBERT model)"),_jo=l(),B2=a("li"),gge=a("strong"),bjo=o("mpnet"),vjo=o(" \u2014 "),kO=a("a"),Fjo=o("MPNetForTokenClassification"),Tjo=o(" (MPNet model)"),Mjo=l(),P2=a("li"),hge=a("strong"),Ejo=o("nystromformer"),Cjo=o(" \u2014 "),SO=a("a"),wjo=o("NystromformerForTokenClassification"),Ajo=o(" (Nystromformer model)"),yjo=l(),I2=a("li"),pge=a("strong"),Ljo=o("qdqbert"),xjo=o(" \u2014 "),RO=a("a"),$jo=o("QDQBertForTokenClassification"),kjo=o(" (QDQBert model)"),Sjo=l(),q2=a("li"),uge=a("strong"),Rjo=o("rembert"),Bjo=o(" \u2014 "),BO=a("a"),Pjo=o("RemBertForTokenClassification"),Ijo=o(" (RemBERT model)"),qjo=l(),N2=a("li"),_ge=a("strong"),Njo=o("roberta"),jjo=o(" \u2014 "),PO=a("a"),Djo=o("RobertaForTokenClassification"),Gjo=o(" (RoBERTa model)"),Ojo=l(),j2=a("li"),bge=a("strong"),Vjo=o("roformer"),Xjo=o(" \u2014 "),IO=a("a"),zjo=o("RoFormerForTokenClassification"),Qjo=o(" (RoFormer model)"),Wjo=l(),D2=a("li"),vge=a("strong"),Hjo=o("squeezebert"),Ujo=o(" \u2014 "),qO=a("a"),Jjo=o("SqueezeBertForTokenClassification"),Yjo=o(" (SqueezeBERT model)"),Kjo=l(),G2=a("li"),Fge=a("strong"),Zjo=o("xlm"),eDo=o(" \u2014 "),NO=a("a"),oDo=o("XLMForTokenClassification"),rDo=o(" (XLM model)"),tDo=l(),O2=a("li"),Tge=a("strong"),aDo=o("xlm-roberta"),nDo=o(" \u2014 "),jO=a("a"),sDo=o("XLMRobertaForTokenClassification"),lDo=o(" (XLM-RoBERTa model)"),iDo=l(),V2=a("li"),Mge=a("strong"),dDo=o("xlm-roberta-xl"),cDo=o(" \u2014 "),DO=a("a"),fDo=o("XLMRobertaXLForTokenClassification"),mDo=o(" (XLM-RoBERTa-XL model)"),gDo=l(),X2=a("li"),Ege=a("strong"),hDo=o("xlnet"),pDo=o(" \u2014 "),GO=a("a"),uDo=o("XLNetForTokenClassification"),_Do=o(" (XLNet model)"),bDo=l(),z2=a("li"),Cge=a("strong"),vDo=o("yoso"),FDo=o(" \u2014 "),OO=a("a"),TDo=o("YosoForTokenClassification"),MDo=o(" (YOSO model)"),EDo=l(),Q2=a("p"),CDo=o("The model is set in evaluation mode by default using "),wge=a("code"),wDo=o("model.eval()"),ADo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Age=a("code"),yDo=o("model.train()"),LDo=l(),F(W2.$$.fragment),ZIe=l(),Ui=a("h2"),H2=a("a"),yge=a("span"),F(My.$$.fragment),xDo=l(),Lge=a("span"),$Do=o("AutoModelForQuestionAnswering"),eqe=l(),qo=a("div"),F(Ey.$$.fragment),kDo=l(),Ji=a("p"),SDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),VO=a("a"),RDo=o("from_pretrained()"),BDo=o(" class method or the "),XO=a("a"),PDo=o("from_config()"),IDo=o(` class
method.`),qDo=l(),Cy=a("p"),NDo=o("This class cannot be instantiated directly using "),xge=a("code"),jDo=o("__init__()"),DDo=o(" (throws an error)."),GDo=l(),ct=a("div"),F(wy.$$.fragment),ODo=l(),$ge=a("p"),VDo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),XDo=l(),Yi=a("p"),zDo=o(`Note:
Loading a model from its configuration file does `),kge=a("strong"),QDo=o("not"),WDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=a("a"),HDo=o("from_pretrained()"),UDo=o(" to load the model weights."),JDo=l(),F(U2.$$.fragment),YDo=l(),to=a("div"),F(Ay.$$.fragment),KDo=l(),Sge=a("p"),ZDo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),eGo=l(),Pa=a("p"),oGo=o("The model class to instantiate is selected based on the "),Rge=a("code"),rGo=o("model_type"),tGo=o(` property of the config object (either
passed as an argument or loaded from `),Bge=a("code"),aGo=o("pretrained_model_name_or_path"),nGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pge=a("code"),sGo=o("pretrained_model_name_or_path"),lGo=o(":"),iGo=l(),O=a("ul"),J2=a("li"),Ige=a("strong"),dGo=o("albert"),cGo=o(" \u2014 "),QO=a("a"),fGo=o("AlbertForQuestionAnswering"),mGo=o(" (ALBERT model)"),gGo=l(),Y2=a("li"),qge=a("strong"),hGo=o("bart"),pGo=o(" \u2014 "),WO=a("a"),uGo=o("BartForQuestionAnswering"),_Go=o(" (BART model)"),bGo=l(),K2=a("li"),Nge=a("strong"),vGo=o("bert"),FGo=o(" \u2014 "),HO=a("a"),TGo=o("BertForQuestionAnswering"),MGo=o(" (BERT model)"),EGo=l(),Z2=a("li"),jge=a("strong"),CGo=o("big_bird"),wGo=o(" \u2014 "),UO=a("a"),AGo=o("BigBirdForQuestionAnswering"),yGo=o(" (BigBird model)"),LGo=l(),ev=a("li"),Dge=a("strong"),xGo=o("bigbird_pegasus"),$Go=o(" \u2014 "),JO=a("a"),kGo=o("BigBirdPegasusForQuestionAnswering"),SGo=o(" (BigBirdPegasus model)"),RGo=l(),ov=a("li"),Gge=a("strong"),BGo=o("camembert"),PGo=o(" \u2014 "),YO=a("a"),IGo=o("CamembertForQuestionAnswering"),qGo=o(" (CamemBERT model)"),NGo=l(),rv=a("li"),Oge=a("strong"),jGo=o("canine"),DGo=o(" \u2014 "),KO=a("a"),GGo=o("CanineForQuestionAnswering"),OGo=o(" (Canine model)"),VGo=l(),tv=a("li"),Vge=a("strong"),XGo=o("convbert"),zGo=o(" \u2014 "),ZO=a("a"),QGo=o("ConvBertForQuestionAnswering"),WGo=o(" (ConvBERT model)"),HGo=l(),av=a("li"),Xge=a("strong"),UGo=o("data2vec-text"),JGo=o(" \u2014 "),eV=a("a"),YGo=o("Data2VecTextForQuestionAnswering"),KGo=o(" (Data2VecText model)"),ZGo=l(),nv=a("li"),zge=a("strong"),eOo=o("deberta"),oOo=o(" \u2014 "),oV=a("a"),rOo=o("DebertaForQuestionAnswering"),tOo=o(" (DeBERTa model)"),aOo=l(),sv=a("li"),Qge=a("strong"),nOo=o("deberta-v2"),sOo=o(" \u2014 "),rV=a("a"),lOo=o("DebertaV2ForQuestionAnswering"),iOo=o(" (DeBERTa-v2 model)"),dOo=l(),lv=a("li"),Wge=a("strong"),cOo=o("distilbert"),fOo=o(" \u2014 "),tV=a("a"),mOo=o("DistilBertForQuestionAnswering"),gOo=o(" (DistilBERT model)"),hOo=l(),iv=a("li"),Hge=a("strong"),pOo=o("electra"),uOo=o(" \u2014 "),aV=a("a"),_Oo=o("ElectraForQuestionAnswering"),bOo=o(" (ELECTRA model)"),vOo=l(),dv=a("li"),Uge=a("strong"),FOo=o("flaubert"),TOo=o(" \u2014 "),nV=a("a"),MOo=o("FlaubertForQuestionAnsweringSimple"),EOo=o(" (FlauBERT model)"),COo=l(),cv=a("li"),Jge=a("strong"),wOo=o("fnet"),AOo=o(" \u2014 "),sV=a("a"),yOo=o("FNetForQuestionAnswering"),LOo=o(" (FNet model)"),xOo=l(),fv=a("li"),Yge=a("strong"),$Oo=o("funnel"),kOo=o(" \u2014 "),lV=a("a"),SOo=o("FunnelForQuestionAnswering"),ROo=o(" (Funnel Transformer model)"),BOo=l(),mv=a("li"),Kge=a("strong"),POo=o("gptj"),IOo=o(" \u2014 "),iV=a("a"),qOo=o("GPTJForQuestionAnswering"),NOo=o(" (GPT-J model)"),jOo=l(),gv=a("li"),Zge=a("strong"),DOo=o("ibert"),GOo=o(" \u2014 "),dV=a("a"),OOo=o("IBertForQuestionAnswering"),VOo=o(" (I-BERT model)"),XOo=l(),hv=a("li"),ehe=a("strong"),zOo=o("layoutlmv2"),QOo=o(" \u2014 "),cV=a("a"),WOo=o("LayoutLMv2ForQuestionAnswering"),HOo=o(" (LayoutLMv2 model)"),UOo=l(),pv=a("li"),ohe=a("strong"),JOo=o("layoutlmv3"),YOo=o(" \u2014 "),fV=a("a"),KOo=o("LayoutLMv3ForQuestionAnswering"),ZOo=o(" (LayoutLMv3 model)"),eVo=l(),uv=a("li"),rhe=a("strong"),oVo=o("led"),rVo=o(" \u2014 "),mV=a("a"),tVo=o("LEDForQuestionAnswering"),aVo=o(" (LED model)"),nVo=l(),_v=a("li"),the=a("strong"),sVo=o("longformer"),lVo=o(" \u2014 "),gV=a("a"),iVo=o("LongformerForQuestionAnswering"),dVo=o(" (Longformer model)"),cVo=l(),bv=a("li"),ahe=a("strong"),fVo=o("lxmert"),mVo=o(" \u2014 "),hV=a("a"),gVo=o("LxmertForQuestionAnswering"),hVo=o(" (LXMERT model)"),pVo=l(),vv=a("li"),nhe=a("strong"),uVo=o("mbart"),_Vo=o(" \u2014 "),pV=a("a"),bVo=o("MBartForQuestionAnswering"),vVo=o(" (mBART model)"),FVo=l(),Fv=a("li"),she=a("strong"),TVo=o("megatron-bert"),MVo=o(" \u2014 "),uV=a("a"),EVo=o("MegatronBertForQuestionAnswering"),CVo=o(" (MegatronBert model)"),wVo=l(),Tv=a("li"),lhe=a("strong"),AVo=o("mobilebert"),yVo=o(" \u2014 "),_V=a("a"),LVo=o("MobileBertForQuestionAnswering"),xVo=o(" (MobileBERT model)"),$Vo=l(),Mv=a("li"),ihe=a("strong"),kVo=o("mpnet"),SVo=o(" \u2014 "),bV=a("a"),RVo=o("MPNetForQuestionAnswering"),BVo=o(" (MPNet model)"),PVo=l(),Ev=a("li"),dhe=a("strong"),IVo=o("nystromformer"),qVo=o(" \u2014 "),vV=a("a"),NVo=o("NystromformerForQuestionAnswering"),jVo=o(" (Nystromformer model)"),DVo=l(),Cv=a("li"),che=a("strong"),GVo=o("qdqbert"),OVo=o(" \u2014 "),FV=a("a"),VVo=o("QDQBertForQuestionAnswering"),XVo=o(" (QDQBert model)"),zVo=l(),wv=a("li"),fhe=a("strong"),QVo=o("reformer"),WVo=o(" \u2014 "),TV=a("a"),HVo=o("ReformerForQuestionAnswering"),UVo=o(" (Reformer model)"),JVo=l(),Av=a("li"),mhe=a("strong"),YVo=o("rembert"),KVo=o(" \u2014 "),MV=a("a"),ZVo=o("RemBertForQuestionAnswering"),eXo=o(" (RemBERT model)"),oXo=l(),yv=a("li"),ghe=a("strong"),rXo=o("roberta"),tXo=o(" \u2014 "),EV=a("a"),aXo=o("RobertaForQuestionAnswering"),nXo=o(" (RoBERTa model)"),sXo=l(),Lv=a("li"),hhe=a("strong"),lXo=o("roformer"),iXo=o(" \u2014 "),CV=a("a"),dXo=o("RoFormerForQuestionAnswering"),cXo=o(" (RoFormer model)"),fXo=l(),xv=a("li"),phe=a("strong"),mXo=o("splinter"),gXo=o(" \u2014 "),wV=a("a"),hXo=o("SplinterForQuestionAnswering"),pXo=o(" (Splinter model)"),uXo=l(),$v=a("li"),uhe=a("strong"),_Xo=o("squeezebert"),bXo=o(" \u2014 "),AV=a("a"),vXo=o("SqueezeBertForQuestionAnswering"),FXo=o(" (SqueezeBERT model)"),TXo=l(),kv=a("li"),_he=a("strong"),MXo=o("xlm"),EXo=o(" \u2014 "),yV=a("a"),CXo=o("XLMForQuestionAnsweringSimple"),wXo=o(" (XLM model)"),AXo=l(),Sv=a("li"),bhe=a("strong"),yXo=o("xlm-roberta"),LXo=o(" \u2014 "),LV=a("a"),xXo=o("XLMRobertaForQuestionAnswering"),$Xo=o(" (XLM-RoBERTa model)"),kXo=l(),Rv=a("li"),vhe=a("strong"),SXo=o("xlm-roberta-xl"),RXo=o(" \u2014 "),xV=a("a"),BXo=o("XLMRobertaXLForQuestionAnswering"),PXo=o(" (XLM-RoBERTa-XL model)"),IXo=l(),Bv=a("li"),Fhe=a("strong"),qXo=o("xlnet"),NXo=o(" \u2014 "),$V=a("a"),jXo=o("XLNetForQuestionAnsweringSimple"),DXo=o(" (XLNet model)"),GXo=l(),Pv=a("li"),The=a("strong"),OXo=o("yoso"),VXo=o(" \u2014 "),kV=a("a"),XXo=o("YosoForQuestionAnswering"),zXo=o(" (YOSO model)"),QXo=l(),Iv=a("p"),WXo=o("The model is set in evaluation mode by default using "),Mhe=a("code"),HXo=o("model.eval()"),UXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ehe=a("code"),JXo=o("model.train()"),YXo=l(),F(qv.$$.fragment),oqe=l(),Ki=a("h2"),Nv=a("a"),Che=a("span"),F(yy.$$.fragment),KXo=l(),whe=a("span"),ZXo=o("AutoModelForTableQuestionAnswering"),rqe=l(),No=a("div"),F(Ly.$$.fragment),ezo=l(),Zi=a("p"),ozo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),SV=a("a"),rzo=o("from_pretrained()"),tzo=o(" class method or the "),RV=a("a"),azo=o("from_config()"),nzo=o(` class
method.`),szo=l(),xy=a("p"),lzo=o("This class cannot be instantiated directly using "),Ahe=a("code"),izo=o("__init__()"),dzo=o(" (throws an error)."),czo=l(),ft=a("div"),F($y.$$.fragment),fzo=l(),yhe=a("p"),mzo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),gzo=l(),ed=a("p"),hzo=o(`Note:
Loading a model from its configuration file does `),Lhe=a("strong"),pzo=o("not"),uzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=a("a"),_zo=o("from_pretrained()"),bzo=o(" to load the model weights."),vzo=l(),F(jv.$$.fragment),Fzo=l(),ao=a("div"),F(ky.$$.fragment),Tzo=l(),xhe=a("p"),Mzo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Ezo=l(),Ia=a("p"),Czo=o("The model class to instantiate is selected based on the "),$he=a("code"),wzo=o("model_type"),Azo=o(` property of the config object (either
passed as an argument or loaded from `),khe=a("code"),yzo=o("pretrained_model_name_or_path"),Lzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),She=a("code"),xzo=o("pretrained_model_name_or_path"),$zo=o(":"),kzo=l(),Rhe=a("ul"),Dv=a("li"),Bhe=a("strong"),Szo=o("tapas"),Rzo=o(" \u2014 "),PV=a("a"),Bzo=o("TapasForQuestionAnswering"),Pzo=o(" (TAPAS model)"),Izo=l(),Gv=a("p"),qzo=o("The model is set in evaluation mode by default using "),Phe=a("code"),Nzo=o("model.eval()"),jzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ihe=a("code"),Dzo=o("model.train()"),Gzo=l(),F(Ov.$$.fragment),tqe=l(),od=a("h2"),Vv=a("a"),qhe=a("span"),F(Sy.$$.fragment),Ozo=l(),Nhe=a("span"),Vzo=o("AutoModelForImageClassification"),aqe=l(),jo=a("div"),F(Ry.$$.fragment),Xzo=l(),rd=a("p"),zzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),IV=a("a"),Qzo=o("from_pretrained()"),Wzo=o(" class method or the "),qV=a("a"),Hzo=o("from_config()"),Uzo=o(` class
method.`),Jzo=l(),By=a("p"),Yzo=o("This class cannot be instantiated directly using "),jhe=a("code"),Kzo=o("__init__()"),Zzo=o(" (throws an error)."),eQo=l(),mt=a("div"),F(Py.$$.fragment),oQo=l(),Dhe=a("p"),rQo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),tQo=l(),td=a("p"),aQo=o(`Note:
Loading a model from its configuration file does `),Ghe=a("strong"),nQo=o("not"),sQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=a("a"),lQo=o("from_pretrained()"),iQo=o(" to load the model weights."),dQo=l(),F(Xv.$$.fragment),cQo=l(),no=a("div"),F(Iy.$$.fragment),fQo=l(),Ohe=a("p"),mQo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),gQo=l(),qa=a("p"),hQo=o("The model class to instantiate is selected based on the "),Vhe=a("code"),pQo=o("model_type"),uQo=o(` property of the config object (either
passed as an argument or loaded from `),Xhe=a("code"),_Qo=o("pretrained_model_name_or_path"),bQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zhe=a("code"),vQo=o("pretrained_model_name_or_path"),FQo=o(":"),TQo=l(),Fe=a("ul"),zv=a("li"),Qhe=a("strong"),MQo=o("beit"),EQo=o(" \u2014 "),jV=a("a"),CQo=o("BeitForImageClassification"),wQo=o(" (BEiT model)"),AQo=l(),Qv=a("li"),Whe=a("strong"),yQo=o("convnext"),LQo=o(" \u2014 "),DV=a("a"),xQo=o("ConvNextForImageClassification"),$Qo=o(" (ConvNext model)"),kQo=l(),Wv=a("li"),Hhe=a("strong"),SQo=o("data2vec-vision"),RQo=o(" \u2014 "),GV=a("a"),BQo=o("Data2VecVisionForImageClassification"),PQo=o(" (Data2VecVision model)"),IQo=l(),Bs=a("li"),Uhe=a("strong"),qQo=o("deit"),NQo=o(" \u2014 "),OV=a("a"),jQo=o("DeiTForImageClassification"),DQo=o(" or "),VV=a("a"),GQo=o("DeiTForImageClassificationWithTeacher"),OQo=o(" (DeiT model)"),VQo=l(),Hv=a("li"),Jhe=a("strong"),XQo=o("imagegpt"),zQo=o(" \u2014 "),XV=a("a"),QQo=o("ImageGPTForImageClassification"),WQo=o(" (ImageGPT model)"),HQo=l(),gt=a("li"),Yhe=a("strong"),UQo=o("perceiver"),JQo=o(" \u2014 "),zV=a("a"),YQo=o("PerceiverForImageClassificationLearned"),KQo=o(" or "),QV=a("a"),ZQo=o("PerceiverForImageClassificationFourier"),eWo=o(" or "),WV=a("a"),oWo=o("PerceiverForImageClassificationConvProcessing"),rWo=o(" (Perceiver model)"),tWo=l(),Uv=a("li"),Khe=a("strong"),aWo=o("poolformer"),nWo=o(" \u2014 "),HV=a("a"),sWo=o("PoolFormerForImageClassification"),lWo=o(" (PoolFormer model)"),iWo=l(),Jv=a("li"),Zhe=a("strong"),dWo=o("regnet"),cWo=o(" \u2014 "),UV=a("a"),fWo=o("RegNetForImageClassification"),mWo=o(" (RegNet model)"),gWo=l(),Yv=a("li"),epe=a("strong"),hWo=o("resnet"),pWo=o(" \u2014 "),JV=a("a"),uWo=o("ResNetForImageClassification"),_Wo=o(" (ResNet model)"),bWo=l(),Kv=a("li"),ope=a("strong"),vWo=o("segformer"),FWo=o(" \u2014 "),YV=a("a"),TWo=o("SegformerForImageClassification"),MWo=o(" (SegFormer model)"),EWo=l(),Zv=a("li"),rpe=a("strong"),CWo=o("swin"),wWo=o(" \u2014 "),KV=a("a"),AWo=o("SwinForImageClassification"),yWo=o(" (Swin model)"),LWo=l(),eF=a("li"),tpe=a("strong"),xWo=o("van"),$Wo=o(" \u2014 "),ZV=a("a"),kWo=o("VanForImageClassification"),SWo=o(" (VAN model)"),RWo=l(),oF=a("li"),ape=a("strong"),BWo=o("vit"),PWo=o(" \u2014 "),eX=a("a"),IWo=o("ViTForImageClassification"),qWo=o(" (ViT model)"),NWo=l(),rF=a("p"),jWo=o("The model is set in evaluation mode by default using "),npe=a("code"),DWo=o("model.eval()"),GWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),spe=a("code"),OWo=o("model.train()"),VWo=l(),F(tF.$$.fragment),nqe=l(),ad=a("h2"),aF=a("a"),lpe=a("span"),F(qy.$$.fragment),XWo=l(),ipe=a("span"),zWo=o("AutoModelForVision2Seq"),sqe=l(),Do=a("div"),F(Ny.$$.fragment),QWo=l(),nd=a("p"),WWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),oX=a("a"),HWo=o("from_pretrained()"),UWo=o(" class method or the "),rX=a("a"),JWo=o("from_config()"),YWo=o(` class
method.`),KWo=l(),jy=a("p"),ZWo=o("This class cannot be instantiated directly using "),dpe=a("code"),eHo=o("__init__()"),oHo=o(" (throws an error)."),rHo=l(),ht=a("div"),F(Dy.$$.fragment),tHo=l(),cpe=a("p"),aHo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),nHo=l(),sd=a("p"),sHo=o(`Note:
Loading a model from its configuration file does `),fpe=a("strong"),lHo=o("not"),iHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tX=a("a"),dHo=o("from_pretrained()"),cHo=o(" to load the model weights."),fHo=l(),F(nF.$$.fragment),mHo=l(),so=a("div"),F(Gy.$$.fragment),gHo=l(),mpe=a("p"),hHo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),pHo=l(),Na=a("p"),uHo=o("The model class to instantiate is selected based on the "),gpe=a("code"),_Ho=o("model_type"),bHo=o(` property of the config object (either
passed as an argument or loaded from `),hpe=a("code"),vHo=o("pretrained_model_name_or_path"),FHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ppe=a("code"),THo=o("pretrained_model_name_or_path"),MHo=o(":"),EHo=l(),upe=a("ul"),sF=a("li"),_pe=a("strong"),CHo=o("vision-encoder-decoder"),wHo=o(" \u2014 "),aX=a("a"),AHo=o("VisionEncoderDecoderModel"),yHo=o(" (Vision Encoder decoder model)"),LHo=l(),lF=a("p"),xHo=o("The model is set in evaluation mode by default using "),bpe=a("code"),$Ho=o("model.eval()"),kHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vpe=a("code"),SHo=o("model.train()"),RHo=l(),F(iF.$$.fragment),lqe=l(),ld=a("h2"),dF=a("a"),Fpe=a("span"),F(Oy.$$.fragment),BHo=l(),Tpe=a("span"),PHo=o("AutoModelForAudioClassification"),iqe=l(),Go=a("div"),F(Vy.$$.fragment),IHo=l(),id=a("p"),qHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),nX=a("a"),NHo=o("from_pretrained()"),jHo=o(" class method or the "),sX=a("a"),DHo=o("from_config()"),GHo=o(` class
method.`),OHo=l(),Xy=a("p"),VHo=o("This class cannot be instantiated directly using "),Mpe=a("code"),XHo=o("__init__()"),zHo=o(" (throws an error)."),QHo=l(),pt=a("div"),F(zy.$$.fragment),WHo=l(),Epe=a("p"),HHo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),UHo=l(),dd=a("p"),JHo=o(`Note:
Loading a model from its configuration file does `),Cpe=a("strong"),YHo=o("not"),KHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lX=a("a"),ZHo=o("from_pretrained()"),eUo=o(" to load the model weights."),oUo=l(),F(cF.$$.fragment),rUo=l(),lo=a("div"),F(Qy.$$.fragment),tUo=l(),wpe=a("p"),aUo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),nUo=l(),ja=a("p"),sUo=o("The model class to instantiate is selected based on the "),Ape=a("code"),lUo=o("model_type"),iUo=o(` property of the config object (either
passed as an argument or loaded from `),ype=a("code"),dUo=o("pretrained_model_name_or_path"),cUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lpe=a("code"),fUo=o("pretrained_model_name_or_path"),mUo=o(":"),gUo=l(),Ne=a("ul"),fF=a("li"),xpe=a("strong"),hUo=o("data2vec-audio"),pUo=o(" \u2014 "),iX=a("a"),uUo=o("Data2VecAudioForSequenceClassification"),_Uo=o(" (Data2VecAudio model)"),bUo=l(),mF=a("li"),$pe=a("strong"),vUo=o("hubert"),FUo=o(" \u2014 "),dX=a("a"),TUo=o("HubertForSequenceClassification"),MUo=o(" (Hubert model)"),EUo=l(),gF=a("li"),kpe=a("strong"),CUo=o("sew"),wUo=o(" \u2014 "),cX=a("a"),AUo=o("SEWForSequenceClassification"),yUo=o(" (SEW model)"),LUo=l(),hF=a("li"),Spe=a("strong"),xUo=o("sew-d"),$Uo=o(" \u2014 "),fX=a("a"),kUo=o("SEWDForSequenceClassification"),SUo=o(" (SEW-D model)"),RUo=l(),pF=a("li"),Rpe=a("strong"),BUo=o("unispeech"),PUo=o(" \u2014 "),mX=a("a"),IUo=o("UniSpeechForSequenceClassification"),qUo=o(" (UniSpeech model)"),NUo=l(),uF=a("li"),Bpe=a("strong"),jUo=o("unispeech-sat"),DUo=o(" \u2014 "),gX=a("a"),GUo=o("UniSpeechSatForSequenceClassification"),OUo=o(" (UniSpeechSat model)"),VUo=l(),_F=a("li"),Ppe=a("strong"),XUo=o("wav2vec2"),zUo=o(" \u2014 "),hX=a("a"),QUo=o("Wav2Vec2ForSequenceClassification"),WUo=o(" (Wav2Vec2 model)"),HUo=l(),bF=a("li"),Ipe=a("strong"),UUo=o("wavlm"),JUo=o(" \u2014 "),pX=a("a"),YUo=o("WavLMForSequenceClassification"),KUo=o(" (WavLM model)"),ZUo=l(),vF=a("p"),eJo=o("The model is set in evaluation mode by default using "),qpe=a("code"),oJo=o("model.eval()"),rJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Npe=a("code"),tJo=o("model.train()"),aJo=l(),F(FF.$$.fragment),dqe=l(),cd=a("h2"),TF=a("a"),jpe=a("span"),F(Wy.$$.fragment),nJo=l(),Dpe=a("span"),sJo=o("AutoModelForAudioFrameClassification"),cqe=l(),Oo=a("div"),F(Hy.$$.fragment),lJo=l(),fd=a("p"),iJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),uX=a("a"),dJo=o("from_pretrained()"),cJo=o(" class method or the "),_X=a("a"),fJo=o("from_config()"),mJo=o(` class
method.`),gJo=l(),Uy=a("p"),hJo=o("This class cannot be instantiated directly using "),Gpe=a("code"),pJo=o("__init__()"),uJo=o(" (throws an error)."),_Jo=l(),ut=a("div"),F(Jy.$$.fragment),bJo=l(),Ope=a("p"),vJo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),FJo=l(),md=a("p"),TJo=o(`Note:
Loading a model from its configuration file does `),Vpe=a("strong"),MJo=o("not"),EJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bX=a("a"),CJo=o("from_pretrained()"),wJo=o(" to load the model weights."),AJo=l(),F(MF.$$.fragment),yJo=l(),io=a("div"),F(Yy.$$.fragment),LJo=l(),Xpe=a("p"),xJo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),$Jo=l(),Da=a("p"),kJo=o("The model class to instantiate is selected based on the "),zpe=a("code"),SJo=o("model_type"),RJo=o(` property of the config object (either
passed as an argument or loaded from `),Qpe=a("code"),BJo=o("pretrained_model_name_or_path"),PJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wpe=a("code"),IJo=o("pretrained_model_name_or_path"),qJo=o(":"),NJo=l(),Ga=a("ul"),EF=a("li"),Hpe=a("strong"),jJo=o("data2vec-audio"),DJo=o(" \u2014 "),vX=a("a"),GJo=o("Data2VecAudioForAudioFrameClassification"),OJo=o(" (Data2VecAudio model)"),VJo=l(),CF=a("li"),Upe=a("strong"),XJo=o("unispeech-sat"),zJo=o(" \u2014 "),FX=a("a"),QJo=o("UniSpeechSatForAudioFrameClassification"),WJo=o(" (UniSpeechSat model)"),HJo=l(),wF=a("li"),Jpe=a("strong"),UJo=o("wav2vec2"),JJo=o(" \u2014 "),TX=a("a"),YJo=o("Wav2Vec2ForAudioFrameClassification"),KJo=o(" (Wav2Vec2 model)"),ZJo=l(),AF=a("li"),Ype=a("strong"),eYo=o("wavlm"),oYo=o(" \u2014 "),MX=a("a"),rYo=o("WavLMForAudioFrameClassification"),tYo=o(" (WavLM model)"),aYo=l(),yF=a("p"),nYo=o("The model is set in evaluation mode by default using "),Kpe=a("code"),sYo=o("model.eval()"),lYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=a("code"),iYo=o("model.train()"),dYo=l(),F(LF.$$.fragment),fqe=l(),gd=a("h2"),xF=a("a"),eue=a("span"),F(Ky.$$.fragment),cYo=l(),oue=a("span"),fYo=o("AutoModelForCTC"),mqe=l(),Vo=a("div"),F(Zy.$$.fragment),mYo=l(),hd=a("p"),gYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),EX=a("a"),hYo=o("from_pretrained()"),pYo=o(" class method or the "),CX=a("a"),uYo=o("from_config()"),_Yo=o(` class
method.`),bYo=l(),eL=a("p"),vYo=o("This class cannot be instantiated directly using "),rue=a("code"),FYo=o("__init__()"),TYo=o(" (throws an error)."),MYo=l(),_t=a("div"),F(oL.$$.fragment),EYo=l(),tue=a("p"),CYo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),wYo=l(),pd=a("p"),AYo=o(`Note:
Loading a model from its configuration file does `),aue=a("strong"),yYo=o("not"),LYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wX=a("a"),xYo=o("from_pretrained()"),$Yo=o(" to load the model weights."),kYo=l(),F($F.$$.fragment),SYo=l(),co=a("div"),F(rL.$$.fragment),RYo=l(),nue=a("p"),BYo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),PYo=l(),Oa=a("p"),IYo=o("The model class to instantiate is selected based on the "),sue=a("code"),qYo=o("model_type"),NYo=o(` property of the config object (either
passed as an argument or loaded from `),lue=a("code"),jYo=o("pretrained_model_name_or_path"),DYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iue=a("code"),GYo=o("pretrained_model_name_or_path"),OYo=o(":"),VYo=l(),je=a("ul"),kF=a("li"),due=a("strong"),XYo=o("data2vec-audio"),zYo=o(" \u2014 "),AX=a("a"),QYo=o("Data2VecAudioForCTC"),WYo=o(" (Data2VecAudio model)"),HYo=l(),SF=a("li"),cue=a("strong"),UYo=o("hubert"),JYo=o(" \u2014 "),yX=a("a"),YYo=o("HubertForCTC"),KYo=o(" (Hubert model)"),ZYo=l(),RF=a("li"),fue=a("strong"),eKo=o("sew"),oKo=o(" \u2014 "),LX=a("a"),rKo=o("SEWForCTC"),tKo=o(" (SEW model)"),aKo=l(),BF=a("li"),mue=a("strong"),nKo=o("sew-d"),sKo=o(" \u2014 "),xX=a("a"),lKo=o("SEWDForCTC"),iKo=o(" (SEW-D model)"),dKo=l(),PF=a("li"),gue=a("strong"),cKo=o("unispeech"),fKo=o(" \u2014 "),$X=a("a"),mKo=o("UniSpeechForCTC"),gKo=o(" (UniSpeech model)"),hKo=l(),IF=a("li"),hue=a("strong"),pKo=o("unispeech-sat"),uKo=o(" \u2014 "),kX=a("a"),_Ko=o("UniSpeechSatForCTC"),bKo=o(" (UniSpeechSat model)"),vKo=l(),qF=a("li"),pue=a("strong"),FKo=o("wav2vec2"),TKo=o(" \u2014 "),SX=a("a"),MKo=o("Wav2Vec2ForCTC"),EKo=o(" (Wav2Vec2 model)"),CKo=l(),NF=a("li"),uue=a("strong"),wKo=o("wavlm"),AKo=o(" \u2014 "),RX=a("a"),yKo=o("WavLMForCTC"),LKo=o(" (WavLM model)"),xKo=l(),jF=a("p"),$Ko=o("The model is set in evaluation mode by default using "),_ue=a("code"),kKo=o("model.eval()"),SKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=a("code"),RKo=o("model.train()"),BKo=l(),F(DF.$$.fragment),gqe=l(),ud=a("h2"),GF=a("a"),vue=a("span"),F(tL.$$.fragment),PKo=l(),Fue=a("span"),IKo=o("AutoModelForSpeechSeq2Seq"),hqe=l(),Xo=a("div"),F(aL.$$.fragment),qKo=l(),_d=a("p"),NKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),BX=a("a"),jKo=o("from_pretrained()"),DKo=o(" class method or the "),PX=a("a"),GKo=o("from_config()"),OKo=o(` class
method.`),VKo=l(),nL=a("p"),XKo=o("This class cannot be instantiated directly using "),Tue=a("code"),zKo=o("__init__()"),QKo=o(" (throws an error)."),WKo=l(),bt=a("div"),F(sL.$$.fragment),HKo=l(),Mue=a("p"),UKo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),JKo=l(),bd=a("p"),YKo=o(`Note:
Loading a model from its configuration file does `),Eue=a("strong"),KKo=o("not"),ZKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IX=a("a"),eZo=o("from_pretrained()"),oZo=o(" to load the model weights."),rZo=l(),F(OF.$$.fragment),tZo=l(),fo=a("div"),F(lL.$$.fragment),aZo=l(),Cue=a("p"),nZo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),sZo=l(),Va=a("p"),lZo=o("The model class to instantiate is selected based on the "),wue=a("code"),iZo=o("model_type"),dZo=o(` property of the config object (either
passed as an argument or loaded from `),Aue=a("code"),cZo=o("pretrained_model_name_or_path"),fZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yue=a("code"),mZo=o("pretrained_model_name_or_path"),gZo=o(":"),hZo=l(),iL=a("ul"),VF=a("li"),Lue=a("strong"),pZo=o("speech-encoder-decoder"),uZo=o(" \u2014 "),qX=a("a"),_Zo=o("SpeechEncoderDecoderModel"),bZo=o(" (Speech Encoder decoder model)"),vZo=l(),XF=a("li"),xue=a("strong"),FZo=o("speech_to_text"),TZo=o(" \u2014 "),NX=a("a"),MZo=o("Speech2TextForConditionalGeneration"),EZo=o(" (Speech2Text model)"),CZo=l(),zF=a("p"),wZo=o("The model is set in evaluation mode by default using "),$ue=a("code"),AZo=o("model.eval()"),yZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kue=a("code"),LZo=o("model.train()"),xZo=l(),F(QF.$$.fragment),pqe=l(),vd=a("h2"),WF=a("a"),Sue=a("span"),F(dL.$$.fragment),$Zo=l(),Rue=a("span"),kZo=o("AutoModelForAudioXVector"),uqe=l(),zo=a("div"),F(cL.$$.fragment),SZo=l(),Fd=a("p"),RZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),jX=a("a"),BZo=o("from_pretrained()"),PZo=o(" class method or the "),DX=a("a"),IZo=o("from_config()"),qZo=o(` class
method.`),NZo=l(),fL=a("p"),jZo=o("This class cannot be instantiated directly using "),Bue=a("code"),DZo=o("__init__()"),GZo=o(" (throws an error)."),OZo=l(),vt=a("div"),F(mL.$$.fragment),VZo=l(),Pue=a("p"),XZo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),zZo=l(),Td=a("p"),QZo=o(`Note:
Loading a model from its configuration file does `),Iue=a("strong"),WZo=o("not"),HZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GX=a("a"),UZo=o("from_pretrained()"),JZo=o(" to load the model weights."),YZo=l(),F(HF.$$.fragment),KZo=l(),mo=a("div"),F(gL.$$.fragment),ZZo=l(),que=a("p"),eer=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),oer=l(),Xa=a("p"),rer=o("The model class to instantiate is selected based on the "),Nue=a("code"),ter=o("model_type"),aer=o(` property of the config object (either
passed as an argument or loaded from `),jue=a("code"),ner=o("pretrained_model_name_or_path"),ser=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Due=a("code"),ler=o("pretrained_model_name_or_path"),ier=o(":"),der=l(),za=a("ul"),UF=a("li"),Gue=a("strong"),cer=o("data2vec-audio"),fer=o(" \u2014 "),OX=a("a"),mer=o("Data2VecAudioForXVector"),ger=o(" (Data2VecAudio model)"),her=l(),JF=a("li"),Oue=a("strong"),per=o("unispeech-sat"),uer=o(" \u2014 "),VX=a("a"),_er=o("UniSpeechSatForXVector"),ber=o(" (UniSpeechSat model)"),ver=l(),YF=a("li"),Vue=a("strong"),Fer=o("wav2vec2"),Ter=o(" \u2014 "),XX=a("a"),Mer=o("Wav2Vec2ForXVector"),Eer=o(" (Wav2Vec2 model)"),Cer=l(),KF=a("li"),Xue=a("strong"),wer=o("wavlm"),Aer=o(" \u2014 "),zX=a("a"),yer=o("WavLMForXVector"),Ler=o(" (WavLM model)"),xer=l(),ZF=a("p"),$er=o("The model is set in evaluation mode by default using "),zue=a("code"),ker=o("model.eval()"),Ser=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Que=a("code"),Rer=o("model.train()"),Ber=l(),F(e6.$$.fragment),_qe=l(),Md=a("h2"),o6=a("a"),Wue=a("span"),F(hL.$$.fragment),Per=l(),Hue=a("span"),Ier=o("AutoModelForMaskedImageModeling"),bqe=l(),Qo=a("div"),F(pL.$$.fragment),qer=l(),Ed=a("p"),Ner=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),QX=a("a"),jer=o("from_pretrained()"),Der=o(" class method or the "),WX=a("a"),Ger=o("from_config()"),Oer=o(` class
method.`),Ver=l(),uL=a("p"),Xer=o("This class cannot be instantiated directly using "),Uue=a("code"),zer=o("__init__()"),Qer=o(" (throws an error)."),Wer=l(),Ft=a("div"),F(_L.$$.fragment),Her=l(),Jue=a("p"),Uer=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Jer=l(),Cd=a("p"),Yer=o(`Note:
Loading a model from its configuration file does `),Yue=a("strong"),Ker=o("not"),Zer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HX=a("a"),eor=o("from_pretrained()"),oor=o(" to load the model weights."),ror=l(),F(r6.$$.fragment),tor=l(),go=a("div"),F(bL.$$.fragment),aor=l(),Kue=a("p"),nor=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),sor=l(),Qa=a("p"),lor=o("The model class to instantiate is selected based on the "),Zue=a("code"),ior=o("model_type"),dor=o(` property of the config object (either
passed as an argument or loaded from `),e_e=a("code"),cor=o("pretrained_model_name_or_path"),mor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o_e=a("code"),gor=o("pretrained_model_name_or_path"),hor=o(":"),por=l(),wd=a("ul"),t6=a("li"),r_e=a("strong"),uor=o("deit"),_or=o(" \u2014 "),UX=a("a"),bor=o("DeiTForMaskedImageModeling"),vor=o(" (DeiT model)"),For=l(),a6=a("li"),t_e=a("strong"),Tor=o("swin"),Mor=o(" \u2014 "),JX=a("a"),Eor=o("SwinForMaskedImageModeling"),Cor=o(" (Swin model)"),wor=l(),n6=a("li"),a_e=a("strong"),Aor=o("vit"),yor=o(" \u2014 "),YX=a("a"),Lor=o("ViTForMaskedImageModeling"),xor=o(" (ViT model)"),$or=l(),s6=a("p"),kor=o("The model is set in evaluation mode by default using "),n_e=a("code"),Sor=o("model.eval()"),Ror=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s_e=a("code"),Bor=o("model.train()"),Por=l(),F(l6.$$.fragment),vqe=l(),Ad=a("h2"),i6=a("a"),l_e=a("span"),F(vL.$$.fragment),Ior=l(),i_e=a("span"),qor=o("AutoModelForObjectDetection"),Fqe=l(),Wo=a("div"),F(FL.$$.fragment),Nor=l(),yd=a("p"),jor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),KX=a("a"),Dor=o("from_pretrained()"),Gor=o(" class method or the "),ZX=a("a"),Oor=o("from_config()"),Vor=o(` class
method.`),Xor=l(),TL=a("p"),zor=o("This class cannot be instantiated directly using "),d_e=a("code"),Qor=o("__init__()"),Wor=o(" (throws an error)."),Hor=l(),Tt=a("div"),F(ML.$$.fragment),Uor=l(),c_e=a("p"),Jor=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Yor=l(),Ld=a("p"),Kor=o(`Note:
Loading a model from its configuration file does `),f_e=a("strong"),Zor=o("not"),err=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=a("a"),orr=o("from_pretrained()"),rrr=o(" to load the model weights."),trr=l(),F(d6.$$.fragment),arr=l(),ho=a("div"),F(EL.$$.fragment),nrr=l(),m_e=a("p"),srr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),lrr=l(),Wa=a("p"),irr=o("The model class to instantiate is selected based on the "),g_e=a("code"),drr=o("model_type"),crr=o(` property of the config object (either
passed as an argument or loaded from `),h_e=a("code"),frr=o("pretrained_model_name_or_path"),mrr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p_e=a("code"),grr=o("pretrained_model_name_or_path"),hrr=o(":"),prr=l(),CL=a("ul"),c6=a("li"),u_e=a("strong"),urr=o("detr"),_rr=o(" \u2014 "),oz=a("a"),brr=o("DetrForObjectDetection"),vrr=o(" (DETR model)"),Frr=l(),f6=a("li"),__e=a("strong"),Trr=o("yolos"),Mrr=o(" \u2014 "),rz=a("a"),Err=o("YolosForObjectDetection"),Crr=o(" (YOLOS model)"),wrr=l(),m6=a("p"),Arr=o("The model is set in evaluation mode by default using "),b_e=a("code"),yrr=o("model.eval()"),Lrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v_e=a("code"),xrr=o("model.train()"),$rr=l(),F(g6.$$.fragment),Tqe=l(),xd=a("h2"),h6=a("a"),F_e=a("span"),F(wL.$$.fragment),krr=l(),T_e=a("span"),Srr=o("AutoModelForImageSegmentation"),Mqe=l(),Ho=a("div"),F(AL.$$.fragment),Rrr=l(),$d=a("p"),Brr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),tz=a("a"),Prr=o("from_pretrained()"),Irr=o(" class method or the "),az=a("a"),qrr=o("from_config()"),Nrr=o(` class
method.`),jrr=l(),yL=a("p"),Drr=o("This class cannot be instantiated directly using "),M_e=a("code"),Grr=o("__init__()"),Orr=o(" (throws an error)."),Vrr=l(),Mt=a("div"),F(LL.$$.fragment),Xrr=l(),E_e=a("p"),zrr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Qrr=l(),kd=a("p"),Wrr=o(`Note:
Loading a model from its configuration file does `),C_e=a("strong"),Hrr=o("not"),Urr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nz=a("a"),Jrr=o("from_pretrained()"),Yrr=o(" to load the model weights."),Krr=l(),F(p6.$$.fragment),Zrr=l(),po=a("div"),F(xL.$$.fragment),etr=l(),w_e=a("p"),otr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),rtr=l(),Ha=a("p"),ttr=o("The model class to instantiate is selected based on the "),A_e=a("code"),atr=o("model_type"),ntr=o(` property of the config object (either
passed as an argument or loaded from `),y_e=a("code"),str=o("pretrained_model_name_or_path"),ltr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L_e=a("code"),itr=o("pretrained_model_name_or_path"),dtr=o(":"),ctr=l(),x_e=a("ul"),u6=a("li"),$_e=a("strong"),ftr=o("detr"),mtr=o(" \u2014 "),sz=a("a"),gtr=o("DetrForSegmentation"),htr=o(" (DETR model)"),ptr=l(),_6=a("p"),utr=o("The model is set in evaluation mode by default using "),k_e=a("code"),_tr=o("model.eval()"),btr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S_e=a("code"),vtr=o("model.train()"),Ftr=l(),F(b6.$$.fragment),Eqe=l(),Sd=a("h2"),v6=a("a"),R_e=a("span"),F($L.$$.fragment),Ttr=l(),B_e=a("span"),Mtr=o("AutoModelForSemanticSegmentation"),Cqe=l(),Uo=a("div"),F(kL.$$.fragment),Etr=l(),Rd=a("p"),Ctr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),lz=a("a"),wtr=o("from_pretrained()"),Atr=o(" class method or the "),iz=a("a"),ytr=o("from_config()"),Ltr=o(` class
method.`),xtr=l(),SL=a("p"),$tr=o("This class cannot be instantiated directly using "),P_e=a("code"),ktr=o("__init__()"),Str=o(" (throws an error)."),Rtr=l(),Et=a("div"),F(RL.$$.fragment),Btr=l(),I_e=a("p"),Ptr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Itr=l(),Bd=a("p"),qtr=o(`Note:
Loading a model from its configuration file does `),q_e=a("strong"),Ntr=o("not"),jtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dz=a("a"),Dtr=o("from_pretrained()"),Gtr=o(" to load the model weights."),Otr=l(),F(F6.$$.fragment),Vtr=l(),uo=a("div"),F(BL.$$.fragment),Xtr=l(),N_e=a("p"),ztr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Qtr=l(),Ua=a("p"),Wtr=o("The model class to instantiate is selected based on the "),j_e=a("code"),Htr=o("model_type"),Utr=o(` property of the config object (either
passed as an argument or loaded from `),D_e=a("code"),Jtr=o("pretrained_model_name_or_path"),Ytr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G_e=a("code"),Ktr=o("pretrained_model_name_or_path"),Ztr=o(":"),ear=l(),Ja=a("ul"),T6=a("li"),O_e=a("strong"),oar=o("beit"),rar=o(" \u2014 "),cz=a("a"),tar=o("BeitForSemanticSegmentation"),aar=o(" (BEiT model)"),nar=l(),M6=a("li"),V_e=a("strong"),sar=o("data2vec-vision"),lar=o(" \u2014 "),fz=a("a"),iar=o("Data2VecVisionForSemanticSegmentation"),dar=o(" (Data2VecVision model)"),car=l(),E6=a("li"),X_e=a("strong"),far=o("dpt"),mar=o(" \u2014 "),mz=a("a"),gar=o("DPTForSemanticSegmentation"),har=o(" (DPT model)"),par=l(),C6=a("li"),z_e=a("strong"),uar=o("segformer"),_ar=o(" \u2014 "),gz=a("a"),bar=o("SegformerForSemanticSegmentation"),Far=o(" (SegFormer model)"),Tar=l(),w6=a("p"),Mar=o("The model is set in evaluation mode by default using "),Q_e=a("code"),Ear=o("model.eval()"),Car=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W_e=a("code"),war=o("model.train()"),Aar=l(),F(A6.$$.fragment),wqe=l(),Pd=a("h2"),y6=a("a"),H_e=a("span"),F(PL.$$.fragment),yar=l(),U_e=a("span"),Lar=o("AutoModelForInstanceSegmentation"),Aqe=l(),Jo=a("div"),F(IL.$$.fragment),xar=l(),Id=a("p"),$ar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),hz=a("a"),kar=o("from_pretrained()"),Sar=o(" class method or the "),pz=a("a"),Rar=o("from_config()"),Bar=o(` class
method.`),Par=l(),qL=a("p"),Iar=o("This class cannot be instantiated directly using "),J_e=a("code"),qar=o("__init__()"),Nar=o(" (throws an error)."),jar=l(),Ct=a("div"),F(NL.$$.fragment),Dar=l(),Y_e=a("p"),Gar=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Oar=l(),qd=a("p"),Var=o(`Note:
Loading a model from its configuration file does `),K_e=a("strong"),Xar=o("not"),zar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uz=a("a"),Qar=o("from_pretrained()"),War=o(" to load the model weights."),Har=l(),F(L6.$$.fragment),Uar=l(),_o=a("div"),F(jL.$$.fragment),Jar=l(),Z_e=a("p"),Yar=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Kar=l(),Ya=a("p"),Zar=o("The model class to instantiate is selected based on the "),e0e=a("code"),enr=o("model_type"),onr=o(` property of the config object (either
passed as an argument or loaded from `),o0e=a("code"),rnr=o("pretrained_model_name_or_path"),tnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=a("code"),anr=o("pretrained_model_name_or_path"),nnr=o(":"),snr=l(),t0e=a("ul"),x6=a("li"),a0e=a("strong"),lnr=o("maskformer"),inr=o(" \u2014 "),_z=a("a"),dnr=o("MaskFormerForInstanceSegmentation"),cnr=o(" (MaskFormer model)"),fnr=l(),$6=a("p"),mnr=o("The model is set in evaluation mode by default using "),n0e=a("code"),gnr=o("model.eval()"),hnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s0e=a("code"),pnr=o("model.train()"),unr=l(),F(k6.$$.fragment),yqe=l(),Nd=a("h2"),S6=a("a"),l0e=a("span"),F(DL.$$.fragment),_nr=l(),i0e=a("span"),bnr=o("TFAutoModel"),Lqe=l(),Yo=a("div"),F(GL.$$.fragment),vnr=l(),jd=a("p"),Fnr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),bz=a("a"),Tnr=o("from_pretrained()"),Mnr=o(" class method or the "),vz=a("a"),Enr=o("from_config()"),Cnr=o(` class
method.`),wnr=l(),OL=a("p"),Anr=o("This class cannot be instantiated directly using "),d0e=a("code"),ynr=o("__init__()"),Lnr=o(" (throws an error)."),xnr=l(),wt=a("div"),F(VL.$$.fragment),$nr=l(),c0e=a("p"),knr=o("Instantiates one of the base model classes of the library from a configuration."),Snr=l(),Dd=a("p"),Rnr=o(`Note:
Loading a model from its configuration file does `),f0e=a("strong"),Bnr=o("not"),Pnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),Inr=o("from_pretrained()"),qnr=o(" to load the model weights."),Nnr=l(),F(R6.$$.fragment),jnr=l(),wr=a("div"),F(XL.$$.fragment),Dnr=l(),m0e=a("p"),Gnr=o("Instantiate one of the base model classes of the library from a pretrained model."),Onr=l(),Ka=a("p"),Vnr=o("The model class to instantiate is selected based on the "),g0e=a("code"),Xnr=o("model_type"),znr=o(` property of the config object (either
passed as an argument or loaded from `),h0e=a("code"),Qnr=o("pretrained_model_name_or_path"),Wnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=a("code"),Hnr=o("pretrained_model_name_or_path"),Unr=o(":"),Jnr=l(),j=a("ul"),B6=a("li"),u0e=a("strong"),Ynr=o("albert"),Knr=o(" \u2014 "),Tz=a("a"),Znr=o("TFAlbertModel"),esr=o(" (ALBERT model)"),osr=l(),P6=a("li"),_0e=a("strong"),rsr=o("bart"),tsr=o(" \u2014 "),Mz=a("a"),asr=o("TFBartModel"),nsr=o(" (BART model)"),ssr=l(),I6=a("li"),b0e=a("strong"),lsr=o("bert"),isr=o(" \u2014 "),Ez=a("a"),dsr=o("TFBertModel"),csr=o(" (BERT model)"),fsr=l(),q6=a("li"),v0e=a("strong"),msr=o("blenderbot"),gsr=o(" \u2014 "),Cz=a("a"),hsr=o("TFBlenderbotModel"),psr=o(" (Blenderbot model)"),usr=l(),N6=a("li"),F0e=a("strong"),_sr=o("blenderbot-small"),bsr=o(" \u2014 "),wz=a("a"),vsr=o("TFBlenderbotSmallModel"),Fsr=o(" (BlenderbotSmall model)"),Tsr=l(),j6=a("li"),T0e=a("strong"),Msr=o("camembert"),Esr=o(" \u2014 "),Az=a("a"),Csr=o("TFCamembertModel"),wsr=o(" (CamemBERT model)"),Asr=l(),D6=a("li"),M0e=a("strong"),ysr=o("clip"),Lsr=o(" \u2014 "),yz=a("a"),xsr=o("TFCLIPModel"),$sr=o(" (CLIP model)"),ksr=l(),G6=a("li"),E0e=a("strong"),Ssr=o("convbert"),Rsr=o(" \u2014 "),Lz=a("a"),Bsr=o("TFConvBertModel"),Psr=o(" (ConvBERT model)"),Isr=l(),O6=a("li"),C0e=a("strong"),qsr=o("convnext"),Nsr=o(" \u2014 "),xz=a("a"),jsr=o("TFConvNextModel"),Dsr=o(" (ConvNext model)"),Gsr=l(),V6=a("li"),w0e=a("strong"),Osr=o("ctrl"),Vsr=o(" \u2014 "),$z=a("a"),Xsr=o("TFCTRLModel"),zsr=o(" (CTRL model)"),Qsr=l(),X6=a("li"),A0e=a("strong"),Wsr=o("data2vec-vision"),Hsr=o(" \u2014 "),kz=a("a"),Usr=o("TFData2VecVisionModel"),Jsr=o(" (Data2VecVision model)"),Ysr=l(),z6=a("li"),y0e=a("strong"),Ksr=o("deberta"),Zsr=o(" \u2014 "),Sz=a("a"),elr=o("TFDebertaModel"),olr=o(" (DeBERTa model)"),rlr=l(),Q6=a("li"),L0e=a("strong"),tlr=o("deberta-v2"),alr=o(" \u2014 "),Rz=a("a"),nlr=o("TFDebertaV2Model"),slr=o(" (DeBERTa-v2 model)"),llr=l(),W6=a("li"),x0e=a("strong"),ilr=o("distilbert"),dlr=o(" \u2014 "),Bz=a("a"),clr=o("TFDistilBertModel"),flr=o(" (DistilBERT model)"),mlr=l(),H6=a("li"),$0e=a("strong"),glr=o("dpr"),hlr=o(" \u2014 "),Pz=a("a"),plr=o("TFDPRQuestionEncoder"),ulr=o(" (DPR model)"),_lr=l(),U6=a("li"),k0e=a("strong"),blr=o("electra"),vlr=o(" \u2014 "),Iz=a("a"),Flr=o("TFElectraModel"),Tlr=o(" (ELECTRA model)"),Mlr=l(),J6=a("li"),S0e=a("strong"),Elr=o("flaubert"),Clr=o(" \u2014 "),qz=a("a"),wlr=o("TFFlaubertModel"),Alr=o(" (FlauBERT model)"),ylr=l(),Ps=a("li"),R0e=a("strong"),Llr=o("funnel"),xlr=o(" \u2014 "),Nz=a("a"),$lr=o("TFFunnelModel"),klr=o(" or "),jz=a("a"),Slr=o("TFFunnelBaseModel"),Rlr=o(" (Funnel Transformer model)"),Blr=l(),Y6=a("li"),B0e=a("strong"),Plr=o("gpt2"),Ilr=o(" \u2014 "),Dz=a("a"),qlr=o("TFGPT2Model"),Nlr=o(" (OpenAI GPT-2 model)"),jlr=l(),K6=a("li"),P0e=a("strong"),Dlr=o("gptj"),Glr=o(" \u2014 "),Gz=a("a"),Olr=o("TFGPTJModel"),Vlr=o(" (GPT-J model)"),Xlr=l(),Z6=a("li"),I0e=a("strong"),zlr=o("hubert"),Qlr=o(" \u2014 "),Oz=a("a"),Wlr=o("TFHubertModel"),Hlr=o(" (Hubert model)"),Ulr=l(),eT=a("li"),q0e=a("strong"),Jlr=o("layoutlm"),Ylr=o(" \u2014 "),Vz=a("a"),Klr=o("TFLayoutLMModel"),Zlr=o(" (LayoutLM model)"),eir=l(),oT=a("li"),N0e=a("strong"),oir=o("led"),rir=o(" \u2014 "),Xz=a("a"),tir=o("TFLEDModel"),air=o(" (LED model)"),nir=l(),rT=a("li"),j0e=a("strong"),sir=o("longformer"),lir=o(" \u2014 "),zz=a("a"),iir=o("TFLongformerModel"),dir=o(" (Longformer model)"),cir=l(),tT=a("li"),D0e=a("strong"),fir=o("lxmert"),mir=o(" \u2014 "),Qz=a("a"),gir=o("TFLxmertModel"),hir=o(" (LXMERT model)"),pir=l(),aT=a("li"),G0e=a("strong"),uir=o("marian"),_ir=o(" \u2014 "),Wz=a("a"),bir=o("TFMarianModel"),vir=o(" (Marian model)"),Fir=l(),nT=a("li"),O0e=a("strong"),Tir=o("mbart"),Mir=o(" \u2014 "),Hz=a("a"),Eir=o("TFMBartModel"),Cir=o(" (mBART model)"),wir=l(),sT=a("li"),V0e=a("strong"),Air=o("mobilebert"),yir=o(" \u2014 "),Uz=a("a"),Lir=o("TFMobileBertModel"),xir=o(" (MobileBERT model)"),$ir=l(),lT=a("li"),X0e=a("strong"),kir=o("mpnet"),Sir=o(" \u2014 "),Jz=a("a"),Rir=o("TFMPNetModel"),Bir=o(" (MPNet model)"),Pir=l(),iT=a("li"),z0e=a("strong"),Iir=o("mt5"),qir=o(" \u2014 "),Yz=a("a"),Nir=o("TFMT5Model"),jir=o(" (mT5 model)"),Dir=l(),dT=a("li"),Q0e=a("strong"),Gir=o("openai-gpt"),Oir=o(" \u2014 "),Kz=a("a"),Vir=o("TFOpenAIGPTModel"),Xir=o(" (OpenAI GPT model)"),zir=l(),cT=a("li"),W0e=a("strong"),Qir=o("pegasus"),Wir=o(" \u2014 "),Zz=a("a"),Hir=o("TFPegasusModel"),Uir=o(" (Pegasus model)"),Jir=l(),fT=a("li"),H0e=a("strong"),Yir=o("rembert"),Kir=o(" \u2014 "),eQ=a("a"),Zir=o("TFRemBertModel"),edr=o(" (RemBERT model)"),odr=l(),mT=a("li"),U0e=a("strong"),rdr=o("roberta"),tdr=o(" \u2014 "),oQ=a("a"),adr=o("TFRobertaModel"),ndr=o(" (RoBERTa model)"),sdr=l(),gT=a("li"),J0e=a("strong"),ldr=o("roformer"),idr=o(" \u2014 "),rQ=a("a"),ddr=o("TFRoFormerModel"),cdr=o(" (RoFormer model)"),fdr=l(),hT=a("li"),Y0e=a("strong"),mdr=o("speech_to_text"),gdr=o(" \u2014 "),tQ=a("a"),hdr=o("TFSpeech2TextModel"),pdr=o(" (Speech2Text model)"),udr=l(),pT=a("li"),K0e=a("strong"),_dr=o("t5"),bdr=o(" \u2014 "),aQ=a("a"),vdr=o("TFT5Model"),Fdr=o(" (T5 model)"),Tdr=l(),uT=a("li"),Z0e=a("strong"),Mdr=o("tapas"),Edr=o(" \u2014 "),nQ=a("a"),Cdr=o("TFTapasModel"),wdr=o(" (TAPAS model)"),Adr=l(),_T=a("li"),e1e=a("strong"),ydr=o("transfo-xl"),Ldr=o(" \u2014 "),sQ=a("a"),xdr=o("TFTransfoXLModel"),$dr=o(" (Transformer-XL model)"),kdr=l(),bT=a("li"),o1e=a("strong"),Sdr=o("vit"),Rdr=o(" \u2014 "),lQ=a("a"),Bdr=o("TFViTModel"),Pdr=o(" (ViT model)"),Idr=l(),vT=a("li"),r1e=a("strong"),qdr=o("vit_mae"),Ndr=o(" \u2014 "),iQ=a("a"),jdr=o("TFViTMAEModel"),Ddr=o(" (ViTMAE model)"),Gdr=l(),FT=a("li"),t1e=a("strong"),Odr=o("wav2vec2"),Vdr=o(" \u2014 "),dQ=a("a"),Xdr=o("TFWav2Vec2Model"),zdr=o(" (Wav2Vec2 model)"),Qdr=l(),TT=a("li"),a1e=a("strong"),Wdr=o("xlm"),Hdr=o(" \u2014 "),cQ=a("a"),Udr=o("TFXLMModel"),Jdr=o(" (XLM model)"),Ydr=l(),MT=a("li"),n1e=a("strong"),Kdr=o("xlm-roberta"),Zdr=o(" \u2014 "),fQ=a("a"),ecr=o("TFXLMRobertaModel"),ocr=o(" (XLM-RoBERTa model)"),rcr=l(),ET=a("li"),s1e=a("strong"),tcr=o("xlnet"),acr=o(" \u2014 "),mQ=a("a"),ncr=o("TFXLNetModel"),scr=o(" (XLNet model)"),lcr=l(),F(CT.$$.fragment),xqe=l(),Gd=a("h2"),wT=a("a"),l1e=a("span"),F(zL.$$.fragment),icr=l(),i1e=a("span"),dcr=o("TFAutoModelForPreTraining"),$qe=l(),Ko=a("div"),F(QL.$$.fragment),ccr=l(),Od=a("p"),fcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gQ=a("a"),mcr=o("from_pretrained()"),gcr=o(" class method or the "),hQ=a("a"),hcr=o("from_config()"),pcr=o(` class
method.`),ucr=l(),WL=a("p"),_cr=o("This class cannot be instantiated directly using "),d1e=a("code"),bcr=o("__init__()"),vcr=o(" (throws an error)."),Fcr=l(),At=a("div"),F(HL.$$.fragment),Tcr=l(),c1e=a("p"),Mcr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Ecr=l(),Vd=a("p"),Ccr=o(`Note:
Loading a model from its configuration file does `),f1e=a("strong"),wcr=o("not"),Acr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pQ=a("a"),ycr=o("from_pretrained()"),Lcr=o(" to load the model weights."),xcr=l(),F(AT.$$.fragment),$cr=l(),Ar=a("div"),F(UL.$$.fragment),kcr=l(),m1e=a("p"),Scr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Rcr=l(),Za=a("p"),Bcr=o("The model class to instantiate is selected based on the "),g1e=a("code"),Pcr=o("model_type"),Icr=o(` property of the config object (either
passed as an argument or loaded from `),h1e=a("code"),qcr=o("pretrained_model_name_or_path"),Ncr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p1e=a("code"),jcr=o("pretrained_model_name_or_path"),Dcr=o(":"),Gcr=l(),se=a("ul"),yT=a("li"),u1e=a("strong"),Ocr=o("albert"),Vcr=o(" \u2014 "),uQ=a("a"),Xcr=o("TFAlbertForPreTraining"),zcr=o(" (ALBERT model)"),Qcr=l(),LT=a("li"),_1e=a("strong"),Wcr=o("bart"),Hcr=o(" \u2014 "),_Q=a("a"),Ucr=o("TFBartForConditionalGeneration"),Jcr=o(" (BART model)"),Ycr=l(),xT=a("li"),b1e=a("strong"),Kcr=o("bert"),Zcr=o(" \u2014 "),bQ=a("a"),efr=o("TFBertForPreTraining"),ofr=o(" (BERT model)"),rfr=l(),$T=a("li"),v1e=a("strong"),tfr=o("camembert"),afr=o(" \u2014 "),vQ=a("a"),nfr=o("TFCamembertForMaskedLM"),sfr=o(" (CamemBERT model)"),lfr=l(),kT=a("li"),F1e=a("strong"),ifr=o("ctrl"),dfr=o(" \u2014 "),FQ=a("a"),cfr=o("TFCTRLLMHeadModel"),ffr=o(" (CTRL model)"),mfr=l(),ST=a("li"),T1e=a("strong"),gfr=o("distilbert"),hfr=o(" \u2014 "),TQ=a("a"),pfr=o("TFDistilBertForMaskedLM"),ufr=o(" (DistilBERT model)"),_fr=l(),RT=a("li"),M1e=a("strong"),bfr=o("electra"),vfr=o(" \u2014 "),MQ=a("a"),Ffr=o("TFElectraForPreTraining"),Tfr=o(" (ELECTRA model)"),Mfr=l(),BT=a("li"),E1e=a("strong"),Efr=o("flaubert"),Cfr=o(" \u2014 "),EQ=a("a"),wfr=o("TFFlaubertWithLMHeadModel"),Afr=o(" (FlauBERT model)"),yfr=l(),PT=a("li"),C1e=a("strong"),Lfr=o("funnel"),xfr=o(" \u2014 "),CQ=a("a"),$fr=o("TFFunnelForPreTraining"),kfr=o(" (Funnel Transformer model)"),Sfr=l(),IT=a("li"),w1e=a("strong"),Rfr=o("gpt2"),Bfr=o(" \u2014 "),wQ=a("a"),Pfr=o("TFGPT2LMHeadModel"),Ifr=o(" (OpenAI GPT-2 model)"),qfr=l(),qT=a("li"),A1e=a("strong"),Nfr=o("layoutlm"),jfr=o(" \u2014 "),AQ=a("a"),Dfr=o("TFLayoutLMForMaskedLM"),Gfr=o(" (LayoutLM model)"),Ofr=l(),NT=a("li"),y1e=a("strong"),Vfr=o("lxmert"),Xfr=o(" \u2014 "),yQ=a("a"),zfr=o("TFLxmertForPreTraining"),Qfr=o(" (LXMERT model)"),Wfr=l(),jT=a("li"),L1e=a("strong"),Hfr=o("mobilebert"),Ufr=o(" \u2014 "),LQ=a("a"),Jfr=o("TFMobileBertForPreTraining"),Yfr=o(" (MobileBERT model)"),Kfr=l(),DT=a("li"),x1e=a("strong"),Zfr=o("mpnet"),emr=o(" \u2014 "),xQ=a("a"),omr=o("TFMPNetForMaskedLM"),rmr=o(" (MPNet model)"),tmr=l(),GT=a("li"),$1e=a("strong"),amr=o("openai-gpt"),nmr=o(" \u2014 "),$Q=a("a"),smr=o("TFOpenAIGPTLMHeadModel"),lmr=o(" (OpenAI GPT model)"),imr=l(),OT=a("li"),k1e=a("strong"),dmr=o("roberta"),cmr=o(" \u2014 "),kQ=a("a"),fmr=o("TFRobertaForMaskedLM"),mmr=o(" (RoBERTa model)"),gmr=l(),VT=a("li"),S1e=a("strong"),hmr=o("t5"),pmr=o(" \u2014 "),SQ=a("a"),umr=o("TFT5ForConditionalGeneration"),_mr=o(" (T5 model)"),bmr=l(),XT=a("li"),R1e=a("strong"),vmr=o("tapas"),Fmr=o(" \u2014 "),RQ=a("a"),Tmr=o("TFTapasForMaskedLM"),Mmr=o(" (TAPAS model)"),Emr=l(),zT=a("li"),B1e=a("strong"),Cmr=o("transfo-xl"),wmr=o(" \u2014 "),BQ=a("a"),Amr=o("TFTransfoXLLMHeadModel"),ymr=o(" (Transformer-XL model)"),Lmr=l(),QT=a("li"),P1e=a("strong"),xmr=o("vit_mae"),$mr=o(" \u2014 "),PQ=a("a"),kmr=o("TFViTMAEForPreTraining"),Smr=o(" (ViTMAE model)"),Rmr=l(),WT=a("li"),I1e=a("strong"),Bmr=o("xlm"),Pmr=o(" \u2014 "),IQ=a("a"),Imr=o("TFXLMWithLMHeadModel"),qmr=o(" (XLM model)"),Nmr=l(),HT=a("li"),q1e=a("strong"),jmr=o("xlm-roberta"),Dmr=o(" \u2014 "),qQ=a("a"),Gmr=o("TFXLMRobertaForMaskedLM"),Omr=o(" (XLM-RoBERTa model)"),Vmr=l(),UT=a("li"),N1e=a("strong"),Xmr=o("xlnet"),zmr=o(" \u2014 "),NQ=a("a"),Qmr=o("TFXLNetLMHeadModel"),Wmr=o(" (XLNet model)"),Hmr=l(),F(JT.$$.fragment),kqe=l(),Xd=a("h2"),YT=a("a"),j1e=a("span"),F(JL.$$.fragment),Umr=l(),D1e=a("span"),Jmr=o("TFAutoModelForCausalLM"),Sqe=l(),Zo=a("div"),F(YL.$$.fragment),Ymr=l(),zd=a("p"),Kmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jQ=a("a"),Zmr=o("from_pretrained()"),egr=o(" class method or the "),DQ=a("a"),ogr=o("from_config()"),rgr=o(` class
method.`),tgr=l(),KL=a("p"),agr=o("This class cannot be instantiated directly using "),G1e=a("code"),ngr=o("__init__()"),sgr=o(" (throws an error)."),lgr=l(),yt=a("div"),F(ZL.$$.fragment),igr=l(),O1e=a("p"),dgr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),cgr=l(),Qd=a("p"),fgr=o(`Note:
Loading a model from its configuration file does `),V1e=a("strong"),mgr=o("not"),ggr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GQ=a("a"),hgr=o("from_pretrained()"),pgr=o(" to load the model weights."),ugr=l(),F(KT.$$.fragment),_gr=l(),yr=a("div"),F(e8.$$.fragment),bgr=l(),X1e=a("p"),vgr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Fgr=l(),en=a("p"),Tgr=o("The model class to instantiate is selected based on the "),z1e=a("code"),Mgr=o("model_type"),Egr=o(` property of the config object (either
passed as an argument or loaded from `),Q1e=a("code"),Cgr=o("pretrained_model_name_or_path"),wgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W1e=a("code"),Agr=o("pretrained_model_name_or_path"),ygr=o(":"),Lgr=l(),Te=a("ul"),ZT=a("li"),H1e=a("strong"),xgr=o("bert"),$gr=o(" \u2014 "),OQ=a("a"),kgr=o("TFBertLMHeadModel"),Sgr=o(" (BERT model)"),Rgr=l(),e7=a("li"),U1e=a("strong"),Bgr=o("camembert"),Pgr=o(" \u2014 "),VQ=a("a"),Igr=o("TFCamembertForCausalLM"),qgr=o(" (CamemBERT model)"),Ngr=l(),o7=a("li"),J1e=a("strong"),jgr=o("ctrl"),Dgr=o(" \u2014 "),XQ=a("a"),Ggr=o("TFCTRLLMHeadModel"),Ogr=o(" (CTRL model)"),Vgr=l(),r7=a("li"),Y1e=a("strong"),Xgr=o("gpt2"),zgr=o(" \u2014 "),zQ=a("a"),Qgr=o("TFGPT2LMHeadModel"),Wgr=o(" (OpenAI GPT-2 model)"),Hgr=l(),t7=a("li"),K1e=a("strong"),Ugr=o("gptj"),Jgr=o(" \u2014 "),QQ=a("a"),Ygr=o("TFGPTJForCausalLM"),Kgr=o(" (GPT-J model)"),Zgr=l(),a7=a("li"),Z1e=a("strong"),ehr=o("openai-gpt"),ohr=o(" \u2014 "),WQ=a("a"),rhr=o("TFOpenAIGPTLMHeadModel"),thr=o(" (OpenAI GPT model)"),ahr=l(),n7=a("li"),ebe=a("strong"),nhr=o("rembert"),shr=o(" \u2014 "),HQ=a("a"),lhr=o("TFRemBertForCausalLM"),ihr=o(" (RemBERT model)"),dhr=l(),s7=a("li"),obe=a("strong"),chr=o("roberta"),fhr=o(" \u2014 "),UQ=a("a"),mhr=o("TFRobertaForCausalLM"),ghr=o(" (RoBERTa model)"),hhr=l(),l7=a("li"),rbe=a("strong"),phr=o("roformer"),uhr=o(" \u2014 "),JQ=a("a"),_hr=o("TFRoFormerForCausalLM"),bhr=o(" (RoFormer model)"),vhr=l(),i7=a("li"),tbe=a("strong"),Fhr=o("transfo-xl"),Thr=o(" \u2014 "),YQ=a("a"),Mhr=o("TFTransfoXLLMHeadModel"),Ehr=o(" (Transformer-XL model)"),Chr=l(),d7=a("li"),abe=a("strong"),whr=o("xlm"),Ahr=o(" \u2014 "),KQ=a("a"),yhr=o("TFXLMWithLMHeadModel"),Lhr=o(" (XLM model)"),xhr=l(),c7=a("li"),nbe=a("strong"),$hr=o("xlnet"),khr=o(" \u2014 "),ZQ=a("a"),Shr=o("TFXLNetLMHeadModel"),Rhr=o(" (XLNet model)"),Bhr=l(),F(f7.$$.fragment),Rqe=l(),Wd=a("h2"),m7=a("a"),sbe=a("span"),F(o8.$$.fragment),Phr=l(),lbe=a("span"),Ihr=o("TFAutoModelForImageClassification"),Bqe=l(),er=a("div"),F(r8.$$.fragment),qhr=l(),Hd=a("p"),Nhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eW=a("a"),jhr=o("from_pretrained()"),Dhr=o(" class method or the "),oW=a("a"),Ghr=o("from_config()"),Ohr=o(` class
method.`),Vhr=l(),t8=a("p"),Xhr=o("This class cannot be instantiated directly using "),ibe=a("code"),zhr=o("__init__()"),Qhr=o(" (throws an error)."),Whr=l(),Lt=a("div"),F(a8.$$.fragment),Hhr=l(),dbe=a("p"),Uhr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Jhr=l(),Ud=a("p"),Yhr=o(`Note:
Loading a model from its configuration file does `),cbe=a("strong"),Khr=o("not"),Zhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=a("a"),epr=o("from_pretrained()"),opr=o(" to load the model weights."),rpr=l(),F(g7.$$.fragment),tpr=l(),Lr=a("div"),F(n8.$$.fragment),apr=l(),fbe=a("p"),npr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),spr=l(),on=a("p"),lpr=o("The model class to instantiate is selected based on the "),mbe=a("code"),ipr=o("model_type"),dpr=o(` property of the config object (either
passed as an argument or loaded from `),gbe=a("code"),cpr=o("pretrained_model_name_or_path"),fpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=a("code"),mpr=o("pretrained_model_name_or_path"),gpr=o(":"),hpr=l(),Jd=a("ul"),h7=a("li"),pbe=a("strong"),ppr=o("convnext"),upr=o(" \u2014 "),tW=a("a"),_pr=o("TFConvNextForImageClassification"),bpr=o(" (ConvNext model)"),vpr=l(),p7=a("li"),ube=a("strong"),Fpr=o("data2vec-vision"),Tpr=o(" \u2014 "),aW=a("a"),Mpr=o("TFData2VecVisionForImageClassification"),Epr=o(" (Data2VecVision model)"),Cpr=l(),u7=a("li"),_be=a("strong"),wpr=o("vit"),Apr=o(" \u2014 "),nW=a("a"),ypr=o("TFViTForImageClassification"),Lpr=o(" (ViT model)"),xpr=l(),F(_7.$$.fragment),Pqe=l(),Yd=a("h2"),b7=a("a"),bbe=a("span"),F(s8.$$.fragment),$pr=l(),vbe=a("span"),kpr=o("TFAutoModelForMaskedLM"),Iqe=l(),or=a("div"),F(l8.$$.fragment),Spr=l(),Kd=a("p"),Rpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sW=a("a"),Bpr=o("from_pretrained()"),Ppr=o(" class method or the "),lW=a("a"),Ipr=o("from_config()"),qpr=o(` class
method.`),Npr=l(),i8=a("p"),jpr=o("This class cannot be instantiated directly using "),Fbe=a("code"),Dpr=o("__init__()"),Gpr=o(" (throws an error)."),Opr=l(),xt=a("div"),F(d8.$$.fragment),Vpr=l(),Tbe=a("p"),Xpr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),zpr=l(),Zd=a("p"),Qpr=o(`Note:
Loading a model from its configuration file does `),Mbe=a("strong"),Wpr=o("not"),Hpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=a("a"),Upr=o("from_pretrained()"),Jpr=o(" to load the model weights."),Ypr=l(),F(v7.$$.fragment),Kpr=l(),xr=a("div"),F(c8.$$.fragment),Zpr=l(),Ebe=a("p"),eur=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),our=l(),rn=a("p"),rur=o("The model class to instantiate is selected based on the "),Cbe=a("code"),tur=o("model_type"),aur=o(` property of the config object (either
passed as an argument or loaded from `),wbe=a("code"),nur=o("pretrained_model_name_or_path"),sur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Abe=a("code"),lur=o("pretrained_model_name_or_path"),iur=o(":"),dur=l(),ie=a("ul"),F7=a("li"),ybe=a("strong"),cur=o("albert"),fur=o(" \u2014 "),dW=a("a"),mur=o("TFAlbertForMaskedLM"),gur=o(" (ALBERT model)"),hur=l(),T7=a("li"),Lbe=a("strong"),pur=o("bert"),uur=o(" \u2014 "),cW=a("a"),_ur=o("TFBertForMaskedLM"),bur=o(" (BERT model)"),vur=l(),M7=a("li"),xbe=a("strong"),Fur=o("camembert"),Tur=o(" \u2014 "),fW=a("a"),Mur=o("TFCamembertForMaskedLM"),Eur=o(" (CamemBERT model)"),Cur=l(),E7=a("li"),$be=a("strong"),wur=o("convbert"),Aur=o(" \u2014 "),mW=a("a"),yur=o("TFConvBertForMaskedLM"),Lur=o(" (ConvBERT model)"),xur=l(),C7=a("li"),kbe=a("strong"),$ur=o("deberta"),kur=o(" \u2014 "),gW=a("a"),Sur=o("TFDebertaForMaskedLM"),Rur=o(" (DeBERTa model)"),Bur=l(),w7=a("li"),Sbe=a("strong"),Pur=o("deberta-v2"),Iur=o(" \u2014 "),hW=a("a"),qur=o("TFDebertaV2ForMaskedLM"),Nur=o(" (DeBERTa-v2 model)"),jur=l(),A7=a("li"),Rbe=a("strong"),Dur=o("distilbert"),Gur=o(" \u2014 "),pW=a("a"),Our=o("TFDistilBertForMaskedLM"),Vur=o(" (DistilBERT model)"),Xur=l(),y7=a("li"),Bbe=a("strong"),zur=o("electra"),Qur=o(" \u2014 "),uW=a("a"),Wur=o("TFElectraForMaskedLM"),Hur=o(" (ELECTRA model)"),Uur=l(),L7=a("li"),Pbe=a("strong"),Jur=o("flaubert"),Yur=o(" \u2014 "),_W=a("a"),Kur=o("TFFlaubertWithLMHeadModel"),Zur=o(" (FlauBERT model)"),e_r=l(),x7=a("li"),Ibe=a("strong"),o_r=o("funnel"),r_r=o(" \u2014 "),bW=a("a"),t_r=o("TFFunnelForMaskedLM"),a_r=o(" (Funnel Transformer model)"),n_r=l(),$7=a("li"),qbe=a("strong"),s_r=o("layoutlm"),l_r=o(" \u2014 "),vW=a("a"),i_r=o("TFLayoutLMForMaskedLM"),d_r=o(" (LayoutLM model)"),c_r=l(),k7=a("li"),Nbe=a("strong"),f_r=o("longformer"),m_r=o(" \u2014 "),FW=a("a"),g_r=o("TFLongformerForMaskedLM"),h_r=o(" (Longformer model)"),p_r=l(),S7=a("li"),jbe=a("strong"),u_r=o("mobilebert"),__r=o(" \u2014 "),TW=a("a"),b_r=o("TFMobileBertForMaskedLM"),v_r=o(" (MobileBERT model)"),F_r=l(),R7=a("li"),Dbe=a("strong"),T_r=o("mpnet"),M_r=o(" \u2014 "),MW=a("a"),E_r=o("TFMPNetForMaskedLM"),C_r=o(" (MPNet model)"),w_r=l(),B7=a("li"),Gbe=a("strong"),A_r=o("rembert"),y_r=o(" \u2014 "),EW=a("a"),L_r=o("TFRemBertForMaskedLM"),x_r=o(" (RemBERT model)"),$_r=l(),P7=a("li"),Obe=a("strong"),k_r=o("roberta"),S_r=o(" \u2014 "),CW=a("a"),R_r=o("TFRobertaForMaskedLM"),B_r=o(" (RoBERTa model)"),P_r=l(),I7=a("li"),Vbe=a("strong"),I_r=o("roformer"),q_r=o(" \u2014 "),wW=a("a"),N_r=o("TFRoFormerForMaskedLM"),j_r=o(" (RoFormer model)"),D_r=l(),q7=a("li"),Xbe=a("strong"),G_r=o("tapas"),O_r=o(" \u2014 "),AW=a("a"),V_r=o("TFTapasForMaskedLM"),X_r=o(" (TAPAS model)"),z_r=l(),N7=a("li"),zbe=a("strong"),Q_r=o("xlm"),W_r=o(" \u2014 "),yW=a("a"),H_r=o("TFXLMWithLMHeadModel"),U_r=o(" (XLM model)"),J_r=l(),j7=a("li"),Qbe=a("strong"),Y_r=o("xlm-roberta"),K_r=o(" \u2014 "),LW=a("a"),Z_r=o("TFXLMRobertaForMaskedLM"),e0r=o(" (XLM-RoBERTa model)"),o0r=l(),F(D7.$$.fragment),qqe=l(),ec=a("h2"),G7=a("a"),Wbe=a("span"),F(f8.$$.fragment),r0r=l(),Hbe=a("span"),t0r=o("TFAutoModelForSeq2SeqLM"),Nqe=l(),rr=a("div"),F(m8.$$.fragment),a0r=l(),oc=a("p"),n0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),xW=a("a"),s0r=o("from_pretrained()"),l0r=o(" class method or the "),$W=a("a"),i0r=o("from_config()"),d0r=o(` class
method.`),c0r=l(),g8=a("p"),f0r=o("This class cannot be instantiated directly using "),Ube=a("code"),m0r=o("__init__()"),g0r=o(" (throws an error)."),h0r=l(),$t=a("div"),F(h8.$$.fragment),p0r=l(),Jbe=a("p"),u0r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_0r=l(),rc=a("p"),b0r=o(`Note:
Loading a model from its configuration file does `),Ybe=a("strong"),v0r=o("not"),F0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kW=a("a"),T0r=o("from_pretrained()"),M0r=o(" to load the model weights."),E0r=l(),F(O7.$$.fragment),C0r=l(),$r=a("div"),F(p8.$$.fragment),w0r=l(),Kbe=a("p"),A0r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),y0r=l(),tn=a("p"),L0r=o("The model class to instantiate is selected based on the "),Zbe=a("code"),x0r=o("model_type"),$0r=o(` property of the config object (either
passed as an argument or loaded from `),e2e=a("code"),k0r=o("pretrained_model_name_or_path"),S0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=a("code"),R0r=o("pretrained_model_name_or_path"),B0r=o(":"),P0r=l(),ye=a("ul"),V7=a("li"),r2e=a("strong"),I0r=o("bart"),q0r=o(" \u2014 "),SW=a("a"),N0r=o("TFBartForConditionalGeneration"),j0r=o(" (BART model)"),D0r=l(),X7=a("li"),t2e=a("strong"),G0r=o("blenderbot"),O0r=o(" \u2014 "),RW=a("a"),V0r=o("TFBlenderbotForConditionalGeneration"),X0r=o(" (Blenderbot model)"),z0r=l(),z7=a("li"),a2e=a("strong"),Q0r=o("blenderbot-small"),W0r=o(" \u2014 "),BW=a("a"),H0r=o("TFBlenderbotSmallForConditionalGeneration"),U0r=o(" (BlenderbotSmall model)"),J0r=l(),Q7=a("li"),n2e=a("strong"),Y0r=o("encoder-decoder"),K0r=o(" \u2014 "),PW=a("a"),Z0r=o("TFEncoderDecoderModel"),e1r=o(" (Encoder decoder model)"),o1r=l(),W7=a("li"),s2e=a("strong"),r1r=o("led"),t1r=o(" \u2014 "),IW=a("a"),a1r=o("TFLEDForConditionalGeneration"),n1r=o(" (LED model)"),s1r=l(),H7=a("li"),l2e=a("strong"),l1r=o("marian"),i1r=o(" \u2014 "),qW=a("a"),d1r=o("TFMarianMTModel"),c1r=o(" (Marian model)"),f1r=l(),U7=a("li"),i2e=a("strong"),m1r=o("mbart"),g1r=o(" \u2014 "),NW=a("a"),h1r=o("TFMBartForConditionalGeneration"),p1r=o(" (mBART model)"),u1r=l(),J7=a("li"),d2e=a("strong"),_1r=o("mt5"),b1r=o(" \u2014 "),jW=a("a"),v1r=o("TFMT5ForConditionalGeneration"),F1r=o(" (mT5 model)"),T1r=l(),Y7=a("li"),c2e=a("strong"),M1r=o("pegasus"),E1r=o(" \u2014 "),DW=a("a"),C1r=o("TFPegasusForConditionalGeneration"),w1r=o(" (Pegasus model)"),A1r=l(),K7=a("li"),f2e=a("strong"),y1r=o("t5"),L1r=o(" \u2014 "),GW=a("a"),x1r=o("TFT5ForConditionalGeneration"),$1r=o(" (T5 model)"),k1r=l(),F(Z7.$$.fragment),jqe=l(),tc=a("h2"),eM=a("a"),m2e=a("span"),F(u8.$$.fragment),S1r=l(),g2e=a("span"),R1r=o("TFAutoModelForSequenceClassification"),Dqe=l(),tr=a("div"),F(_8.$$.fragment),B1r=l(),ac=a("p"),P1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),OW=a("a"),I1r=o("from_pretrained()"),q1r=o(" class method or the "),VW=a("a"),N1r=o("from_config()"),j1r=o(` class
method.`),D1r=l(),b8=a("p"),G1r=o("This class cannot be instantiated directly using "),h2e=a("code"),O1r=o("__init__()"),V1r=o(" (throws an error)."),X1r=l(),kt=a("div"),F(v8.$$.fragment),z1r=l(),p2e=a("p"),Q1r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),W1r=l(),nc=a("p"),H1r=o(`Note:
Loading a model from its configuration file does `),u2e=a("strong"),U1r=o("not"),J1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XW=a("a"),Y1r=o("from_pretrained()"),K1r=o(" to load the model weights."),Z1r=l(),F(oM.$$.fragment),ebr=l(),kr=a("div"),F(F8.$$.fragment),obr=l(),_2e=a("p"),rbr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),tbr=l(),an=a("p"),abr=o("The model class to instantiate is selected based on the "),b2e=a("code"),nbr=o("model_type"),sbr=o(` property of the config object (either
passed as an argument or loaded from `),v2e=a("code"),lbr=o("pretrained_model_name_or_path"),ibr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F2e=a("code"),dbr=o("pretrained_model_name_or_path"),cbr=o(":"),fbr=l(),ee=a("ul"),rM=a("li"),T2e=a("strong"),mbr=o("albert"),gbr=o(" \u2014 "),zW=a("a"),hbr=o("TFAlbertForSequenceClassification"),pbr=o(" (ALBERT model)"),ubr=l(),tM=a("li"),M2e=a("strong"),_br=o("bert"),bbr=o(" \u2014 "),QW=a("a"),vbr=o("TFBertForSequenceClassification"),Fbr=o(" (BERT model)"),Tbr=l(),aM=a("li"),E2e=a("strong"),Mbr=o("camembert"),Ebr=o(" \u2014 "),WW=a("a"),Cbr=o("TFCamembertForSequenceClassification"),wbr=o(" (CamemBERT model)"),Abr=l(),nM=a("li"),C2e=a("strong"),ybr=o("convbert"),Lbr=o(" \u2014 "),HW=a("a"),xbr=o("TFConvBertForSequenceClassification"),$br=o(" (ConvBERT model)"),kbr=l(),sM=a("li"),w2e=a("strong"),Sbr=o("ctrl"),Rbr=o(" \u2014 "),UW=a("a"),Bbr=o("TFCTRLForSequenceClassification"),Pbr=o(" (CTRL model)"),Ibr=l(),lM=a("li"),A2e=a("strong"),qbr=o("deberta"),Nbr=o(" \u2014 "),JW=a("a"),jbr=o("TFDebertaForSequenceClassification"),Dbr=o(" (DeBERTa model)"),Gbr=l(),iM=a("li"),y2e=a("strong"),Obr=o("deberta-v2"),Vbr=o(" \u2014 "),YW=a("a"),Xbr=o("TFDebertaV2ForSequenceClassification"),zbr=o(" (DeBERTa-v2 model)"),Qbr=l(),dM=a("li"),L2e=a("strong"),Wbr=o("distilbert"),Hbr=o(" \u2014 "),KW=a("a"),Ubr=o("TFDistilBertForSequenceClassification"),Jbr=o(" (DistilBERT model)"),Ybr=l(),cM=a("li"),x2e=a("strong"),Kbr=o("electra"),Zbr=o(" \u2014 "),ZW=a("a"),e2r=o("TFElectraForSequenceClassification"),o2r=o(" (ELECTRA model)"),r2r=l(),fM=a("li"),$2e=a("strong"),t2r=o("flaubert"),a2r=o(" \u2014 "),eH=a("a"),n2r=o("TFFlaubertForSequenceClassification"),s2r=o(" (FlauBERT model)"),l2r=l(),mM=a("li"),k2e=a("strong"),i2r=o("funnel"),d2r=o(" \u2014 "),oH=a("a"),c2r=o("TFFunnelForSequenceClassification"),f2r=o(" (Funnel Transformer model)"),m2r=l(),gM=a("li"),S2e=a("strong"),g2r=o("gpt2"),h2r=o(" \u2014 "),rH=a("a"),p2r=o("TFGPT2ForSequenceClassification"),u2r=o(" (OpenAI GPT-2 model)"),_2r=l(),hM=a("li"),R2e=a("strong"),b2r=o("gptj"),v2r=o(" \u2014 "),tH=a("a"),F2r=o("TFGPTJForSequenceClassification"),T2r=o(" (GPT-J model)"),M2r=l(),pM=a("li"),B2e=a("strong"),E2r=o("layoutlm"),C2r=o(" \u2014 "),aH=a("a"),w2r=o("TFLayoutLMForSequenceClassification"),A2r=o(" (LayoutLM model)"),y2r=l(),uM=a("li"),P2e=a("strong"),L2r=o("longformer"),x2r=o(" \u2014 "),nH=a("a"),$2r=o("TFLongformerForSequenceClassification"),k2r=o(" (Longformer model)"),S2r=l(),_M=a("li"),I2e=a("strong"),R2r=o("mobilebert"),B2r=o(" \u2014 "),sH=a("a"),P2r=o("TFMobileBertForSequenceClassification"),I2r=o(" (MobileBERT model)"),q2r=l(),bM=a("li"),q2e=a("strong"),N2r=o("mpnet"),j2r=o(" \u2014 "),lH=a("a"),D2r=o("TFMPNetForSequenceClassification"),G2r=o(" (MPNet model)"),O2r=l(),vM=a("li"),N2e=a("strong"),V2r=o("openai-gpt"),X2r=o(" \u2014 "),iH=a("a"),z2r=o("TFOpenAIGPTForSequenceClassification"),Q2r=o(" (OpenAI GPT model)"),W2r=l(),FM=a("li"),j2e=a("strong"),H2r=o("rembert"),U2r=o(" \u2014 "),dH=a("a"),J2r=o("TFRemBertForSequenceClassification"),Y2r=o(" (RemBERT model)"),K2r=l(),TM=a("li"),D2e=a("strong"),Z2r=o("roberta"),evr=o(" \u2014 "),cH=a("a"),ovr=o("TFRobertaForSequenceClassification"),rvr=o(" (RoBERTa model)"),tvr=l(),MM=a("li"),G2e=a("strong"),avr=o("roformer"),nvr=o(" \u2014 "),fH=a("a"),svr=o("TFRoFormerForSequenceClassification"),lvr=o(" (RoFormer model)"),ivr=l(),EM=a("li"),O2e=a("strong"),dvr=o("tapas"),cvr=o(" \u2014 "),mH=a("a"),fvr=o("TFTapasForSequenceClassification"),mvr=o(" (TAPAS model)"),gvr=l(),CM=a("li"),V2e=a("strong"),hvr=o("transfo-xl"),pvr=o(" \u2014 "),gH=a("a"),uvr=o("TFTransfoXLForSequenceClassification"),_vr=o(" (Transformer-XL model)"),bvr=l(),wM=a("li"),X2e=a("strong"),vvr=o("xlm"),Fvr=o(" \u2014 "),hH=a("a"),Tvr=o("TFXLMForSequenceClassification"),Mvr=o(" (XLM model)"),Evr=l(),AM=a("li"),z2e=a("strong"),Cvr=o("xlm-roberta"),wvr=o(" \u2014 "),pH=a("a"),Avr=o("TFXLMRobertaForSequenceClassification"),yvr=o(" (XLM-RoBERTa model)"),Lvr=l(),yM=a("li"),Q2e=a("strong"),xvr=o("xlnet"),$vr=o(" \u2014 "),uH=a("a"),kvr=o("TFXLNetForSequenceClassification"),Svr=o(" (XLNet model)"),Rvr=l(),F(LM.$$.fragment),Gqe=l(),sc=a("h2"),xM=a("a"),W2e=a("span"),F(T8.$$.fragment),Bvr=l(),H2e=a("span"),Pvr=o("TFAutoModelForMultipleChoice"),Oqe=l(),ar=a("div"),F(M8.$$.fragment),Ivr=l(),lc=a("p"),qvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_H=a("a"),Nvr=o("from_pretrained()"),jvr=o(" class method or the "),bH=a("a"),Dvr=o("from_config()"),Gvr=o(` class
method.`),Ovr=l(),E8=a("p"),Vvr=o("This class cannot be instantiated directly using "),U2e=a("code"),Xvr=o("__init__()"),zvr=o(" (throws an error)."),Qvr=l(),St=a("div"),F(C8.$$.fragment),Wvr=l(),J2e=a("p"),Hvr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Uvr=l(),ic=a("p"),Jvr=o(`Note:
Loading a model from its configuration file does `),Y2e=a("strong"),Yvr=o("not"),Kvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vH=a("a"),Zvr=o("from_pretrained()"),eFr=o(" to load the model weights."),oFr=l(),F($M.$$.fragment),rFr=l(),Sr=a("div"),F(w8.$$.fragment),tFr=l(),K2e=a("p"),aFr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),nFr=l(),nn=a("p"),sFr=o("The model class to instantiate is selected based on the "),Z2e=a("code"),lFr=o("model_type"),iFr=o(` property of the config object (either
passed as an argument or loaded from `),eve=a("code"),dFr=o("pretrained_model_name_or_path"),cFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ove=a("code"),fFr=o("pretrained_model_name_or_path"),mFr=o(":"),gFr=l(),pe=a("ul"),kM=a("li"),rve=a("strong"),hFr=o("albert"),pFr=o(" \u2014 "),FH=a("a"),uFr=o("TFAlbertForMultipleChoice"),_Fr=o(" (ALBERT model)"),bFr=l(),SM=a("li"),tve=a("strong"),vFr=o("bert"),FFr=o(" \u2014 "),TH=a("a"),TFr=o("TFBertForMultipleChoice"),MFr=o(" (BERT model)"),EFr=l(),RM=a("li"),ave=a("strong"),CFr=o("camembert"),wFr=o(" \u2014 "),MH=a("a"),AFr=o("TFCamembertForMultipleChoice"),yFr=o(" (CamemBERT model)"),LFr=l(),BM=a("li"),nve=a("strong"),xFr=o("convbert"),$Fr=o(" \u2014 "),EH=a("a"),kFr=o("TFConvBertForMultipleChoice"),SFr=o(" (ConvBERT model)"),RFr=l(),PM=a("li"),sve=a("strong"),BFr=o("distilbert"),PFr=o(" \u2014 "),CH=a("a"),IFr=o("TFDistilBertForMultipleChoice"),qFr=o(" (DistilBERT model)"),NFr=l(),IM=a("li"),lve=a("strong"),jFr=o("electra"),DFr=o(" \u2014 "),wH=a("a"),GFr=o("TFElectraForMultipleChoice"),OFr=o(" (ELECTRA model)"),VFr=l(),qM=a("li"),ive=a("strong"),XFr=o("flaubert"),zFr=o(" \u2014 "),AH=a("a"),QFr=o("TFFlaubertForMultipleChoice"),WFr=o(" (FlauBERT model)"),HFr=l(),NM=a("li"),dve=a("strong"),UFr=o("funnel"),JFr=o(" \u2014 "),yH=a("a"),YFr=o("TFFunnelForMultipleChoice"),KFr=o(" (Funnel Transformer model)"),ZFr=l(),jM=a("li"),cve=a("strong"),e6r=o("longformer"),o6r=o(" \u2014 "),LH=a("a"),r6r=o("TFLongformerForMultipleChoice"),t6r=o(" (Longformer model)"),a6r=l(),DM=a("li"),fve=a("strong"),n6r=o("mobilebert"),s6r=o(" \u2014 "),xH=a("a"),l6r=o("TFMobileBertForMultipleChoice"),i6r=o(" (MobileBERT model)"),d6r=l(),GM=a("li"),mve=a("strong"),c6r=o("mpnet"),f6r=o(" \u2014 "),$H=a("a"),m6r=o("TFMPNetForMultipleChoice"),g6r=o(" (MPNet model)"),h6r=l(),OM=a("li"),gve=a("strong"),p6r=o("rembert"),u6r=o(" \u2014 "),kH=a("a"),_6r=o("TFRemBertForMultipleChoice"),b6r=o(" (RemBERT model)"),v6r=l(),VM=a("li"),hve=a("strong"),F6r=o("roberta"),T6r=o(" \u2014 "),SH=a("a"),M6r=o("TFRobertaForMultipleChoice"),E6r=o(" (RoBERTa model)"),C6r=l(),XM=a("li"),pve=a("strong"),w6r=o("roformer"),A6r=o(" \u2014 "),RH=a("a"),y6r=o("TFRoFormerForMultipleChoice"),L6r=o(" (RoFormer model)"),x6r=l(),zM=a("li"),uve=a("strong"),$6r=o("xlm"),k6r=o(" \u2014 "),BH=a("a"),S6r=o("TFXLMForMultipleChoice"),R6r=o(" (XLM model)"),B6r=l(),QM=a("li"),_ve=a("strong"),P6r=o("xlm-roberta"),I6r=o(" \u2014 "),PH=a("a"),q6r=o("TFXLMRobertaForMultipleChoice"),N6r=o(" (XLM-RoBERTa model)"),j6r=l(),WM=a("li"),bve=a("strong"),D6r=o("xlnet"),G6r=o(" \u2014 "),IH=a("a"),O6r=o("TFXLNetForMultipleChoice"),V6r=o(" (XLNet model)"),X6r=l(),F(HM.$$.fragment),Vqe=l(),dc=a("h2"),UM=a("a"),vve=a("span"),F(A8.$$.fragment),z6r=l(),Fve=a("span"),Q6r=o("TFAutoModelForNextSentencePrediction"),Xqe=l(),nr=a("div"),F(y8.$$.fragment),W6r=l(),cc=a("p"),H6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),qH=a("a"),U6r=o("from_pretrained()"),J6r=o(" class method or the "),NH=a("a"),Y6r=o("from_config()"),K6r=o(` class
method.`),Z6r=l(),L8=a("p"),eTr=o("This class cannot be instantiated directly using "),Tve=a("code"),oTr=o("__init__()"),rTr=o(" (throws an error)."),tTr=l(),Rt=a("div"),F(x8.$$.fragment),aTr=l(),Mve=a("p"),nTr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),sTr=l(),fc=a("p"),lTr=o(`Note:
Loading a model from its configuration file does `),Eve=a("strong"),iTr=o("not"),dTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=a("a"),cTr=o("from_pretrained()"),fTr=o(" to load the model weights."),mTr=l(),F(JM.$$.fragment),gTr=l(),Rr=a("div"),F($8.$$.fragment),hTr=l(),Cve=a("p"),pTr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),uTr=l(),sn=a("p"),_Tr=o("The model class to instantiate is selected based on the "),wve=a("code"),bTr=o("model_type"),vTr=o(` property of the config object (either
passed as an argument or loaded from `),Ave=a("code"),FTr=o("pretrained_model_name_or_path"),TTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yve=a("code"),MTr=o("pretrained_model_name_or_path"),ETr=o(":"),CTr=l(),k8=a("ul"),YM=a("li"),Lve=a("strong"),wTr=o("bert"),ATr=o(" \u2014 "),DH=a("a"),yTr=o("TFBertForNextSentencePrediction"),LTr=o(" (BERT model)"),xTr=l(),KM=a("li"),xve=a("strong"),$Tr=o("mobilebert"),kTr=o(" \u2014 "),GH=a("a"),STr=o("TFMobileBertForNextSentencePrediction"),RTr=o(" (MobileBERT model)"),BTr=l(),F(ZM.$$.fragment),zqe=l(),mc=a("h2"),e4=a("a"),$ve=a("span"),F(S8.$$.fragment),PTr=l(),kve=a("span"),ITr=o("TFAutoModelForTableQuestionAnswering"),Qqe=l(),sr=a("div"),F(R8.$$.fragment),qTr=l(),gc=a("p"),NTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),OH=a("a"),jTr=o("from_pretrained()"),DTr=o(" class method or the "),VH=a("a"),GTr=o("from_config()"),OTr=o(` class
method.`),VTr=l(),B8=a("p"),XTr=o("This class cannot be instantiated directly using "),Sve=a("code"),zTr=o("__init__()"),QTr=o(" (throws an error)."),WTr=l(),Bt=a("div"),F(P8.$$.fragment),HTr=l(),Rve=a("p"),UTr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),JTr=l(),hc=a("p"),YTr=o(`Note:
Loading a model from its configuration file does `),Bve=a("strong"),KTr=o("not"),ZTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=a("a"),e7r=o("from_pretrained()"),o7r=o(" to load the model weights."),r7r=l(),F(o4.$$.fragment),t7r=l(),Br=a("div"),F(I8.$$.fragment),a7r=l(),Pve=a("p"),n7r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),s7r=l(),ln=a("p"),l7r=o("The model class to instantiate is selected based on the "),Ive=a("code"),i7r=o("model_type"),d7r=o(` property of the config object (either
passed as an argument or loaded from `),qve=a("code"),c7r=o("pretrained_model_name_or_path"),f7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nve=a("code"),m7r=o("pretrained_model_name_or_path"),g7r=o(":"),h7r=l(),jve=a("ul"),r4=a("li"),Dve=a("strong"),p7r=o("tapas"),u7r=o(" \u2014 "),zH=a("a"),_7r=o("TFTapasForQuestionAnswering"),b7r=o(" (TAPAS model)"),v7r=l(),F(t4.$$.fragment),Wqe=l(),pc=a("h2"),a4=a("a"),Gve=a("span"),F(q8.$$.fragment),F7r=l(),Ove=a("span"),T7r=o("TFAutoModelForTokenClassification"),Hqe=l(),lr=a("div"),F(N8.$$.fragment),M7r=l(),uc=a("p"),E7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),QH=a("a"),C7r=o("from_pretrained()"),w7r=o(" class method or the "),WH=a("a"),A7r=o("from_config()"),y7r=o(` class
method.`),L7r=l(),j8=a("p"),x7r=o("This class cannot be instantiated directly using "),Vve=a("code"),$7r=o("__init__()"),k7r=o(" (throws an error)."),S7r=l(),Pt=a("div"),F(D8.$$.fragment),R7r=l(),Xve=a("p"),B7r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),P7r=l(),_c=a("p"),I7r=o(`Note:
Loading a model from its configuration file does `),zve=a("strong"),q7r=o("not"),N7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HH=a("a"),j7r=o("from_pretrained()"),D7r=o(" to load the model weights."),G7r=l(),F(n4.$$.fragment),O7r=l(),Pr=a("div"),F(G8.$$.fragment),V7r=l(),Qve=a("p"),X7r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),z7r=l(),dn=a("p"),Q7r=o("The model class to instantiate is selected based on the "),Wve=a("code"),W7r=o("model_type"),H7r=o(` property of the config object (either
passed as an argument or loaded from `),Hve=a("code"),U7r=o("pretrained_model_name_or_path"),J7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uve=a("code"),Y7r=o("pretrained_model_name_or_path"),K7r=o(":"),Z7r=l(),de=a("ul"),s4=a("li"),Jve=a("strong"),eMr=o("albert"),oMr=o(" \u2014 "),UH=a("a"),rMr=o("TFAlbertForTokenClassification"),tMr=o(" (ALBERT model)"),aMr=l(),l4=a("li"),Yve=a("strong"),nMr=o("bert"),sMr=o(" \u2014 "),JH=a("a"),lMr=o("TFBertForTokenClassification"),iMr=o(" (BERT model)"),dMr=l(),i4=a("li"),Kve=a("strong"),cMr=o("camembert"),fMr=o(" \u2014 "),YH=a("a"),mMr=o("TFCamembertForTokenClassification"),gMr=o(" (CamemBERT model)"),hMr=l(),d4=a("li"),Zve=a("strong"),pMr=o("convbert"),uMr=o(" \u2014 "),KH=a("a"),_Mr=o("TFConvBertForTokenClassification"),bMr=o(" (ConvBERT model)"),vMr=l(),c4=a("li"),eFe=a("strong"),FMr=o("deberta"),TMr=o(" \u2014 "),ZH=a("a"),MMr=o("TFDebertaForTokenClassification"),EMr=o(" (DeBERTa model)"),CMr=l(),f4=a("li"),oFe=a("strong"),wMr=o("deberta-v2"),AMr=o(" \u2014 "),eU=a("a"),yMr=o("TFDebertaV2ForTokenClassification"),LMr=o(" (DeBERTa-v2 model)"),xMr=l(),m4=a("li"),rFe=a("strong"),$Mr=o("distilbert"),kMr=o(" \u2014 "),oU=a("a"),SMr=o("TFDistilBertForTokenClassification"),RMr=o(" (DistilBERT model)"),BMr=l(),g4=a("li"),tFe=a("strong"),PMr=o("electra"),IMr=o(" \u2014 "),rU=a("a"),qMr=o("TFElectraForTokenClassification"),NMr=o(" (ELECTRA model)"),jMr=l(),h4=a("li"),aFe=a("strong"),DMr=o("flaubert"),GMr=o(" \u2014 "),tU=a("a"),OMr=o("TFFlaubertForTokenClassification"),VMr=o(" (FlauBERT model)"),XMr=l(),p4=a("li"),nFe=a("strong"),zMr=o("funnel"),QMr=o(" \u2014 "),aU=a("a"),WMr=o("TFFunnelForTokenClassification"),HMr=o(" (Funnel Transformer model)"),UMr=l(),u4=a("li"),sFe=a("strong"),JMr=o("layoutlm"),YMr=o(" \u2014 "),nU=a("a"),KMr=o("TFLayoutLMForTokenClassification"),ZMr=o(" (LayoutLM model)"),e4r=l(),_4=a("li"),lFe=a("strong"),o4r=o("longformer"),r4r=o(" \u2014 "),sU=a("a"),t4r=o("TFLongformerForTokenClassification"),a4r=o(" (Longformer model)"),n4r=l(),b4=a("li"),iFe=a("strong"),s4r=o("mobilebert"),l4r=o(" \u2014 "),lU=a("a"),i4r=o("TFMobileBertForTokenClassification"),d4r=o(" (MobileBERT model)"),c4r=l(),v4=a("li"),dFe=a("strong"),f4r=o("mpnet"),m4r=o(" \u2014 "),iU=a("a"),g4r=o("TFMPNetForTokenClassification"),h4r=o(" (MPNet model)"),p4r=l(),F4=a("li"),cFe=a("strong"),u4r=o("rembert"),_4r=o(" \u2014 "),dU=a("a"),b4r=o("TFRemBertForTokenClassification"),v4r=o(" (RemBERT model)"),F4r=l(),T4=a("li"),fFe=a("strong"),T4r=o("roberta"),M4r=o(" \u2014 "),cU=a("a"),E4r=o("TFRobertaForTokenClassification"),C4r=o(" (RoBERTa model)"),w4r=l(),M4=a("li"),mFe=a("strong"),A4r=o("roformer"),y4r=o(" \u2014 "),fU=a("a"),L4r=o("TFRoFormerForTokenClassification"),x4r=o(" (RoFormer model)"),$4r=l(),E4=a("li"),gFe=a("strong"),k4r=o("xlm"),S4r=o(" \u2014 "),mU=a("a"),R4r=o("TFXLMForTokenClassification"),B4r=o(" (XLM model)"),P4r=l(),C4=a("li"),hFe=a("strong"),I4r=o("xlm-roberta"),q4r=o(" \u2014 "),gU=a("a"),N4r=o("TFXLMRobertaForTokenClassification"),j4r=o(" (XLM-RoBERTa model)"),D4r=l(),w4=a("li"),pFe=a("strong"),G4r=o("xlnet"),O4r=o(" \u2014 "),hU=a("a"),V4r=o("TFXLNetForTokenClassification"),X4r=o(" (XLNet model)"),z4r=l(),F(A4.$$.fragment),Uqe=l(),bc=a("h2"),y4=a("a"),uFe=a("span"),F(O8.$$.fragment),Q4r=l(),_Fe=a("span"),W4r=o("TFAutoModelForQuestionAnswering"),Jqe=l(),ir=a("div"),F(V8.$$.fragment),H4r=l(),vc=a("p"),U4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),pU=a("a"),J4r=o("from_pretrained()"),Y4r=o(" class method or the "),uU=a("a"),K4r=o("from_config()"),Z4r=o(` class
method.`),eEr=l(),X8=a("p"),oEr=o("This class cannot be instantiated directly using "),bFe=a("code"),rEr=o("__init__()"),tEr=o(" (throws an error)."),aEr=l(),It=a("div"),F(z8.$$.fragment),nEr=l(),vFe=a("p"),sEr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),lEr=l(),Fc=a("p"),iEr=o(`Note:
Loading a model from its configuration file does `),FFe=a("strong"),dEr=o("not"),cEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_U=a("a"),fEr=o("from_pretrained()"),mEr=o(" to load the model weights."),gEr=l(),F(L4.$$.fragment),hEr=l(),Ir=a("div"),F(Q8.$$.fragment),pEr=l(),TFe=a("p"),uEr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),_Er=l(),cn=a("p"),bEr=o("The model class to instantiate is selected based on the "),MFe=a("code"),vEr=o("model_type"),FEr=o(` property of the config object (either
passed as an argument or loaded from `),EFe=a("code"),TEr=o("pretrained_model_name_or_path"),MEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CFe=a("code"),EEr=o("pretrained_model_name_or_path"),CEr=o(":"),wEr=l(),ce=a("ul"),x4=a("li"),wFe=a("strong"),AEr=o("albert"),yEr=o(" \u2014 "),bU=a("a"),LEr=o("TFAlbertForQuestionAnswering"),xEr=o(" (ALBERT model)"),$Er=l(),$4=a("li"),AFe=a("strong"),kEr=o("bert"),SEr=o(" \u2014 "),vU=a("a"),REr=o("TFBertForQuestionAnswering"),BEr=o(" (BERT model)"),PEr=l(),k4=a("li"),yFe=a("strong"),IEr=o("camembert"),qEr=o(" \u2014 "),FU=a("a"),NEr=o("TFCamembertForQuestionAnswering"),jEr=o(" (CamemBERT model)"),DEr=l(),S4=a("li"),LFe=a("strong"),GEr=o("convbert"),OEr=o(" \u2014 "),TU=a("a"),VEr=o("TFConvBertForQuestionAnswering"),XEr=o(" (ConvBERT model)"),zEr=l(),R4=a("li"),xFe=a("strong"),QEr=o("deberta"),WEr=o(" \u2014 "),MU=a("a"),HEr=o("TFDebertaForQuestionAnswering"),UEr=o(" (DeBERTa model)"),JEr=l(),B4=a("li"),$Fe=a("strong"),YEr=o("deberta-v2"),KEr=o(" \u2014 "),EU=a("a"),ZEr=o("TFDebertaV2ForQuestionAnswering"),e5r=o(" (DeBERTa-v2 model)"),o5r=l(),P4=a("li"),kFe=a("strong"),r5r=o("distilbert"),t5r=o(" \u2014 "),CU=a("a"),a5r=o("TFDistilBertForQuestionAnswering"),n5r=o(" (DistilBERT model)"),s5r=l(),I4=a("li"),SFe=a("strong"),l5r=o("electra"),i5r=o(" \u2014 "),wU=a("a"),d5r=o("TFElectraForQuestionAnswering"),c5r=o(" (ELECTRA model)"),f5r=l(),q4=a("li"),RFe=a("strong"),m5r=o("flaubert"),g5r=o(" \u2014 "),AU=a("a"),h5r=o("TFFlaubertForQuestionAnsweringSimple"),p5r=o(" (FlauBERT model)"),u5r=l(),N4=a("li"),BFe=a("strong"),_5r=o("funnel"),b5r=o(" \u2014 "),yU=a("a"),v5r=o("TFFunnelForQuestionAnswering"),F5r=o(" (Funnel Transformer model)"),T5r=l(),j4=a("li"),PFe=a("strong"),M5r=o("gptj"),E5r=o(" \u2014 "),LU=a("a"),C5r=o("TFGPTJForQuestionAnswering"),w5r=o(" (GPT-J model)"),A5r=l(),D4=a("li"),IFe=a("strong"),y5r=o("longformer"),L5r=o(" \u2014 "),xU=a("a"),x5r=o("TFLongformerForQuestionAnswering"),$5r=o(" (Longformer model)"),k5r=l(),G4=a("li"),qFe=a("strong"),S5r=o("mobilebert"),R5r=o(" \u2014 "),$U=a("a"),B5r=o("TFMobileBertForQuestionAnswering"),P5r=o(" (MobileBERT model)"),I5r=l(),O4=a("li"),NFe=a("strong"),q5r=o("mpnet"),N5r=o(" \u2014 "),kU=a("a"),j5r=o("TFMPNetForQuestionAnswering"),D5r=o(" (MPNet model)"),G5r=l(),V4=a("li"),jFe=a("strong"),O5r=o("rembert"),V5r=o(" \u2014 "),SU=a("a"),X5r=o("TFRemBertForQuestionAnswering"),z5r=o(" (RemBERT model)"),Q5r=l(),X4=a("li"),DFe=a("strong"),W5r=o("roberta"),H5r=o(" \u2014 "),RU=a("a"),U5r=o("TFRobertaForQuestionAnswering"),J5r=o(" (RoBERTa model)"),Y5r=l(),z4=a("li"),GFe=a("strong"),K5r=o("roformer"),Z5r=o(" \u2014 "),BU=a("a"),eCr=o("TFRoFormerForQuestionAnswering"),oCr=o(" (RoFormer model)"),rCr=l(),Q4=a("li"),OFe=a("strong"),tCr=o("xlm"),aCr=o(" \u2014 "),PU=a("a"),nCr=o("TFXLMForQuestionAnsweringSimple"),sCr=o(" (XLM model)"),lCr=l(),W4=a("li"),VFe=a("strong"),iCr=o("xlm-roberta"),dCr=o(" \u2014 "),IU=a("a"),cCr=o("TFXLMRobertaForQuestionAnswering"),fCr=o(" (XLM-RoBERTa model)"),mCr=l(),H4=a("li"),XFe=a("strong"),gCr=o("xlnet"),hCr=o(" \u2014 "),qU=a("a"),pCr=o("TFXLNetForQuestionAnsweringSimple"),uCr=o(" (XLNet model)"),_Cr=l(),F(U4.$$.fragment),Yqe=l(),Tc=a("h2"),J4=a("a"),zFe=a("span"),F(W8.$$.fragment),bCr=l(),QFe=a("span"),vCr=o("TFAutoModelForVision2Seq"),Kqe=l(),dr=a("div"),F(H8.$$.fragment),FCr=l(),Mc=a("p"),TCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),NU=a("a"),MCr=o("from_pretrained()"),ECr=o(" class method or the "),jU=a("a"),CCr=o("from_config()"),wCr=o(` class
method.`),ACr=l(),U8=a("p"),yCr=o("This class cannot be instantiated directly using "),WFe=a("code"),LCr=o("__init__()"),xCr=o(" (throws an error)."),$Cr=l(),qt=a("div"),F(J8.$$.fragment),kCr=l(),HFe=a("p"),SCr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),RCr=l(),Ec=a("p"),BCr=o(`Note:
Loading a model from its configuration file does `),UFe=a("strong"),PCr=o("not"),ICr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DU=a("a"),qCr=o("from_pretrained()"),NCr=o(" to load the model weights."),jCr=l(),F(Y4.$$.fragment),DCr=l(),qr=a("div"),F(Y8.$$.fragment),GCr=l(),JFe=a("p"),OCr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),VCr=l(),fn=a("p"),XCr=o("The model class to instantiate is selected based on the "),YFe=a("code"),zCr=o("model_type"),QCr=o(` property of the config object (either
passed as an argument or loaded from `),KFe=a("code"),WCr=o("pretrained_model_name_or_path"),HCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=a("code"),UCr=o("pretrained_model_name_or_path"),JCr=o(":"),YCr=l(),e6e=a("ul"),K4=a("li"),o6e=a("strong"),KCr=o("vision-encoder-decoder"),ZCr=o(" \u2014 "),GU=a("a"),e3r=o("TFVisionEncoderDecoderModel"),o3r=o(" (Vision Encoder decoder model)"),r3r=l(),F(Z4.$$.fragment),Zqe=l(),Cc=a("h2"),eE=a("a"),r6e=a("span"),F(K8.$$.fragment),t3r=l(),t6e=a("span"),a3r=o("TFAutoModelForSpeechSeq2Seq"),eNe=l(),cr=a("div"),F(Z8.$$.fragment),n3r=l(),wc=a("p"),s3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),OU=a("a"),l3r=o("from_pretrained()"),i3r=o(" class method or the "),VU=a("a"),d3r=o("from_config()"),c3r=o(` class
method.`),f3r=l(),ex=a("p"),m3r=o("This class cannot be instantiated directly using "),a6e=a("code"),g3r=o("__init__()"),h3r=o(" (throws an error)."),p3r=l(),Nt=a("div"),F(ox.$$.fragment),u3r=l(),n6e=a("p"),_3r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),b3r=l(),Ac=a("p"),v3r=o(`Note:
Loading a model from its configuration file does `),s6e=a("strong"),F3r=o("not"),T3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XU=a("a"),M3r=o("from_pretrained()"),E3r=o(" to load the model weights."),C3r=l(),F(oE.$$.fragment),w3r=l(),Nr=a("div"),F(rx.$$.fragment),A3r=l(),l6e=a("p"),y3r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),L3r=l(),mn=a("p"),x3r=o("The model class to instantiate is selected based on the "),i6e=a("code"),$3r=o("model_type"),k3r=o(` property of the config object (either
passed as an argument or loaded from `),d6e=a("code"),S3r=o("pretrained_model_name_or_path"),R3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c6e=a("code"),B3r=o("pretrained_model_name_or_path"),P3r=o(":"),I3r=l(),f6e=a("ul"),rE=a("li"),m6e=a("strong"),q3r=o("speech_to_text"),N3r=o(" \u2014 "),zU=a("a"),j3r=o("TFSpeech2TextForConditionalGeneration"),D3r=o(" (Speech2Text model)"),G3r=l(),F(tE.$$.fragment),oNe=l(),yc=a("h2"),aE=a("a"),g6e=a("span"),F(tx.$$.fragment),O3r=l(),h6e=a("span"),V3r=o("FlaxAutoModel"),rNe=l(),fr=a("div"),F(ax.$$.fragment),X3r=l(),Lc=a("p"),z3r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),QU=a("a"),Q3r=o("from_pretrained()"),W3r=o(" class method or the "),WU=a("a"),H3r=o("from_config()"),U3r=o(` class
method.`),J3r=l(),nx=a("p"),Y3r=o("This class cannot be instantiated directly using "),p6e=a("code"),K3r=o("__init__()"),Z3r=o(" (throws an error)."),ewr=l(),jt=a("div"),F(sx.$$.fragment),owr=l(),u6e=a("p"),rwr=o("Instantiates one of the base model classes of the library from a configuration."),twr=l(),xc=a("p"),awr=o(`Note:
Loading a model from its configuration file does `),_6e=a("strong"),nwr=o("not"),swr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=a("a"),lwr=o("from_pretrained()"),iwr=o(" to load the model weights."),dwr=l(),F(nE.$$.fragment),cwr=l(),jr=a("div"),F(lx.$$.fragment),fwr=l(),b6e=a("p"),mwr=o("Instantiate one of the base model classes of the library from a pretrained model."),gwr=l(),gn=a("p"),hwr=o("The model class to instantiate is selected based on the "),v6e=a("code"),pwr=o("model_type"),uwr=o(` property of the config object (either
passed as an argument or loaded from `),F6e=a("code"),_wr=o("pretrained_model_name_or_path"),bwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=a("code"),vwr=o("pretrained_model_name_or_path"),Fwr=o(":"),Twr=l(),re=a("ul"),sE=a("li"),M6e=a("strong"),Mwr=o("albert"),Ewr=o(" \u2014 "),UU=a("a"),Cwr=o("FlaxAlbertModel"),wwr=o(" (ALBERT model)"),Awr=l(),lE=a("li"),E6e=a("strong"),ywr=o("bart"),Lwr=o(" \u2014 "),JU=a("a"),xwr=o("FlaxBartModel"),$wr=o(" (BART model)"),kwr=l(),iE=a("li"),C6e=a("strong"),Swr=o("beit"),Rwr=o(" \u2014 "),YU=a("a"),Bwr=o("FlaxBeitModel"),Pwr=o(" (BEiT model)"),Iwr=l(),dE=a("li"),w6e=a("strong"),qwr=o("bert"),Nwr=o(" \u2014 "),KU=a("a"),jwr=o("FlaxBertModel"),Dwr=o(" (BERT model)"),Gwr=l(),cE=a("li"),A6e=a("strong"),Owr=o("big_bird"),Vwr=o(" \u2014 "),ZU=a("a"),Xwr=o("FlaxBigBirdModel"),zwr=o(" (BigBird model)"),Qwr=l(),fE=a("li"),y6e=a("strong"),Wwr=o("blenderbot"),Hwr=o(" \u2014 "),eJ=a("a"),Uwr=o("FlaxBlenderbotModel"),Jwr=o(" (Blenderbot model)"),Ywr=l(),mE=a("li"),L6e=a("strong"),Kwr=o("blenderbot-small"),Zwr=o(" \u2014 "),oJ=a("a"),eAr=o("FlaxBlenderbotSmallModel"),oAr=o(" (BlenderbotSmall model)"),rAr=l(),gE=a("li"),x6e=a("strong"),tAr=o("clip"),aAr=o(" \u2014 "),rJ=a("a"),nAr=o("FlaxCLIPModel"),sAr=o(" (CLIP model)"),lAr=l(),hE=a("li"),$6e=a("strong"),iAr=o("distilbert"),dAr=o(" \u2014 "),tJ=a("a"),cAr=o("FlaxDistilBertModel"),fAr=o(" (DistilBERT model)"),mAr=l(),pE=a("li"),k6e=a("strong"),gAr=o("electra"),hAr=o(" \u2014 "),aJ=a("a"),pAr=o("FlaxElectraModel"),uAr=o(" (ELECTRA model)"),_Ar=l(),uE=a("li"),S6e=a("strong"),bAr=o("gpt2"),vAr=o(" \u2014 "),nJ=a("a"),FAr=o("FlaxGPT2Model"),TAr=o(" (OpenAI GPT-2 model)"),MAr=l(),_E=a("li"),R6e=a("strong"),EAr=o("gpt_neo"),CAr=o(" \u2014 "),sJ=a("a"),wAr=o("FlaxGPTNeoModel"),AAr=o(" (GPT Neo model)"),yAr=l(),bE=a("li"),B6e=a("strong"),LAr=o("gptj"),xAr=o(" \u2014 "),lJ=a("a"),$Ar=o("FlaxGPTJModel"),kAr=o(" (GPT-J model)"),SAr=l(),vE=a("li"),P6e=a("strong"),RAr=o("marian"),BAr=o(" \u2014 "),iJ=a("a"),PAr=o("FlaxMarianModel"),IAr=o(" (Marian model)"),qAr=l(),FE=a("li"),I6e=a("strong"),NAr=o("mbart"),jAr=o(" \u2014 "),dJ=a("a"),DAr=o("FlaxMBartModel"),GAr=o(" (mBART model)"),OAr=l(),TE=a("li"),q6e=a("strong"),VAr=o("mt5"),XAr=o(" \u2014 "),cJ=a("a"),zAr=o("FlaxMT5Model"),QAr=o(" (mT5 model)"),WAr=l(),ME=a("li"),N6e=a("strong"),HAr=o("pegasus"),UAr=o(" \u2014 "),fJ=a("a"),JAr=o("FlaxPegasusModel"),YAr=o(" (Pegasus model)"),KAr=l(),EE=a("li"),j6e=a("strong"),ZAr=o("roberta"),eyr=o(" \u2014 "),mJ=a("a"),oyr=o("FlaxRobertaModel"),ryr=o(" (RoBERTa model)"),tyr=l(),CE=a("li"),D6e=a("strong"),ayr=o("roformer"),nyr=o(" \u2014 "),gJ=a("a"),syr=o("FlaxRoFormerModel"),lyr=o(" (RoFormer model)"),iyr=l(),wE=a("li"),G6e=a("strong"),dyr=o("t5"),cyr=o(" \u2014 "),hJ=a("a"),fyr=o("FlaxT5Model"),myr=o(" (T5 model)"),gyr=l(),AE=a("li"),O6e=a("strong"),hyr=o("vision-text-dual-encoder"),pyr=o(" \u2014 "),pJ=a("a"),uyr=o("FlaxVisionTextDualEncoderModel"),_yr=o(" (VisionTextDualEncoder model)"),byr=l(),yE=a("li"),V6e=a("strong"),vyr=o("vit"),Fyr=o(" \u2014 "),uJ=a("a"),Tyr=o("FlaxViTModel"),Myr=o(" (ViT model)"),Eyr=l(),LE=a("li"),X6e=a("strong"),Cyr=o("wav2vec2"),wyr=o(" \u2014 "),_J=a("a"),Ayr=o("FlaxWav2Vec2Model"),yyr=o(" (Wav2Vec2 model)"),Lyr=l(),xE=a("li"),z6e=a("strong"),xyr=o("xglm"),$yr=o(" \u2014 "),bJ=a("a"),kyr=o("FlaxXGLMModel"),Syr=o(" (XGLM model)"),Ryr=l(),$E=a("li"),Q6e=a("strong"),Byr=o("xlm-roberta"),Pyr=o(" \u2014 "),vJ=a("a"),Iyr=o("FlaxXLMRobertaModel"),qyr=o(" (XLM-RoBERTa model)"),Nyr=l(),F(kE.$$.fragment),tNe=l(),$c=a("h2"),SE=a("a"),W6e=a("span"),F(ix.$$.fragment),jyr=l(),H6e=a("span"),Dyr=o("FlaxAutoModelForCausalLM"),aNe=l(),mr=a("div"),F(dx.$$.fragment),Gyr=l(),kc=a("p"),Oyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),FJ=a("a"),Vyr=o("from_pretrained()"),Xyr=o(" class method or the "),TJ=a("a"),zyr=o("from_config()"),Qyr=o(` class
method.`),Wyr=l(),cx=a("p"),Hyr=o("This class cannot be instantiated directly using "),U6e=a("code"),Uyr=o("__init__()"),Jyr=o(" (throws an error)."),Yyr=l(),Dt=a("div"),F(fx.$$.fragment),Kyr=l(),J6e=a("p"),Zyr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),eLr=l(),Sc=a("p"),oLr=o(`Note:
Loading a model from its configuration file does `),Y6e=a("strong"),rLr=o("not"),tLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MJ=a("a"),aLr=o("from_pretrained()"),nLr=o(" to load the model weights."),sLr=l(),F(RE.$$.fragment),lLr=l(),Dr=a("div"),F(mx.$$.fragment),iLr=l(),K6e=a("p"),dLr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cLr=l(),hn=a("p"),fLr=o("The model class to instantiate is selected based on the "),Z6e=a("code"),mLr=o("model_type"),gLr=o(` property of the config object (either
passed as an argument or loaded from `),eTe=a("code"),hLr=o("pretrained_model_name_or_path"),pLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=a("code"),uLr=o("pretrained_model_name_or_path"),_Lr=o(":"),bLr=l(),ke=a("ul"),BE=a("li"),rTe=a("strong"),vLr=o("bart"),FLr=o(" \u2014 "),EJ=a("a"),TLr=o("FlaxBartForCausalLM"),MLr=o(" (BART model)"),ELr=l(),PE=a("li"),tTe=a("strong"),CLr=o("bert"),wLr=o(" \u2014 "),CJ=a("a"),ALr=o("FlaxBertForCausalLM"),yLr=o(" (BERT model)"),LLr=l(),IE=a("li"),aTe=a("strong"),xLr=o("big_bird"),$Lr=o(" \u2014 "),wJ=a("a"),kLr=o("FlaxBigBirdForCausalLM"),SLr=o(" (BigBird model)"),RLr=l(),qE=a("li"),nTe=a("strong"),BLr=o("electra"),PLr=o(" \u2014 "),AJ=a("a"),ILr=o("FlaxElectraForCausalLM"),qLr=o(" (ELECTRA model)"),NLr=l(),NE=a("li"),sTe=a("strong"),jLr=o("gpt2"),DLr=o(" \u2014 "),yJ=a("a"),GLr=o("FlaxGPT2LMHeadModel"),OLr=o(" (OpenAI GPT-2 model)"),VLr=l(),jE=a("li"),lTe=a("strong"),XLr=o("gpt_neo"),zLr=o(" \u2014 "),LJ=a("a"),QLr=o("FlaxGPTNeoForCausalLM"),WLr=o(" (GPT Neo model)"),HLr=l(),DE=a("li"),iTe=a("strong"),ULr=o("gptj"),JLr=o(" \u2014 "),xJ=a("a"),YLr=o("FlaxGPTJForCausalLM"),KLr=o(" (GPT-J model)"),ZLr=l(),GE=a("li"),dTe=a("strong"),e8r=o("roberta"),o8r=o(" \u2014 "),$J=a("a"),r8r=o("FlaxRobertaForCausalLM"),t8r=o(" (RoBERTa model)"),a8r=l(),OE=a("li"),cTe=a("strong"),n8r=o("xglm"),s8r=o(" \u2014 "),kJ=a("a"),l8r=o("FlaxXGLMForCausalLM"),i8r=o(" (XGLM model)"),d8r=l(),F(VE.$$.fragment),nNe=l(),Rc=a("h2"),XE=a("a"),fTe=a("span"),F(gx.$$.fragment),c8r=l(),mTe=a("span"),f8r=o("FlaxAutoModelForPreTraining"),sNe=l(),gr=a("div"),F(hx.$$.fragment),m8r=l(),Bc=a("p"),g8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),SJ=a("a"),h8r=o("from_pretrained()"),p8r=o(" class method or the "),RJ=a("a"),u8r=o("from_config()"),_8r=o(` class
method.`),b8r=l(),px=a("p"),v8r=o("This class cannot be instantiated directly using "),gTe=a("code"),F8r=o("__init__()"),T8r=o(" (throws an error)."),M8r=l(),Gt=a("div"),F(ux.$$.fragment),E8r=l(),hTe=a("p"),C8r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),w8r=l(),Pc=a("p"),A8r=o(`Note:
Loading a model from its configuration file does `),pTe=a("strong"),y8r=o("not"),L8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=a("a"),x8r=o("from_pretrained()"),$8r=o(" to load the model weights."),k8r=l(),F(zE.$$.fragment),S8r=l(),Gr=a("div"),F(_x.$$.fragment),R8r=l(),uTe=a("p"),B8r=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),P8r=l(),pn=a("p"),I8r=o("The model class to instantiate is selected based on the "),_Te=a("code"),q8r=o("model_type"),N8r=o(` property of the config object (either
passed as an argument or loaded from `),bTe=a("code"),j8r=o("pretrained_model_name_or_path"),D8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=a("code"),G8r=o("pretrained_model_name_or_path"),O8r=o(":"),V8r=l(),Me=a("ul"),QE=a("li"),FTe=a("strong"),X8r=o("albert"),z8r=o(" \u2014 "),PJ=a("a"),Q8r=o("FlaxAlbertForPreTraining"),W8r=o(" (ALBERT model)"),H8r=l(),WE=a("li"),TTe=a("strong"),U8r=o("bart"),J8r=o(" \u2014 "),IJ=a("a"),Y8r=o("FlaxBartForConditionalGeneration"),K8r=o(" (BART model)"),Z8r=l(),HE=a("li"),MTe=a("strong"),exr=o("bert"),oxr=o(" \u2014 "),qJ=a("a"),rxr=o("FlaxBertForPreTraining"),txr=o(" (BERT model)"),axr=l(),UE=a("li"),ETe=a("strong"),nxr=o("big_bird"),sxr=o(" \u2014 "),NJ=a("a"),lxr=o("FlaxBigBirdForPreTraining"),ixr=o(" (BigBird model)"),dxr=l(),JE=a("li"),CTe=a("strong"),cxr=o("electra"),fxr=o(" \u2014 "),jJ=a("a"),mxr=o("FlaxElectraForPreTraining"),gxr=o(" (ELECTRA model)"),hxr=l(),YE=a("li"),wTe=a("strong"),pxr=o("mbart"),uxr=o(" \u2014 "),DJ=a("a"),_xr=o("FlaxMBartForConditionalGeneration"),bxr=o(" (mBART model)"),vxr=l(),KE=a("li"),ATe=a("strong"),Fxr=o("mt5"),Txr=o(" \u2014 "),GJ=a("a"),Mxr=o("FlaxMT5ForConditionalGeneration"),Exr=o(" (mT5 model)"),Cxr=l(),ZE=a("li"),yTe=a("strong"),wxr=o("roberta"),Axr=o(" \u2014 "),OJ=a("a"),yxr=o("FlaxRobertaForMaskedLM"),Lxr=o(" (RoBERTa model)"),xxr=l(),e5=a("li"),LTe=a("strong"),$xr=o("roformer"),kxr=o(" \u2014 "),VJ=a("a"),Sxr=o("FlaxRoFormerForMaskedLM"),Rxr=o(" (RoFormer model)"),Bxr=l(),o5=a("li"),xTe=a("strong"),Pxr=o("t5"),Ixr=o(" \u2014 "),XJ=a("a"),qxr=o("FlaxT5ForConditionalGeneration"),Nxr=o(" (T5 model)"),jxr=l(),r5=a("li"),$Te=a("strong"),Dxr=o("wav2vec2"),Gxr=o(" \u2014 "),zJ=a("a"),Oxr=o("FlaxWav2Vec2ForPreTraining"),Vxr=o(" (Wav2Vec2 model)"),Xxr=l(),t5=a("li"),kTe=a("strong"),zxr=o("xlm-roberta"),Qxr=o(" \u2014 "),QJ=a("a"),Wxr=o("FlaxXLMRobertaForMaskedLM"),Hxr=o(" (XLM-RoBERTa model)"),Uxr=l(),F(a5.$$.fragment),lNe=l(),Ic=a("h2"),n5=a("a"),STe=a("span"),F(bx.$$.fragment),Jxr=l(),RTe=a("span"),Yxr=o("FlaxAutoModelForMaskedLM"),iNe=l(),hr=a("div"),F(vx.$$.fragment),Kxr=l(),qc=a("p"),Zxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WJ=a("a"),e9r=o("from_pretrained()"),o9r=o(" class method or the "),HJ=a("a"),r9r=o("from_config()"),t9r=o(` class
method.`),a9r=l(),Fx=a("p"),n9r=o("This class cannot be instantiated directly using "),BTe=a("code"),s9r=o("__init__()"),l9r=o(" (throws an error)."),i9r=l(),Ot=a("div"),F(Tx.$$.fragment),d9r=l(),PTe=a("p"),c9r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),f9r=l(),Nc=a("p"),m9r=o(`Note:
Loading a model from its configuration file does `),ITe=a("strong"),g9r=o("not"),h9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UJ=a("a"),p9r=o("from_pretrained()"),u9r=o(" to load the model weights."),_9r=l(),F(s5.$$.fragment),b9r=l(),Or=a("div"),F(Mx.$$.fragment),v9r=l(),qTe=a("p"),F9r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),T9r=l(),un=a("p"),M9r=o("The model class to instantiate is selected based on the "),NTe=a("code"),E9r=o("model_type"),C9r=o(` property of the config object (either
passed as an argument or loaded from `),jTe=a("code"),w9r=o("pretrained_model_name_or_path"),A9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DTe=a("code"),y9r=o("pretrained_model_name_or_path"),L9r=o(":"),x9r=l(),Le=a("ul"),l5=a("li"),GTe=a("strong"),$9r=o("albert"),k9r=o(" \u2014 "),JJ=a("a"),S9r=o("FlaxAlbertForMaskedLM"),R9r=o(" (ALBERT model)"),B9r=l(),i5=a("li"),OTe=a("strong"),P9r=o("bart"),I9r=o(" \u2014 "),YJ=a("a"),q9r=o("FlaxBartForConditionalGeneration"),N9r=o(" (BART model)"),j9r=l(),d5=a("li"),VTe=a("strong"),D9r=o("bert"),G9r=o(" \u2014 "),KJ=a("a"),O9r=o("FlaxBertForMaskedLM"),V9r=o(" (BERT model)"),X9r=l(),c5=a("li"),XTe=a("strong"),z9r=o("big_bird"),Q9r=o(" \u2014 "),ZJ=a("a"),W9r=o("FlaxBigBirdForMaskedLM"),H9r=o(" (BigBird model)"),U9r=l(),f5=a("li"),zTe=a("strong"),J9r=o("distilbert"),Y9r=o(" \u2014 "),eY=a("a"),K9r=o("FlaxDistilBertForMaskedLM"),Z9r=o(" (DistilBERT model)"),e$r=l(),m5=a("li"),QTe=a("strong"),o$r=o("electra"),r$r=o(" \u2014 "),oY=a("a"),t$r=o("FlaxElectraForMaskedLM"),a$r=o(" (ELECTRA model)"),n$r=l(),g5=a("li"),WTe=a("strong"),s$r=o("mbart"),l$r=o(" \u2014 "),rY=a("a"),i$r=o("FlaxMBartForConditionalGeneration"),d$r=o(" (mBART model)"),c$r=l(),h5=a("li"),HTe=a("strong"),f$r=o("roberta"),m$r=o(" \u2014 "),tY=a("a"),g$r=o("FlaxRobertaForMaskedLM"),h$r=o(" (RoBERTa model)"),p$r=l(),p5=a("li"),UTe=a("strong"),u$r=o("roformer"),_$r=o(" \u2014 "),aY=a("a"),b$r=o("FlaxRoFormerForMaskedLM"),v$r=o(" (RoFormer model)"),F$r=l(),u5=a("li"),JTe=a("strong"),T$r=o("xlm-roberta"),M$r=o(" \u2014 "),nY=a("a"),E$r=o("FlaxXLMRobertaForMaskedLM"),C$r=o(" (XLM-RoBERTa model)"),w$r=l(),F(_5.$$.fragment),dNe=l(),jc=a("h2"),b5=a("a"),YTe=a("span"),F(Ex.$$.fragment),A$r=l(),KTe=a("span"),y$r=o("FlaxAutoModelForSeq2SeqLM"),cNe=l(),pr=a("div"),F(Cx.$$.fragment),L$r=l(),Dc=a("p"),x$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),sY=a("a"),$$r=o("from_pretrained()"),k$r=o(" class method or the "),lY=a("a"),S$r=o("from_config()"),R$r=o(` class
method.`),B$r=l(),wx=a("p"),P$r=o("This class cannot be instantiated directly using "),ZTe=a("code"),I$r=o("__init__()"),q$r=o(" (throws an error)."),N$r=l(),Vt=a("div"),F(Ax.$$.fragment),j$r=l(),e7e=a("p"),D$r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),G$r=l(),Gc=a("p"),O$r=o(`Note:
Loading a model from its configuration file does `),o7e=a("strong"),V$r=o("not"),X$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=a("a"),z$r=o("from_pretrained()"),Q$r=o(" to load the model weights."),W$r=l(),F(v5.$$.fragment),H$r=l(),Vr=a("div"),F(yx.$$.fragment),U$r=l(),r7e=a("p"),J$r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Y$r=l(),_n=a("p"),K$r=o("The model class to instantiate is selected based on the "),t7e=a("code"),Z$r=o("model_type"),ekr=o(` property of the config object (either
passed as an argument or loaded from `),a7e=a("code"),okr=o("pretrained_model_name_or_path"),rkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=a("code"),tkr=o("pretrained_model_name_or_path"),akr=o(":"),nkr=l(),Se=a("ul"),F5=a("li"),s7e=a("strong"),skr=o("bart"),lkr=o(" \u2014 "),dY=a("a"),ikr=o("FlaxBartForConditionalGeneration"),dkr=o(" (BART model)"),ckr=l(),T5=a("li"),l7e=a("strong"),fkr=o("blenderbot"),mkr=o(" \u2014 "),cY=a("a"),gkr=o("FlaxBlenderbotForConditionalGeneration"),hkr=o(" (Blenderbot model)"),pkr=l(),M5=a("li"),i7e=a("strong"),ukr=o("blenderbot-small"),_kr=o(" \u2014 "),fY=a("a"),bkr=o("FlaxBlenderbotSmallForConditionalGeneration"),vkr=o(" (BlenderbotSmall model)"),Fkr=l(),E5=a("li"),d7e=a("strong"),Tkr=o("encoder-decoder"),Mkr=o(" \u2014 "),mY=a("a"),Ekr=o("FlaxEncoderDecoderModel"),Ckr=o(" (Encoder decoder model)"),wkr=l(),C5=a("li"),c7e=a("strong"),Akr=o("marian"),ykr=o(" \u2014 "),gY=a("a"),Lkr=o("FlaxMarianMTModel"),xkr=o(" (Marian model)"),$kr=l(),w5=a("li"),f7e=a("strong"),kkr=o("mbart"),Skr=o(" \u2014 "),hY=a("a"),Rkr=o("FlaxMBartForConditionalGeneration"),Bkr=o(" (mBART model)"),Pkr=l(),A5=a("li"),m7e=a("strong"),Ikr=o("mt5"),qkr=o(" \u2014 "),pY=a("a"),Nkr=o("FlaxMT5ForConditionalGeneration"),jkr=o(" (mT5 model)"),Dkr=l(),y5=a("li"),g7e=a("strong"),Gkr=o("pegasus"),Okr=o(" \u2014 "),uY=a("a"),Vkr=o("FlaxPegasusForConditionalGeneration"),Xkr=o(" (Pegasus model)"),zkr=l(),L5=a("li"),h7e=a("strong"),Qkr=o("t5"),Wkr=o(" \u2014 "),_Y=a("a"),Hkr=o("FlaxT5ForConditionalGeneration"),Ukr=o(" (T5 model)"),Jkr=l(),F(x5.$$.fragment),fNe=l(),Oc=a("h2"),$5=a("a"),p7e=a("span"),F(Lx.$$.fragment),Ykr=l(),u7e=a("span"),Kkr=o("FlaxAutoModelForSequenceClassification"),mNe=l(),ur=a("div"),F(xx.$$.fragment),Zkr=l(),Vc=a("p"),eSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),bY=a("a"),oSr=o("from_pretrained()"),rSr=o(" class method or the "),vY=a("a"),tSr=o("from_config()"),aSr=o(` class
method.`),nSr=l(),$x=a("p"),sSr=o("This class cannot be instantiated directly using "),_7e=a("code"),lSr=o("__init__()"),iSr=o(" (throws an error)."),dSr=l(),Xt=a("div"),F(kx.$$.fragment),cSr=l(),b7e=a("p"),fSr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),mSr=l(),Xc=a("p"),gSr=o(`Note:
Loading a model from its configuration file does `),v7e=a("strong"),hSr=o("not"),pSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FY=a("a"),uSr=o("from_pretrained()"),_Sr=o(" to load the model weights."),bSr=l(),F(k5.$$.fragment),vSr=l(),Xr=a("div"),F(Sx.$$.fragment),FSr=l(),F7e=a("p"),TSr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),MSr=l(),bn=a("p"),ESr=o("The model class to instantiate is selected based on the "),T7e=a("code"),CSr=o("model_type"),wSr=o(` property of the config object (either
passed as an argument or loaded from `),M7e=a("code"),ASr=o("pretrained_model_name_or_path"),ySr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E7e=a("code"),LSr=o("pretrained_model_name_or_path"),xSr=o(":"),$Sr=l(),xe=a("ul"),S5=a("li"),C7e=a("strong"),kSr=o("albert"),SSr=o(" \u2014 "),TY=a("a"),RSr=o("FlaxAlbertForSequenceClassification"),BSr=o(" (ALBERT model)"),PSr=l(),R5=a("li"),w7e=a("strong"),ISr=o("bart"),qSr=o(" \u2014 "),MY=a("a"),NSr=o("FlaxBartForSequenceClassification"),jSr=o(" (BART model)"),DSr=l(),B5=a("li"),A7e=a("strong"),GSr=o("bert"),OSr=o(" \u2014 "),EY=a("a"),VSr=o("FlaxBertForSequenceClassification"),XSr=o(" (BERT model)"),zSr=l(),P5=a("li"),y7e=a("strong"),QSr=o("big_bird"),WSr=o(" \u2014 "),CY=a("a"),HSr=o("FlaxBigBirdForSequenceClassification"),USr=o(" (BigBird model)"),JSr=l(),I5=a("li"),L7e=a("strong"),YSr=o("distilbert"),KSr=o(" \u2014 "),wY=a("a"),ZSr=o("FlaxDistilBertForSequenceClassification"),eRr=o(" (DistilBERT model)"),oRr=l(),q5=a("li"),x7e=a("strong"),rRr=o("electra"),tRr=o(" \u2014 "),AY=a("a"),aRr=o("FlaxElectraForSequenceClassification"),nRr=o(" (ELECTRA model)"),sRr=l(),N5=a("li"),$7e=a("strong"),lRr=o("mbart"),iRr=o(" \u2014 "),yY=a("a"),dRr=o("FlaxMBartForSequenceClassification"),cRr=o(" (mBART model)"),fRr=l(),j5=a("li"),k7e=a("strong"),mRr=o("roberta"),gRr=o(" \u2014 "),LY=a("a"),hRr=o("FlaxRobertaForSequenceClassification"),pRr=o(" (RoBERTa model)"),uRr=l(),D5=a("li"),S7e=a("strong"),_Rr=o("roformer"),bRr=o(" \u2014 "),xY=a("a"),vRr=o("FlaxRoFormerForSequenceClassification"),FRr=o(" (RoFormer model)"),TRr=l(),G5=a("li"),R7e=a("strong"),MRr=o("xlm-roberta"),ERr=o(" \u2014 "),$Y=a("a"),CRr=o("FlaxXLMRobertaForSequenceClassification"),wRr=o(" (XLM-RoBERTa model)"),ARr=l(),F(O5.$$.fragment),gNe=l(),zc=a("h2"),V5=a("a"),B7e=a("span"),F(Rx.$$.fragment),yRr=l(),P7e=a("span"),LRr=o("FlaxAutoModelForQuestionAnswering"),hNe=l(),_r=a("div"),F(Bx.$$.fragment),xRr=l(),Qc=a("p"),$Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),kY=a("a"),kRr=o("from_pretrained()"),SRr=o(" class method or the "),SY=a("a"),RRr=o("from_config()"),BRr=o(` class
method.`),PRr=l(),Px=a("p"),IRr=o("This class cannot be instantiated directly using "),I7e=a("code"),qRr=o("__init__()"),NRr=o(" (throws an error)."),jRr=l(),zt=a("div"),F(Ix.$$.fragment),DRr=l(),q7e=a("p"),GRr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ORr=l(),Wc=a("p"),VRr=o(`Note:
Loading a model from its configuration file does `),N7e=a("strong"),XRr=o("not"),zRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=a("a"),QRr=o("from_pretrained()"),WRr=o(" to load the model weights."),HRr=l(),F(X5.$$.fragment),URr=l(),zr=a("div"),F(qx.$$.fragment),JRr=l(),j7e=a("p"),YRr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),KRr=l(),vn=a("p"),ZRr=o("The model class to instantiate is selected based on the "),D7e=a("code"),eBr=o("model_type"),oBr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),rBr=o("pretrained_model_name_or_path"),tBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),aBr=o("pretrained_model_name_or_path"),nBr=o(":"),sBr=l(),$e=a("ul"),z5=a("li"),V7e=a("strong"),lBr=o("albert"),iBr=o(" \u2014 "),BY=a("a"),dBr=o("FlaxAlbertForQuestionAnswering"),cBr=o(" (ALBERT model)"),fBr=l(),Q5=a("li"),X7e=a("strong"),mBr=o("bart"),gBr=o(" \u2014 "),PY=a("a"),hBr=o("FlaxBartForQuestionAnswering"),pBr=o(" (BART model)"),uBr=l(),W5=a("li"),z7e=a("strong"),_Br=o("bert"),bBr=o(" \u2014 "),IY=a("a"),vBr=o("FlaxBertForQuestionAnswering"),FBr=o(" (BERT model)"),TBr=l(),H5=a("li"),Q7e=a("strong"),MBr=o("big_bird"),EBr=o(" \u2014 "),qY=a("a"),CBr=o("FlaxBigBirdForQuestionAnswering"),wBr=o(" (BigBird model)"),ABr=l(),U5=a("li"),W7e=a("strong"),yBr=o("distilbert"),LBr=o(" \u2014 "),NY=a("a"),xBr=o("FlaxDistilBertForQuestionAnswering"),$Br=o(" (DistilBERT model)"),kBr=l(),J5=a("li"),H7e=a("strong"),SBr=o("electra"),RBr=o(" \u2014 "),jY=a("a"),BBr=o("FlaxElectraForQuestionAnswering"),PBr=o(" (ELECTRA model)"),IBr=l(),Y5=a("li"),U7e=a("strong"),qBr=o("mbart"),NBr=o(" \u2014 "),DY=a("a"),jBr=o("FlaxMBartForQuestionAnswering"),DBr=o(" (mBART model)"),GBr=l(),K5=a("li"),J7e=a("strong"),OBr=o("roberta"),VBr=o(" \u2014 "),GY=a("a"),XBr=o("FlaxRobertaForQuestionAnswering"),zBr=o(" (RoBERTa model)"),QBr=l(),Z5=a("li"),Y7e=a("strong"),WBr=o("roformer"),HBr=o(" \u2014 "),OY=a("a"),UBr=o("FlaxRoFormerForQuestionAnswering"),JBr=o(" (RoFormer model)"),YBr=l(),eC=a("li"),K7e=a("strong"),KBr=o("xlm-roberta"),ZBr=o(" \u2014 "),VY=a("a"),ePr=o("FlaxXLMRobertaForQuestionAnswering"),oPr=o(" (XLM-RoBERTa model)"),rPr=l(),F(oC.$$.fragment),pNe=l(),Hc=a("h2"),rC=a("a"),Z7e=a("span"),F(Nx.$$.fragment),tPr=l(),eMe=a("span"),aPr=o("FlaxAutoModelForTokenClassification"),uNe=l(),br=a("div"),F(jx.$$.fragment),nPr=l(),Uc=a("p"),sPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),XY=a("a"),lPr=o("from_pretrained()"),iPr=o(" class method or the "),zY=a("a"),dPr=o("from_config()"),cPr=o(` class
method.`),fPr=l(),Dx=a("p"),mPr=o("This class cannot be instantiated directly using "),oMe=a("code"),gPr=o("__init__()"),hPr=o(" (throws an error)."),pPr=l(),Qt=a("div"),F(Gx.$$.fragment),uPr=l(),rMe=a("p"),_Pr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),bPr=l(),Jc=a("p"),vPr=o(`Note:
Loading a model from its configuration file does `),tMe=a("strong"),FPr=o("not"),TPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=a("a"),MPr=o("from_pretrained()"),EPr=o(" to load the model weights."),CPr=l(),F(tC.$$.fragment),wPr=l(),Qr=a("div"),F(Ox.$$.fragment),APr=l(),aMe=a("p"),yPr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),LPr=l(),Fn=a("p"),xPr=o("The model class to instantiate is selected based on the "),nMe=a("code"),$Pr=o("model_type"),kPr=o(` property of the config object (either
passed as an argument or loaded from `),sMe=a("code"),SPr=o("pretrained_model_name_or_path"),RPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lMe=a("code"),BPr=o("pretrained_model_name_or_path"),PPr=o(":"),IPr=l(),De=a("ul"),aC=a("li"),iMe=a("strong"),qPr=o("albert"),NPr=o(" \u2014 "),WY=a("a"),jPr=o("FlaxAlbertForTokenClassification"),DPr=o(" (ALBERT model)"),GPr=l(),nC=a("li"),dMe=a("strong"),OPr=o("bert"),VPr=o(" \u2014 "),HY=a("a"),XPr=o("FlaxBertForTokenClassification"),zPr=o(" (BERT model)"),QPr=l(),sC=a("li"),cMe=a("strong"),WPr=o("big_bird"),HPr=o(" \u2014 "),UY=a("a"),UPr=o("FlaxBigBirdForTokenClassification"),JPr=o(" (BigBird model)"),YPr=l(),lC=a("li"),fMe=a("strong"),KPr=o("distilbert"),ZPr=o(" \u2014 "),JY=a("a"),eIr=o("FlaxDistilBertForTokenClassification"),oIr=o(" (DistilBERT model)"),rIr=l(),iC=a("li"),mMe=a("strong"),tIr=o("electra"),aIr=o(" \u2014 "),YY=a("a"),nIr=o("FlaxElectraForTokenClassification"),sIr=o(" (ELECTRA model)"),lIr=l(),dC=a("li"),gMe=a("strong"),iIr=o("roberta"),dIr=o(" \u2014 "),KY=a("a"),cIr=o("FlaxRobertaForTokenClassification"),fIr=o(" (RoBERTa model)"),mIr=l(),cC=a("li"),hMe=a("strong"),gIr=o("roformer"),hIr=o(" \u2014 "),ZY=a("a"),pIr=o("FlaxRoFormerForTokenClassification"),uIr=o(" (RoFormer model)"),_Ir=l(),fC=a("li"),pMe=a("strong"),bIr=o("xlm-roberta"),vIr=o(" \u2014 "),eK=a("a"),FIr=o("FlaxXLMRobertaForTokenClassification"),TIr=o(" (XLM-RoBERTa model)"),MIr=l(),F(mC.$$.fragment),_Ne=l(),Yc=a("h2"),gC=a("a"),uMe=a("span"),F(Vx.$$.fragment),EIr=l(),_Me=a("span"),CIr=o("FlaxAutoModelForMultipleChoice"),bNe=l(),vr=a("div"),F(Xx.$$.fragment),wIr=l(),Kc=a("p"),AIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),oK=a("a"),yIr=o("from_pretrained()"),LIr=o(" class method or the "),rK=a("a"),xIr=o("from_config()"),$Ir=o(` class
method.`),kIr=l(),zx=a("p"),SIr=o("This class cannot be instantiated directly using "),bMe=a("code"),RIr=o("__init__()"),BIr=o(" (throws an error)."),PIr=l(),Wt=a("div"),F(Qx.$$.fragment),IIr=l(),vMe=a("p"),qIr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),NIr=l(),Zc=a("p"),jIr=o(`Note:
Loading a model from its configuration file does `),FMe=a("strong"),DIr=o("not"),GIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=a("a"),OIr=o("from_pretrained()"),VIr=o(" to load the model weights."),XIr=l(),F(hC.$$.fragment),zIr=l(),Wr=a("div"),F(Wx.$$.fragment),QIr=l(),TMe=a("p"),WIr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),HIr=l(),Tn=a("p"),UIr=o("The model class to instantiate is selected based on the "),MMe=a("code"),JIr=o("model_type"),YIr=o(` property of the config object (either
passed as an argument or loaded from `),EMe=a("code"),KIr=o("pretrained_model_name_or_path"),ZIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CMe=a("code"),eqr=o("pretrained_model_name_or_path"),oqr=o(":"),rqr=l(),Ge=a("ul"),pC=a("li"),wMe=a("strong"),tqr=o("albert"),aqr=o(" \u2014 "),aK=a("a"),nqr=o("FlaxAlbertForMultipleChoice"),sqr=o(" (ALBERT model)"),lqr=l(),uC=a("li"),AMe=a("strong"),iqr=o("bert"),dqr=o(" \u2014 "),nK=a("a"),cqr=o("FlaxBertForMultipleChoice"),fqr=o(" (BERT model)"),mqr=l(),_C=a("li"),yMe=a("strong"),gqr=o("big_bird"),hqr=o(" \u2014 "),sK=a("a"),pqr=o("FlaxBigBirdForMultipleChoice"),uqr=o(" (BigBird model)"),_qr=l(),bC=a("li"),LMe=a("strong"),bqr=o("distilbert"),vqr=o(" \u2014 "),lK=a("a"),Fqr=o("FlaxDistilBertForMultipleChoice"),Tqr=o(" (DistilBERT model)"),Mqr=l(),vC=a("li"),xMe=a("strong"),Eqr=o("electra"),Cqr=o(" \u2014 "),iK=a("a"),wqr=o("FlaxElectraForMultipleChoice"),Aqr=o(" (ELECTRA model)"),yqr=l(),FC=a("li"),$Me=a("strong"),Lqr=o("roberta"),xqr=o(" \u2014 "),dK=a("a"),$qr=o("FlaxRobertaForMultipleChoice"),kqr=o(" (RoBERTa model)"),Sqr=l(),TC=a("li"),kMe=a("strong"),Rqr=o("roformer"),Bqr=o(" \u2014 "),cK=a("a"),Pqr=o("FlaxRoFormerForMultipleChoice"),Iqr=o(" (RoFormer model)"),qqr=l(),MC=a("li"),SMe=a("strong"),Nqr=o("xlm-roberta"),jqr=o(" \u2014 "),fK=a("a"),Dqr=o("FlaxXLMRobertaForMultipleChoice"),Gqr=o(" (XLM-RoBERTa model)"),Oqr=l(),F(EC.$$.fragment),vNe=l(),ef=a("h2"),CC=a("a"),RMe=a("span"),F(Hx.$$.fragment),Vqr=l(),BMe=a("span"),Xqr=o("FlaxAutoModelForNextSentencePrediction"),FNe=l(),Fr=a("div"),F(Ux.$$.fragment),zqr=l(),of=a("p"),Qqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mK=a("a"),Wqr=o("from_pretrained()"),Hqr=o(" class method or the "),gK=a("a"),Uqr=o("from_config()"),Jqr=o(` class
method.`),Yqr=l(),Jx=a("p"),Kqr=o("This class cannot be instantiated directly using "),PMe=a("code"),Zqr=o("__init__()"),eNr=o(" (throws an error)."),oNr=l(),Ht=a("div"),F(Yx.$$.fragment),rNr=l(),IMe=a("p"),tNr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),aNr=l(),rf=a("p"),nNr=o(`Note:
Loading a model from its configuration file does `),qMe=a("strong"),sNr=o("not"),lNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hK=a("a"),iNr=o("from_pretrained()"),dNr=o(" to load the model weights."),cNr=l(),F(wC.$$.fragment),fNr=l(),Hr=a("div"),F(Kx.$$.fragment),mNr=l(),NMe=a("p"),gNr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hNr=l(),Mn=a("p"),pNr=o("The model class to instantiate is selected based on the "),jMe=a("code"),uNr=o("model_type"),_Nr=o(` property of the config object (either
passed as an argument or loaded from `),DMe=a("code"),bNr=o("pretrained_model_name_or_path"),vNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GMe=a("code"),FNr=o("pretrained_model_name_or_path"),TNr=o(":"),MNr=l(),OMe=a("ul"),AC=a("li"),VMe=a("strong"),ENr=o("bert"),CNr=o(" \u2014 "),pK=a("a"),wNr=o("FlaxBertForNextSentencePrediction"),ANr=o(" (BERT model)"),yNr=l(),F(yC.$$.fragment),TNe=l(),tf=a("h2"),LC=a("a"),XMe=a("span"),F(Zx.$$.fragment),LNr=l(),zMe=a("span"),xNr=o("FlaxAutoModelForImageClassification"),MNe=l(),Tr=a("div"),F(e9.$$.fragment),$Nr=l(),af=a("p"),kNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),uK=a("a"),SNr=o("from_pretrained()"),RNr=o(" class method or the "),_K=a("a"),BNr=o("from_config()"),PNr=o(` class
method.`),INr=l(),o9=a("p"),qNr=o("This class cannot be instantiated directly using "),QMe=a("code"),NNr=o("__init__()"),jNr=o(" (throws an error)."),DNr=l(),Ut=a("div"),F(r9.$$.fragment),GNr=l(),WMe=a("p"),ONr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),VNr=l(),nf=a("p"),XNr=o(`Note:
Loading a model from its configuration file does `),HMe=a("strong"),zNr=o("not"),QNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=a("a"),WNr=o("from_pretrained()"),HNr=o(" to load the model weights."),UNr=l(),F(xC.$$.fragment),JNr=l(),Ur=a("div"),F(t9.$$.fragment),YNr=l(),UMe=a("p"),KNr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),ZNr=l(),En=a("p"),ejr=o("The model class to instantiate is selected based on the "),JMe=a("code"),ojr=o("model_type"),rjr=o(` property of the config object (either
passed as an argument or loaded from `),YMe=a("code"),tjr=o("pretrained_model_name_or_path"),ajr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=a("code"),njr=o("pretrained_model_name_or_path"),sjr=o(":"),ljr=l(),a9=a("ul"),$C=a("li"),ZMe=a("strong"),ijr=o("beit"),djr=o(" \u2014 "),vK=a("a"),cjr=o("FlaxBeitForImageClassification"),fjr=o(" (BEiT model)"),mjr=l(),kC=a("li"),e4e=a("strong"),gjr=o("vit"),hjr=o(" \u2014 "),FK=a("a"),pjr=o("FlaxViTForImageClassification"),ujr=o(" (ViT model)"),_jr=l(),F(SC.$$.fragment),ENe=l(),sf=a("h2"),RC=a("a"),o4e=a("span"),F(n9.$$.fragment),bjr=l(),r4e=a("span"),vjr=o("FlaxAutoModelForVision2Seq"),CNe=l(),Mr=a("div"),F(s9.$$.fragment),Fjr=l(),lf=a("p"),Tjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),TK=a("a"),Mjr=o("from_pretrained()"),Ejr=o(" class method or the "),MK=a("a"),Cjr=o("from_config()"),wjr=o(` class
method.`),Ajr=l(),l9=a("p"),yjr=o("This class cannot be instantiated directly using "),t4e=a("code"),Ljr=o("__init__()"),xjr=o(" (throws an error)."),$jr=l(),Jt=a("div"),F(i9.$$.fragment),kjr=l(),a4e=a("p"),Sjr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Rjr=l(),df=a("p"),Bjr=o(`Note:
Loading a model from its configuration file does `),n4e=a("strong"),Pjr=o("not"),Ijr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=a("a"),qjr=o("from_pretrained()"),Njr=o(" to load the model weights."),jjr=l(),F(BC.$$.fragment),Djr=l(),Jr=a("div"),F(d9.$$.fragment),Gjr=l(),s4e=a("p"),Ojr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Vjr=l(),Cn=a("p"),Xjr=o("The model class to instantiate is selected based on the "),l4e=a("code"),zjr=o("model_type"),Qjr=o(` property of the config object (either
passed as an argument or loaded from `),i4e=a("code"),Wjr=o("pretrained_model_name_or_path"),Hjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d4e=a("code"),Ujr=o("pretrained_model_name_or_path"),Jjr=o(":"),Yjr=l(),c4e=a("ul"),PC=a("li"),f4e=a("strong"),Kjr=o("vision-encoder-decoder"),Zjr=o(" \u2014 "),CK=a("a"),eDr=o("FlaxVisionEncoderDecoderModel"),oDr=o(" (Vision Encoder decoder model)"),rDr=l(),F(IC.$$.fragment),this.h()},l(f){const _=Hyt('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var c9=s(p);m=n(c9,"A",{id:!0,class:!0,href:!0});var m4e=s(m);u=n(m4e,"SPAN",{});var g4e=s(u);T(d.$$.fragment,g4e),g4e.forEach(t),m4e.forEach(t),h=i(c9),Mo=n(c9,"SPAN",{});var h4e=s(Mo);ii=r(h4e,"Auto Classes"),h4e.forEach(t),c9.forEach(t),gf=i(f),et=n(f,"P",{});var f9=s(et);di=r(f9,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ci=n(f9,"CODE",{});var p4e=s(ci);oA=r(p4e,"from_pretrained()"),p4e.forEach(t),hf=r(f9,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),f9.forEach(t),qe=i(f),Xe=n(f,"P",{});var wn=s(Xe);fi=r(wn,"Instantiating one of "),An=n(wn,"A",{href:!0});var u4e=s(An);rA=r(u4e,"AutoConfig"),u4e.forEach(t),yn=r(wn,", "),Ln=n(wn,"A",{href:!0});var _4e=s(Ln);tA=r(_4e,"AutoModel"),_4e.forEach(t),mi=r(wn,`, and
`),xn=n(wn,"A",{href:!0});var b4e=s(xn);aA=r(b4e,"AutoTokenizer"),b4e.forEach(t),gi=r(wn," will directly create a class of the relevant architecture. For instance"),wn.forEach(t),pf=i(f),T(Ma.$$.fragment,f),ze=i(f),Ae=n(f,"P",{});var m9=s(Ae);E$=r(m9,"will create a model that is an instance of "),hi=n(m9,"A",{href:!0});var v4e=s(hi);C$=r(v4e,"BertModel"),v4e.forEach(t),w$=r(m9,"."),m9.forEach(t),Eo=i(f),Ea=n(f,"P",{});var g9=s(Ea);A$=r(g9,"There is one class of "),uf=n(g9,"CODE",{});var F4e=s(uf);y$=r(F4e,"AutoModel"),F4e.forEach(t),RDe=r(g9," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),g9.forEach(t),MIe=i(f),pi=n(f,"H2",{class:!0});var h9=s(pi);_f=n(h9,"A",{id:!0,class:!0,href:!0});var T4e=s(_f);bee=n(T4e,"SPAN",{});var M4e=s(bee);T(nA.$$.fragment,M4e),M4e.forEach(t),T4e.forEach(t),BDe=i(h9),vee=n(h9,"SPAN",{});var E4e=s(vee);PDe=r(E4e,"Extending the Auto Classes"),E4e.forEach(t),h9.forEach(t),EIe=i(f),$n=n(f,"P",{});var cf=s($n);IDe=r(cf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Fee=n(cf,"CODE",{});var C4e=s(Fee);qDe=r(C4e,"NewModel"),C4e.forEach(t),NDe=r(cf,", make sure you have a "),Tee=n(cf,"CODE",{});var w4e=s(Tee);jDe=r(w4e,"NewModelConfig"),w4e.forEach(t),DDe=r(cf,` then you can add those to the auto
classes like this:`),cf.forEach(t),CIe=i(f),T(sA.$$.fragment,f),wIe=i(f),L$=n(f,"P",{});var A4e=s(L$);GDe=r(A4e,"You will then be able to use the auto classes like you would usually do!"),A4e.forEach(t),AIe=i(f),T(bf.$$.fragment,f),yIe=i(f),ui=n(f,"H2",{class:!0});var p9=s(ui);vf=n(p9,"A",{id:!0,class:!0,href:!0});var y4e=s(vf);Mee=n(y4e,"SPAN",{});var L4e=s(Mee);T(lA.$$.fragment,L4e),L4e.forEach(t),y4e.forEach(t),ODe=i(p9),Eee=n(p9,"SPAN",{});var x4e=s(Eee);VDe=r(x4e,"AutoConfig"),x4e.forEach(t),p9.forEach(t),LIe=i(f),Co=n(f,"DIV",{class:!0});var Kr=s(Co);T(iA.$$.fragment,Kr),XDe=i(Kr),dA=n(Kr,"P",{});var u9=s(dA);zDe=r(u9,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),x$=n(u9,"A",{href:!0});var $4e=s(x$);QDe=r($4e,"from_pretrained()"),$4e.forEach(t),WDe=r(u9," class method."),u9.forEach(t),HDe=i(Kr),cA=n(Kr,"P",{});var _9=s(cA);UDe=r(_9,"This class cannot be instantiated directly using "),Cee=n(_9,"CODE",{});var k4e=s(Cee);JDe=r(k4e,"__init__()"),k4e.forEach(t),YDe=r(_9," (throws an error)."),_9.forEach(t),KDe=i(Kr),Er=n(Kr,"DIV",{class:!0});var Zr=s(Er);T(fA.$$.fragment,Zr),ZDe=i(Zr),wee=n(Zr,"P",{});var S4e=s(wee);eGe=r(S4e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),S4e.forEach(t),oGe=i(Zr),_i=n(Zr,"P",{});var ff=s(_i);rGe=r(ff,"The configuration class to instantiate is selected based on the "),Aee=n(ff,"CODE",{});var R4e=s(Aee);tGe=r(R4e,"model_type"),R4e.forEach(t),aGe=r(ff,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),yee=n(ff,"CODE",{});var B4e=s(yee);nGe=r(B4e,"pretrained_model_name_or_path"),B4e.forEach(t),sGe=r(ff,":"),ff.forEach(t),lGe=i(Zr),A=n(Zr,"UL",{});var y=s(A);Ff=n(y,"LI",{});var qC=s(Ff);Lee=n(qC,"STRONG",{});var P4e=s(Lee);iGe=r(P4e,"albert"),P4e.forEach(t),dGe=r(qC," \u2014 "),$$=n(qC,"A",{href:!0});var I4e=s($$);cGe=r(I4e,"AlbertConfig"),I4e.forEach(t),fGe=r(qC," (ALBERT model)"),qC.forEach(t),mGe=i(y),Tf=n(y,"LI",{});var NC=s(Tf);xee=n(NC,"STRONG",{});var q4e=s(xee);gGe=r(q4e,"bart"),q4e.forEach(t),hGe=r(NC," \u2014 "),k$=n(NC,"A",{href:!0});var N4e=s(k$);pGe=r(N4e,"BartConfig"),N4e.forEach(t),uGe=r(NC," (BART model)"),NC.forEach(t),_Ge=i(y),Mf=n(y,"LI",{});var jC=s(Mf);$ee=n(jC,"STRONG",{});var j4e=s($ee);bGe=r(j4e,"beit"),j4e.forEach(t),vGe=r(jC," \u2014 "),S$=n(jC,"A",{href:!0});var D4e=s(S$);FGe=r(D4e,"BeitConfig"),D4e.forEach(t),TGe=r(jC," (BEiT model)"),jC.forEach(t),MGe=i(y),Ef=n(y,"LI",{});var DC=s(Ef);kee=n(DC,"STRONG",{});var G4e=s(kee);EGe=r(G4e,"bert"),G4e.forEach(t),CGe=r(DC," \u2014 "),R$=n(DC,"A",{href:!0});var O4e=s(R$);wGe=r(O4e,"BertConfig"),O4e.forEach(t),AGe=r(DC," (BERT model)"),DC.forEach(t),yGe=i(y),Cf=n(y,"LI",{});var GC=s(Cf);See=n(GC,"STRONG",{});var V4e=s(See);LGe=r(V4e,"bert-generation"),V4e.forEach(t),xGe=r(GC," \u2014 "),B$=n(GC,"A",{href:!0});var X4e=s(B$);$Ge=r(X4e,"BertGenerationConfig"),X4e.forEach(t),kGe=r(GC," (Bert Generation model)"),GC.forEach(t),SGe=i(y),wf=n(y,"LI",{});var OC=s(wf);Ree=n(OC,"STRONG",{});var z4e=s(Ree);RGe=r(z4e,"big_bird"),z4e.forEach(t),BGe=r(OC," \u2014 "),P$=n(OC,"A",{href:!0});var Q4e=s(P$);PGe=r(Q4e,"BigBirdConfig"),Q4e.forEach(t),IGe=r(OC," (BigBird model)"),OC.forEach(t),qGe=i(y),Af=n(y,"LI",{});var VC=s(Af);Bee=n(VC,"STRONG",{});var W4e=s(Bee);NGe=r(W4e,"bigbird_pegasus"),W4e.forEach(t),jGe=r(VC," \u2014 "),I$=n(VC,"A",{href:!0});var H4e=s(I$);DGe=r(H4e,"BigBirdPegasusConfig"),H4e.forEach(t),GGe=r(VC," (BigBirdPegasus model)"),VC.forEach(t),OGe=i(y),yf=n(y,"LI",{});var XC=s(yf);Pee=n(XC,"STRONG",{});var U4e=s(Pee);VGe=r(U4e,"blenderbot"),U4e.forEach(t),XGe=r(XC," \u2014 "),q$=n(XC,"A",{href:!0});var J4e=s(q$);zGe=r(J4e,"BlenderbotConfig"),J4e.forEach(t),QGe=r(XC," (Blenderbot model)"),XC.forEach(t),WGe=i(y),Lf=n(y,"LI",{});var zC=s(Lf);Iee=n(zC,"STRONG",{});var Y4e=s(Iee);HGe=r(Y4e,"blenderbot-small"),Y4e.forEach(t),UGe=r(zC," \u2014 "),N$=n(zC,"A",{href:!0});var K4e=s(N$);JGe=r(K4e,"BlenderbotSmallConfig"),K4e.forEach(t),YGe=r(zC," (BlenderbotSmall model)"),zC.forEach(t),KGe=i(y),xf=n(y,"LI",{});var QC=s(xf);qee=n(QC,"STRONG",{});var Z4e=s(qee);ZGe=r(Z4e,"camembert"),Z4e.forEach(t),eOe=r(QC," \u2014 "),j$=n(QC,"A",{href:!0});var eEe=s(j$);oOe=r(eEe,"CamembertConfig"),eEe.forEach(t),rOe=r(QC," (CamemBERT model)"),QC.forEach(t),tOe=i(y),$f=n(y,"LI",{});var WC=s($f);Nee=n(WC,"STRONG",{});var oEe=s(Nee);aOe=r(oEe,"canine"),oEe.forEach(t),nOe=r(WC," \u2014 "),D$=n(WC,"A",{href:!0});var rEe=s(D$);sOe=r(rEe,"CanineConfig"),rEe.forEach(t),lOe=r(WC," (Canine model)"),WC.forEach(t),iOe=i(y),kf=n(y,"LI",{});var HC=s(kf);jee=n(HC,"STRONG",{});var tEe=s(jee);dOe=r(tEe,"clip"),tEe.forEach(t),cOe=r(HC," \u2014 "),G$=n(HC,"A",{href:!0});var aEe=s(G$);fOe=r(aEe,"CLIPConfig"),aEe.forEach(t),mOe=r(HC," (CLIP model)"),HC.forEach(t),gOe=i(y),Sf=n(y,"LI",{});var UC=s(Sf);Dee=n(UC,"STRONG",{});var nEe=s(Dee);hOe=r(nEe,"convbert"),nEe.forEach(t),pOe=r(UC," \u2014 "),O$=n(UC,"A",{href:!0});var sEe=s(O$);uOe=r(sEe,"ConvBertConfig"),sEe.forEach(t),_Oe=r(UC," (ConvBERT model)"),UC.forEach(t),bOe=i(y),Rf=n(y,"LI",{});var JC=s(Rf);Gee=n(JC,"STRONG",{});var lEe=s(Gee);vOe=r(lEe,"convnext"),lEe.forEach(t),FOe=r(JC," \u2014 "),V$=n(JC,"A",{href:!0});var iEe=s(V$);TOe=r(iEe,"ConvNextConfig"),iEe.forEach(t),MOe=r(JC," (ConvNext model)"),JC.forEach(t),EOe=i(y),Bf=n(y,"LI",{});var YC=s(Bf);Oee=n(YC,"STRONG",{});var dEe=s(Oee);COe=r(dEe,"ctrl"),dEe.forEach(t),wOe=r(YC," \u2014 "),X$=n(YC,"A",{href:!0});var cEe=s(X$);AOe=r(cEe,"CTRLConfig"),cEe.forEach(t),yOe=r(YC," (CTRL model)"),YC.forEach(t),LOe=i(y),Pf=n(y,"LI",{});var KC=s(Pf);Vee=n(KC,"STRONG",{});var fEe=s(Vee);xOe=r(fEe,"data2vec-audio"),fEe.forEach(t),$Oe=r(KC," \u2014 "),z$=n(KC,"A",{href:!0});var mEe=s(z$);kOe=r(mEe,"Data2VecAudioConfig"),mEe.forEach(t),SOe=r(KC," (Data2VecAudio model)"),KC.forEach(t),ROe=i(y),If=n(y,"LI",{});var ZC=s(If);Xee=n(ZC,"STRONG",{});var gEe=s(Xee);BOe=r(gEe,"data2vec-text"),gEe.forEach(t),POe=r(ZC," \u2014 "),Q$=n(ZC,"A",{href:!0});var hEe=s(Q$);IOe=r(hEe,"Data2VecTextConfig"),hEe.forEach(t),qOe=r(ZC," (Data2VecText model)"),ZC.forEach(t),NOe=i(y),qf=n(y,"LI",{});var e3=s(qf);zee=n(e3,"STRONG",{});var pEe=s(zee);jOe=r(pEe,"data2vec-vision"),pEe.forEach(t),DOe=r(e3," \u2014 "),W$=n(e3,"A",{href:!0});var uEe=s(W$);GOe=r(uEe,"Data2VecVisionConfig"),uEe.forEach(t),OOe=r(e3," (Data2VecVision model)"),e3.forEach(t),VOe=i(y),Nf=n(y,"LI",{});var o3=s(Nf);Qee=n(o3,"STRONG",{});var _Ee=s(Qee);XOe=r(_Ee,"deberta"),_Ee.forEach(t),zOe=r(o3," \u2014 "),H$=n(o3,"A",{href:!0});var bEe=s(H$);QOe=r(bEe,"DebertaConfig"),bEe.forEach(t),WOe=r(o3," (DeBERTa model)"),o3.forEach(t),HOe=i(y),jf=n(y,"LI",{});var r3=s(jf);Wee=n(r3,"STRONG",{});var vEe=s(Wee);UOe=r(vEe,"deberta-v2"),vEe.forEach(t),JOe=r(r3," \u2014 "),U$=n(r3,"A",{href:!0});var FEe=s(U$);YOe=r(FEe,"DebertaV2Config"),FEe.forEach(t),KOe=r(r3," (DeBERTa-v2 model)"),r3.forEach(t),ZOe=i(y),Df=n(y,"LI",{});var t3=s(Df);Hee=n(t3,"STRONG",{});var TEe=s(Hee);eVe=r(TEe,"decision_transformer"),TEe.forEach(t),oVe=r(t3," \u2014 "),J$=n(t3,"A",{href:!0});var MEe=s(J$);rVe=r(MEe,"DecisionTransformerConfig"),MEe.forEach(t),tVe=r(t3," (Decision Transformer model)"),t3.forEach(t),aVe=i(y),Gf=n(y,"LI",{});var a3=s(Gf);Uee=n(a3,"STRONG",{});var EEe=s(Uee);nVe=r(EEe,"deit"),EEe.forEach(t),sVe=r(a3," \u2014 "),Y$=n(a3,"A",{href:!0});var CEe=s(Y$);lVe=r(CEe,"DeiTConfig"),CEe.forEach(t),iVe=r(a3," (DeiT model)"),a3.forEach(t),dVe=i(y),Of=n(y,"LI",{});var n3=s(Of);Jee=n(n3,"STRONG",{});var wEe=s(Jee);cVe=r(wEe,"detr"),wEe.forEach(t),fVe=r(n3," \u2014 "),K$=n(n3,"A",{href:!0});var aDr=s(K$);mVe=r(aDr,"DetrConfig"),aDr.forEach(t),gVe=r(n3," (DETR model)"),n3.forEach(t),hVe=i(y),Vf=n(y,"LI",{});var AEe=s(Vf);Yee=n(AEe,"STRONG",{});var nDr=s(Yee);pVe=r(nDr,"distilbert"),nDr.forEach(t),uVe=r(AEe," \u2014 "),Z$=n(AEe,"A",{href:!0});var sDr=s(Z$);_Ve=r(sDr,"DistilBertConfig"),sDr.forEach(t),bVe=r(AEe," (DistilBERT model)"),AEe.forEach(t),vVe=i(y),Xf=n(y,"LI",{});var yEe=s(Xf);Kee=n(yEe,"STRONG",{});var lDr=s(Kee);FVe=r(lDr,"dpr"),lDr.forEach(t),TVe=r(yEe," \u2014 "),ek=n(yEe,"A",{href:!0});var iDr=s(ek);MVe=r(iDr,"DPRConfig"),iDr.forEach(t),EVe=r(yEe," (DPR model)"),yEe.forEach(t),CVe=i(y),zf=n(y,"LI",{});var LEe=s(zf);Zee=n(LEe,"STRONG",{});var dDr=s(Zee);wVe=r(dDr,"dpt"),dDr.forEach(t),AVe=r(LEe," \u2014 "),ok=n(LEe,"A",{href:!0});var cDr=s(ok);yVe=r(cDr,"DPTConfig"),cDr.forEach(t),LVe=r(LEe," (DPT model)"),LEe.forEach(t),xVe=i(y),Qf=n(y,"LI",{});var xEe=s(Qf);eoe=n(xEe,"STRONG",{});var fDr=s(eoe);$Ve=r(fDr,"electra"),fDr.forEach(t),kVe=r(xEe," \u2014 "),rk=n(xEe,"A",{href:!0});var mDr=s(rk);SVe=r(mDr,"ElectraConfig"),mDr.forEach(t),RVe=r(xEe," (ELECTRA model)"),xEe.forEach(t),BVe=i(y),Wf=n(y,"LI",{});var $Ee=s(Wf);ooe=n($Ee,"STRONG",{});var gDr=s(ooe);PVe=r(gDr,"encoder-decoder"),gDr.forEach(t),IVe=r($Ee," \u2014 "),tk=n($Ee,"A",{href:!0});var hDr=s(tk);qVe=r(hDr,"EncoderDecoderConfig"),hDr.forEach(t),NVe=r($Ee," (Encoder decoder model)"),$Ee.forEach(t),jVe=i(y),Hf=n(y,"LI",{});var kEe=s(Hf);roe=n(kEe,"STRONG",{});var pDr=s(roe);DVe=r(pDr,"flaubert"),pDr.forEach(t),GVe=r(kEe," \u2014 "),ak=n(kEe,"A",{href:!0});var uDr=s(ak);OVe=r(uDr,"FlaubertConfig"),uDr.forEach(t),VVe=r(kEe," (FlauBERT model)"),kEe.forEach(t),XVe=i(y),Uf=n(y,"LI",{});var SEe=s(Uf);toe=n(SEe,"STRONG",{});var _Dr=s(toe);zVe=r(_Dr,"flava"),_Dr.forEach(t),QVe=r(SEe," \u2014 "),nk=n(SEe,"A",{href:!0});var bDr=s(nk);WVe=r(bDr,"FlavaConfig"),bDr.forEach(t),HVe=r(SEe," (Flava model)"),SEe.forEach(t),UVe=i(y),Jf=n(y,"LI",{});var REe=s(Jf);aoe=n(REe,"STRONG",{});var vDr=s(aoe);JVe=r(vDr,"fnet"),vDr.forEach(t),YVe=r(REe," \u2014 "),sk=n(REe,"A",{href:!0});var FDr=s(sk);KVe=r(FDr,"FNetConfig"),FDr.forEach(t),ZVe=r(REe," (FNet model)"),REe.forEach(t),eXe=i(y),Yf=n(y,"LI",{});var BEe=s(Yf);noe=n(BEe,"STRONG",{});var TDr=s(noe);oXe=r(TDr,"fsmt"),TDr.forEach(t),rXe=r(BEe," \u2014 "),lk=n(BEe,"A",{href:!0});var MDr=s(lk);tXe=r(MDr,"FSMTConfig"),MDr.forEach(t),aXe=r(BEe," (FairSeq Machine-Translation model)"),BEe.forEach(t),nXe=i(y),Kf=n(y,"LI",{});var PEe=s(Kf);soe=n(PEe,"STRONG",{});var EDr=s(soe);sXe=r(EDr,"funnel"),EDr.forEach(t),lXe=r(PEe," \u2014 "),ik=n(PEe,"A",{href:!0});var CDr=s(ik);iXe=r(CDr,"FunnelConfig"),CDr.forEach(t),dXe=r(PEe," (Funnel Transformer model)"),PEe.forEach(t),cXe=i(y),Zf=n(y,"LI",{});var IEe=s(Zf);loe=n(IEe,"STRONG",{});var wDr=s(loe);fXe=r(wDr,"glpn"),wDr.forEach(t),mXe=r(IEe," \u2014 "),dk=n(IEe,"A",{href:!0});var ADr=s(dk);gXe=r(ADr,"GLPNConfig"),ADr.forEach(t),hXe=r(IEe," (GLPN model)"),IEe.forEach(t),pXe=i(y),em=n(y,"LI",{});var qEe=s(em);ioe=n(qEe,"STRONG",{});var yDr=s(ioe);uXe=r(yDr,"gpt2"),yDr.forEach(t),_Xe=r(qEe," \u2014 "),ck=n(qEe,"A",{href:!0});var LDr=s(ck);bXe=r(LDr,"GPT2Config"),LDr.forEach(t),vXe=r(qEe," (OpenAI GPT-2 model)"),qEe.forEach(t),FXe=i(y),om=n(y,"LI",{});var NEe=s(om);doe=n(NEe,"STRONG",{});var xDr=s(doe);TXe=r(xDr,"gpt_neo"),xDr.forEach(t),MXe=r(NEe," \u2014 "),fk=n(NEe,"A",{href:!0});var $Dr=s(fk);EXe=r($Dr,"GPTNeoConfig"),$Dr.forEach(t),CXe=r(NEe," (GPT Neo model)"),NEe.forEach(t),wXe=i(y),rm=n(y,"LI",{});var jEe=s(rm);coe=n(jEe,"STRONG",{});var kDr=s(coe);AXe=r(kDr,"gptj"),kDr.forEach(t),yXe=r(jEe," \u2014 "),mk=n(jEe,"A",{href:!0});var SDr=s(mk);LXe=r(SDr,"GPTJConfig"),SDr.forEach(t),xXe=r(jEe," (GPT-J model)"),jEe.forEach(t),$Xe=i(y),tm=n(y,"LI",{});var DEe=s(tm);foe=n(DEe,"STRONG",{});var RDr=s(foe);kXe=r(RDr,"hubert"),RDr.forEach(t),SXe=r(DEe," \u2014 "),gk=n(DEe,"A",{href:!0});var BDr=s(gk);RXe=r(BDr,"HubertConfig"),BDr.forEach(t),BXe=r(DEe," (Hubert model)"),DEe.forEach(t),PXe=i(y),am=n(y,"LI",{});var GEe=s(am);moe=n(GEe,"STRONG",{});var PDr=s(moe);IXe=r(PDr,"ibert"),PDr.forEach(t),qXe=r(GEe," \u2014 "),hk=n(GEe,"A",{href:!0});var IDr=s(hk);NXe=r(IDr,"IBertConfig"),IDr.forEach(t),jXe=r(GEe," (I-BERT model)"),GEe.forEach(t),DXe=i(y),nm=n(y,"LI",{});var OEe=s(nm);goe=n(OEe,"STRONG",{});var qDr=s(goe);GXe=r(qDr,"imagegpt"),qDr.forEach(t),OXe=r(OEe," \u2014 "),pk=n(OEe,"A",{href:!0});var NDr=s(pk);VXe=r(NDr,"ImageGPTConfig"),NDr.forEach(t),XXe=r(OEe," (ImageGPT model)"),OEe.forEach(t),zXe=i(y),sm=n(y,"LI",{});var VEe=s(sm);hoe=n(VEe,"STRONG",{});var jDr=s(hoe);QXe=r(jDr,"layoutlm"),jDr.forEach(t),WXe=r(VEe," \u2014 "),uk=n(VEe,"A",{href:!0});var DDr=s(uk);HXe=r(DDr,"LayoutLMConfig"),DDr.forEach(t),UXe=r(VEe," (LayoutLM model)"),VEe.forEach(t),JXe=i(y),lm=n(y,"LI",{});var XEe=s(lm);poe=n(XEe,"STRONG",{});var GDr=s(poe);YXe=r(GDr,"layoutlmv2"),GDr.forEach(t),KXe=r(XEe," \u2014 "),_k=n(XEe,"A",{href:!0});var ODr=s(_k);ZXe=r(ODr,"LayoutLMv2Config"),ODr.forEach(t),eze=r(XEe," (LayoutLMv2 model)"),XEe.forEach(t),oze=i(y),im=n(y,"LI",{});var zEe=s(im);uoe=n(zEe,"STRONG",{});var VDr=s(uoe);rze=r(VDr,"layoutlmv3"),VDr.forEach(t),tze=r(zEe," \u2014 "),bk=n(zEe,"A",{href:!0});var XDr=s(bk);aze=r(XDr,"LayoutLMv3Config"),XDr.forEach(t),nze=r(zEe," (LayoutLMv3 model)"),zEe.forEach(t),sze=i(y),dm=n(y,"LI",{});var QEe=s(dm);_oe=n(QEe,"STRONG",{});var zDr=s(_oe);lze=r(zDr,"led"),zDr.forEach(t),ize=r(QEe," \u2014 "),vk=n(QEe,"A",{href:!0});var QDr=s(vk);dze=r(QDr,"LEDConfig"),QDr.forEach(t),cze=r(QEe," (LED model)"),QEe.forEach(t),fze=i(y),cm=n(y,"LI",{});var WEe=s(cm);boe=n(WEe,"STRONG",{});var WDr=s(boe);mze=r(WDr,"longformer"),WDr.forEach(t),gze=r(WEe," \u2014 "),Fk=n(WEe,"A",{href:!0});var HDr=s(Fk);hze=r(HDr,"LongformerConfig"),HDr.forEach(t),pze=r(WEe," (Longformer model)"),WEe.forEach(t),uze=i(y),fm=n(y,"LI",{});var HEe=s(fm);voe=n(HEe,"STRONG",{});var UDr=s(voe);_ze=r(UDr,"luke"),UDr.forEach(t),bze=r(HEe," \u2014 "),Tk=n(HEe,"A",{href:!0});var JDr=s(Tk);vze=r(JDr,"LukeConfig"),JDr.forEach(t),Fze=r(HEe," (LUKE model)"),HEe.forEach(t),Tze=i(y),mm=n(y,"LI",{});var UEe=s(mm);Foe=n(UEe,"STRONG",{});var YDr=s(Foe);Mze=r(YDr,"lxmert"),YDr.forEach(t),Eze=r(UEe," \u2014 "),Mk=n(UEe,"A",{href:!0});var KDr=s(Mk);Cze=r(KDr,"LxmertConfig"),KDr.forEach(t),wze=r(UEe," (LXMERT model)"),UEe.forEach(t),Aze=i(y),gm=n(y,"LI",{});var JEe=s(gm);Toe=n(JEe,"STRONG",{});var ZDr=s(Toe);yze=r(ZDr,"m2m_100"),ZDr.forEach(t),Lze=r(JEe," \u2014 "),Ek=n(JEe,"A",{href:!0});var eGr=s(Ek);xze=r(eGr,"M2M100Config"),eGr.forEach(t),$ze=r(JEe," (M2M100 model)"),JEe.forEach(t),kze=i(y),hm=n(y,"LI",{});var YEe=s(hm);Moe=n(YEe,"STRONG",{});var oGr=s(Moe);Sze=r(oGr,"marian"),oGr.forEach(t),Rze=r(YEe," \u2014 "),Ck=n(YEe,"A",{href:!0});var rGr=s(Ck);Bze=r(rGr,"MarianConfig"),rGr.forEach(t),Pze=r(YEe," (Marian model)"),YEe.forEach(t),Ize=i(y),pm=n(y,"LI",{});var KEe=s(pm);Eoe=n(KEe,"STRONG",{});var tGr=s(Eoe);qze=r(tGr,"maskformer"),tGr.forEach(t),Nze=r(KEe," \u2014 "),wk=n(KEe,"A",{href:!0});var aGr=s(wk);jze=r(aGr,"MaskFormerConfig"),aGr.forEach(t),Dze=r(KEe," (MaskFormer model)"),KEe.forEach(t),Gze=i(y),um=n(y,"LI",{});var ZEe=s(um);Coe=n(ZEe,"STRONG",{});var nGr=s(Coe);Oze=r(nGr,"mbart"),nGr.forEach(t),Vze=r(ZEe," \u2014 "),Ak=n(ZEe,"A",{href:!0});var sGr=s(Ak);Xze=r(sGr,"MBartConfig"),sGr.forEach(t),zze=r(ZEe," (mBART model)"),ZEe.forEach(t),Qze=i(y),_m=n(y,"LI",{});var e5e=s(_m);woe=n(e5e,"STRONG",{});var lGr=s(woe);Wze=r(lGr,"megatron-bert"),lGr.forEach(t),Hze=r(e5e," \u2014 "),yk=n(e5e,"A",{href:!0});var iGr=s(yk);Uze=r(iGr,"MegatronBertConfig"),iGr.forEach(t),Jze=r(e5e," (MegatronBert model)"),e5e.forEach(t),Yze=i(y),bm=n(y,"LI",{});var o5e=s(bm);Aoe=n(o5e,"STRONG",{});var dGr=s(Aoe);Kze=r(dGr,"mobilebert"),dGr.forEach(t),Zze=r(o5e," \u2014 "),Lk=n(o5e,"A",{href:!0});var cGr=s(Lk);eQe=r(cGr,"MobileBertConfig"),cGr.forEach(t),oQe=r(o5e," (MobileBERT model)"),o5e.forEach(t),rQe=i(y),vm=n(y,"LI",{});var r5e=s(vm);yoe=n(r5e,"STRONG",{});var fGr=s(yoe);tQe=r(fGr,"mpnet"),fGr.forEach(t),aQe=r(r5e," \u2014 "),xk=n(r5e,"A",{href:!0});var mGr=s(xk);nQe=r(mGr,"MPNetConfig"),mGr.forEach(t),sQe=r(r5e," (MPNet model)"),r5e.forEach(t),lQe=i(y),Fm=n(y,"LI",{});var t5e=s(Fm);Loe=n(t5e,"STRONG",{});var gGr=s(Loe);iQe=r(gGr,"mt5"),gGr.forEach(t),dQe=r(t5e," \u2014 "),$k=n(t5e,"A",{href:!0});var hGr=s($k);cQe=r(hGr,"MT5Config"),hGr.forEach(t),fQe=r(t5e," (mT5 model)"),t5e.forEach(t),mQe=i(y),Tm=n(y,"LI",{});var a5e=s(Tm);xoe=n(a5e,"STRONG",{});var pGr=s(xoe);gQe=r(pGr,"nystromformer"),pGr.forEach(t),hQe=r(a5e," \u2014 "),kk=n(a5e,"A",{href:!0});var uGr=s(kk);pQe=r(uGr,"NystromformerConfig"),uGr.forEach(t),uQe=r(a5e," (Nystromformer model)"),a5e.forEach(t),_Qe=i(y),Mm=n(y,"LI",{});var n5e=s(Mm);$oe=n(n5e,"STRONG",{});var _Gr=s($oe);bQe=r(_Gr,"openai-gpt"),_Gr.forEach(t),vQe=r(n5e," \u2014 "),Sk=n(n5e,"A",{href:!0});var bGr=s(Sk);FQe=r(bGr,"OpenAIGPTConfig"),bGr.forEach(t),TQe=r(n5e," (OpenAI GPT model)"),n5e.forEach(t),MQe=i(y),Em=n(y,"LI",{});var s5e=s(Em);koe=n(s5e,"STRONG",{});var vGr=s(koe);EQe=r(vGr,"opt"),vGr.forEach(t),CQe=r(s5e," \u2014 "),Rk=n(s5e,"A",{href:!0});var FGr=s(Rk);wQe=r(FGr,"OPTConfig"),FGr.forEach(t),AQe=r(s5e," (OPT model)"),s5e.forEach(t),yQe=i(y),Cm=n(y,"LI",{});var l5e=s(Cm);Soe=n(l5e,"STRONG",{});var TGr=s(Soe);LQe=r(TGr,"pegasus"),TGr.forEach(t),xQe=r(l5e," \u2014 "),Bk=n(l5e,"A",{href:!0});var MGr=s(Bk);$Qe=r(MGr,"PegasusConfig"),MGr.forEach(t),kQe=r(l5e," (Pegasus model)"),l5e.forEach(t),SQe=i(y),wm=n(y,"LI",{});var i5e=s(wm);Roe=n(i5e,"STRONG",{});var EGr=s(Roe);RQe=r(EGr,"perceiver"),EGr.forEach(t),BQe=r(i5e," \u2014 "),Pk=n(i5e,"A",{href:!0});var CGr=s(Pk);PQe=r(CGr,"PerceiverConfig"),CGr.forEach(t),IQe=r(i5e," (Perceiver model)"),i5e.forEach(t),qQe=i(y),Am=n(y,"LI",{});var d5e=s(Am);Boe=n(d5e,"STRONG",{});var wGr=s(Boe);NQe=r(wGr,"plbart"),wGr.forEach(t),jQe=r(d5e," \u2014 "),Ik=n(d5e,"A",{href:!0});var AGr=s(Ik);DQe=r(AGr,"PLBartConfig"),AGr.forEach(t),GQe=r(d5e," (PLBart model)"),d5e.forEach(t),OQe=i(y),ym=n(y,"LI",{});var c5e=s(ym);Poe=n(c5e,"STRONG",{});var yGr=s(Poe);VQe=r(yGr,"poolformer"),yGr.forEach(t),XQe=r(c5e," \u2014 "),qk=n(c5e,"A",{href:!0});var LGr=s(qk);zQe=r(LGr,"PoolFormerConfig"),LGr.forEach(t),QQe=r(c5e," (PoolFormer model)"),c5e.forEach(t),WQe=i(y),Lm=n(y,"LI",{});var f5e=s(Lm);Ioe=n(f5e,"STRONG",{});var xGr=s(Ioe);HQe=r(xGr,"prophetnet"),xGr.forEach(t),UQe=r(f5e," \u2014 "),Nk=n(f5e,"A",{href:!0});var $Gr=s(Nk);JQe=r($Gr,"ProphetNetConfig"),$Gr.forEach(t),YQe=r(f5e," (ProphetNet model)"),f5e.forEach(t),KQe=i(y),xm=n(y,"LI",{});var m5e=s(xm);qoe=n(m5e,"STRONG",{});var kGr=s(qoe);ZQe=r(kGr,"qdqbert"),kGr.forEach(t),eWe=r(m5e," \u2014 "),jk=n(m5e,"A",{href:!0});var SGr=s(jk);oWe=r(SGr,"QDQBertConfig"),SGr.forEach(t),rWe=r(m5e," (QDQBert model)"),m5e.forEach(t),tWe=i(y),$m=n(y,"LI",{});var g5e=s($m);Noe=n(g5e,"STRONG",{});var RGr=s(Noe);aWe=r(RGr,"rag"),RGr.forEach(t),nWe=r(g5e," \u2014 "),Dk=n(g5e,"A",{href:!0});var BGr=s(Dk);sWe=r(BGr,"RagConfig"),BGr.forEach(t),lWe=r(g5e," (RAG model)"),g5e.forEach(t),iWe=i(y),km=n(y,"LI",{});var h5e=s(km);joe=n(h5e,"STRONG",{});var PGr=s(joe);dWe=r(PGr,"realm"),PGr.forEach(t),cWe=r(h5e," \u2014 "),Gk=n(h5e,"A",{href:!0});var IGr=s(Gk);fWe=r(IGr,"RealmConfig"),IGr.forEach(t),mWe=r(h5e," (Realm model)"),h5e.forEach(t),gWe=i(y),Sm=n(y,"LI",{});var p5e=s(Sm);Doe=n(p5e,"STRONG",{});var qGr=s(Doe);hWe=r(qGr,"reformer"),qGr.forEach(t),pWe=r(p5e," \u2014 "),Ok=n(p5e,"A",{href:!0});var NGr=s(Ok);uWe=r(NGr,"ReformerConfig"),NGr.forEach(t),_We=r(p5e," (Reformer model)"),p5e.forEach(t),bWe=i(y),Rm=n(y,"LI",{});var u5e=s(Rm);Goe=n(u5e,"STRONG",{});var jGr=s(Goe);vWe=r(jGr,"regnet"),jGr.forEach(t),FWe=r(u5e," \u2014 "),Vk=n(u5e,"A",{href:!0});var DGr=s(Vk);TWe=r(DGr,"RegNetConfig"),DGr.forEach(t),MWe=r(u5e," (RegNet model)"),u5e.forEach(t),EWe=i(y),Bm=n(y,"LI",{});var _5e=s(Bm);Ooe=n(_5e,"STRONG",{});var GGr=s(Ooe);CWe=r(GGr,"rembert"),GGr.forEach(t),wWe=r(_5e," \u2014 "),Xk=n(_5e,"A",{href:!0});var OGr=s(Xk);AWe=r(OGr,"RemBertConfig"),OGr.forEach(t),yWe=r(_5e," (RemBERT model)"),_5e.forEach(t),LWe=i(y),Pm=n(y,"LI",{});var b5e=s(Pm);Voe=n(b5e,"STRONG",{});var VGr=s(Voe);xWe=r(VGr,"resnet"),VGr.forEach(t),$We=r(b5e," \u2014 "),zk=n(b5e,"A",{href:!0});var XGr=s(zk);kWe=r(XGr,"ResNetConfig"),XGr.forEach(t),SWe=r(b5e," (ResNet model)"),b5e.forEach(t),RWe=i(y),Im=n(y,"LI",{});var v5e=s(Im);Xoe=n(v5e,"STRONG",{});var zGr=s(Xoe);BWe=r(zGr,"retribert"),zGr.forEach(t),PWe=r(v5e," \u2014 "),Qk=n(v5e,"A",{href:!0});var QGr=s(Qk);IWe=r(QGr,"RetriBertConfig"),QGr.forEach(t),qWe=r(v5e," (RetriBERT model)"),v5e.forEach(t),NWe=i(y),qm=n(y,"LI",{});var F5e=s(qm);zoe=n(F5e,"STRONG",{});var WGr=s(zoe);jWe=r(WGr,"roberta"),WGr.forEach(t),DWe=r(F5e," \u2014 "),Wk=n(F5e,"A",{href:!0});var HGr=s(Wk);GWe=r(HGr,"RobertaConfig"),HGr.forEach(t),OWe=r(F5e," (RoBERTa model)"),F5e.forEach(t),VWe=i(y),Nm=n(y,"LI",{});var T5e=s(Nm);Qoe=n(T5e,"STRONG",{});var UGr=s(Qoe);XWe=r(UGr,"roformer"),UGr.forEach(t),zWe=r(T5e," \u2014 "),Hk=n(T5e,"A",{href:!0});var JGr=s(Hk);QWe=r(JGr,"RoFormerConfig"),JGr.forEach(t),WWe=r(T5e," (RoFormer model)"),T5e.forEach(t),HWe=i(y),jm=n(y,"LI",{});var M5e=s(jm);Woe=n(M5e,"STRONG",{});var YGr=s(Woe);UWe=r(YGr,"segformer"),YGr.forEach(t),JWe=r(M5e," \u2014 "),Uk=n(M5e,"A",{href:!0});var KGr=s(Uk);YWe=r(KGr,"SegformerConfig"),KGr.forEach(t),KWe=r(M5e," (SegFormer model)"),M5e.forEach(t),ZWe=i(y),Dm=n(y,"LI",{});var E5e=s(Dm);Hoe=n(E5e,"STRONG",{});var ZGr=s(Hoe);eHe=r(ZGr,"sew"),ZGr.forEach(t),oHe=r(E5e," \u2014 "),Jk=n(E5e,"A",{href:!0});var eOr=s(Jk);rHe=r(eOr,"SEWConfig"),eOr.forEach(t),tHe=r(E5e," (SEW model)"),E5e.forEach(t),aHe=i(y),Gm=n(y,"LI",{});var C5e=s(Gm);Uoe=n(C5e,"STRONG",{});var oOr=s(Uoe);nHe=r(oOr,"sew-d"),oOr.forEach(t),sHe=r(C5e," \u2014 "),Yk=n(C5e,"A",{href:!0});var rOr=s(Yk);lHe=r(rOr,"SEWDConfig"),rOr.forEach(t),iHe=r(C5e," (SEW-D model)"),C5e.forEach(t),dHe=i(y),Om=n(y,"LI",{});var w5e=s(Om);Joe=n(w5e,"STRONG",{});var tOr=s(Joe);cHe=r(tOr,"speech-encoder-decoder"),tOr.forEach(t),fHe=r(w5e," \u2014 "),Kk=n(w5e,"A",{href:!0});var aOr=s(Kk);mHe=r(aOr,"SpeechEncoderDecoderConfig"),aOr.forEach(t),gHe=r(w5e," (Speech Encoder decoder model)"),w5e.forEach(t),hHe=i(y),Vm=n(y,"LI",{});var A5e=s(Vm);Yoe=n(A5e,"STRONG",{});var nOr=s(Yoe);pHe=r(nOr,"speech_to_text"),nOr.forEach(t),uHe=r(A5e," \u2014 "),Zk=n(A5e,"A",{href:!0});var sOr=s(Zk);_He=r(sOr,"Speech2TextConfig"),sOr.forEach(t),bHe=r(A5e," (Speech2Text model)"),A5e.forEach(t),vHe=i(y),Xm=n(y,"LI",{});var y5e=s(Xm);Koe=n(y5e,"STRONG",{});var lOr=s(Koe);FHe=r(lOr,"speech_to_text_2"),lOr.forEach(t),THe=r(y5e," \u2014 "),eS=n(y5e,"A",{href:!0});var iOr=s(eS);MHe=r(iOr,"Speech2Text2Config"),iOr.forEach(t),EHe=r(y5e," (Speech2Text2 model)"),y5e.forEach(t),CHe=i(y),zm=n(y,"LI",{});var L5e=s(zm);Zoe=n(L5e,"STRONG",{});var dOr=s(Zoe);wHe=r(dOr,"splinter"),dOr.forEach(t),AHe=r(L5e," \u2014 "),oS=n(L5e,"A",{href:!0});var cOr=s(oS);yHe=r(cOr,"SplinterConfig"),cOr.forEach(t),LHe=r(L5e," (Splinter model)"),L5e.forEach(t),xHe=i(y),Qm=n(y,"LI",{});var x5e=s(Qm);ere=n(x5e,"STRONG",{});var fOr=s(ere);$He=r(fOr,"squeezebert"),fOr.forEach(t),kHe=r(x5e," \u2014 "),rS=n(x5e,"A",{href:!0});var mOr=s(rS);SHe=r(mOr,"SqueezeBertConfig"),mOr.forEach(t),RHe=r(x5e," (SqueezeBERT model)"),x5e.forEach(t),BHe=i(y),Wm=n(y,"LI",{});var $5e=s(Wm);ore=n($5e,"STRONG",{});var gOr=s(ore);PHe=r(gOr,"swin"),gOr.forEach(t),IHe=r($5e," \u2014 "),tS=n($5e,"A",{href:!0});var hOr=s(tS);qHe=r(hOr,"SwinConfig"),hOr.forEach(t),NHe=r($5e," (Swin model)"),$5e.forEach(t),jHe=i(y),Hm=n(y,"LI",{});var k5e=s(Hm);rre=n(k5e,"STRONG",{});var pOr=s(rre);DHe=r(pOr,"t5"),pOr.forEach(t),GHe=r(k5e," \u2014 "),aS=n(k5e,"A",{href:!0});var uOr=s(aS);OHe=r(uOr,"T5Config"),uOr.forEach(t),VHe=r(k5e," (T5 model)"),k5e.forEach(t),XHe=i(y),Um=n(y,"LI",{});var S5e=s(Um);tre=n(S5e,"STRONG",{});var _Or=s(tre);zHe=r(_Or,"tapas"),_Or.forEach(t),QHe=r(S5e," \u2014 "),nS=n(S5e,"A",{href:!0});var bOr=s(nS);WHe=r(bOr,"TapasConfig"),bOr.forEach(t),HHe=r(S5e," (TAPAS model)"),S5e.forEach(t),UHe=i(y),Jm=n(y,"LI",{});var R5e=s(Jm);are=n(R5e,"STRONG",{});var vOr=s(are);JHe=r(vOr,"tapex"),vOr.forEach(t),YHe=r(R5e," \u2014 "),sS=n(R5e,"A",{href:!0});var FOr=s(sS);KHe=r(FOr,"BartConfig"),FOr.forEach(t),ZHe=r(R5e," (TAPEX model)"),R5e.forEach(t),eUe=i(y),Ym=n(y,"LI",{});var B5e=s(Ym);nre=n(B5e,"STRONG",{});var TOr=s(nre);oUe=r(TOr,"transfo-xl"),TOr.forEach(t),rUe=r(B5e," \u2014 "),lS=n(B5e,"A",{href:!0});var MOr=s(lS);tUe=r(MOr,"TransfoXLConfig"),MOr.forEach(t),aUe=r(B5e," (Transformer-XL model)"),B5e.forEach(t),nUe=i(y),Km=n(y,"LI",{});var P5e=s(Km);sre=n(P5e,"STRONG",{});var EOr=s(sre);sUe=r(EOr,"trocr"),EOr.forEach(t),lUe=r(P5e," \u2014 "),iS=n(P5e,"A",{href:!0});var COr=s(iS);iUe=r(COr,"TrOCRConfig"),COr.forEach(t),dUe=r(P5e," (TrOCR model)"),P5e.forEach(t),cUe=i(y),Zm=n(y,"LI",{});var I5e=s(Zm);lre=n(I5e,"STRONG",{});var wOr=s(lre);fUe=r(wOr,"unispeech"),wOr.forEach(t),mUe=r(I5e," \u2014 "),dS=n(I5e,"A",{href:!0});var AOr=s(dS);gUe=r(AOr,"UniSpeechConfig"),AOr.forEach(t),hUe=r(I5e," (UniSpeech model)"),I5e.forEach(t),pUe=i(y),eg=n(y,"LI",{});var q5e=s(eg);ire=n(q5e,"STRONG",{});var yOr=s(ire);uUe=r(yOr,"unispeech-sat"),yOr.forEach(t),_Ue=r(q5e," \u2014 "),cS=n(q5e,"A",{href:!0});var LOr=s(cS);bUe=r(LOr,"UniSpeechSatConfig"),LOr.forEach(t),vUe=r(q5e," (UniSpeechSat model)"),q5e.forEach(t),FUe=i(y),og=n(y,"LI",{});var N5e=s(og);dre=n(N5e,"STRONG",{});var xOr=s(dre);TUe=r(xOr,"van"),xOr.forEach(t),MUe=r(N5e," \u2014 "),fS=n(N5e,"A",{href:!0});var $Or=s(fS);EUe=r($Or,"VanConfig"),$Or.forEach(t),CUe=r(N5e," (VAN model)"),N5e.forEach(t),wUe=i(y),rg=n(y,"LI",{});var j5e=s(rg);cre=n(j5e,"STRONG",{});var kOr=s(cre);AUe=r(kOr,"vilt"),kOr.forEach(t),yUe=r(j5e," \u2014 "),mS=n(j5e,"A",{href:!0});var SOr=s(mS);LUe=r(SOr,"ViltConfig"),SOr.forEach(t),xUe=r(j5e," (ViLT model)"),j5e.forEach(t),$Ue=i(y),tg=n(y,"LI",{});var D5e=s(tg);fre=n(D5e,"STRONG",{});var ROr=s(fre);kUe=r(ROr,"vision-encoder-decoder"),ROr.forEach(t),SUe=r(D5e," \u2014 "),gS=n(D5e,"A",{href:!0});var BOr=s(gS);RUe=r(BOr,"VisionEncoderDecoderConfig"),BOr.forEach(t),BUe=r(D5e," (Vision Encoder decoder model)"),D5e.forEach(t),PUe=i(y),ag=n(y,"LI",{});var G5e=s(ag);mre=n(G5e,"STRONG",{});var POr=s(mre);IUe=r(POr,"vision-text-dual-encoder"),POr.forEach(t),qUe=r(G5e," \u2014 "),hS=n(G5e,"A",{href:!0});var IOr=s(hS);NUe=r(IOr,"VisionTextDualEncoderConfig"),IOr.forEach(t),jUe=r(G5e," (VisionTextDualEncoder model)"),G5e.forEach(t),DUe=i(y),ng=n(y,"LI",{});var O5e=s(ng);gre=n(O5e,"STRONG",{});var qOr=s(gre);GUe=r(qOr,"visual_bert"),qOr.forEach(t),OUe=r(O5e," \u2014 "),pS=n(O5e,"A",{href:!0});var NOr=s(pS);VUe=r(NOr,"VisualBertConfig"),NOr.forEach(t),XUe=r(O5e," (VisualBert model)"),O5e.forEach(t),zUe=i(y),sg=n(y,"LI",{});var V5e=s(sg);hre=n(V5e,"STRONG",{});var jOr=s(hre);QUe=r(jOr,"vit"),jOr.forEach(t),WUe=r(V5e," \u2014 "),uS=n(V5e,"A",{href:!0});var DOr=s(uS);HUe=r(DOr,"ViTConfig"),DOr.forEach(t),UUe=r(V5e," (ViT model)"),V5e.forEach(t),JUe=i(y),lg=n(y,"LI",{});var X5e=s(lg);pre=n(X5e,"STRONG",{});var GOr=s(pre);YUe=r(GOr,"vit_mae"),GOr.forEach(t),KUe=r(X5e," \u2014 "),_S=n(X5e,"A",{href:!0});var OOr=s(_S);ZUe=r(OOr,"ViTMAEConfig"),OOr.forEach(t),eJe=r(X5e," (ViTMAE model)"),X5e.forEach(t),oJe=i(y),ig=n(y,"LI",{});var z5e=s(ig);ure=n(z5e,"STRONG",{});var VOr=s(ure);rJe=r(VOr,"wav2vec2"),VOr.forEach(t),tJe=r(z5e," \u2014 "),bS=n(z5e,"A",{href:!0});var XOr=s(bS);aJe=r(XOr,"Wav2Vec2Config"),XOr.forEach(t),nJe=r(z5e," (Wav2Vec2 model)"),z5e.forEach(t),sJe=i(y),dg=n(y,"LI",{});var Q5e=s(dg);_re=n(Q5e,"STRONG",{});var zOr=s(_re);lJe=r(zOr,"wavlm"),zOr.forEach(t),iJe=r(Q5e," \u2014 "),vS=n(Q5e,"A",{href:!0});var QOr=s(vS);dJe=r(QOr,"WavLMConfig"),QOr.forEach(t),cJe=r(Q5e," (WavLM model)"),Q5e.forEach(t),fJe=i(y),cg=n(y,"LI",{});var W5e=s(cg);bre=n(W5e,"STRONG",{});var WOr=s(bre);mJe=r(WOr,"xglm"),WOr.forEach(t),gJe=r(W5e," \u2014 "),FS=n(W5e,"A",{href:!0});var HOr=s(FS);hJe=r(HOr,"XGLMConfig"),HOr.forEach(t),pJe=r(W5e," (XGLM model)"),W5e.forEach(t),uJe=i(y),fg=n(y,"LI",{});var H5e=s(fg);vre=n(H5e,"STRONG",{});var UOr=s(vre);_Je=r(UOr,"xlm"),UOr.forEach(t),bJe=r(H5e," \u2014 "),TS=n(H5e,"A",{href:!0});var JOr=s(TS);vJe=r(JOr,"XLMConfig"),JOr.forEach(t),FJe=r(H5e," (XLM model)"),H5e.forEach(t),TJe=i(y),mg=n(y,"LI",{});var U5e=s(mg);Fre=n(U5e,"STRONG",{});var YOr=s(Fre);MJe=r(YOr,"xlm-prophetnet"),YOr.forEach(t),EJe=r(U5e," \u2014 "),MS=n(U5e,"A",{href:!0});var KOr=s(MS);CJe=r(KOr,"XLMProphetNetConfig"),KOr.forEach(t),wJe=r(U5e," (XLMProphetNet model)"),U5e.forEach(t),AJe=i(y),gg=n(y,"LI",{});var J5e=s(gg);Tre=n(J5e,"STRONG",{});var ZOr=s(Tre);yJe=r(ZOr,"xlm-roberta"),ZOr.forEach(t),LJe=r(J5e," \u2014 "),ES=n(J5e,"A",{href:!0});var eVr=s(ES);xJe=r(eVr,"XLMRobertaConfig"),eVr.forEach(t),$Je=r(J5e," (XLM-RoBERTa model)"),J5e.forEach(t),kJe=i(y),hg=n(y,"LI",{});var Y5e=s(hg);Mre=n(Y5e,"STRONG",{});var oVr=s(Mre);SJe=r(oVr,"xlm-roberta-xl"),oVr.forEach(t),RJe=r(Y5e," \u2014 "),CS=n(Y5e,"A",{href:!0});var rVr=s(CS);BJe=r(rVr,"XLMRobertaXLConfig"),rVr.forEach(t),PJe=r(Y5e," (XLM-RoBERTa-XL model)"),Y5e.forEach(t),IJe=i(y),pg=n(y,"LI",{});var K5e=s(pg);Ere=n(K5e,"STRONG",{});var tVr=s(Ere);qJe=r(tVr,"xlnet"),tVr.forEach(t),NJe=r(K5e," \u2014 "),wS=n(K5e,"A",{href:!0});var aVr=s(wS);jJe=r(aVr,"XLNetConfig"),aVr.forEach(t),DJe=r(K5e," (XLNet model)"),K5e.forEach(t),GJe=i(y),ug=n(y,"LI",{});var Z5e=s(ug);Cre=n(Z5e,"STRONG",{});var nVr=s(Cre);OJe=r(nVr,"yolos"),nVr.forEach(t),VJe=r(Z5e," \u2014 "),AS=n(Z5e,"A",{href:!0});var sVr=s(AS);XJe=r(sVr,"YolosConfig"),sVr.forEach(t),zJe=r(Z5e," (YOLOS model)"),Z5e.forEach(t),QJe=i(y),_g=n(y,"LI",{});var eCe=s(_g);wre=n(eCe,"STRONG",{});var lVr=s(wre);WJe=r(lVr,"yoso"),lVr.forEach(t),HJe=r(eCe," \u2014 "),yS=n(eCe,"A",{href:!0});var iVr=s(yS);UJe=r(iVr,"YosoConfig"),iVr.forEach(t),JJe=r(eCe," (YOSO model)"),eCe.forEach(t),y.forEach(t),YJe=i(Zr),T(bg.$$.fragment,Zr),Zr.forEach(t),KJe=i(Kr),vg=n(Kr,"DIV",{class:!0});var ANe=s(vg);T(mA.$$.fragment,ANe),ZJe=i(ANe),Are=n(ANe,"P",{});var dVr=s(Are);eYe=r(dVr,"Register a new configuration for this class."),dVr.forEach(t),ANe.forEach(t),Kr.forEach(t),xIe=i(f),bi=n(f,"H2",{class:!0});var yNe=s(bi);Fg=n(yNe,"A",{id:!0,class:!0,href:!0});var cVr=s(Fg);yre=n(cVr,"SPAN",{});var fVr=s(yre);T(gA.$$.fragment,fVr),fVr.forEach(t),cVr.forEach(t),oYe=i(yNe),Lre=n(yNe,"SPAN",{});var mVr=s(Lre);rYe=r(mVr,"AutoTokenizer"),mVr.forEach(t),yNe.forEach(t),$Ie=i(f),wo=n(f,"DIV",{class:!0});var Is=s(wo);T(hA.$$.fragment,Is),tYe=i(Is),pA=n(Is,"P",{});var LNe=s(pA);aYe=r(LNe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),LS=n(LNe,"A",{href:!0});var gVr=s(LS);nYe=r(gVr,"AutoTokenizer.from_pretrained()"),gVr.forEach(t),sYe=r(LNe," class method."),LNe.forEach(t),lYe=i(Is),uA=n(Is,"P",{});var xNe=s(uA);iYe=r(xNe,"This class cannot be instantiated directly using "),xre=n(xNe,"CODE",{});var hVr=s(xre);dYe=r(hVr,"__init__()"),hVr.forEach(t),cYe=r(xNe," (throws an error)."),xNe.forEach(t),fYe=i(Is),Cr=n(Is,"DIV",{class:!0});var qs=s(Cr);T(_A.$$.fragment,qs),mYe=i(qs),$re=n(qs,"P",{});var pVr=s($re);gYe=r(pVr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),pVr.forEach(t),hYe=i(qs),Ca=n(qs,"P",{});var s3=s(Ca);pYe=r(s3,"The tokenizer class to instantiate is selected based on the "),kre=n(s3,"CODE",{});var uVr=s(kre);uYe=r(uVr,"model_type"),uVr.forEach(t),_Ye=r(s3,` property of the config object (either
passed as an argument or loaded from `),Sre=n(s3,"CODE",{});var _Vr=s(Sre);bYe=r(_Vr,"pretrained_model_name_or_path"),_Vr.forEach(t),vYe=r(s3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rre=n(s3,"CODE",{});var bVr=s(Rre);FYe=r(bVr,"pretrained_model_name_or_path"),bVr.forEach(t),TYe=r(s3,":"),s3.forEach(t),MYe=i(qs),k=n(qs,"UL",{});var S=s(k);kn=n(S,"LI",{});var b9=s(kn);Bre=n(b9,"STRONG",{});var vVr=s(Bre);EYe=r(vVr,"albert"),vVr.forEach(t),CYe=r(b9," \u2014 "),xS=n(b9,"A",{href:!0});var FVr=s(xS);wYe=r(FVr,"AlbertTokenizer"),FVr.forEach(t),AYe=r(b9," or "),$S=n(b9,"A",{href:!0});var TVr=s($S);yYe=r(TVr,"AlbertTokenizerFast"),TVr.forEach(t),LYe=r(b9," (ALBERT model)"),b9.forEach(t),xYe=i(S),Sn=n(S,"LI",{});var v9=s(Sn);Pre=n(v9,"STRONG",{});var MVr=s(Pre);$Ye=r(MVr,"bart"),MVr.forEach(t),kYe=r(v9," \u2014 "),kS=n(v9,"A",{href:!0});var EVr=s(kS);SYe=r(EVr,"BartTokenizer"),EVr.forEach(t),RYe=r(v9," or "),SS=n(v9,"A",{href:!0});var CVr=s(SS);BYe=r(CVr,"BartTokenizerFast"),CVr.forEach(t),PYe=r(v9," (BART model)"),v9.forEach(t),IYe=i(S),Rn=n(S,"LI",{});var F9=s(Rn);Ire=n(F9,"STRONG",{});var wVr=s(Ire);qYe=r(wVr,"barthez"),wVr.forEach(t),NYe=r(F9," \u2014 "),RS=n(F9,"A",{href:!0});var AVr=s(RS);jYe=r(AVr,"BarthezTokenizer"),AVr.forEach(t),DYe=r(F9," or "),BS=n(F9,"A",{href:!0});var yVr=s(BS);GYe=r(yVr,"BarthezTokenizerFast"),yVr.forEach(t),OYe=r(F9," (BARThez model)"),F9.forEach(t),VYe=i(S),Tg=n(S,"LI",{});var oCe=s(Tg);qre=n(oCe,"STRONG",{});var LVr=s(qre);XYe=r(LVr,"bartpho"),LVr.forEach(t),zYe=r(oCe," \u2014 "),PS=n(oCe,"A",{href:!0});var xVr=s(PS);QYe=r(xVr,"BartphoTokenizer"),xVr.forEach(t),WYe=r(oCe," (BARTpho model)"),oCe.forEach(t),HYe=i(S),Bn=n(S,"LI",{});var T9=s(Bn);Nre=n(T9,"STRONG",{});var $Vr=s(Nre);UYe=r($Vr,"bert"),$Vr.forEach(t),JYe=r(T9," \u2014 "),IS=n(T9,"A",{href:!0});var kVr=s(IS);YYe=r(kVr,"BertTokenizer"),kVr.forEach(t),KYe=r(T9," or "),qS=n(T9,"A",{href:!0});var SVr=s(qS);ZYe=r(SVr,"BertTokenizerFast"),SVr.forEach(t),eKe=r(T9," (BERT model)"),T9.forEach(t),oKe=i(S),Mg=n(S,"LI",{});var rCe=s(Mg);jre=n(rCe,"STRONG",{});var RVr=s(jre);rKe=r(RVr,"bert-generation"),RVr.forEach(t),tKe=r(rCe," \u2014 "),NS=n(rCe,"A",{href:!0});var BVr=s(NS);aKe=r(BVr,"BertGenerationTokenizer"),BVr.forEach(t),nKe=r(rCe," (Bert Generation model)"),rCe.forEach(t),sKe=i(S),Eg=n(S,"LI",{});var tCe=s(Eg);Dre=n(tCe,"STRONG",{});var PVr=s(Dre);lKe=r(PVr,"bert-japanese"),PVr.forEach(t),iKe=r(tCe," \u2014 "),jS=n(tCe,"A",{href:!0});var IVr=s(jS);dKe=r(IVr,"BertJapaneseTokenizer"),IVr.forEach(t),cKe=r(tCe," (BertJapanese model)"),tCe.forEach(t),fKe=i(S),Cg=n(S,"LI",{});var aCe=s(Cg);Gre=n(aCe,"STRONG",{});var qVr=s(Gre);mKe=r(qVr,"bertweet"),qVr.forEach(t),gKe=r(aCe," \u2014 "),DS=n(aCe,"A",{href:!0});var NVr=s(DS);hKe=r(NVr,"BertweetTokenizer"),NVr.forEach(t),pKe=r(aCe," (Bertweet model)"),aCe.forEach(t),uKe=i(S),Pn=n(S,"LI",{});var M9=s(Pn);Ore=n(M9,"STRONG",{});var jVr=s(Ore);_Ke=r(jVr,"big_bird"),jVr.forEach(t),bKe=r(M9," \u2014 "),GS=n(M9,"A",{href:!0});var DVr=s(GS);vKe=r(DVr,"BigBirdTokenizer"),DVr.forEach(t),FKe=r(M9," or "),OS=n(M9,"A",{href:!0});var GVr=s(OS);TKe=r(GVr,"BigBirdTokenizerFast"),GVr.forEach(t),MKe=r(M9," (BigBird model)"),M9.forEach(t),EKe=i(S),In=n(S,"LI",{});var E9=s(In);Vre=n(E9,"STRONG",{});var OVr=s(Vre);CKe=r(OVr,"bigbird_pegasus"),OVr.forEach(t),wKe=r(E9," \u2014 "),VS=n(E9,"A",{href:!0});var VVr=s(VS);AKe=r(VVr,"PegasusTokenizer"),VVr.forEach(t),yKe=r(E9," or "),XS=n(E9,"A",{href:!0});var XVr=s(XS);LKe=r(XVr,"PegasusTokenizerFast"),XVr.forEach(t),xKe=r(E9," (BigBirdPegasus model)"),E9.forEach(t),$Ke=i(S),qn=n(S,"LI",{});var C9=s(qn);Xre=n(C9,"STRONG",{});var zVr=s(Xre);kKe=r(zVr,"blenderbot"),zVr.forEach(t),SKe=r(C9," \u2014 "),zS=n(C9,"A",{href:!0});var QVr=s(zS);RKe=r(QVr,"BlenderbotTokenizer"),QVr.forEach(t),BKe=r(C9," or "),QS=n(C9,"A",{href:!0});var WVr=s(QS);PKe=r(WVr,"BlenderbotTokenizerFast"),WVr.forEach(t),IKe=r(C9," (Blenderbot model)"),C9.forEach(t),qKe=i(S),wg=n(S,"LI",{});var nCe=s(wg);zre=n(nCe,"STRONG",{});var HVr=s(zre);NKe=r(HVr,"blenderbot-small"),HVr.forEach(t),jKe=r(nCe," \u2014 "),WS=n(nCe,"A",{href:!0});var UVr=s(WS);DKe=r(UVr,"BlenderbotSmallTokenizer"),UVr.forEach(t),GKe=r(nCe," (BlenderbotSmall model)"),nCe.forEach(t),OKe=i(S),Ag=n(S,"LI",{});var sCe=s(Ag);Qre=n(sCe,"STRONG",{});var JVr=s(Qre);VKe=r(JVr,"byt5"),JVr.forEach(t),XKe=r(sCe," \u2014 "),HS=n(sCe,"A",{href:!0});var YVr=s(HS);zKe=r(YVr,"ByT5Tokenizer"),YVr.forEach(t),QKe=r(sCe," (ByT5 model)"),sCe.forEach(t),WKe=i(S),Nn=n(S,"LI",{});var w9=s(Nn);Wre=n(w9,"STRONG",{});var KVr=s(Wre);HKe=r(KVr,"camembert"),KVr.forEach(t),UKe=r(w9," \u2014 "),US=n(w9,"A",{href:!0});var ZVr=s(US);JKe=r(ZVr,"CamembertTokenizer"),ZVr.forEach(t),YKe=r(w9," or "),JS=n(w9,"A",{href:!0});var eXr=s(JS);KKe=r(eXr,"CamembertTokenizerFast"),eXr.forEach(t),ZKe=r(w9," (CamemBERT model)"),w9.forEach(t),eZe=i(S),yg=n(S,"LI",{});var lCe=s(yg);Hre=n(lCe,"STRONG",{});var oXr=s(Hre);oZe=r(oXr,"canine"),oXr.forEach(t),rZe=r(lCe," \u2014 "),YS=n(lCe,"A",{href:!0});var rXr=s(YS);tZe=r(rXr,"CanineTokenizer"),rXr.forEach(t),aZe=r(lCe," (Canine model)"),lCe.forEach(t),nZe=i(S),jn=n(S,"LI",{});var A9=s(jn);Ure=n(A9,"STRONG",{});var tXr=s(Ure);sZe=r(tXr,"clip"),tXr.forEach(t),lZe=r(A9," \u2014 "),KS=n(A9,"A",{href:!0});var aXr=s(KS);iZe=r(aXr,"CLIPTokenizer"),aXr.forEach(t),dZe=r(A9," or "),ZS=n(A9,"A",{href:!0});var nXr=s(ZS);cZe=r(nXr,"CLIPTokenizerFast"),nXr.forEach(t),fZe=r(A9," (CLIP model)"),A9.forEach(t),mZe=i(S),Dn=n(S,"LI",{});var y9=s(Dn);Jre=n(y9,"STRONG",{});var sXr=s(Jre);gZe=r(sXr,"convbert"),sXr.forEach(t),hZe=r(y9," \u2014 "),eR=n(y9,"A",{href:!0});var lXr=s(eR);pZe=r(lXr,"ConvBertTokenizer"),lXr.forEach(t),uZe=r(y9," or "),oR=n(y9,"A",{href:!0});var iXr=s(oR);_Ze=r(iXr,"ConvBertTokenizerFast"),iXr.forEach(t),bZe=r(y9," (ConvBERT model)"),y9.forEach(t),vZe=i(S),Gn=n(S,"LI",{});var L9=s(Gn);Yre=n(L9,"STRONG",{});var dXr=s(Yre);FZe=r(dXr,"cpm"),dXr.forEach(t),TZe=r(L9," \u2014 "),rR=n(L9,"A",{href:!0});var cXr=s(rR);MZe=r(cXr,"CpmTokenizer"),cXr.forEach(t),EZe=r(L9," or "),tR=n(L9,"A",{href:!0});var fXr=s(tR);CZe=r(fXr,"CpmTokenizerFast"),fXr.forEach(t),wZe=r(L9," (CPM model)"),L9.forEach(t),AZe=i(S),Lg=n(S,"LI",{});var iCe=s(Lg);Kre=n(iCe,"STRONG",{});var mXr=s(Kre);yZe=r(mXr,"ctrl"),mXr.forEach(t),LZe=r(iCe," \u2014 "),aR=n(iCe,"A",{href:!0});var gXr=s(aR);xZe=r(gXr,"CTRLTokenizer"),gXr.forEach(t),$Ze=r(iCe," (CTRL model)"),iCe.forEach(t),kZe=i(S),On=n(S,"LI",{});var x9=s(On);Zre=n(x9,"STRONG",{});var hXr=s(Zre);SZe=r(hXr,"data2vec-text"),hXr.forEach(t),RZe=r(x9," \u2014 "),nR=n(x9,"A",{href:!0});var pXr=s(nR);BZe=r(pXr,"RobertaTokenizer"),pXr.forEach(t),PZe=r(x9," or "),sR=n(x9,"A",{href:!0});var uXr=s(sR);IZe=r(uXr,"RobertaTokenizerFast"),uXr.forEach(t),qZe=r(x9," (Data2VecText model)"),x9.forEach(t),NZe=i(S),Vn=n(S,"LI",{});var $9=s(Vn);ete=n($9,"STRONG",{});var _Xr=s(ete);jZe=r(_Xr,"deberta"),_Xr.forEach(t),DZe=r($9," \u2014 "),lR=n($9,"A",{href:!0});var bXr=s(lR);GZe=r(bXr,"DebertaTokenizer"),bXr.forEach(t),OZe=r($9," or "),iR=n($9,"A",{href:!0});var vXr=s(iR);VZe=r(vXr,"DebertaTokenizerFast"),vXr.forEach(t),XZe=r($9," (DeBERTa model)"),$9.forEach(t),zZe=i(S),Xn=n(S,"LI",{});var k9=s(Xn);ote=n(k9,"STRONG",{});var FXr=s(ote);QZe=r(FXr,"deberta-v2"),FXr.forEach(t),WZe=r(k9," \u2014 "),dR=n(k9,"A",{href:!0});var TXr=s(dR);HZe=r(TXr,"DebertaV2Tokenizer"),TXr.forEach(t),UZe=r(k9," or "),cR=n(k9,"A",{href:!0});var MXr=s(cR);JZe=r(MXr,"DebertaV2TokenizerFast"),MXr.forEach(t),YZe=r(k9," (DeBERTa-v2 model)"),k9.forEach(t),KZe=i(S),zn=n(S,"LI",{});var S9=s(zn);rte=n(S9,"STRONG",{});var EXr=s(rte);ZZe=r(EXr,"distilbert"),EXr.forEach(t),eeo=r(S9," \u2014 "),fR=n(S9,"A",{href:!0});var CXr=s(fR);oeo=r(CXr,"DistilBertTokenizer"),CXr.forEach(t),reo=r(S9," or "),mR=n(S9,"A",{href:!0});var wXr=s(mR);teo=r(wXr,"DistilBertTokenizerFast"),wXr.forEach(t),aeo=r(S9," (DistilBERT model)"),S9.forEach(t),neo=i(S),Qn=n(S,"LI",{});var R9=s(Qn);tte=n(R9,"STRONG",{});var AXr=s(tte);seo=r(AXr,"dpr"),AXr.forEach(t),leo=r(R9," \u2014 "),gR=n(R9,"A",{href:!0});var yXr=s(gR);ieo=r(yXr,"DPRQuestionEncoderTokenizer"),yXr.forEach(t),deo=r(R9," or "),hR=n(R9,"A",{href:!0});var LXr=s(hR);ceo=r(LXr,"DPRQuestionEncoderTokenizerFast"),LXr.forEach(t),feo=r(R9," (DPR model)"),R9.forEach(t),meo=i(S),Wn=n(S,"LI",{});var B9=s(Wn);ate=n(B9,"STRONG",{});var xXr=s(ate);geo=r(xXr,"electra"),xXr.forEach(t),heo=r(B9," \u2014 "),pR=n(B9,"A",{href:!0});var $Xr=s(pR);peo=r($Xr,"ElectraTokenizer"),$Xr.forEach(t),ueo=r(B9," or "),uR=n(B9,"A",{href:!0});var kXr=s(uR);_eo=r(kXr,"ElectraTokenizerFast"),kXr.forEach(t),beo=r(B9," (ELECTRA model)"),B9.forEach(t),veo=i(S),xg=n(S,"LI",{});var dCe=s(xg);nte=n(dCe,"STRONG",{});var SXr=s(nte);Feo=r(SXr,"flaubert"),SXr.forEach(t),Teo=r(dCe," \u2014 "),_R=n(dCe,"A",{href:!0});var RXr=s(_R);Meo=r(RXr,"FlaubertTokenizer"),RXr.forEach(t),Eeo=r(dCe," (FlauBERT model)"),dCe.forEach(t),Ceo=i(S),Hn=n(S,"LI",{});var P9=s(Hn);ste=n(P9,"STRONG",{});var BXr=s(ste);weo=r(BXr,"fnet"),BXr.forEach(t),Aeo=r(P9," \u2014 "),bR=n(P9,"A",{href:!0});var PXr=s(bR);yeo=r(PXr,"FNetTokenizer"),PXr.forEach(t),Leo=r(P9," or "),vR=n(P9,"A",{href:!0});var IXr=s(vR);xeo=r(IXr,"FNetTokenizerFast"),IXr.forEach(t),$eo=r(P9," (FNet model)"),P9.forEach(t),keo=i(S),$g=n(S,"LI",{});var cCe=s($g);lte=n(cCe,"STRONG",{});var qXr=s(lte);Seo=r(qXr,"fsmt"),qXr.forEach(t),Reo=r(cCe," \u2014 "),FR=n(cCe,"A",{href:!0});var NXr=s(FR);Beo=r(NXr,"FSMTTokenizer"),NXr.forEach(t),Peo=r(cCe," (FairSeq Machine-Translation model)"),cCe.forEach(t),Ieo=i(S),Un=n(S,"LI",{});var I9=s(Un);ite=n(I9,"STRONG",{});var jXr=s(ite);qeo=r(jXr,"funnel"),jXr.forEach(t),Neo=r(I9," \u2014 "),TR=n(I9,"A",{href:!0});var DXr=s(TR);jeo=r(DXr,"FunnelTokenizer"),DXr.forEach(t),Deo=r(I9," or "),MR=n(I9,"A",{href:!0});var GXr=s(MR);Geo=r(GXr,"FunnelTokenizerFast"),GXr.forEach(t),Oeo=r(I9," (Funnel Transformer model)"),I9.forEach(t),Veo=i(S),Jn=n(S,"LI",{});var q9=s(Jn);dte=n(q9,"STRONG",{});var OXr=s(dte);Xeo=r(OXr,"gpt2"),OXr.forEach(t),zeo=r(q9," \u2014 "),ER=n(q9,"A",{href:!0});var VXr=s(ER);Qeo=r(VXr,"GPT2Tokenizer"),VXr.forEach(t),Weo=r(q9," or "),CR=n(q9,"A",{href:!0});var XXr=s(CR);Heo=r(XXr,"GPT2TokenizerFast"),XXr.forEach(t),Ueo=r(q9," (OpenAI GPT-2 model)"),q9.forEach(t),Jeo=i(S),Yn=n(S,"LI",{});var N9=s(Yn);cte=n(N9,"STRONG",{});var zXr=s(cte);Yeo=r(zXr,"gpt_neo"),zXr.forEach(t),Keo=r(N9," \u2014 "),wR=n(N9,"A",{href:!0});var QXr=s(wR);Zeo=r(QXr,"GPT2Tokenizer"),QXr.forEach(t),eoo=r(N9," or "),AR=n(N9,"A",{href:!0});var WXr=s(AR);ooo=r(WXr,"GPT2TokenizerFast"),WXr.forEach(t),roo=r(N9," (GPT Neo model)"),N9.forEach(t),too=i(S),Kn=n(S,"LI",{});var j9=s(Kn);fte=n(j9,"STRONG",{});var HXr=s(fte);aoo=r(HXr,"gptj"),HXr.forEach(t),noo=r(j9," \u2014 "),yR=n(j9,"A",{href:!0});var UXr=s(yR);soo=r(UXr,"GPT2Tokenizer"),UXr.forEach(t),loo=r(j9," or "),LR=n(j9,"A",{href:!0});var JXr=s(LR);ioo=r(JXr,"GPT2TokenizerFast"),JXr.forEach(t),doo=r(j9," (GPT-J model)"),j9.forEach(t),coo=i(S),Zn=n(S,"LI",{});var D9=s(Zn);mte=n(D9,"STRONG",{});var YXr=s(mte);foo=r(YXr,"herbert"),YXr.forEach(t),moo=r(D9," \u2014 "),xR=n(D9,"A",{href:!0});var KXr=s(xR);goo=r(KXr,"HerbertTokenizer"),KXr.forEach(t),hoo=r(D9," or "),$R=n(D9,"A",{href:!0});var ZXr=s($R);poo=r(ZXr,"HerbertTokenizerFast"),ZXr.forEach(t),uoo=r(D9," (HerBERT model)"),D9.forEach(t),_oo=i(S),kg=n(S,"LI",{});var fCe=s(kg);gte=n(fCe,"STRONG",{});var ezr=s(gte);boo=r(ezr,"hubert"),ezr.forEach(t),voo=r(fCe," \u2014 "),kR=n(fCe,"A",{href:!0});var ozr=s(kR);Foo=r(ozr,"Wav2Vec2CTCTokenizer"),ozr.forEach(t),Too=r(fCe," (Hubert model)"),fCe.forEach(t),Moo=i(S),es=n(S,"LI",{});var G9=s(es);hte=n(G9,"STRONG",{});var rzr=s(hte);Eoo=r(rzr,"ibert"),rzr.forEach(t),Coo=r(G9," \u2014 "),SR=n(G9,"A",{href:!0});var tzr=s(SR);woo=r(tzr,"RobertaTokenizer"),tzr.forEach(t),Aoo=r(G9," or "),RR=n(G9,"A",{href:!0});var azr=s(RR);yoo=r(azr,"RobertaTokenizerFast"),azr.forEach(t),Loo=r(G9," (I-BERT model)"),G9.forEach(t),xoo=i(S),os=n(S,"LI",{});var O9=s(os);pte=n(O9,"STRONG",{});var nzr=s(pte);$oo=r(nzr,"layoutlm"),nzr.forEach(t),koo=r(O9," \u2014 "),BR=n(O9,"A",{href:!0});var szr=s(BR);Soo=r(szr,"LayoutLMTokenizer"),szr.forEach(t),Roo=r(O9," or "),PR=n(O9,"A",{href:!0});var lzr=s(PR);Boo=r(lzr,"LayoutLMTokenizerFast"),lzr.forEach(t),Poo=r(O9," (LayoutLM model)"),O9.forEach(t),Ioo=i(S),rs=n(S,"LI",{});var V9=s(rs);ute=n(V9,"STRONG",{});var izr=s(ute);qoo=r(izr,"layoutlmv2"),izr.forEach(t),Noo=r(V9," \u2014 "),IR=n(V9,"A",{href:!0});var dzr=s(IR);joo=r(dzr,"LayoutLMv2Tokenizer"),dzr.forEach(t),Doo=r(V9," or "),qR=n(V9,"A",{href:!0});var czr=s(qR);Goo=r(czr,"LayoutLMv2TokenizerFast"),czr.forEach(t),Ooo=r(V9," (LayoutLMv2 model)"),V9.forEach(t),Voo=i(S),ts=n(S,"LI",{});var X9=s(ts);_te=n(X9,"STRONG",{});var fzr=s(_te);Xoo=r(fzr,"layoutlmv3"),fzr.forEach(t),zoo=r(X9," \u2014 "),NR=n(X9,"A",{href:!0});var mzr=s(NR);Qoo=r(mzr,"LayoutLMv3Tokenizer"),mzr.forEach(t),Woo=r(X9," or "),jR=n(X9,"A",{href:!0});var gzr=s(jR);Hoo=r(gzr,"LayoutLMv3TokenizerFast"),gzr.forEach(t),Uoo=r(X9," (LayoutLMv3 model)"),X9.forEach(t),Joo=i(S),as=n(S,"LI",{});var z9=s(as);bte=n(z9,"STRONG",{});var hzr=s(bte);Yoo=r(hzr,"layoutxlm"),hzr.forEach(t),Koo=r(z9," \u2014 "),DR=n(z9,"A",{href:!0});var pzr=s(DR);Zoo=r(pzr,"LayoutXLMTokenizer"),pzr.forEach(t),ero=r(z9," or "),GR=n(z9,"A",{href:!0});var uzr=s(GR);oro=r(uzr,"LayoutXLMTokenizerFast"),uzr.forEach(t),rro=r(z9," (LayoutXLM model)"),z9.forEach(t),tro=i(S),ns=n(S,"LI",{});var Q9=s(ns);vte=n(Q9,"STRONG",{});var _zr=s(vte);aro=r(_zr,"led"),_zr.forEach(t),nro=r(Q9," \u2014 "),OR=n(Q9,"A",{href:!0});var bzr=s(OR);sro=r(bzr,"LEDTokenizer"),bzr.forEach(t),lro=r(Q9," or "),VR=n(Q9,"A",{href:!0});var vzr=s(VR);iro=r(vzr,"LEDTokenizerFast"),vzr.forEach(t),dro=r(Q9," (LED model)"),Q9.forEach(t),cro=i(S),ss=n(S,"LI",{});var W9=s(ss);Fte=n(W9,"STRONG",{});var Fzr=s(Fte);fro=r(Fzr,"longformer"),Fzr.forEach(t),mro=r(W9," \u2014 "),XR=n(W9,"A",{href:!0});var Tzr=s(XR);gro=r(Tzr,"LongformerTokenizer"),Tzr.forEach(t),hro=r(W9," or "),zR=n(W9,"A",{href:!0});var Mzr=s(zR);pro=r(Mzr,"LongformerTokenizerFast"),Mzr.forEach(t),uro=r(W9," (Longformer model)"),W9.forEach(t),_ro=i(S),Sg=n(S,"LI",{});var mCe=s(Sg);Tte=n(mCe,"STRONG",{});var Ezr=s(Tte);bro=r(Ezr,"luke"),Ezr.forEach(t),vro=r(mCe," \u2014 "),QR=n(mCe,"A",{href:!0});var Czr=s(QR);Fro=r(Czr,"LukeTokenizer"),Czr.forEach(t),Tro=r(mCe," (LUKE model)"),mCe.forEach(t),Mro=i(S),ls=n(S,"LI",{});var H9=s(ls);Mte=n(H9,"STRONG",{});var wzr=s(Mte);Ero=r(wzr,"lxmert"),wzr.forEach(t),Cro=r(H9," \u2014 "),WR=n(H9,"A",{href:!0});var Azr=s(WR);wro=r(Azr,"LxmertTokenizer"),Azr.forEach(t),Aro=r(H9," or "),HR=n(H9,"A",{href:!0});var yzr=s(HR);yro=r(yzr,"LxmertTokenizerFast"),yzr.forEach(t),Lro=r(H9," (LXMERT model)"),H9.forEach(t),xro=i(S),Rg=n(S,"LI",{});var gCe=s(Rg);Ete=n(gCe,"STRONG",{});var Lzr=s(Ete);$ro=r(Lzr,"m2m_100"),Lzr.forEach(t),kro=r(gCe," \u2014 "),UR=n(gCe,"A",{href:!0});var xzr=s(UR);Sro=r(xzr,"M2M100Tokenizer"),xzr.forEach(t),Rro=r(gCe," (M2M100 model)"),gCe.forEach(t),Bro=i(S),Bg=n(S,"LI",{});var hCe=s(Bg);Cte=n(hCe,"STRONG",{});var $zr=s(Cte);Pro=r($zr,"marian"),$zr.forEach(t),Iro=r(hCe," \u2014 "),JR=n(hCe,"A",{href:!0});var kzr=s(JR);qro=r(kzr,"MarianTokenizer"),kzr.forEach(t),Nro=r(hCe," (Marian model)"),hCe.forEach(t),jro=i(S),is=n(S,"LI",{});var U9=s(is);wte=n(U9,"STRONG",{});var Szr=s(wte);Dro=r(Szr,"mbart"),Szr.forEach(t),Gro=r(U9," \u2014 "),YR=n(U9,"A",{href:!0});var Rzr=s(YR);Oro=r(Rzr,"MBartTokenizer"),Rzr.forEach(t),Vro=r(U9," or "),KR=n(U9,"A",{href:!0});var Bzr=s(KR);Xro=r(Bzr,"MBartTokenizerFast"),Bzr.forEach(t),zro=r(U9," (mBART model)"),U9.forEach(t),Qro=i(S),ds=n(S,"LI",{});var J9=s(ds);Ate=n(J9,"STRONG",{});var Pzr=s(Ate);Wro=r(Pzr,"mbart50"),Pzr.forEach(t),Hro=r(J9," \u2014 "),ZR=n(J9,"A",{href:!0});var Izr=s(ZR);Uro=r(Izr,"MBart50Tokenizer"),Izr.forEach(t),Jro=r(J9," or "),eB=n(J9,"A",{href:!0});var qzr=s(eB);Yro=r(qzr,"MBart50TokenizerFast"),qzr.forEach(t),Kro=r(J9," (mBART-50 model)"),J9.forEach(t),Zro=i(S),cs=n(S,"LI",{});var Y9=s(cs);yte=n(Y9,"STRONG",{});var Nzr=s(yte);eto=r(Nzr,"megatron-bert"),Nzr.forEach(t),oto=r(Y9," \u2014 "),oB=n(Y9,"A",{href:!0});var jzr=s(oB);rto=r(jzr,"BertTokenizer"),jzr.forEach(t),tto=r(Y9," or "),rB=n(Y9,"A",{href:!0});var Dzr=s(rB);ato=r(Dzr,"BertTokenizerFast"),Dzr.forEach(t),nto=r(Y9," (MegatronBert model)"),Y9.forEach(t),sto=i(S),Pg=n(S,"LI",{});var pCe=s(Pg);Lte=n(pCe,"STRONG",{});var Gzr=s(Lte);lto=r(Gzr,"mluke"),Gzr.forEach(t),ito=r(pCe," \u2014 "),tB=n(pCe,"A",{href:!0});var Ozr=s(tB);dto=r(Ozr,"MLukeTokenizer"),Ozr.forEach(t),cto=r(pCe," (mLUKE model)"),pCe.forEach(t),fto=i(S),fs=n(S,"LI",{});var K9=s(fs);xte=n(K9,"STRONG",{});var Vzr=s(xte);mto=r(Vzr,"mobilebert"),Vzr.forEach(t),gto=r(K9," \u2014 "),aB=n(K9,"A",{href:!0});var Xzr=s(aB);hto=r(Xzr,"MobileBertTokenizer"),Xzr.forEach(t),pto=r(K9," or "),nB=n(K9,"A",{href:!0});var zzr=s(nB);uto=r(zzr,"MobileBertTokenizerFast"),zzr.forEach(t),_to=r(K9," (MobileBERT model)"),K9.forEach(t),bto=i(S),ms=n(S,"LI",{});var Z9=s(ms);$te=n(Z9,"STRONG",{});var Qzr=s($te);vto=r(Qzr,"mpnet"),Qzr.forEach(t),Fto=r(Z9," \u2014 "),sB=n(Z9,"A",{href:!0});var Wzr=s(sB);Tto=r(Wzr,"MPNetTokenizer"),Wzr.forEach(t),Mto=r(Z9," or "),lB=n(Z9,"A",{href:!0});var Hzr=s(lB);Eto=r(Hzr,"MPNetTokenizerFast"),Hzr.forEach(t),Cto=r(Z9," (MPNet model)"),Z9.forEach(t),wto=i(S),gs=n(S,"LI",{});var e$=s(gs);kte=n(e$,"STRONG",{});var Uzr=s(kte);Ato=r(Uzr,"mt5"),Uzr.forEach(t),yto=r(e$," \u2014 "),iB=n(e$,"A",{href:!0});var Jzr=s(iB);Lto=r(Jzr,"MT5Tokenizer"),Jzr.forEach(t),xto=r(e$," or "),dB=n(e$,"A",{href:!0});var Yzr=s(dB);$to=r(Yzr,"MT5TokenizerFast"),Yzr.forEach(t),kto=r(e$," (mT5 model)"),e$.forEach(t),Sto=i(S),hs=n(S,"LI",{});var o$=s(hs);Ste=n(o$,"STRONG",{});var Kzr=s(Ste);Rto=r(Kzr,"nystromformer"),Kzr.forEach(t),Bto=r(o$," \u2014 "),cB=n(o$,"A",{href:!0});var Zzr=s(cB);Pto=r(Zzr,"AlbertTokenizer"),Zzr.forEach(t),Ito=r(o$," or "),fB=n(o$,"A",{href:!0});var eQr=s(fB);qto=r(eQr,"AlbertTokenizerFast"),eQr.forEach(t),Nto=r(o$," (Nystromformer model)"),o$.forEach(t),jto=i(S),ps=n(S,"LI",{});var r$=s(ps);Rte=n(r$,"STRONG",{});var oQr=s(Rte);Dto=r(oQr,"openai-gpt"),oQr.forEach(t),Gto=r(r$," \u2014 "),mB=n(r$,"A",{href:!0});var rQr=s(mB);Oto=r(rQr,"OpenAIGPTTokenizer"),rQr.forEach(t),Vto=r(r$," or "),gB=n(r$,"A",{href:!0});var tQr=s(gB);Xto=r(tQr,"OpenAIGPTTokenizerFast"),tQr.forEach(t),zto=r(r$," (OpenAI GPT model)"),r$.forEach(t),Qto=i(S),Ig=n(S,"LI",{});var uCe=s(Ig);Bte=n(uCe,"STRONG",{});var aQr=s(Bte);Wto=r(aQr,"opt"),aQr.forEach(t),Hto=r(uCe," \u2014 "),hB=n(uCe,"A",{href:!0});var nQr=s(hB);Uto=r(nQr,"GPT2Tokenizer"),nQr.forEach(t),Jto=r(uCe," (OPT model)"),uCe.forEach(t),Yto=i(S),us=n(S,"LI",{});var t$=s(us);Pte=n(t$,"STRONG",{});var sQr=s(Pte);Kto=r(sQr,"pegasus"),sQr.forEach(t),Zto=r(t$," \u2014 "),pB=n(t$,"A",{href:!0});var lQr=s(pB);eao=r(lQr,"PegasusTokenizer"),lQr.forEach(t),oao=r(t$," or "),uB=n(t$,"A",{href:!0});var iQr=s(uB);rao=r(iQr,"PegasusTokenizerFast"),iQr.forEach(t),tao=r(t$," (Pegasus model)"),t$.forEach(t),aao=i(S),qg=n(S,"LI",{});var _Ce=s(qg);Ite=n(_Ce,"STRONG",{});var dQr=s(Ite);nao=r(dQr,"perceiver"),dQr.forEach(t),sao=r(_Ce," \u2014 "),_B=n(_Ce,"A",{href:!0});var cQr=s(_B);lao=r(cQr,"PerceiverTokenizer"),cQr.forEach(t),iao=r(_Ce," (Perceiver model)"),_Ce.forEach(t),dao=i(S),Ng=n(S,"LI",{});var bCe=s(Ng);qte=n(bCe,"STRONG",{});var fQr=s(qte);cao=r(fQr,"phobert"),fQr.forEach(t),fao=r(bCe," \u2014 "),bB=n(bCe,"A",{href:!0});var mQr=s(bB);mao=r(mQr,"PhobertTokenizer"),mQr.forEach(t),gao=r(bCe," (PhoBERT model)"),bCe.forEach(t),hao=i(S),jg=n(S,"LI",{});var vCe=s(jg);Nte=n(vCe,"STRONG",{});var gQr=s(Nte);pao=r(gQr,"plbart"),gQr.forEach(t),uao=r(vCe," \u2014 "),vB=n(vCe,"A",{href:!0});var hQr=s(vB);_ao=r(hQr,"PLBartTokenizer"),hQr.forEach(t),bao=r(vCe," (PLBart model)"),vCe.forEach(t),vao=i(S),Dg=n(S,"LI",{});var FCe=s(Dg);jte=n(FCe,"STRONG",{});var pQr=s(jte);Fao=r(pQr,"prophetnet"),pQr.forEach(t),Tao=r(FCe," \u2014 "),FB=n(FCe,"A",{href:!0});var uQr=s(FB);Mao=r(uQr,"ProphetNetTokenizer"),uQr.forEach(t),Eao=r(FCe," (ProphetNet model)"),FCe.forEach(t),Cao=i(S),_s=n(S,"LI",{});var a$=s(_s);Dte=n(a$,"STRONG",{});var _Qr=s(Dte);wao=r(_Qr,"qdqbert"),_Qr.forEach(t),Aao=r(a$," \u2014 "),TB=n(a$,"A",{href:!0});var bQr=s(TB);yao=r(bQr,"BertTokenizer"),bQr.forEach(t),Lao=r(a$," or "),MB=n(a$,"A",{href:!0});var vQr=s(MB);xao=r(vQr,"BertTokenizerFast"),vQr.forEach(t),$ao=r(a$," (QDQBert model)"),a$.forEach(t),kao=i(S),Gg=n(S,"LI",{});var TCe=s(Gg);Gte=n(TCe,"STRONG",{});var FQr=s(Gte);Sao=r(FQr,"rag"),FQr.forEach(t),Rao=r(TCe," \u2014 "),EB=n(TCe,"A",{href:!0});var TQr=s(EB);Bao=r(TQr,"RagTokenizer"),TQr.forEach(t),Pao=r(TCe," (RAG model)"),TCe.forEach(t),Iao=i(S),bs=n(S,"LI",{});var n$=s(bs);Ote=n(n$,"STRONG",{});var MQr=s(Ote);qao=r(MQr,"realm"),MQr.forEach(t),Nao=r(n$," \u2014 "),CB=n(n$,"A",{href:!0});var EQr=s(CB);jao=r(EQr,"RealmTokenizer"),EQr.forEach(t),Dao=r(n$," or "),wB=n(n$,"A",{href:!0});var CQr=s(wB);Gao=r(CQr,"RealmTokenizerFast"),CQr.forEach(t),Oao=r(n$," (Realm model)"),n$.forEach(t),Vao=i(S),vs=n(S,"LI",{});var s$=s(vs);Vte=n(s$,"STRONG",{});var wQr=s(Vte);Xao=r(wQr,"reformer"),wQr.forEach(t),zao=r(s$," \u2014 "),AB=n(s$,"A",{href:!0});var AQr=s(AB);Qao=r(AQr,"ReformerTokenizer"),AQr.forEach(t),Wao=r(s$," or "),yB=n(s$,"A",{href:!0});var yQr=s(yB);Hao=r(yQr,"ReformerTokenizerFast"),yQr.forEach(t),Uao=r(s$," (Reformer model)"),s$.forEach(t),Jao=i(S),Fs=n(S,"LI",{});var l$=s(Fs);Xte=n(l$,"STRONG",{});var LQr=s(Xte);Yao=r(LQr,"rembert"),LQr.forEach(t),Kao=r(l$," \u2014 "),LB=n(l$,"A",{href:!0});var xQr=s(LB);Zao=r(xQr,"RemBertTokenizer"),xQr.forEach(t),eno=r(l$," or "),xB=n(l$,"A",{href:!0});var $Qr=s(xB);ono=r($Qr,"RemBertTokenizerFast"),$Qr.forEach(t),rno=r(l$," (RemBERT model)"),l$.forEach(t),tno=i(S),Ts=n(S,"LI",{});var i$=s(Ts);zte=n(i$,"STRONG",{});var kQr=s(zte);ano=r(kQr,"retribert"),kQr.forEach(t),nno=r(i$," \u2014 "),$B=n(i$,"A",{href:!0});var SQr=s($B);sno=r(SQr,"RetriBertTokenizer"),SQr.forEach(t),lno=r(i$," or "),kB=n(i$,"A",{href:!0});var RQr=s(kB);ino=r(RQr,"RetriBertTokenizerFast"),RQr.forEach(t),dno=r(i$," (RetriBERT model)"),i$.forEach(t),cno=i(S),Ms=n(S,"LI",{});var d$=s(Ms);Qte=n(d$,"STRONG",{});var BQr=s(Qte);fno=r(BQr,"roberta"),BQr.forEach(t),mno=r(d$," \u2014 "),SB=n(d$,"A",{href:!0});var PQr=s(SB);gno=r(PQr,"RobertaTokenizer"),PQr.forEach(t),hno=r(d$," or "),RB=n(d$,"A",{href:!0});var IQr=s(RB);pno=r(IQr,"RobertaTokenizerFast"),IQr.forEach(t),uno=r(d$," (RoBERTa model)"),d$.forEach(t),_no=i(S),Es=n(S,"LI",{});var c$=s(Es);Wte=n(c$,"STRONG",{});var qQr=s(Wte);bno=r(qQr,"roformer"),qQr.forEach(t),vno=r(c$," \u2014 "),BB=n(c$,"A",{href:!0});var NQr=s(BB);Fno=r(NQr,"RoFormerTokenizer"),NQr.forEach(t),Tno=r(c$," or "),PB=n(c$,"A",{href:!0});var jQr=s(PB);Mno=r(jQr,"RoFormerTokenizerFast"),jQr.forEach(t),Eno=r(c$," (RoFormer model)"),c$.forEach(t),Cno=i(S),Og=n(S,"LI",{});var MCe=s(Og);Hte=n(MCe,"STRONG",{});var DQr=s(Hte);wno=r(DQr,"speech_to_text"),DQr.forEach(t),Ano=r(MCe," \u2014 "),IB=n(MCe,"A",{href:!0});var GQr=s(IB);yno=r(GQr,"Speech2TextTokenizer"),GQr.forEach(t),Lno=r(MCe," (Speech2Text model)"),MCe.forEach(t),xno=i(S),Vg=n(S,"LI",{});var ECe=s(Vg);Ute=n(ECe,"STRONG",{});var OQr=s(Ute);$no=r(OQr,"speech_to_text_2"),OQr.forEach(t),kno=r(ECe," \u2014 "),qB=n(ECe,"A",{href:!0});var VQr=s(qB);Sno=r(VQr,"Speech2Text2Tokenizer"),VQr.forEach(t),Rno=r(ECe," (Speech2Text2 model)"),ECe.forEach(t),Bno=i(S),Cs=n(S,"LI",{});var f$=s(Cs);Jte=n(f$,"STRONG",{});var XQr=s(Jte);Pno=r(XQr,"splinter"),XQr.forEach(t),Ino=r(f$," \u2014 "),NB=n(f$,"A",{href:!0});var zQr=s(NB);qno=r(zQr,"SplinterTokenizer"),zQr.forEach(t),Nno=r(f$," or "),jB=n(f$,"A",{href:!0});var QQr=s(jB);jno=r(QQr,"SplinterTokenizerFast"),QQr.forEach(t),Dno=r(f$," (Splinter model)"),f$.forEach(t),Gno=i(S),ws=n(S,"LI",{});var m$=s(ws);Yte=n(m$,"STRONG",{});var WQr=s(Yte);Ono=r(WQr,"squeezebert"),WQr.forEach(t),Vno=r(m$," \u2014 "),DB=n(m$,"A",{href:!0});var HQr=s(DB);Xno=r(HQr,"SqueezeBertTokenizer"),HQr.forEach(t),zno=r(m$," or "),GB=n(m$,"A",{href:!0});var UQr=s(GB);Qno=r(UQr,"SqueezeBertTokenizerFast"),UQr.forEach(t),Wno=r(m$," (SqueezeBERT model)"),m$.forEach(t),Hno=i(S),As=n(S,"LI",{});var g$=s(As);Kte=n(g$,"STRONG",{});var JQr=s(Kte);Uno=r(JQr,"t5"),JQr.forEach(t),Jno=r(g$," \u2014 "),OB=n(g$,"A",{href:!0});var YQr=s(OB);Yno=r(YQr,"T5Tokenizer"),YQr.forEach(t),Kno=r(g$," or "),VB=n(g$,"A",{href:!0});var KQr=s(VB);Zno=r(KQr,"T5TokenizerFast"),KQr.forEach(t),eso=r(g$," (T5 model)"),g$.forEach(t),oso=i(S),Xg=n(S,"LI",{});var CCe=s(Xg);Zte=n(CCe,"STRONG",{});var ZQr=s(Zte);rso=r(ZQr,"tapas"),ZQr.forEach(t),tso=r(CCe," \u2014 "),XB=n(CCe,"A",{href:!0});var eWr=s(XB);aso=r(eWr,"TapasTokenizer"),eWr.forEach(t),nso=r(CCe," (TAPAS model)"),CCe.forEach(t),sso=i(S),zg=n(S,"LI",{});var wCe=s(zg);eae=n(wCe,"STRONG",{});var oWr=s(eae);lso=r(oWr,"tapex"),oWr.forEach(t),iso=r(wCe," \u2014 "),zB=n(wCe,"A",{href:!0});var rWr=s(zB);dso=r(rWr,"TapexTokenizer"),rWr.forEach(t),cso=r(wCe," (TAPEX model)"),wCe.forEach(t),fso=i(S),Qg=n(S,"LI",{});var ACe=s(Qg);oae=n(ACe,"STRONG",{});var tWr=s(oae);mso=r(tWr,"transfo-xl"),tWr.forEach(t),gso=r(ACe," \u2014 "),QB=n(ACe,"A",{href:!0});var aWr=s(QB);hso=r(aWr,"TransfoXLTokenizer"),aWr.forEach(t),pso=r(ACe," (Transformer-XL model)"),ACe.forEach(t),uso=i(S),ys=n(S,"LI",{});var h$=s(ys);rae=n(h$,"STRONG",{});var nWr=s(rae);_so=r(nWr,"visual_bert"),nWr.forEach(t),bso=r(h$," \u2014 "),WB=n(h$,"A",{href:!0});var sWr=s(WB);vso=r(sWr,"BertTokenizer"),sWr.forEach(t),Fso=r(h$," or "),HB=n(h$,"A",{href:!0});var lWr=s(HB);Tso=r(lWr,"BertTokenizerFast"),lWr.forEach(t),Mso=r(h$," (VisualBert model)"),h$.forEach(t),Eso=i(S),Wg=n(S,"LI",{});var yCe=s(Wg);tae=n(yCe,"STRONG",{});var iWr=s(tae);Cso=r(iWr,"wav2vec2"),iWr.forEach(t),wso=r(yCe," \u2014 "),UB=n(yCe,"A",{href:!0});var dWr=s(UB);Aso=r(dWr,"Wav2Vec2CTCTokenizer"),dWr.forEach(t),yso=r(yCe," (Wav2Vec2 model)"),yCe.forEach(t),Lso=i(S),Hg=n(S,"LI",{});var LCe=s(Hg);aae=n(LCe,"STRONG",{});var cWr=s(aae);xso=r(cWr,"wav2vec2_phoneme"),cWr.forEach(t),$so=r(LCe," \u2014 "),JB=n(LCe,"A",{href:!0});var fWr=s(JB);kso=r(fWr,"Wav2Vec2PhonemeCTCTokenizer"),fWr.forEach(t),Sso=r(LCe," (Wav2Vec2Phoneme model)"),LCe.forEach(t),Rso=i(S),Ls=n(S,"LI",{});var p$=s(Ls);nae=n(p$,"STRONG",{});var mWr=s(nae);Bso=r(mWr,"xglm"),mWr.forEach(t),Pso=r(p$," \u2014 "),YB=n(p$,"A",{href:!0});var gWr=s(YB);Iso=r(gWr,"XGLMTokenizer"),gWr.forEach(t),qso=r(p$," or "),KB=n(p$,"A",{href:!0});var hWr=s(KB);Nso=r(hWr,"XGLMTokenizerFast"),hWr.forEach(t),jso=r(p$," (XGLM model)"),p$.forEach(t),Dso=i(S),Ug=n(S,"LI",{});var xCe=s(Ug);sae=n(xCe,"STRONG",{});var pWr=s(sae);Gso=r(pWr,"xlm"),pWr.forEach(t),Oso=r(xCe," \u2014 "),ZB=n(xCe,"A",{href:!0});var uWr=s(ZB);Vso=r(uWr,"XLMTokenizer"),uWr.forEach(t),Xso=r(xCe," (XLM model)"),xCe.forEach(t),zso=i(S),Jg=n(S,"LI",{});var $Ce=s(Jg);lae=n($Ce,"STRONG",{});var _Wr=s(lae);Qso=r(_Wr,"xlm-prophetnet"),_Wr.forEach(t),Wso=r($Ce," \u2014 "),eP=n($Ce,"A",{href:!0});var bWr=s(eP);Hso=r(bWr,"XLMProphetNetTokenizer"),bWr.forEach(t),Uso=r($Ce," (XLMProphetNet model)"),$Ce.forEach(t),Jso=i(S),xs=n(S,"LI",{});var u$=s(xs);iae=n(u$,"STRONG",{});var vWr=s(iae);Yso=r(vWr,"xlm-roberta"),vWr.forEach(t),Kso=r(u$," \u2014 "),oP=n(u$,"A",{href:!0});var FWr=s(oP);Zso=r(FWr,"XLMRobertaTokenizer"),FWr.forEach(t),elo=r(u$," or "),rP=n(u$,"A",{href:!0});var TWr=s(rP);olo=r(TWr,"XLMRobertaTokenizerFast"),TWr.forEach(t),rlo=r(u$," (XLM-RoBERTa model)"),u$.forEach(t),tlo=i(S),$s=n(S,"LI",{});var _$=s($s);dae=n(_$,"STRONG",{});var MWr=s(dae);alo=r(MWr,"xlm-roberta-xl"),MWr.forEach(t),nlo=r(_$," \u2014 "),tP=n(_$,"A",{href:!0});var EWr=s(tP);slo=r(EWr,"RobertaTokenizer"),EWr.forEach(t),llo=r(_$," or "),aP=n(_$,"A",{href:!0});var CWr=s(aP);ilo=r(CWr,"RobertaTokenizerFast"),CWr.forEach(t),dlo=r(_$," (XLM-RoBERTa-XL model)"),_$.forEach(t),clo=i(S),ks=n(S,"LI",{});var b$=s(ks);cae=n(b$,"STRONG",{});var wWr=s(cae);flo=r(wWr,"xlnet"),wWr.forEach(t),mlo=r(b$," \u2014 "),nP=n(b$,"A",{href:!0});var AWr=s(nP);glo=r(AWr,"XLNetTokenizer"),AWr.forEach(t),hlo=r(b$," or "),sP=n(b$,"A",{href:!0});var yWr=s(sP);plo=r(yWr,"XLNetTokenizerFast"),yWr.forEach(t),ulo=r(b$," (XLNet model)"),b$.forEach(t),_lo=i(S),Ss=n(S,"LI",{});var v$=s(Ss);fae=n(v$,"STRONG",{});var LWr=s(fae);blo=r(LWr,"yoso"),LWr.forEach(t),vlo=r(v$," \u2014 "),lP=n(v$,"A",{href:!0});var xWr=s(lP);Flo=r(xWr,"AlbertTokenizer"),xWr.forEach(t),Tlo=r(v$," or "),iP=n(v$,"A",{href:!0});var $Wr=s(iP);Mlo=r($Wr,"AlbertTokenizerFast"),$Wr.forEach(t),Elo=r(v$," (YOSO model)"),v$.forEach(t),S.forEach(t),Clo=i(qs),T(Yg.$$.fragment,qs),qs.forEach(t),wlo=i(Is),Kg=n(Is,"DIV",{class:!0});var $Ne=s(Kg);T(bA.$$.fragment,$Ne),Alo=i($Ne),mae=n($Ne,"P",{});var kWr=s(mae);ylo=r(kWr,"Register a new tokenizer in this mapping."),kWr.forEach(t),$Ne.forEach(t),Is.forEach(t),kIe=i(f),vi=n(f,"H2",{class:!0});var kNe=s(vi);Zg=n(kNe,"A",{id:!0,class:!0,href:!0});var SWr=s(Zg);gae=n(SWr,"SPAN",{});var RWr=s(gae);T(vA.$$.fragment,RWr),RWr.forEach(t),SWr.forEach(t),Llo=i(kNe),hae=n(kNe,"SPAN",{});var BWr=s(hae);xlo=r(BWr,"AutoFeatureExtractor"),BWr.forEach(t),kNe.forEach(t),SIe=i(f),Ao=n(f,"DIV",{class:!0});var Ns=s(Ao);T(FA.$$.fragment,Ns),$lo=i(Ns),TA=n(Ns,"P",{});var SNe=s(TA);klo=r(SNe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),dP=n(SNe,"A",{href:!0});var PWr=s(dP);Slo=r(PWr,"AutoFeatureExtractor.from_pretrained()"),PWr.forEach(t),Rlo=r(SNe," class method."),SNe.forEach(t),Blo=i(Ns),MA=n(Ns,"P",{});var RNe=s(MA);Plo=r(RNe,"This class cannot be instantiated directly using "),pae=n(RNe,"CODE",{});var IWr=s(pae);Ilo=r(IWr,"__init__()"),IWr.forEach(t),qlo=r(RNe," (throws an error)."),RNe.forEach(t),Nlo=i(Ns),Qe=n(Ns,"DIV",{class:!0});var Yt=s(Qe);T(EA.$$.fragment,Yt),jlo=i(Yt),uae=n(Yt,"P",{});var qWr=s(uae);Dlo=r(qWr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),qWr.forEach(t),Glo=i(Yt),wa=n(Yt,"P",{});var l3=s(wa);Olo=r(l3,"The feature extractor class to instantiate is selected based on the "),_ae=n(l3,"CODE",{});var NWr=s(_ae);Vlo=r(NWr,"model_type"),NWr.forEach(t),Xlo=r(l3,` property of the config object
(either passed as an argument or loaded from `),bae=n(l3,"CODE",{});var jWr=s(bae);zlo=r(jWr,"pretrained_model_name_or_path"),jWr.forEach(t),Qlo=r(l3,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),vae=n(l3,"CODE",{});var DWr=s(vae);Wlo=r(DWr,"pretrained_model_name_or_path"),DWr.forEach(t),Hlo=r(l3,":"),l3.forEach(t),Ulo=i(Yt),Z=n(Yt,"UL",{});var te=s(Z);eh=n(te,"LI",{});var kCe=s(eh);Fae=n(kCe,"STRONG",{});var GWr=s(Fae);Jlo=r(GWr,"beit"),GWr.forEach(t),Ylo=r(kCe," \u2014 "),cP=n(kCe,"A",{href:!0});var OWr=s(cP);Klo=r(OWr,"BeitFeatureExtractor"),OWr.forEach(t),Zlo=r(kCe," (BEiT model)"),kCe.forEach(t),eio=i(te),oh=n(te,"LI",{});var SCe=s(oh);Tae=n(SCe,"STRONG",{});var VWr=s(Tae);oio=r(VWr,"clip"),VWr.forEach(t),rio=r(SCe," \u2014 "),fP=n(SCe,"A",{href:!0});var XWr=s(fP);tio=r(XWr,"CLIPFeatureExtractor"),XWr.forEach(t),aio=r(SCe," (CLIP model)"),SCe.forEach(t),nio=i(te),rh=n(te,"LI",{});var RCe=s(rh);Mae=n(RCe,"STRONG",{});var zWr=s(Mae);sio=r(zWr,"convnext"),zWr.forEach(t),lio=r(RCe," \u2014 "),mP=n(RCe,"A",{href:!0});var QWr=s(mP);iio=r(QWr,"ConvNextFeatureExtractor"),QWr.forEach(t),dio=r(RCe," (ConvNext model)"),RCe.forEach(t),cio=i(te),th=n(te,"LI",{});var BCe=s(th);Eae=n(BCe,"STRONG",{});var WWr=s(Eae);fio=r(WWr,"data2vec-audio"),WWr.forEach(t),mio=r(BCe," \u2014 "),gP=n(BCe,"A",{href:!0});var HWr=s(gP);gio=r(HWr,"Wav2Vec2FeatureExtractor"),HWr.forEach(t),hio=r(BCe," (Data2VecAudio model)"),BCe.forEach(t),pio=i(te),ah=n(te,"LI",{});var PCe=s(ah);Cae=n(PCe,"STRONG",{});var UWr=s(Cae);uio=r(UWr,"data2vec-vision"),UWr.forEach(t),_io=r(PCe," \u2014 "),hP=n(PCe,"A",{href:!0});var JWr=s(hP);bio=r(JWr,"BeitFeatureExtractor"),JWr.forEach(t),vio=r(PCe," (Data2VecVision model)"),PCe.forEach(t),Fio=i(te),nh=n(te,"LI",{});var ICe=s(nh);wae=n(ICe,"STRONG",{});var YWr=s(wae);Tio=r(YWr,"deit"),YWr.forEach(t),Mio=r(ICe," \u2014 "),pP=n(ICe,"A",{href:!0});var KWr=s(pP);Eio=r(KWr,"DeiTFeatureExtractor"),KWr.forEach(t),Cio=r(ICe," (DeiT model)"),ICe.forEach(t),wio=i(te),sh=n(te,"LI",{});var qCe=s(sh);Aae=n(qCe,"STRONG",{});var ZWr=s(Aae);Aio=r(ZWr,"detr"),ZWr.forEach(t),yio=r(qCe," \u2014 "),uP=n(qCe,"A",{href:!0});var eHr=s(uP);Lio=r(eHr,"DetrFeatureExtractor"),eHr.forEach(t),xio=r(qCe," (DETR model)"),qCe.forEach(t),$io=i(te),lh=n(te,"LI",{});var NCe=s(lh);yae=n(NCe,"STRONG",{});var oHr=s(yae);kio=r(oHr,"dpt"),oHr.forEach(t),Sio=r(NCe," \u2014 "),_P=n(NCe,"A",{href:!0});var rHr=s(_P);Rio=r(rHr,"DPTFeatureExtractor"),rHr.forEach(t),Bio=r(NCe," (DPT model)"),NCe.forEach(t),Pio=i(te),ih=n(te,"LI",{});var jCe=s(ih);Lae=n(jCe,"STRONG",{});var tHr=s(Lae);Iio=r(tHr,"flava"),tHr.forEach(t),qio=r(jCe," \u2014 "),bP=n(jCe,"A",{href:!0});var aHr=s(bP);Nio=r(aHr,"FlavaFeatureExtractor"),aHr.forEach(t),jio=r(jCe," (Flava model)"),jCe.forEach(t),Dio=i(te),dh=n(te,"LI",{});var DCe=s(dh);xae=n(DCe,"STRONG",{});var nHr=s(xae);Gio=r(nHr,"glpn"),nHr.forEach(t),Oio=r(DCe," \u2014 "),vP=n(DCe,"A",{href:!0});var sHr=s(vP);Vio=r(sHr,"GLPNFeatureExtractor"),sHr.forEach(t),Xio=r(DCe," (GLPN model)"),DCe.forEach(t),zio=i(te),ch=n(te,"LI",{});var GCe=s(ch);$ae=n(GCe,"STRONG",{});var lHr=s($ae);Qio=r(lHr,"hubert"),lHr.forEach(t),Wio=r(GCe," \u2014 "),FP=n(GCe,"A",{href:!0});var iHr=s(FP);Hio=r(iHr,"Wav2Vec2FeatureExtractor"),iHr.forEach(t),Uio=r(GCe," (Hubert model)"),GCe.forEach(t),Jio=i(te),fh=n(te,"LI",{});var OCe=s(fh);kae=n(OCe,"STRONG",{});var dHr=s(kae);Yio=r(dHr,"layoutlmv2"),dHr.forEach(t),Kio=r(OCe," \u2014 "),TP=n(OCe,"A",{href:!0});var cHr=s(TP);Zio=r(cHr,"LayoutLMv2FeatureExtractor"),cHr.forEach(t),edo=r(OCe," (LayoutLMv2 model)"),OCe.forEach(t),odo=i(te),mh=n(te,"LI",{});var VCe=s(mh);Sae=n(VCe,"STRONG",{});var fHr=s(Sae);rdo=r(fHr,"layoutlmv3"),fHr.forEach(t),tdo=r(VCe," \u2014 "),MP=n(VCe,"A",{href:!0});var mHr=s(MP);ado=r(mHr,"LayoutLMv3FeatureExtractor"),mHr.forEach(t),ndo=r(VCe," (LayoutLMv3 model)"),VCe.forEach(t),sdo=i(te),gh=n(te,"LI",{});var XCe=s(gh);Rae=n(XCe,"STRONG",{});var gHr=s(Rae);ldo=r(gHr,"maskformer"),gHr.forEach(t),ido=r(XCe," \u2014 "),EP=n(XCe,"A",{href:!0});var hHr=s(EP);ddo=r(hHr,"MaskFormerFeatureExtractor"),hHr.forEach(t),cdo=r(XCe," (MaskFormer model)"),XCe.forEach(t),fdo=i(te),hh=n(te,"LI",{});var zCe=s(hh);Bae=n(zCe,"STRONG",{});var pHr=s(Bae);mdo=r(pHr,"perceiver"),pHr.forEach(t),gdo=r(zCe," \u2014 "),CP=n(zCe,"A",{href:!0});var uHr=s(CP);hdo=r(uHr,"PerceiverFeatureExtractor"),uHr.forEach(t),pdo=r(zCe," (Perceiver model)"),zCe.forEach(t),udo=i(te),ph=n(te,"LI",{});var QCe=s(ph);Pae=n(QCe,"STRONG",{});var _Hr=s(Pae);_do=r(_Hr,"poolformer"),_Hr.forEach(t),bdo=r(QCe," \u2014 "),wP=n(QCe,"A",{href:!0});var bHr=s(wP);vdo=r(bHr,"PoolFormerFeatureExtractor"),bHr.forEach(t),Fdo=r(QCe," (PoolFormer model)"),QCe.forEach(t),Tdo=i(te),uh=n(te,"LI",{});var WCe=s(uh);Iae=n(WCe,"STRONG",{});var vHr=s(Iae);Mdo=r(vHr,"regnet"),vHr.forEach(t),Edo=r(WCe," \u2014 "),AP=n(WCe,"A",{href:!0});var FHr=s(AP);Cdo=r(FHr,"ConvNextFeatureExtractor"),FHr.forEach(t),wdo=r(WCe," (RegNet model)"),WCe.forEach(t),Ado=i(te),_h=n(te,"LI",{});var HCe=s(_h);qae=n(HCe,"STRONG",{});var THr=s(qae);ydo=r(THr,"resnet"),THr.forEach(t),Ldo=r(HCe," \u2014 "),yP=n(HCe,"A",{href:!0});var MHr=s(yP);xdo=r(MHr,"ConvNextFeatureExtractor"),MHr.forEach(t),$do=r(HCe," (ResNet model)"),HCe.forEach(t),kdo=i(te),bh=n(te,"LI",{});var UCe=s(bh);Nae=n(UCe,"STRONG",{});var EHr=s(Nae);Sdo=r(EHr,"segformer"),EHr.forEach(t),Rdo=r(UCe," \u2014 "),LP=n(UCe,"A",{href:!0});var CHr=s(LP);Bdo=r(CHr,"SegformerFeatureExtractor"),CHr.forEach(t),Pdo=r(UCe," (SegFormer model)"),UCe.forEach(t),Ido=i(te),vh=n(te,"LI",{});var JCe=s(vh);jae=n(JCe,"STRONG",{});var wHr=s(jae);qdo=r(wHr,"speech_to_text"),wHr.forEach(t),Ndo=r(JCe," \u2014 "),xP=n(JCe,"A",{href:!0});var AHr=s(xP);jdo=r(AHr,"Speech2TextFeatureExtractor"),AHr.forEach(t),Ddo=r(JCe," (Speech2Text model)"),JCe.forEach(t),Gdo=i(te),Fh=n(te,"LI",{});var YCe=s(Fh);Dae=n(YCe,"STRONG",{});var yHr=s(Dae);Odo=r(yHr,"swin"),yHr.forEach(t),Vdo=r(YCe," \u2014 "),$P=n(YCe,"A",{href:!0});var LHr=s($P);Xdo=r(LHr,"ViTFeatureExtractor"),LHr.forEach(t),zdo=r(YCe," (Swin model)"),YCe.forEach(t),Qdo=i(te),Th=n(te,"LI",{});var KCe=s(Th);Gae=n(KCe,"STRONG",{});var xHr=s(Gae);Wdo=r(xHr,"van"),xHr.forEach(t),Hdo=r(KCe," \u2014 "),kP=n(KCe,"A",{href:!0});var $Hr=s(kP);Udo=r($Hr,"ConvNextFeatureExtractor"),$Hr.forEach(t),Jdo=r(KCe," (VAN model)"),KCe.forEach(t),Ydo=i(te),Mh=n(te,"LI",{});var ZCe=s(Mh);Oae=n(ZCe,"STRONG",{});var kHr=s(Oae);Kdo=r(kHr,"vit"),kHr.forEach(t),Zdo=r(ZCe," \u2014 "),SP=n(ZCe,"A",{href:!0});var SHr=s(SP);eco=r(SHr,"ViTFeatureExtractor"),SHr.forEach(t),oco=r(ZCe," (ViT model)"),ZCe.forEach(t),rco=i(te),Eh=n(te,"LI",{});var e3e=s(Eh);Vae=n(e3e,"STRONG",{});var RHr=s(Vae);tco=r(RHr,"vit_mae"),RHr.forEach(t),aco=r(e3e," \u2014 "),RP=n(e3e,"A",{href:!0});var BHr=s(RP);nco=r(BHr,"ViTFeatureExtractor"),BHr.forEach(t),sco=r(e3e," (ViTMAE model)"),e3e.forEach(t),lco=i(te),Ch=n(te,"LI",{});var o3e=s(Ch);Xae=n(o3e,"STRONG",{});var PHr=s(Xae);ico=r(PHr,"wav2vec2"),PHr.forEach(t),dco=r(o3e," \u2014 "),BP=n(o3e,"A",{href:!0});var IHr=s(BP);cco=r(IHr,"Wav2Vec2FeatureExtractor"),IHr.forEach(t),fco=r(o3e," (Wav2Vec2 model)"),o3e.forEach(t),mco=i(te),wh=n(te,"LI",{});var r3e=s(wh);zae=n(r3e,"STRONG",{});var qHr=s(zae);gco=r(qHr,"yolos"),qHr.forEach(t),hco=r(r3e," \u2014 "),PP=n(r3e,"A",{href:!0});var NHr=s(PP);pco=r(NHr,"YolosFeatureExtractor"),NHr.forEach(t),uco=r(r3e," (YOLOS model)"),r3e.forEach(t),te.forEach(t),_co=i(Yt),T(Ah.$$.fragment,Yt),bco=i(Yt),T(yh.$$.fragment,Yt),Yt.forEach(t),vco=i(Ns),Lh=n(Ns,"DIV",{class:!0});var BNe=s(Lh);T(CA.$$.fragment,BNe),Fco=i(BNe),Qae=n(BNe,"P",{});var jHr=s(Qae);Tco=r(jHr,"Register a new feature extractor for this class."),jHr.forEach(t),BNe.forEach(t),Ns.forEach(t),RIe=i(f),Fi=n(f,"H2",{class:!0});var PNe=s(Fi);xh=n(PNe,"A",{id:!0,class:!0,href:!0});var DHr=s(xh);Wae=n(DHr,"SPAN",{});var GHr=s(Wae);T(wA.$$.fragment,GHr),GHr.forEach(t),DHr.forEach(t),Mco=i(PNe),Hae=n(PNe,"SPAN",{});var OHr=s(Hae);Eco=r(OHr,"AutoProcessor"),OHr.forEach(t),PNe.forEach(t),BIe=i(f),yo=n(f,"DIV",{class:!0});var js=s(yo);T(AA.$$.fragment,js),Cco=i(js),yA=n(js,"P",{});var INe=s(yA);wco=r(INe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),IP=n(INe,"A",{href:!0});var VHr=s(IP);Aco=r(VHr,"AutoProcessor.from_pretrained()"),VHr.forEach(t),yco=r(INe," class method."),INe.forEach(t),Lco=i(js),LA=n(js,"P",{});var qNe=s(LA);xco=r(qNe,"This class cannot be instantiated directly using "),Uae=n(qNe,"CODE",{});var XHr=s(Uae);$co=r(XHr,"__init__()"),XHr.forEach(t),kco=r(qNe," (throws an error)."),qNe.forEach(t),Sco=i(js),We=n(js,"DIV",{class:!0});var Kt=s(We);T(xA.$$.fragment,Kt),Rco=i(Kt),Jae=n(Kt,"P",{});var zHr=s(Jae);Bco=r(zHr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),zHr.forEach(t),Pco=i(Kt),Ti=n(Kt,"P",{});var wK=s(Ti);Ico=r(wK,"The processor class to instantiate is selected based on the "),Yae=n(wK,"CODE",{});var QHr=s(Yae);qco=r(QHr,"model_type"),QHr.forEach(t),Nco=r(wK,` property of the config object (either
passed as an argument or loaded from `),Kae=n(wK,"CODE",{});var WHr=s(Kae);jco=r(WHr,"pretrained_model_name_or_path"),WHr.forEach(t),Dco=r(wK," if possible):"),wK.forEach(t),Gco=i(Kt),ue=n(Kt,"UL",{});var ve=s(ue);$h=n(ve,"LI",{});var t3e=s($h);Zae=n(t3e,"STRONG",{});var HHr=s(Zae);Oco=r(HHr,"clip"),HHr.forEach(t),Vco=r(t3e," \u2014 "),qP=n(t3e,"A",{href:!0});var UHr=s(qP);Xco=r(UHr,"CLIPProcessor"),UHr.forEach(t),zco=r(t3e," (CLIP model)"),t3e.forEach(t),Qco=i(ve),kh=n(ve,"LI",{});var a3e=s(kh);ene=n(a3e,"STRONG",{});var JHr=s(ene);Wco=r(JHr,"flava"),JHr.forEach(t),Hco=r(a3e," \u2014 "),one=n(a3e,"CODE",{});var YHr=s(one);Uco=r(YHr,"FLAVAProcessor"),YHr.forEach(t),Jco=r(a3e," (Flava model)"),a3e.forEach(t),Yco=i(ve),Sh=n(ve,"LI",{});var n3e=s(Sh);rne=n(n3e,"STRONG",{});var KHr=s(rne);Kco=r(KHr,"layoutlmv2"),KHr.forEach(t),Zco=r(n3e," \u2014 "),NP=n(n3e,"A",{href:!0});var ZHr=s(NP);efo=r(ZHr,"LayoutLMv2Processor"),ZHr.forEach(t),ofo=r(n3e," (LayoutLMv2 model)"),n3e.forEach(t),rfo=i(ve),Rh=n(ve,"LI",{});var s3e=s(Rh);tne=n(s3e,"STRONG",{});var eUr=s(tne);tfo=r(eUr,"layoutlmv3"),eUr.forEach(t),afo=r(s3e," \u2014 "),jP=n(s3e,"A",{href:!0});var oUr=s(jP);nfo=r(oUr,"LayoutLMv3Processor"),oUr.forEach(t),sfo=r(s3e," (LayoutLMv3 model)"),s3e.forEach(t),lfo=i(ve),Bh=n(ve,"LI",{});var l3e=s(Bh);ane=n(l3e,"STRONG",{});var rUr=s(ane);ifo=r(rUr,"layoutxlm"),rUr.forEach(t),dfo=r(l3e," \u2014 "),DP=n(l3e,"A",{href:!0});var tUr=s(DP);cfo=r(tUr,"LayoutXLMProcessor"),tUr.forEach(t),ffo=r(l3e," (LayoutXLM model)"),l3e.forEach(t),mfo=i(ve),Ph=n(ve,"LI",{});var i3e=s(Ph);nne=n(i3e,"STRONG",{});var aUr=s(nne);gfo=r(aUr,"sew"),aUr.forEach(t),hfo=r(i3e," \u2014 "),GP=n(i3e,"A",{href:!0});var nUr=s(GP);pfo=r(nUr,"Wav2Vec2Processor"),nUr.forEach(t),ufo=r(i3e," (SEW model)"),i3e.forEach(t),_fo=i(ve),Ih=n(ve,"LI",{});var d3e=s(Ih);sne=n(d3e,"STRONG",{});var sUr=s(sne);bfo=r(sUr,"sew-d"),sUr.forEach(t),vfo=r(d3e," \u2014 "),OP=n(d3e,"A",{href:!0});var lUr=s(OP);Ffo=r(lUr,"Wav2Vec2Processor"),lUr.forEach(t),Tfo=r(d3e," (SEW-D model)"),d3e.forEach(t),Mfo=i(ve),qh=n(ve,"LI",{});var c3e=s(qh);lne=n(c3e,"STRONG",{});var iUr=s(lne);Efo=r(iUr,"speech_to_text"),iUr.forEach(t),Cfo=r(c3e," \u2014 "),VP=n(c3e,"A",{href:!0});var dUr=s(VP);wfo=r(dUr,"Speech2TextProcessor"),dUr.forEach(t),Afo=r(c3e," (Speech2Text model)"),c3e.forEach(t),yfo=i(ve),Nh=n(ve,"LI",{});var f3e=s(Nh);ine=n(f3e,"STRONG",{});var cUr=s(ine);Lfo=r(cUr,"speech_to_text_2"),cUr.forEach(t),xfo=r(f3e," \u2014 "),XP=n(f3e,"A",{href:!0});var fUr=s(XP);$fo=r(fUr,"Speech2Text2Processor"),fUr.forEach(t),kfo=r(f3e," (Speech2Text2 model)"),f3e.forEach(t),Sfo=i(ve),jh=n(ve,"LI",{});var m3e=s(jh);dne=n(m3e,"STRONG",{});var mUr=s(dne);Rfo=r(mUr,"trocr"),mUr.forEach(t),Bfo=r(m3e," \u2014 "),zP=n(m3e,"A",{href:!0});var gUr=s(zP);Pfo=r(gUr,"TrOCRProcessor"),gUr.forEach(t),Ifo=r(m3e," (TrOCR model)"),m3e.forEach(t),qfo=i(ve),Dh=n(ve,"LI",{});var g3e=s(Dh);cne=n(g3e,"STRONG",{});var hUr=s(cne);Nfo=r(hUr,"unispeech"),hUr.forEach(t),jfo=r(g3e," \u2014 "),QP=n(g3e,"A",{href:!0});var pUr=s(QP);Dfo=r(pUr,"Wav2Vec2Processor"),pUr.forEach(t),Gfo=r(g3e," (UniSpeech model)"),g3e.forEach(t),Ofo=i(ve),Gh=n(ve,"LI",{});var h3e=s(Gh);fne=n(h3e,"STRONG",{});var uUr=s(fne);Vfo=r(uUr,"unispeech-sat"),uUr.forEach(t),Xfo=r(h3e," \u2014 "),WP=n(h3e,"A",{href:!0});var _Ur=s(WP);zfo=r(_Ur,"Wav2Vec2Processor"),_Ur.forEach(t),Qfo=r(h3e," (UniSpeechSat model)"),h3e.forEach(t),Wfo=i(ve),Oh=n(ve,"LI",{});var p3e=s(Oh);mne=n(p3e,"STRONG",{});var bUr=s(mne);Hfo=r(bUr,"vilt"),bUr.forEach(t),Ufo=r(p3e," \u2014 "),HP=n(p3e,"A",{href:!0});var vUr=s(HP);Jfo=r(vUr,"ViltProcessor"),vUr.forEach(t),Yfo=r(p3e," (ViLT model)"),p3e.forEach(t),Kfo=i(ve),Vh=n(ve,"LI",{});var u3e=s(Vh);gne=n(u3e,"STRONG",{});var FUr=s(gne);Zfo=r(FUr,"vision-text-dual-encoder"),FUr.forEach(t),emo=r(u3e," \u2014 "),UP=n(u3e,"A",{href:!0});var TUr=s(UP);omo=r(TUr,"VisionTextDualEncoderProcessor"),TUr.forEach(t),rmo=r(u3e," (VisionTextDualEncoder model)"),u3e.forEach(t),tmo=i(ve),Xh=n(ve,"LI",{});var _3e=s(Xh);hne=n(_3e,"STRONG",{});var MUr=s(hne);amo=r(MUr,"wav2vec2"),MUr.forEach(t),nmo=r(_3e," \u2014 "),JP=n(_3e,"A",{href:!0});var EUr=s(JP);smo=r(EUr,"Wav2Vec2Processor"),EUr.forEach(t),lmo=r(_3e," (Wav2Vec2 model)"),_3e.forEach(t),imo=i(ve),zh=n(ve,"LI",{});var b3e=s(zh);pne=n(b3e,"STRONG",{});var CUr=s(pne);dmo=r(CUr,"wavlm"),CUr.forEach(t),cmo=r(b3e," \u2014 "),YP=n(b3e,"A",{href:!0});var wUr=s(YP);fmo=r(wUr,"Wav2Vec2Processor"),wUr.forEach(t),mmo=r(b3e," (WavLM model)"),b3e.forEach(t),ve.forEach(t),gmo=i(Kt),T(Qh.$$.fragment,Kt),hmo=i(Kt),T(Wh.$$.fragment,Kt),Kt.forEach(t),pmo=i(js),Hh=n(js,"DIV",{class:!0});var NNe=s(Hh);T($A.$$.fragment,NNe),umo=i(NNe),une=n(NNe,"P",{});var AUr=s(une);_mo=r(AUr,"Register a new processor for this class."),AUr.forEach(t),NNe.forEach(t),js.forEach(t),PIe=i(f),Mi=n(f,"H2",{class:!0});var jNe=s(Mi);Uh=n(jNe,"A",{id:!0,class:!0,href:!0});var yUr=s(Uh);_ne=n(yUr,"SPAN",{});var LUr=s(_ne);T(kA.$$.fragment,LUr),LUr.forEach(t),yUr.forEach(t),bmo=i(jNe),bne=n(jNe,"SPAN",{});var xUr=s(bne);vmo=r(xUr,"AutoModel"),xUr.forEach(t),jNe.forEach(t),IIe=i(f),Lo=n(f,"DIV",{class:!0});var Ds=s(Lo);T(SA.$$.fragment,Ds),Fmo=i(Ds),Ei=n(Ds,"P",{});var AK=s(Ei);Tmo=r(AK,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),KP=n(AK,"A",{href:!0});var $Ur=s(KP);Mmo=r($Ur,"from_pretrained()"),$Ur.forEach(t),Emo=r(AK," class method or the "),ZP=n(AK,"A",{href:!0});var kUr=s(ZP);Cmo=r(kUr,"from_config()"),kUr.forEach(t),wmo=r(AK,` class
method.`),AK.forEach(t),Amo=i(Ds),RA=n(Ds,"P",{});var DNe=s(RA);ymo=r(DNe,"This class cannot be instantiated directly using "),vne=n(DNe,"CODE",{});var SUr=s(vne);Lmo=r(SUr,"__init__()"),SUr.forEach(t),xmo=r(DNe," (throws an error)."),DNe.forEach(t),$mo=i(Ds),ot=n(Ds,"DIV",{class:!0});var i3=s(ot);T(BA.$$.fragment,i3),kmo=i(i3),Fne=n(i3,"P",{});var RUr=s(Fne);Smo=r(RUr,"Instantiates one of the base model classes of the library from a configuration."),RUr.forEach(t),Rmo=i(i3),Ci=n(i3,"P",{});var yK=s(Ci);Bmo=r(yK,`Note:
Loading a model from its configuration file does `),Tne=n(yK,"STRONG",{});var BUr=s(Tne);Pmo=r(BUr,"not"),BUr.forEach(t),Imo=r(yK,` load the model weights. It only affects the
model\u2019s configuration. Use `),eI=n(yK,"A",{href:!0});var PUr=s(eI);qmo=r(PUr,"from_pretrained()"),PUr.forEach(t),Nmo=r(yK," to load the model weights."),yK.forEach(t),jmo=i(i3),T(Jh.$$.fragment,i3),i3.forEach(t),Dmo=i(Ds),He=n(Ds,"DIV",{class:!0});var Zt=s(He);T(PA.$$.fragment,Zt),Gmo=i(Zt),Mne=n(Zt,"P",{});var IUr=s(Mne);Omo=r(IUr,"Instantiate one of the base model classes of the library from a pretrained model."),IUr.forEach(t),Vmo=i(Zt),Aa=n(Zt,"P",{});var d3=s(Aa);Xmo=r(d3,"The model class to instantiate is selected based on the "),Ene=n(d3,"CODE",{});var qUr=s(Ene);zmo=r(qUr,"model_type"),qUr.forEach(t),Qmo=r(d3,` property of the config object (either
passed as an argument or loaded from `),Cne=n(d3,"CODE",{});var NUr=s(Cne);Wmo=r(NUr,"pretrained_model_name_or_path"),NUr.forEach(t),Hmo=r(d3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wne=n(d3,"CODE",{});var jUr=s(wne);Umo=r(jUr,"pretrained_model_name_or_path"),jUr.forEach(t),Jmo=r(d3,":"),d3.forEach(t),Ymo=i(Zt),x=n(Zt,"UL",{});var $=s(x);Yh=n($,"LI",{});var v3e=s(Yh);Ane=n(v3e,"STRONG",{});var DUr=s(Ane);Kmo=r(DUr,"albert"),DUr.forEach(t),Zmo=r(v3e," \u2014 "),oI=n(v3e,"A",{href:!0});var GUr=s(oI);ego=r(GUr,"AlbertModel"),GUr.forEach(t),ogo=r(v3e," (ALBERT model)"),v3e.forEach(t),rgo=i($),Kh=n($,"LI",{});var F3e=s(Kh);yne=n(F3e,"STRONG",{});var OUr=s(yne);tgo=r(OUr,"bart"),OUr.forEach(t),ago=r(F3e," \u2014 "),rI=n(F3e,"A",{href:!0});var VUr=s(rI);ngo=r(VUr,"BartModel"),VUr.forEach(t),sgo=r(F3e," (BART model)"),F3e.forEach(t),lgo=i($),Zh=n($,"LI",{});var T3e=s(Zh);Lne=n(T3e,"STRONG",{});var XUr=s(Lne);igo=r(XUr,"beit"),XUr.forEach(t),dgo=r(T3e," \u2014 "),tI=n(T3e,"A",{href:!0});var zUr=s(tI);cgo=r(zUr,"BeitModel"),zUr.forEach(t),fgo=r(T3e," (BEiT model)"),T3e.forEach(t),mgo=i($),ep=n($,"LI",{});var M3e=s(ep);xne=n(M3e,"STRONG",{});var QUr=s(xne);ggo=r(QUr,"bert"),QUr.forEach(t),hgo=r(M3e," \u2014 "),aI=n(M3e,"A",{href:!0});var WUr=s(aI);pgo=r(WUr,"BertModel"),WUr.forEach(t),ugo=r(M3e," (BERT model)"),M3e.forEach(t),_go=i($),op=n($,"LI",{});var E3e=s(op);$ne=n(E3e,"STRONG",{});var HUr=s($ne);bgo=r(HUr,"bert-generation"),HUr.forEach(t),vgo=r(E3e," \u2014 "),nI=n(E3e,"A",{href:!0});var UUr=s(nI);Fgo=r(UUr,"BertGenerationEncoder"),UUr.forEach(t),Tgo=r(E3e," (Bert Generation model)"),E3e.forEach(t),Mgo=i($),rp=n($,"LI",{});var C3e=s(rp);kne=n(C3e,"STRONG",{});var JUr=s(kne);Ego=r(JUr,"big_bird"),JUr.forEach(t),Cgo=r(C3e," \u2014 "),sI=n(C3e,"A",{href:!0});var YUr=s(sI);wgo=r(YUr,"BigBirdModel"),YUr.forEach(t),Ago=r(C3e," (BigBird model)"),C3e.forEach(t),ygo=i($),tp=n($,"LI",{});var w3e=s(tp);Sne=n(w3e,"STRONG",{});var KUr=s(Sne);Lgo=r(KUr,"bigbird_pegasus"),KUr.forEach(t),xgo=r(w3e," \u2014 "),lI=n(w3e,"A",{href:!0});var ZUr=s(lI);$go=r(ZUr,"BigBirdPegasusModel"),ZUr.forEach(t),kgo=r(w3e," (BigBirdPegasus model)"),w3e.forEach(t),Sgo=i($),ap=n($,"LI",{});var A3e=s(ap);Rne=n(A3e,"STRONG",{});var eJr=s(Rne);Rgo=r(eJr,"blenderbot"),eJr.forEach(t),Bgo=r(A3e," \u2014 "),iI=n(A3e,"A",{href:!0});var oJr=s(iI);Pgo=r(oJr,"BlenderbotModel"),oJr.forEach(t),Igo=r(A3e," (Blenderbot model)"),A3e.forEach(t),qgo=i($),np=n($,"LI",{});var y3e=s(np);Bne=n(y3e,"STRONG",{});var rJr=s(Bne);Ngo=r(rJr,"blenderbot-small"),rJr.forEach(t),jgo=r(y3e," \u2014 "),dI=n(y3e,"A",{href:!0});var tJr=s(dI);Dgo=r(tJr,"BlenderbotSmallModel"),tJr.forEach(t),Ggo=r(y3e," (BlenderbotSmall model)"),y3e.forEach(t),Ogo=i($),sp=n($,"LI",{});var L3e=s(sp);Pne=n(L3e,"STRONG",{});var aJr=s(Pne);Vgo=r(aJr,"camembert"),aJr.forEach(t),Xgo=r(L3e," \u2014 "),cI=n(L3e,"A",{href:!0});var nJr=s(cI);zgo=r(nJr,"CamembertModel"),nJr.forEach(t),Qgo=r(L3e," (CamemBERT model)"),L3e.forEach(t),Wgo=i($),lp=n($,"LI",{});var x3e=s(lp);Ine=n(x3e,"STRONG",{});var sJr=s(Ine);Hgo=r(sJr,"canine"),sJr.forEach(t),Ugo=r(x3e," \u2014 "),fI=n(x3e,"A",{href:!0});var lJr=s(fI);Jgo=r(lJr,"CanineModel"),lJr.forEach(t),Ygo=r(x3e," (Canine model)"),x3e.forEach(t),Kgo=i($),ip=n($,"LI",{});var $3e=s(ip);qne=n($3e,"STRONG",{});var iJr=s(qne);Zgo=r(iJr,"clip"),iJr.forEach(t),eho=r($3e," \u2014 "),mI=n($3e,"A",{href:!0});var dJr=s(mI);oho=r(dJr,"CLIPModel"),dJr.forEach(t),rho=r($3e," (CLIP model)"),$3e.forEach(t),tho=i($),dp=n($,"LI",{});var k3e=s(dp);Nne=n(k3e,"STRONG",{});var cJr=s(Nne);aho=r(cJr,"convbert"),cJr.forEach(t),nho=r(k3e," \u2014 "),gI=n(k3e,"A",{href:!0});var fJr=s(gI);sho=r(fJr,"ConvBertModel"),fJr.forEach(t),lho=r(k3e," (ConvBERT model)"),k3e.forEach(t),iho=i($),cp=n($,"LI",{});var S3e=s(cp);jne=n(S3e,"STRONG",{});var mJr=s(jne);dho=r(mJr,"convnext"),mJr.forEach(t),cho=r(S3e," \u2014 "),hI=n(S3e,"A",{href:!0});var gJr=s(hI);fho=r(gJr,"ConvNextModel"),gJr.forEach(t),mho=r(S3e," (ConvNext model)"),S3e.forEach(t),gho=i($),fp=n($,"LI",{});var R3e=s(fp);Dne=n(R3e,"STRONG",{});var hJr=s(Dne);hho=r(hJr,"ctrl"),hJr.forEach(t),pho=r(R3e," \u2014 "),pI=n(R3e,"A",{href:!0});var pJr=s(pI);uho=r(pJr,"CTRLModel"),pJr.forEach(t),_ho=r(R3e," (CTRL model)"),R3e.forEach(t),bho=i($),mp=n($,"LI",{});var B3e=s(mp);Gne=n(B3e,"STRONG",{});var uJr=s(Gne);vho=r(uJr,"data2vec-audio"),uJr.forEach(t),Fho=r(B3e," \u2014 "),uI=n(B3e,"A",{href:!0});var _Jr=s(uI);Tho=r(_Jr,"Data2VecAudioModel"),_Jr.forEach(t),Mho=r(B3e," (Data2VecAudio model)"),B3e.forEach(t),Eho=i($),gp=n($,"LI",{});var P3e=s(gp);One=n(P3e,"STRONG",{});var bJr=s(One);Cho=r(bJr,"data2vec-text"),bJr.forEach(t),who=r(P3e," \u2014 "),_I=n(P3e,"A",{href:!0});var vJr=s(_I);Aho=r(vJr,"Data2VecTextModel"),vJr.forEach(t),yho=r(P3e," (Data2VecText model)"),P3e.forEach(t),Lho=i($),hp=n($,"LI",{});var I3e=s(hp);Vne=n(I3e,"STRONG",{});var FJr=s(Vne);xho=r(FJr,"data2vec-vision"),FJr.forEach(t),$ho=r(I3e," \u2014 "),bI=n(I3e,"A",{href:!0});var TJr=s(bI);kho=r(TJr,"Data2VecVisionModel"),TJr.forEach(t),Sho=r(I3e," (Data2VecVision model)"),I3e.forEach(t),Rho=i($),pp=n($,"LI",{});var q3e=s(pp);Xne=n(q3e,"STRONG",{});var MJr=s(Xne);Bho=r(MJr,"deberta"),MJr.forEach(t),Pho=r(q3e," \u2014 "),vI=n(q3e,"A",{href:!0});var EJr=s(vI);Iho=r(EJr,"DebertaModel"),EJr.forEach(t),qho=r(q3e," (DeBERTa model)"),q3e.forEach(t),Nho=i($),up=n($,"LI",{});var N3e=s(up);zne=n(N3e,"STRONG",{});var CJr=s(zne);jho=r(CJr,"deberta-v2"),CJr.forEach(t),Dho=r(N3e," \u2014 "),FI=n(N3e,"A",{href:!0});var wJr=s(FI);Gho=r(wJr,"DebertaV2Model"),wJr.forEach(t),Oho=r(N3e," (DeBERTa-v2 model)"),N3e.forEach(t),Vho=i($),_p=n($,"LI",{});var j3e=s(_p);Qne=n(j3e,"STRONG",{});var AJr=s(Qne);Xho=r(AJr,"decision_transformer"),AJr.forEach(t),zho=r(j3e," \u2014 "),TI=n(j3e,"A",{href:!0});var yJr=s(TI);Qho=r(yJr,"DecisionTransformerModel"),yJr.forEach(t),Who=r(j3e," (Decision Transformer model)"),j3e.forEach(t),Hho=i($),bp=n($,"LI",{});var D3e=s(bp);Wne=n(D3e,"STRONG",{});var LJr=s(Wne);Uho=r(LJr,"deit"),LJr.forEach(t),Jho=r(D3e," \u2014 "),MI=n(D3e,"A",{href:!0});var xJr=s(MI);Yho=r(xJr,"DeiTModel"),xJr.forEach(t),Kho=r(D3e," (DeiT model)"),D3e.forEach(t),Zho=i($),vp=n($,"LI",{});var G3e=s(vp);Hne=n(G3e,"STRONG",{});var $Jr=s(Hne);epo=r($Jr,"detr"),$Jr.forEach(t),opo=r(G3e," \u2014 "),EI=n(G3e,"A",{href:!0});var kJr=s(EI);rpo=r(kJr,"DetrModel"),kJr.forEach(t),tpo=r(G3e," (DETR model)"),G3e.forEach(t),apo=i($),Fp=n($,"LI",{});var O3e=s(Fp);Une=n(O3e,"STRONG",{});var SJr=s(Une);npo=r(SJr,"distilbert"),SJr.forEach(t),spo=r(O3e," \u2014 "),CI=n(O3e,"A",{href:!0});var RJr=s(CI);lpo=r(RJr,"DistilBertModel"),RJr.forEach(t),ipo=r(O3e," (DistilBERT model)"),O3e.forEach(t),dpo=i($),Tp=n($,"LI",{});var V3e=s(Tp);Jne=n(V3e,"STRONG",{});var BJr=s(Jne);cpo=r(BJr,"dpr"),BJr.forEach(t),fpo=r(V3e," \u2014 "),wI=n(V3e,"A",{href:!0});var PJr=s(wI);mpo=r(PJr,"DPRQuestionEncoder"),PJr.forEach(t),gpo=r(V3e," (DPR model)"),V3e.forEach(t),hpo=i($),Mp=n($,"LI",{});var X3e=s(Mp);Yne=n(X3e,"STRONG",{});var IJr=s(Yne);ppo=r(IJr,"dpt"),IJr.forEach(t),upo=r(X3e," \u2014 "),AI=n(X3e,"A",{href:!0});var qJr=s(AI);_po=r(qJr,"DPTModel"),qJr.forEach(t),bpo=r(X3e," (DPT model)"),X3e.forEach(t),vpo=i($),Ep=n($,"LI",{});var z3e=s(Ep);Kne=n(z3e,"STRONG",{});var NJr=s(Kne);Fpo=r(NJr,"electra"),NJr.forEach(t),Tpo=r(z3e," \u2014 "),yI=n(z3e,"A",{href:!0});var jJr=s(yI);Mpo=r(jJr,"ElectraModel"),jJr.forEach(t),Epo=r(z3e," (ELECTRA model)"),z3e.forEach(t),Cpo=i($),Cp=n($,"LI",{});var Q3e=s(Cp);Zne=n(Q3e,"STRONG",{});var DJr=s(Zne);wpo=r(DJr,"flaubert"),DJr.forEach(t),Apo=r(Q3e," \u2014 "),LI=n(Q3e,"A",{href:!0});var GJr=s(LI);ypo=r(GJr,"FlaubertModel"),GJr.forEach(t),Lpo=r(Q3e," (FlauBERT model)"),Q3e.forEach(t),xpo=i($),wp=n($,"LI",{});var W3e=s(wp);ese=n(W3e,"STRONG",{});var OJr=s(ese);$po=r(OJr,"flava"),OJr.forEach(t),kpo=r(W3e," \u2014 "),xI=n(W3e,"A",{href:!0});var VJr=s(xI);Spo=r(VJr,"FlavaModel"),VJr.forEach(t),Rpo=r(W3e," (Flava model)"),W3e.forEach(t),Bpo=i($),Ap=n($,"LI",{});var H3e=s(Ap);ose=n(H3e,"STRONG",{});var XJr=s(ose);Ppo=r(XJr,"fnet"),XJr.forEach(t),Ipo=r(H3e," \u2014 "),$I=n(H3e,"A",{href:!0});var zJr=s($I);qpo=r(zJr,"FNetModel"),zJr.forEach(t),Npo=r(H3e," (FNet model)"),H3e.forEach(t),jpo=i($),yp=n($,"LI",{});var U3e=s(yp);rse=n(U3e,"STRONG",{});var QJr=s(rse);Dpo=r(QJr,"fsmt"),QJr.forEach(t),Gpo=r(U3e," \u2014 "),kI=n(U3e,"A",{href:!0});var WJr=s(kI);Opo=r(WJr,"FSMTModel"),WJr.forEach(t),Vpo=r(U3e," (FairSeq Machine-Translation model)"),U3e.forEach(t),Xpo=i($),Rs=n($,"LI",{});var F$=s(Rs);tse=n(F$,"STRONG",{});var HJr=s(tse);zpo=r(HJr,"funnel"),HJr.forEach(t),Qpo=r(F$," \u2014 "),SI=n(F$,"A",{href:!0});var UJr=s(SI);Wpo=r(UJr,"FunnelModel"),UJr.forEach(t),Hpo=r(F$," or "),RI=n(F$,"A",{href:!0});var JJr=s(RI);Upo=r(JJr,"FunnelBaseModel"),JJr.forEach(t),Jpo=r(F$," (Funnel Transformer model)"),F$.forEach(t),Ypo=i($),Lp=n($,"LI",{});var J3e=s(Lp);ase=n(J3e,"STRONG",{});var YJr=s(ase);Kpo=r(YJr,"glpn"),YJr.forEach(t),Zpo=r(J3e," \u2014 "),BI=n(J3e,"A",{href:!0});var KJr=s(BI);euo=r(KJr,"GLPNModel"),KJr.forEach(t),ouo=r(J3e," (GLPN model)"),J3e.forEach(t),ruo=i($),xp=n($,"LI",{});var Y3e=s(xp);nse=n(Y3e,"STRONG",{});var ZJr=s(nse);tuo=r(ZJr,"gpt2"),ZJr.forEach(t),auo=r(Y3e," \u2014 "),PI=n(Y3e,"A",{href:!0});var eYr=s(PI);nuo=r(eYr,"GPT2Model"),eYr.forEach(t),suo=r(Y3e," (OpenAI GPT-2 model)"),Y3e.forEach(t),luo=i($),$p=n($,"LI",{});var K3e=s($p);sse=n(K3e,"STRONG",{});var oYr=s(sse);iuo=r(oYr,"gpt_neo"),oYr.forEach(t),duo=r(K3e," \u2014 "),II=n(K3e,"A",{href:!0});var rYr=s(II);cuo=r(rYr,"GPTNeoModel"),rYr.forEach(t),fuo=r(K3e," (GPT Neo model)"),K3e.forEach(t),muo=i($),kp=n($,"LI",{});var Z3e=s(kp);lse=n(Z3e,"STRONG",{});var tYr=s(lse);guo=r(tYr,"gptj"),tYr.forEach(t),huo=r(Z3e," \u2014 "),qI=n(Z3e,"A",{href:!0});var aYr=s(qI);puo=r(aYr,"GPTJModel"),aYr.forEach(t),uuo=r(Z3e," (GPT-J model)"),Z3e.forEach(t),_uo=i($),Sp=n($,"LI",{});var ewe=s(Sp);ise=n(ewe,"STRONG",{});var nYr=s(ise);buo=r(nYr,"hubert"),nYr.forEach(t),vuo=r(ewe," \u2014 "),NI=n(ewe,"A",{href:!0});var sYr=s(NI);Fuo=r(sYr,"HubertModel"),sYr.forEach(t),Tuo=r(ewe," (Hubert model)"),ewe.forEach(t),Muo=i($),Rp=n($,"LI",{});var owe=s(Rp);dse=n(owe,"STRONG",{});var lYr=s(dse);Euo=r(lYr,"ibert"),lYr.forEach(t),Cuo=r(owe," \u2014 "),jI=n(owe,"A",{href:!0});var iYr=s(jI);wuo=r(iYr,"IBertModel"),iYr.forEach(t),Auo=r(owe," (I-BERT model)"),owe.forEach(t),yuo=i($),Bp=n($,"LI",{});var rwe=s(Bp);cse=n(rwe,"STRONG",{});var dYr=s(cse);Luo=r(dYr,"imagegpt"),dYr.forEach(t),xuo=r(rwe," \u2014 "),DI=n(rwe,"A",{href:!0});var cYr=s(DI);$uo=r(cYr,"ImageGPTModel"),cYr.forEach(t),kuo=r(rwe," (ImageGPT model)"),rwe.forEach(t),Suo=i($),Pp=n($,"LI",{});var twe=s(Pp);fse=n(twe,"STRONG",{});var fYr=s(fse);Ruo=r(fYr,"layoutlm"),fYr.forEach(t),Buo=r(twe," \u2014 "),GI=n(twe,"A",{href:!0});var mYr=s(GI);Puo=r(mYr,"LayoutLMModel"),mYr.forEach(t),Iuo=r(twe," (LayoutLM model)"),twe.forEach(t),quo=i($),Ip=n($,"LI",{});var awe=s(Ip);mse=n(awe,"STRONG",{});var gYr=s(mse);Nuo=r(gYr,"layoutlmv2"),gYr.forEach(t),juo=r(awe," \u2014 "),OI=n(awe,"A",{href:!0});var hYr=s(OI);Duo=r(hYr,"LayoutLMv2Model"),hYr.forEach(t),Guo=r(awe," (LayoutLMv2 model)"),awe.forEach(t),Ouo=i($),qp=n($,"LI",{});var nwe=s(qp);gse=n(nwe,"STRONG",{});var pYr=s(gse);Vuo=r(pYr,"layoutlmv3"),pYr.forEach(t),Xuo=r(nwe," \u2014 "),VI=n(nwe,"A",{href:!0});var uYr=s(VI);zuo=r(uYr,"LayoutLMv3Model"),uYr.forEach(t),Quo=r(nwe," (LayoutLMv3 model)"),nwe.forEach(t),Wuo=i($),Np=n($,"LI",{});var swe=s(Np);hse=n(swe,"STRONG",{});var _Yr=s(hse);Huo=r(_Yr,"led"),_Yr.forEach(t),Uuo=r(swe," \u2014 "),XI=n(swe,"A",{href:!0});var bYr=s(XI);Juo=r(bYr,"LEDModel"),bYr.forEach(t),Yuo=r(swe," (LED model)"),swe.forEach(t),Kuo=i($),jp=n($,"LI",{});var lwe=s(jp);pse=n(lwe,"STRONG",{});var vYr=s(pse);Zuo=r(vYr,"longformer"),vYr.forEach(t),e_o=r(lwe," \u2014 "),zI=n(lwe,"A",{href:!0});var FYr=s(zI);o_o=r(FYr,"LongformerModel"),FYr.forEach(t),r_o=r(lwe," (Longformer model)"),lwe.forEach(t),t_o=i($),Dp=n($,"LI",{});var iwe=s(Dp);use=n(iwe,"STRONG",{});var TYr=s(use);a_o=r(TYr,"luke"),TYr.forEach(t),n_o=r(iwe," \u2014 "),QI=n(iwe,"A",{href:!0});var MYr=s(QI);s_o=r(MYr,"LukeModel"),MYr.forEach(t),l_o=r(iwe," (LUKE model)"),iwe.forEach(t),i_o=i($),Gp=n($,"LI",{});var dwe=s(Gp);_se=n(dwe,"STRONG",{});var EYr=s(_se);d_o=r(EYr,"lxmert"),EYr.forEach(t),c_o=r(dwe," \u2014 "),WI=n(dwe,"A",{href:!0});var CYr=s(WI);f_o=r(CYr,"LxmertModel"),CYr.forEach(t),m_o=r(dwe," (LXMERT model)"),dwe.forEach(t),g_o=i($),Op=n($,"LI",{});var cwe=s(Op);bse=n(cwe,"STRONG",{});var wYr=s(bse);h_o=r(wYr,"m2m_100"),wYr.forEach(t),p_o=r(cwe," \u2014 "),HI=n(cwe,"A",{href:!0});var AYr=s(HI);u_o=r(AYr,"M2M100Model"),AYr.forEach(t),__o=r(cwe," (M2M100 model)"),cwe.forEach(t),b_o=i($),Vp=n($,"LI",{});var fwe=s(Vp);vse=n(fwe,"STRONG",{});var yYr=s(vse);v_o=r(yYr,"marian"),yYr.forEach(t),F_o=r(fwe," \u2014 "),UI=n(fwe,"A",{href:!0});var LYr=s(UI);T_o=r(LYr,"MarianModel"),LYr.forEach(t),M_o=r(fwe," (Marian model)"),fwe.forEach(t),E_o=i($),Xp=n($,"LI",{});var mwe=s(Xp);Fse=n(mwe,"STRONG",{});var xYr=s(Fse);C_o=r(xYr,"maskformer"),xYr.forEach(t),w_o=r(mwe," \u2014 "),JI=n(mwe,"A",{href:!0});var $Yr=s(JI);A_o=r($Yr,"MaskFormerModel"),$Yr.forEach(t),y_o=r(mwe," (MaskFormer model)"),mwe.forEach(t),L_o=i($),zp=n($,"LI",{});var gwe=s(zp);Tse=n(gwe,"STRONG",{});var kYr=s(Tse);x_o=r(kYr,"mbart"),kYr.forEach(t),$_o=r(gwe," \u2014 "),YI=n(gwe,"A",{href:!0});var SYr=s(YI);k_o=r(SYr,"MBartModel"),SYr.forEach(t),S_o=r(gwe," (mBART model)"),gwe.forEach(t),R_o=i($),Qp=n($,"LI",{});var hwe=s(Qp);Mse=n(hwe,"STRONG",{});var RYr=s(Mse);B_o=r(RYr,"megatron-bert"),RYr.forEach(t),P_o=r(hwe," \u2014 "),KI=n(hwe,"A",{href:!0});var BYr=s(KI);I_o=r(BYr,"MegatronBertModel"),BYr.forEach(t),q_o=r(hwe," (MegatronBert model)"),hwe.forEach(t),N_o=i($),Wp=n($,"LI",{});var pwe=s(Wp);Ese=n(pwe,"STRONG",{});var PYr=s(Ese);j_o=r(PYr,"mobilebert"),PYr.forEach(t),D_o=r(pwe," \u2014 "),ZI=n(pwe,"A",{href:!0});var IYr=s(ZI);G_o=r(IYr,"MobileBertModel"),IYr.forEach(t),O_o=r(pwe," (MobileBERT model)"),pwe.forEach(t),V_o=i($),Hp=n($,"LI",{});var uwe=s(Hp);Cse=n(uwe,"STRONG",{});var qYr=s(Cse);X_o=r(qYr,"mpnet"),qYr.forEach(t),z_o=r(uwe," \u2014 "),eq=n(uwe,"A",{href:!0});var NYr=s(eq);Q_o=r(NYr,"MPNetModel"),NYr.forEach(t),W_o=r(uwe," (MPNet model)"),uwe.forEach(t),H_o=i($),Up=n($,"LI",{});var _we=s(Up);wse=n(_we,"STRONG",{});var jYr=s(wse);U_o=r(jYr,"mt5"),jYr.forEach(t),J_o=r(_we," \u2014 "),oq=n(_we,"A",{href:!0});var DYr=s(oq);Y_o=r(DYr,"MT5Model"),DYr.forEach(t),K_o=r(_we," (mT5 model)"),_we.forEach(t),Z_o=i($),Jp=n($,"LI",{});var bwe=s(Jp);Ase=n(bwe,"STRONG",{});var GYr=s(Ase);e0o=r(GYr,"nystromformer"),GYr.forEach(t),o0o=r(bwe," \u2014 "),rq=n(bwe,"A",{href:!0});var OYr=s(rq);r0o=r(OYr,"NystromformerModel"),OYr.forEach(t),t0o=r(bwe," (Nystromformer model)"),bwe.forEach(t),a0o=i($),Yp=n($,"LI",{});var vwe=s(Yp);yse=n(vwe,"STRONG",{});var VYr=s(yse);n0o=r(VYr,"openai-gpt"),VYr.forEach(t),s0o=r(vwe," \u2014 "),tq=n(vwe,"A",{href:!0});var XYr=s(tq);l0o=r(XYr,"OpenAIGPTModel"),XYr.forEach(t),i0o=r(vwe," (OpenAI GPT model)"),vwe.forEach(t),d0o=i($),Kp=n($,"LI",{});var Fwe=s(Kp);Lse=n(Fwe,"STRONG",{});var zYr=s(Lse);c0o=r(zYr,"opt"),zYr.forEach(t),f0o=r(Fwe," \u2014 "),aq=n(Fwe,"A",{href:!0});var QYr=s(aq);m0o=r(QYr,"OPTModel"),QYr.forEach(t),g0o=r(Fwe," (OPT model)"),Fwe.forEach(t),h0o=i($),Zp=n($,"LI",{});var Twe=s(Zp);xse=n(Twe,"STRONG",{});var WYr=s(xse);p0o=r(WYr,"pegasus"),WYr.forEach(t),u0o=r(Twe," \u2014 "),nq=n(Twe,"A",{href:!0});var HYr=s(nq);_0o=r(HYr,"PegasusModel"),HYr.forEach(t),b0o=r(Twe," (Pegasus model)"),Twe.forEach(t),v0o=i($),eu=n($,"LI",{});var Mwe=s(eu);$se=n(Mwe,"STRONG",{});var UYr=s($se);F0o=r(UYr,"perceiver"),UYr.forEach(t),T0o=r(Mwe," \u2014 "),sq=n(Mwe,"A",{href:!0});var JYr=s(sq);M0o=r(JYr,"PerceiverModel"),JYr.forEach(t),E0o=r(Mwe," (Perceiver model)"),Mwe.forEach(t),C0o=i($),ou=n($,"LI",{});var Ewe=s(ou);kse=n(Ewe,"STRONG",{});var YYr=s(kse);w0o=r(YYr,"plbart"),YYr.forEach(t),A0o=r(Ewe," \u2014 "),lq=n(Ewe,"A",{href:!0});var KYr=s(lq);y0o=r(KYr,"PLBartModel"),KYr.forEach(t),L0o=r(Ewe," (PLBart model)"),Ewe.forEach(t),x0o=i($),ru=n($,"LI",{});var Cwe=s(ru);Sse=n(Cwe,"STRONG",{});var ZYr=s(Sse);$0o=r(ZYr,"poolformer"),ZYr.forEach(t),k0o=r(Cwe," \u2014 "),iq=n(Cwe,"A",{href:!0});var eKr=s(iq);S0o=r(eKr,"PoolFormerModel"),eKr.forEach(t),R0o=r(Cwe," (PoolFormer model)"),Cwe.forEach(t),B0o=i($),tu=n($,"LI",{});var wwe=s(tu);Rse=n(wwe,"STRONG",{});var oKr=s(Rse);P0o=r(oKr,"prophetnet"),oKr.forEach(t),I0o=r(wwe," \u2014 "),dq=n(wwe,"A",{href:!0});var rKr=s(dq);q0o=r(rKr,"ProphetNetModel"),rKr.forEach(t),N0o=r(wwe," (ProphetNet model)"),wwe.forEach(t),j0o=i($),au=n($,"LI",{});var Awe=s(au);Bse=n(Awe,"STRONG",{});var tKr=s(Bse);D0o=r(tKr,"qdqbert"),tKr.forEach(t),G0o=r(Awe," \u2014 "),cq=n(Awe,"A",{href:!0});var aKr=s(cq);O0o=r(aKr,"QDQBertModel"),aKr.forEach(t),V0o=r(Awe," (QDQBert model)"),Awe.forEach(t),X0o=i($),nu=n($,"LI",{});var ywe=s(nu);Pse=n(ywe,"STRONG",{});var nKr=s(Pse);z0o=r(nKr,"reformer"),nKr.forEach(t),Q0o=r(ywe," \u2014 "),fq=n(ywe,"A",{href:!0});var sKr=s(fq);W0o=r(sKr,"ReformerModel"),sKr.forEach(t),H0o=r(ywe," (Reformer model)"),ywe.forEach(t),U0o=i($),su=n($,"LI",{});var Lwe=s(su);Ise=n(Lwe,"STRONG",{});var lKr=s(Ise);J0o=r(lKr,"regnet"),lKr.forEach(t),Y0o=r(Lwe," \u2014 "),mq=n(Lwe,"A",{href:!0});var iKr=s(mq);K0o=r(iKr,"RegNetModel"),iKr.forEach(t),Z0o=r(Lwe," (RegNet model)"),Lwe.forEach(t),e1o=i($),lu=n($,"LI",{});var xwe=s(lu);qse=n(xwe,"STRONG",{});var dKr=s(qse);o1o=r(dKr,"rembert"),dKr.forEach(t),r1o=r(xwe," \u2014 "),gq=n(xwe,"A",{href:!0});var cKr=s(gq);t1o=r(cKr,"RemBertModel"),cKr.forEach(t),a1o=r(xwe," (RemBERT model)"),xwe.forEach(t),n1o=i($),iu=n($,"LI",{});var $we=s(iu);Nse=n($we,"STRONG",{});var fKr=s(Nse);s1o=r(fKr,"resnet"),fKr.forEach(t),l1o=r($we," \u2014 "),hq=n($we,"A",{href:!0});var mKr=s(hq);i1o=r(mKr,"ResNetModel"),mKr.forEach(t),d1o=r($we," (ResNet model)"),$we.forEach(t),c1o=i($),du=n($,"LI",{});var kwe=s(du);jse=n(kwe,"STRONG",{});var gKr=s(jse);f1o=r(gKr,"retribert"),gKr.forEach(t),m1o=r(kwe," \u2014 "),pq=n(kwe,"A",{href:!0});var hKr=s(pq);g1o=r(hKr,"RetriBertModel"),hKr.forEach(t),h1o=r(kwe," (RetriBERT model)"),kwe.forEach(t),p1o=i($),cu=n($,"LI",{});var Swe=s(cu);Dse=n(Swe,"STRONG",{});var pKr=s(Dse);u1o=r(pKr,"roberta"),pKr.forEach(t),_1o=r(Swe," \u2014 "),uq=n(Swe,"A",{href:!0});var uKr=s(uq);b1o=r(uKr,"RobertaModel"),uKr.forEach(t),v1o=r(Swe," (RoBERTa model)"),Swe.forEach(t),F1o=i($),fu=n($,"LI",{});var Rwe=s(fu);Gse=n(Rwe,"STRONG",{});var _Kr=s(Gse);T1o=r(_Kr,"roformer"),_Kr.forEach(t),M1o=r(Rwe," \u2014 "),_q=n(Rwe,"A",{href:!0});var bKr=s(_q);E1o=r(bKr,"RoFormerModel"),bKr.forEach(t),C1o=r(Rwe," (RoFormer model)"),Rwe.forEach(t),w1o=i($),mu=n($,"LI",{});var Bwe=s(mu);Ose=n(Bwe,"STRONG",{});var vKr=s(Ose);A1o=r(vKr,"segformer"),vKr.forEach(t),y1o=r(Bwe," \u2014 "),bq=n(Bwe,"A",{href:!0});var FKr=s(bq);L1o=r(FKr,"SegformerModel"),FKr.forEach(t),x1o=r(Bwe," (SegFormer model)"),Bwe.forEach(t),$1o=i($),gu=n($,"LI",{});var Pwe=s(gu);Vse=n(Pwe,"STRONG",{});var TKr=s(Vse);k1o=r(TKr,"sew"),TKr.forEach(t),S1o=r(Pwe," \u2014 "),vq=n(Pwe,"A",{href:!0});var MKr=s(vq);R1o=r(MKr,"SEWModel"),MKr.forEach(t),B1o=r(Pwe," (SEW model)"),Pwe.forEach(t),P1o=i($),hu=n($,"LI",{});var Iwe=s(hu);Xse=n(Iwe,"STRONG",{});var EKr=s(Xse);I1o=r(EKr,"sew-d"),EKr.forEach(t),q1o=r(Iwe," \u2014 "),Fq=n(Iwe,"A",{href:!0});var CKr=s(Fq);N1o=r(CKr,"SEWDModel"),CKr.forEach(t),j1o=r(Iwe," (SEW-D model)"),Iwe.forEach(t),D1o=i($),pu=n($,"LI",{});var qwe=s(pu);zse=n(qwe,"STRONG",{});var wKr=s(zse);G1o=r(wKr,"speech_to_text"),wKr.forEach(t),O1o=r(qwe," \u2014 "),Tq=n(qwe,"A",{href:!0});var AKr=s(Tq);V1o=r(AKr,"Speech2TextModel"),AKr.forEach(t),X1o=r(qwe," (Speech2Text model)"),qwe.forEach(t),z1o=i($),uu=n($,"LI",{});var Nwe=s(uu);Qse=n(Nwe,"STRONG",{});var yKr=s(Qse);Q1o=r(yKr,"splinter"),yKr.forEach(t),W1o=r(Nwe," \u2014 "),Mq=n(Nwe,"A",{href:!0});var LKr=s(Mq);H1o=r(LKr,"SplinterModel"),LKr.forEach(t),U1o=r(Nwe," (Splinter model)"),Nwe.forEach(t),J1o=i($),_u=n($,"LI",{});var jwe=s(_u);Wse=n(jwe,"STRONG",{});var xKr=s(Wse);Y1o=r(xKr,"squeezebert"),xKr.forEach(t),K1o=r(jwe," \u2014 "),Eq=n(jwe,"A",{href:!0});var $Kr=s(Eq);Z1o=r($Kr,"SqueezeBertModel"),$Kr.forEach(t),ebo=r(jwe," (SqueezeBERT model)"),jwe.forEach(t),obo=i($),bu=n($,"LI",{});var Dwe=s(bu);Hse=n(Dwe,"STRONG",{});var kKr=s(Hse);rbo=r(kKr,"swin"),kKr.forEach(t),tbo=r(Dwe," \u2014 "),Cq=n(Dwe,"A",{href:!0});var SKr=s(Cq);abo=r(SKr,"SwinModel"),SKr.forEach(t),nbo=r(Dwe," (Swin model)"),Dwe.forEach(t),sbo=i($),vu=n($,"LI",{});var Gwe=s(vu);Use=n(Gwe,"STRONG",{});var RKr=s(Use);lbo=r(RKr,"t5"),RKr.forEach(t),ibo=r(Gwe," \u2014 "),wq=n(Gwe,"A",{href:!0});var BKr=s(wq);dbo=r(BKr,"T5Model"),BKr.forEach(t),cbo=r(Gwe," (T5 model)"),Gwe.forEach(t),fbo=i($),Fu=n($,"LI",{});var Owe=s(Fu);Jse=n(Owe,"STRONG",{});var PKr=s(Jse);mbo=r(PKr,"tapas"),PKr.forEach(t),gbo=r(Owe," \u2014 "),Aq=n(Owe,"A",{href:!0});var IKr=s(Aq);hbo=r(IKr,"TapasModel"),IKr.forEach(t),pbo=r(Owe," (TAPAS model)"),Owe.forEach(t),ubo=i($),Tu=n($,"LI",{});var Vwe=s(Tu);Yse=n(Vwe,"STRONG",{});var qKr=s(Yse);_bo=r(qKr,"transfo-xl"),qKr.forEach(t),bbo=r(Vwe," \u2014 "),yq=n(Vwe,"A",{href:!0});var NKr=s(yq);vbo=r(NKr,"TransfoXLModel"),NKr.forEach(t),Fbo=r(Vwe," (Transformer-XL model)"),Vwe.forEach(t),Tbo=i($),Mu=n($,"LI",{});var Xwe=s(Mu);Kse=n(Xwe,"STRONG",{});var jKr=s(Kse);Mbo=r(jKr,"unispeech"),jKr.forEach(t),Ebo=r(Xwe," \u2014 "),Lq=n(Xwe,"A",{href:!0});var DKr=s(Lq);Cbo=r(DKr,"UniSpeechModel"),DKr.forEach(t),wbo=r(Xwe," (UniSpeech model)"),Xwe.forEach(t),Abo=i($),Eu=n($,"LI",{});var zwe=s(Eu);Zse=n(zwe,"STRONG",{});var GKr=s(Zse);ybo=r(GKr,"unispeech-sat"),GKr.forEach(t),Lbo=r(zwe," \u2014 "),xq=n(zwe,"A",{href:!0});var OKr=s(xq);xbo=r(OKr,"UniSpeechSatModel"),OKr.forEach(t),$bo=r(zwe," (UniSpeechSat model)"),zwe.forEach(t),kbo=i($),Cu=n($,"LI",{});var Qwe=s(Cu);ele=n(Qwe,"STRONG",{});var VKr=s(ele);Sbo=r(VKr,"van"),VKr.forEach(t),Rbo=r(Qwe," \u2014 "),$q=n(Qwe,"A",{href:!0});var XKr=s($q);Bbo=r(XKr,"VanModel"),XKr.forEach(t),Pbo=r(Qwe," (VAN model)"),Qwe.forEach(t),Ibo=i($),wu=n($,"LI",{});var Wwe=s(wu);ole=n(Wwe,"STRONG",{});var zKr=s(ole);qbo=r(zKr,"vilt"),zKr.forEach(t),Nbo=r(Wwe," \u2014 "),kq=n(Wwe,"A",{href:!0});var QKr=s(kq);jbo=r(QKr,"ViltModel"),QKr.forEach(t),Dbo=r(Wwe," (ViLT model)"),Wwe.forEach(t),Gbo=i($),Au=n($,"LI",{});var Hwe=s(Au);rle=n(Hwe,"STRONG",{});var WKr=s(rle);Obo=r(WKr,"vision-text-dual-encoder"),WKr.forEach(t),Vbo=r(Hwe," \u2014 "),Sq=n(Hwe,"A",{href:!0});var HKr=s(Sq);Xbo=r(HKr,"VisionTextDualEncoderModel"),HKr.forEach(t),zbo=r(Hwe," (VisionTextDualEncoder model)"),Hwe.forEach(t),Qbo=i($),yu=n($,"LI",{});var Uwe=s(yu);tle=n(Uwe,"STRONG",{});var UKr=s(tle);Wbo=r(UKr,"visual_bert"),UKr.forEach(t),Hbo=r(Uwe," \u2014 "),Rq=n(Uwe,"A",{href:!0});var JKr=s(Rq);Ubo=r(JKr,"VisualBertModel"),JKr.forEach(t),Jbo=r(Uwe," (VisualBert model)"),Uwe.forEach(t),Ybo=i($),Lu=n($,"LI",{});var Jwe=s(Lu);ale=n(Jwe,"STRONG",{});var YKr=s(ale);Kbo=r(YKr,"vit"),YKr.forEach(t),Zbo=r(Jwe," \u2014 "),Bq=n(Jwe,"A",{href:!0});var KKr=s(Bq);e2o=r(KKr,"ViTModel"),KKr.forEach(t),o2o=r(Jwe," (ViT model)"),Jwe.forEach(t),r2o=i($),xu=n($,"LI",{});var Ywe=s(xu);nle=n(Ywe,"STRONG",{});var ZKr=s(nle);t2o=r(ZKr,"vit_mae"),ZKr.forEach(t),a2o=r(Ywe," \u2014 "),Pq=n(Ywe,"A",{href:!0});var eZr=s(Pq);n2o=r(eZr,"ViTMAEModel"),eZr.forEach(t),s2o=r(Ywe," (ViTMAE model)"),Ywe.forEach(t),l2o=i($),$u=n($,"LI",{});var Kwe=s($u);sle=n(Kwe,"STRONG",{});var oZr=s(sle);i2o=r(oZr,"wav2vec2"),oZr.forEach(t),d2o=r(Kwe," \u2014 "),Iq=n(Kwe,"A",{href:!0});var rZr=s(Iq);c2o=r(rZr,"Wav2Vec2Model"),rZr.forEach(t),f2o=r(Kwe," (Wav2Vec2 model)"),Kwe.forEach(t),m2o=i($),ku=n($,"LI",{});var Zwe=s(ku);lle=n(Zwe,"STRONG",{});var tZr=s(lle);g2o=r(tZr,"wavlm"),tZr.forEach(t),h2o=r(Zwe," \u2014 "),qq=n(Zwe,"A",{href:!0});var aZr=s(qq);p2o=r(aZr,"WavLMModel"),aZr.forEach(t),u2o=r(Zwe," (WavLM model)"),Zwe.forEach(t),_2o=i($),Su=n($,"LI",{});var eAe=s(Su);ile=n(eAe,"STRONG",{});var nZr=s(ile);b2o=r(nZr,"xglm"),nZr.forEach(t),v2o=r(eAe," \u2014 "),Nq=n(eAe,"A",{href:!0});var sZr=s(Nq);F2o=r(sZr,"XGLMModel"),sZr.forEach(t),T2o=r(eAe," (XGLM model)"),eAe.forEach(t),M2o=i($),Ru=n($,"LI",{});var oAe=s(Ru);dle=n(oAe,"STRONG",{});var lZr=s(dle);E2o=r(lZr,"xlm"),lZr.forEach(t),C2o=r(oAe," \u2014 "),jq=n(oAe,"A",{href:!0});var iZr=s(jq);w2o=r(iZr,"XLMModel"),iZr.forEach(t),A2o=r(oAe," (XLM model)"),oAe.forEach(t),y2o=i($),Bu=n($,"LI",{});var rAe=s(Bu);cle=n(rAe,"STRONG",{});var dZr=s(cle);L2o=r(dZr,"xlm-prophetnet"),dZr.forEach(t),x2o=r(rAe," \u2014 "),Dq=n(rAe,"A",{href:!0});var cZr=s(Dq);$2o=r(cZr,"XLMProphetNetModel"),cZr.forEach(t),k2o=r(rAe," (XLMProphetNet model)"),rAe.forEach(t),S2o=i($),Pu=n($,"LI",{});var tAe=s(Pu);fle=n(tAe,"STRONG",{});var fZr=s(fle);R2o=r(fZr,"xlm-roberta"),fZr.forEach(t),B2o=r(tAe," \u2014 "),Gq=n(tAe,"A",{href:!0});var mZr=s(Gq);P2o=r(mZr,"XLMRobertaModel"),mZr.forEach(t),I2o=r(tAe," (XLM-RoBERTa model)"),tAe.forEach(t),q2o=i($),Iu=n($,"LI",{});var aAe=s(Iu);mle=n(aAe,"STRONG",{});var gZr=s(mle);N2o=r(gZr,"xlm-roberta-xl"),gZr.forEach(t),j2o=r(aAe," \u2014 "),Oq=n(aAe,"A",{href:!0});var hZr=s(Oq);D2o=r(hZr,"XLMRobertaXLModel"),hZr.forEach(t),G2o=r(aAe," (XLM-RoBERTa-XL model)"),aAe.forEach(t),O2o=i($),qu=n($,"LI",{});var nAe=s(qu);gle=n(nAe,"STRONG",{});var pZr=s(gle);V2o=r(pZr,"xlnet"),pZr.forEach(t),X2o=r(nAe," \u2014 "),Vq=n(nAe,"A",{href:!0});var uZr=s(Vq);z2o=r(uZr,"XLNetModel"),uZr.forEach(t),Q2o=r(nAe," (XLNet model)"),nAe.forEach(t),W2o=i($),Nu=n($,"LI",{});var sAe=s(Nu);hle=n(sAe,"STRONG",{});var _Zr=s(hle);H2o=r(_Zr,"yolos"),_Zr.forEach(t),U2o=r(sAe," \u2014 "),Xq=n(sAe,"A",{href:!0});var bZr=s(Xq);J2o=r(bZr,"YolosModel"),bZr.forEach(t),Y2o=r(sAe," (YOLOS model)"),sAe.forEach(t),K2o=i($),ju=n($,"LI",{});var lAe=s(ju);ple=n(lAe,"STRONG",{});var vZr=s(ple);Z2o=r(vZr,"yoso"),vZr.forEach(t),evo=r(lAe," \u2014 "),zq=n(lAe,"A",{href:!0});var FZr=s(zq);ovo=r(FZr,"YosoModel"),FZr.forEach(t),rvo=r(lAe," (YOSO model)"),lAe.forEach(t),$.forEach(t),tvo=i(Zt),Du=n(Zt,"P",{});var iAe=s(Du);avo=r(iAe,"The model is set in evaluation mode by default using "),ule=n(iAe,"CODE",{});var TZr=s(ule);nvo=r(TZr,"model.eval()"),TZr.forEach(t),svo=r(iAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_le=n(iAe,"CODE",{});var MZr=s(_le);lvo=r(MZr,"model.train()"),MZr.forEach(t),iAe.forEach(t),ivo=i(Zt),T(Gu.$$.fragment,Zt),Zt.forEach(t),Ds.forEach(t),qIe=i(f),wi=n(f,"H2",{class:!0});var GNe=s(wi);Ou=n(GNe,"A",{id:!0,class:!0,href:!0});var EZr=s(Ou);ble=n(EZr,"SPAN",{});var CZr=s(ble);T(IA.$$.fragment,CZr),CZr.forEach(t),EZr.forEach(t),dvo=i(GNe),vle=n(GNe,"SPAN",{});var wZr=s(vle);cvo=r(wZr,"AutoModelForPreTraining"),wZr.forEach(t),GNe.forEach(t),NIe=i(f),xo=n(f,"DIV",{class:!0});var Gs=s(xo);T(qA.$$.fragment,Gs),fvo=i(Gs),Ai=n(Gs,"P",{});var LK=s(Ai);mvo=r(LK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Qq=n(LK,"A",{href:!0});var AZr=s(Qq);gvo=r(AZr,"from_pretrained()"),AZr.forEach(t),hvo=r(LK," class method or the "),Wq=n(LK,"A",{href:!0});var yZr=s(Wq);pvo=r(yZr,"from_config()"),yZr.forEach(t),uvo=r(LK,` class
method.`),LK.forEach(t),_vo=i(Gs),NA=n(Gs,"P",{});var ONe=s(NA);bvo=r(ONe,"This class cannot be instantiated directly using "),Fle=n(ONe,"CODE",{});var LZr=s(Fle);vvo=r(LZr,"__init__()"),LZr.forEach(t),Fvo=r(ONe," (throws an error)."),ONe.forEach(t),Tvo=i(Gs),rt=n(Gs,"DIV",{class:!0});var c3=s(rt);T(jA.$$.fragment,c3),Mvo=i(c3),Tle=n(c3,"P",{});var xZr=s(Tle);Evo=r(xZr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xZr.forEach(t),Cvo=i(c3),yi=n(c3,"P",{});var xK=s(yi);wvo=r(xK,`Note:
Loading a model from its configuration file does `),Mle=n(xK,"STRONG",{});var $Zr=s(Mle);Avo=r($Zr,"not"),$Zr.forEach(t),yvo=r(xK,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hq=n(xK,"A",{href:!0});var kZr=s(Hq);Lvo=r(kZr,"from_pretrained()"),kZr.forEach(t),xvo=r(xK," to load the model weights."),xK.forEach(t),$vo=i(c3),T(Vu.$$.fragment,c3),c3.forEach(t),kvo=i(Gs),Ue=n(Gs,"DIV",{class:!0});var ea=s(Ue);T(DA.$$.fragment,ea),Svo=i(ea),Ele=n(ea,"P",{});var SZr=s(Ele);Rvo=r(SZr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),SZr.forEach(t),Bvo=i(ea),ya=n(ea,"P",{});var f3=s(ya);Pvo=r(f3,"The model class to instantiate is selected based on the "),Cle=n(f3,"CODE",{});var RZr=s(Cle);Ivo=r(RZr,"model_type"),RZr.forEach(t),qvo=r(f3,` property of the config object (either
passed as an argument or loaded from `),wle=n(f3,"CODE",{});var BZr=s(wle);Nvo=r(BZr,"pretrained_model_name_or_path"),BZr.forEach(t),jvo=r(f3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ale=n(f3,"CODE",{});var PZr=s(Ale);Dvo=r(PZr,"pretrained_model_name_or_path"),PZr.forEach(t),Gvo=r(f3,":"),f3.forEach(t),Ovo=i(ea),G=n(ea,"UL",{});var V=s(G);Xu=n(V,"LI",{});var dAe=s(Xu);yle=n(dAe,"STRONG",{});var IZr=s(yle);Vvo=r(IZr,"albert"),IZr.forEach(t),Xvo=r(dAe," \u2014 "),Uq=n(dAe,"A",{href:!0});var qZr=s(Uq);zvo=r(qZr,"AlbertForPreTraining"),qZr.forEach(t),Qvo=r(dAe," (ALBERT model)"),dAe.forEach(t),Wvo=i(V),zu=n(V,"LI",{});var cAe=s(zu);Lle=n(cAe,"STRONG",{});var NZr=s(Lle);Hvo=r(NZr,"bart"),NZr.forEach(t),Uvo=r(cAe," \u2014 "),Jq=n(cAe,"A",{href:!0});var jZr=s(Jq);Jvo=r(jZr,"BartForConditionalGeneration"),jZr.forEach(t),Yvo=r(cAe," (BART model)"),cAe.forEach(t),Kvo=i(V),Qu=n(V,"LI",{});var fAe=s(Qu);xle=n(fAe,"STRONG",{});var DZr=s(xle);Zvo=r(DZr,"bert"),DZr.forEach(t),eFo=r(fAe," \u2014 "),Yq=n(fAe,"A",{href:!0});var GZr=s(Yq);oFo=r(GZr,"BertForPreTraining"),GZr.forEach(t),rFo=r(fAe," (BERT model)"),fAe.forEach(t),tFo=i(V),Wu=n(V,"LI",{});var mAe=s(Wu);$le=n(mAe,"STRONG",{});var OZr=s($le);aFo=r(OZr,"big_bird"),OZr.forEach(t),nFo=r(mAe," \u2014 "),Kq=n(mAe,"A",{href:!0});var VZr=s(Kq);sFo=r(VZr,"BigBirdForPreTraining"),VZr.forEach(t),lFo=r(mAe," (BigBird model)"),mAe.forEach(t),iFo=i(V),Hu=n(V,"LI",{});var gAe=s(Hu);kle=n(gAe,"STRONG",{});var XZr=s(kle);dFo=r(XZr,"camembert"),XZr.forEach(t),cFo=r(gAe," \u2014 "),Zq=n(gAe,"A",{href:!0});var zZr=s(Zq);fFo=r(zZr,"CamembertForMaskedLM"),zZr.forEach(t),mFo=r(gAe," (CamemBERT model)"),gAe.forEach(t),gFo=i(V),Uu=n(V,"LI",{});var hAe=s(Uu);Sle=n(hAe,"STRONG",{});var QZr=s(Sle);hFo=r(QZr,"ctrl"),QZr.forEach(t),pFo=r(hAe," \u2014 "),eN=n(hAe,"A",{href:!0});var WZr=s(eN);uFo=r(WZr,"CTRLLMHeadModel"),WZr.forEach(t),_Fo=r(hAe," (CTRL model)"),hAe.forEach(t),bFo=i(V),Ju=n(V,"LI",{});var pAe=s(Ju);Rle=n(pAe,"STRONG",{});var HZr=s(Rle);vFo=r(HZr,"data2vec-text"),HZr.forEach(t),FFo=r(pAe," \u2014 "),oN=n(pAe,"A",{href:!0});var UZr=s(oN);TFo=r(UZr,"Data2VecTextForMaskedLM"),UZr.forEach(t),MFo=r(pAe," (Data2VecText model)"),pAe.forEach(t),EFo=i(V),Yu=n(V,"LI",{});var uAe=s(Yu);Ble=n(uAe,"STRONG",{});var JZr=s(Ble);CFo=r(JZr,"deberta"),JZr.forEach(t),wFo=r(uAe," \u2014 "),rN=n(uAe,"A",{href:!0});var YZr=s(rN);AFo=r(YZr,"DebertaForMaskedLM"),YZr.forEach(t),yFo=r(uAe," (DeBERTa model)"),uAe.forEach(t),LFo=i(V),Ku=n(V,"LI",{});var _Ae=s(Ku);Ple=n(_Ae,"STRONG",{});var KZr=s(Ple);xFo=r(KZr,"deberta-v2"),KZr.forEach(t),$Fo=r(_Ae," \u2014 "),tN=n(_Ae,"A",{href:!0});var ZZr=s(tN);kFo=r(ZZr,"DebertaV2ForMaskedLM"),ZZr.forEach(t),SFo=r(_Ae," (DeBERTa-v2 model)"),_Ae.forEach(t),RFo=i(V),Zu=n(V,"LI",{});var bAe=s(Zu);Ile=n(bAe,"STRONG",{});var eet=s(Ile);BFo=r(eet,"distilbert"),eet.forEach(t),PFo=r(bAe," \u2014 "),aN=n(bAe,"A",{href:!0});var oet=s(aN);IFo=r(oet,"DistilBertForMaskedLM"),oet.forEach(t),qFo=r(bAe," (DistilBERT model)"),bAe.forEach(t),NFo=i(V),e_=n(V,"LI",{});var vAe=s(e_);qle=n(vAe,"STRONG",{});var ret=s(qle);jFo=r(ret,"electra"),ret.forEach(t),DFo=r(vAe," \u2014 "),nN=n(vAe,"A",{href:!0});var tet=s(nN);GFo=r(tet,"ElectraForPreTraining"),tet.forEach(t),OFo=r(vAe," (ELECTRA model)"),vAe.forEach(t),VFo=i(V),o_=n(V,"LI",{});var FAe=s(o_);Nle=n(FAe,"STRONG",{});var aet=s(Nle);XFo=r(aet,"flaubert"),aet.forEach(t),zFo=r(FAe," \u2014 "),sN=n(FAe,"A",{href:!0});var net=s(sN);QFo=r(net,"FlaubertWithLMHeadModel"),net.forEach(t),WFo=r(FAe," (FlauBERT model)"),FAe.forEach(t),HFo=i(V),r_=n(V,"LI",{});var TAe=s(r_);jle=n(TAe,"STRONG",{});var set=s(jle);UFo=r(set,"flava"),set.forEach(t),JFo=r(TAe," \u2014 "),lN=n(TAe,"A",{href:!0});var iet=s(lN);YFo=r(iet,"FlavaForPreTraining"),iet.forEach(t),KFo=r(TAe," (Flava model)"),TAe.forEach(t),ZFo=i(V),t_=n(V,"LI",{});var MAe=s(t_);Dle=n(MAe,"STRONG",{});var det=s(Dle);e6o=r(det,"fnet"),det.forEach(t),o6o=r(MAe," \u2014 "),iN=n(MAe,"A",{href:!0});var cet=s(iN);r6o=r(cet,"FNetForPreTraining"),cet.forEach(t),t6o=r(MAe," (FNet model)"),MAe.forEach(t),a6o=i(V),a_=n(V,"LI",{});var EAe=s(a_);Gle=n(EAe,"STRONG",{});var fet=s(Gle);n6o=r(fet,"fsmt"),fet.forEach(t),s6o=r(EAe," \u2014 "),dN=n(EAe,"A",{href:!0});var met=s(dN);l6o=r(met,"FSMTForConditionalGeneration"),met.forEach(t),i6o=r(EAe," (FairSeq Machine-Translation model)"),EAe.forEach(t),d6o=i(V),n_=n(V,"LI",{});var CAe=s(n_);Ole=n(CAe,"STRONG",{});var get=s(Ole);c6o=r(get,"funnel"),get.forEach(t),f6o=r(CAe," \u2014 "),cN=n(CAe,"A",{href:!0});var het=s(cN);m6o=r(het,"FunnelForPreTraining"),het.forEach(t),g6o=r(CAe," (Funnel Transformer model)"),CAe.forEach(t),h6o=i(V),s_=n(V,"LI",{});var wAe=s(s_);Vle=n(wAe,"STRONG",{});var pet=s(Vle);p6o=r(pet,"gpt2"),pet.forEach(t),u6o=r(wAe," \u2014 "),fN=n(wAe,"A",{href:!0});var uet=s(fN);_6o=r(uet,"GPT2LMHeadModel"),uet.forEach(t),b6o=r(wAe," (OpenAI GPT-2 model)"),wAe.forEach(t),v6o=i(V),l_=n(V,"LI",{});var AAe=s(l_);Xle=n(AAe,"STRONG",{});var _et=s(Xle);F6o=r(_et,"ibert"),_et.forEach(t),T6o=r(AAe," \u2014 "),mN=n(AAe,"A",{href:!0});var bet=s(mN);M6o=r(bet,"IBertForMaskedLM"),bet.forEach(t),E6o=r(AAe," (I-BERT model)"),AAe.forEach(t),C6o=i(V),i_=n(V,"LI",{});var yAe=s(i_);zle=n(yAe,"STRONG",{});var vet=s(zle);w6o=r(vet,"layoutlm"),vet.forEach(t),A6o=r(yAe," \u2014 "),gN=n(yAe,"A",{href:!0});var Fet=s(gN);y6o=r(Fet,"LayoutLMForMaskedLM"),Fet.forEach(t),L6o=r(yAe," (LayoutLM model)"),yAe.forEach(t),x6o=i(V),d_=n(V,"LI",{});var LAe=s(d_);Qle=n(LAe,"STRONG",{});var Tet=s(Qle);$6o=r(Tet,"longformer"),Tet.forEach(t),k6o=r(LAe," \u2014 "),hN=n(LAe,"A",{href:!0});var Met=s(hN);S6o=r(Met,"LongformerForMaskedLM"),Met.forEach(t),R6o=r(LAe," (Longformer model)"),LAe.forEach(t),B6o=i(V),c_=n(V,"LI",{});var xAe=s(c_);Wle=n(xAe,"STRONG",{});var Eet=s(Wle);P6o=r(Eet,"lxmert"),Eet.forEach(t),I6o=r(xAe," \u2014 "),pN=n(xAe,"A",{href:!0});var Cet=s(pN);q6o=r(Cet,"LxmertForPreTraining"),Cet.forEach(t),N6o=r(xAe," (LXMERT model)"),xAe.forEach(t),j6o=i(V),f_=n(V,"LI",{});var $Ae=s(f_);Hle=n($Ae,"STRONG",{});var wet=s(Hle);D6o=r(wet,"megatron-bert"),wet.forEach(t),G6o=r($Ae," \u2014 "),uN=n($Ae,"A",{href:!0});var Aet=s(uN);O6o=r(Aet,"MegatronBertForPreTraining"),Aet.forEach(t),V6o=r($Ae," (MegatronBert model)"),$Ae.forEach(t),X6o=i(V),m_=n(V,"LI",{});var kAe=s(m_);Ule=n(kAe,"STRONG",{});var yet=s(Ule);z6o=r(yet,"mobilebert"),yet.forEach(t),Q6o=r(kAe," \u2014 "),_N=n(kAe,"A",{href:!0});var Let=s(_N);W6o=r(Let,"MobileBertForPreTraining"),Let.forEach(t),H6o=r(kAe," (MobileBERT model)"),kAe.forEach(t),U6o=i(V),g_=n(V,"LI",{});var SAe=s(g_);Jle=n(SAe,"STRONG",{});var xet=s(Jle);J6o=r(xet,"mpnet"),xet.forEach(t),Y6o=r(SAe," \u2014 "),bN=n(SAe,"A",{href:!0});var $et=s(bN);K6o=r($et,"MPNetForMaskedLM"),$et.forEach(t),Z6o=r(SAe," (MPNet model)"),SAe.forEach(t),eTo=i(V),h_=n(V,"LI",{});var RAe=s(h_);Yle=n(RAe,"STRONG",{});var ket=s(Yle);oTo=r(ket,"openai-gpt"),ket.forEach(t),rTo=r(RAe," \u2014 "),vN=n(RAe,"A",{href:!0});var Set=s(vN);tTo=r(Set,"OpenAIGPTLMHeadModel"),Set.forEach(t),aTo=r(RAe," (OpenAI GPT model)"),RAe.forEach(t),nTo=i(V),p_=n(V,"LI",{});var BAe=s(p_);Kle=n(BAe,"STRONG",{});var Ret=s(Kle);sTo=r(Ret,"retribert"),Ret.forEach(t),lTo=r(BAe," \u2014 "),FN=n(BAe,"A",{href:!0});var Bet=s(FN);iTo=r(Bet,"RetriBertModel"),Bet.forEach(t),dTo=r(BAe," (RetriBERT model)"),BAe.forEach(t),cTo=i(V),u_=n(V,"LI",{});var PAe=s(u_);Zle=n(PAe,"STRONG",{});var Pet=s(Zle);fTo=r(Pet,"roberta"),Pet.forEach(t),mTo=r(PAe," \u2014 "),TN=n(PAe,"A",{href:!0});var Iet=s(TN);gTo=r(Iet,"RobertaForMaskedLM"),Iet.forEach(t),hTo=r(PAe," (RoBERTa model)"),PAe.forEach(t),pTo=i(V),__=n(V,"LI",{});var IAe=s(__);eie=n(IAe,"STRONG",{});var qet=s(eie);uTo=r(qet,"squeezebert"),qet.forEach(t),_To=r(IAe," \u2014 "),MN=n(IAe,"A",{href:!0});var Net=s(MN);bTo=r(Net,"SqueezeBertForMaskedLM"),Net.forEach(t),vTo=r(IAe," (SqueezeBERT model)"),IAe.forEach(t),FTo=i(V),b_=n(V,"LI",{});var qAe=s(b_);oie=n(qAe,"STRONG",{});var jet=s(oie);TTo=r(jet,"t5"),jet.forEach(t),MTo=r(qAe," \u2014 "),EN=n(qAe,"A",{href:!0});var Det=s(EN);ETo=r(Det,"T5ForConditionalGeneration"),Det.forEach(t),CTo=r(qAe," (T5 model)"),qAe.forEach(t),wTo=i(V),v_=n(V,"LI",{});var NAe=s(v_);rie=n(NAe,"STRONG",{});var Get=s(rie);ATo=r(Get,"tapas"),Get.forEach(t),yTo=r(NAe," \u2014 "),CN=n(NAe,"A",{href:!0});var Oet=s(CN);LTo=r(Oet,"TapasForMaskedLM"),Oet.forEach(t),xTo=r(NAe," (TAPAS model)"),NAe.forEach(t),$To=i(V),F_=n(V,"LI",{});var jAe=s(F_);tie=n(jAe,"STRONG",{});var Vet=s(tie);kTo=r(Vet,"transfo-xl"),Vet.forEach(t),STo=r(jAe," \u2014 "),wN=n(jAe,"A",{href:!0});var Xet=s(wN);RTo=r(Xet,"TransfoXLLMHeadModel"),Xet.forEach(t),BTo=r(jAe," (Transformer-XL model)"),jAe.forEach(t),PTo=i(V),T_=n(V,"LI",{});var DAe=s(T_);aie=n(DAe,"STRONG",{});var zet=s(aie);ITo=r(zet,"unispeech"),zet.forEach(t),qTo=r(DAe," \u2014 "),AN=n(DAe,"A",{href:!0});var Qet=s(AN);NTo=r(Qet,"UniSpeechForPreTraining"),Qet.forEach(t),jTo=r(DAe," (UniSpeech model)"),DAe.forEach(t),DTo=i(V),M_=n(V,"LI",{});var GAe=s(M_);nie=n(GAe,"STRONG",{});var Wet=s(nie);GTo=r(Wet,"unispeech-sat"),Wet.forEach(t),OTo=r(GAe," \u2014 "),yN=n(GAe,"A",{href:!0});var Het=s(yN);VTo=r(Het,"UniSpeechSatForPreTraining"),Het.forEach(t),XTo=r(GAe," (UniSpeechSat model)"),GAe.forEach(t),zTo=i(V),E_=n(V,"LI",{});var OAe=s(E_);sie=n(OAe,"STRONG",{});var Uet=s(sie);QTo=r(Uet,"visual_bert"),Uet.forEach(t),WTo=r(OAe," \u2014 "),LN=n(OAe,"A",{href:!0});var Jet=s(LN);HTo=r(Jet,"VisualBertForPreTraining"),Jet.forEach(t),UTo=r(OAe," (VisualBert model)"),OAe.forEach(t),JTo=i(V),C_=n(V,"LI",{});var VAe=s(C_);lie=n(VAe,"STRONG",{});var Yet=s(lie);YTo=r(Yet,"vit_mae"),Yet.forEach(t),KTo=r(VAe," \u2014 "),xN=n(VAe,"A",{href:!0});var Ket=s(xN);ZTo=r(Ket,"ViTMAEForPreTraining"),Ket.forEach(t),e7o=r(VAe," (ViTMAE model)"),VAe.forEach(t),o7o=i(V),w_=n(V,"LI",{});var XAe=s(w_);iie=n(XAe,"STRONG",{});var Zet=s(iie);r7o=r(Zet,"wav2vec2"),Zet.forEach(t),t7o=r(XAe," \u2014 "),$N=n(XAe,"A",{href:!0});var eot=s($N);a7o=r(eot,"Wav2Vec2ForPreTraining"),eot.forEach(t),n7o=r(XAe," (Wav2Vec2 model)"),XAe.forEach(t),s7o=i(V),A_=n(V,"LI",{});var zAe=s(A_);die=n(zAe,"STRONG",{});var oot=s(die);l7o=r(oot,"xlm"),oot.forEach(t),i7o=r(zAe," \u2014 "),kN=n(zAe,"A",{href:!0});var rot=s(kN);d7o=r(rot,"XLMWithLMHeadModel"),rot.forEach(t),c7o=r(zAe," (XLM model)"),zAe.forEach(t),f7o=i(V),y_=n(V,"LI",{});var QAe=s(y_);cie=n(QAe,"STRONG",{});var tot=s(cie);m7o=r(tot,"xlm-roberta"),tot.forEach(t),g7o=r(QAe," \u2014 "),SN=n(QAe,"A",{href:!0});var aot=s(SN);h7o=r(aot,"XLMRobertaForMaskedLM"),aot.forEach(t),p7o=r(QAe," (XLM-RoBERTa model)"),QAe.forEach(t),u7o=i(V),L_=n(V,"LI",{});var WAe=s(L_);fie=n(WAe,"STRONG",{});var not=s(fie);_7o=r(not,"xlm-roberta-xl"),not.forEach(t),b7o=r(WAe," \u2014 "),RN=n(WAe,"A",{href:!0});var sot=s(RN);v7o=r(sot,"XLMRobertaXLForMaskedLM"),sot.forEach(t),F7o=r(WAe," (XLM-RoBERTa-XL model)"),WAe.forEach(t),T7o=i(V),x_=n(V,"LI",{});var HAe=s(x_);mie=n(HAe,"STRONG",{});var lot=s(mie);M7o=r(lot,"xlnet"),lot.forEach(t),E7o=r(HAe," \u2014 "),BN=n(HAe,"A",{href:!0});var iot=s(BN);C7o=r(iot,"XLNetLMHeadModel"),iot.forEach(t),w7o=r(HAe," (XLNet model)"),HAe.forEach(t),V.forEach(t),A7o=i(ea),$_=n(ea,"P",{});var UAe=s($_);y7o=r(UAe,"The model is set in evaluation mode by default using "),gie=n(UAe,"CODE",{});var dot=s(gie);L7o=r(dot,"model.eval()"),dot.forEach(t),x7o=r(UAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hie=n(UAe,"CODE",{});var cot=s(hie);$7o=r(cot,"model.train()"),cot.forEach(t),UAe.forEach(t),k7o=i(ea),T(k_.$$.fragment,ea),ea.forEach(t),Gs.forEach(t),jIe=i(f),Li=n(f,"H2",{class:!0});var VNe=s(Li);S_=n(VNe,"A",{id:!0,class:!0,href:!0});var fot=s(S_);pie=n(fot,"SPAN",{});var mot=s(pie);T(GA.$$.fragment,mot),mot.forEach(t),fot.forEach(t),S7o=i(VNe),uie=n(VNe,"SPAN",{});var got=s(uie);R7o=r(got,"AutoModelForCausalLM"),got.forEach(t),VNe.forEach(t),DIe=i(f),$o=n(f,"DIV",{class:!0});var Os=s($o);T(OA.$$.fragment,Os),B7o=i(Os),xi=n(Os,"P",{});var $K=s(xi);P7o=r($K,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),PN=n($K,"A",{href:!0});var hot=s(PN);I7o=r(hot,"from_pretrained()"),hot.forEach(t),q7o=r($K," class method or the "),IN=n($K,"A",{href:!0});var pot=s(IN);N7o=r(pot,"from_config()"),pot.forEach(t),j7o=r($K,` class
method.`),$K.forEach(t),D7o=i(Os),VA=n(Os,"P",{});var XNe=s(VA);G7o=r(XNe,"This class cannot be instantiated directly using "),_ie=n(XNe,"CODE",{});var uot=s(_ie);O7o=r(uot,"__init__()"),uot.forEach(t),V7o=r(XNe," (throws an error)."),XNe.forEach(t),X7o=i(Os),tt=n(Os,"DIV",{class:!0});var m3=s(tt);T(XA.$$.fragment,m3),z7o=i(m3),bie=n(m3,"P",{});var _ot=s(bie);Q7o=r(_ot,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),_ot.forEach(t),W7o=i(m3),$i=n(m3,"P",{});var kK=s($i);H7o=r(kK,`Note:
Loading a model from its configuration file does `),vie=n(kK,"STRONG",{});var bot=s(vie);U7o=r(bot,"not"),bot.forEach(t),J7o=r(kK,` load the model weights. It only affects the
model\u2019s configuration. Use `),qN=n(kK,"A",{href:!0});var vot=s(qN);Y7o=r(vot,"from_pretrained()"),vot.forEach(t),K7o=r(kK," to load the model weights."),kK.forEach(t),Z7o=i(m3),T(R_.$$.fragment,m3),m3.forEach(t),eMo=i(Os),Je=n(Os,"DIV",{class:!0});var oa=s(Je);T(zA.$$.fragment,oa),oMo=i(oa),Fie=n(oa,"P",{});var Fot=s(Fie);rMo=r(Fot,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Fot.forEach(t),tMo=i(oa),La=n(oa,"P",{});var g3=s(La);aMo=r(g3,"The model class to instantiate is selected based on the "),Tie=n(g3,"CODE",{});var Tot=s(Tie);nMo=r(Tot,"model_type"),Tot.forEach(t),sMo=r(g3,` property of the config object (either
passed as an argument or loaded from `),Mie=n(g3,"CODE",{});var Mot=s(Mie);lMo=r(Mot,"pretrained_model_name_or_path"),Mot.forEach(t),iMo=r(g3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Eie=n(g3,"CODE",{});var Eot=s(Eie);dMo=r(Eot,"pretrained_model_name_or_path"),Eot.forEach(t),cMo=r(g3,":"),g3.forEach(t),fMo=i(oa),z=n(oa,"UL",{});var W=s(z);B_=n(W,"LI",{});var JAe=s(B_);Cie=n(JAe,"STRONG",{});var Cot=s(Cie);mMo=r(Cot,"bart"),Cot.forEach(t),gMo=r(JAe," \u2014 "),NN=n(JAe,"A",{href:!0});var wot=s(NN);hMo=r(wot,"BartForCausalLM"),wot.forEach(t),pMo=r(JAe," (BART model)"),JAe.forEach(t),uMo=i(W),P_=n(W,"LI",{});var YAe=s(P_);wie=n(YAe,"STRONG",{});var Aot=s(wie);_Mo=r(Aot,"bert"),Aot.forEach(t),bMo=r(YAe," \u2014 "),jN=n(YAe,"A",{href:!0});var yot=s(jN);vMo=r(yot,"BertLMHeadModel"),yot.forEach(t),FMo=r(YAe," (BERT model)"),YAe.forEach(t),TMo=i(W),I_=n(W,"LI",{});var KAe=s(I_);Aie=n(KAe,"STRONG",{});var Lot=s(Aie);MMo=r(Lot,"bert-generation"),Lot.forEach(t),EMo=r(KAe," \u2014 "),DN=n(KAe,"A",{href:!0});var xot=s(DN);CMo=r(xot,"BertGenerationDecoder"),xot.forEach(t),wMo=r(KAe," (Bert Generation model)"),KAe.forEach(t),AMo=i(W),q_=n(W,"LI",{});var ZAe=s(q_);yie=n(ZAe,"STRONG",{});var $ot=s(yie);yMo=r($ot,"big_bird"),$ot.forEach(t),LMo=r(ZAe," \u2014 "),GN=n(ZAe,"A",{href:!0});var kot=s(GN);xMo=r(kot,"BigBirdForCausalLM"),kot.forEach(t),$Mo=r(ZAe," (BigBird model)"),ZAe.forEach(t),kMo=i(W),N_=n(W,"LI",{});var eye=s(N_);Lie=n(eye,"STRONG",{});var Sot=s(Lie);SMo=r(Sot,"bigbird_pegasus"),Sot.forEach(t),RMo=r(eye," \u2014 "),ON=n(eye,"A",{href:!0});var Rot=s(ON);BMo=r(Rot,"BigBirdPegasusForCausalLM"),Rot.forEach(t),PMo=r(eye," (BigBirdPegasus model)"),eye.forEach(t),IMo=i(W),j_=n(W,"LI",{});var oye=s(j_);xie=n(oye,"STRONG",{});var Bot=s(xie);qMo=r(Bot,"blenderbot"),Bot.forEach(t),NMo=r(oye," \u2014 "),VN=n(oye,"A",{href:!0});var Pot=s(VN);jMo=r(Pot,"BlenderbotForCausalLM"),Pot.forEach(t),DMo=r(oye," (Blenderbot model)"),oye.forEach(t),GMo=i(W),D_=n(W,"LI",{});var rye=s(D_);$ie=n(rye,"STRONG",{});var Iot=s($ie);OMo=r(Iot,"blenderbot-small"),Iot.forEach(t),VMo=r(rye," \u2014 "),XN=n(rye,"A",{href:!0});var qot=s(XN);XMo=r(qot,"BlenderbotSmallForCausalLM"),qot.forEach(t),zMo=r(rye," (BlenderbotSmall model)"),rye.forEach(t),QMo=i(W),G_=n(W,"LI",{});var tye=s(G_);kie=n(tye,"STRONG",{});var Not=s(kie);WMo=r(Not,"camembert"),Not.forEach(t),HMo=r(tye," \u2014 "),zN=n(tye,"A",{href:!0});var jot=s(zN);UMo=r(jot,"CamembertForCausalLM"),jot.forEach(t),JMo=r(tye," (CamemBERT model)"),tye.forEach(t),YMo=i(W),O_=n(W,"LI",{});var aye=s(O_);Sie=n(aye,"STRONG",{});var Dot=s(Sie);KMo=r(Dot,"ctrl"),Dot.forEach(t),ZMo=r(aye," \u2014 "),QN=n(aye,"A",{href:!0});var Got=s(QN);e4o=r(Got,"CTRLLMHeadModel"),Got.forEach(t),o4o=r(aye," (CTRL model)"),aye.forEach(t),r4o=i(W),V_=n(W,"LI",{});var nye=s(V_);Rie=n(nye,"STRONG",{});var Oot=s(Rie);t4o=r(Oot,"data2vec-text"),Oot.forEach(t),a4o=r(nye," \u2014 "),WN=n(nye,"A",{href:!0});var Vot=s(WN);n4o=r(Vot,"Data2VecTextForCausalLM"),Vot.forEach(t),s4o=r(nye," (Data2VecText model)"),nye.forEach(t),l4o=i(W),X_=n(W,"LI",{});var sye=s(X_);Bie=n(sye,"STRONG",{});var Xot=s(Bie);i4o=r(Xot,"electra"),Xot.forEach(t),d4o=r(sye," \u2014 "),HN=n(sye,"A",{href:!0});var zot=s(HN);c4o=r(zot,"ElectraForCausalLM"),zot.forEach(t),f4o=r(sye," (ELECTRA model)"),sye.forEach(t),m4o=i(W),z_=n(W,"LI",{});var lye=s(z_);Pie=n(lye,"STRONG",{});var Qot=s(Pie);g4o=r(Qot,"gpt2"),Qot.forEach(t),h4o=r(lye," \u2014 "),UN=n(lye,"A",{href:!0});var Wot=s(UN);p4o=r(Wot,"GPT2LMHeadModel"),Wot.forEach(t),u4o=r(lye," (OpenAI GPT-2 model)"),lye.forEach(t),_4o=i(W),Q_=n(W,"LI",{});var iye=s(Q_);Iie=n(iye,"STRONG",{});var Hot=s(Iie);b4o=r(Hot,"gpt_neo"),Hot.forEach(t),v4o=r(iye," \u2014 "),JN=n(iye,"A",{href:!0});var Uot=s(JN);F4o=r(Uot,"GPTNeoForCausalLM"),Uot.forEach(t),T4o=r(iye," (GPT Neo model)"),iye.forEach(t),M4o=i(W),W_=n(W,"LI",{});var dye=s(W_);qie=n(dye,"STRONG",{});var Jot=s(qie);E4o=r(Jot,"gptj"),Jot.forEach(t),C4o=r(dye," \u2014 "),YN=n(dye,"A",{href:!0});var Yot=s(YN);w4o=r(Yot,"GPTJForCausalLM"),Yot.forEach(t),A4o=r(dye," (GPT-J model)"),dye.forEach(t),y4o=i(W),H_=n(W,"LI",{});var cye=s(H_);Nie=n(cye,"STRONG",{});var Kot=s(Nie);L4o=r(Kot,"marian"),Kot.forEach(t),x4o=r(cye," \u2014 "),KN=n(cye,"A",{href:!0});var Zot=s(KN);$4o=r(Zot,"MarianForCausalLM"),Zot.forEach(t),k4o=r(cye," (Marian model)"),cye.forEach(t),S4o=i(W),U_=n(W,"LI",{});var fye=s(U_);jie=n(fye,"STRONG",{});var ert=s(jie);R4o=r(ert,"mbart"),ert.forEach(t),B4o=r(fye," \u2014 "),ZN=n(fye,"A",{href:!0});var ort=s(ZN);P4o=r(ort,"MBartForCausalLM"),ort.forEach(t),I4o=r(fye," (mBART model)"),fye.forEach(t),q4o=i(W),J_=n(W,"LI",{});var mye=s(J_);Die=n(mye,"STRONG",{});var rrt=s(Die);N4o=r(rrt,"megatron-bert"),rrt.forEach(t),j4o=r(mye," \u2014 "),ej=n(mye,"A",{href:!0});var trt=s(ej);D4o=r(trt,"MegatronBertForCausalLM"),trt.forEach(t),G4o=r(mye," (MegatronBert model)"),mye.forEach(t),O4o=i(W),Y_=n(W,"LI",{});var gye=s(Y_);Gie=n(gye,"STRONG",{});var art=s(Gie);V4o=r(art,"openai-gpt"),art.forEach(t),X4o=r(gye," \u2014 "),oj=n(gye,"A",{href:!0});var nrt=s(oj);z4o=r(nrt,"OpenAIGPTLMHeadModel"),nrt.forEach(t),Q4o=r(gye," (OpenAI GPT model)"),gye.forEach(t),W4o=i(W),K_=n(W,"LI",{});var hye=s(K_);Oie=n(hye,"STRONG",{});var srt=s(Oie);H4o=r(srt,"opt"),srt.forEach(t),U4o=r(hye," \u2014 "),rj=n(hye,"A",{href:!0});var lrt=s(rj);J4o=r(lrt,"OPTForCausalLM"),lrt.forEach(t),Y4o=r(hye," (OPT model)"),hye.forEach(t),K4o=i(W),Z_=n(W,"LI",{});var pye=s(Z_);Vie=n(pye,"STRONG",{});var irt=s(Vie);Z4o=r(irt,"pegasus"),irt.forEach(t),eEo=r(pye," \u2014 "),tj=n(pye,"A",{href:!0});var drt=s(tj);oEo=r(drt,"PegasusForCausalLM"),drt.forEach(t),rEo=r(pye," (Pegasus model)"),pye.forEach(t),tEo=i(W),e0=n(W,"LI",{});var uye=s(e0);Xie=n(uye,"STRONG",{});var crt=s(Xie);aEo=r(crt,"plbart"),crt.forEach(t),nEo=r(uye," \u2014 "),aj=n(uye,"A",{href:!0});var frt=s(aj);sEo=r(frt,"PLBartForCausalLM"),frt.forEach(t),lEo=r(uye," (PLBart model)"),uye.forEach(t),iEo=i(W),o0=n(W,"LI",{});var _ye=s(o0);zie=n(_ye,"STRONG",{});var mrt=s(zie);dEo=r(mrt,"prophetnet"),mrt.forEach(t),cEo=r(_ye," \u2014 "),nj=n(_ye,"A",{href:!0});var grt=s(nj);fEo=r(grt,"ProphetNetForCausalLM"),grt.forEach(t),mEo=r(_ye," (ProphetNet model)"),_ye.forEach(t),gEo=i(W),r0=n(W,"LI",{});var bye=s(r0);Qie=n(bye,"STRONG",{});var hrt=s(Qie);hEo=r(hrt,"qdqbert"),hrt.forEach(t),pEo=r(bye," \u2014 "),sj=n(bye,"A",{href:!0});var prt=s(sj);uEo=r(prt,"QDQBertLMHeadModel"),prt.forEach(t),_Eo=r(bye," (QDQBert model)"),bye.forEach(t),bEo=i(W),t0=n(W,"LI",{});var vye=s(t0);Wie=n(vye,"STRONG",{});var urt=s(Wie);vEo=r(urt,"reformer"),urt.forEach(t),FEo=r(vye," \u2014 "),lj=n(vye,"A",{href:!0});var _rt=s(lj);TEo=r(_rt,"ReformerModelWithLMHead"),_rt.forEach(t),MEo=r(vye," (Reformer model)"),vye.forEach(t),EEo=i(W),a0=n(W,"LI",{});var Fye=s(a0);Hie=n(Fye,"STRONG",{});var brt=s(Hie);CEo=r(brt,"rembert"),brt.forEach(t),wEo=r(Fye," \u2014 "),ij=n(Fye,"A",{href:!0});var vrt=s(ij);AEo=r(vrt,"RemBertForCausalLM"),vrt.forEach(t),yEo=r(Fye," (RemBERT model)"),Fye.forEach(t),LEo=i(W),n0=n(W,"LI",{});var Tye=s(n0);Uie=n(Tye,"STRONG",{});var Frt=s(Uie);xEo=r(Frt,"roberta"),Frt.forEach(t),$Eo=r(Tye," \u2014 "),dj=n(Tye,"A",{href:!0});var Trt=s(dj);kEo=r(Trt,"RobertaForCausalLM"),Trt.forEach(t),SEo=r(Tye," (RoBERTa model)"),Tye.forEach(t),REo=i(W),s0=n(W,"LI",{});var Mye=s(s0);Jie=n(Mye,"STRONG",{});var Mrt=s(Jie);BEo=r(Mrt,"roformer"),Mrt.forEach(t),PEo=r(Mye," \u2014 "),cj=n(Mye,"A",{href:!0});var Ert=s(cj);IEo=r(Ert,"RoFormerForCausalLM"),Ert.forEach(t),qEo=r(Mye," (RoFormer model)"),Mye.forEach(t),NEo=i(W),l0=n(W,"LI",{});var Eye=s(l0);Yie=n(Eye,"STRONG",{});var Crt=s(Yie);jEo=r(Crt,"speech_to_text_2"),Crt.forEach(t),DEo=r(Eye," \u2014 "),fj=n(Eye,"A",{href:!0});var wrt=s(fj);GEo=r(wrt,"Speech2Text2ForCausalLM"),wrt.forEach(t),OEo=r(Eye," (Speech2Text2 model)"),Eye.forEach(t),VEo=i(W),i0=n(W,"LI",{});var Cye=s(i0);Kie=n(Cye,"STRONG",{});var Art=s(Kie);XEo=r(Art,"transfo-xl"),Art.forEach(t),zEo=r(Cye," \u2014 "),mj=n(Cye,"A",{href:!0});var yrt=s(mj);QEo=r(yrt,"TransfoXLLMHeadModel"),yrt.forEach(t),WEo=r(Cye," (Transformer-XL model)"),Cye.forEach(t),HEo=i(W),d0=n(W,"LI",{});var wye=s(d0);Zie=n(wye,"STRONG",{});var Lrt=s(Zie);UEo=r(Lrt,"trocr"),Lrt.forEach(t),JEo=r(wye," \u2014 "),gj=n(wye,"A",{href:!0});var xrt=s(gj);YEo=r(xrt,"TrOCRForCausalLM"),xrt.forEach(t),KEo=r(wye," (TrOCR model)"),wye.forEach(t),ZEo=i(W),c0=n(W,"LI",{});var Aye=s(c0);ede=n(Aye,"STRONG",{});var $rt=s(ede);e5o=r($rt,"xglm"),$rt.forEach(t),o5o=r(Aye," \u2014 "),hj=n(Aye,"A",{href:!0});var krt=s(hj);r5o=r(krt,"XGLMForCausalLM"),krt.forEach(t),t5o=r(Aye," (XGLM model)"),Aye.forEach(t),a5o=i(W),f0=n(W,"LI",{});var yye=s(f0);ode=n(yye,"STRONG",{});var Srt=s(ode);n5o=r(Srt,"xlm"),Srt.forEach(t),s5o=r(yye," \u2014 "),pj=n(yye,"A",{href:!0});var Rrt=s(pj);l5o=r(Rrt,"XLMWithLMHeadModel"),Rrt.forEach(t),i5o=r(yye," (XLM model)"),yye.forEach(t),d5o=i(W),m0=n(W,"LI",{});var Lye=s(m0);rde=n(Lye,"STRONG",{});var Brt=s(rde);c5o=r(Brt,"xlm-prophetnet"),Brt.forEach(t),f5o=r(Lye," \u2014 "),uj=n(Lye,"A",{href:!0});var Prt=s(uj);m5o=r(Prt,"XLMProphetNetForCausalLM"),Prt.forEach(t),g5o=r(Lye," (XLMProphetNet model)"),Lye.forEach(t),h5o=i(W),g0=n(W,"LI",{});var xye=s(g0);tde=n(xye,"STRONG",{});var Irt=s(tde);p5o=r(Irt,"xlm-roberta"),Irt.forEach(t),u5o=r(xye," \u2014 "),_j=n(xye,"A",{href:!0});var qrt=s(_j);_5o=r(qrt,"XLMRobertaForCausalLM"),qrt.forEach(t),b5o=r(xye," (XLM-RoBERTa model)"),xye.forEach(t),v5o=i(W),h0=n(W,"LI",{});var $ye=s(h0);ade=n($ye,"STRONG",{});var Nrt=s(ade);F5o=r(Nrt,"xlm-roberta-xl"),Nrt.forEach(t),T5o=r($ye," \u2014 "),bj=n($ye,"A",{href:!0});var jrt=s(bj);M5o=r(jrt,"XLMRobertaXLForCausalLM"),jrt.forEach(t),E5o=r($ye," (XLM-RoBERTa-XL model)"),$ye.forEach(t),C5o=i(W),p0=n(W,"LI",{});var kye=s(p0);nde=n(kye,"STRONG",{});var Drt=s(nde);w5o=r(Drt,"xlnet"),Drt.forEach(t),A5o=r(kye," \u2014 "),vj=n(kye,"A",{href:!0});var Grt=s(vj);y5o=r(Grt,"XLNetLMHeadModel"),Grt.forEach(t),L5o=r(kye," (XLNet model)"),kye.forEach(t),W.forEach(t),x5o=i(oa),u0=n(oa,"P",{});var Sye=s(u0);$5o=r(Sye,"The model is set in evaluation mode by default using "),sde=n(Sye,"CODE",{});var Ort=s(sde);k5o=r(Ort,"model.eval()"),Ort.forEach(t),S5o=r(Sye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lde=n(Sye,"CODE",{});var Vrt=s(lde);R5o=r(Vrt,"model.train()"),Vrt.forEach(t),Sye.forEach(t),B5o=i(oa),T(_0.$$.fragment,oa),oa.forEach(t),Os.forEach(t),GIe=i(f),ki=n(f,"H2",{class:!0});var zNe=s(ki);b0=n(zNe,"A",{id:!0,class:!0,href:!0});var Xrt=s(b0);ide=n(Xrt,"SPAN",{});var zrt=s(ide);T(QA.$$.fragment,zrt),zrt.forEach(t),Xrt.forEach(t),P5o=i(zNe),dde=n(zNe,"SPAN",{});var Qrt=s(dde);I5o=r(Qrt,"AutoModelForMaskedLM"),Qrt.forEach(t),zNe.forEach(t),OIe=i(f),ko=n(f,"DIV",{class:!0});var Vs=s(ko);T(WA.$$.fragment,Vs),q5o=i(Vs),Si=n(Vs,"P",{});var SK=s(Si);N5o=r(SK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fj=n(SK,"A",{href:!0});var Wrt=s(Fj);j5o=r(Wrt,"from_pretrained()"),Wrt.forEach(t),D5o=r(SK," class method or the "),Tj=n(SK,"A",{href:!0});var Hrt=s(Tj);G5o=r(Hrt,"from_config()"),Hrt.forEach(t),O5o=r(SK,` class
method.`),SK.forEach(t),V5o=i(Vs),HA=n(Vs,"P",{});var QNe=s(HA);X5o=r(QNe,"This class cannot be instantiated directly using "),cde=n(QNe,"CODE",{});var Urt=s(cde);z5o=r(Urt,"__init__()"),Urt.forEach(t),Q5o=r(QNe," (throws an error)."),QNe.forEach(t),W5o=i(Vs),at=n(Vs,"DIV",{class:!0});var h3=s(at);T(UA.$$.fragment,h3),H5o=i(h3),fde=n(h3,"P",{});var Jrt=s(fde);U5o=r(Jrt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Jrt.forEach(t),J5o=i(h3),Ri=n(h3,"P",{});var RK=s(Ri);Y5o=r(RK,`Note:
Loading a model from its configuration file does `),mde=n(RK,"STRONG",{});var Yrt=s(mde);K5o=r(Yrt,"not"),Yrt.forEach(t),Z5o=r(RK,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mj=n(RK,"A",{href:!0});var Krt=s(Mj);eCo=r(Krt,"from_pretrained()"),Krt.forEach(t),oCo=r(RK," to load the model weights."),RK.forEach(t),rCo=i(h3),T(v0.$$.fragment,h3),h3.forEach(t),tCo=i(Vs),Ye=n(Vs,"DIV",{class:!0});var ra=s(Ye);T(JA.$$.fragment,ra),aCo=i(ra),gde=n(ra,"P",{});var Zrt=s(gde);nCo=r(Zrt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Zrt.forEach(t),sCo=i(ra),xa=n(ra,"P",{});var p3=s(xa);lCo=r(p3,"The model class to instantiate is selected based on the "),hde=n(p3,"CODE",{});var ett=s(hde);iCo=r(ett,"model_type"),ett.forEach(t),dCo=r(p3,` property of the config object (either
passed as an argument or loaded from `),pde=n(p3,"CODE",{});var ott=s(pde);cCo=r(ott,"pretrained_model_name_or_path"),ott.forEach(t),fCo=r(p3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ude=n(p3,"CODE",{});var rtt=s(ude);mCo=r(rtt,"pretrained_model_name_or_path"),rtt.forEach(t),gCo=r(p3,":"),p3.forEach(t),hCo=i(ra),Q=n(ra,"UL",{});var U=s(Q);F0=n(U,"LI",{});var Rye=s(F0);_de=n(Rye,"STRONG",{});var ttt=s(_de);pCo=r(ttt,"albert"),ttt.forEach(t),uCo=r(Rye," \u2014 "),Ej=n(Rye,"A",{href:!0});var att=s(Ej);_Co=r(att,"AlbertForMaskedLM"),att.forEach(t),bCo=r(Rye," (ALBERT model)"),Rye.forEach(t),vCo=i(U),T0=n(U,"LI",{});var Bye=s(T0);bde=n(Bye,"STRONG",{});var ntt=s(bde);FCo=r(ntt,"bart"),ntt.forEach(t),TCo=r(Bye," \u2014 "),Cj=n(Bye,"A",{href:!0});var stt=s(Cj);MCo=r(stt,"BartForConditionalGeneration"),stt.forEach(t),ECo=r(Bye," (BART model)"),Bye.forEach(t),CCo=i(U),M0=n(U,"LI",{});var Pye=s(M0);vde=n(Pye,"STRONG",{});var ltt=s(vde);wCo=r(ltt,"bert"),ltt.forEach(t),ACo=r(Pye," \u2014 "),wj=n(Pye,"A",{href:!0});var itt=s(wj);yCo=r(itt,"BertForMaskedLM"),itt.forEach(t),LCo=r(Pye," (BERT model)"),Pye.forEach(t),xCo=i(U),E0=n(U,"LI",{});var Iye=s(E0);Fde=n(Iye,"STRONG",{});var dtt=s(Fde);$Co=r(dtt,"big_bird"),dtt.forEach(t),kCo=r(Iye," \u2014 "),Aj=n(Iye,"A",{href:!0});var ctt=s(Aj);SCo=r(ctt,"BigBirdForMaskedLM"),ctt.forEach(t),RCo=r(Iye," (BigBird model)"),Iye.forEach(t),BCo=i(U),C0=n(U,"LI",{});var qye=s(C0);Tde=n(qye,"STRONG",{});var ftt=s(Tde);PCo=r(ftt,"camembert"),ftt.forEach(t),ICo=r(qye," \u2014 "),yj=n(qye,"A",{href:!0});var mtt=s(yj);qCo=r(mtt,"CamembertForMaskedLM"),mtt.forEach(t),NCo=r(qye," (CamemBERT model)"),qye.forEach(t),jCo=i(U),w0=n(U,"LI",{});var Nye=s(w0);Mde=n(Nye,"STRONG",{});var gtt=s(Mde);DCo=r(gtt,"convbert"),gtt.forEach(t),GCo=r(Nye," \u2014 "),Lj=n(Nye,"A",{href:!0});var htt=s(Lj);OCo=r(htt,"ConvBertForMaskedLM"),htt.forEach(t),VCo=r(Nye," (ConvBERT model)"),Nye.forEach(t),XCo=i(U),A0=n(U,"LI",{});var jye=s(A0);Ede=n(jye,"STRONG",{});var ptt=s(Ede);zCo=r(ptt,"data2vec-text"),ptt.forEach(t),QCo=r(jye," \u2014 "),xj=n(jye,"A",{href:!0});var utt=s(xj);WCo=r(utt,"Data2VecTextForMaskedLM"),utt.forEach(t),HCo=r(jye," (Data2VecText model)"),jye.forEach(t),UCo=i(U),y0=n(U,"LI",{});var Dye=s(y0);Cde=n(Dye,"STRONG",{});var _tt=s(Cde);JCo=r(_tt,"deberta"),_tt.forEach(t),YCo=r(Dye," \u2014 "),$j=n(Dye,"A",{href:!0});var btt=s($j);KCo=r(btt,"DebertaForMaskedLM"),btt.forEach(t),ZCo=r(Dye," (DeBERTa model)"),Dye.forEach(t),e3o=i(U),L0=n(U,"LI",{});var Gye=s(L0);wde=n(Gye,"STRONG",{});var vtt=s(wde);o3o=r(vtt,"deberta-v2"),vtt.forEach(t),r3o=r(Gye," \u2014 "),kj=n(Gye,"A",{href:!0});var Ftt=s(kj);t3o=r(Ftt,"DebertaV2ForMaskedLM"),Ftt.forEach(t),a3o=r(Gye," (DeBERTa-v2 model)"),Gye.forEach(t),n3o=i(U),x0=n(U,"LI",{});var Oye=s(x0);Ade=n(Oye,"STRONG",{});var Ttt=s(Ade);s3o=r(Ttt,"distilbert"),Ttt.forEach(t),l3o=r(Oye," \u2014 "),Sj=n(Oye,"A",{href:!0});var Mtt=s(Sj);i3o=r(Mtt,"DistilBertForMaskedLM"),Mtt.forEach(t),d3o=r(Oye," (DistilBERT model)"),Oye.forEach(t),c3o=i(U),$0=n(U,"LI",{});var Vye=s($0);yde=n(Vye,"STRONG",{});var Ett=s(yde);f3o=r(Ett,"electra"),Ett.forEach(t),m3o=r(Vye," \u2014 "),Rj=n(Vye,"A",{href:!0});var Ctt=s(Rj);g3o=r(Ctt,"ElectraForMaskedLM"),Ctt.forEach(t),h3o=r(Vye," (ELECTRA model)"),Vye.forEach(t),p3o=i(U),k0=n(U,"LI",{});var Xye=s(k0);Lde=n(Xye,"STRONG",{});var wtt=s(Lde);u3o=r(wtt,"flaubert"),wtt.forEach(t),_3o=r(Xye," \u2014 "),Bj=n(Xye,"A",{href:!0});var Att=s(Bj);b3o=r(Att,"FlaubertWithLMHeadModel"),Att.forEach(t),v3o=r(Xye," (FlauBERT model)"),Xye.forEach(t),F3o=i(U),S0=n(U,"LI",{});var zye=s(S0);xde=n(zye,"STRONG",{});var ytt=s(xde);T3o=r(ytt,"fnet"),ytt.forEach(t),M3o=r(zye," \u2014 "),Pj=n(zye,"A",{href:!0});var Ltt=s(Pj);E3o=r(Ltt,"FNetForMaskedLM"),Ltt.forEach(t),C3o=r(zye," (FNet model)"),zye.forEach(t),w3o=i(U),R0=n(U,"LI",{});var Qye=s(R0);$de=n(Qye,"STRONG",{});var xtt=s($de);A3o=r(xtt,"funnel"),xtt.forEach(t),y3o=r(Qye," \u2014 "),Ij=n(Qye,"A",{href:!0});var $tt=s(Ij);L3o=r($tt,"FunnelForMaskedLM"),$tt.forEach(t),x3o=r(Qye," (Funnel Transformer model)"),Qye.forEach(t),$3o=i(U),B0=n(U,"LI",{});var Wye=s(B0);kde=n(Wye,"STRONG",{});var ktt=s(kde);k3o=r(ktt,"ibert"),ktt.forEach(t),S3o=r(Wye," \u2014 "),qj=n(Wye,"A",{href:!0});var Stt=s(qj);R3o=r(Stt,"IBertForMaskedLM"),Stt.forEach(t),B3o=r(Wye," (I-BERT model)"),Wye.forEach(t),P3o=i(U),P0=n(U,"LI",{});var Hye=s(P0);Sde=n(Hye,"STRONG",{});var Rtt=s(Sde);I3o=r(Rtt,"layoutlm"),Rtt.forEach(t),q3o=r(Hye," \u2014 "),Nj=n(Hye,"A",{href:!0});var Btt=s(Nj);N3o=r(Btt,"LayoutLMForMaskedLM"),Btt.forEach(t),j3o=r(Hye," (LayoutLM model)"),Hye.forEach(t),D3o=i(U),I0=n(U,"LI",{});var Uye=s(I0);Rde=n(Uye,"STRONG",{});var Ptt=s(Rde);G3o=r(Ptt,"longformer"),Ptt.forEach(t),O3o=r(Uye," \u2014 "),jj=n(Uye,"A",{href:!0});var Itt=s(jj);V3o=r(Itt,"LongformerForMaskedLM"),Itt.forEach(t),X3o=r(Uye," (Longformer model)"),Uye.forEach(t),z3o=i(U),q0=n(U,"LI",{});var Jye=s(q0);Bde=n(Jye,"STRONG",{});var qtt=s(Bde);Q3o=r(qtt,"mbart"),qtt.forEach(t),W3o=r(Jye," \u2014 "),Dj=n(Jye,"A",{href:!0});var Ntt=s(Dj);H3o=r(Ntt,"MBartForConditionalGeneration"),Ntt.forEach(t),U3o=r(Jye," (mBART model)"),Jye.forEach(t),J3o=i(U),N0=n(U,"LI",{});var Yye=s(N0);Pde=n(Yye,"STRONG",{});var jtt=s(Pde);Y3o=r(jtt,"megatron-bert"),jtt.forEach(t),K3o=r(Yye," \u2014 "),Gj=n(Yye,"A",{href:!0});var Dtt=s(Gj);Z3o=r(Dtt,"MegatronBertForMaskedLM"),Dtt.forEach(t),ewo=r(Yye," (MegatronBert model)"),Yye.forEach(t),owo=i(U),j0=n(U,"LI",{});var Kye=s(j0);Ide=n(Kye,"STRONG",{});var Gtt=s(Ide);rwo=r(Gtt,"mobilebert"),Gtt.forEach(t),two=r(Kye," \u2014 "),Oj=n(Kye,"A",{href:!0});var Ott=s(Oj);awo=r(Ott,"MobileBertForMaskedLM"),Ott.forEach(t),nwo=r(Kye," (MobileBERT model)"),Kye.forEach(t),swo=i(U),D0=n(U,"LI",{});var Zye=s(D0);qde=n(Zye,"STRONG",{});var Vtt=s(qde);lwo=r(Vtt,"mpnet"),Vtt.forEach(t),iwo=r(Zye," \u2014 "),Vj=n(Zye,"A",{href:!0});var Xtt=s(Vj);dwo=r(Xtt,"MPNetForMaskedLM"),Xtt.forEach(t),cwo=r(Zye," (MPNet model)"),Zye.forEach(t),fwo=i(U),G0=n(U,"LI",{});var eLe=s(G0);Nde=n(eLe,"STRONG",{});var ztt=s(Nde);mwo=r(ztt,"nystromformer"),ztt.forEach(t),gwo=r(eLe," \u2014 "),Xj=n(eLe,"A",{href:!0});var Qtt=s(Xj);hwo=r(Qtt,"NystromformerForMaskedLM"),Qtt.forEach(t),pwo=r(eLe," (Nystromformer model)"),eLe.forEach(t),uwo=i(U),O0=n(U,"LI",{});var oLe=s(O0);jde=n(oLe,"STRONG",{});var Wtt=s(jde);_wo=r(Wtt,"perceiver"),Wtt.forEach(t),bwo=r(oLe," \u2014 "),zj=n(oLe,"A",{href:!0});var Htt=s(zj);vwo=r(Htt,"PerceiverForMaskedLM"),Htt.forEach(t),Fwo=r(oLe," (Perceiver model)"),oLe.forEach(t),Two=i(U),V0=n(U,"LI",{});var rLe=s(V0);Dde=n(rLe,"STRONG",{});var Utt=s(Dde);Mwo=r(Utt,"qdqbert"),Utt.forEach(t),Ewo=r(rLe," \u2014 "),Qj=n(rLe,"A",{href:!0});var Jtt=s(Qj);Cwo=r(Jtt,"QDQBertForMaskedLM"),Jtt.forEach(t),wwo=r(rLe," (QDQBert model)"),rLe.forEach(t),Awo=i(U),X0=n(U,"LI",{});var tLe=s(X0);Gde=n(tLe,"STRONG",{});var Ytt=s(Gde);ywo=r(Ytt,"reformer"),Ytt.forEach(t),Lwo=r(tLe," \u2014 "),Wj=n(tLe,"A",{href:!0});var Ktt=s(Wj);xwo=r(Ktt,"ReformerForMaskedLM"),Ktt.forEach(t),$wo=r(tLe," (Reformer model)"),tLe.forEach(t),kwo=i(U),z0=n(U,"LI",{});var aLe=s(z0);Ode=n(aLe,"STRONG",{});var Ztt=s(Ode);Swo=r(Ztt,"rembert"),Ztt.forEach(t),Rwo=r(aLe," \u2014 "),Hj=n(aLe,"A",{href:!0});var eat=s(Hj);Bwo=r(eat,"RemBertForMaskedLM"),eat.forEach(t),Pwo=r(aLe," (RemBERT model)"),aLe.forEach(t),Iwo=i(U),Q0=n(U,"LI",{});var nLe=s(Q0);Vde=n(nLe,"STRONG",{});var oat=s(Vde);qwo=r(oat,"roberta"),oat.forEach(t),Nwo=r(nLe," \u2014 "),Uj=n(nLe,"A",{href:!0});var rat=s(Uj);jwo=r(rat,"RobertaForMaskedLM"),rat.forEach(t),Dwo=r(nLe," (RoBERTa model)"),nLe.forEach(t),Gwo=i(U),W0=n(U,"LI",{});var sLe=s(W0);Xde=n(sLe,"STRONG",{});var tat=s(Xde);Owo=r(tat,"roformer"),tat.forEach(t),Vwo=r(sLe," \u2014 "),Jj=n(sLe,"A",{href:!0});var aat=s(Jj);Xwo=r(aat,"RoFormerForMaskedLM"),aat.forEach(t),zwo=r(sLe," (RoFormer model)"),sLe.forEach(t),Qwo=i(U),H0=n(U,"LI",{});var lLe=s(H0);zde=n(lLe,"STRONG",{});var nat=s(zde);Wwo=r(nat,"squeezebert"),nat.forEach(t),Hwo=r(lLe," \u2014 "),Yj=n(lLe,"A",{href:!0});var sat=s(Yj);Uwo=r(sat,"SqueezeBertForMaskedLM"),sat.forEach(t),Jwo=r(lLe," (SqueezeBERT model)"),lLe.forEach(t),Ywo=i(U),U0=n(U,"LI",{});var iLe=s(U0);Qde=n(iLe,"STRONG",{});var lat=s(Qde);Kwo=r(lat,"tapas"),lat.forEach(t),Zwo=r(iLe," \u2014 "),Kj=n(iLe,"A",{href:!0});var iat=s(Kj);eAo=r(iat,"TapasForMaskedLM"),iat.forEach(t),oAo=r(iLe," (TAPAS model)"),iLe.forEach(t),rAo=i(U),J0=n(U,"LI",{});var dLe=s(J0);Wde=n(dLe,"STRONG",{});var dat=s(Wde);tAo=r(dat,"wav2vec2"),dat.forEach(t),aAo=r(dLe," \u2014 "),Hde=n(dLe,"CODE",{});var cat=s(Hde);nAo=r(cat,"Wav2Vec2ForMaskedLM"),cat.forEach(t),sAo=r(dLe," (Wav2Vec2 model)"),dLe.forEach(t),lAo=i(U),Y0=n(U,"LI",{});var cLe=s(Y0);Ude=n(cLe,"STRONG",{});var fat=s(Ude);iAo=r(fat,"xlm"),fat.forEach(t),dAo=r(cLe," \u2014 "),Zj=n(cLe,"A",{href:!0});var mat=s(Zj);cAo=r(mat,"XLMWithLMHeadModel"),mat.forEach(t),fAo=r(cLe," (XLM model)"),cLe.forEach(t),mAo=i(U),K0=n(U,"LI",{});var fLe=s(K0);Jde=n(fLe,"STRONG",{});var gat=s(Jde);gAo=r(gat,"xlm-roberta"),gat.forEach(t),hAo=r(fLe," \u2014 "),eD=n(fLe,"A",{href:!0});var hat=s(eD);pAo=r(hat,"XLMRobertaForMaskedLM"),hat.forEach(t),uAo=r(fLe," (XLM-RoBERTa model)"),fLe.forEach(t),_Ao=i(U),Z0=n(U,"LI",{});var mLe=s(Z0);Yde=n(mLe,"STRONG",{});var pat=s(Yde);bAo=r(pat,"xlm-roberta-xl"),pat.forEach(t),vAo=r(mLe," \u2014 "),oD=n(mLe,"A",{href:!0});var uat=s(oD);FAo=r(uat,"XLMRobertaXLForMaskedLM"),uat.forEach(t),TAo=r(mLe," (XLM-RoBERTa-XL model)"),mLe.forEach(t),MAo=i(U),e1=n(U,"LI",{});var gLe=s(e1);Kde=n(gLe,"STRONG",{});var _at=s(Kde);EAo=r(_at,"yoso"),_at.forEach(t),CAo=r(gLe," \u2014 "),rD=n(gLe,"A",{href:!0});var bat=s(rD);wAo=r(bat,"YosoForMaskedLM"),bat.forEach(t),AAo=r(gLe," (YOSO model)"),gLe.forEach(t),U.forEach(t),yAo=i(ra),o1=n(ra,"P",{});var hLe=s(o1);LAo=r(hLe,"The model is set in evaluation mode by default using "),Zde=n(hLe,"CODE",{});var vat=s(Zde);xAo=r(vat,"model.eval()"),vat.forEach(t),$Ao=r(hLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ece=n(hLe,"CODE",{});var Fat=s(ece);kAo=r(Fat,"model.train()"),Fat.forEach(t),hLe.forEach(t),SAo=i(ra),T(r1.$$.fragment,ra),ra.forEach(t),Vs.forEach(t),VIe=i(f),Bi=n(f,"H2",{class:!0});var WNe=s(Bi);t1=n(WNe,"A",{id:!0,class:!0,href:!0});var Tat=s(t1);oce=n(Tat,"SPAN",{});var Mat=s(oce);T(YA.$$.fragment,Mat),Mat.forEach(t),Tat.forEach(t),RAo=i(WNe),rce=n(WNe,"SPAN",{});var Eat=s(rce);BAo=r(Eat,"AutoModelForSeq2SeqLM"),Eat.forEach(t),WNe.forEach(t),XIe=i(f),So=n(f,"DIV",{class:!0});var Xs=s(So);T(KA.$$.fragment,Xs),PAo=i(Xs),Pi=n(Xs,"P",{});var BK=s(Pi);IAo=r(BK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tD=n(BK,"A",{href:!0});var Cat=s(tD);qAo=r(Cat,"from_pretrained()"),Cat.forEach(t),NAo=r(BK," class method or the "),aD=n(BK,"A",{href:!0});var wat=s(aD);jAo=r(wat,"from_config()"),wat.forEach(t),DAo=r(BK,` class
method.`),BK.forEach(t),GAo=i(Xs),ZA=n(Xs,"P",{});var HNe=s(ZA);OAo=r(HNe,"This class cannot be instantiated directly using "),tce=n(HNe,"CODE",{});var Aat=s(tce);VAo=r(Aat,"__init__()"),Aat.forEach(t),XAo=r(HNe," (throws an error)."),HNe.forEach(t),zAo=i(Xs),nt=n(Xs,"DIV",{class:!0});var u3=s(nt);T(ey.$$.fragment,u3),QAo=i(u3),ace=n(u3,"P",{});var yat=s(ace);WAo=r(yat,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yat.forEach(t),HAo=i(u3),Ii=n(u3,"P",{});var PK=s(Ii);UAo=r(PK,`Note:
Loading a model from its configuration file does `),nce=n(PK,"STRONG",{});var Lat=s(nce);JAo=r(Lat,"not"),Lat.forEach(t),YAo=r(PK,` load the model weights. It only affects the
model\u2019s configuration. Use `),nD=n(PK,"A",{href:!0});var xat=s(nD);KAo=r(xat,"from_pretrained()"),xat.forEach(t),ZAo=r(PK," to load the model weights."),PK.forEach(t),eyo=i(u3),T(a1.$$.fragment,u3),u3.forEach(t),oyo=i(Xs),Ke=n(Xs,"DIV",{class:!0});var ta=s(Ke);T(oy.$$.fragment,ta),ryo=i(ta),sce=n(ta,"P",{});var $at=s(sce);tyo=r($at,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$at.forEach(t),ayo=i(ta),$a=n(ta,"P",{});var _3=s($a);nyo=r(_3,"The model class to instantiate is selected based on the "),lce=n(_3,"CODE",{});var kat=s(lce);syo=r(kat,"model_type"),kat.forEach(t),lyo=r(_3,` property of the config object (either
passed as an argument or loaded from `),ice=n(_3,"CODE",{});var Sat=s(ice);iyo=r(Sat,"pretrained_model_name_or_path"),Sat.forEach(t),dyo=r(_3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dce=n(_3,"CODE",{});var Rat=s(dce);cyo=r(Rat,"pretrained_model_name_or_path"),Rat.forEach(t),fyo=r(_3,":"),_3.forEach(t),myo=i(ta),he=n(ta,"UL",{});var _e=s(he);n1=n(_e,"LI",{});var pLe=s(n1);cce=n(pLe,"STRONG",{});var Bat=s(cce);gyo=r(Bat,"bart"),Bat.forEach(t),hyo=r(pLe," \u2014 "),sD=n(pLe,"A",{href:!0});var Pat=s(sD);pyo=r(Pat,"BartForConditionalGeneration"),Pat.forEach(t),uyo=r(pLe," (BART model)"),pLe.forEach(t),_yo=i(_e),s1=n(_e,"LI",{});var uLe=s(s1);fce=n(uLe,"STRONG",{});var Iat=s(fce);byo=r(Iat,"bigbird_pegasus"),Iat.forEach(t),vyo=r(uLe," \u2014 "),lD=n(uLe,"A",{href:!0});var qat=s(lD);Fyo=r(qat,"BigBirdPegasusForConditionalGeneration"),qat.forEach(t),Tyo=r(uLe," (BigBirdPegasus model)"),uLe.forEach(t),Myo=i(_e),l1=n(_e,"LI",{});var _Le=s(l1);mce=n(_Le,"STRONG",{});var Nat=s(mce);Eyo=r(Nat,"blenderbot"),Nat.forEach(t),Cyo=r(_Le," \u2014 "),iD=n(_Le,"A",{href:!0});var jat=s(iD);wyo=r(jat,"BlenderbotForConditionalGeneration"),jat.forEach(t),Ayo=r(_Le," (Blenderbot model)"),_Le.forEach(t),yyo=i(_e),i1=n(_e,"LI",{});var bLe=s(i1);gce=n(bLe,"STRONG",{});var Dat=s(gce);Lyo=r(Dat,"blenderbot-small"),Dat.forEach(t),xyo=r(bLe," \u2014 "),dD=n(bLe,"A",{href:!0});var Gat=s(dD);$yo=r(Gat,"BlenderbotSmallForConditionalGeneration"),Gat.forEach(t),kyo=r(bLe," (BlenderbotSmall model)"),bLe.forEach(t),Syo=i(_e),d1=n(_e,"LI",{});var vLe=s(d1);hce=n(vLe,"STRONG",{});var Oat=s(hce);Ryo=r(Oat,"encoder-decoder"),Oat.forEach(t),Byo=r(vLe," \u2014 "),cD=n(vLe,"A",{href:!0});var Vat=s(cD);Pyo=r(Vat,"EncoderDecoderModel"),Vat.forEach(t),Iyo=r(vLe," (Encoder decoder model)"),vLe.forEach(t),qyo=i(_e),c1=n(_e,"LI",{});var FLe=s(c1);pce=n(FLe,"STRONG",{});var Xat=s(pce);Nyo=r(Xat,"fsmt"),Xat.forEach(t),jyo=r(FLe," \u2014 "),fD=n(FLe,"A",{href:!0});var zat=s(fD);Dyo=r(zat,"FSMTForConditionalGeneration"),zat.forEach(t),Gyo=r(FLe," (FairSeq Machine-Translation model)"),FLe.forEach(t),Oyo=i(_e),f1=n(_e,"LI",{});var TLe=s(f1);uce=n(TLe,"STRONG",{});var Qat=s(uce);Vyo=r(Qat,"led"),Qat.forEach(t),Xyo=r(TLe," \u2014 "),mD=n(TLe,"A",{href:!0});var Wat=s(mD);zyo=r(Wat,"LEDForConditionalGeneration"),Wat.forEach(t),Qyo=r(TLe," (LED model)"),TLe.forEach(t),Wyo=i(_e),m1=n(_e,"LI",{});var MLe=s(m1);_ce=n(MLe,"STRONG",{});var Hat=s(_ce);Hyo=r(Hat,"m2m_100"),Hat.forEach(t),Uyo=r(MLe," \u2014 "),gD=n(MLe,"A",{href:!0});var Uat=s(gD);Jyo=r(Uat,"M2M100ForConditionalGeneration"),Uat.forEach(t),Yyo=r(MLe," (M2M100 model)"),MLe.forEach(t),Kyo=i(_e),g1=n(_e,"LI",{});var ELe=s(g1);bce=n(ELe,"STRONG",{});var Jat=s(bce);Zyo=r(Jat,"marian"),Jat.forEach(t),eLo=r(ELe," \u2014 "),hD=n(ELe,"A",{href:!0});var Yat=s(hD);oLo=r(Yat,"MarianMTModel"),Yat.forEach(t),rLo=r(ELe," (Marian model)"),ELe.forEach(t),tLo=i(_e),h1=n(_e,"LI",{});var CLe=s(h1);vce=n(CLe,"STRONG",{});var Kat=s(vce);aLo=r(Kat,"mbart"),Kat.forEach(t),nLo=r(CLe," \u2014 "),pD=n(CLe,"A",{href:!0});var Zat=s(pD);sLo=r(Zat,"MBartForConditionalGeneration"),Zat.forEach(t),lLo=r(CLe," (mBART model)"),CLe.forEach(t),iLo=i(_e),p1=n(_e,"LI",{});var wLe=s(p1);Fce=n(wLe,"STRONG",{});var ent=s(Fce);dLo=r(ent,"mt5"),ent.forEach(t),cLo=r(wLe," \u2014 "),uD=n(wLe,"A",{href:!0});var ont=s(uD);fLo=r(ont,"MT5ForConditionalGeneration"),ont.forEach(t),mLo=r(wLe," (mT5 model)"),wLe.forEach(t),gLo=i(_e),u1=n(_e,"LI",{});var ALe=s(u1);Tce=n(ALe,"STRONG",{});var rnt=s(Tce);hLo=r(rnt,"pegasus"),rnt.forEach(t),pLo=r(ALe," \u2014 "),_D=n(ALe,"A",{href:!0});var tnt=s(_D);uLo=r(tnt,"PegasusForConditionalGeneration"),tnt.forEach(t),_Lo=r(ALe," (Pegasus model)"),ALe.forEach(t),bLo=i(_e),_1=n(_e,"LI",{});var yLe=s(_1);Mce=n(yLe,"STRONG",{});var ant=s(Mce);vLo=r(ant,"plbart"),ant.forEach(t),FLo=r(yLe," \u2014 "),bD=n(yLe,"A",{href:!0});var nnt=s(bD);TLo=r(nnt,"PLBartForConditionalGeneration"),nnt.forEach(t),MLo=r(yLe," (PLBart model)"),yLe.forEach(t),ELo=i(_e),b1=n(_e,"LI",{});var LLe=s(b1);Ece=n(LLe,"STRONG",{});var snt=s(Ece);CLo=r(snt,"prophetnet"),snt.forEach(t),wLo=r(LLe," \u2014 "),vD=n(LLe,"A",{href:!0});var lnt=s(vD);ALo=r(lnt,"ProphetNetForConditionalGeneration"),lnt.forEach(t),yLo=r(LLe," (ProphetNet model)"),LLe.forEach(t),LLo=i(_e),v1=n(_e,"LI",{});var xLe=s(v1);Cce=n(xLe,"STRONG",{});var int=s(Cce);xLo=r(int,"t5"),int.forEach(t),$Lo=r(xLe," \u2014 "),FD=n(xLe,"A",{href:!0});var dnt=s(FD);kLo=r(dnt,"T5ForConditionalGeneration"),dnt.forEach(t),SLo=r(xLe," (T5 model)"),xLe.forEach(t),RLo=i(_e),F1=n(_e,"LI",{});var $Le=s(F1);wce=n($Le,"STRONG",{});var cnt=s(wce);BLo=r(cnt,"tapex"),cnt.forEach(t),PLo=r($Le," \u2014 "),TD=n($Le,"A",{href:!0});var fnt=s(TD);ILo=r(fnt,"BartForConditionalGeneration"),fnt.forEach(t),qLo=r($Le," (TAPEX model)"),$Le.forEach(t),NLo=i(_e),T1=n(_e,"LI",{});var kLe=s(T1);Ace=n(kLe,"STRONG",{});var mnt=s(Ace);jLo=r(mnt,"xlm-prophetnet"),mnt.forEach(t),DLo=r(kLe," \u2014 "),MD=n(kLe,"A",{href:!0});var gnt=s(MD);GLo=r(gnt,"XLMProphetNetForConditionalGeneration"),gnt.forEach(t),OLo=r(kLe," (XLMProphetNet model)"),kLe.forEach(t),_e.forEach(t),VLo=i(ta),M1=n(ta,"P",{});var SLe=s(M1);XLo=r(SLe,"The model is set in evaluation mode by default using "),yce=n(SLe,"CODE",{});var hnt=s(yce);zLo=r(hnt,"model.eval()"),hnt.forEach(t),QLo=r(SLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lce=n(SLe,"CODE",{});var pnt=s(Lce);WLo=r(pnt,"model.train()"),pnt.forEach(t),SLe.forEach(t),HLo=i(ta),T(E1.$$.fragment,ta),ta.forEach(t),Xs.forEach(t),zIe=i(f),qi=n(f,"H2",{class:!0});var UNe=s(qi);C1=n(UNe,"A",{id:!0,class:!0,href:!0});var unt=s(C1);xce=n(unt,"SPAN",{});var _nt=s(xce);T(ry.$$.fragment,_nt),_nt.forEach(t),unt.forEach(t),ULo=i(UNe),$ce=n(UNe,"SPAN",{});var bnt=s($ce);JLo=r(bnt,"AutoModelForSequenceClassification"),bnt.forEach(t),UNe.forEach(t),QIe=i(f),Ro=n(f,"DIV",{class:!0});var zs=s(Ro);T(ty.$$.fragment,zs),YLo=i(zs),Ni=n(zs,"P",{});var IK=s(Ni);KLo=r(IK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ED=n(IK,"A",{href:!0});var vnt=s(ED);ZLo=r(vnt,"from_pretrained()"),vnt.forEach(t),e8o=r(IK," class method or the "),CD=n(IK,"A",{href:!0});var Fnt=s(CD);o8o=r(Fnt,"from_config()"),Fnt.forEach(t),r8o=r(IK,` class
method.`),IK.forEach(t),t8o=i(zs),ay=n(zs,"P",{});var JNe=s(ay);a8o=r(JNe,"This class cannot be instantiated directly using "),kce=n(JNe,"CODE",{});var Tnt=s(kce);n8o=r(Tnt,"__init__()"),Tnt.forEach(t),s8o=r(JNe," (throws an error)."),JNe.forEach(t),l8o=i(zs),st=n(zs,"DIV",{class:!0});var b3=s(st);T(ny.$$.fragment,b3),i8o=i(b3),Sce=n(b3,"P",{});var Mnt=s(Sce);d8o=r(Mnt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Mnt.forEach(t),c8o=i(b3),ji=n(b3,"P",{});var qK=s(ji);f8o=r(qK,`Note:
Loading a model from its configuration file does `),Rce=n(qK,"STRONG",{});var Ent=s(Rce);m8o=r(Ent,"not"),Ent.forEach(t),g8o=r(qK,` load the model weights. It only affects the
model\u2019s configuration. Use `),wD=n(qK,"A",{href:!0});var Cnt=s(wD);h8o=r(Cnt,"from_pretrained()"),Cnt.forEach(t),p8o=r(qK," to load the model weights."),qK.forEach(t),u8o=i(b3),T(w1.$$.fragment,b3),b3.forEach(t),_8o=i(zs),Ze=n(zs,"DIV",{class:!0});var aa=s(Ze);T(sy.$$.fragment,aa),b8o=i(aa),Bce=n(aa,"P",{});var wnt=s(Bce);v8o=r(wnt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),wnt.forEach(t),F8o=i(aa),ka=n(aa,"P",{});var v3=s(ka);T8o=r(v3,"The model class to instantiate is selected based on the "),Pce=n(v3,"CODE",{});var Ant=s(Pce);M8o=r(Ant,"model_type"),Ant.forEach(t),E8o=r(v3,` property of the config object (either
passed as an argument or loaded from `),Ice=n(v3,"CODE",{});var ynt=s(Ice);C8o=r(ynt,"pretrained_model_name_or_path"),ynt.forEach(t),w8o=r(v3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qce=n(v3,"CODE",{});var Lnt=s(qce);A8o=r(Lnt,"pretrained_model_name_or_path"),Lnt.forEach(t),y8o=r(v3,":"),v3.forEach(t),L8o=i(aa),q=n(aa,"UL",{});var N=s(q);A1=n(N,"LI",{});var RLe=s(A1);Nce=n(RLe,"STRONG",{});var xnt=s(Nce);x8o=r(xnt,"albert"),xnt.forEach(t),$8o=r(RLe," \u2014 "),AD=n(RLe,"A",{href:!0});var $nt=s(AD);k8o=r($nt,"AlbertForSequenceClassification"),$nt.forEach(t),S8o=r(RLe," (ALBERT model)"),RLe.forEach(t),R8o=i(N),y1=n(N,"LI",{});var BLe=s(y1);jce=n(BLe,"STRONG",{});var knt=s(jce);B8o=r(knt,"bart"),knt.forEach(t),P8o=r(BLe," \u2014 "),yD=n(BLe,"A",{href:!0});var Snt=s(yD);I8o=r(Snt,"BartForSequenceClassification"),Snt.forEach(t),q8o=r(BLe," (BART model)"),BLe.forEach(t),N8o=i(N),L1=n(N,"LI",{});var PLe=s(L1);Dce=n(PLe,"STRONG",{});var Rnt=s(Dce);j8o=r(Rnt,"bert"),Rnt.forEach(t),D8o=r(PLe," \u2014 "),LD=n(PLe,"A",{href:!0});var Bnt=s(LD);G8o=r(Bnt,"BertForSequenceClassification"),Bnt.forEach(t),O8o=r(PLe," (BERT model)"),PLe.forEach(t),V8o=i(N),x1=n(N,"LI",{});var ILe=s(x1);Gce=n(ILe,"STRONG",{});var Pnt=s(Gce);X8o=r(Pnt,"big_bird"),Pnt.forEach(t),z8o=r(ILe," \u2014 "),xD=n(ILe,"A",{href:!0});var Int=s(xD);Q8o=r(Int,"BigBirdForSequenceClassification"),Int.forEach(t),W8o=r(ILe," (BigBird model)"),ILe.forEach(t),H8o=i(N),$1=n(N,"LI",{});var qLe=s($1);Oce=n(qLe,"STRONG",{});var qnt=s(Oce);U8o=r(qnt,"bigbird_pegasus"),qnt.forEach(t),J8o=r(qLe," \u2014 "),$D=n(qLe,"A",{href:!0});var Nnt=s($D);Y8o=r(Nnt,"BigBirdPegasusForSequenceClassification"),Nnt.forEach(t),K8o=r(qLe," (BigBirdPegasus model)"),qLe.forEach(t),Z8o=i(N),k1=n(N,"LI",{});var NLe=s(k1);Vce=n(NLe,"STRONG",{});var jnt=s(Vce);exo=r(jnt,"camembert"),jnt.forEach(t),oxo=r(NLe," \u2014 "),kD=n(NLe,"A",{href:!0});var Dnt=s(kD);rxo=r(Dnt,"CamembertForSequenceClassification"),Dnt.forEach(t),txo=r(NLe," (CamemBERT model)"),NLe.forEach(t),axo=i(N),S1=n(N,"LI",{});var jLe=s(S1);Xce=n(jLe,"STRONG",{});var Gnt=s(Xce);nxo=r(Gnt,"canine"),Gnt.forEach(t),sxo=r(jLe," \u2014 "),SD=n(jLe,"A",{href:!0});var Ont=s(SD);lxo=r(Ont,"CanineForSequenceClassification"),Ont.forEach(t),ixo=r(jLe," (Canine model)"),jLe.forEach(t),dxo=i(N),R1=n(N,"LI",{});var DLe=s(R1);zce=n(DLe,"STRONG",{});var Vnt=s(zce);cxo=r(Vnt,"convbert"),Vnt.forEach(t),fxo=r(DLe," \u2014 "),RD=n(DLe,"A",{href:!0});var Xnt=s(RD);mxo=r(Xnt,"ConvBertForSequenceClassification"),Xnt.forEach(t),gxo=r(DLe," (ConvBERT model)"),DLe.forEach(t),hxo=i(N),B1=n(N,"LI",{});var GLe=s(B1);Qce=n(GLe,"STRONG",{});var znt=s(Qce);pxo=r(znt,"ctrl"),znt.forEach(t),uxo=r(GLe," \u2014 "),BD=n(GLe,"A",{href:!0});var Qnt=s(BD);_xo=r(Qnt,"CTRLForSequenceClassification"),Qnt.forEach(t),bxo=r(GLe," (CTRL model)"),GLe.forEach(t),vxo=i(N),P1=n(N,"LI",{});var OLe=s(P1);Wce=n(OLe,"STRONG",{});var Wnt=s(Wce);Fxo=r(Wnt,"data2vec-text"),Wnt.forEach(t),Txo=r(OLe," \u2014 "),PD=n(OLe,"A",{href:!0});var Hnt=s(PD);Mxo=r(Hnt,"Data2VecTextForSequenceClassification"),Hnt.forEach(t),Exo=r(OLe," (Data2VecText model)"),OLe.forEach(t),Cxo=i(N),I1=n(N,"LI",{});var VLe=s(I1);Hce=n(VLe,"STRONG",{});var Unt=s(Hce);wxo=r(Unt,"deberta"),Unt.forEach(t),Axo=r(VLe," \u2014 "),ID=n(VLe,"A",{href:!0});var Jnt=s(ID);yxo=r(Jnt,"DebertaForSequenceClassification"),Jnt.forEach(t),Lxo=r(VLe," (DeBERTa model)"),VLe.forEach(t),xxo=i(N),q1=n(N,"LI",{});var XLe=s(q1);Uce=n(XLe,"STRONG",{});var Ynt=s(Uce);$xo=r(Ynt,"deberta-v2"),Ynt.forEach(t),kxo=r(XLe," \u2014 "),qD=n(XLe,"A",{href:!0});var Knt=s(qD);Sxo=r(Knt,"DebertaV2ForSequenceClassification"),Knt.forEach(t),Rxo=r(XLe," (DeBERTa-v2 model)"),XLe.forEach(t),Bxo=i(N),N1=n(N,"LI",{});var zLe=s(N1);Jce=n(zLe,"STRONG",{});var Znt=s(Jce);Pxo=r(Znt,"distilbert"),Znt.forEach(t),Ixo=r(zLe," \u2014 "),ND=n(zLe,"A",{href:!0});var est=s(ND);qxo=r(est,"DistilBertForSequenceClassification"),est.forEach(t),Nxo=r(zLe," (DistilBERT model)"),zLe.forEach(t),jxo=i(N),j1=n(N,"LI",{});var QLe=s(j1);Yce=n(QLe,"STRONG",{});var ost=s(Yce);Dxo=r(ost,"electra"),ost.forEach(t),Gxo=r(QLe," \u2014 "),jD=n(QLe,"A",{href:!0});var rst=s(jD);Oxo=r(rst,"ElectraForSequenceClassification"),rst.forEach(t),Vxo=r(QLe," (ELECTRA model)"),QLe.forEach(t),Xxo=i(N),D1=n(N,"LI",{});var WLe=s(D1);Kce=n(WLe,"STRONG",{});var tst=s(Kce);zxo=r(tst,"flaubert"),tst.forEach(t),Qxo=r(WLe," \u2014 "),DD=n(WLe,"A",{href:!0});var ast=s(DD);Wxo=r(ast,"FlaubertForSequenceClassification"),ast.forEach(t),Hxo=r(WLe," (FlauBERT model)"),WLe.forEach(t),Uxo=i(N),G1=n(N,"LI",{});var HLe=s(G1);Zce=n(HLe,"STRONG",{});var nst=s(Zce);Jxo=r(nst,"fnet"),nst.forEach(t),Yxo=r(HLe," \u2014 "),GD=n(HLe,"A",{href:!0});var sst=s(GD);Kxo=r(sst,"FNetForSequenceClassification"),sst.forEach(t),Zxo=r(HLe," (FNet model)"),HLe.forEach(t),e9o=i(N),O1=n(N,"LI",{});var ULe=s(O1);efe=n(ULe,"STRONG",{});var lst=s(efe);o9o=r(lst,"funnel"),lst.forEach(t),r9o=r(ULe," \u2014 "),OD=n(ULe,"A",{href:!0});var ist=s(OD);t9o=r(ist,"FunnelForSequenceClassification"),ist.forEach(t),a9o=r(ULe," (Funnel Transformer model)"),ULe.forEach(t),n9o=i(N),V1=n(N,"LI",{});var JLe=s(V1);ofe=n(JLe,"STRONG",{});var dst=s(ofe);s9o=r(dst,"gpt2"),dst.forEach(t),l9o=r(JLe," \u2014 "),VD=n(JLe,"A",{href:!0});var cst=s(VD);i9o=r(cst,"GPT2ForSequenceClassification"),cst.forEach(t),d9o=r(JLe," (OpenAI GPT-2 model)"),JLe.forEach(t),c9o=i(N),X1=n(N,"LI",{});var YLe=s(X1);rfe=n(YLe,"STRONG",{});var fst=s(rfe);f9o=r(fst,"gpt_neo"),fst.forEach(t),m9o=r(YLe," \u2014 "),XD=n(YLe,"A",{href:!0});var mst=s(XD);g9o=r(mst,"GPTNeoForSequenceClassification"),mst.forEach(t),h9o=r(YLe," (GPT Neo model)"),YLe.forEach(t),p9o=i(N),z1=n(N,"LI",{});var KLe=s(z1);tfe=n(KLe,"STRONG",{});var gst=s(tfe);u9o=r(gst,"gptj"),gst.forEach(t),_9o=r(KLe," \u2014 "),zD=n(KLe,"A",{href:!0});var hst=s(zD);b9o=r(hst,"GPTJForSequenceClassification"),hst.forEach(t),v9o=r(KLe," (GPT-J model)"),KLe.forEach(t),F9o=i(N),Q1=n(N,"LI",{});var ZLe=s(Q1);afe=n(ZLe,"STRONG",{});var pst=s(afe);T9o=r(pst,"ibert"),pst.forEach(t),M9o=r(ZLe," \u2014 "),QD=n(ZLe,"A",{href:!0});var ust=s(QD);E9o=r(ust,"IBertForSequenceClassification"),ust.forEach(t),C9o=r(ZLe," (I-BERT model)"),ZLe.forEach(t),w9o=i(N),W1=n(N,"LI",{});var e8e=s(W1);nfe=n(e8e,"STRONG",{});var _st=s(nfe);A9o=r(_st,"layoutlm"),_st.forEach(t),y9o=r(e8e," \u2014 "),WD=n(e8e,"A",{href:!0});var bst=s(WD);L9o=r(bst,"LayoutLMForSequenceClassification"),bst.forEach(t),x9o=r(e8e," (LayoutLM model)"),e8e.forEach(t),$9o=i(N),H1=n(N,"LI",{});var o8e=s(H1);sfe=n(o8e,"STRONG",{});var vst=s(sfe);k9o=r(vst,"layoutlmv2"),vst.forEach(t),S9o=r(o8e," \u2014 "),HD=n(o8e,"A",{href:!0});var Fst=s(HD);R9o=r(Fst,"LayoutLMv2ForSequenceClassification"),Fst.forEach(t),B9o=r(o8e," (LayoutLMv2 model)"),o8e.forEach(t),P9o=i(N),U1=n(N,"LI",{});var r8e=s(U1);lfe=n(r8e,"STRONG",{});var Tst=s(lfe);I9o=r(Tst,"layoutlmv3"),Tst.forEach(t),q9o=r(r8e," \u2014 "),UD=n(r8e,"A",{href:!0});var Mst=s(UD);N9o=r(Mst,"LayoutLMv3ForSequenceClassification"),Mst.forEach(t),j9o=r(r8e," (LayoutLMv3 model)"),r8e.forEach(t),D9o=i(N),J1=n(N,"LI",{});var t8e=s(J1);ife=n(t8e,"STRONG",{});var Est=s(ife);G9o=r(Est,"led"),Est.forEach(t),O9o=r(t8e," \u2014 "),JD=n(t8e,"A",{href:!0});var Cst=s(JD);V9o=r(Cst,"LEDForSequenceClassification"),Cst.forEach(t),X9o=r(t8e," (LED model)"),t8e.forEach(t),z9o=i(N),Y1=n(N,"LI",{});var a8e=s(Y1);dfe=n(a8e,"STRONG",{});var wst=s(dfe);Q9o=r(wst,"longformer"),wst.forEach(t),W9o=r(a8e," \u2014 "),YD=n(a8e,"A",{href:!0});var Ast=s(YD);H9o=r(Ast,"LongformerForSequenceClassification"),Ast.forEach(t),U9o=r(a8e," (Longformer model)"),a8e.forEach(t),J9o=i(N),K1=n(N,"LI",{});var n8e=s(K1);cfe=n(n8e,"STRONG",{});var yst=s(cfe);Y9o=r(yst,"mbart"),yst.forEach(t),K9o=r(n8e," \u2014 "),KD=n(n8e,"A",{href:!0});var Lst=s(KD);Z9o=r(Lst,"MBartForSequenceClassification"),Lst.forEach(t),e$o=r(n8e," (mBART model)"),n8e.forEach(t),o$o=i(N),Z1=n(N,"LI",{});var s8e=s(Z1);ffe=n(s8e,"STRONG",{});var xst=s(ffe);r$o=r(xst,"megatron-bert"),xst.forEach(t),t$o=r(s8e," \u2014 "),ZD=n(s8e,"A",{href:!0});var $st=s(ZD);a$o=r($st,"MegatronBertForSequenceClassification"),$st.forEach(t),n$o=r(s8e," (MegatronBert model)"),s8e.forEach(t),s$o=i(N),eb=n(N,"LI",{});var l8e=s(eb);mfe=n(l8e,"STRONG",{});var kst=s(mfe);l$o=r(kst,"mobilebert"),kst.forEach(t),i$o=r(l8e," \u2014 "),eG=n(l8e,"A",{href:!0});var Sst=s(eG);d$o=r(Sst,"MobileBertForSequenceClassification"),Sst.forEach(t),c$o=r(l8e," (MobileBERT model)"),l8e.forEach(t),f$o=i(N),ob=n(N,"LI",{});var i8e=s(ob);gfe=n(i8e,"STRONG",{});var Rst=s(gfe);m$o=r(Rst,"mpnet"),Rst.forEach(t),g$o=r(i8e," \u2014 "),oG=n(i8e,"A",{href:!0});var Bst=s(oG);h$o=r(Bst,"MPNetForSequenceClassification"),Bst.forEach(t),p$o=r(i8e," (MPNet model)"),i8e.forEach(t),u$o=i(N),rb=n(N,"LI",{});var d8e=s(rb);hfe=n(d8e,"STRONG",{});var Pst=s(hfe);_$o=r(Pst,"nystromformer"),Pst.forEach(t),b$o=r(d8e," \u2014 "),rG=n(d8e,"A",{href:!0});var Ist=s(rG);v$o=r(Ist,"NystromformerForSequenceClassification"),Ist.forEach(t),F$o=r(d8e," (Nystromformer model)"),d8e.forEach(t),T$o=i(N),tb=n(N,"LI",{});var c8e=s(tb);pfe=n(c8e,"STRONG",{});var qst=s(pfe);M$o=r(qst,"openai-gpt"),qst.forEach(t),E$o=r(c8e," \u2014 "),tG=n(c8e,"A",{href:!0});var Nst=s(tG);C$o=r(Nst,"OpenAIGPTForSequenceClassification"),Nst.forEach(t),w$o=r(c8e," (OpenAI GPT model)"),c8e.forEach(t),A$o=i(N),ab=n(N,"LI",{});var f8e=s(ab);ufe=n(f8e,"STRONG",{});var jst=s(ufe);y$o=r(jst,"perceiver"),jst.forEach(t),L$o=r(f8e," \u2014 "),aG=n(f8e,"A",{href:!0});var Dst=s(aG);x$o=r(Dst,"PerceiverForSequenceClassification"),Dst.forEach(t),$$o=r(f8e," (Perceiver model)"),f8e.forEach(t),k$o=i(N),nb=n(N,"LI",{});var m8e=s(nb);_fe=n(m8e,"STRONG",{});var Gst=s(_fe);S$o=r(Gst,"plbart"),Gst.forEach(t),R$o=r(m8e," \u2014 "),nG=n(m8e,"A",{href:!0});var Ost=s(nG);B$o=r(Ost,"PLBartForSequenceClassification"),Ost.forEach(t),P$o=r(m8e," (PLBart model)"),m8e.forEach(t),I$o=i(N),sb=n(N,"LI",{});var g8e=s(sb);bfe=n(g8e,"STRONG",{});var Vst=s(bfe);q$o=r(Vst,"qdqbert"),Vst.forEach(t),N$o=r(g8e," \u2014 "),sG=n(g8e,"A",{href:!0});var Xst=s(sG);j$o=r(Xst,"QDQBertForSequenceClassification"),Xst.forEach(t),D$o=r(g8e," (QDQBert model)"),g8e.forEach(t),G$o=i(N),lb=n(N,"LI",{});var h8e=s(lb);vfe=n(h8e,"STRONG",{});var zst=s(vfe);O$o=r(zst,"reformer"),zst.forEach(t),V$o=r(h8e," \u2014 "),lG=n(h8e,"A",{href:!0});var Qst=s(lG);X$o=r(Qst,"ReformerForSequenceClassification"),Qst.forEach(t),z$o=r(h8e," (Reformer model)"),h8e.forEach(t),Q$o=i(N),ib=n(N,"LI",{});var p8e=s(ib);Ffe=n(p8e,"STRONG",{});var Wst=s(Ffe);W$o=r(Wst,"rembert"),Wst.forEach(t),H$o=r(p8e," \u2014 "),iG=n(p8e,"A",{href:!0});var Hst=s(iG);U$o=r(Hst,"RemBertForSequenceClassification"),Hst.forEach(t),J$o=r(p8e," (RemBERT model)"),p8e.forEach(t),Y$o=i(N),db=n(N,"LI",{});var u8e=s(db);Tfe=n(u8e,"STRONG",{});var Ust=s(Tfe);K$o=r(Ust,"roberta"),Ust.forEach(t),Z$o=r(u8e," \u2014 "),dG=n(u8e,"A",{href:!0});var Jst=s(dG);eko=r(Jst,"RobertaForSequenceClassification"),Jst.forEach(t),oko=r(u8e," (RoBERTa model)"),u8e.forEach(t),rko=i(N),cb=n(N,"LI",{});var _8e=s(cb);Mfe=n(_8e,"STRONG",{});var Yst=s(Mfe);tko=r(Yst,"roformer"),Yst.forEach(t),ako=r(_8e," \u2014 "),cG=n(_8e,"A",{href:!0});var Kst=s(cG);nko=r(Kst,"RoFormerForSequenceClassification"),Kst.forEach(t),sko=r(_8e," (RoFormer model)"),_8e.forEach(t),lko=i(N),fb=n(N,"LI",{});var b8e=s(fb);Efe=n(b8e,"STRONG",{});var Zst=s(Efe);iko=r(Zst,"squeezebert"),Zst.forEach(t),dko=r(b8e," \u2014 "),fG=n(b8e,"A",{href:!0});var elt=s(fG);cko=r(elt,"SqueezeBertForSequenceClassification"),elt.forEach(t),fko=r(b8e," (SqueezeBERT model)"),b8e.forEach(t),mko=i(N),mb=n(N,"LI",{});var v8e=s(mb);Cfe=n(v8e,"STRONG",{});var olt=s(Cfe);gko=r(olt,"tapas"),olt.forEach(t),hko=r(v8e," \u2014 "),mG=n(v8e,"A",{href:!0});var rlt=s(mG);pko=r(rlt,"TapasForSequenceClassification"),rlt.forEach(t),uko=r(v8e," (TAPAS model)"),v8e.forEach(t),_ko=i(N),gb=n(N,"LI",{});var F8e=s(gb);wfe=n(F8e,"STRONG",{});var tlt=s(wfe);bko=r(tlt,"tapex"),tlt.forEach(t),vko=r(F8e," \u2014 "),gG=n(F8e,"A",{href:!0});var alt=s(gG);Fko=r(alt,"BartForSequenceClassification"),alt.forEach(t),Tko=r(F8e," (TAPEX model)"),F8e.forEach(t),Mko=i(N),hb=n(N,"LI",{});var T8e=s(hb);Afe=n(T8e,"STRONG",{});var nlt=s(Afe);Eko=r(nlt,"transfo-xl"),nlt.forEach(t),Cko=r(T8e," \u2014 "),hG=n(T8e,"A",{href:!0});var slt=s(hG);wko=r(slt,"TransfoXLForSequenceClassification"),slt.forEach(t),Ako=r(T8e," (Transformer-XL model)"),T8e.forEach(t),yko=i(N),pb=n(N,"LI",{});var M8e=s(pb);yfe=n(M8e,"STRONG",{});var llt=s(yfe);Lko=r(llt,"xlm"),llt.forEach(t),xko=r(M8e," \u2014 "),pG=n(M8e,"A",{href:!0});var ilt=s(pG);$ko=r(ilt,"XLMForSequenceClassification"),ilt.forEach(t),kko=r(M8e," (XLM model)"),M8e.forEach(t),Sko=i(N),ub=n(N,"LI",{});var E8e=s(ub);Lfe=n(E8e,"STRONG",{});var dlt=s(Lfe);Rko=r(dlt,"xlm-roberta"),dlt.forEach(t),Bko=r(E8e," \u2014 "),uG=n(E8e,"A",{href:!0});var clt=s(uG);Pko=r(clt,"XLMRobertaForSequenceClassification"),clt.forEach(t),Iko=r(E8e," (XLM-RoBERTa model)"),E8e.forEach(t),qko=i(N),_b=n(N,"LI",{});var C8e=s(_b);xfe=n(C8e,"STRONG",{});var flt=s(xfe);Nko=r(flt,"xlm-roberta-xl"),flt.forEach(t),jko=r(C8e," \u2014 "),_G=n(C8e,"A",{href:!0});var mlt=s(_G);Dko=r(mlt,"XLMRobertaXLForSequenceClassification"),mlt.forEach(t),Gko=r(C8e," (XLM-RoBERTa-XL model)"),C8e.forEach(t),Oko=i(N),bb=n(N,"LI",{});var w8e=s(bb);$fe=n(w8e,"STRONG",{});var glt=s($fe);Vko=r(glt,"xlnet"),glt.forEach(t),Xko=r(w8e," \u2014 "),bG=n(w8e,"A",{href:!0});var hlt=s(bG);zko=r(hlt,"XLNetForSequenceClassification"),hlt.forEach(t),Qko=r(w8e," (XLNet model)"),w8e.forEach(t),Wko=i(N),vb=n(N,"LI",{});var A8e=s(vb);kfe=n(A8e,"STRONG",{});var plt=s(kfe);Hko=r(plt,"yoso"),plt.forEach(t),Uko=r(A8e," \u2014 "),vG=n(A8e,"A",{href:!0});var ult=s(vG);Jko=r(ult,"YosoForSequenceClassification"),ult.forEach(t),Yko=r(A8e," (YOSO model)"),A8e.forEach(t),N.forEach(t),Kko=i(aa),Fb=n(aa,"P",{});var y8e=s(Fb);Zko=r(y8e,"The model is set in evaluation mode by default using "),Sfe=n(y8e,"CODE",{});var _lt=s(Sfe);eSo=r(_lt,"model.eval()"),_lt.forEach(t),oSo=r(y8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rfe=n(y8e,"CODE",{});var blt=s(Rfe);rSo=r(blt,"model.train()"),blt.forEach(t),y8e.forEach(t),tSo=i(aa),T(Tb.$$.fragment,aa),aa.forEach(t),zs.forEach(t),WIe=i(f),Di=n(f,"H2",{class:!0});var YNe=s(Di);Mb=n(YNe,"A",{id:!0,class:!0,href:!0});var vlt=s(Mb);Bfe=n(vlt,"SPAN",{});var Flt=s(Bfe);T(ly.$$.fragment,Flt),Flt.forEach(t),vlt.forEach(t),aSo=i(YNe),Pfe=n(YNe,"SPAN",{});var Tlt=s(Pfe);nSo=r(Tlt,"AutoModelForMultipleChoice"),Tlt.forEach(t),YNe.forEach(t),HIe=i(f),Bo=n(f,"DIV",{class:!0});var Qs=s(Bo);T(iy.$$.fragment,Qs),sSo=i(Qs),Gi=n(Qs,"P",{});var NK=s(Gi);lSo=r(NK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FG=n(NK,"A",{href:!0});var Mlt=s(FG);iSo=r(Mlt,"from_pretrained()"),Mlt.forEach(t),dSo=r(NK," class method or the "),TG=n(NK,"A",{href:!0});var Elt=s(TG);cSo=r(Elt,"from_config()"),Elt.forEach(t),fSo=r(NK,` class
method.`),NK.forEach(t),mSo=i(Qs),dy=n(Qs,"P",{});var KNe=s(dy);gSo=r(KNe,"This class cannot be instantiated directly using "),Ife=n(KNe,"CODE",{});var Clt=s(Ife);hSo=r(Clt,"__init__()"),Clt.forEach(t),pSo=r(KNe," (throws an error)."),KNe.forEach(t),uSo=i(Qs),lt=n(Qs,"DIV",{class:!0});var F3=s(lt);T(cy.$$.fragment,F3),_So=i(F3),qfe=n(F3,"P",{});var wlt=s(qfe);bSo=r(wlt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wlt.forEach(t),vSo=i(F3),Oi=n(F3,"P",{});var jK=s(Oi);FSo=r(jK,`Note:
Loading a model from its configuration file does `),Nfe=n(jK,"STRONG",{});var Alt=s(Nfe);TSo=r(Alt,"not"),Alt.forEach(t),MSo=r(jK,` load the model weights. It only affects the
model\u2019s configuration. Use `),MG=n(jK,"A",{href:!0});var ylt=s(MG);ESo=r(ylt,"from_pretrained()"),ylt.forEach(t),CSo=r(jK," to load the model weights."),jK.forEach(t),wSo=i(F3),T(Eb.$$.fragment,F3),F3.forEach(t),ASo=i(Qs),eo=n(Qs,"DIV",{class:!0});var na=s(eo);T(fy.$$.fragment,na),ySo=i(na),jfe=n(na,"P",{});var Llt=s(jfe);LSo=r(Llt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Llt.forEach(t),xSo=i(na),Sa=n(na,"P",{});var T3=s(Sa);$So=r(T3,"The model class to instantiate is selected based on the "),Dfe=n(T3,"CODE",{});var xlt=s(Dfe);kSo=r(xlt,"model_type"),xlt.forEach(t),SSo=r(T3,` property of the config object (either
passed as an argument or loaded from `),Gfe=n(T3,"CODE",{});var $lt=s(Gfe);RSo=r($lt,"pretrained_model_name_or_path"),$lt.forEach(t),BSo=r(T3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ofe=n(T3,"CODE",{});var klt=s(Ofe);PSo=r(klt,"pretrained_model_name_or_path"),klt.forEach(t),ISo=r(T3,":"),T3.forEach(t),qSo=i(na),Y=n(na,"UL",{});var K=s(Y);Cb=n(K,"LI",{});var L8e=s(Cb);Vfe=n(L8e,"STRONG",{});var Slt=s(Vfe);NSo=r(Slt,"albert"),Slt.forEach(t),jSo=r(L8e," \u2014 "),EG=n(L8e,"A",{href:!0});var Rlt=s(EG);DSo=r(Rlt,"AlbertForMultipleChoice"),Rlt.forEach(t),GSo=r(L8e," (ALBERT model)"),L8e.forEach(t),OSo=i(K),wb=n(K,"LI",{});var x8e=s(wb);Xfe=n(x8e,"STRONG",{});var Blt=s(Xfe);VSo=r(Blt,"bert"),Blt.forEach(t),XSo=r(x8e," \u2014 "),CG=n(x8e,"A",{href:!0});var Plt=s(CG);zSo=r(Plt,"BertForMultipleChoice"),Plt.forEach(t),QSo=r(x8e," (BERT model)"),x8e.forEach(t),WSo=i(K),Ab=n(K,"LI",{});var $8e=s(Ab);zfe=n($8e,"STRONG",{});var Ilt=s(zfe);HSo=r(Ilt,"big_bird"),Ilt.forEach(t),USo=r($8e," \u2014 "),wG=n($8e,"A",{href:!0});var qlt=s(wG);JSo=r(qlt,"BigBirdForMultipleChoice"),qlt.forEach(t),YSo=r($8e," (BigBird model)"),$8e.forEach(t),KSo=i(K),yb=n(K,"LI",{});var k8e=s(yb);Qfe=n(k8e,"STRONG",{});var Nlt=s(Qfe);ZSo=r(Nlt,"camembert"),Nlt.forEach(t),eRo=r(k8e," \u2014 "),AG=n(k8e,"A",{href:!0});var jlt=s(AG);oRo=r(jlt,"CamembertForMultipleChoice"),jlt.forEach(t),rRo=r(k8e," (CamemBERT model)"),k8e.forEach(t),tRo=i(K),Lb=n(K,"LI",{});var S8e=s(Lb);Wfe=n(S8e,"STRONG",{});var Dlt=s(Wfe);aRo=r(Dlt,"canine"),Dlt.forEach(t),nRo=r(S8e," \u2014 "),yG=n(S8e,"A",{href:!0});var Glt=s(yG);sRo=r(Glt,"CanineForMultipleChoice"),Glt.forEach(t),lRo=r(S8e," (Canine model)"),S8e.forEach(t),iRo=i(K),xb=n(K,"LI",{});var R8e=s(xb);Hfe=n(R8e,"STRONG",{});var Olt=s(Hfe);dRo=r(Olt,"convbert"),Olt.forEach(t),cRo=r(R8e," \u2014 "),LG=n(R8e,"A",{href:!0});var Vlt=s(LG);fRo=r(Vlt,"ConvBertForMultipleChoice"),Vlt.forEach(t),mRo=r(R8e," (ConvBERT model)"),R8e.forEach(t),gRo=i(K),$b=n(K,"LI",{});var B8e=s($b);Ufe=n(B8e,"STRONG",{});var Xlt=s(Ufe);hRo=r(Xlt,"data2vec-text"),Xlt.forEach(t),pRo=r(B8e," \u2014 "),xG=n(B8e,"A",{href:!0});var zlt=s(xG);uRo=r(zlt,"Data2VecTextForMultipleChoice"),zlt.forEach(t),_Ro=r(B8e," (Data2VecText model)"),B8e.forEach(t),bRo=i(K),kb=n(K,"LI",{});var P8e=s(kb);Jfe=n(P8e,"STRONG",{});var Qlt=s(Jfe);vRo=r(Qlt,"deberta-v2"),Qlt.forEach(t),FRo=r(P8e," \u2014 "),$G=n(P8e,"A",{href:!0});var Wlt=s($G);TRo=r(Wlt,"DebertaV2ForMultipleChoice"),Wlt.forEach(t),MRo=r(P8e," (DeBERTa-v2 model)"),P8e.forEach(t),ERo=i(K),Sb=n(K,"LI",{});var I8e=s(Sb);Yfe=n(I8e,"STRONG",{});var Hlt=s(Yfe);CRo=r(Hlt,"distilbert"),Hlt.forEach(t),wRo=r(I8e," \u2014 "),kG=n(I8e,"A",{href:!0});var Ult=s(kG);ARo=r(Ult,"DistilBertForMultipleChoice"),Ult.forEach(t),yRo=r(I8e," (DistilBERT model)"),I8e.forEach(t),LRo=i(K),Rb=n(K,"LI",{});var q8e=s(Rb);Kfe=n(q8e,"STRONG",{});var Jlt=s(Kfe);xRo=r(Jlt,"electra"),Jlt.forEach(t),$Ro=r(q8e," \u2014 "),SG=n(q8e,"A",{href:!0});var Ylt=s(SG);kRo=r(Ylt,"ElectraForMultipleChoice"),Ylt.forEach(t),SRo=r(q8e," (ELECTRA model)"),q8e.forEach(t),RRo=i(K),Bb=n(K,"LI",{});var N8e=s(Bb);Zfe=n(N8e,"STRONG",{});var Klt=s(Zfe);BRo=r(Klt,"flaubert"),Klt.forEach(t),PRo=r(N8e," \u2014 "),RG=n(N8e,"A",{href:!0});var Zlt=s(RG);IRo=r(Zlt,"FlaubertForMultipleChoice"),Zlt.forEach(t),qRo=r(N8e," (FlauBERT model)"),N8e.forEach(t),NRo=i(K),Pb=n(K,"LI",{});var j8e=s(Pb);eme=n(j8e,"STRONG",{});var eit=s(eme);jRo=r(eit,"fnet"),eit.forEach(t),DRo=r(j8e," \u2014 "),BG=n(j8e,"A",{href:!0});var oit=s(BG);GRo=r(oit,"FNetForMultipleChoice"),oit.forEach(t),ORo=r(j8e," (FNet model)"),j8e.forEach(t),VRo=i(K),Ib=n(K,"LI",{});var D8e=s(Ib);ome=n(D8e,"STRONG",{});var rit=s(ome);XRo=r(rit,"funnel"),rit.forEach(t),zRo=r(D8e," \u2014 "),PG=n(D8e,"A",{href:!0});var tit=s(PG);QRo=r(tit,"FunnelForMultipleChoice"),tit.forEach(t),WRo=r(D8e," (Funnel Transformer model)"),D8e.forEach(t),HRo=i(K),qb=n(K,"LI",{});var G8e=s(qb);rme=n(G8e,"STRONG",{});var ait=s(rme);URo=r(ait,"ibert"),ait.forEach(t),JRo=r(G8e," \u2014 "),IG=n(G8e,"A",{href:!0});var nit=s(IG);YRo=r(nit,"IBertForMultipleChoice"),nit.forEach(t),KRo=r(G8e," (I-BERT model)"),G8e.forEach(t),ZRo=i(K),Nb=n(K,"LI",{});var O8e=s(Nb);tme=n(O8e,"STRONG",{});var sit=s(tme);eBo=r(sit,"longformer"),sit.forEach(t),oBo=r(O8e," \u2014 "),qG=n(O8e,"A",{href:!0});var lit=s(qG);rBo=r(lit,"LongformerForMultipleChoice"),lit.forEach(t),tBo=r(O8e," (Longformer model)"),O8e.forEach(t),aBo=i(K),jb=n(K,"LI",{});var V8e=s(jb);ame=n(V8e,"STRONG",{});var iit=s(ame);nBo=r(iit,"megatron-bert"),iit.forEach(t),sBo=r(V8e," \u2014 "),NG=n(V8e,"A",{href:!0});var dit=s(NG);lBo=r(dit,"MegatronBertForMultipleChoice"),dit.forEach(t),iBo=r(V8e," (MegatronBert model)"),V8e.forEach(t),dBo=i(K),Db=n(K,"LI",{});var X8e=s(Db);nme=n(X8e,"STRONG",{});var cit=s(nme);cBo=r(cit,"mobilebert"),cit.forEach(t),fBo=r(X8e," \u2014 "),jG=n(X8e,"A",{href:!0});var fit=s(jG);mBo=r(fit,"MobileBertForMultipleChoice"),fit.forEach(t),gBo=r(X8e," (MobileBERT model)"),X8e.forEach(t),hBo=i(K),Gb=n(K,"LI",{});var z8e=s(Gb);sme=n(z8e,"STRONG",{});var mit=s(sme);pBo=r(mit,"mpnet"),mit.forEach(t),uBo=r(z8e," \u2014 "),DG=n(z8e,"A",{href:!0});var git=s(DG);_Bo=r(git,"MPNetForMultipleChoice"),git.forEach(t),bBo=r(z8e," (MPNet model)"),z8e.forEach(t),vBo=i(K),Ob=n(K,"LI",{});var Q8e=s(Ob);lme=n(Q8e,"STRONG",{});var hit=s(lme);FBo=r(hit,"nystromformer"),hit.forEach(t),TBo=r(Q8e," \u2014 "),GG=n(Q8e,"A",{href:!0});var pit=s(GG);MBo=r(pit,"NystromformerForMultipleChoice"),pit.forEach(t),EBo=r(Q8e," (Nystromformer model)"),Q8e.forEach(t),CBo=i(K),Vb=n(K,"LI",{});var W8e=s(Vb);ime=n(W8e,"STRONG",{});var uit=s(ime);wBo=r(uit,"qdqbert"),uit.forEach(t),ABo=r(W8e," \u2014 "),OG=n(W8e,"A",{href:!0});var _it=s(OG);yBo=r(_it,"QDQBertForMultipleChoice"),_it.forEach(t),LBo=r(W8e," (QDQBert model)"),W8e.forEach(t),xBo=i(K),Xb=n(K,"LI",{});var H8e=s(Xb);dme=n(H8e,"STRONG",{});var bit=s(dme);$Bo=r(bit,"rembert"),bit.forEach(t),kBo=r(H8e," \u2014 "),VG=n(H8e,"A",{href:!0});var vit=s(VG);SBo=r(vit,"RemBertForMultipleChoice"),vit.forEach(t),RBo=r(H8e," (RemBERT model)"),H8e.forEach(t),BBo=i(K),zb=n(K,"LI",{});var U8e=s(zb);cme=n(U8e,"STRONG",{});var Fit=s(cme);PBo=r(Fit,"roberta"),Fit.forEach(t),IBo=r(U8e," \u2014 "),XG=n(U8e,"A",{href:!0});var Tit=s(XG);qBo=r(Tit,"RobertaForMultipleChoice"),Tit.forEach(t),NBo=r(U8e," (RoBERTa model)"),U8e.forEach(t),jBo=i(K),Qb=n(K,"LI",{});var J8e=s(Qb);fme=n(J8e,"STRONG",{});var Mit=s(fme);DBo=r(Mit,"roformer"),Mit.forEach(t),GBo=r(J8e," \u2014 "),zG=n(J8e,"A",{href:!0});var Eit=s(zG);OBo=r(Eit,"RoFormerForMultipleChoice"),Eit.forEach(t),VBo=r(J8e," (RoFormer model)"),J8e.forEach(t),XBo=i(K),Wb=n(K,"LI",{});var Y8e=s(Wb);mme=n(Y8e,"STRONG",{});var Cit=s(mme);zBo=r(Cit,"squeezebert"),Cit.forEach(t),QBo=r(Y8e," \u2014 "),QG=n(Y8e,"A",{href:!0});var wit=s(QG);WBo=r(wit,"SqueezeBertForMultipleChoice"),wit.forEach(t),HBo=r(Y8e," (SqueezeBERT model)"),Y8e.forEach(t),UBo=i(K),Hb=n(K,"LI",{});var K8e=s(Hb);gme=n(K8e,"STRONG",{});var Ait=s(gme);JBo=r(Ait,"xlm"),Ait.forEach(t),YBo=r(K8e," \u2014 "),WG=n(K8e,"A",{href:!0});var yit=s(WG);KBo=r(yit,"XLMForMultipleChoice"),yit.forEach(t),ZBo=r(K8e," (XLM model)"),K8e.forEach(t),ePo=i(K),Ub=n(K,"LI",{});var Z8e=s(Ub);hme=n(Z8e,"STRONG",{});var Lit=s(hme);oPo=r(Lit,"xlm-roberta"),Lit.forEach(t),rPo=r(Z8e," \u2014 "),HG=n(Z8e,"A",{href:!0});var xit=s(HG);tPo=r(xit,"XLMRobertaForMultipleChoice"),xit.forEach(t),aPo=r(Z8e," (XLM-RoBERTa model)"),Z8e.forEach(t),nPo=i(K),Jb=n(K,"LI",{});var exe=s(Jb);pme=n(exe,"STRONG",{});var $it=s(pme);sPo=r($it,"xlm-roberta-xl"),$it.forEach(t),lPo=r(exe," \u2014 "),UG=n(exe,"A",{href:!0});var kit=s(UG);iPo=r(kit,"XLMRobertaXLForMultipleChoice"),kit.forEach(t),dPo=r(exe," (XLM-RoBERTa-XL model)"),exe.forEach(t),cPo=i(K),Yb=n(K,"LI",{});var oxe=s(Yb);ume=n(oxe,"STRONG",{});var Sit=s(ume);fPo=r(Sit,"xlnet"),Sit.forEach(t),mPo=r(oxe," \u2014 "),JG=n(oxe,"A",{href:!0});var Rit=s(JG);gPo=r(Rit,"XLNetForMultipleChoice"),Rit.forEach(t),hPo=r(oxe," (XLNet model)"),oxe.forEach(t),pPo=i(K),Kb=n(K,"LI",{});var rxe=s(Kb);_me=n(rxe,"STRONG",{});var Bit=s(_me);uPo=r(Bit,"yoso"),Bit.forEach(t),_Po=r(rxe," \u2014 "),YG=n(rxe,"A",{href:!0});var Pit=s(YG);bPo=r(Pit,"YosoForMultipleChoice"),Pit.forEach(t),vPo=r(rxe," (YOSO model)"),rxe.forEach(t),K.forEach(t),FPo=i(na),Zb=n(na,"P",{});var txe=s(Zb);TPo=r(txe,"The model is set in evaluation mode by default using "),bme=n(txe,"CODE",{});var Iit=s(bme);MPo=r(Iit,"model.eval()"),Iit.forEach(t),EPo=r(txe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vme=n(txe,"CODE",{});var qit=s(vme);CPo=r(qit,"model.train()"),qit.forEach(t),txe.forEach(t),wPo=i(na),T(e2.$$.fragment,na),na.forEach(t),Qs.forEach(t),UIe=i(f),Vi=n(f,"H2",{class:!0});var ZNe=s(Vi);o2=n(ZNe,"A",{id:!0,class:!0,href:!0});var Nit=s(o2);Fme=n(Nit,"SPAN",{});var jit=s(Fme);T(my.$$.fragment,jit),jit.forEach(t),Nit.forEach(t),APo=i(ZNe),Tme=n(ZNe,"SPAN",{});var Dit=s(Tme);yPo=r(Dit,"AutoModelForNextSentencePrediction"),Dit.forEach(t),ZNe.forEach(t),JIe=i(f),Po=n(f,"DIV",{class:!0});var Ws=s(Po);T(gy.$$.fragment,Ws),LPo=i(Ws),Xi=n(Ws,"P",{});var DK=s(Xi);xPo=r(DK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),KG=n(DK,"A",{href:!0});var Git=s(KG);$Po=r(Git,"from_pretrained()"),Git.forEach(t),kPo=r(DK," class method or the "),ZG=n(DK,"A",{href:!0});var Oit=s(ZG);SPo=r(Oit,"from_config()"),Oit.forEach(t),RPo=r(DK,` class
method.`),DK.forEach(t),BPo=i(Ws),hy=n(Ws,"P",{});var eje=s(hy);PPo=r(eje,"This class cannot be instantiated directly using "),Mme=n(eje,"CODE",{});var Vit=s(Mme);IPo=r(Vit,"__init__()"),Vit.forEach(t),qPo=r(eje," (throws an error)."),eje.forEach(t),NPo=i(Ws),it=n(Ws,"DIV",{class:!0});var M3=s(it);T(py.$$.fragment,M3),jPo=i(M3),Eme=n(M3,"P",{});var Xit=s(Eme);DPo=r(Xit,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Xit.forEach(t),GPo=i(M3),zi=n(M3,"P",{});var GK=s(zi);OPo=r(GK,`Note:
Loading a model from its configuration file does `),Cme=n(GK,"STRONG",{});var zit=s(Cme);VPo=r(zit,"not"),zit.forEach(t),XPo=r(GK,` load the model weights. It only affects the
model\u2019s configuration. Use `),eO=n(GK,"A",{href:!0});var Qit=s(eO);zPo=r(Qit,"from_pretrained()"),Qit.forEach(t),QPo=r(GK," to load the model weights."),GK.forEach(t),WPo=i(M3),T(r2.$$.fragment,M3),M3.forEach(t),HPo=i(Ws),oo=n(Ws,"DIV",{class:!0});var sa=s(oo);T(uy.$$.fragment,sa),UPo=i(sa),wme=n(sa,"P",{});var Wit=s(wme);JPo=r(Wit,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Wit.forEach(t),YPo=i(sa),Ra=n(sa,"P",{});var E3=s(Ra);KPo=r(E3,"The model class to instantiate is selected based on the "),Ame=n(E3,"CODE",{});var Hit=s(Ame);ZPo=r(Hit,"model_type"),Hit.forEach(t),eIo=r(E3,` property of the config object (either
passed as an argument or loaded from `),yme=n(E3,"CODE",{});var Uit=s(yme);oIo=r(Uit,"pretrained_model_name_or_path"),Uit.forEach(t),rIo=r(E3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lme=n(E3,"CODE",{});var Jit=s(Lme);tIo=r(Jit,"pretrained_model_name_or_path"),Jit.forEach(t),aIo=r(E3,":"),E3.forEach(t),nIo=i(sa),Yr=n(sa,"UL",{});var Hs=s(Yr);t2=n(Hs,"LI",{});var axe=s(t2);xme=n(axe,"STRONG",{});var Yit=s(xme);sIo=r(Yit,"bert"),Yit.forEach(t),lIo=r(axe," \u2014 "),oO=n(axe,"A",{href:!0});var Kit=s(oO);iIo=r(Kit,"BertForNextSentencePrediction"),Kit.forEach(t),dIo=r(axe," (BERT model)"),axe.forEach(t),cIo=i(Hs),a2=n(Hs,"LI",{});var nxe=s(a2);$me=n(nxe,"STRONG",{});var Zit=s($me);fIo=r(Zit,"fnet"),Zit.forEach(t),mIo=r(nxe," \u2014 "),rO=n(nxe,"A",{href:!0});var edt=s(rO);gIo=r(edt,"FNetForNextSentencePrediction"),edt.forEach(t),hIo=r(nxe," (FNet model)"),nxe.forEach(t),pIo=i(Hs),n2=n(Hs,"LI",{});var sxe=s(n2);kme=n(sxe,"STRONG",{});var odt=s(kme);uIo=r(odt,"megatron-bert"),odt.forEach(t),_Io=r(sxe," \u2014 "),tO=n(sxe,"A",{href:!0});var rdt=s(tO);bIo=r(rdt,"MegatronBertForNextSentencePrediction"),rdt.forEach(t),vIo=r(sxe," (MegatronBert model)"),sxe.forEach(t),FIo=i(Hs),s2=n(Hs,"LI",{});var lxe=s(s2);Sme=n(lxe,"STRONG",{});var tdt=s(Sme);TIo=r(tdt,"mobilebert"),tdt.forEach(t),MIo=r(lxe," \u2014 "),aO=n(lxe,"A",{href:!0});var adt=s(aO);EIo=r(adt,"MobileBertForNextSentencePrediction"),adt.forEach(t),CIo=r(lxe," (MobileBERT model)"),lxe.forEach(t),wIo=i(Hs),l2=n(Hs,"LI",{});var ixe=s(l2);Rme=n(ixe,"STRONG",{});var ndt=s(Rme);AIo=r(ndt,"qdqbert"),ndt.forEach(t),yIo=r(ixe," \u2014 "),nO=n(ixe,"A",{href:!0});var sdt=s(nO);LIo=r(sdt,"QDQBertForNextSentencePrediction"),sdt.forEach(t),xIo=r(ixe," (QDQBert model)"),ixe.forEach(t),Hs.forEach(t),$Io=i(sa),i2=n(sa,"P",{});var dxe=s(i2);kIo=r(dxe,"The model is set in evaluation mode by default using "),Bme=n(dxe,"CODE",{});var ldt=s(Bme);SIo=r(ldt,"model.eval()"),ldt.forEach(t),RIo=r(dxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pme=n(dxe,"CODE",{});var idt=s(Pme);BIo=r(idt,"model.train()"),idt.forEach(t),dxe.forEach(t),PIo=i(sa),T(d2.$$.fragment,sa),sa.forEach(t),Ws.forEach(t),YIe=i(f),Qi=n(f,"H2",{class:!0});var oje=s(Qi);c2=n(oje,"A",{id:!0,class:!0,href:!0});var ddt=s(c2);Ime=n(ddt,"SPAN",{});var cdt=s(Ime);T(_y.$$.fragment,cdt),cdt.forEach(t),ddt.forEach(t),IIo=i(oje),qme=n(oje,"SPAN",{});var fdt=s(qme);qIo=r(fdt,"AutoModelForTokenClassification"),fdt.forEach(t),oje.forEach(t),KIe=i(f),Io=n(f,"DIV",{class:!0});var Us=s(Io);T(by.$$.fragment,Us),NIo=i(Us),Wi=n(Us,"P",{});var OK=s(Wi);jIo=r(OK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),sO=n(OK,"A",{href:!0});var mdt=s(sO);DIo=r(mdt,"from_pretrained()"),mdt.forEach(t),GIo=r(OK," class method or the "),lO=n(OK,"A",{href:!0});var gdt=s(lO);OIo=r(gdt,"from_config()"),gdt.forEach(t),VIo=r(OK,` class
method.`),OK.forEach(t),XIo=i(Us),vy=n(Us,"P",{});var rje=s(vy);zIo=r(rje,"This class cannot be instantiated directly using "),Nme=n(rje,"CODE",{});var hdt=s(Nme);QIo=r(hdt,"__init__()"),hdt.forEach(t),WIo=r(rje," (throws an error)."),rje.forEach(t),HIo=i(Us),dt=n(Us,"DIV",{class:!0});var C3=s(dt);T(Fy.$$.fragment,C3),UIo=i(C3),jme=n(C3,"P",{});var pdt=s(jme);JIo=r(pdt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),pdt.forEach(t),YIo=i(C3),Hi=n(C3,"P",{});var VK=s(Hi);KIo=r(VK,`Note:
Loading a model from its configuration file does `),Dme=n(VK,"STRONG",{});var udt=s(Dme);ZIo=r(udt,"not"),udt.forEach(t),eqo=r(VK,` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=n(VK,"A",{href:!0});var _dt=s(iO);oqo=r(_dt,"from_pretrained()"),_dt.forEach(t),rqo=r(VK," to load the model weights."),VK.forEach(t),tqo=i(C3),T(f2.$$.fragment,C3),C3.forEach(t),aqo=i(Us),ro=n(Us,"DIV",{class:!0});var la=s(ro);T(Ty.$$.fragment,la),nqo=i(la),Gme=n(la,"P",{});var bdt=s(Gme);sqo=r(bdt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),bdt.forEach(t),lqo=i(la),Ba=n(la,"P",{});var w3=s(Ba);iqo=r(w3,"The model class to instantiate is selected based on the "),Ome=n(w3,"CODE",{});var vdt=s(Ome);dqo=r(vdt,"model_type"),vdt.forEach(t),cqo=r(w3,` property of the config object (either
passed as an argument or loaded from `),Vme=n(w3,"CODE",{});var Fdt=s(Vme);fqo=r(Fdt,"pretrained_model_name_or_path"),Fdt.forEach(t),mqo=r(w3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xme=n(w3,"CODE",{});var Tdt=s(Xme);gqo=r(Tdt,"pretrained_model_name_or_path"),Tdt.forEach(t),hqo=r(w3,":"),w3.forEach(t),pqo=i(la),H=n(la,"UL",{});var J=s(H);m2=n(J,"LI",{});var cxe=s(m2);zme=n(cxe,"STRONG",{});var Mdt=s(zme);uqo=r(Mdt,"albert"),Mdt.forEach(t),_qo=r(cxe," \u2014 "),dO=n(cxe,"A",{href:!0});var Edt=s(dO);bqo=r(Edt,"AlbertForTokenClassification"),Edt.forEach(t),vqo=r(cxe," (ALBERT model)"),cxe.forEach(t),Fqo=i(J),g2=n(J,"LI",{});var fxe=s(g2);Qme=n(fxe,"STRONG",{});var Cdt=s(Qme);Tqo=r(Cdt,"bert"),Cdt.forEach(t),Mqo=r(fxe," \u2014 "),cO=n(fxe,"A",{href:!0});var wdt=s(cO);Eqo=r(wdt,"BertForTokenClassification"),wdt.forEach(t),Cqo=r(fxe," (BERT model)"),fxe.forEach(t),wqo=i(J),h2=n(J,"LI",{});var mxe=s(h2);Wme=n(mxe,"STRONG",{});var Adt=s(Wme);Aqo=r(Adt,"big_bird"),Adt.forEach(t),yqo=r(mxe," \u2014 "),fO=n(mxe,"A",{href:!0});var ydt=s(fO);Lqo=r(ydt,"BigBirdForTokenClassification"),ydt.forEach(t),xqo=r(mxe," (BigBird model)"),mxe.forEach(t),$qo=i(J),p2=n(J,"LI",{});var gxe=s(p2);Hme=n(gxe,"STRONG",{});var Ldt=s(Hme);kqo=r(Ldt,"camembert"),Ldt.forEach(t),Sqo=r(gxe," \u2014 "),mO=n(gxe,"A",{href:!0});var xdt=s(mO);Rqo=r(xdt,"CamembertForTokenClassification"),xdt.forEach(t),Bqo=r(gxe," (CamemBERT model)"),gxe.forEach(t),Pqo=i(J),u2=n(J,"LI",{});var hxe=s(u2);Ume=n(hxe,"STRONG",{});var $dt=s(Ume);Iqo=r($dt,"canine"),$dt.forEach(t),qqo=r(hxe," \u2014 "),gO=n(hxe,"A",{href:!0});var kdt=s(gO);Nqo=r(kdt,"CanineForTokenClassification"),kdt.forEach(t),jqo=r(hxe," (Canine model)"),hxe.forEach(t),Dqo=i(J),_2=n(J,"LI",{});var pxe=s(_2);Jme=n(pxe,"STRONG",{});var Sdt=s(Jme);Gqo=r(Sdt,"convbert"),Sdt.forEach(t),Oqo=r(pxe," \u2014 "),hO=n(pxe,"A",{href:!0});var Rdt=s(hO);Vqo=r(Rdt,"ConvBertForTokenClassification"),Rdt.forEach(t),Xqo=r(pxe," (ConvBERT model)"),pxe.forEach(t),zqo=i(J),b2=n(J,"LI",{});var uxe=s(b2);Yme=n(uxe,"STRONG",{});var Bdt=s(Yme);Qqo=r(Bdt,"data2vec-text"),Bdt.forEach(t),Wqo=r(uxe," \u2014 "),pO=n(uxe,"A",{href:!0});var Pdt=s(pO);Hqo=r(Pdt,"Data2VecTextForTokenClassification"),Pdt.forEach(t),Uqo=r(uxe," (Data2VecText model)"),uxe.forEach(t),Jqo=i(J),v2=n(J,"LI",{});var _xe=s(v2);Kme=n(_xe,"STRONG",{});var Idt=s(Kme);Yqo=r(Idt,"deberta"),Idt.forEach(t),Kqo=r(_xe," \u2014 "),uO=n(_xe,"A",{href:!0});var qdt=s(uO);Zqo=r(qdt,"DebertaForTokenClassification"),qdt.forEach(t),eNo=r(_xe," (DeBERTa model)"),_xe.forEach(t),oNo=i(J),F2=n(J,"LI",{});var bxe=s(F2);Zme=n(bxe,"STRONG",{});var Ndt=s(Zme);rNo=r(Ndt,"deberta-v2"),Ndt.forEach(t),tNo=r(bxe," \u2014 "),_O=n(bxe,"A",{href:!0});var jdt=s(_O);aNo=r(jdt,"DebertaV2ForTokenClassification"),jdt.forEach(t),nNo=r(bxe," (DeBERTa-v2 model)"),bxe.forEach(t),sNo=i(J),T2=n(J,"LI",{});var vxe=s(T2);ege=n(vxe,"STRONG",{});var Ddt=s(ege);lNo=r(Ddt,"distilbert"),Ddt.forEach(t),iNo=r(vxe," \u2014 "),bO=n(vxe,"A",{href:!0});var Gdt=s(bO);dNo=r(Gdt,"DistilBertForTokenClassification"),Gdt.forEach(t),cNo=r(vxe," (DistilBERT model)"),vxe.forEach(t),fNo=i(J),M2=n(J,"LI",{});var Fxe=s(M2);oge=n(Fxe,"STRONG",{});var Odt=s(oge);mNo=r(Odt,"electra"),Odt.forEach(t),gNo=r(Fxe," \u2014 "),vO=n(Fxe,"A",{href:!0});var Vdt=s(vO);hNo=r(Vdt,"ElectraForTokenClassification"),Vdt.forEach(t),pNo=r(Fxe," (ELECTRA model)"),Fxe.forEach(t),uNo=i(J),E2=n(J,"LI",{});var Txe=s(E2);rge=n(Txe,"STRONG",{});var Xdt=s(rge);_No=r(Xdt,"flaubert"),Xdt.forEach(t),bNo=r(Txe," \u2014 "),FO=n(Txe,"A",{href:!0});var zdt=s(FO);vNo=r(zdt,"FlaubertForTokenClassification"),zdt.forEach(t),FNo=r(Txe," (FlauBERT model)"),Txe.forEach(t),TNo=i(J),C2=n(J,"LI",{});var Mxe=s(C2);tge=n(Mxe,"STRONG",{});var Qdt=s(tge);MNo=r(Qdt,"fnet"),Qdt.forEach(t),ENo=r(Mxe," \u2014 "),TO=n(Mxe,"A",{href:!0});var Wdt=s(TO);CNo=r(Wdt,"FNetForTokenClassification"),Wdt.forEach(t),wNo=r(Mxe," (FNet model)"),Mxe.forEach(t),ANo=i(J),w2=n(J,"LI",{});var Exe=s(w2);age=n(Exe,"STRONG",{});var Hdt=s(age);yNo=r(Hdt,"funnel"),Hdt.forEach(t),LNo=r(Exe," \u2014 "),MO=n(Exe,"A",{href:!0});var Udt=s(MO);xNo=r(Udt,"FunnelForTokenClassification"),Udt.forEach(t),$No=r(Exe," (Funnel Transformer model)"),Exe.forEach(t),kNo=i(J),A2=n(J,"LI",{});var Cxe=s(A2);nge=n(Cxe,"STRONG",{});var Jdt=s(nge);SNo=r(Jdt,"gpt2"),Jdt.forEach(t),RNo=r(Cxe," \u2014 "),EO=n(Cxe,"A",{href:!0});var Ydt=s(EO);BNo=r(Ydt,"GPT2ForTokenClassification"),Ydt.forEach(t),PNo=r(Cxe," (OpenAI GPT-2 model)"),Cxe.forEach(t),INo=i(J),y2=n(J,"LI",{});var wxe=s(y2);sge=n(wxe,"STRONG",{});var Kdt=s(sge);qNo=r(Kdt,"ibert"),Kdt.forEach(t),NNo=r(wxe," \u2014 "),CO=n(wxe,"A",{href:!0});var Zdt=s(CO);jNo=r(Zdt,"IBertForTokenClassification"),Zdt.forEach(t),DNo=r(wxe," (I-BERT model)"),wxe.forEach(t),GNo=i(J),L2=n(J,"LI",{});var Axe=s(L2);lge=n(Axe,"STRONG",{});var ect=s(lge);ONo=r(ect,"layoutlm"),ect.forEach(t),VNo=r(Axe," \u2014 "),wO=n(Axe,"A",{href:!0});var oct=s(wO);XNo=r(oct,"LayoutLMForTokenClassification"),oct.forEach(t),zNo=r(Axe," (LayoutLM model)"),Axe.forEach(t),QNo=i(J),x2=n(J,"LI",{});var yxe=s(x2);ige=n(yxe,"STRONG",{});var rct=s(ige);WNo=r(rct,"layoutlmv2"),rct.forEach(t),HNo=r(yxe," \u2014 "),AO=n(yxe,"A",{href:!0});var tct=s(AO);UNo=r(tct,"LayoutLMv2ForTokenClassification"),tct.forEach(t),JNo=r(yxe," (LayoutLMv2 model)"),yxe.forEach(t),YNo=i(J),$2=n(J,"LI",{});var Lxe=s($2);dge=n(Lxe,"STRONG",{});var act=s(dge);KNo=r(act,"layoutlmv3"),act.forEach(t),ZNo=r(Lxe," \u2014 "),yO=n(Lxe,"A",{href:!0});var nct=s(yO);ejo=r(nct,"LayoutLMv3ForTokenClassification"),nct.forEach(t),ojo=r(Lxe," (LayoutLMv3 model)"),Lxe.forEach(t),rjo=i(J),k2=n(J,"LI",{});var xxe=s(k2);cge=n(xxe,"STRONG",{});var sct=s(cge);tjo=r(sct,"longformer"),sct.forEach(t),ajo=r(xxe," \u2014 "),LO=n(xxe,"A",{href:!0});var lct=s(LO);njo=r(lct,"LongformerForTokenClassification"),lct.forEach(t),sjo=r(xxe," (Longformer model)"),xxe.forEach(t),ljo=i(J),S2=n(J,"LI",{});var $xe=s(S2);fge=n($xe,"STRONG",{});var ict=s(fge);ijo=r(ict,"megatron-bert"),ict.forEach(t),djo=r($xe," \u2014 "),xO=n($xe,"A",{href:!0});var dct=s(xO);cjo=r(dct,"MegatronBertForTokenClassification"),dct.forEach(t),fjo=r($xe," (MegatronBert model)"),$xe.forEach(t),mjo=i(J),R2=n(J,"LI",{});var kxe=s(R2);mge=n(kxe,"STRONG",{});var cct=s(mge);gjo=r(cct,"mobilebert"),cct.forEach(t),hjo=r(kxe," \u2014 "),$O=n(kxe,"A",{href:!0});var fct=s($O);pjo=r(fct,"MobileBertForTokenClassification"),fct.forEach(t),ujo=r(kxe," (MobileBERT model)"),kxe.forEach(t),_jo=i(J),B2=n(J,"LI",{});var Sxe=s(B2);gge=n(Sxe,"STRONG",{});var mct=s(gge);bjo=r(mct,"mpnet"),mct.forEach(t),vjo=r(Sxe," \u2014 "),kO=n(Sxe,"A",{href:!0});var gct=s(kO);Fjo=r(gct,"MPNetForTokenClassification"),gct.forEach(t),Tjo=r(Sxe," (MPNet model)"),Sxe.forEach(t),Mjo=i(J),P2=n(J,"LI",{});var Rxe=s(P2);hge=n(Rxe,"STRONG",{});var hct=s(hge);Ejo=r(hct,"nystromformer"),hct.forEach(t),Cjo=r(Rxe," \u2014 "),SO=n(Rxe,"A",{href:!0});var pct=s(SO);wjo=r(pct,"NystromformerForTokenClassification"),pct.forEach(t),Ajo=r(Rxe," (Nystromformer model)"),Rxe.forEach(t),yjo=i(J),I2=n(J,"LI",{});var Bxe=s(I2);pge=n(Bxe,"STRONG",{});var uct=s(pge);Ljo=r(uct,"qdqbert"),uct.forEach(t),xjo=r(Bxe," \u2014 "),RO=n(Bxe,"A",{href:!0});var _ct=s(RO);$jo=r(_ct,"QDQBertForTokenClassification"),_ct.forEach(t),kjo=r(Bxe," (QDQBert model)"),Bxe.forEach(t),Sjo=i(J),q2=n(J,"LI",{});var Pxe=s(q2);uge=n(Pxe,"STRONG",{});var bct=s(uge);Rjo=r(bct,"rembert"),bct.forEach(t),Bjo=r(Pxe," \u2014 "),BO=n(Pxe,"A",{href:!0});var vct=s(BO);Pjo=r(vct,"RemBertForTokenClassification"),vct.forEach(t),Ijo=r(Pxe," (RemBERT model)"),Pxe.forEach(t),qjo=i(J),N2=n(J,"LI",{});var Ixe=s(N2);_ge=n(Ixe,"STRONG",{});var Fct=s(_ge);Njo=r(Fct,"roberta"),Fct.forEach(t),jjo=r(Ixe," \u2014 "),PO=n(Ixe,"A",{href:!0});var Tct=s(PO);Djo=r(Tct,"RobertaForTokenClassification"),Tct.forEach(t),Gjo=r(Ixe," (RoBERTa model)"),Ixe.forEach(t),Ojo=i(J),j2=n(J,"LI",{});var qxe=s(j2);bge=n(qxe,"STRONG",{});var Mct=s(bge);Vjo=r(Mct,"roformer"),Mct.forEach(t),Xjo=r(qxe," \u2014 "),IO=n(qxe,"A",{href:!0});var Ect=s(IO);zjo=r(Ect,"RoFormerForTokenClassification"),Ect.forEach(t),Qjo=r(qxe," (RoFormer model)"),qxe.forEach(t),Wjo=i(J),D2=n(J,"LI",{});var Nxe=s(D2);vge=n(Nxe,"STRONG",{});var Cct=s(vge);Hjo=r(Cct,"squeezebert"),Cct.forEach(t),Ujo=r(Nxe," \u2014 "),qO=n(Nxe,"A",{href:!0});var wct=s(qO);Jjo=r(wct,"SqueezeBertForTokenClassification"),wct.forEach(t),Yjo=r(Nxe," (SqueezeBERT model)"),Nxe.forEach(t),Kjo=i(J),G2=n(J,"LI",{});var jxe=s(G2);Fge=n(jxe,"STRONG",{});var Act=s(Fge);Zjo=r(Act,"xlm"),Act.forEach(t),eDo=r(jxe," \u2014 "),NO=n(jxe,"A",{href:!0});var yct=s(NO);oDo=r(yct,"XLMForTokenClassification"),yct.forEach(t),rDo=r(jxe," (XLM model)"),jxe.forEach(t),tDo=i(J),O2=n(J,"LI",{});var Dxe=s(O2);Tge=n(Dxe,"STRONG",{});var Lct=s(Tge);aDo=r(Lct,"xlm-roberta"),Lct.forEach(t),nDo=r(Dxe," \u2014 "),jO=n(Dxe,"A",{href:!0});var xct=s(jO);sDo=r(xct,"XLMRobertaForTokenClassification"),xct.forEach(t),lDo=r(Dxe," (XLM-RoBERTa model)"),Dxe.forEach(t),iDo=i(J),V2=n(J,"LI",{});var Gxe=s(V2);Mge=n(Gxe,"STRONG",{});var $ct=s(Mge);dDo=r($ct,"xlm-roberta-xl"),$ct.forEach(t),cDo=r(Gxe," \u2014 "),DO=n(Gxe,"A",{href:!0});var kct=s(DO);fDo=r(kct,"XLMRobertaXLForTokenClassification"),kct.forEach(t),mDo=r(Gxe," (XLM-RoBERTa-XL model)"),Gxe.forEach(t),gDo=i(J),X2=n(J,"LI",{});var Oxe=s(X2);Ege=n(Oxe,"STRONG",{});var Sct=s(Ege);hDo=r(Sct,"xlnet"),Sct.forEach(t),pDo=r(Oxe," \u2014 "),GO=n(Oxe,"A",{href:!0});var Rct=s(GO);uDo=r(Rct,"XLNetForTokenClassification"),Rct.forEach(t),_Do=r(Oxe," (XLNet model)"),Oxe.forEach(t),bDo=i(J),z2=n(J,"LI",{});var Vxe=s(z2);Cge=n(Vxe,"STRONG",{});var Bct=s(Cge);vDo=r(Bct,"yoso"),Bct.forEach(t),FDo=r(Vxe," \u2014 "),OO=n(Vxe,"A",{href:!0});var Pct=s(OO);TDo=r(Pct,"YosoForTokenClassification"),Pct.forEach(t),MDo=r(Vxe," (YOSO model)"),Vxe.forEach(t),J.forEach(t),EDo=i(la),Q2=n(la,"P",{});var Xxe=s(Q2);CDo=r(Xxe,"The model is set in evaluation mode by default using "),wge=n(Xxe,"CODE",{});var Ict=s(wge);wDo=r(Ict,"model.eval()"),Ict.forEach(t),ADo=r(Xxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Age=n(Xxe,"CODE",{});var qct=s(Age);yDo=r(qct,"model.train()"),qct.forEach(t),Xxe.forEach(t),LDo=i(la),T(W2.$$.fragment,la),la.forEach(t),Us.forEach(t),ZIe=i(f),Ui=n(f,"H2",{class:!0});var tje=s(Ui);H2=n(tje,"A",{id:!0,class:!0,href:!0});var Nct=s(H2);yge=n(Nct,"SPAN",{});var jct=s(yge);T(My.$$.fragment,jct),jct.forEach(t),Nct.forEach(t),xDo=i(tje),Lge=n(tje,"SPAN",{});var Dct=s(Lge);$Do=r(Dct,"AutoModelForQuestionAnswering"),Dct.forEach(t),tje.forEach(t),eqe=i(f),qo=n(f,"DIV",{class:!0});var Js=s(qo);T(Ey.$$.fragment,Js),kDo=i(Js),Ji=n(Js,"P",{});var XK=s(Ji);SDo=r(XK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),VO=n(XK,"A",{href:!0});var Gct=s(VO);RDo=r(Gct,"from_pretrained()"),Gct.forEach(t),BDo=r(XK," class method or the "),XO=n(XK,"A",{href:!0});var Oct=s(XO);PDo=r(Oct,"from_config()"),Oct.forEach(t),IDo=r(XK,` class
method.`),XK.forEach(t),qDo=i(Js),Cy=n(Js,"P",{});var aje=s(Cy);NDo=r(aje,"This class cannot be instantiated directly using "),xge=n(aje,"CODE",{});var Vct=s(xge);jDo=r(Vct,"__init__()"),Vct.forEach(t),DDo=r(aje," (throws an error)."),aje.forEach(t),GDo=i(Js),ct=n(Js,"DIV",{class:!0});var A3=s(ct);T(wy.$$.fragment,A3),ODo=i(A3),$ge=n(A3,"P",{});var Xct=s($ge);VDo=r(Xct,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Xct.forEach(t),XDo=i(A3),Yi=n(A3,"P",{});var zK=s(Yi);zDo=r(zK,`Note:
Loading a model from its configuration file does `),kge=n(zK,"STRONG",{});var zct=s(kge);QDo=r(zct,"not"),zct.forEach(t),WDo=r(zK,` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=n(zK,"A",{href:!0});var Qct=s(zO);HDo=r(Qct,"from_pretrained()"),Qct.forEach(t),UDo=r(zK," to load the model weights."),zK.forEach(t),JDo=i(A3),T(U2.$$.fragment,A3),A3.forEach(t),YDo=i(Js),to=n(Js,"DIV",{class:!0});var ia=s(to);T(Ay.$$.fragment,ia),KDo=i(ia),Sge=n(ia,"P",{});var Wct=s(Sge);ZDo=r(Wct,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Wct.forEach(t),eGo=i(ia),Pa=n(ia,"P",{});var y3=s(Pa);oGo=r(y3,"The model class to instantiate is selected based on the "),Rge=n(y3,"CODE",{});var Hct=s(Rge);rGo=r(Hct,"model_type"),Hct.forEach(t),tGo=r(y3,` property of the config object (either
passed as an argument or loaded from `),Bge=n(y3,"CODE",{});var Uct=s(Bge);aGo=r(Uct,"pretrained_model_name_or_path"),Uct.forEach(t),nGo=r(y3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pge=n(y3,"CODE",{});var Jct=s(Pge);sGo=r(Jct,"pretrained_model_name_or_path"),Jct.forEach(t),lGo=r(y3,":"),y3.forEach(t),iGo=i(ia),O=n(ia,"UL",{});var X=s(O);J2=n(X,"LI",{});var zxe=s(J2);Ige=n(zxe,"STRONG",{});var Yct=s(Ige);dGo=r(Yct,"albert"),Yct.forEach(t),cGo=r(zxe," \u2014 "),QO=n(zxe,"A",{href:!0});var Kct=s(QO);fGo=r(Kct,"AlbertForQuestionAnswering"),Kct.forEach(t),mGo=r(zxe," (ALBERT model)"),zxe.forEach(t),gGo=i(X),Y2=n(X,"LI",{});var Qxe=s(Y2);qge=n(Qxe,"STRONG",{});var Zct=s(qge);hGo=r(Zct,"bart"),Zct.forEach(t),pGo=r(Qxe," \u2014 "),WO=n(Qxe,"A",{href:!0});var eft=s(WO);uGo=r(eft,"BartForQuestionAnswering"),eft.forEach(t),_Go=r(Qxe," (BART model)"),Qxe.forEach(t),bGo=i(X),K2=n(X,"LI",{});var Wxe=s(K2);Nge=n(Wxe,"STRONG",{});var oft=s(Nge);vGo=r(oft,"bert"),oft.forEach(t),FGo=r(Wxe," \u2014 "),HO=n(Wxe,"A",{href:!0});var rft=s(HO);TGo=r(rft,"BertForQuestionAnswering"),rft.forEach(t),MGo=r(Wxe," (BERT model)"),Wxe.forEach(t),EGo=i(X),Z2=n(X,"LI",{});var Hxe=s(Z2);jge=n(Hxe,"STRONG",{});var tft=s(jge);CGo=r(tft,"big_bird"),tft.forEach(t),wGo=r(Hxe," \u2014 "),UO=n(Hxe,"A",{href:!0});var aft=s(UO);AGo=r(aft,"BigBirdForQuestionAnswering"),aft.forEach(t),yGo=r(Hxe," (BigBird model)"),Hxe.forEach(t),LGo=i(X),ev=n(X,"LI",{});var Uxe=s(ev);Dge=n(Uxe,"STRONG",{});var nft=s(Dge);xGo=r(nft,"bigbird_pegasus"),nft.forEach(t),$Go=r(Uxe," \u2014 "),JO=n(Uxe,"A",{href:!0});var sft=s(JO);kGo=r(sft,"BigBirdPegasusForQuestionAnswering"),sft.forEach(t),SGo=r(Uxe," (BigBirdPegasus model)"),Uxe.forEach(t),RGo=i(X),ov=n(X,"LI",{});var Jxe=s(ov);Gge=n(Jxe,"STRONG",{});var lft=s(Gge);BGo=r(lft,"camembert"),lft.forEach(t),PGo=r(Jxe," \u2014 "),YO=n(Jxe,"A",{href:!0});var ift=s(YO);IGo=r(ift,"CamembertForQuestionAnswering"),ift.forEach(t),qGo=r(Jxe," (CamemBERT model)"),Jxe.forEach(t),NGo=i(X),rv=n(X,"LI",{});var Yxe=s(rv);Oge=n(Yxe,"STRONG",{});var dft=s(Oge);jGo=r(dft,"canine"),dft.forEach(t),DGo=r(Yxe," \u2014 "),KO=n(Yxe,"A",{href:!0});var cft=s(KO);GGo=r(cft,"CanineForQuestionAnswering"),cft.forEach(t),OGo=r(Yxe," (Canine model)"),Yxe.forEach(t),VGo=i(X),tv=n(X,"LI",{});var Kxe=s(tv);Vge=n(Kxe,"STRONG",{});var fft=s(Vge);XGo=r(fft,"convbert"),fft.forEach(t),zGo=r(Kxe," \u2014 "),ZO=n(Kxe,"A",{href:!0});var mft=s(ZO);QGo=r(mft,"ConvBertForQuestionAnswering"),mft.forEach(t),WGo=r(Kxe," (ConvBERT model)"),Kxe.forEach(t),HGo=i(X),av=n(X,"LI",{});var Zxe=s(av);Xge=n(Zxe,"STRONG",{});var gft=s(Xge);UGo=r(gft,"data2vec-text"),gft.forEach(t),JGo=r(Zxe," \u2014 "),eV=n(Zxe,"A",{href:!0});var hft=s(eV);YGo=r(hft,"Data2VecTextForQuestionAnswering"),hft.forEach(t),KGo=r(Zxe," (Data2VecText model)"),Zxe.forEach(t),ZGo=i(X),nv=n(X,"LI",{});var e9e=s(nv);zge=n(e9e,"STRONG",{});var pft=s(zge);eOo=r(pft,"deberta"),pft.forEach(t),oOo=r(e9e," \u2014 "),oV=n(e9e,"A",{href:!0});var uft=s(oV);rOo=r(uft,"DebertaForQuestionAnswering"),uft.forEach(t),tOo=r(e9e," (DeBERTa model)"),e9e.forEach(t),aOo=i(X),sv=n(X,"LI",{});var o9e=s(sv);Qge=n(o9e,"STRONG",{});var _ft=s(Qge);nOo=r(_ft,"deberta-v2"),_ft.forEach(t),sOo=r(o9e," \u2014 "),rV=n(o9e,"A",{href:!0});var bft=s(rV);lOo=r(bft,"DebertaV2ForQuestionAnswering"),bft.forEach(t),iOo=r(o9e," (DeBERTa-v2 model)"),o9e.forEach(t),dOo=i(X),lv=n(X,"LI",{});var r9e=s(lv);Wge=n(r9e,"STRONG",{});var vft=s(Wge);cOo=r(vft,"distilbert"),vft.forEach(t),fOo=r(r9e," \u2014 "),tV=n(r9e,"A",{href:!0});var Fft=s(tV);mOo=r(Fft,"DistilBertForQuestionAnswering"),Fft.forEach(t),gOo=r(r9e," (DistilBERT model)"),r9e.forEach(t),hOo=i(X),iv=n(X,"LI",{});var t9e=s(iv);Hge=n(t9e,"STRONG",{});var Tft=s(Hge);pOo=r(Tft,"electra"),Tft.forEach(t),uOo=r(t9e," \u2014 "),aV=n(t9e,"A",{href:!0});var Mft=s(aV);_Oo=r(Mft,"ElectraForQuestionAnswering"),Mft.forEach(t),bOo=r(t9e," (ELECTRA model)"),t9e.forEach(t),vOo=i(X),dv=n(X,"LI",{});var a9e=s(dv);Uge=n(a9e,"STRONG",{});var Eft=s(Uge);FOo=r(Eft,"flaubert"),Eft.forEach(t),TOo=r(a9e," \u2014 "),nV=n(a9e,"A",{href:!0});var Cft=s(nV);MOo=r(Cft,"FlaubertForQuestionAnsweringSimple"),Cft.forEach(t),EOo=r(a9e," (FlauBERT model)"),a9e.forEach(t),COo=i(X),cv=n(X,"LI",{});var n9e=s(cv);Jge=n(n9e,"STRONG",{});var wft=s(Jge);wOo=r(wft,"fnet"),wft.forEach(t),AOo=r(n9e," \u2014 "),sV=n(n9e,"A",{href:!0});var Aft=s(sV);yOo=r(Aft,"FNetForQuestionAnswering"),Aft.forEach(t),LOo=r(n9e," (FNet model)"),n9e.forEach(t),xOo=i(X),fv=n(X,"LI",{});var s9e=s(fv);Yge=n(s9e,"STRONG",{});var yft=s(Yge);$Oo=r(yft,"funnel"),yft.forEach(t),kOo=r(s9e," \u2014 "),lV=n(s9e,"A",{href:!0});var Lft=s(lV);SOo=r(Lft,"FunnelForQuestionAnswering"),Lft.forEach(t),ROo=r(s9e," (Funnel Transformer model)"),s9e.forEach(t),BOo=i(X),mv=n(X,"LI",{});var l9e=s(mv);Kge=n(l9e,"STRONG",{});var xft=s(Kge);POo=r(xft,"gptj"),xft.forEach(t),IOo=r(l9e," \u2014 "),iV=n(l9e,"A",{href:!0});var $ft=s(iV);qOo=r($ft,"GPTJForQuestionAnswering"),$ft.forEach(t),NOo=r(l9e," (GPT-J model)"),l9e.forEach(t),jOo=i(X),gv=n(X,"LI",{});var i9e=s(gv);Zge=n(i9e,"STRONG",{});var kft=s(Zge);DOo=r(kft,"ibert"),kft.forEach(t),GOo=r(i9e," \u2014 "),dV=n(i9e,"A",{href:!0});var Sft=s(dV);OOo=r(Sft,"IBertForQuestionAnswering"),Sft.forEach(t),VOo=r(i9e," (I-BERT model)"),i9e.forEach(t),XOo=i(X),hv=n(X,"LI",{});var d9e=s(hv);ehe=n(d9e,"STRONG",{});var Rft=s(ehe);zOo=r(Rft,"layoutlmv2"),Rft.forEach(t),QOo=r(d9e," \u2014 "),cV=n(d9e,"A",{href:!0});var Bft=s(cV);WOo=r(Bft,"LayoutLMv2ForQuestionAnswering"),Bft.forEach(t),HOo=r(d9e," (LayoutLMv2 model)"),d9e.forEach(t),UOo=i(X),pv=n(X,"LI",{});var c9e=s(pv);ohe=n(c9e,"STRONG",{});var Pft=s(ohe);JOo=r(Pft,"layoutlmv3"),Pft.forEach(t),YOo=r(c9e," \u2014 "),fV=n(c9e,"A",{href:!0});var Ift=s(fV);KOo=r(Ift,"LayoutLMv3ForQuestionAnswering"),Ift.forEach(t),ZOo=r(c9e," (LayoutLMv3 model)"),c9e.forEach(t),eVo=i(X),uv=n(X,"LI",{});var f9e=s(uv);rhe=n(f9e,"STRONG",{});var qft=s(rhe);oVo=r(qft,"led"),qft.forEach(t),rVo=r(f9e," \u2014 "),mV=n(f9e,"A",{href:!0});var Nft=s(mV);tVo=r(Nft,"LEDForQuestionAnswering"),Nft.forEach(t),aVo=r(f9e," (LED model)"),f9e.forEach(t),nVo=i(X),_v=n(X,"LI",{});var m9e=s(_v);the=n(m9e,"STRONG",{});var jft=s(the);sVo=r(jft,"longformer"),jft.forEach(t),lVo=r(m9e," \u2014 "),gV=n(m9e,"A",{href:!0});var Dft=s(gV);iVo=r(Dft,"LongformerForQuestionAnswering"),Dft.forEach(t),dVo=r(m9e," (Longformer model)"),m9e.forEach(t),cVo=i(X),bv=n(X,"LI",{});var g9e=s(bv);ahe=n(g9e,"STRONG",{});var Gft=s(ahe);fVo=r(Gft,"lxmert"),Gft.forEach(t),mVo=r(g9e," \u2014 "),hV=n(g9e,"A",{href:!0});var Oft=s(hV);gVo=r(Oft,"LxmertForQuestionAnswering"),Oft.forEach(t),hVo=r(g9e," (LXMERT model)"),g9e.forEach(t),pVo=i(X),vv=n(X,"LI",{});var h9e=s(vv);nhe=n(h9e,"STRONG",{});var Vft=s(nhe);uVo=r(Vft,"mbart"),Vft.forEach(t),_Vo=r(h9e," \u2014 "),pV=n(h9e,"A",{href:!0});var Xft=s(pV);bVo=r(Xft,"MBartForQuestionAnswering"),Xft.forEach(t),vVo=r(h9e," (mBART model)"),h9e.forEach(t),FVo=i(X),Fv=n(X,"LI",{});var p9e=s(Fv);she=n(p9e,"STRONG",{});var zft=s(she);TVo=r(zft,"megatron-bert"),zft.forEach(t),MVo=r(p9e," \u2014 "),uV=n(p9e,"A",{href:!0});var Qft=s(uV);EVo=r(Qft,"MegatronBertForQuestionAnswering"),Qft.forEach(t),CVo=r(p9e," (MegatronBert model)"),p9e.forEach(t),wVo=i(X),Tv=n(X,"LI",{});var u9e=s(Tv);lhe=n(u9e,"STRONG",{});var Wft=s(lhe);AVo=r(Wft,"mobilebert"),Wft.forEach(t),yVo=r(u9e," \u2014 "),_V=n(u9e,"A",{href:!0});var Hft=s(_V);LVo=r(Hft,"MobileBertForQuestionAnswering"),Hft.forEach(t),xVo=r(u9e," (MobileBERT model)"),u9e.forEach(t),$Vo=i(X),Mv=n(X,"LI",{});var _9e=s(Mv);ihe=n(_9e,"STRONG",{});var Uft=s(ihe);kVo=r(Uft,"mpnet"),Uft.forEach(t),SVo=r(_9e," \u2014 "),bV=n(_9e,"A",{href:!0});var Jft=s(bV);RVo=r(Jft,"MPNetForQuestionAnswering"),Jft.forEach(t),BVo=r(_9e," (MPNet model)"),_9e.forEach(t),PVo=i(X),Ev=n(X,"LI",{});var b9e=s(Ev);dhe=n(b9e,"STRONG",{});var Yft=s(dhe);IVo=r(Yft,"nystromformer"),Yft.forEach(t),qVo=r(b9e," \u2014 "),vV=n(b9e,"A",{href:!0});var Kft=s(vV);NVo=r(Kft,"NystromformerForQuestionAnswering"),Kft.forEach(t),jVo=r(b9e," (Nystromformer model)"),b9e.forEach(t),DVo=i(X),Cv=n(X,"LI",{});var v9e=s(Cv);che=n(v9e,"STRONG",{});var Zft=s(che);GVo=r(Zft,"qdqbert"),Zft.forEach(t),OVo=r(v9e," \u2014 "),FV=n(v9e,"A",{href:!0});var emt=s(FV);VVo=r(emt,"QDQBertForQuestionAnswering"),emt.forEach(t),XVo=r(v9e," (QDQBert model)"),v9e.forEach(t),zVo=i(X),wv=n(X,"LI",{});var F9e=s(wv);fhe=n(F9e,"STRONG",{});var omt=s(fhe);QVo=r(omt,"reformer"),omt.forEach(t),WVo=r(F9e," \u2014 "),TV=n(F9e,"A",{href:!0});var rmt=s(TV);HVo=r(rmt,"ReformerForQuestionAnswering"),rmt.forEach(t),UVo=r(F9e," (Reformer model)"),F9e.forEach(t),JVo=i(X),Av=n(X,"LI",{});var T9e=s(Av);mhe=n(T9e,"STRONG",{});var tmt=s(mhe);YVo=r(tmt,"rembert"),tmt.forEach(t),KVo=r(T9e," \u2014 "),MV=n(T9e,"A",{href:!0});var amt=s(MV);ZVo=r(amt,"RemBertForQuestionAnswering"),amt.forEach(t),eXo=r(T9e," (RemBERT model)"),T9e.forEach(t),oXo=i(X),yv=n(X,"LI",{});var M9e=s(yv);ghe=n(M9e,"STRONG",{});var nmt=s(ghe);rXo=r(nmt,"roberta"),nmt.forEach(t),tXo=r(M9e," \u2014 "),EV=n(M9e,"A",{href:!0});var smt=s(EV);aXo=r(smt,"RobertaForQuestionAnswering"),smt.forEach(t),nXo=r(M9e," (RoBERTa model)"),M9e.forEach(t),sXo=i(X),Lv=n(X,"LI",{});var E9e=s(Lv);hhe=n(E9e,"STRONG",{});var lmt=s(hhe);lXo=r(lmt,"roformer"),lmt.forEach(t),iXo=r(E9e," \u2014 "),CV=n(E9e,"A",{href:!0});var imt=s(CV);dXo=r(imt,"RoFormerForQuestionAnswering"),imt.forEach(t),cXo=r(E9e," (RoFormer model)"),E9e.forEach(t),fXo=i(X),xv=n(X,"LI",{});var C9e=s(xv);phe=n(C9e,"STRONG",{});var dmt=s(phe);mXo=r(dmt,"splinter"),dmt.forEach(t),gXo=r(C9e," \u2014 "),wV=n(C9e,"A",{href:!0});var cmt=s(wV);hXo=r(cmt,"SplinterForQuestionAnswering"),cmt.forEach(t),pXo=r(C9e," (Splinter model)"),C9e.forEach(t),uXo=i(X),$v=n(X,"LI",{});var w9e=s($v);uhe=n(w9e,"STRONG",{});var fmt=s(uhe);_Xo=r(fmt,"squeezebert"),fmt.forEach(t),bXo=r(w9e," \u2014 "),AV=n(w9e,"A",{href:!0});var mmt=s(AV);vXo=r(mmt,"SqueezeBertForQuestionAnswering"),mmt.forEach(t),FXo=r(w9e," (SqueezeBERT model)"),w9e.forEach(t),TXo=i(X),kv=n(X,"LI",{});var A9e=s(kv);_he=n(A9e,"STRONG",{});var gmt=s(_he);MXo=r(gmt,"xlm"),gmt.forEach(t),EXo=r(A9e," \u2014 "),yV=n(A9e,"A",{href:!0});var hmt=s(yV);CXo=r(hmt,"XLMForQuestionAnsweringSimple"),hmt.forEach(t),wXo=r(A9e," (XLM model)"),A9e.forEach(t),AXo=i(X),Sv=n(X,"LI",{});var y9e=s(Sv);bhe=n(y9e,"STRONG",{});var pmt=s(bhe);yXo=r(pmt,"xlm-roberta"),pmt.forEach(t),LXo=r(y9e," \u2014 "),LV=n(y9e,"A",{href:!0});var umt=s(LV);xXo=r(umt,"XLMRobertaForQuestionAnswering"),umt.forEach(t),$Xo=r(y9e," (XLM-RoBERTa model)"),y9e.forEach(t),kXo=i(X),Rv=n(X,"LI",{});var L9e=s(Rv);vhe=n(L9e,"STRONG",{});var _mt=s(vhe);SXo=r(_mt,"xlm-roberta-xl"),_mt.forEach(t),RXo=r(L9e," \u2014 "),xV=n(L9e,"A",{href:!0});var bmt=s(xV);BXo=r(bmt,"XLMRobertaXLForQuestionAnswering"),bmt.forEach(t),PXo=r(L9e," (XLM-RoBERTa-XL model)"),L9e.forEach(t),IXo=i(X),Bv=n(X,"LI",{});var x9e=s(Bv);Fhe=n(x9e,"STRONG",{});var vmt=s(Fhe);qXo=r(vmt,"xlnet"),vmt.forEach(t),NXo=r(x9e," \u2014 "),$V=n(x9e,"A",{href:!0});var Fmt=s($V);jXo=r(Fmt,"XLNetForQuestionAnsweringSimple"),Fmt.forEach(t),DXo=r(x9e," (XLNet model)"),x9e.forEach(t),GXo=i(X),Pv=n(X,"LI",{});var $9e=s(Pv);The=n($9e,"STRONG",{});var Tmt=s(The);OXo=r(Tmt,"yoso"),Tmt.forEach(t),VXo=r($9e," \u2014 "),kV=n($9e,"A",{href:!0});var Mmt=s(kV);XXo=r(Mmt,"YosoForQuestionAnswering"),Mmt.forEach(t),zXo=r($9e," (YOSO model)"),$9e.forEach(t),X.forEach(t),QXo=i(ia),Iv=n(ia,"P",{});var k9e=s(Iv);WXo=r(k9e,"The model is set in evaluation mode by default using "),Mhe=n(k9e,"CODE",{});var Emt=s(Mhe);HXo=r(Emt,"model.eval()"),Emt.forEach(t),UXo=r(k9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ehe=n(k9e,"CODE",{});var Cmt=s(Ehe);JXo=r(Cmt,"model.train()"),Cmt.forEach(t),k9e.forEach(t),YXo=i(ia),T(qv.$$.fragment,ia),ia.forEach(t),Js.forEach(t),oqe=i(f),Ki=n(f,"H2",{class:!0});var nje=s(Ki);Nv=n(nje,"A",{id:!0,class:!0,href:!0});var wmt=s(Nv);Che=n(wmt,"SPAN",{});var Amt=s(Che);T(yy.$$.fragment,Amt),Amt.forEach(t),wmt.forEach(t),KXo=i(nje),whe=n(nje,"SPAN",{});var ymt=s(whe);ZXo=r(ymt,"AutoModelForTableQuestionAnswering"),ymt.forEach(t),nje.forEach(t),rqe=i(f),No=n(f,"DIV",{class:!0});var Ys=s(No);T(Ly.$$.fragment,Ys),ezo=i(Ys),Zi=n(Ys,"P",{});var QK=s(Zi);ozo=r(QK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),SV=n(QK,"A",{href:!0});var Lmt=s(SV);rzo=r(Lmt,"from_pretrained()"),Lmt.forEach(t),tzo=r(QK," class method or the "),RV=n(QK,"A",{href:!0});var xmt=s(RV);azo=r(xmt,"from_config()"),xmt.forEach(t),nzo=r(QK,` class
method.`),QK.forEach(t),szo=i(Ys),xy=n(Ys,"P",{});var sje=s(xy);lzo=r(sje,"This class cannot be instantiated directly using "),Ahe=n(sje,"CODE",{});var $mt=s(Ahe);izo=r($mt,"__init__()"),$mt.forEach(t),dzo=r(sje," (throws an error)."),sje.forEach(t),czo=i(Ys),ft=n(Ys,"DIV",{class:!0});var L3=s(ft);T($y.$$.fragment,L3),fzo=i(L3),yhe=n(L3,"P",{});var kmt=s(yhe);mzo=r(kmt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),kmt.forEach(t),gzo=i(L3),ed=n(L3,"P",{});var WK=s(ed);hzo=r(WK,`Note:
Loading a model from its configuration file does `),Lhe=n(WK,"STRONG",{});var Smt=s(Lhe);pzo=r(Smt,"not"),Smt.forEach(t),uzo=r(WK,` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=n(WK,"A",{href:!0});var Rmt=s(BV);_zo=r(Rmt,"from_pretrained()"),Rmt.forEach(t),bzo=r(WK," to load the model weights."),WK.forEach(t),vzo=i(L3),T(jv.$$.fragment,L3),L3.forEach(t),Fzo=i(Ys),ao=n(Ys,"DIV",{class:!0});var da=s(ao);T(ky.$$.fragment,da),Tzo=i(da),xhe=n(da,"P",{});var Bmt=s(xhe);Mzo=r(Bmt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Bmt.forEach(t),Ezo=i(da),Ia=n(da,"P",{});var x3=s(Ia);Czo=r(x3,"The model class to instantiate is selected based on the "),$he=n(x3,"CODE",{});var Pmt=s($he);wzo=r(Pmt,"model_type"),Pmt.forEach(t),Azo=r(x3,` property of the config object (either
passed as an argument or loaded from `),khe=n(x3,"CODE",{});var Imt=s(khe);yzo=r(Imt,"pretrained_model_name_or_path"),Imt.forEach(t),Lzo=r(x3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),She=n(x3,"CODE",{});var qmt=s(She);xzo=r(qmt,"pretrained_model_name_or_path"),qmt.forEach(t),$zo=r(x3,":"),x3.forEach(t),kzo=i(da),Rhe=n(da,"UL",{});var Nmt=s(Rhe);Dv=n(Nmt,"LI",{});var S9e=s(Dv);Bhe=n(S9e,"STRONG",{});var jmt=s(Bhe);Szo=r(jmt,"tapas"),jmt.forEach(t),Rzo=r(S9e," \u2014 "),PV=n(S9e,"A",{href:!0});var Dmt=s(PV);Bzo=r(Dmt,"TapasForQuestionAnswering"),Dmt.forEach(t),Pzo=r(S9e," (TAPAS model)"),S9e.forEach(t),Nmt.forEach(t),Izo=i(da),Gv=n(da,"P",{});var R9e=s(Gv);qzo=r(R9e,"The model is set in evaluation mode by default using "),Phe=n(R9e,"CODE",{});var Gmt=s(Phe);Nzo=r(Gmt,"model.eval()"),Gmt.forEach(t),jzo=r(R9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ihe=n(R9e,"CODE",{});var Omt=s(Ihe);Dzo=r(Omt,"model.train()"),Omt.forEach(t),R9e.forEach(t),Gzo=i(da),T(Ov.$$.fragment,da),da.forEach(t),Ys.forEach(t),tqe=i(f),od=n(f,"H2",{class:!0});var lje=s(od);Vv=n(lje,"A",{id:!0,class:!0,href:!0});var Vmt=s(Vv);qhe=n(Vmt,"SPAN",{});var Xmt=s(qhe);T(Sy.$$.fragment,Xmt),Xmt.forEach(t),Vmt.forEach(t),Ozo=i(lje),Nhe=n(lje,"SPAN",{});var zmt=s(Nhe);Vzo=r(zmt,"AutoModelForImageClassification"),zmt.forEach(t),lje.forEach(t),aqe=i(f),jo=n(f,"DIV",{class:!0});var Ks=s(jo);T(Ry.$$.fragment,Ks),Xzo=i(Ks),rd=n(Ks,"P",{});var HK=s(rd);zzo=r(HK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),IV=n(HK,"A",{href:!0});var Qmt=s(IV);Qzo=r(Qmt,"from_pretrained()"),Qmt.forEach(t),Wzo=r(HK," class method or the "),qV=n(HK,"A",{href:!0});var Wmt=s(qV);Hzo=r(Wmt,"from_config()"),Wmt.forEach(t),Uzo=r(HK,` class
method.`),HK.forEach(t),Jzo=i(Ks),By=n(Ks,"P",{});var ije=s(By);Yzo=r(ije,"This class cannot be instantiated directly using "),jhe=n(ije,"CODE",{});var Hmt=s(jhe);Kzo=r(Hmt,"__init__()"),Hmt.forEach(t),Zzo=r(ije," (throws an error)."),ije.forEach(t),eQo=i(Ks),mt=n(Ks,"DIV",{class:!0});var $3=s(mt);T(Py.$$.fragment,$3),oQo=i($3),Dhe=n($3,"P",{});var Umt=s(Dhe);rQo=r(Umt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Umt.forEach(t),tQo=i($3),td=n($3,"P",{});var UK=s(td);aQo=r(UK,`Note:
Loading a model from its configuration file does `),Ghe=n(UK,"STRONG",{});var Jmt=s(Ghe);nQo=r(Jmt,"not"),Jmt.forEach(t),sQo=r(UK,` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=n(UK,"A",{href:!0});var Ymt=s(NV);lQo=r(Ymt,"from_pretrained()"),Ymt.forEach(t),iQo=r(UK," to load the model weights."),UK.forEach(t),dQo=i($3),T(Xv.$$.fragment,$3),$3.forEach(t),cQo=i(Ks),no=n(Ks,"DIV",{class:!0});var ca=s(no);T(Iy.$$.fragment,ca),fQo=i(ca),Ohe=n(ca,"P",{});var Kmt=s(Ohe);mQo=r(Kmt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Kmt.forEach(t),gQo=i(ca),qa=n(ca,"P",{});var k3=s(qa);hQo=r(k3,"The model class to instantiate is selected based on the "),Vhe=n(k3,"CODE",{});var Zmt=s(Vhe);pQo=r(Zmt,"model_type"),Zmt.forEach(t),uQo=r(k3,` property of the config object (either
passed as an argument or loaded from `),Xhe=n(k3,"CODE",{});var egt=s(Xhe);_Qo=r(egt,"pretrained_model_name_or_path"),egt.forEach(t),bQo=r(k3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zhe=n(k3,"CODE",{});var ogt=s(zhe);vQo=r(ogt,"pretrained_model_name_or_path"),ogt.forEach(t),FQo=r(k3,":"),k3.forEach(t),TQo=i(ca),Fe=n(ca,"UL",{});var Ee=s(Fe);zv=n(Ee,"LI",{});var B9e=s(zv);Qhe=n(B9e,"STRONG",{});var rgt=s(Qhe);MQo=r(rgt,"beit"),rgt.forEach(t),EQo=r(B9e," \u2014 "),jV=n(B9e,"A",{href:!0});var tgt=s(jV);CQo=r(tgt,"BeitForImageClassification"),tgt.forEach(t),wQo=r(B9e," (BEiT model)"),B9e.forEach(t),AQo=i(Ee),Qv=n(Ee,"LI",{});var P9e=s(Qv);Whe=n(P9e,"STRONG",{});var agt=s(Whe);yQo=r(agt,"convnext"),agt.forEach(t),LQo=r(P9e," \u2014 "),DV=n(P9e,"A",{href:!0});var ngt=s(DV);xQo=r(ngt,"ConvNextForImageClassification"),ngt.forEach(t),$Qo=r(P9e," (ConvNext model)"),P9e.forEach(t),kQo=i(Ee),Wv=n(Ee,"LI",{});var I9e=s(Wv);Hhe=n(I9e,"STRONG",{});var sgt=s(Hhe);SQo=r(sgt,"data2vec-vision"),sgt.forEach(t),RQo=r(I9e," \u2014 "),GV=n(I9e,"A",{href:!0});var lgt=s(GV);BQo=r(lgt,"Data2VecVisionForImageClassification"),lgt.forEach(t),PQo=r(I9e," (Data2VecVision model)"),I9e.forEach(t),IQo=i(Ee),Bs=n(Ee,"LI",{});var T$=s(Bs);Uhe=n(T$,"STRONG",{});var igt=s(Uhe);qQo=r(igt,"deit"),igt.forEach(t),NQo=r(T$," \u2014 "),OV=n(T$,"A",{href:!0});var dgt=s(OV);jQo=r(dgt,"DeiTForImageClassification"),dgt.forEach(t),DQo=r(T$," or "),VV=n(T$,"A",{href:!0});var cgt=s(VV);GQo=r(cgt,"DeiTForImageClassificationWithTeacher"),cgt.forEach(t),OQo=r(T$," (DeiT model)"),T$.forEach(t),VQo=i(Ee),Hv=n(Ee,"LI",{});var q9e=s(Hv);Jhe=n(q9e,"STRONG",{});var fgt=s(Jhe);XQo=r(fgt,"imagegpt"),fgt.forEach(t),zQo=r(q9e," \u2014 "),XV=n(q9e,"A",{href:!0});var mgt=s(XV);QQo=r(mgt,"ImageGPTForImageClassification"),mgt.forEach(t),WQo=r(q9e," (ImageGPT model)"),q9e.forEach(t),HQo=i(Ee),gt=n(Ee,"LI",{});var mf=s(gt);Yhe=n(mf,"STRONG",{});var ggt=s(Yhe);UQo=r(ggt,"perceiver"),ggt.forEach(t),JQo=r(mf," \u2014 "),zV=n(mf,"A",{href:!0});var hgt=s(zV);YQo=r(hgt,"PerceiverForImageClassificationLearned"),hgt.forEach(t),KQo=r(mf," or "),QV=n(mf,"A",{href:!0});var pgt=s(QV);ZQo=r(pgt,"PerceiverForImageClassificationFourier"),pgt.forEach(t),eWo=r(mf," or "),WV=n(mf,"A",{href:!0});var ugt=s(WV);oWo=r(ugt,"PerceiverForImageClassificationConvProcessing"),ugt.forEach(t),rWo=r(mf," (Perceiver model)"),mf.forEach(t),tWo=i(Ee),Uv=n(Ee,"LI",{});var N9e=s(Uv);Khe=n(N9e,"STRONG",{});var _gt=s(Khe);aWo=r(_gt,"poolformer"),_gt.forEach(t),nWo=r(N9e," \u2014 "),HV=n(N9e,"A",{href:!0});var bgt=s(HV);sWo=r(bgt,"PoolFormerForImageClassification"),bgt.forEach(t),lWo=r(N9e," (PoolFormer model)"),N9e.forEach(t),iWo=i(Ee),Jv=n(Ee,"LI",{});var j9e=s(Jv);Zhe=n(j9e,"STRONG",{});var vgt=s(Zhe);dWo=r(vgt,"regnet"),vgt.forEach(t),cWo=r(j9e," \u2014 "),UV=n(j9e,"A",{href:!0});var Fgt=s(UV);fWo=r(Fgt,"RegNetForImageClassification"),Fgt.forEach(t),mWo=r(j9e," (RegNet model)"),j9e.forEach(t),gWo=i(Ee),Yv=n(Ee,"LI",{});var D9e=s(Yv);epe=n(D9e,"STRONG",{});var Tgt=s(epe);hWo=r(Tgt,"resnet"),Tgt.forEach(t),pWo=r(D9e," \u2014 "),JV=n(D9e,"A",{href:!0});var Mgt=s(JV);uWo=r(Mgt,"ResNetForImageClassification"),Mgt.forEach(t),_Wo=r(D9e," (ResNet model)"),D9e.forEach(t),bWo=i(Ee),Kv=n(Ee,"LI",{});var G9e=s(Kv);ope=n(G9e,"STRONG",{});var Egt=s(ope);vWo=r(Egt,"segformer"),Egt.forEach(t),FWo=r(G9e," \u2014 "),YV=n(G9e,"A",{href:!0});var Cgt=s(YV);TWo=r(Cgt,"SegformerForImageClassification"),Cgt.forEach(t),MWo=r(G9e," (SegFormer model)"),G9e.forEach(t),EWo=i(Ee),Zv=n(Ee,"LI",{});var O9e=s(Zv);rpe=n(O9e,"STRONG",{});var wgt=s(rpe);CWo=r(wgt,"swin"),wgt.forEach(t),wWo=r(O9e," \u2014 "),KV=n(O9e,"A",{href:!0});var Agt=s(KV);AWo=r(Agt,"SwinForImageClassification"),Agt.forEach(t),yWo=r(O9e," (Swin model)"),O9e.forEach(t),LWo=i(Ee),eF=n(Ee,"LI",{});var V9e=s(eF);tpe=n(V9e,"STRONG",{});var ygt=s(tpe);xWo=r(ygt,"van"),ygt.forEach(t),$Wo=r(V9e," \u2014 "),ZV=n(V9e,"A",{href:!0});var Lgt=s(ZV);kWo=r(Lgt,"VanForImageClassification"),Lgt.forEach(t),SWo=r(V9e," (VAN model)"),V9e.forEach(t),RWo=i(Ee),oF=n(Ee,"LI",{});var X9e=s(oF);ape=n(X9e,"STRONG",{});var xgt=s(ape);BWo=r(xgt,"vit"),xgt.forEach(t),PWo=r(X9e," \u2014 "),eX=n(X9e,"A",{href:!0});var $gt=s(eX);IWo=r($gt,"ViTForImageClassification"),$gt.forEach(t),qWo=r(X9e," (ViT model)"),X9e.forEach(t),Ee.forEach(t),NWo=i(ca),rF=n(ca,"P",{});var z9e=s(rF);jWo=r(z9e,"The model is set in evaluation mode by default using "),npe=n(z9e,"CODE",{});var kgt=s(npe);DWo=r(kgt,"model.eval()"),kgt.forEach(t),GWo=r(z9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),spe=n(z9e,"CODE",{});var Sgt=s(spe);OWo=r(Sgt,"model.train()"),Sgt.forEach(t),z9e.forEach(t),VWo=i(ca),T(tF.$$.fragment,ca),ca.forEach(t),Ks.forEach(t),nqe=i(f),ad=n(f,"H2",{class:!0});var dje=s(ad);aF=n(dje,"A",{id:!0,class:!0,href:!0});var Rgt=s(aF);lpe=n(Rgt,"SPAN",{});var Bgt=s(lpe);T(qy.$$.fragment,Bgt),Bgt.forEach(t),Rgt.forEach(t),XWo=i(dje),ipe=n(dje,"SPAN",{});var Pgt=s(ipe);zWo=r(Pgt,"AutoModelForVision2Seq"),Pgt.forEach(t),dje.forEach(t),sqe=i(f),Do=n(f,"DIV",{class:!0});var Zs=s(Do);T(Ny.$$.fragment,Zs),QWo=i(Zs),nd=n(Zs,"P",{});var JK=s(nd);WWo=r(JK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),oX=n(JK,"A",{href:!0});var Igt=s(oX);HWo=r(Igt,"from_pretrained()"),Igt.forEach(t),UWo=r(JK," class method or the "),rX=n(JK,"A",{href:!0});var qgt=s(rX);JWo=r(qgt,"from_config()"),qgt.forEach(t),YWo=r(JK,` class
method.`),JK.forEach(t),KWo=i(Zs),jy=n(Zs,"P",{});var cje=s(jy);ZWo=r(cje,"This class cannot be instantiated directly using "),dpe=n(cje,"CODE",{});var Ngt=s(dpe);eHo=r(Ngt,"__init__()"),Ngt.forEach(t),oHo=r(cje," (throws an error)."),cje.forEach(t),rHo=i(Zs),ht=n(Zs,"DIV",{class:!0});var S3=s(ht);T(Dy.$$.fragment,S3),tHo=i(S3),cpe=n(S3,"P",{});var jgt=s(cpe);aHo=r(jgt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),jgt.forEach(t),nHo=i(S3),sd=n(S3,"P",{});var YK=s(sd);sHo=r(YK,`Note:
Loading a model from its configuration file does `),fpe=n(YK,"STRONG",{});var Dgt=s(fpe);lHo=r(Dgt,"not"),Dgt.forEach(t),iHo=r(YK,` load the model weights. It only affects the
model\u2019s configuration. Use `),tX=n(YK,"A",{href:!0});var Ggt=s(tX);dHo=r(Ggt,"from_pretrained()"),Ggt.forEach(t),cHo=r(YK," to load the model weights."),YK.forEach(t),fHo=i(S3),T(nF.$$.fragment,S3),S3.forEach(t),mHo=i(Zs),so=n(Zs,"DIV",{class:!0});var fa=s(so);T(Gy.$$.fragment,fa),gHo=i(fa),mpe=n(fa,"P",{});var Ogt=s(mpe);hHo=r(Ogt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ogt.forEach(t),pHo=i(fa),Na=n(fa,"P",{});var R3=s(Na);uHo=r(R3,"The model class to instantiate is selected based on the "),gpe=n(R3,"CODE",{});var Vgt=s(gpe);_Ho=r(Vgt,"model_type"),Vgt.forEach(t),bHo=r(R3,` property of the config object (either
passed as an argument or loaded from `),hpe=n(R3,"CODE",{});var Xgt=s(hpe);vHo=r(Xgt,"pretrained_model_name_or_path"),Xgt.forEach(t),FHo=r(R3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ppe=n(R3,"CODE",{});var zgt=s(ppe);THo=r(zgt,"pretrained_model_name_or_path"),zgt.forEach(t),MHo=r(R3,":"),R3.forEach(t),EHo=i(fa),upe=n(fa,"UL",{});var Qgt=s(upe);sF=n(Qgt,"LI",{});var Q9e=s(sF);_pe=n(Q9e,"STRONG",{});var Wgt=s(_pe);CHo=r(Wgt,"vision-encoder-decoder"),Wgt.forEach(t),wHo=r(Q9e," \u2014 "),aX=n(Q9e,"A",{href:!0});var Hgt=s(aX);AHo=r(Hgt,"VisionEncoderDecoderModel"),Hgt.forEach(t),yHo=r(Q9e," (Vision Encoder decoder model)"),Q9e.forEach(t),Qgt.forEach(t),LHo=i(fa),lF=n(fa,"P",{});var W9e=s(lF);xHo=r(W9e,"The model is set in evaluation mode by default using "),bpe=n(W9e,"CODE",{});var Ugt=s(bpe);$Ho=r(Ugt,"model.eval()"),Ugt.forEach(t),kHo=r(W9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vpe=n(W9e,"CODE",{});var Jgt=s(vpe);SHo=r(Jgt,"model.train()"),Jgt.forEach(t),W9e.forEach(t),RHo=i(fa),T(iF.$$.fragment,fa),fa.forEach(t),Zs.forEach(t),lqe=i(f),ld=n(f,"H2",{class:!0});var fje=s(ld);dF=n(fje,"A",{id:!0,class:!0,href:!0});var Ygt=s(dF);Fpe=n(Ygt,"SPAN",{});var Kgt=s(Fpe);T(Oy.$$.fragment,Kgt),Kgt.forEach(t),Ygt.forEach(t),BHo=i(fje),Tpe=n(fje,"SPAN",{});var Zgt=s(Tpe);PHo=r(Zgt,"AutoModelForAudioClassification"),Zgt.forEach(t),fje.forEach(t),iqe=i(f),Go=n(f,"DIV",{class:!0});var el=s(Go);T(Vy.$$.fragment,el),IHo=i(el),id=n(el,"P",{});var KK=s(id);qHo=r(KK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),nX=n(KK,"A",{href:!0});var eht=s(nX);NHo=r(eht,"from_pretrained()"),eht.forEach(t),jHo=r(KK," class method or the "),sX=n(KK,"A",{href:!0});var oht=s(sX);DHo=r(oht,"from_config()"),oht.forEach(t),GHo=r(KK,` class
method.`),KK.forEach(t),OHo=i(el),Xy=n(el,"P",{});var mje=s(Xy);VHo=r(mje,"This class cannot be instantiated directly using "),Mpe=n(mje,"CODE",{});var rht=s(Mpe);XHo=r(rht,"__init__()"),rht.forEach(t),zHo=r(mje," (throws an error)."),mje.forEach(t),QHo=i(el),pt=n(el,"DIV",{class:!0});var B3=s(pt);T(zy.$$.fragment,B3),WHo=i(B3),Epe=n(B3,"P",{});var tht=s(Epe);HHo=r(tht,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),tht.forEach(t),UHo=i(B3),dd=n(B3,"P",{});var ZK=s(dd);JHo=r(ZK,`Note:
Loading a model from its configuration file does `),Cpe=n(ZK,"STRONG",{});var aht=s(Cpe);YHo=r(aht,"not"),aht.forEach(t),KHo=r(ZK,` load the model weights. It only affects the
model\u2019s configuration. Use `),lX=n(ZK,"A",{href:!0});var nht=s(lX);ZHo=r(nht,"from_pretrained()"),nht.forEach(t),eUo=r(ZK," to load the model weights."),ZK.forEach(t),oUo=i(B3),T(cF.$$.fragment,B3),B3.forEach(t),rUo=i(el),lo=n(el,"DIV",{class:!0});var ma=s(lo);T(Qy.$$.fragment,ma),tUo=i(ma),wpe=n(ma,"P",{});var sht=s(wpe);aUo=r(sht,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),sht.forEach(t),nUo=i(ma),ja=n(ma,"P",{});var P3=s(ja);sUo=r(P3,"The model class to instantiate is selected based on the "),Ape=n(P3,"CODE",{});var lht=s(Ape);lUo=r(lht,"model_type"),lht.forEach(t),iUo=r(P3,` property of the config object (either
passed as an argument or loaded from `),ype=n(P3,"CODE",{});var iht=s(ype);dUo=r(iht,"pretrained_model_name_or_path"),iht.forEach(t),cUo=r(P3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lpe=n(P3,"CODE",{});var dht=s(Lpe);fUo=r(dht,"pretrained_model_name_or_path"),dht.forEach(t),mUo=r(P3,":"),P3.forEach(t),gUo=i(ma),Ne=n(ma,"UL",{});var bo=s(Ne);fF=n(bo,"LI",{});var H9e=s(fF);xpe=n(H9e,"STRONG",{});var cht=s(xpe);hUo=r(cht,"data2vec-audio"),cht.forEach(t),pUo=r(H9e," \u2014 "),iX=n(H9e,"A",{href:!0});var fht=s(iX);uUo=r(fht,"Data2VecAudioForSequenceClassification"),fht.forEach(t),_Uo=r(H9e," (Data2VecAudio model)"),H9e.forEach(t),bUo=i(bo),mF=n(bo,"LI",{});var U9e=s(mF);$pe=n(U9e,"STRONG",{});var mht=s($pe);vUo=r(mht,"hubert"),mht.forEach(t),FUo=r(U9e," \u2014 "),dX=n(U9e,"A",{href:!0});var ght=s(dX);TUo=r(ght,"HubertForSequenceClassification"),ght.forEach(t),MUo=r(U9e," (Hubert model)"),U9e.forEach(t),EUo=i(bo),gF=n(bo,"LI",{});var J9e=s(gF);kpe=n(J9e,"STRONG",{});var hht=s(kpe);CUo=r(hht,"sew"),hht.forEach(t),wUo=r(J9e," \u2014 "),cX=n(J9e,"A",{href:!0});var pht=s(cX);AUo=r(pht,"SEWForSequenceClassification"),pht.forEach(t),yUo=r(J9e," (SEW model)"),J9e.forEach(t),LUo=i(bo),hF=n(bo,"LI",{});var Y9e=s(hF);Spe=n(Y9e,"STRONG",{});var uht=s(Spe);xUo=r(uht,"sew-d"),uht.forEach(t),$Uo=r(Y9e," \u2014 "),fX=n(Y9e,"A",{href:!0});var _ht=s(fX);kUo=r(_ht,"SEWDForSequenceClassification"),_ht.forEach(t),SUo=r(Y9e," (SEW-D model)"),Y9e.forEach(t),RUo=i(bo),pF=n(bo,"LI",{});var K9e=s(pF);Rpe=n(K9e,"STRONG",{});var bht=s(Rpe);BUo=r(bht,"unispeech"),bht.forEach(t),PUo=r(K9e," \u2014 "),mX=n(K9e,"A",{href:!0});var vht=s(mX);IUo=r(vht,"UniSpeechForSequenceClassification"),vht.forEach(t),qUo=r(K9e," (UniSpeech model)"),K9e.forEach(t),NUo=i(bo),uF=n(bo,"LI",{});var Z9e=s(uF);Bpe=n(Z9e,"STRONG",{});var Fht=s(Bpe);jUo=r(Fht,"unispeech-sat"),Fht.forEach(t),DUo=r(Z9e," \u2014 "),gX=n(Z9e,"A",{href:!0});var Tht=s(gX);GUo=r(Tht,"UniSpeechSatForSequenceClassification"),Tht.forEach(t),OUo=r(Z9e," (UniSpeechSat model)"),Z9e.forEach(t),VUo=i(bo),_F=n(bo,"LI",{});var e$e=s(_F);Ppe=n(e$e,"STRONG",{});var Mht=s(Ppe);XUo=r(Mht,"wav2vec2"),Mht.forEach(t),zUo=r(e$e," \u2014 "),hX=n(e$e,"A",{href:!0});var Eht=s(hX);QUo=r(Eht,"Wav2Vec2ForSequenceClassification"),Eht.forEach(t),WUo=r(e$e," (Wav2Vec2 model)"),e$e.forEach(t),HUo=i(bo),bF=n(bo,"LI",{});var o$e=s(bF);Ipe=n(o$e,"STRONG",{});var Cht=s(Ipe);UUo=r(Cht,"wavlm"),Cht.forEach(t),JUo=r(o$e," \u2014 "),pX=n(o$e,"A",{href:!0});var wht=s(pX);YUo=r(wht,"WavLMForSequenceClassification"),wht.forEach(t),KUo=r(o$e," (WavLM model)"),o$e.forEach(t),bo.forEach(t),ZUo=i(ma),vF=n(ma,"P",{});var r$e=s(vF);eJo=r(r$e,"The model is set in evaluation mode by default using "),qpe=n(r$e,"CODE",{});var Aht=s(qpe);oJo=r(Aht,"model.eval()"),Aht.forEach(t),rJo=r(r$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Npe=n(r$e,"CODE",{});var yht=s(Npe);tJo=r(yht,"model.train()"),yht.forEach(t),r$e.forEach(t),aJo=i(ma),T(FF.$$.fragment,ma),ma.forEach(t),el.forEach(t),dqe=i(f),cd=n(f,"H2",{class:!0});var gje=s(cd);TF=n(gje,"A",{id:!0,class:!0,href:!0});var Lht=s(TF);jpe=n(Lht,"SPAN",{});var xht=s(jpe);T(Wy.$$.fragment,xht),xht.forEach(t),Lht.forEach(t),nJo=i(gje),Dpe=n(gje,"SPAN",{});var $ht=s(Dpe);sJo=r($ht,"AutoModelForAudioFrameClassification"),$ht.forEach(t),gje.forEach(t),cqe=i(f),Oo=n(f,"DIV",{class:!0});var ol=s(Oo);T(Hy.$$.fragment,ol),lJo=i(ol),fd=n(ol,"P",{});var eZ=s(fd);iJo=r(eZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),uX=n(eZ,"A",{href:!0});var kht=s(uX);dJo=r(kht,"from_pretrained()"),kht.forEach(t),cJo=r(eZ," class method or the "),_X=n(eZ,"A",{href:!0});var Sht=s(_X);fJo=r(Sht,"from_config()"),Sht.forEach(t),mJo=r(eZ,` class
method.`),eZ.forEach(t),gJo=i(ol),Uy=n(ol,"P",{});var hje=s(Uy);hJo=r(hje,"This class cannot be instantiated directly using "),Gpe=n(hje,"CODE",{});var Rht=s(Gpe);pJo=r(Rht,"__init__()"),Rht.forEach(t),uJo=r(hje," (throws an error)."),hje.forEach(t),_Jo=i(ol),ut=n(ol,"DIV",{class:!0});var I3=s(ut);T(Jy.$$.fragment,I3),bJo=i(I3),Ope=n(I3,"P",{});var Bht=s(Ope);vJo=r(Bht,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Bht.forEach(t),FJo=i(I3),md=n(I3,"P",{});var oZ=s(md);TJo=r(oZ,`Note:
Loading a model from its configuration file does `),Vpe=n(oZ,"STRONG",{});var Pht=s(Vpe);MJo=r(Pht,"not"),Pht.forEach(t),EJo=r(oZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),bX=n(oZ,"A",{href:!0});var Iht=s(bX);CJo=r(Iht,"from_pretrained()"),Iht.forEach(t),wJo=r(oZ," to load the model weights."),oZ.forEach(t),AJo=i(I3),T(MF.$$.fragment,I3),I3.forEach(t),yJo=i(ol),io=n(ol,"DIV",{class:!0});var ga=s(io);T(Yy.$$.fragment,ga),LJo=i(ga),Xpe=n(ga,"P",{});var qht=s(Xpe);xJo=r(qht,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),qht.forEach(t),$Jo=i(ga),Da=n(ga,"P",{});var q3=s(Da);kJo=r(q3,"The model class to instantiate is selected based on the "),zpe=n(q3,"CODE",{});var Nht=s(zpe);SJo=r(Nht,"model_type"),Nht.forEach(t),RJo=r(q3,` property of the config object (either
passed as an argument or loaded from `),Qpe=n(q3,"CODE",{});var jht=s(Qpe);BJo=r(jht,"pretrained_model_name_or_path"),jht.forEach(t),PJo=r(q3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wpe=n(q3,"CODE",{});var Dht=s(Wpe);IJo=r(Dht,"pretrained_model_name_or_path"),Dht.forEach(t),qJo=r(q3,":"),q3.forEach(t),NJo=i(ga),Ga=n(ga,"UL",{});var N3=s(Ga);EF=n(N3,"LI",{});var t$e=s(EF);Hpe=n(t$e,"STRONG",{});var Ght=s(Hpe);jJo=r(Ght,"data2vec-audio"),Ght.forEach(t),DJo=r(t$e," \u2014 "),vX=n(t$e,"A",{href:!0});var Oht=s(vX);GJo=r(Oht,"Data2VecAudioForAudioFrameClassification"),Oht.forEach(t),OJo=r(t$e," (Data2VecAudio model)"),t$e.forEach(t),VJo=i(N3),CF=n(N3,"LI",{});var a$e=s(CF);Upe=n(a$e,"STRONG",{});var Vht=s(Upe);XJo=r(Vht,"unispeech-sat"),Vht.forEach(t),zJo=r(a$e," \u2014 "),FX=n(a$e,"A",{href:!0});var Xht=s(FX);QJo=r(Xht,"UniSpeechSatForAudioFrameClassification"),Xht.forEach(t),WJo=r(a$e," (UniSpeechSat model)"),a$e.forEach(t),HJo=i(N3),wF=n(N3,"LI",{});var n$e=s(wF);Jpe=n(n$e,"STRONG",{});var zht=s(Jpe);UJo=r(zht,"wav2vec2"),zht.forEach(t),JJo=r(n$e," \u2014 "),TX=n(n$e,"A",{href:!0});var Qht=s(TX);YJo=r(Qht,"Wav2Vec2ForAudioFrameClassification"),Qht.forEach(t),KJo=r(n$e," (Wav2Vec2 model)"),n$e.forEach(t),ZJo=i(N3),AF=n(N3,"LI",{});var s$e=s(AF);Ype=n(s$e,"STRONG",{});var Wht=s(Ype);eYo=r(Wht,"wavlm"),Wht.forEach(t),oYo=r(s$e," \u2014 "),MX=n(s$e,"A",{href:!0});var Hht=s(MX);rYo=r(Hht,"WavLMForAudioFrameClassification"),Hht.forEach(t),tYo=r(s$e," (WavLM model)"),s$e.forEach(t),N3.forEach(t),aYo=i(ga),yF=n(ga,"P",{});var l$e=s(yF);nYo=r(l$e,"The model is set in evaluation mode by default using "),Kpe=n(l$e,"CODE",{});var Uht=s(Kpe);sYo=r(Uht,"model.eval()"),Uht.forEach(t),lYo=r(l$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=n(l$e,"CODE",{});var Jht=s(Zpe);iYo=r(Jht,"model.train()"),Jht.forEach(t),l$e.forEach(t),dYo=i(ga),T(LF.$$.fragment,ga),ga.forEach(t),ol.forEach(t),fqe=i(f),gd=n(f,"H2",{class:!0});var pje=s(gd);xF=n(pje,"A",{id:!0,class:!0,href:!0});var Yht=s(xF);eue=n(Yht,"SPAN",{});var Kht=s(eue);T(Ky.$$.fragment,Kht),Kht.forEach(t),Yht.forEach(t),cYo=i(pje),oue=n(pje,"SPAN",{});var Zht=s(oue);fYo=r(Zht,"AutoModelForCTC"),Zht.forEach(t),pje.forEach(t),mqe=i(f),Vo=n(f,"DIV",{class:!0});var rl=s(Vo);T(Zy.$$.fragment,rl),mYo=i(rl),hd=n(rl,"P",{});var rZ=s(hd);gYo=r(rZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),EX=n(rZ,"A",{href:!0});var ept=s(EX);hYo=r(ept,"from_pretrained()"),ept.forEach(t),pYo=r(rZ," class method or the "),CX=n(rZ,"A",{href:!0});var opt=s(CX);uYo=r(opt,"from_config()"),opt.forEach(t),_Yo=r(rZ,` class
method.`),rZ.forEach(t),bYo=i(rl),eL=n(rl,"P",{});var uje=s(eL);vYo=r(uje,"This class cannot be instantiated directly using "),rue=n(uje,"CODE",{});var rpt=s(rue);FYo=r(rpt,"__init__()"),rpt.forEach(t),TYo=r(uje," (throws an error)."),uje.forEach(t),MYo=i(rl),_t=n(rl,"DIV",{class:!0});var j3=s(_t);T(oL.$$.fragment,j3),EYo=i(j3),tue=n(j3,"P",{});var tpt=s(tue);CYo=r(tpt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),tpt.forEach(t),wYo=i(j3),pd=n(j3,"P",{});var tZ=s(pd);AYo=r(tZ,`Note:
Loading a model from its configuration file does `),aue=n(tZ,"STRONG",{});var apt=s(aue);yYo=r(apt,"not"),apt.forEach(t),LYo=r(tZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),wX=n(tZ,"A",{href:!0});var npt=s(wX);xYo=r(npt,"from_pretrained()"),npt.forEach(t),$Yo=r(tZ," to load the model weights."),tZ.forEach(t),kYo=i(j3),T($F.$$.fragment,j3),j3.forEach(t),SYo=i(rl),co=n(rl,"DIV",{class:!0});var ha=s(co);T(rL.$$.fragment,ha),RYo=i(ha),nue=n(ha,"P",{});var spt=s(nue);BYo=r(spt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),spt.forEach(t),PYo=i(ha),Oa=n(ha,"P",{});var D3=s(Oa);IYo=r(D3,"The model class to instantiate is selected based on the "),sue=n(D3,"CODE",{});var lpt=s(sue);qYo=r(lpt,"model_type"),lpt.forEach(t),NYo=r(D3,` property of the config object (either
passed as an argument or loaded from `),lue=n(D3,"CODE",{});var ipt=s(lue);jYo=r(ipt,"pretrained_model_name_or_path"),ipt.forEach(t),DYo=r(D3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iue=n(D3,"CODE",{});var dpt=s(iue);GYo=r(dpt,"pretrained_model_name_or_path"),dpt.forEach(t),OYo=r(D3,":"),D3.forEach(t),VYo=i(ha),je=n(ha,"UL",{});var vo=s(je);kF=n(vo,"LI",{});var i$e=s(kF);due=n(i$e,"STRONG",{});var cpt=s(due);XYo=r(cpt,"data2vec-audio"),cpt.forEach(t),zYo=r(i$e," \u2014 "),AX=n(i$e,"A",{href:!0});var fpt=s(AX);QYo=r(fpt,"Data2VecAudioForCTC"),fpt.forEach(t),WYo=r(i$e," (Data2VecAudio model)"),i$e.forEach(t),HYo=i(vo),SF=n(vo,"LI",{});var d$e=s(SF);cue=n(d$e,"STRONG",{});var mpt=s(cue);UYo=r(mpt,"hubert"),mpt.forEach(t),JYo=r(d$e," \u2014 "),yX=n(d$e,"A",{href:!0});var gpt=s(yX);YYo=r(gpt,"HubertForCTC"),gpt.forEach(t),KYo=r(d$e," (Hubert model)"),d$e.forEach(t),ZYo=i(vo),RF=n(vo,"LI",{});var c$e=s(RF);fue=n(c$e,"STRONG",{});var hpt=s(fue);eKo=r(hpt,"sew"),hpt.forEach(t),oKo=r(c$e," \u2014 "),LX=n(c$e,"A",{href:!0});var ppt=s(LX);rKo=r(ppt,"SEWForCTC"),ppt.forEach(t),tKo=r(c$e," (SEW model)"),c$e.forEach(t),aKo=i(vo),BF=n(vo,"LI",{});var f$e=s(BF);mue=n(f$e,"STRONG",{});var upt=s(mue);nKo=r(upt,"sew-d"),upt.forEach(t),sKo=r(f$e," \u2014 "),xX=n(f$e,"A",{href:!0});var _pt=s(xX);lKo=r(_pt,"SEWDForCTC"),_pt.forEach(t),iKo=r(f$e," (SEW-D model)"),f$e.forEach(t),dKo=i(vo),PF=n(vo,"LI",{});var m$e=s(PF);gue=n(m$e,"STRONG",{});var bpt=s(gue);cKo=r(bpt,"unispeech"),bpt.forEach(t),fKo=r(m$e," \u2014 "),$X=n(m$e,"A",{href:!0});var vpt=s($X);mKo=r(vpt,"UniSpeechForCTC"),vpt.forEach(t),gKo=r(m$e," (UniSpeech model)"),m$e.forEach(t),hKo=i(vo),IF=n(vo,"LI",{});var g$e=s(IF);hue=n(g$e,"STRONG",{});var Fpt=s(hue);pKo=r(Fpt,"unispeech-sat"),Fpt.forEach(t),uKo=r(g$e," \u2014 "),kX=n(g$e,"A",{href:!0});var Tpt=s(kX);_Ko=r(Tpt,"UniSpeechSatForCTC"),Tpt.forEach(t),bKo=r(g$e," (UniSpeechSat model)"),g$e.forEach(t),vKo=i(vo),qF=n(vo,"LI",{});var h$e=s(qF);pue=n(h$e,"STRONG",{});var Mpt=s(pue);FKo=r(Mpt,"wav2vec2"),Mpt.forEach(t),TKo=r(h$e," \u2014 "),SX=n(h$e,"A",{href:!0});var Ept=s(SX);MKo=r(Ept,"Wav2Vec2ForCTC"),Ept.forEach(t),EKo=r(h$e," (Wav2Vec2 model)"),h$e.forEach(t),CKo=i(vo),NF=n(vo,"LI",{});var p$e=s(NF);uue=n(p$e,"STRONG",{});var Cpt=s(uue);wKo=r(Cpt,"wavlm"),Cpt.forEach(t),AKo=r(p$e," \u2014 "),RX=n(p$e,"A",{href:!0});var wpt=s(RX);yKo=r(wpt,"WavLMForCTC"),wpt.forEach(t),LKo=r(p$e," (WavLM model)"),p$e.forEach(t),vo.forEach(t),xKo=i(ha),jF=n(ha,"P",{});var u$e=s(jF);$Ko=r(u$e,"The model is set in evaluation mode by default using "),_ue=n(u$e,"CODE",{});var Apt=s(_ue);kKo=r(Apt,"model.eval()"),Apt.forEach(t),SKo=r(u$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=n(u$e,"CODE",{});var ypt=s(bue);RKo=r(ypt,"model.train()"),ypt.forEach(t),u$e.forEach(t),BKo=i(ha),T(DF.$$.fragment,ha),ha.forEach(t),rl.forEach(t),gqe=i(f),ud=n(f,"H2",{class:!0});var _je=s(ud);GF=n(_je,"A",{id:!0,class:!0,href:!0});var Lpt=s(GF);vue=n(Lpt,"SPAN",{});var xpt=s(vue);T(tL.$$.fragment,xpt),xpt.forEach(t),Lpt.forEach(t),PKo=i(_je),Fue=n(_je,"SPAN",{});var $pt=s(Fue);IKo=r($pt,"AutoModelForSpeechSeq2Seq"),$pt.forEach(t),_je.forEach(t),hqe=i(f),Xo=n(f,"DIV",{class:!0});var tl=s(Xo);T(aL.$$.fragment,tl),qKo=i(tl),_d=n(tl,"P",{});var aZ=s(_d);NKo=r(aZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),BX=n(aZ,"A",{href:!0});var kpt=s(BX);jKo=r(kpt,"from_pretrained()"),kpt.forEach(t),DKo=r(aZ," class method or the "),PX=n(aZ,"A",{href:!0});var Spt=s(PX);GKo=r(Spt,"from_config()"),Spt.forEach(t),OKo=r(aZ,` class
method.`),aZ.forEach(t),VKo=i(tl),nL=n(tl,"P",{});var bje=s(nL);XKo=r(bje,"This class cannot be instantiated directly using "),Tue=n(bje,"CODE",{});var Rpt=s(Tue);zKo=r(Rpt,"__init__()"),Rpt.forEach(t),QKo=r(bje," (throws an error)."),bje.forEach(t),WKo=i(tl),bt=n(tl,"DIV",{class:!0});var G3=s(bt);T(sL.$$.fragment,G3),HKo=i(G3),Mue=n(G3,"P",{});var Bpt=s(Mue);UKo=r(Bpt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Bpt.forEach(t),JKo=i(G3),bd=n(G3,"P",{});var nZ=s(bd);YKo=r(nZ,`Note:
Loading a model from its configuration file does `),Eue=n(nZ,"STRONG",{});var Ppt=s(Eue);KKo=r(Ppt,"not"),Ppt.forEach(t),ZKo=r(nZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),IX=n(nZ,"A",{href:!0});var Ipt=s(IX);eZo=r(Ipt,"from_pretrained()"),Ipt.forEach(t),oZo=r(nZ," to load the model weights."),nZ.forEach(t),rZo=i(G3),T(OF.$$.fragment,G3),G3.forEach(t),tZo=i(tl),fo=n(tl,"DIV",{class:!0});var pa=s(fo);T(lL.$$.fragment,pa),aZo=i(pa),Cue=n(pa,"P",{});var qpt=s(Cue);nZo=r(qpt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),qpt.forEach(t),sZo=i(pa),Va=n(pa,"P",{});var O3=s(Va);lZo=r(O3,"The model class to instantiate is selected based on the "),wue=n(O3,"CODE",{});var Npt=s(wue);iZo=r(Npt,"model_type"),Npt.forEach(t),dZo=r(O3,` property of the config object (either
passed as an argument or loaded from `),Aue=n(O3,"CODE",{});var jpt=s(Aue);cZo=r(jpt,"pretrained_model_name_or_path"),jpt.forEach(t),fZo=r(O3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yue=n(O3,"CODE",{});var Dpt=s(yue);mZo=r(Dpt,"pretrained_model_name_or_path"),Dpt.forEach(t),gZo=r(O3,":"),O3.forEach(t),hZo=i(pa),iL=n(pa,"UL",{});var vje=s(iL);VF=n(vje,"LI",{});var _$e=s(VF);Lue=n(_$e,"STRONG",{});var Gpt=s(Lue);pZo=r(Gpt,"speech-encoder-decoder"),Gpt.forEach(t),uZo=r(_$e," \u2014 "),qX=n(_$e,"A",{href:!0});var Opt=s(qX);_Zo=r(Opt,"SpeechEncoderDecoderModel"),Opt.forEach(t),bZo=r(_$e," (Speech Encoder decoder model)"),_$e.forEach(t),vZo=i(vje),XF=n(vje,"LI",{});var b$e=s(XF);xue=n(b$e,"STRONG",{});var Vpt=s(xue);FZo=r(Vpt,"speech_to_text"),Vpt.forEach(t),TZo=r(b$e," \u2014 "),NX=n(b$e,"A",{href:!0});var Xpt=s(NX);MZo=r(Xpt,"Speech2TextForConditionalGeneration"),Xpt.forEach(t),EZo=r(b$e," (Speech2Text model)"),b$e.forEach(t),vje.forEach(t),CZo=i(pa),zF=n(pa,"P",{});var v$e=s(zF);wZo=r(v$e,"The model is set in evaluation mode by default using "),$ue=n(v$e,"CODE",{});var zpt=s($ue);AZo=r(zpt,"model.eval()"),zpt.forEach(t),yZo=r(v$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kue=n(v$e,"CODE",{});var Qpt=s(kue);LZo=r(Qpt,"model.train()"),Qpt.forEach(t),v$e.forEach(t),xZo=i(pa),T(QF.$$.fragment,pa),pa.forEach(t),tl.forEach(t),pqe=i(f),vd=n(f,"H2",{class:!0});var Fje=s(vd);WF=n(Fje,"A",{id:!0,class:!0,href:!0});var Wpt=s(WF);Sue=n(Wpt,"SPAN",{});var Hpt=s(Sue);T(dL.$$.fragment,Hpt),Hpt.forEach(t),Wpt.forEach(t),$Zo=i(Fje),Rue=n(Fje,"SPAN",{});var Upt=s(Rue);kZo=r(Upt,"AutoModelForAudioXVector"),Upt.forEach(t),Fje.forEach(t),uqe=i(f),zo=n(f,"DIV",{class:!0});var al=s(zo);T(cL.$$.fragment,al),SZo=i(al),Fd=n(al,"P",{});var sZ=s(Fd);RZo=r(sZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),jX=n(sZ,"A",{href:!0});var Jpt=s(jX);BZo=r(Jpt,"from_pretrained()"),Jpt.forEach(t),PZo=r(sZ," class method or the "),DX=n(sZ,"A",{href:!0});var Ypt=s(DX);IZo=r(Ypt,"from_config()"),Ypt.forEach(t),qZo=r(sZ,` class
method.`),sZ.forEach(t),NZo=i(al),fL=n(al,"P",{});var Tje=s(fL);jZo=r(Tje,"This class cannot be instantiated directly using "),Bue=n(Tje,"CODE",{});var Kpt=s(Bue);DZo=r(Kpt,"__init__()"),Kpt.forEach(t),GZo=r(Tje," (throws an error)."),Tje.forEach(t),OZo=i(al),vt=n(al,"DIV",{class:!0});var V3=s(vt);T(mL.$$.fragment,V3),VZo=i(V3),Pue=n(V3,"P",{});var Zpt=s(Pue);XZo=r(Zpt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Zpt.forEach(t),zZo=i(V3),Td=n(V3,"P",{});var lZ=s(Td);QZo=r(lZ,`Note:
Loading a model from its configuration file does `),Iue=n(lZ,"STRONG",{});var eut=s(Iue);WZo=r(eut,"not"),eut.forEach(t),HZo=r(lZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),GX=n(lZ,"A",{href:!0});var out=s(GX);UZo=r(out,"from_pretrained()"),out.forEach(t),JZo=r(lZ," to load the model weights."),lZ.forEach(t),YZo=i(V3),T(HF.$$.fragment,V3),V3.forEach(t),KZo=i(al),mo=n(al,"DIV",{class:!0});var ua=s(mo);T(gL.$$.fragment,ua),ZZo=i(ua),que=n(ua,"P",{});var rut=s(que);eer=r(rut,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),rut.forEach(t),oer=i(ua),Xa=n(ua,"P",{});var X3=s(Xa);rer=r(X3,"The model class to instantiate is selected based on the "),Nue=n(X3,"CODE",{});var tut=s(Nue);ter=r(tut,"model_type"),tut.forEach(t),aer=r(X3,` property of the config object (either
passed as an argument or loaded from `),jue=n(X3,"CODE",{});var aut=s(jue);ner=r(aut,"pretrained_model_name_or_path"),aut.forEach(t),ser=r(X3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Due=n(X3,"CODE",{});var nut=s(Due);ler=r(nut,"pretrained_model_name_or_path"),nut.forEach(t),ier=r(X3,":"),X3.forEach(t),der=i(ua),za=n(ua,"UL",{});var z3=s(za);UF=n(z3,"LI",{});var F$e=s(UF);Gue=n(F$e,"STRONG",{});var sut=s(Gue);cer=r(sut,"data2vec-audio"),sut.forEach(t),fer=r(F$e," \u2014 "),OX=n(F$e,"A",{href:!0});var lut=s(OX);mer=r(lut,"Data2VecAudioForXVector"),lut.forEach(t),ger=r(F$e," (Data2VecAudio model)"),F$e.forEach(t),her=i(z3),JF=n(z3,"LI",{});var T$e=s(JF);Oue=n(T$e,"STRONG",{});var iut=s(Oue);per=r(iut,"unispeech-sat"),iut.forEach(t),uer=r(T$e," \u2014 "),VX=n(T$e,"A",{href:!0});var dut=s(VX);_er=r(dut,"UniSpeechSatForXVector"),dut.forEach(t),ber=r(T$e," (UniSpeechSat model)"),T$e.forEach(t),ver=i(z3),YF=n(z3,"LI",{});var M$e=s(YF);Vue=n(M$e,"STRONG",{});var cut=s(Vue);Fer=r(cut,"wav2vec2"),cut.forEach(t),Ter=r(M$e," \u2014 "),XX=n(M$e,"A",{href:!0});var fut=s(XX);Mer=r(fut,"Wav2Vec2ForXVector"),fut.forEach(t),Eer=r(M$e," (Wav2Vec2 model)"),M$e.forEach(t),Cer=i(z3),KF=n(z3,"LI",{});var E$e=s(KF);Xue=n(E$e,"STRONG",{});var mut=s(Xue);wer=r(mut,"wavlm"),mut.forEach(t),Aer=r(E$e," \u2014 "),zX=n(E$e,"A",{href:!0});var gut=s(zX);yer=r(gut,"WavLMForXVector"),gut.forEach(t),Ler=r(E$e," (WavLM model)"),E$e.forEach(t),z3.forEach(t),xer=i(ua),ZF=n(ua,"P",{});var C$e=s(ZF);$er=r(C$e,"The model is set in evaluation mode by default using "),zue=n(C$e,"CODE",{});var hut=s(zue);ker=r(hut,"model.eval()"),hut.forEach(t),Ser=r(C$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Que=n(C$e,"CODE",{});var put=s(Que);Rer=r(put,"model.train()"),put.forEach(t),C$e.forEach(t),Ber=i(ua),T(e6.$$.fragment,ua),ua.forEach(t),al.forEach(t),_qe=i(f),Md=n(f,"H2",{class:!0});var Mje=s(Md);o6=n(Mje,"A",{id:!0,class:!0,href:!0});var uut=s(o6);Wue=n(uut,"SPAN",{});var _ut=s(Wue);T(hL.$$.fragment,_ut),_ut.forEach(t),uut.forEach(t),Per=i(Mje),Hue=n(Mje,"SPAN",{});var but=s(Hue);Ier=r(but,"AutoModelForMaskedImageModeling"),but.forEach(t),Mje.forEach(t),bqe=i(f),Qo=n(f,"DIV",{class:!0});var nl=s(Qo);T(pL.$$.fragment,nl),qer=i(nl),Ed=n(nl,"P",{});var iZ=s(Ed);Ner=r(iZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),QX=n(iZ,"A",{href:!0});var vut=s(QX);jer=r(vut,"from_pretrained()"),vut.forEach(t),Der=r(iZ," class method or the "),WX=n(iZ,"A",{href:!0});var Fut=s(WX);Ger=r(Fut,"from_config()"),Fut.forEach(t),Oer=r(iZ,` class
method.`),iZ.forEach(t),Ver=i(nl),uL=n(nl,"P",{});var Eje=s(uL);Xer=r(Eje,"This class cannot be instantiated directly using "),Uue=n(Eje,"CODE",{});var Tut=s(Uue);zer=r(Tut,"__init__()"),Tut.forEach(t),Qer=r(Eje," (throws an error)."),Eje.forEach(t),Wer=i(nl),Ft=n(nl,"DIV",{class:!0});var Q3=s(Ft);T(_L.$$.fragment,Q3),Her=i(Q3),Jue=n(Q3,"P",{});var Mut=s(Jue);Uer=r(Mut,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Mut.forEach(t),Jer=i(Q3),Cd=n(Q3,"P",{});var dZ=s(Cd);Yer=r(dZ,`Note:
Loading a model from its configuration file does `),Yue=n(dZ,"STRONG",{});var Eut=s(Yue);Ker=r(Eut,"not"),Eut.forEach(t),Zer=r(dZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),HX=n(dZ,"A",{href:!0});var Cut=s(HX);eor=r(Cut,"from_pretrained()"),Cut.forEach(t),oor=r(dZ," to load the model weights."),dZ.forEach(t),ror=i(Q3),T(r6.$$.fragment,Q3),Q3.forEach(t),tor=i(nl),go=n(nl,"DIV",{class:!0});var _a=s(go);T(bL.$$.fragment,_a),aor=i(_a),Kue=n(_a,"P",{});var wut=s(Kue);nor=r(wut,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),wut.forEach(t),sor=i(_a),Qa=n(_a,"P",{});var W3=s(Qa);lor=r(W3,"The model class to instantiate is selected based on the "),Zue=n(W3,"CODE",{});var Aut=s(Zue);ior=r(Aut,"model_type"),Aut.forEach(t),dor=r(W3,` property of the config object (either
passed as an argument or loaded from `),e_e=n(W3,"CODE",{});var yut=s(e_e);cor=r(yut,"pretrained_model_name_or_path"),yut.forEach(t),mor=r(W3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o_e=n(W3,"CODE",{});var Lut=s(o_e);gor=r(Lut,"pretrained_model_name_or_path"),Lut.forEach(t),hor=r(W3,":"),W3.forEach(t),por=i(_a),wd=n(_a,"UL",{});var cZ=s(wd);t6=n(cZ,"LI",{});var w$e=s(t6);r_e=n(w$e,"STRONG",{});var xut=s(r_e);uor=r(xut,"deit"),xut.forEach(t),_or=r(w$e," \u2014 "),UX=n(w$e,"A",{href:!0});var $ut=s(UX);bor=r($ut,"DeiTForMaskedImageModeling"),$ut.forEach(t),vor=r(w$e," (DeiT model)"),w$e.forEach(t),For=i(cZ),a6=n(cZ,"LI",{});var A$e=s(a6);t_e=n(A$e,"STRONG",{});var kut=s(t_e);Tor=r(kut,"swin"),kut.forEach(t),Mor=r(A$e," \u2014 "),JX=n(A$e,"A",{href:!0});var Sut=s(JX);Eor=r(Sut,"SwinForMaskedImageModeling"),Sut.forEach(t),Cor=r(A$e," (Swin model)"),A$e.forEach(t),wor=i(cZ),n6=n(cZ,"LI",{});var y$e=s(n6);a_e=n(y$e,"STRONG",{});var Rut=s(a_e);Aor=r(Rut,"vit"),Rut.forEach(t),yor=r(y$e," \u2014 "),YX=n(y$e,"A",{href:!0});var But=s(YX);Lor=r(But,"ViTForMaskedImageModeling"),But.forEach(t),xor=r(y$e," (ViT model)"),y$e.forEach(t),cZ.forEach(t),$or=i(_a),s6=n(_a,"P",{});var L$e=s(s6);kor=r(L$e,"The model is set in evaluation mode by default using "),n_e=n(L$e,"CODE",{});var Put=s(n_e);Sor=r(Put,"model.eval()"),Put.forEach(t),Ror=r(L$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s_e=n(L$e,"CODE",{});var Iut=s(s_e);Bor=r(Iut,"model.train()"),Iut.forEach(t),L$e.forEach(t),Por=i(_a),T(l6.$$.fragment,_a),_a.forEach(t),nl.forEach(t),vqe=i(f),Ad=n(f,"H2",{class:!0});var Cje=s(Ad);i6=n(Cje,"A",{id:!0,class:!0,href:!0});var qut=s(i6);l_e=n(qut,"SPAN",{});var Nut=s(l_e);T(vL.$$.fragment,Nut),Nut.forEach(t),qut.forEach(t),Ior=i(Cje),i_e=n(Cje,"SPAN",{});var jut=s(i_e);qor=r(jut,"AutoModelForObjectDetection"),jut.forEach(t),Cje.forEach(t),Fqe=i(f),Wo=n(f,"DIV",{class:!0});var sl=s(Wo);T(FL.$$.fragment,sl),Nor=i(sl),yd=n(sl,"P",{});var fZ=s(yd);jor=r(fZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),KX=n(fZ,"A",{href:!0});var Dut=s(KX);Dor=r(Dut,"from_pretrained()"),Dut.forEach(t),Gor=r(fZ," class method or the "),ZX=n(fZ,"A",{href:!0});var Gut=s(ZX);Oor=r(Gut,"from_config()"),Gut.forEach(t),Vor=r(fZ,` class
method.`),fZ.forEach(t),Xor=i(sl),TL=n(sl,"P",{});var wje=s(TL);zor=r(wje,"This class cannot be instantiated directly using "),d_e=n(wje,"CODE",{});var Out=s(d_e);Qor=r(Out,"__init__()"),Out.forEach(t),Wor=r(wje," (throws an error)."),wje.forEach(t),Hor=i(sl),Tt=n(sl,"DIV",{class:!0});var H3=s(Tt);T(ML.$$.fragment,H3),Uor=i(H3),c_e=n(H3,"P",{});var Vut=s(c_e);Jor=r(Vut,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Vut.forEach(t),Yor=i(H3),Ld=n(H3,"P",{});var mZ=s(Ld);Kor=r(mZ,`Note:
Loading a model from its configuration file does `),f_e=n(mZ,"STRONG",{});var Xut=s(f_e);Zor=r(Xut,"not"),Xut.forEach(t),err=r(mZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=n(mZ,"A",{href:!0});var zut=s(ez);orr=r(zut,"from_pretrained()"),zut.forEach(t),rrr=r(mZ," to load the model weights."),mZ.forEach(t),trr=i(H3),T(d6.$$.fragment,H3),H3.forEach(t),arr=i(sl),ho=n(sl,"DIV",{class:!0});var ba=s(ho);T(EL.$$.fragment,ba),nrr=i(ba),m_e=n(ba,"P",{});var Qut=s(m_e);srr=r(Qut,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Qut.forEach(t),lrr=i(ba),Wa=n(ba,"P",{});var U3=s(Wa);irr=r(U3,"The model class to instantiate is selected based on the "),g_e=n(U3,"CODE",{});var Wut=s(g_e);drr=r(Wut,"model_type"),Wut.forEach(t),crr=r(U3,` property of the config object (either
passed as an argument or loaded from `),h_e=n(U3,"CODE",{});var Hut=s(h_e);frr=r(Hut,"pretrained_model_name_or_path"),Hut.forEach(t),mrr=r(U3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p_e=n(U3,"CODE",{});var Uut=s(p_e);grr=r(Uut,"pretrained_model_name_or_path"),Uut.forEach(t),hrr=r(U3,":"),U3.forEach(t),prr=i(ba),CL=n(ba,"UL",{});var Aje=s(CL);c6=n(Aje,"LI",{});var x$e=s(c6);u_e=n(x$e,"STRONG",{});var Jut=s(u_e);urr=r(Jut,"detr"),Jut.forEach(t),_rr=r(x$e," \u2014 "),oz=n(x$e,"A",{href:!0});var Yut=s(oz);brr=r(Yut,"DetrForObjectDetection"),Yut.forEach(t),vrr=r(x$e," (DETR model)"),x$e.forEach(t),Frr=i(Aje),f6=n(Aje,"LI",{});var $$e=s(f6);__e=n($$e,"STRONG",{});var Kut=s(__e);Trr=r(Kut,"yolos"),Kut.forEach(t),Mrr=r($$e," \u2014 "),rz=n($$e,"A",{href:!0});var Zut=s(rz);Err=r(Zut,"YolosForObjectDetection"),Zut.forEach(t),Crr=r($$e," (YOLOS model)"),$$e.forEach(t),Aje.forEach(t),wrr=i(ba),m6=n(ba,"P",{});var k$e=s(m6);Arr=r(k$e,"The model is set in evaluation mode by default using "),b_e=n(k$e,"CODE",{});var e_t=s(b_e);yrr=r(e_t,"model.eval()"),e_t.forEach(t),Lrr=r(k$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v_e=n(k$e,"CODE",{});var o_t=s(v_e);xrr=r(o_t,"model.train()"),o_t.forEach(t),k$e.forEach(t),$rr=i(ba),T(g6.$$.fragment,ba),ba.forEach(t),sl.forEach(t),Tqe=i(f),xd=n(f,"H2",{class:!0});var yje=s(xd);h6=n(yje,"A",{id:!0,class:!0,href:!0});var r_t=s(h6);F_e=n(r_t,"SPAN",{});var t_t=s(F_e);T(wL.$$.fragment,t_t),t_t.forEach(t),r_t.forEach(t),krr=i(yje),T_e=n(yje,"SPAN",{});var a_t=s(T_e);Srr=r(a_t,"AutoModelForImageSegmentation"),a_t.forEach(t),yje.forEach(t),Mqe=i(f),Ho=n(f,"DIV",{class:!0});var ll=s(Ho);T(AL.$$.fragment,ll),Rrr=i(ll),$d=n(ll,"P",{});var gZ=s($d);Brr=r(gZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),tz=n(gZ,"A",{href:!0});var n_t=s(tz);Prr=r(n_t,"from_pretrained()"),n_t.forEach(t),Irr=r(gZ," class method or the "),az=n(gZ,"A",{href:!0});var s_t=s(az);qrr=r(s_t,"from_config()"),s_t.forEach(t),Nrr=r(gZ,` class
method.`),gZ.forEach(t),jrr=i(ll),yL=n(ll,"P",{});var Lje=s(yL);Drr=r(Lje,"This class cannot be instantiated directly using "),M_e=n(Lje,"CODE",{});var l_t=s(M_e);Grr=r(l_t,"__init__()"),l_t.forEach(t),Orr=r(Lje," (throws an error)."),Lje.forEach(t),Vrr=i(ll),Mt=n(ll,"DIV",{class:!0});var J3=s(Mt);T(LL.$$.fragment,J3),Xrr=i(J3),E_e=n(J3,"P",{});var i_t=s(E_e);zrr=r(i_t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),i_t.forEach(t),Qrr=i(J3),kd=n(J3,"P",{});var hZ=s(kd);Wrr=r(hZ,`Note:
Loading a model from its configuration file does `),C_e=n(hZ,"STRONG",{});var d_t=s(C_e);Hrr=r(d_t,"not"),d_t.forEach(t),Urr=r(hZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),nz=n(hZ,"A",{href:!0});var c_t=s(nz);Jrr=r(c_t,"from_pretrained()"),c_t.forEach(t),Yrr=r(hZ," to load the model weights."),hZ.forEach(t),Krr=i(J3),T(p6.$$.fragment,J3),J3.forEach(t),Zrr=i(ll),po=n(ll,"DIV",{class:!0});var va=s(po);T(xL.$$.fragment,va),etr=i(va),w_e=n(va,"P",{});var f_t=s(w_e);otr=r(f_t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),f_t.forEach(t),rtr=i(va),Ha=n(va,"P",{});var Y3=s(Ha);ttr=r(Y3,"The model class to instantiate is selected based on the "),A_e=n(Y3,"CODE",{});var m_t=s(A_e);atr=r(m_t,"model_type"),m_t.forEach(t),ntr=r(Y3,` property of the config object (either
passed as an argument or loaded from `),y_e=n(Y3,"CODE",{});var g_t=s(y_e);str=r(g_t,"pretrained_model_name_or_path"),g_t.forEach(t),ltr=r(Y3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L_e=n(Y3,"CODE",{});var h_t=s(L_e);itr=r(h_t,"pretrained_model_name_or_path"),h_t.forEach(t),dtr=r(Y3,":"),Y3.forEach(t),ctr=i(va),x_e=n(va,"UL",{});var p_t=s(x_e);u6=n(p_t,"LI",{});var S$e=s(u6);$_e=n(S$e,"STRONG",{});var u_t=s($_e);ftr=r(u_t,"detr"),u_t.forEach(t),mtr=r(S$e," \u2014 "),sz=n(S$e,"A",{href:!0});var __t=s(sz);gtr=r(__t,"DetrForSegmentation"),__t.forEach(t),htr=r(S$e," (DETR model)"),S$e.forEach(t),p_t.forEach(t),ptr=i(va),_6=n(va,"P",{});var R$e=s(_6);utr=r(R$e,"The model is set in evaluation mode by default using "),k_e=n(R$e,"CODE",{});var b_t=s(k_e);_tr=r(b_t,"model.eval()"),b_t.forEach(t),btr=r(R$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S_e=n(R$e,"CODE",{});var v_t=s(S_e);vtr=r(v_t,"model.train()"),v_t.forEach(t),R$e.forEach(t),Ftr=i(va),T(b6.$$.fragment,va),va.forEach(t),ll.forEach(t),Eqe=i(f),Sd=n(f,"H2",{class:!0});var xje=s(Sd);v6=n(xje,"A",{id:!0,class:!0,href:!0});var F_t=s(v6);R_e=n(F_t,"SPAN",{});var T_t=s(R_e);T($L.$$.fragment,T_t),T_t.forEach(t),F_t.forEach(t),Ttr=i(xje),B_e=n(xje,"SPAN",{});var M_t=s(B_e);Mtr=r(M_t,"AutoModelForSemanticSegmentation"),M_t.forEach(t),xje.forEach(t),Cqe=i(f),Uo=n(f,"DIV",{class:!0});var il=s(Uo);T(kL.$$.fragment,il),Etr=i(il),Rd=n(il,"P",{});var pZ=s(Rd);Ctr=r(pZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),lz=n(pZ,"A",{href:!0});var E_t=s(lz);wtr=r(E_t,"from_pretrained()"),E_t.forEach(t),Atr=r(pZ," class method or the "),iz=n(pZ,"A",{href:!0});var C_t=s(iz);ytr=r(C_t,"from_config()"),C_t.forEach(t),Ltr=r(pZ,` class
method.`),pZ.forEach(t),xtr=i(il),SL=n(il,"P",{});var $je=s(SL);$tr=r($je,"This class cannot be instantiated directly using "),P_e=n($je,"CODE",{});var w_t=s(P_e);ktr=r(w_t,"__init__()"),w_t.forEach(t),Str=r($je," (throws an error)."),$je.forEach(t),Rtr=i(il),Et=n(il,"DIV",{class:!0});var K3=s(Et);T(RL.$$.fragment,K3),Btr=i(K3),I_e=n(K3,"P",{});var A_t=s(I_e);Ptr=r(A_t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),A_t.forEach(t),Itr=i(K3),Bd=n(K3,"P",{});var uZ=s(Bd);qtr=r(uZ,`Note:
Loading a model from its configuration file does `),q_e=n(uZ,"STRONG",{});var y_t=s(q_e);Ntr=r(y_t,"not"),y_t.forEach(t),jtr=r(uZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),dz=n(uZ,"A",{href:!0});var L_t=s(dz);Dtr=r(L_t,"from_pretrained()"),L_t.forEach(t),Gtr=r(uZ," to load the model weights."),uZ.forEach(t),Otr=i(K3),T(F6.$$.fragment,K3),K3.forEach(t),Vtr=i(il),uo=n(il,"DIV",{class:!0});var Fa=s(uo);T(BL.$$.fragment,Fa),Xtr=i(Fa),N_e=n(Fa,"P",{});var x_t=s(N_e);ztr=r(x_t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),x_t.forEach(t),Qtr=i(Fa),Ua=n(Fa,"P",{});var Z3=s(Ua);Wtr=r(Z3,"The model class to instantiate is selected based on the "),j_e=n(Z3,"CODE",{});var $_t=s(j_e);Htr=r($_t,"model_type"),$_t.forEach(t),Utr=r(Z3,` property of the config object (either
passed as an argument or loaded from `),D_e=n(Z3,"CODE",{});var k_t=s(D_e);Jtr=r(k_t,"pretrained_model_name_or_path"),k_t.forEach(t),Ytr=r(Z3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G_e=n(Z3,"CODE",{});var S_t=s(G_e);Ktr=r(S_t,"pretrained_model_name_or_path"),S_t.forEach(t),Ztr=r(Z3,":"),Z3.forEach(t),ear=i(Fa),Ja=n(Fa,"UL",{});var ew=s(Ja);T6=n(ew,"LI",{});var B$e=s(T6);O_e=n(B$e,"STRONG",{});var R_t=s(O_e);oar=r(R_t,"beit"),R_t.forEach(t),rar=r(B$e," \u2014 "),cz=n(B$e,"A",{href:!0});var B_t=s(cz);tar=r(B_t,"BeitForSemanticSegmentation"),B_t.forEach(t),aar=r(B$e," (BEiT model)"),B$e.forEach(t),nar=i(ew),M6=n(ew,"LI",{});var P$e=s(M6);V_e=n(P$e,"STRONG",{});var P_t=s(V_e);sar=r(P_t,"data2vec-vision"),P_t.forEach(t),lar=r(P$e," \u2014 "),fz=n(P$e,"A",{href:!0});var I_t=s(fz);iar=r(I_t,"Data2VecVisionForSemanticSegmentation"),I_t.forEach(t),dar=r(P$e," (Data2VecVision model)"),P$e.forEach(t),car=i(ew),E6=n(ew,"LI",{});var I$e=s(E6);X_e=n(I$e,"STRONG",{});var q_t=s(X_e);far=r(q_t,"dpt"),q_t.forEach(t),mar=r(I$e," \u2014 "),mz=n(I$e,"A",{href:!0});var N_t=s(mz);gar=r(N_t,"DPTForSemanticSegmentation"),N_t.forEach(t),har=r(I$e," (DPT model)"),I$e.forEach(t),par=i(ew),C6=n(ew,"LI",{});var q$e=s(C6);z_e=n(q$e,"STRONG",{});var j_t=s(z_e);uar=r(j_t,"segformer"),j_t.forEach(t),_ar=r(q$e," \u2014 "),gz=n(q$e,"A",{href:!0});var D_t=s(gz);bar=r(D_t,"SegformerForSemanticSegmentation"),D_t.forEach(t),Far=r(q$e," (SegFormer model)"),q$e.forEach(t),ew.forEach(t),Tar=i(Fa),w6=n(Fa,"P",{});var N$e=s(w6);Mar=r(N$e,"The model is set in evaluation mode by default using "),Q_e=n(N$e,"CODE",{});var G_t=s(Q_e);Ear=r(G_t,"model.eval()"),G_t.forEach(t),Car=r(N$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W_e=n(N$e,"CODE",{});var O_t=s(W_e);war=r(O_t,"model.train()"),O_t.forEach(t),N$e.forEach(t),Aar=i(Fa),T(A6.$$.fragment,Fa),Fa.forEach(t),il.forEach(t),wqe=i(f),Pd=n(f,"H2",{class:!0});var kje=s(Pd);y6=n(kje,"A",{id:!0,class:!0,href:!0});var V_t=s(y6);H_e=n(V_t,"SPAN",{});var X_t=s(H_e);T(PL.$$.fragment,X_t),X_t.forEach(t),V_t.forEach(t),yar=i(kje),U_e=n(kje,"SPAN",{});var z_t=s(U_e);Lar=r(z_t,"AutoModelForInstanceSegmentation"),z_t.forEach(t),kje.forEach(t),Aqe=i(f),Jo=n(f,"DIV",{class:!0});var dl=s(Jo);T(IL.$$.fragment,dl),xar=i(dl),Id=n(dl,"P",{});var _Z=s(Id);$ar=r(_Z,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),hz=n(_Z,"A",{href:!0});var Q_t=s(hz);kar=r(Q_t,"from_pretrained()"),Q_t.forEach(t),Sar=r(_Z," class method or the "),pz=n(_Z,"A",{href:!0});var W_t=s(pz);Rar=r(W_t,"from_config()"),W_t.forEach(t),Bar=r(_Z,` class
method.`),_Z.forEach(t),Par=i(dl),qL=n(dl,"P",{});var Sje=s(qL);Iar=r(Sje,"This class cannot be instantiated directly using "),J_e=n(Sje,"CODE",{});var H_t=s(J_e);qar=r(H_t,"__init__()"),H_t.forEach(t),Nar=r(Sje," (throws an error)."),Sje.forEach(t),jar=i(dl),Ct=n(dl,"DIV",{class:!0});var ow=s(Ct);T(NL.$$.fragment,ow),Dar=i(ow),Y_e=n(ow,"P",{});var U_t=s(Y_e);Gar=r(U_t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),U_t.forEach(t),Oar=i(ow),qd=n(ow,"P",{});var bZ=s(qd);Var=r(bZ,`Note:
Loading a model from its configuration file does `),K_e=n(bZ,"STRONG",{});var J_t=s(K_e);Xar=r(J_t,"not"),J_t.forEach(t),zar=r(bZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),uz=n(bZ,"A",{href:!0});var Y_t=s(uz);Qar=r(Y_t,"from_pretrained()"),Y_t.forEach(t),War=r(bZ," to load the model weights."),bZ.forEach(t),Har=i(ow),T(L6.$$.fragment,ow),ow.forEach(t),Uar=i(dl),_o=n(dl,"DIV",{class:!0});var Ta=s(_o);T(jL.$$.fragment,Ta),Jar=i(Ta),Z_e=n(Ta,"P",{});var K_t=s(Z_e);Yar=r(K_t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),K_t.forEach(t),Kar=i(Ta),Ya=n(Ta,"P",{});var rw=s(Ya);Zar=r(rw,"The model class to instantiate is selected based on the "),e0e=n(rw,"CODE",{});var Z_t=s(e0e);enr=r(Z_t,"model_type"),Z_t.forEach(t),onr=r(rw,` property of the config object (either
passed as an argument or loaded from `),o0e=n(rw,"CODE",{});var e0t=s(o0e);rnr=r(e0t,"pretrained_model_name_or_path"),e0t.forEach(t),tnr=r(rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=n(rw,"CODE",{});var o0t=s(r0e);anr=r(o0t,"pretrained_model_name_or_path"),o0t.forEach(t),nnr=r(rw,":"),rw.forEach(t),snr=i(Ta),t0e=n(Ta,"UL",{});var r0t=s(t0e);x6=n(r0t,"LI",{});var j$e=s(x6);a0e=n(j$e,"STRONG",{});var t0t=s(a0e);lnr=r(t0t,"maskformer"),t0t.forEach(t),inr=r(j$e," \u2014 "),_z=n(j$e,"A",{href:!0});var a0t=s(_z);dnr=r(a0t,"MaskFormerForInstanceSegmentation"),a0t.forEach(t),cnr=r(j$e," (MaskFormer model)"),j$e.forEach(t),r0t.forEach(t),fnr=i(Ta),$6=n(Ta,"P",{});var D$e=s($6);mnr=r(D$e,"The model is set in evaluation mode by default using "),n0e=n(D$e,"CODE",{});var n0t=s(n0e);gnr=r(n0t,"model.eval()"),n0t.forEach(t),hnr=r(D$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s0e=n(D$e,"CODE",{});var s0t=s(s0e);pnr=r(s0t,"model.train()"),s0t.forEach(t),D$e.forEach(t),unr=i(Ta),T(k6.$$.fragment,Ta),Ta.forEach(t),dl.forEach(t),yqe=i(f),Nd=n(f,"H2",{class:!0});var Rje=s(Nd);S6=n(Rje,"A",{id:!0,class:!0,href:!0});var l0t=s(S6);l0e=n(l0t,"SPAN",{});var i0t=s(l0e);T(DL.$$.fragment,i0t),i0t.forEach(t),l0t.forEach(t),_nr=i(Rje),i0e=n(Rje,"SPAN",{});var d0t=s(i0e);bnr=r(d0t,"TFAutoModel"),d0t.forEach(t),Rje.forEach(t),Lqe=i(f),Yo=n(f,"DIV",{class:!0});var cl=s(Yo);T(GL.$$.fragment,cl),vnr=i(cl),jd=n(cl,"P",{});var vZ=s(jd);Fnr=r(vZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),bz=n(vZ,"A",{href:!0});var c0t=s(bz);Tnr=r(c0t,"from_pretrained()"),c0t.forEach(t),Mnr=r(vZ," class method or the "),vz=n(vZ,"A",{href:!0});var f0t=s(vz);Enr=r(f0t,"from_config()"),f0t.forEach(t),Cnr=r(vZ,` class
method.`),vZ.forEach(t),wnr=i(cl),OL=n(cl,"P",{});var Bje=s(OL);Anr=r(Bje,"This class cannot be instantiated directly using "),d0e=n(Bje,"CODE",{});var m0t=s(d0e);ynr=r(m0t,"__init__()"),m0t.forEach(t),Lnr=r(Bje," (throws an error)."),Bje.forEach(t),xnr=i(cl),wt=n(cl,"DIV",{class:!0});var tw=s(wt);T(VL.$$.fragment,tw),$nr=i(tw),c0e=n(tw,"P",{});var g0t=s(c0e);knr=r(g0t,"Instantiates one of the base model classes of the library from a configuration."),g0t.forEach(t),Snr=i(tw),Dd=n(tw,"P",{});var FZ=s(Dd);Rnr=r(FZ,`Note:
Loading a model from its configuration file does `),f0e=n(FZ,"STRONG",{});var h0t=s(f0e);Bnr=r(h0t,"not"),h0t.forEach(t),Pnr=r(FZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(FZ,"A",{href:!0});var p0t=s(Fz);Inr=r(p0t,"from_pretrained()"),p0t.forEach(t),qnr=r(FZ," to load the model weights."),FZ.forEach(t),Nnr=i(tw),T(R6.$$.fragment,tw),tw.forEach(t),jnr=i(cl),wr=n(cl,"DIV",{class:!0});var fl=s(wr);T(XL.$$.fragment,fl),Dnr=i(fl),m0e=n(fl,"P",{});var u0t=s(m0e);Gnr=r(u0t,"Instantiate one of the base model classes of the library from a pretrained model."),u0t.forEach(t),Onr=i(fl),Ka=n(fl,"P",{});var aw=s(Ka);Vnr=r(aw,"The model class to instantiate is selected based on the "),g0e=n(aw,"CODE",{});var _0t=s(g0e);Xnr=r(_0t,"model_type"),_0t.forEach(t),znr=r(aw,` property of the config object (either
passed as an argument or loaded from `),h0e=n(aw,"CODE",{});var b0t=s(h0e);Qnr=r(b0t,"pretrained_model_name_or_path"),b0t.forEach(t),Wnr=r(aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=n(aw,"CODE",{});var v0t=s(p0e);Hnr=r(v0t,"pretrained_model_name_or_path"),v0t.forEach(t),Unr=r(aw,":"),aw.forEach(t),Jnr=i(fl),j=n(fl,"UL",{});var D=s(j);B6=n(D,"LI",{});var G$e=s(B6);u0e=n(G$e,"STRONG",{});var F0t=s(u0e);Ynr=r(F0t,"albert"),F0t.forEach(t),Knr=r(G$e," \u2014 "),Tz=n(G$e,"A",{href:!0});var T0t=s(Tz);Znr=r(T0t,"TFAlbertModel"),T0t.forEach(t),esr=r(G$e," (ALBERT model)"),G$e.forEach(t),osr=i(D),P6=n(D,"LI",{});var O$e=s(P6);_0e=n(O$e,"STRONG",{});var M0t=s(_0e);rsr=r(M0t,"bart"),M0t.forEach(t),tsr=r(O$e," \u2014 "),Mz=n(O$e,"A",{href:!0});var E0t=s(Mz);asr=r(E0t,"TFBartModel"),E0t.forEach(t),nsr=r(O$e," (BART model)"),O$e.forEach(t),ssr=i(D),I6=n(D,"LI",{});var V$e=s(I6);b0e=n(V$e,"STRONG",{});var C0t=s(b0e);lsr=r(C0t,"bert"),C0t.forEach(t),isr=r(V$e," \u2014 "),Ez=n(V$e,"A",{href:!0});var w0t=s(Ez);dsr=r(w0t,"TFBertModel"),w0t.forEach(t),csr=r(V$e," (BERT model)"),V$e.forEach(t),fsr=i(D),q6=n(D,"LI",{});var X$e=s(q6);v0e=n(X$e,"STRONG",{});var A0t=s(v0e);msr=r(A0t,"blenderbot"),A0t.forEach(t),gsr=r(X$e," \u2014 "),Cz=n(X$e,"A",{href:!0});var y0t=s(Cz);hsr=r(y0t,"TFBlenderbotModel"),y0t.forEach(t),psr=r(X$e," (Blenderbot model)"),X$e.forEach(t),usr=i(D),N6=n(D,"LI",{});var z$e=s(N6);F0e=n(z$e,"STRONG",{});var L0t=s(F0e);_sr=r(L0t,"blenderbot-small"),L0t.forEach(t),bsr=r(z$e," \u2014 "),wz=n(z$e,"A",{href:!0});var x0t=s(wz);vsr=r(x0t,"TFBlenderbotSmallModel"),x0t.forEach(t),Fsr=r(z$e," (BlenderbotSmall model)"),z$e.forEach(t),Tsr=i(D),j6=n(D,"LI",{});var Q$e=s(j6);T0e=n(Q$e,"STRONG",{});var $0t=s(T0e);Msr=r($0t,"camembert"),$0t.forEach(t),Esr=r(Q$e," \u2014 "),Az=n(Q$e,"A",{href:!0});var k0t=s(Az);Csr=r(k0t,"TFCamembertModel"),k0t.forEach(t),wsr=r(Q$e," (CamemBERT model)"),Q$e.forEach(t),Asr=i(D),D6=n(D,"LI",{});var W$e=s(D6);M0e=n(W$e,"STRONG",{});var S0t=s(M0e);ysr=r(S0t,"clip"),S0t.forEach(t),Lsr=r(W$e," \u2014 "),yz=n(W$e,"A",{href:!0});var R0t=s(yz);xsr=r(R0t,"TFCLIPModel"),R0t.forEach(t),$sr=r(W$e," (CLIP model)"),W$e.forEach(t),ksr=i(D),G6=n(D,"LI",{});var H$e=s(G6);E0e=n(H$e,"STRONG",{});var B0t=s(E0e);Ssr=r(B0t,"convbert"),B0t.forEach(t),Rsr=r(H$e," \u2014 "),Lz=n(H$e,"A",{href:!0});var P0t=s(Lz);Bsr=r(P0t,"TFConvBertModel"),P0t.forEach(t),Psr=r(H$e," (ConvBERT model)"),H$e.forEach(t),Isr=i(D),O6=n(D,"LI",{});var U$e=s(O6);C0e=n(U$e,"STRONG",{});var I0t=s(C0e);qsr=r(I0t,"convnext"),I0t.forEach(t),Nsr=r(U$e," \u2014 "),xz=n(U$e,"A",{href:!0});var q0t=s(xz);jsr=r(q0t,"TFConvNextModel"),q0t.forEach(t),Dsr=r(U$e," (ConvNext model)"),U$e.forEach(t),Gsr=i(D),V6=n(D,"LI",{});var J$e=s(V6);w0e=n(J$e,"STRONG",{});var N0t=s(w0e);Osr=r(N0t,"ctrl"),N0t.forEach(t),Vsr=r(J$e," \u2014 "),$z=n(J$e,"A",{href:!0});var j0t=s($z);Xsr=r(j0t,"TFCTRLModel"),j0t.forEach(t),zsr=r(J$e," (CTRL model)"),J$e.forEach(t),Qsr=i(D),X6=n(D,"LI",{});var Y$e=s(X6);A0e=n(Y$e,"STRONG",{});var D0t=s(A0e);Wsr=r(D0t,"data2vec-vision"),D0t.forEach(t),Hsr=r(Y$e," \u2014 "),kz=n(Y$e,"A",{href:!0});var G0t=s(kz);Usr=r(G0t,"TFData2VecVisionModel"),G0t.forEach(t),Jsr=r(Y$e," (Data2VecVision model)"),Y$e.forEach(t),Ysr=i(D),z6=n(D,"LI",{});var K$e=s(z6);y0e=n(K$e,"STRONG",{});var O0t=s(y0e);Ksr=r(O0t,"deberta"),O0t.forEach(t),Zsr=r(K$e," \u2014 "),Sz=n(K$e,"A",{href:!0});var V0t=s(Sz);elr=r(V0t,"TFDebertaModel"),V0t.forEach(t),olr=r(K$e," (DeBERTa model)"),K$e.forEach(t),rlr=i(D),Q6=n(D,"LI",{});var Z$e=s(Q6);L0e=n(Z$e,"STRONG",{});var X0t=s(L0e);tlr=r(X0t,"deberta-v2"),X0t.forEach(t),alr=r(Z$e," \u2014 "),Rz=n(Z$e,"A",{href:!0});var z0t=s(Rz);nlr=r(z0t,"TFDebertaV2Model"),z0t.forEach(t),slr=r(Z$e," (DeBERTa-v2 model)"),Z$e.forEach(t),llr=i(D),W6=n(D,"LI",{});var eke=s(W6);x0e=n(eke,"STRONG",{});var Q0t=s(x0e);ilr=r(Q0t,"distilbert"),Q0t.forEach(t),dlr=r(eke," \u2014 "),Bz=n(eke,"A",{href:!0});var W0t=s(Bz);clr=r(W0t,"TFDistilBertModel"),W0t.forEach(t),flr=r(eke," (DistilBERT model)"),eke.forEach(t),mlr=i(D),H6=n(D,"LI",{});var oke=s(H6);$0e=n(oke,"STRONG",{});var H0t=s($0e);glr=r(H0t,"dpr"),H0t.forEach(t),hlr=r(oke," \u2014 "),Pz=n(oke,"A",{href:!0});var U0t=s(Pz);plr=r(U0t,"TFDPRQuestionEncoder"),U0t.forEach(t),ulr=r(oke," (DPR model)"),oke.forEach(t),_lr=i(D),U6=n(D,"LI",{});var rke=s(U6);k0e=n(rke,"STRONG",{});var J0t=s(k0e);blr=r(J0t,"electra"),J0t.forEach(t),vlr=r(rke," \u2014 "),Iz=n(rke,"A",{href:!0});var Y0t=s(Iz);Flr=r(Y0t,"TFElectraModel"),Y0t.forEach(t),Tlr=r(rke," (ELECTRA model)"),rke.forEach(t),Mlr=i(D),J6=n(D,"LI",{});var tke=s(J6);S0e=n(tke,"STRONG",{});var K0t=s(S0e);Elr=r(K0t,"flaubert"),K0t.forEach(t),Clr=r(tke," \u2014 "),qz=n(tke,"A",{href:!0});var Z0t=s(qz);wlr=r(Z0t,"TFFlaubertModel"),Z0t.forEach(t),Alr=r(tke," (FlauBERT model)"),tke.forEach(t),ylr=i(D),Ps=n(D,"LI",{});var M$=s(Ps);R0e=n(M$,"STRONG",{});var e1t=s(R0e);Llr=r(e1t,"funnel"),e1t.forEach(t),xlr=r(M$," \u2014 "),Nz=n(M$,"A",{href:!0});var o1t=s(Nz);$lr=r(o1t,"TFFunnelModel"),o1t.forEach(t),klr=r(M$," or "),jz=n(M$,"A",{href:!0});var r1t=s(jz);Slr=r(r1t,"TFFunnelBaseModel"),r1t.forEach(t),Rlr=r(M$," (Funnel Transformer model)"),M$.forEach(t),Blr=i(D),Y6=n(D,"LI",{});var ake=s(Y6);B0e=n(ake,"STRONG",{});var t1t=s(B0e);Plr=r(t1t,"gpt2"),t1t.forEach(t),Ilr=r(ake," \u2014 "),Dz=n(ake,"A",{href:!0});var a1t=s(Dz);qlr=r(a1t,"TFGPT2Model"),a1t.forEach(t),Nlr=r(ake," (OpenAI GPT-2 model)"),ake.forEach(t),jlr=i(D),K6=n(D,"LI",{});var nke=s(K6);P0e=n(nke,"STRONG",{});var n1t=s(P0e);Dlr=r(n1t,"gptj"),n1t.forEach(t),Glr=r(nke," \u2014 "),Gz=n(nke,"A",{href:!0});var s1t=s(Gz);Olr=r(s1t,"TFGPTJModel"),s1t.forEach(t),Vlr=r(nke," (GPT-J model)"),nke.forEach(t),Xlr=i(D),Z6=n(D,"LI",{});var ske=s(Z6);I0e=n(ske,"STRONG",{});var l1t=s(I0e);zlr=r(l1t,"hubert"),l1t.forEach(t),Qlr=r(ske," \u2014 "),Oz=n(ske,"A",{href:!0});var i1t=s(Oz);Wlr=r(i1t,"TFHubertModel"),i1t.forEach(t),Hlr=r(ske," (Hubert model)"),ske.forEach(t),Ulr=i(D),eT=n(D,"LI",{});var lke=s(eT);q0e=n(lke,"STRONG",{});var d1t=s(q0e);Jlr=r(d1t,"layoutlm"),d1t.forEach(t),Ylr=r(lke," \u2014 "),Vz=n(lke,"A",{href:!0});var c1t=s(Vz);Klr=r(c1t,"TFLayoutLMModel"),c1t.forEach(t),Zlr=r(lke," (LayoutLM model)"),lke.forEach(t),eir=i(D),oT=n(D,"LI",{});var ike=s(oT);N0e=n(ike,"STRONG",{});var f1t=s(N0e);oir=r(f1t,"led"),f1t.forEach(t),rir=r(ike," \u2014 "),Xz=n(ike,"A",{href:!0});var m1t=s(Xz);tir=r(m1t,"TFLEDModel"),m1t.forEach(t),air=r(ike," (LED model)"),ike.forEach(t),nir=i(D),rT=n(D,"LI",{});var dke=s(rT);j0e=n(dke,"STRONG",{});var g1t=s(j0e);sir=r(g1t,"longformer"),g1t.forEach(t),lir=r(dke," \u2014 "),zz=n(dke,"A",{href:!0});var h1t=s(zz);iir=r(h1t,"TFLongformerModel"),h1t.forEach(t),dir=r(dke," (Longformer model)"),dke.forEach(t),cir=i(D),tT=n(D,"LI",{});var cke=s(tT);D0e=n(cke,"STRONG",{});var p1t=s(D0e);fir=r(p1t,"lxmert"),p1t.forEach(t),mir=r(cke," \u2014 "),Qz=n(cke,"A",{href:!0});var u1t=s(Qz);gir=r(u1t,"TFLxmertModel"),u1t.forEach(t),hir=r(cke," (LXMERT model)"),cke.forEach(t),pir=i(D),aT=n(D,"LI",{});var fke=s(aT);G0e=n(fke,"STRONG",{});var _1t=s(G0e);uir=r(_1t,"marian"),_1t.forEach(t),_ir=r(fke," \u2014 "),Wz=n(fke,"A",{href:!0});var b1t=s(Wz);bir=r(b1t,"TFMarianModel"),b1t.forEach(t),vir=r(fke," (Marian model)"),fke.forEach(t),Fir=i(D),nT=n(D,"LI",{});var mke=s(nT);O0e=n(mke,"STRONG",{});var v1t=s(O0e);Tir=r(v1t,"mbart"),v1t.forEach(t),Mir=r(mke," \u2014 "),Hz=n(mke,"A",{href:!0});var F1t=s(Hz);Eir=r(F1t,"TFMBartModel"),F1t.forEach(t),Cir=r(mke," (mBART model)"),mke.forEach(t),wir=i(D),sT=n(D,"LI",{});var gke=s(sT);V0e=n(gke,"STRONG",{});var T1t=s(V0e);Air=r(T1t,"mobilebert"),T1t.forEach(t),yir=r(gke," \u2014 "),Uz=n(gke,"A",{href:!0});var M1t=s(Uz);Lir=r(M1t,"TFMobileBertModel"),M1t.forEach(t),xir=r(gke," (MobileBERT model)"),gke.forEach(t),$ir=i(D),lT=n(D,"LI",{});var hke=s(lT);X0e=n(hke,"STRONG",{});var E1t=s(X0e);kir=r(E1t,"mpnet"),E1t.forEach(t),Sir=r(hke," \u2014 "),Jz=n(hke,"A",{href:!0});var C1t=s(Jz);Rir=r(C1t,"TFMPNetModel"),C1t.forEach(t),Bir=r(hke," (MPNet model)"),hke.forEach(t),Pir=i(D),iT=n(D,"LI",{});var pke=s(iT);z0e=n(pke,"STRONG",{});var w1t=s(z0e);Iir=r(w1t,"mt5"),w1t.forEach(t),qir=r(pke," \u2014 "),Yz=n(pke,"A",{href:!0});var A1t=s(Yz);Nir=r(A1t,"TFMT5Model"),A1t.forEach(t),jir=r(pke," (mT5 model)"),pke.forEach(t),Dir=i(D),dT=n(D,"LI",{});var uke=s(dT);Q0e=n(uke,"STRONG",{});var y1t=s(Q0e);Gir=r(y1t,"openai-gpt"),y1t.forEach(t),Oir=r(uke," \u2014 "),Kz=n(uke,"A",{href:!0});var L1t=s(Kz);Vir=r(L1t,"TFOpenAIGPTModel"),L1t.forEach(t),Xir=r(uke," (OpenAI GPT model)"),uke.forEach(t),zir=i(D),cT=n(D,"LI",{});var _ke=s(cT);W0e=n(_ke,"STRONG",{});var x1t=s(W0e);Qir=r(x1t,"pegasus"),x1t.forEach(t),Wir=r(_ke," \u2014 "),Zz=n(_ke,"A",{href:!0});var $1t=s(Zz);Hir=r($1t,"TFPegasusModel"),$1t.forEach(t),Uir=r(_ke," (Pegasus model)"),_ke.forEach(t),Jir=i(D),fT=n(D,"LI",{});var bke=s(fT);H0e=n(bke,"STRONG",{});var k1t=s(H0e);Yir=r(k1t,"rembert"),k1t.forEach(t),Kir=r(bke," \u2014 "),eQ=n(bke,"A",{href:!0});var S1t=s(eQ);Zir=r(S1t,"TFRemBertModel"),S1t.forEach(t),edr=r(bke," (RemBERT model)"),bke.forEach(t),odr=i(D),mT=n(D,"LI",{});var vke=s(mT);U0e=n(vke,"STRONG",{});var R1t=s(U0e);rdr=r(R1t,"roberta"),R1t.forEach(t),tdr=r(vke," \u2014 "),oQ=n(vke,"A",{href:!0});var B1t=s(oQ);adr=r(B1t,"TFRobertaModel"),B1t.forEach(t),ndr=r(vke," (RoBERTa model)"),vke.forEach(t),sdr=i(D),gT=n(D,"LI",{});var Fke=s(gT);J0e=n(Fke,"STRONG",{});var P1t=s(J0e);ldr=r(P1t,"roformer"),P1t.forEach(t),idr=r(Fke," \u2014 "),rQ=n(Fke,"A",{href:!0});var I1t=s(rQ);ddr=r(I1t,"TFRoFormerModel"),I1t.forEach(t),cdr=r(Fke," (RoFormer model)"),Fke.forEach(t),fdr=i(D),hT=n(D,"LI",{});var Tke=s(hT);Y0e=n(Tke,"STRONG",{});var q1t=s(Y0e);mdr=r(q1t,"speech_to_text"),q1t.forEach(t),gdr=r(Tke," \u2014 "),tQ=n(Tke,"A",{href:!0});var N1t=s(tQ);hdr=r(N1t,"TFSpeech2TextModel"),N1t.forEach(t),pdr=r(Tke," (Speech2Text model)"),Tke.forEach(t),udr=i(D),pT=n(D,"LI",{});var Mke=s(pT);K0e=n(Mke,"STRONG",{});var j1t=s(K0e);_dr=r(j1t,"t5"),j1t.forEach(t),bdr=r(Mke," \u2014 "),aQ=n(Mke,"A",{href:!0});var D1t=s(aQ);vdr=r(D1t,"TFT5Model"),D1t.forEach(t),Fdr=r(Mke," (T5 model)"),Mke.forEach(t),Tdr=i(D),uT=n(D,"LI",{});var Eke=s(uT);Z0e=n(Eke,"STRONG",{});var G1t=s(Z0e);Mdr=r(G1t,"tapas"),G1t.forEach(t),Edr=r(Eke," \u2014 "),nQ=n(Eke,"A",{href:!0});var O1t=s(nQ);Cdr=r(O1t,"TFTapasModel"),O1t.forEach(t),wdr=r(Eke," (TAPAS model)"),Eke.forEach(t),Adr=i(D),_T=n(D,"LI",{});var Cke=s(_T);e1e=n(Cke,"STRONG",{});var V1t=s(e1e);ydr=r(V1t,"transfo-xl"),V1t.forEach(t),Ldr=r(Cke," \u2014 "),sQ=n(Cke,"A",{href:!0});var X1t=s(sQ);xdr=r(X1t,"TFTransfoXLModel"),X1t.forEach(t),$dr=r(Cke," (Transformer-XL model)"),Cke.forEach(t),kdr=i(D),bT=n(D,"LI",{});var wke=s(bT);o1e=n(wke,"STRONG",{});var z1t=s(o1e);Sdr=r(z1t,"vit"),z1t.forEach(t),Rdr=r(wke," \u2014 "),lQ=n(wke,"A",{href:!0});var Q1t=s(lQ);Bdr=r(Q1t,"TFViTModel"),Q1t.forEach(t),Pdr=r(wke," (ViT model)"),wke.forEach(t),Idr=i(D),vT=n(D,"LI",{});var Ake=s(vT);r1e=n(Ake,"STRONG",{});var W1t=s(r1e);qdr=r(W1t,"vit_mae"),W1t.forEach(t),Ndr=r(Ake," \u2014 "),iQ=n(Ake,"A",{href:!0});var H1t=s(iQ);jdr=r(H1t,"TFViTMAEModel"),H1t.forEach(t),Ddr=r(Ake," (ViTMAE model)"),Ake.forEach(t),Gdr=i(D),FT=n(D,"LI",{});var yke=s(FT);t1e=n(yke,"STRONG",{});var U1t=s(t1e);Odr=r(U1t,"wav2vec2"),U1t.forEach(t),Vdr=r(yke," \u2014 "),dQ=n(yke,"A",{href:!0});var J1t=s(dQ);Xdr=r(J1t,"TFWav2Vec2Model"),J1t.forEach(t),zdr=r(yke," (Wav2Vec2 model)"),yke.forEach(t),Qdr=i(D),TT=n(D,"LI",{});var Lke=s(TT);a1e=n(Lke,"STRONG",{});var Y1t=s(a1e);Wdr=r(Y1t,"xlm"),Y1t.forEach(t),Hdr=r(Lke," \u2014 "),cQ=n(Lke,"A",{href:!0});var K1t=s(cQ);Udr=r(K1t,"TFXLMModel"),K1t.forEach(t),Jdr=r(Lke," (XLM model)"),Lke.forEach(t),Ydr=i(D),MT=n(D,"LI",{});var xke=s(MT);n1e=n(xke,"STRONG",{});var Z1t=s(n1e);Kdr=r(Z1t,"xlm-roberta"),Z1t.forEach(t),Zdr=r(xke," \u2014 "),fQ=n(xke,"A",{href:!0});var ebt=s(fQ);ecr=r(ebt,"TFXLMRobertaModel"),ebt.forEach(t),ocr=r(xke," (XLM-RoBERTa model)"),xke.forEach(t),rcr=i(D),ET=n(D,"LI",{});var $ke=s(ET);s1e=n($ke,"STRONG",{});var obt=s(s1e);tcr=r(obt,"xlnet"),obt.forEach(t),acr=r($ke," \u2014 "),mQ=n($ke,"A",{href:!0});var rbt=s(mQ);ncr=r(rbt,"TFXLNetModel"),rbt.forEach(t),scr=r($ke," (XLNet model)"),$ke.forEach(t),D.forEach(t),lcr=i(fl),T(CT.$$.fragment,fl),fl.forEach(t),cl.forEach(t),xqe=i(f),Gd=n(f,"H2",{class:!0});var Pje=s(Gd);wT=n(Pje,"A",{id:!0,class:!0,href:!0});var tbt=s(wT);l1e=n(tbt,"SPAN",{});var abt=s(l1e);T(zL.$$.fragment,abt),abt.forEach(t),tbt.forEach(t),icr=i(Pje),i1e=n(Pje,"SPAN",{});var nbt=s(i1e);dcr=r(nbt,"TFAutoModelForPreTraining"),nbt.forEach(t),Pje.forEach(t),$qe=i(f),Ko=n(f,"DIV",{class:!0});var ml=s(Ko);T(QL.$$.fragment,ml),ccr=i(ml),Od=n(ml,"P",{});var TZ=s(Od);fcr=r(TZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gQ=n(TZ,"A",{href:!0});var sbt=s(gQ);mcr=r(sbt,"from_pretrained()"),sbt.forEach(t),gcr=r(TZ," class method or the "),hQ=n(TZ,"A",{href:!0});var lbt=s(hQ);hcr=r(lbt,"from_config()"),lbt.forEach(t),pcr=r(TZ,` class
method.`),TZ.forEach(t),ucr=i(ml),WL=n(ml,"P",{});var Ije=s(WL);_cr=r(Ije,"This class cannot be instantiated directly using "),d1e=n(Ije,"CODE",{});var ibt=s(d1e);bcr=r(ibt,"__init__()"),ibt.forEach(t),vcr=r(Ije," (throws an error)."),Ije.forEach(t),Fcr=i(ml),At=n(ml,"DIV",{class:!0});var nw=s(At);T(HL.$$.fragment,nw),Tcr=i(nw),c1e=n(nw,"P",{});var dbt=s(c1e);Mcr=r(dbt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),dbt.forEach(t),Ecr=i(nw),Vd=n(nw,"P",{});var MZ=s(Vd);Ccr=r(MZ,`Note:
Loading a model from its configuration file does `),f1e=n(MZ,"STRONG",{});var cbt=s(f1e);wcr=r(cbt,"not"),cbt.forEach(t),Acr=r(MZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),pQ=n(MZ,"A",{href:!0});var fbt=s(pQ);ycr=r(fbt,"from_pretrained()"),fbt.forEach(t),Lcr=r(MZ," to load the model weights."),MZ.forEach(t),xcr=i(nw),T(AT.$$.fragment,nw),nw.forEach(t),$cr=i(ml),Ar=n(ml,"DIV",{class:!0});var gl=s(Ar);T(UL.$$.fragment,gl),kcr=i(gl),m1e=n(gl,"P",{});var mbt=s(m1e);Scr=r(mbt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),mbt.forEach(t),Rcr=i(gl),Za=n(gl,"P",{});var sw=s(Za);Bcr=r(sw,"The model class to instantiate is selected based on the "),g1e=n(sw,"CODE",{});var gbt=s(g1e);Pcr=r(gbt,"model_type"),gbt.forEach(t),Icr=r(sw,` property of the config object (either
passed as an argument or loaded from `),h1e=n(sw,"CODE",{});var hbt=s(h1e);qcr=r(hbt,"pretrained_model_name_or_path"),hbt.forEach(t),Ncr=r(sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p1e=n(sw,"CODE",{});var pbt=s(p1e);jcr=r(pbt,"pretrained_model_name_or_path"),pbt.forEach(t),Dcr=r(sw,":"),sw.forEach(t),Gcr=i(gl),se=n(gl,"UL",{});var le=s(se);yT=n(le,"LI",{});var kke=s(yT);u1e=n(kke,"STRONG",{});var ubt=s(u1e);Ocr=r(ubt,"albert"),ubt.forEach(t),Vcr=r(kke," \u2014 "),uQ=n(kke,"A",{href:!0});var _bt=s(uQ);Xcr=r(_bt,"TFAlbertForPreTraining"),_bt.forEach(t),zcr=r(kke," (ALBERT model)"),kke.forEach(t),Qcr=i(le),LT=n(le,"LI",{});var Ske=s(LT);_1e=n(Ske,"STRONG",{});var bbt=s(_1e);Wcr=r(bbt,"bart"),bbt.forEach(t),Hcr=r(Ske," \u2014 "),_Q=n(Ske,"A",{href:!0});var vbt=s(_Q);Ucr=r(vbt,"TFBartForConditionalGeneration"),vbt.forEach(t),Jcr=r(Ske," (BART model)"),Ske.forEach(t),Ycr=i(le),xT=n(le,"LI",{});var Rke=s(xT);b1e=n(Rke,"STRONG",{});var Fbt=s(b1e);Kcr=r(Fbt,"bert"),Fbt.forEach(t),Zcr=r(Rke," \u2014 "),bQ=n(Rke,"A",{href:!0});var Tbt=s(bQ);efr=r(Tbt,"TFBertForPreTraining"),Tbt.forEach(t),ofr=r(Rke," (BERT model)"),Rke.forEach(t),rfr=i(le),$T=n(le,"LI",{});var Bke=s($T);v1e=n(Bke,"STRONG",{});var Mbt=s(v1e);tfr=r(Mbt,"camembert"),Mbt.forEach(t),afr=r(Bke," \u2014 "),vQ=n(Bke,"A",{href:!0});var Ebt=s(vQ);nfr=r(Ebt,"TFCamembertForMaskedLM"),Ebt.forEach(t),sfr=r(Bke," (CamemBERT model)"),Bke.forEach(t),lfr=i(le),kT=n(le,"LI",{});var Pke=s(kT);F1e=n(Pke,"STRONG",{});var Cbt=s(F1e);ifr=r(Cbt,"ctrl"),Cbt.forEach(t),dfr=r(Pke," \u2014 "),FQ=n(Pke,"A",{href:!0});var wbt=s(FQ);cfr=r(wbt,"TFCTRLLMHeadModel"),wbt.forEach(t),ffr=r(Pke," (CTRL model)"),Pke.forEach(t),mfr=i(le),ST=n(le,"LI",{});var Ike=s(ST);T1e=n(Ike,"STRONG",{});var Abt=s(T1e);gfr=r(Abt,"distilbert"),Abt.forEach(t),hfr=r(Ike," \u2014 "),TQ=n(Ike,"A",{href:!0});var ybt=s(TQ);pfr=r(ybt,"TFDistilBertForMaskedLM"),ybt.forEach(t),ufr=r(Ike," (DistilBERT model)"),Ike.forEach(t),_fr=i(le),RT=n(le,"LI",{});var qke=s(RT);M1e=n(qke,"STRONG",{});var Lbt=s(M1e);bfr=r(Lbt,"electra"),Lbt.forEach(t),vfr=r(qke," \u2014 "),MQ=n(qke,"A",{href:!0});var xbt=s(MQ);Ffr=r(xbt,"TFElectraForPreTraining"),xbt.forEach(t),Tfr=r(qke," (ELECTRA model)"),qke.forEach(t),Mfr=i(le),BT=n(le,"LI",{});var Nke=s(BT);E1e=n(Nke,"STRONG",{});var $bt=s(E1e);Efr=r($bt,"flaubert"),$bt.forEach(t),Cfr=r(Nke," \u2014 "),EQ=n(Nke,"A",{href:!0});var kbt=s(EQ);wfr=r(kbt,"TFFlaubertWithLMHeadModel"),kbt.forEach(t),Afr=r(Nke," (FlauBERT model)"),Nke.forEach(t),yfr=i(le),PT=n(le,"LI",{});var jke=s(PT);C1e=n(jke,"STRONG",{});var Sbt=s(C1e);Lfr=r(Sbt,"funnel"),Sbt.forEach(t),xfr=r(jke," \u2014 "),CQ=n(jke,"A",{href:!0});var Rbt=s(CQ);$fr=r(Rbt,"TFFunnelForPreTraining"),Rbt.forEach(t),kfr=r(jke," (Funnel Transformer model)"),jke.forEach(t),Sfr=i(le),IT=n(le,"LI",{});var Dke=s(IT);w1e=n(Dke,"STRONG",{});var Bbt=s(w1e);Rfr=r(Bbt,"gpt2"),Bbt.forEach(t),Bfr=r(Dke," \u2014 "),wQ=n(Dke,"A",{href:!0});var Pbt=s(wQ);Pfr=r(Pbt,"TFGPT2LMHeadModel"),Pbt.forEach(t),Ifr=r(Dke," (OpenAI GPT-2 model)"),Dke.forEach(t),qfr=i(le),qT=n(le,"LI",{});var Gke=s(qT);A1e=n(Gke,"STRONG",{});var Ibt=s(A1e);Nfr=r(Ibt,"layoutlm"),Ibt.forEach(t),jfr=r(Gke," \u2014 "),AQ=n(Gke,"A",{href:!0});var qbt=s(AQ);Dfr=r(qbt,"TFLayoutLMForMaskedLM"),qbt.forEach(t),Gfr=r(Gke," (LayoutLM model)"),Gke.forEach(t),Ofr=i(le),NT=n(le,"LI",{});var Oke=s(NT);y1e=n(Oke,"STRONG",{});var Nbt=s(y1e);Vfr=r(Nbt,"lxmert"),Nbt.forEach(t),Xfr=r(Oke," \u2014 "),yQ=n(Oke,"A",{href:!0});var jbt=s(yQ);zfr=r(jbt,"TFLxmertForPreTraining"),jbt.forEach(t),Qfr=r(Oke," (LXMERT model)"),Oke.forEach(t),Wfr=i(le),jT=n(le,"LI",{});var Vke=s(jT);L1e=n(Vke,"STRONG",{});var Dbt=s(L1e);Hfr=r(Dbt,"mobilebert"),Dbt.forEach(t),Ufr=r(Vke," \u2014 "),LQ=n(Vke,"A",{href:!0});var Gbt=s(LQ);Jfr=r(Gbt,"TFMobileBertForPreTraining"),Gbt.forEach(t),Yfr=r(Vke," (MobileBERT model)"),Vke.forEach(t),Kfr=i(le),DT=n(le,"LI",{});var Xke=s(DT);x1e=n(Xke,"STRONG",{});var Obt=s(x1e);Zfr=r(Obt,"mpnet"),Obt.forEach(t),emr=r(Xke," \u2014 "),xQ=n(Xke,"A",{href:!0});var Vbt=s(xQ);omr=r(Vbt,"TFMPNetForMaskedLM"),Vbt.forEach(t),rmr=r(Xke," (MPNet model)"),Xke.forEach(t),tmr=i(le),GT=n(le,"LI",{});var zke=s(GT);$1e=n(zke,"STRONG",{});var Xbt=s($1e);amr=r(Xbt,"openai-gpt"),Xbt.forEach(t),nmr=r(zke," \u2014 "),$Q=n(zke,"A",{href:!0});var zbt=s($Q);smr=r(zbt,"TFOpenAIGPTLMHeadModel"),zbt.forEach(t),lmr=r(zke," (OpenAI GPT model)"),zke.forEach(t),imr=i(le),OT=n(le,"LI",{});var Qke=s(OT);k1e=n(Qke,"STRONG",{});var Qbt=s(k1e);dmr=r(Qbt,"roberta"),Qbt.forEach(t),cmr=r(Qke," \u2014 "),kQ=n(Qke,"A",{href:!0});var Wbt=s(kQ);fmr=r(Wbt,"TFRobertaForMaskedLM"),Wbt.forEach(t),mmr=r(Qke," (RoBERTa model)"),Qke.forEach(t),gmr=i(le),VT=n(le,"LI",{});var Wke=s(VT);S1e=n(Wke,"STRONG",{});var Hbt=s(S1e);hmr=r(Hbt,"t5"),Hbt.forEach(t),pmr=r(Wke," \u2014 "),SQ=n(Wke,"A",{href:!0});var Ubt=s(SQ);umr=r(Ubt,"TFT5ForConditionalGeneration"),Ubt.forEach(t),_mr=r(Wke," (T5 model)"),Wke.forEach(t),bmr=i(le),XT=n(le,"LI",{});var Hke=s(XT);R1e=n(Hke,"STRONG",{});var Jbt=s(R1e);vmr=r(Jbt,"tapas"),Jbt.forEach(t),Fmr=r(Hke," \u2014 "),RQ=n(Hke,"A",{href:!0});var Ybt=s(RQ);Tmr=r(Ybt,"TFTapasForMaskedLM"),Ybt.forEach(t),Mmr=r(Hke," (TAPAS model)"),Hke.forEach(t),Emr=i(le),zT=n(le,"LI",{});var Uke=s(zT);B1e=n(Uke,"STRONG",{});var Kbt=s(B1e);Cmr=r(Kbt,"transfo-xl"),Kbt.forEach(t),wmr=r(Uke," \u2014 "),BQ=n(Uke,"A",{href:!0});var Zbt=s(BQ);Amr=r(Zbt,"TFTransfoXLLMHeadModel"),Zbt.forEach(t),ymr=r(Uke," (Transformer-XL model)"),Uke.forEach(t),Lmr=i(le),QT=n(le,"LI",{});var Jke=s(QT);P1e=n(Jke,"STRONG",{});var e2t=s(P1e);xmr=r(e2t,"vit_mae"),e2t.forEach(t),$mr=r(Jke," \u2014 "),PQ=n(Jke,"A",{href:!0});var o2t=s(PQ);kmr=r(o2t,"TFViTMAEForPreTraining"),o2t.forEach(t),Smr=r(Jke," (ViTMAE model)"),Jke.forEach(t),Rmr=i(le),WT=n(le,"LI",{});var Yke=s(WT);I1e=n(Yke,"STRONG",{});var r2t=s(I1e);Bmr=r(r2t,"xlm"),r2t.forEach(t),Pmr=r(Yke," \u2014 "),IQ=n(Yke,"A",{href:!0});var t2t=s(IQ);Imr=r(t2t,"TFXLMWithLMHeadModel"),t2t.forEach(t),qmr=r(Yke," (XLM model)"),Yke.forEach(t),Nmr=i(le),HT=n(le,"LI",{});var Kke=s(HT);q1e=n(Kke,"STRONG",{});var a2t=s(q1e);jmr=r(a2t,"xlm-roberta"),a2t.forEach(t),Dmr=r(Kke," \u2014 "),qQ=n(Kke,"A",{href:!0});var n2t=s(qQ);Gmr=r(n2t,"TFXLMRobertaForMaskedLM"),n2t.forEach(t),Omr=r(Kke," (XLM-RoBERTa model)"),Kke.forEach(t),Vmr=i(le),UT=n(le,"LI",{});var Zke=s(UT);N1e=n(Zke,"STRONG",{});var s2t=s(N1e);Xmr=r(s2t,"xlnet"),s2t.forEach(t),zmr=r(Zke," \u2014 "),NQ=n(Zke,"A",{href:!0});var l2t=s(NQ);Qmr=r(l2t,"TFXLNetLMHeadModel"),l2t.forEach(t),Wmr=r(Zke," (XLNet model)"),Zke.forEach(t),le.forEach(t),Hmr=i(gl),T(JT.$$.fragment,gl),gl.forEach(t),ml.forEach(t),kqe=i(f),Xd=n(f,"H2",{class:!0});var qje=s(Xd);YT=n(qje,"A",{id:!0,class:!0,href:!0});var i2t=s(YT);j1e=n(i2t,"SPAN",{});var d2t=s(j1e);T(JL.$$.fragment,d2t),d2t.forEach(t),i2t.forEach(t),Umr=i(qje),D1e=n(qje,"SPAN",{});var c2t=s(D1e);Jmr=r(c2t,"TFAutoModelForCausalLM"),c2t.forEach(t),qje.forEach(t),Sqe=i(f),Zo=n(f,"DIV",{class:!0});var hl=s(Zo);T(YL.$$.fragment,hl),Ymr=i(hl),zd=n(hl,"P",{});var EZ=s(zd);Kmr=r(EZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jQ=n(EZ,"A",{href:!0});var f2t=s(jQ);Zmr=r(f2t,"from_pretrained()"),f2t.forEach(t),egr=r(EZ," class method or the "),DQ=n(EZ,"A",{href:!0});var m2t=s(DQ);ogr=r(m2t,"from_config()"),m2t.forEach(t),rgr=r(EZ,` class
method.`),EZ.forEach(t),tgr=i(hl),KL=n(hl,"P",{});var Nje=s(KL);agr=r(Nje,"This class cannot be instantiated directly using "),G1e=n(Nje,"CODE",{});var g2t=s(G1e);ngr=r(g2t,"__init__()"),g2t.forEach(t),sgr=r(Nje," (throws an error)."),Nje.forEach(t),lgr=i(hl),yt=n(hl,"DIV",{class:!0});var lw=s(yt);T(ZL.$$.fragment,lw),igr=i(lw),O1e=n(lw,"P",{});var h2t=s(O1e);dgr=r(h2t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),h2t.forEach(t),cgr=i(lw),Qd=n(lw,"P",{});var CZ=s(Qd);fgr=r(CZ,`Note:
Loading a model from its configuration file does `),V1e=n(CZ,"STRONG",{});var p2t=s(V1e);mgr=r(p2t,"not"),p2t.forEach(t),ggr=r(CZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),GQ=n(CZ,"A",{href:!0});var u2t=s(GQ);hgr=r(u2t,"from_pretrained()"),u2t.forEach(t),pgr=r(CZ," to load the model weights."),CZ.forEach(t),ugr=i(lw),T(KT.$$.fragment,lw),lw.forEach(t),_gr=i(hl),yr=n(hl,"DIV",{class:!0});var pl=s(yr);T(e8.$$.fragment,pl),bgr=i(pl),X1e=n(pl,"P",{});var _2t=s(X1e);vgr=r(_2t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),_2t.forEach(t),Fgr=i(pl),en=n(pl,"P",{});var iw=s(en);Tgr=r(iw,"The model class to instantiate is selected based on the "),z1e=n(iw,"CODE",{});var b2t=s(z1e);Mgr=r(b2t,"model_type"),b2t.forEach(t),Egr=r(iw,` property of the config object (either
passed as an argument or loaded from `),Q1e=n(iw,"CODE",{});var v2t=s(Q1e);Cgr=r(v2t,"pretrained_model_name_or_path"),v2t.forEach(t),wgr=r(iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W1e=n(iw,"CODE",{});var F2t=s(W1e);Agr=r(F2t,"pretrained_model_name_or_path"),F2t.forEach(t),ygr=r(iw,":"),iw.forEach(t),Lgr=i(pl),Te=n(pl,"UL",{});var Ce=s(Te);ZT=n(Ce,"LI",{});var eSe=s(ZT);H1e=n(eSe,"STRONG",{});var T2t=s(H1e);xgr=r(T2t,"bert"),T2t.forEach(t),$gr=r(eSe," \u2014 "),OQ=n(eSe,"A",{href:!0});var M2t=s(OQ);kgr=r(M2t,"TFBertLMHeadModel"),M2t.forEach(t),Sgr=r(eSe," (BERT model)"),eSe.forEach(t),Rgr=i(Ce),e7=n(Ce,"LI",{});var oSe=s(e7);U1e=n(oSe,"STRONG",{});var E2t=s(U1e);Bgr=r(E2t,"camembert"),E2t.forEach(t),Pgr=r(oSe," \u2014 "),VQ=n(oSe,"A",{href:!0});var C2t=s(VQ);Igr=r(C2t,"TFCamembertForCausalLM"),C2t.forEach(t),qgr=r(oSe," (CamemBERT model)"),oSe.forEach(t),Ngr=i(Ce),o7=n(Ce,"LI",{});var rSe=s(o7);J1e=n(rSe,"STRONG",{});var w2t=s(J1e);jgr=r(w2t,"ctrl"),w2t.forEach(t),Dgr=r(rSe," \u2014 "),XQ=n(rSe,"A",{href:!0});var A2t=s(XQ);Ggr=r(A2t,"TFCTRLLMHeadModel"),A2t.forEach(t),Ogr=r(rSe," (CTRL model)"),rSe.forEach(t),Vgr=i(Ce),r7=n(Ce,"LI",{});var tSe=s(r7);Y1e=n(tSe,"STRONG",{});var y2t=s(Y1e);Xgr=r(y2t,"gpt2"),y2t.forEach(t),zgr=r(tSe," \u2014 "),zQ=n(tSe,"A",{href:!0});var L2t=s(zQ);Qgr=r(L2t,"TFGPT2LMHeadModel"),L2t.forEach(t),Wgr=r(tSe," (OpenAI GPT-2 model)"),tSe.forEach(t),Hgr=i(Ce),t7=n(Ce,"LI",{});var aSe=s(t7);K1e=n(aSe,"STRONG",{});var x2t=s(K1e);Ugr=r(x2t,"gptj"),x2t.forEach(t),Jgr=r(aSe," \u2014 "),QQ=n(aSe,"A",{href:!0});var $2t=s(QQ);Ygr=r($2t,"TFGPTJForCausalLM"),$2t.forEach(t),Kgr=r(aSe," (GPT-J model)"),aSe.forEach(t),Zgr=i(Ce),a7=n(Ce,"LI",{});var nSe=s(a7);Z1e=n(nSe,"STRONG",{});var k2t=s(Z1e);ehr=r(k2t,"openai-gpt"),k2t.forEach(t),ohr=r(nSe," \u2014 "),WQ=n(nSe,"A",{href:!0});var S2t=s(WQ);rhr=r(S2t,"TFOpenAIGPTLMHeadModel"),S2t.forEach(t),thr=r(nSe," (OpenAI GPT model)"),nSe.forEach(t),ahr=i(Ce),n7=n(Ce,"LI",{});var sSe=s(n7);ebe=n(sSe,"STRONG",{});var R2t=s(ebe);nhr=r(R2t,"rembert"),R2t.forEach(t),shr=r(sSe," \u2014 "),HQ=n(sSe,"A",{href:!0});var B2t=s(HQ);lhr=r(B2t,"TFRemBertForCausalLM"),B2t.forEach(t),ihr=r(sSe," (RemBERT model)"),sSe.forEach(t),dhr=i(Ce),s7=n(Ce,"LI",{});var lSe=s(s7);obe=n(lSe,"STRONG",{});var P2t=s(obe);chr=r(P2t,"roberta"),P2t.forEach(t),fhr=r(lSe," \u2014 "),UQ=n(lSe,"A",{href:!0});var I2t=s(UQ);mhr=r(I2t,"TFRobertaForCausalLM"),I2t.forEach(t),ghr=r(lSe," (RoBERTa model)"),lSe.forEach(t),hhr=i(Ce),l7=n(Ce,"LI",{});var iSe=s(l7);rbe=n(iSe,"STRONG",{});var q2t=s(rbe);phr=r(q2t,"roformer"),q2t.forEach(t),uhr=r(iSe," \u2014 "),JQ=n(iSe,"A",{href:!0});var N2t=s(JQ);_hr=r(N2t,"TFRoFormerForCausalLM"),N2t.forEach(t),bhr=r(iSe," (RoFormer model)"),iSe.forEach(t),vhr=i(Ce),i7=n(Ce,"LI",{});var dSe=s(i7);tbe=n(dSe,"STRONG",{});var j2t=s(tbe);Fhr=r(j2t,"transfo-xl"),j2t.forEach(t),Thr=r(dSe," \u2014 "),YQ=n(dSe,"A",{href:!0});var D2t=s(YQ);Mhr=r(D2t,"TFTransfoXLLMHeadModel"),D2t.forEach(t),Ehr=r(dSe," (Transformer-XL model)"),dSe.forEach(t),Chr=i(Ce),d7=n(Ce,"LI",{});var cSe=s(d7);abe=n(cSe,"STRONG",{});var G2t=s(abe);whr=r(G2t,"xlm"),G2t.forEach(t),Ahr=r(cSe," \u2014 "),KQ=n(cSe,"A",{href:!0});var O2t=s(KQ);yhr=r(O2t,"TFXLMWithLMHeadModel"),O2t.forEach(t),Lhr=r(cSe," (XLM model)"),cSe.forEach(t),xhr=i(Ce),c7=n(Ce,"LI",{});var fSe=s(c7);nbe=n(fSe,"STRONG",{});var V2t=s(nbe);$hr=r(V2t,"xlnet"),V2t.forEach(t),khr=r(fSe," \u2014 "),ZQ=n(fSe,"A",{href:!0});var X2t=s(ZQ);Shr=r(X2t,"TFXLNetLMHeadModel"),X2t.forEach(t),Rhr=r(fSe," (XLNet model)"),fSe.forEach(t),Ce.forEach(t),Bhr=i(pl),T(f7.$$.fragment,pl),pl.forEach(t),hl.forEach(t),Rqe=i(f),Wd=n(f,"H2",{class:!0});var jje=s(Wd);m7=n(jje,"A",{id:!0,class:!0,href:!0});var z2t=s(m7);sbe=n(z2t,"SPAN",{});var Q2t=s(sbe);T(o8.$$.fragment,Q2t),Q2t.forEach(t),z2t.forEach(t),Phr=i(jje),lbe=n(jje,"SPAN",{});var W2t=s(lbe);Ihr=r(W2t,"TFAutoModelForImageClassification"),W2t.forEach(t),jje.forEach(t),Bqe=i(f),er=n(f,"DIV",{class:!0});var ul=s(er);T(r8.$$.fragment,ul),qhr=i(ul),Hd=n(ul,"P",{});var wZ=s(Hd);Nhr=r(wZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eW=n(wZ,"A",{href:!0});var H2t=s(eW);jhr=r(H2t,"from_pretrained()"),H2t.forEach(t),Dhr=r(wZ," class method or the "),oW=n(wZ,"A",{href:!0});var U2t=s(oW);Ghr=r(U2t,"from_config()"),U2t.forEach(t),Ohr=r(wZ,` class
method.`),wZ.forEach(t),Vhr=i(ul),t8=n(ul,"P",{});var Dje=s(t8);Xhr=r(Dje,"This class cannot be instantiated directly using "),ibe=n(Dje,"CODE",{});var J2t=s(ibe);zhr=r(J2t,"__init__()"),J2t.forEach(t),Qhr=r(Dje," (throws an error)."),Dje.forEach(t),Whr=i(ul),Lt=n(ul,"DIV",{class:!0});var dw=s(Lt);T(a8.$$.fragment,dw),Hhr=i(dw),dbe=n(dw,"P",{});var Y2t=s(dbe);Uhr=r(Y2t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Y2t.forEach(t),Jhr=i(dw),Ud=n(dw,"P",{});var AZ=s(Ud);Yhr=r(AZ,`Note:
Loading a model from its configuration file does `),cbe=n(AZ,"STRONG",{});var K2t=s(cbe);Khr=r(K2t,"not"),K2t.forEach(t),Zhr=r(AZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=n(AZ,"A",{href:!0});var Z2t=s(rW);epr=r(Z2t,"from_pretrained()"),Z2t.forEach(t),opr=r(AZ," to load the model weights."),AZ.forEach(t),rpr=i(dw),T(g7.$$.fragment,dw),dw.forEach(t),tpr=i(ul),Lr=n(ul,"DIV",{class:!0});var _l=s(Lr);T(n8.$$.fragment,_l),apr=i(_l),fbe=n(_l,"P",{});var evt=s(fbe);npr=r(evt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),evt.forEach(t),spr=i(_l),on=n(_l,"P",{});var cw=s(on);lpr=r(cw,"The model class to instantiate is selected based on the "),mbe=n(cw,"CODE",{});var ovt=s(mbe);ipr=r(ovt,"model_type"),ovt.forEach(t),dpr=r(cw,` property of the config object (either
passed as an argument or loaded from `),gbe=n(cw,"CODE",{});var rvt=s(gbe);cpr=r(rvt,"pretrained_model_name_or_path"),rvt.forEach(t),fpr=r(cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=n(cw,"CODE",{});var tvt=s(hbe);mpr=r(tvt,"pretrained_model_name_or_path"),tvt.forEach(t),gpr=r(cw,":"),cw.forEach(t),hpr=i(_l),Jd=n(_l,"UL",{});var yZ=s(Jd);h7=n(yZ,"LI",{});var mSe=s(h7);pbe=n(mSe,"STRONG",{});var avt=s(pbe);ppr=r(avt,"convnext"),avt.forEach(t),upr=r(mSe," \u2014 "),tW=n(mSe,"A",{href:!0});var nvt=s(tW);_pr=r(nvt,"TFConvNextForImageClassification"),nvt.forEach(t),bpr=r(mSe," (ConvNext model)"),mSe.forEach(t),vpr=i(yZ),p7=n(yZ,"LI",{});var gSe=s(p7);ube=n(gSe,"STRONG",{});var svt=s(ube);Fpr=r(svt,"data2vec-vision"),svt.forEach(t),Tpr=r(gSe," \u2014 "),aW=n(gSe,"A",{href:!0});var lvt=s(aW);Mpr=r(lvt,"TFData2VecVisionForImageClassification"),lvt.forEach(t),Epr=r(gSe," (Data2VecVision model)"),gSe.forEach(t),Cpr=i(yZ),u7=n(yZ,"LI",{});var hSe=s(u7);_be=n(hSe,"STRONG",{});var ivt=s(_be);wpr=r(ivt,"vit"),ivt.forEach(t),Apr=r(hSe," \u2014 "),nW=n(hSe,"A",{href:!0});var dvt=s(nW);ypr=r(dvt,"TFViTForImageClassification"),dvt.forEach(t),Lpr=r(hSe," (ViT model)"),hSe.forEach(t),yZ.forEach(t),xpr=i(_l),T(_7.$$.fragment,_l),_l.forEach(t),ul.forEach(t),Pqe=i(f),Yd=n(f,"H2",{class:!0});var Gje=s(Yd);b7=n(Gje,"A",{id:!0,class:!0,href:!0});var cvt=s(b7);bbe=n(cvt,"SPAN",{});var fvt=s(bbe);T(s8.$$.fragment,fvt),fvt.forEach(t),cvt.forEach(t),$pr=i(Gje),vbe=n(Gje,"SPAN",{});var mvt=s(vbe);kpr=r(mvt,"TFAutoModelForMaskedLM"),mvt.forEach(t),Gje.forEach(t),Iqe=i(f),or=n(f,"DIV",{class:!0});var bl=s(or);T(l8.$$.fragment,bl),Spr=i(bl),Kd=n(bl,"P",{});var LZ=s(Kd);Rpr=r(LZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sW=n(LZ,"A",{href:!0});var gvt=s(sW);Bpr=r(gvt,"from_pretrained()"),gvt.forEach(t),Ppr=r(LZ," class method or the "),lW=n(LZ,"A",{href:!0});var hvt=s(lW);Ipr=r(hvt,"from_config()"),hvt.forEach(t),qpr=r(LZ,` class
method.`),LZ.forEach(t),Npr=i(bl),i8=n(bl,"P",{});var Oje=s(i8);jpr=r(Oje,"This class cannot be instantiated directly using "),Fbe=n(Oje,"CODE",{});var pvt=s(Fbe);Dpr=r(pvt,"__init__()"),pvt.forEach(t),Gpr=r(Oje," (throws an error)."),Oje.forEach(t),Opr=i(bl),xt=n(bl,"DIV",{class:!0});var fw=s(xt);T(d8.$$.fragment,fw),Vpr=i(fw),Tbe=n(fw,"P",{});var uvt=s(Tbe);Xpr=r(uvt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),uvt.forEach(t),zpr=i(fw),Zd=n(fw,"P",{});var xZ=s(Zd);Qpr=r(xZ,`Note:
Loading a model from its configuration file does `),Mbe=n(xZ,"STRONG",{});var _vt=s(Mbe);Wpr=r(_vt,"not"),_vt.forEach(t),Hpr=r(xZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=n(xZ,"A",{href:!0});var bvt=s(iW);Upr=r(bvt,"from_pretrained()"),bvt.forEach(t),Jpr=r(xZ," to load the model weights."),xZ.forEach(t),Ypr=i(fw),T(v7.$$.fragment,fw),fw.forEach(t),Kpr=i(bl),xr=n(bl,"DIV",{class:!0});var vl=s(xr);T(c8.$$.fragment,vl),Zpr=i(vl),Ebe=n(vl,"P",{});var vvt=s(Ebe);eur=r(vvt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),vvt.forEach(t),our=i(vl),rn=n(vl,"P",{});var mw=s(rn);rur=r(mw,"The model class to instantiate is selected based on the "),Cbe=n(mw,"CODE",{});var Fvt=s(Cbe);tur=r(Fvt,"model_type"),Fvt.forEach(t),aur=r(mw,` property of the config object (either
passed as an argument or loaded from `),wbe=n(mw,"CODE",{});var Tvt=s(wbe);nur=r(Tvt,"pretrained_model_name_or_path"),Tvt.forEach(t),sur=r(mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Abe=n(mw,"CODE",{});var Mvt=s(Abe);lur=r(Mvt,"pretrained_model_name_or_path"),Mvt.forEach(t),iur=r(mw,":"),mw.forEach(t),dur=i(vl),ie=n(vl,"UL",{});var fe=s(ie);F7=n(fe,"LI",{});var pSe=s(F7);ybe=n(pSe,"STRONG",{});var Evt=s(ybe);cur=r(Evt,"albert"),Evt.forEach(t),fur=r(pSe," \u2014 "),dW=n(pSe,"A",{href:!0});var Cvt=s(dW);mur=r(Cvt,"TFAlbertForMaskedLM"),Cvt.forEach(t),gur=r(pSe," (ALBERT model)"),pSe.forEach(t),hur=i(fe),T7=n(fe,"LI",{});var uSe=s(T7);Lbe=n(uSe,"STRONG",{});var wvt=s(Lbe);pur=r(wvt,"bert"),wvt.forEach(t),uur=r(uSe," \u2014 "),cW=n(uSe,"A",{href:!0});var Avt=s(cW);_ur=r(Avt,"TFBertForMaskedLM"),Avt.forEach(t),bur=r(uSe," (BERT model)"),uSe.forEach(t),vur=i(fe),M7=n(fe,"LI",{});var _Se=s(M7);xbe=n(_Se,"STRONG",{});var yvt=s(xbe);Fur=r(yvt,"camembert"),yvt.forEach(t),Tur=r(_Se," \u2014 "),fW=n(_Se,"A",{href:!0});var Lvt=s(fW);Mur=r(Lvt,"TFCamembertForMaskedLM"),Lvt.forEach(t),Eur=r(_Se," (CamemBERT model)"),_Se.forEach(t),Cur=i(fe),E7=n(fe,"LI",{});var bSe=s(E7);$be=n(bSe,"STRONG",{});var xvt=s($be);wur=r(xvt,"convbert"),xvt.forEach(t),Aur=r(bSe," \u2014 "),mW=n(bSe,"A",{href:!0});var $vt=s(mW);yur=r($vt,"TFConvBertForMaskedLM"),$vt.forEach(t),Lur=r(bSe," (ConvBERT model)"),bSe.forEach(t),xur=i(fe),C7=n(fe,"LI",{});var vSe=s(C7);kbe=n(vSe,"STRONG",{});var kvt=s(kbe);$ur=r(kvt,"deberta"),kvt.forEach(t),kur=r(vSe," \u2014 "),gW=n(vSe,"A",{href:!0});var Svt=s(gW);Sur=r(Svt,"TFDebertaForMaskedLM"),Svt.forEach(t),Rur=r(vSe," (DeBERTa model)"),vSe.forEach(t),Bur=i(fe),w7=n(fe,"LI",{});var FSe=s(w7);Sbe=n(FSe,"STRONG",{});var Rvt=s(Sbe);Pur=r(Rvt,"deberta-v2"),Rvt.forEach(t),Iur=r(FSe," \u2014 "),hW=n(FSe,"A",{href:!0});var Bvt=s(hW);qur=r(Bvt,"TFDebertaV2ForMaskedLM"),Bvt.forEach(t),Nur=r(FSe," (DeBERTa-v2 model)"),FSe.forEach(t),jur=i(fe),A7=n(fe,"LI",{});var TSe=s(A7);Rbe=n(TSe,"STRONG",{});var Pvt=s(Rbe);Dur=r(Pvt,"distilbert"),Pvt.forEach(t),Gur=r(TSe," \u2014 "),pW=n(TSe,"A",{href:!0});var Ivt=s(pW);Our=r(Ivt,"TFDistilBertForMaskedLM"),Ivt.forEach(t),Vur=r(TSe," (DistilBERT model)"),TSe.forEach(t),Xur=i(fe),y7=n(fe,"LI",{});var MSe=s(y7);Bbe=n(MSe,"STRONG",{});var qvt=s(Bbe);zur=r(qvt,"electra"),qvt.forEach(t),Qur=r(MSe," \u2014 "),uW=n(MSe,"A",{href:!0});var Nvt=s(uW);Wur=r(Nvt,"TFElectraForMaskedLM"),Nvt.forEach(t),Hur=r(MSe," (ELECTRA model)"),MSe.forEach(t),Uur=i(fe),L7=n(fe,"LI",{});var ESe=s(L7);Pbe=n(ESe,"STRONG",{});var jvt=s(Pbe);Jur=r(jvt,"flaubert"),jvt.forEach(t),Yur=r(ESe," \u2014 "),_W=n(ESe,"A",{href:!0});var Dvt=s(_W);Kur=r(Dvt,"TFFlaubertWithLMHeadModel"),Dvt.forEach(t),Zur=r(ESe," (FlauBERT model)"),ESe.forEach(t),e_r=i(fe),x7=n(fe,"LI",{});var CSe=s(x7);Ibe=n(CSe,"STRONG",{});var Gvt=s(Ibe);o_r=r(Gvt,"funnel"),Gvt.forEach(t),r_r=r(CSe," \u2014 "),bW=n(CSe,"A",{href:!0});var Ovt=s(bW);t_r=r(Ovt,"TFFunnelForMaskedLM"),Ovt.forEach(t),a_r=r(CSe," (Funnel Transformer model)"),CSe.forEach(t),n_r=i(fe),$7=n(fe,"LI",{});var wSe=s($7);qbe=n(wSe,"STRONG",{});var Vvt=s(qbe);s_r=r(Vvt,"layoutlm"),Vvt.forEach(t),l_r=r(wSe," \u2014 "),vW=n(wSe,"A",{href:!0});var Xvt=s(vW);i_r=r(Xvt,"TFLayoutLMForMaskedLM"),Xvt.forEach(t),d_r=r(wSe," (LayoutLM model)"),wSe.forEach(t),c_r=i(fe),k7=n(fe,"LI",{});var ASe=s(k7);Nbe=n(ASe,"STRONG",{});var zvt=s(Nbe);f_r=r(zvt,"longformer"),zvt.forEach(t),m_r=r(ASe," \u2014 "),FW=n(ASe,"A",{href:!0});var Qvt=s(FW);g_r=r(Qvt,"TFLongformerForMaskedLM"),Qvt.forEach(t),h_r=r(ASe," (Longformer model)"),ASe.forEach(t),p_r=i(fe),S7=n(fe,"LI",{});var ySe=s(S7);jbe=n(ySe,"STRONG",{});var Wvt=s(jbe);u_r=r(Wvt,"mobilebert"),Wvt.forEach(t),__r=r(ySe," \u2014 "),TW=n(ySe,"A",{href:!0});var Hvt=s(TW);b_r=r(Hvt,"TFMobileBertForMaskedLM"),Hvt.forEach(t),v_r=r(ySe," (MobileBERT model)"),ySe.forEach(t),F_r=i(fe),R7=n(fe,"LI",{});var LSe=s(R7);Dbe=n(LSe,"STRONG",{});var Uvt=s(Dbe);T_r=r(Uvt,"mpnet"),Uvt.forEach(t),M_r=r(LSe," \u2014 "),MW=n(LSe,"A",{href:!0});var Jvt=s(MW);E_r=r(Jvt,"TFMPNetForMaskedLM"),Jvt.forEach(t),C_r=r(LSe," (MPNet model)"),LSe.forEach(t),w_r=i(fe),B7=n(fe,"LI",{});var xSe=s(B7);Gbe=n(xSe,"STRONG",{});var Yvt=s(Gbe);A_r=r(Yvt,"rembert"),Yvt.forEach(t),y_r=r(xSe," \u2014 "),EW=n(xSe,"A",{href:!0});var Kvt=s(EW);L_r=r(Kvt,"TFRemBertForMaskedLM"),Kvt.forEach(t),x_r=r(xSe," (RemBERT model)"),xSe.forEach(t),$_r=i(fe),P7=n(fe,"LI",{});var $Se=s(P7);Obe=n($Se,"STRONG",{});var Zvt=s(Obe);k_r=r(Zvt,"roberta"),Zvt.forEach(t),S_r=r($Se," \u2014 "),CW=n($Se,"A",{href:!0});var eFt=s(CW);R_r=r(eFt,"TFRobertaForMaskedLM"),eFt.forEach(t),B_r=r($Se," (RoBERTa model)"),$Se.forEach(t),P_r=i(fe),I7=n(fe,"LI",{});var kSe=s(I7);Vbe=n(kSe,"STRONG",{});var oFt=s(Vbe);I_r=r(oFt,"roformer"),oFt.forEach(t),q_r=r(kSe," \u2014 "),wW=n(kSe,"A",{href:!0});var rFt=s(wW);N_r=r(rFt,"TFRoFormerForMaskedLM"),rFt.forEach(t),j_r=r(kSe," (RoFormer model)"),kSe.forEach(t),D_r=i(fe),q7=n(fe,"LI",{});var SSe=s(q7);Xbe=n(SSe,"STRONG",{});var tFt=s(Xbe);G_r=r(tFt,"tapas"),tFt.forEach(t),O_r=r(SSe," \u2014 "),AW=n(SSe,"A",{href:!0});var aFt=s(AW);V_r=r(aFt,"TFTapasForMaskedLM"),aFt.forEach(t),X_r=r(SSe," (TAPAS model)"),SSe.forEach(t),z_r=i(fe),N7=n(fe,"LI",{});var RSe=s(N7);zbe=n(RSe,"STRONG",{});var nFt=s(zbe);Q_r=r(nFt,"xlm"),nFt.forEach(t),W_r=r(RSe," \u2014 "),yW=n(RSe,"A",{href:!0});var sFt=s(yW);H_r=r(sFt,"TFXLMWithLMHeadModel"),sFt.forEach(t),U_r=r(RSe," (XLM model)"),RSe.forEach(t),J_r=i(fe),j7=n(fe,"LI",{});var BSe=s(j7);Qbe=n(BSe,"STRONG",{});var lFt=s(Qbe);Y_r=r(lFt,"xlm-roberta"),lFt.forEach(t),K_r=r(BSe," \u2014 "),LW=n(BSe,"A",{href:!0});var iFt=s(LW);Z_r=r(iFt,"TFXLMRobertaForMaskedLM"),iFt.forEach(t),e0r=r(BSe," (XLM-RoBERTa model)"),BSe.forEach(t),fe.forEach(t),o0r=i(vl),T(D7.$$.fragment,vl),vl.forEach(t),bl.forEach(t),qqe=i(f),ec=n(f,"H2",{class:!0});var Vje=s(ec);G7=n(Vje,"A",{id:!0,class:!0,href:!0});var dFt=s(G7);Wbe=n(dFt,"SPAN",{});var cFt=s(Wbe);T(f8.$$.fragment,cFt),cFt.forEach(t),dFt.forEach(t),r0r=i(Vje),Hbe=n(Vje,"SPAN",{});var fFt=s(Hbe);t0r=r(fFt,"TFAutoModelForSeq2SeqLM"),fFt.forEach(t),Vje.forEach(t),Nqe=i(f),rr=n(f,"DIV",{class:!0});var Fl=s(rr);T(m8.$$.fragment,Fl),a0r=i(Fl),oc=n(Fl,"P",{});var $Z=s(oc);n0r=r($Z,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),xW=n($Z,"A",{href:!0});var mFt=s(xW);s0r=r(mFt,"from_pretrained()"),mFt.forEach(t),l0r=r($Z," class method or the "),$W=n($Z,"A",{href:!0});var gFt=s($W);i0r=r(gFt,"from_config()"),gFt.forEach(t),d0r=r($Z,` class
method.`),$Z.forEach(t),c0r=i(Fl),g8=n(Fl,"P",{});var Xje=s(g8);f0r=r(Xje,"This class cannot be instantiated directly using "),Ube=n(Xje,"CODE",{});var hFt=s(Ube);m0r=r(hFt,"__init__()"),hFt.forEach(t),g0r=r(Xje," (throws an error)."),Xje.forEach(t),h0r=i(Fl),$t=n(Fl,"DIV",{class:!0});var gw=s($t);T(h8.$$.fragment,gw),p0r=i(gw),Jbe=n(gw,"P",{});var pFt=s(Jbe);u0r=r(pFt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),pFt.forEach(t),_0r=i(gw),rc=n(gw,"P",{});var kZ=s(rc);b0r=r(kZ,`Note:
Loading a model from its configuration file does `),Ybe=n(kZ,"STRONG",{});var uFt=s(Ybe);v0r=r(uFt,"not"),uFt.forEach(t),F0r=r(kZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),kW=n(kZ,"A",{href:!0});var _Ft=s(kW);T0r=r(_Ft,"from_pretrained()"),_Ft.forEach(t),M0r=r(kZ," to load the model weights."),kZ.forEach(t),E0r=i(gw),T(O7.$$.fragment,gw),gw.forEach(t),C0r=i(Fl),$r=n(Fl,"DIV",{class:!0});var Tl=s($r);T(p8.$$.fragment,Tl),w0r=i(Tl),Kbe=n(Tl,"P",{});var bFt=s(Kbe);A0r=r(bFt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),bFt.forEach(t),y0r=i(Tl),tn=n(Tl,"P",{});var hw=s(tn);L0r=r(hw,"The model class to instantiate is selected based on the "),Zbe=n(hw,"CODE",{});var vFt=s(Zbe);x0r=r(vFt,"model_type"),vFt.forEach(t),$0r=r(hw,` property of the config object (either
passed as an argument or loaded from `),e2e=n(hw,"CODE",{});var FFt=s(e2e);k0r=r(FFt,"pretrained_model_name_or_path"),FFt.forEach(t),S0r=r(hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=n(hw,"CODE",{});var TFt=s(o2e);R0r=r(TFt,"pretrained_model_name_or_path"),TFt.forEach(t),B0r=r(hw,":"),hw.forEach(t),P0r=i(Tl),ye=n(Tl,"UL",{});var Re=s(ye);V7=n(Re,"LI",{});var PSe=s(V7);r2e=n(PSe,"STRONG",{});var MFt=s(r2e);I0r=r(MFt,"bart"),MFt.forEach(t),q0r=r(PSe," \u2014 "),SW=n(PSe,"A",{href:!0});var EFt=s(SW);N0r=r(EFt,"TFBartForConditionalGeneration"),EFt.forEach(t),j0r=r(PSe," (BART model)"),PSe.forEach(t),D0r=i(Re),X7=n(Re,"LI",{});var ISe=s(X7);t2e=n(ISe,"STRONG",{});var CFt=s(t2e);G0r=r(CFt,"blenderbot"),CFt.forEach(t),O0r=r(ISe," \u2014 "),RW=n(ISe,"A",{href:!0});var wFt=s(RW);V0r=r(wFt,"TFBlenderbotForConditionalGeneration"),wFt.forEach(t),X0r=r(ISe," (Blenderbot model)"),ISe.forEach(t),z0r=i(Re),z7=n(Re,"LI",{});var qSe=s(z7);a2e=n(qSe,"STRONG",{});var AFt=s(a2e);Q0r=r(AFt,"blenderbot-small"),AFt.forEach(t),W0r=r(qSe," \u2014 "),BW=n(qSe,"A",{href:!0});var yFt=s(BW);H0r=r(yFt,"TFBlenderbotSmallForConditionalGeneration"),yFt.forEach(t),U0r=r(qSe," (BlenderbotSmall model)"),qSe.forEach(t),J0r=i(Re),Q7=n(Re,"LI",{});var NSe=s(Q7);n2e=n(NSe,"STRONG",{});var LFt=s(n2e);Y0r=r(LFt,"encoder-decoder"),LFt.forEach(t),K0r=r(NSe," \u2014 "),PW=n(NSe,"A",{href:!0});var xFt=s(PW);Z0r=r(xFt,"TFEncoderDecoderModel"),xFt.forEach(t),e1r=r(NSe," (Encoder decoder model)"),NSe.forEach(t),o1r=i(Re),W7=n(Re,"LI",{});var jSe=s(W7);s2e=n(jSe,"STRONG",{});var $Ft=s(s2e);r1r=r($Ft,"led"),$Ft.forEach(t),t1r=r(jSe," \u2014 "),IW=n(jSe,"A",{href:!0});var kFt=s(IW);a1r=r(kFt,"TFLEDForConditionalGeneration"),kFt.forEach(t),n1r=r(jSe," (LED model)"),jSe.forEach(t),s1r=i(Re),H7=n(Re,"LI",{});var DSe=s(H7);l2e=n(DSe,"STRONG",{});var SFt=s(l2e);l1r=r(SFt,"marian"),SFt.forEach(t),i1r=r(DSe," \u2014 "),qW=n(DSe,"A",{href:!0});var RFt=s(qW);d1r=r(RFt,"TFMarianMTModel"),RFt.forEach(t),c1r=r(DSe," (Marian model)"),DSe.forEach(t),f1r=i(Re),U7=n(Re,"LI",{});var GSe=s(U7);i2e=n(GSe,"STRONG",{});var BFt=s(i2e);m1r=r(BFt,"mbart"),BFt.forEach(t),g1r=r(GSe," \u2014 "),NW=n(GSe,"A",{href:!0});var PFt=s(NW);h1r=r(PFt,"TFMBartForConditionalGeneration"),PFt.forEach(t),p1r=r(GSe," (mBART model)"),GSe.forEach(t),u1r=i(Re),J7=n(Re,"LI",{});var OSe=s(J7);d2e=n(OSe,"STRONG",{});var IFt=s(d2e);_1r=r(IFt,"mt5"),IFt.forEach(t),b1r=r(OSe," \u2014 "),jW=n(OSe,"A",{href:!0});var qFt=s(jW);v1r=r(qFt,"TFMT5ForConditionalGeneration"),qFt.forEach(t),F1r=r(OSe," (mT5 model)"),OSe.forEach(t),T1r=i(Re),Y7=n(Re,"LI",{});var VSe=s(Y7);c2e=n(VSe,"STRONG",{});var NFt=s(c2e);M1r=r(NFt,"pegasus"),NFt.forEach(t),E1r=r(VSe," \u2014 "),DW=n(VSe,"A",{href:!0});var jFt=s(DW);C1r=r(jFt,"TFPegasusForConditionalGeneration"),jFt.forEach(t),w1r=r(VSe," (Pegasus model)"),VSe.forEach(t),A1r=i(Re),K7=n(Re,"LI",{});var XSe=s(K7);f2e=n(XSe,"STRONG",{});var DFt=s(f2e);y1r=r(DFt,"t5"),DFt.forEach(t),L1r=r(XSe," \u2014 "),GW=n(XSe,"A",{href:!0});var GFt=s(GW);x1r=r(GFt,"TFT5ForConditionalGeneration"),GFt.forEach(t),$1r=r(XSe," (T5 model)"),XSe.forEach(t),Re.forEach(t),k1r=i(Tl),T(Z7.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),jqe=i(f),tc=n(f,"H2",{class:!0});var zje=s(tc);eM=n(zje,"A",{id:!0,class:!0,href:!0});var OFt=s(eM);m2e=n(OFt,"SPAN",{});var VFt=s(m2e);T(u8.$$.fragment,VFt),VFt.forEach(t),OFt.forEach(t),S1r=i(zje),g2e=n(zje,"SPAN",{});var XFt=s(g2e);R1r=r(XFt,"TFAutoModelForSequenceClassification"),XFt.forEach(t),zje.forEach(t),Dqe=i(f),tr=n(f,"DIV",{class:!0});var Ml=s(tr);T(_8.$$.fragment,Ml),B1r=i(Ml),ac=n(Ml,"P",{});var SZ=s(ac);P1r=r(SZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),OW=n(SZ,"A",{href:!0});var zFt=s(OW);I1r=r(zFt,"from_pretrained()"),zFt.forEach(t),q1r=r(SZ," class method or the "),VW=n(SZ,"A",{href:!0});var QFt=s(VW);N1r=r(QFt,"from_config()"),QFt.forEach(t),j1r=r(SZ,` class
method.`),SZ.forEach(t),D1r=i(Ml),b8=n(Ml,"P",{});var Qje=s(b8);G1r=r(Qje,"This class cannot be instantiated directly using "),h2e=n(Qje,"CODE",{});var WFt=s(h2e);O1r=r(WFt,"__init__()"),WFt.forEach(t),V1r=r(Qje," (throws an error)."),Qje.forEach(t),X1r=i(Ml),kt=n(Ml,"DIV",{class:!0});var pw=s(kt);T(v8.$$.fragment,pw),z1r=i(pw),p2e=n(pw,"P",{});var HFt=s(p2e);Q1r=r(HFt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),HFt.forEach(t),W1r=i(pw),nc=n(pw,"P",{});var RZ=s(nc);H1r=r(RZ,`Note:
Loading a model from its configuration file does `),u2e=n(RZ,"STRONG",{});var UFt=s(u2e);U1r=r(UFt,"not"),UFt.forEach(t),J1r=r(RZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XW=n(RZ,"A",{href:!0});var JFt=s(XW);Y1r=r(JFt,"from_pretrained()"),JFt.forEach(t),K1r=r(RZ," to load the model weights."),RZ.forEach(t),Z1r=i(pw),T(oM.$$.fragment,pw),pw.forEach(t),ebr=i(Ml),kr=n(Ml,"DIV",{class:!0});var El=s(kr);T(F8.$$.fragment,El),obr=i(El),_2e=n(El,"P",{});var YFt=s(_2e);rbr=r(YFt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),YFt.forEach(t),tbr=i(El),an=n(El,"P",{});var uw=s(an);abr=r(uw,"The model class to instantiate is selected based on the "),b2e=n(uw,"CODE",{});var KFt=s(b2e);nbr=r(KFt,"model_type"),KFt.forEach(t),sbr=r(uw,` property of the config object (either
passed as an argument or loaded from `),v2e=n(uw,"CODE",{});var ZFt=s(v2e);lbr=r(ZFt,"pretrained_model_name_or_path"),ZFt.forEach(t),ibr=r(uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F2e=n(uw,"CODE",{});var e6t=s(F2e);dbr=r(e6t,"pretrained_model_name_or_path"),e6t.forEach(t),cbr=r(uw,":"),uw.forEach(t),fbr=i(El),ee=n(El,"UL",{});var ae=s(ee);rM=n(ae,"LI",{});var zSe=s(rM);T2e=n(zSe,"STRONG",{});var o6t=s(T2e);mbr=r(o6t,"albert"),o6t.forEach(t),gbr=r(zSe," \u2014 "),zW=n(zSe,"A",{href:!0});var r6t=s(zW);hbr=r(r6t,"TFAlbertForSequenceClassification"),r6t.forEach(t),pbr=r(zSe," (ALBERT model)"),zSe.forEach(t),ubr=i(ae),tM=n(ae,"LI",{});var QSe=s(tM);M2e=n(QSe,"STRONG",{});var t6t=s(M2e);_br=r(t6t,"bert"),t6t.forEach(t),bbr=r(QSe," \u2014 "),QW=n(QSe,"A",{href:!0});var a6t=s(QW);vbr=r(a6t,"TFBertForSequenceClassification"),a6t.forEach(t),Fbr=r(QSe," (BERT model)"),QSe.forEach(t),Tbr=i(ae),aM=n(ae,"LI",{});var WSe=s(aM);E2e=n(WSe,"STRONG",{});var n6t=s(E2e);Mbr=r(n6t,"camembert"),n6t.forEach(t),Ebr=r(WSe," \u2014 "),WW=n(WSe,"A",{href:!0});var s6t=s(WW);Cbr=r(s6t,"TFCamembertForSequenceClassification"),s6t.forEach(t),wbr=r(WSe," (CamemBERT model)"),WSe.forEach(t),Abr=i(ae),nM=n(ae,"LI",{});var HSe=s(nM);C2e=n(HSe,"STRONG",{});var l6t=s(C2e);ybr=r(l6t,"convbert"),l6t.forEach(t),Lbr=r(HSe," \u2014 "),HW=n(HSe,"A",{href:!0});var i6t=s(HW);xbr=r(i6t,"TFConvBertForSequenceClassification"),i6t.forEach(t),$br=r(HSe," (ConvBERT model)"),HSe.forEach(t),kbr=i(ae),sM=n(ae,"LI",{});var USe=s(sM);w2e=n(USe,"STRONG",{});var d6t=s(w2e);Sbr=r(d6t,"ctrl"),d6t.forEach(t),Rbr=r(USe," \u2014 "),UW=n(USe,"A",{href:!0});var c6t=s(UW);Bbr=r(c6t,"TFCTRLForSequenceClassification"),c6t.forEach(t),Pbr=r(USe," (CTRL model)"),USe.forEach(t),Ibr=i(ae),lM=n(ae,"LI",{});var JSe=s(lM);A2e=n(JSe,"STRONG",{});var f6t=s(A2e);qbr=r(f6t,"deberta"),f6t.forEach(t),Nbr=r(JSe," \u2014 "),JW=n(JSe,"A",{href:!0});var m6t=s(JW);jbr=r(m6t,"TFDebertaForSequenceClassification"),m6t.forEach(t),Dbr=r(JSe," (DeBERTa model)"),JSe.forEach(t),Gbr=i(ae),iM=n(ae,"LI",{});var YSe=s(iM);y2e=n(YSe,"STRONG",{});var g6t=s(y2e);Obr=r(g6t,"deberta-v2"),g6t.forEach(t),Vbr=r(YSe," \u2014 "),YW=n(YSe,"A",{href:!0});var h6t=s(YW);Xbr=r(h6t,"TFDebertaV2ForSequenceClassification"),h6t.forEach(t),zbr=r(YSe," (DeBERTa-v2 model)"),YSe.forEach(t),Qbr=i(ae),dM=n(ae,"LI",{});var KSe=s(dM);L2e=n(KSe,"STRONG",{});var p6t=s(L2e);Wbr=r(p6t,"distilbert"),p6t.forEach(t),Hbr=r(KSe," \u2014 "),KW=n(KSe,"A",{href:!0});var u6t=s(KW);Ubr=r(u6t,"TFDistilBertForSequenceClassification"),u6t.forEach(t),Jbr=r(KSe," (DistilBERT model)"),KSe.forEach(t),Ybr=i(ae),cM=n(ae,"LI",{});var ZSe=s(cM);x2e=n(ZSe,"STRONG",{});var _6t=s(x2e);Kbr=r(_6t,"electra"),_6t.forEach(t),Zbr=r(ZSe," \u2014 "),ZW=n(ZSe,"A",{href:!0});var b6t=s(ZW);e2r=r(b6t,"TFElectraForSequenceClassification"),b6t.forEach(t),o2r=r(ZSe," (ELECTRA model)"),ZSe.forEach(t),r2r=i(ae),fM=n(ae,"LI",{});var eRe=s(fM);$2e=n(eRe,"STRONG",{});var v6t=s($2e);t2r=r(v6t,"flaubert"),v6t.forEach(t),a2r=r(eRe," \u2014 "),eH=n(eRe,"A",{href:!0});var F6t=s(eH);n2r=r(F6t,"TFFlaubertForSequenceClassification"),F6t.forEach(t),s2r=r(eRe," (FlauBERT model)"),eRe.forEach(t),l2r=i(ae),mM=n(ae,"LI",{});var oRe=s(mM);k2e=n(oRe,"STRONG",{});var T6t=s(k2e);i2r=r(T6t,"funnel"),T6t.forEach(t),d2r=r(oRe," \u2014 "),oH=n(oRe,"A",{href:!0});var M6t=s(oH);c2r=r(M6t,"TFFunnelForSequenceClassification"),M6t.forEach(t),f2r=r(oRe," (Funnel Transformer model)"),oRe.forEach(t),m2r=i(ae),gM=n(ae,"LI",{});var rRe=s(gM);S2e=n(rRe,"STRONG",{});var E6t=s(S2e);g2r=r(E6t,"gpt2"),E6t.forEach(t),h2r=r(rRe," \u2014 "),rH=n(rRe,"A",{href:!0});var C6t=s(rH);p2r=r(C6t,"TFGPT2ForSequenceClassification"),C6t.forEach(t),u2r=r(rRe," (OpenAI GPT-2 model)"),rRe.forEach(t),_2r=i(ae),hM=n(ae,"LI",{});var tRe=s(hM);R2e=n(tRe,"STRONG",{});var w6t=s(R2e);b2r=r(w6t,"gptj"),w6t.forEach(t),v2r=r(tRe," \u2014 "),tH=n(tRe,"A",{href:!0});var A6t=s(tH);F2r=r(A6t,"TFGPTJForSequenceClassification"),A6t.forEach(t),T2r=r(tRe," (GPT-J model)"),tRe.forEach(t),M2r=i(ae),pM=n(ae,"LI",{});var aRe=s(pM);B2e=n(aRe,"STRONG",{});var y6t=s(B2e);E2r=r(y6t,"layoutlm"),y6t.forEach(t),C2r=r(aRe," \u2014 "),aH=n(aRe,"A",{href:!0});var L6t=s(aH);w2r=r(L6t,"TFLayoutLMForSequenceClassification"),L6t.forEach(t),A2r=r(aRe," (LayoutLM model)"),aRe.forEach(t),y2r=i(ae),uM=n(ae,"LI",{});var nRe=s(uM);P2e=n(nRe,"STRONG",{});var x6t=s(P2e);L2r=r(x6t,"longformer"),x6t.forEach(t),x2r=r(nRe," \u2014 "),nH=n(nRe,"A",{href:!0});var $6t=s(nH);$2r=r($6t,"TFLongformerForSequenceClassification"),$6t.forEach(t),k2r=r(nRe," (Longformer model)"),nRe.forEach(t),S2r=i(ae),_M=n(ae,"LI",{});var sRe=s(_M);I2e=n(sRe,"STRONG",{});var k6t=s(I2e);R2r=r(k6t,"mobilebert"),k6t.forEach(t),B2r=r(sRe," \u2014 "),sH=n(sRe,"A",{href:!0});var S6t=s(sH);P2r=r(S6t,"TFMobileBertForSequenceClassification"),S6t.forEach(t),I2r=r(sRe," (MobileBERT model)"),sRe.forEach(t),q2r=i(ae),bM=n(ae,"LI",{});var lRe=s(bM);q2e=n(lRe,"STRONG",{});var R6t=s(q2e);N2r=r(R6t,"mpnet"),R6t.forEach(t),j2r=r(lRe," \u2014 "),lH=n(lRe,"A",{href:!0});var B6t=s(lH);D2r=r(B6t,"TFMPNetForSequenceClassification"),B6t.forEach(t),G2r=r(lRe," (MPNet model)"),lRe.forEach(t),O2r=i(ae),vM=n(ae,"LI",{});var iRe=s(vM);N2e=n(iRe,"STRONG",{});var P6t=s(N2e);V2r=r(P6t,"openai-gpt"),P6t.forEach(t),X2r=r(iRe," \u2014 "),iH=n(iRe,"A",{href:!0});var I6t=s(iH);z2r=r(I6t,"TFOpenAIGPTForSequenceClassification"),I6t.forEach(t),Q2r=r(iRe," (OpenAI GPT model)"),iRe.forEach(t),W2r=i(ae),FM=n(ae,"LI",{});var dRe=s(FM);j2e=n(dRe,"STRONG",{});var q6t=s(j2e);H2r=r(q6t,"rembert"),q6t.forEach(t),U2r=r(dRe," \u2014 "),dH=n(dRe,"A",{href:!0});var N6t=s(dH);J2r=r(N6t,"TFRemBertForSequenceClassification"),N6t.forEach(t),Y2r=r(dRe," (RemBERT model)"),dRe.forEach(t),K2r=i(ae),TM=n(ae,"LI",{});var cRe=s(TM);D2e=n(cRe,"STRONG",{});var j6t=s(D2e);Z2r=r(j6t,"roberta"),j6t.forEach(t),evr=r(cRe," \u2014 "),cH=n(cRe,"A",{href:!0});var D6t=s(cH);ovr=r(D6t,"TFRobertaForSequenceClassification"),D6t.forEach(t),rvr=r(cRe," (RoBERTa model)"),cRe.forEach(t),tvr=i(ae),MM=n(ae,"LI",{});var fRe=s(MM);G2e=n(fRe,"STRONG",{});var G6t=s(G2e);avr=r(G6t,"roformer"),G6t.forEach(t),nvr=r(fRe," \u2014 "),fH=n(fRe,"A",{href:!0});var O6t=s(fH);svr=r(O6t,"TFRoFormerForSequenceClassification"),O6t.forEach(t),lvr=r(fRe," (RoFormer model)"),fRe.forEach(t),ivr=i(ae),EM=n(ae,"LI",{});var mRe=s(EM);O2e=n(mRe,"STRONG",{});var V6t=s(O2e);dvr=r(V6t,"tapas"),V6t.forEach(t),cvr=r(mRe," \u2014 "),mH=n(mRe,"A",{href:!0});var X6t=s(mH);fvr=r(X6t,"TFTapasForSequenceClassification"),X6t.forEach(t),mvr=r(mRe," (TAPAS model)"),mRe.forEach(t),gvr=i(ae),CM=n(ae,"LI",{});var gRe=s(CM);V2e=n(gRe,"STRONG",{});var z6t=s(V2e);hvr=r(z6t,"transfo-xl"),z6t.forEach(t),pvr=r(gRe," \u2014 "),gH=n(gRe,"A",{href:!0});var Q6t=s(gH);uvr=r(Q6t,"TFTransfoXLForSequenceClassification"),Q6t.forEach(t),_vr=r(gRe," (Transformer-XL model)"),gRe.forEach(t),bvr=i(ae),wM=n(ae,"LI",{});var hRe=s(wM);X2e=n(hRe,"STRONG",{});var W6t=s(X2e);vvr=r(W6t,"xlm"),W6t.forEach(t),Fvr=r(hRe," \u2014 "),hH=n(hRe,"A",{href:!0});var H6t=s(hH);Tvr=r(H6t,"TFXLMForSequenceClassification"),H6t.forEach(t),Mvr=r(hRe," (XLM model)"),hRe.forEach(t),Evr=i(ae),AM=n(ae,"LI",{});var pRe=s(AM);z2e=n(pRe,"STRONG",{});var U6t=s(z2e);Cvr=r(U6t,"xlm-roberta"),U6t.forEach(t),wvr=r(pRe," \u2014 "),pH=n(pRe,"A",{href:!0});var J6t=s(pH);Avr=r(J6t,"TFXLMRobertaForSequenceClassification"),J6t.forEach(t),yvr=r(pRe," (XLM-RoBERTa model)"),pRe.forEach(t),Lvr=i(ae),yM=n(ae,"LI",{});var uRe=s(yM);Q2e=n(uRe,"STRONG",{});var Y6t=s(Q2e);xvr=r(Y6t,"xlnet"),Y6t.forEach(t),$vr=r(uRe," \u2014 "),uH=n(uRe,"A",{href:!0});var K6t=s(uH);kvr=r(K6t,"TFXLNetForSequenceClassification"),K6t.forEach(t),Svr=r(uRe," (XLNet model)"),uRe.forEach(t),ae.forEach(t),Rvr=i(El),T(LM.$$.fragment,El),El.forEach(t),Ml.forEach(t),Gqe=i(f),sc=n(f,"H2",{class:!0});var Wje=s(sc);xM=n(Wje,"A",{id:!0,class:!0,href:!0});var Z6t=s(xM);W2e=n(Z6t,"SPAN",{});var eTt=s(W2e);T(T8.$$.fragment,eTt),eTt.forEach(t),Z6t.forEach(t),Bvr=i(Wje),H2e=n(Wje,"SPAN",{});var oTt=s(H2e);Pvr=r(oTt,"TFAutoModelForMultipleChoice"),oTt.forEach(t),Wje.forEach(t),Oqe=i(f),ar=n(f,"DIV",{class:!0});var Cl=s(ar);T(M8.$$.fragment,Cl),Ivr=i(Cl),lc=n(Cl,"P",{});var BZ=s(lc);qvr=r(BZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_H=n(BZ,"A",{href:!0});var rTt=s(_H);Nvr=r(rTt,"from_pretrained()"),rTt.forEach(t),jvr=r(BZ," class method or the "),bH=n(BZ,"A",{href:!0});var tTt=s(bH);Dvr=r(tTt,"from_config()"),tTt.forEach(t),Gvr=r(BZ,` class
method.`),BZ.forEach(t),Ovr=i(Cl),E8=n(Cl,"P",{});var Hje=s(E8);Vvr=r(Hje,"This class cannot be instantiated directly using "),U2e=n(Hje,"CODE",{});var aTt=s(U2e);Xvr=r(aTt,"__init__()"),aTt.forEach(t),zvr=r(Hje," (throws an error)."),Hje.forEach(t),Qvr=i(Cl),St=n(Cl,"DIV",{class:!0});var _w=s(St);T(C8.$$.fragment,_w),Wvr=i(_w),J2e=n(_w,"P",{});var nTt=s(J2e);Hvr=r(nTt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),nTt.forEach(t),Uvr=i(_w),ic=n(_w,"P",{});var PZ=s(ic);Jvr=r(PZ,`Note:
Loading a model from its configuration file does `),Y2e=n(PZ,"STRONG",{});var sTt=s(Y2e);Yvr=r(sTt,"not"),sTt.forEach(t),Kvr=r(PZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),vH=n(PZ,"A",{href:!0});var lTt=s(vH);Zvr=r(lTt,"from_pretrained()"),lTt.forEach(t),eFr=r(PZ," to load the model weights."),PZ.forEach(t),oFr=i(_w),T($M.$$.fragment,_w),_w.forEach(t),rFr=i(Cl),Sr=n(Cl,"DIV",{class:!0});var wl=s(Sr);T(w8.$$.fragment,wl),tFr=i(wl),K2e=n(wl,"P",{});var iTt=s(K2e);aFr=r(iTt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),iTt.forEach(t),nFr=i(wl),nn=n(wl,"P",{});var bw=s(nn);sFr=r(bw,"The model class to instantiate is selected based on the "),Z2e=n(bw,"CODE",{});var dTt=s(Z2e);lFr=r(dTt,"model_type"),dTt.forEach(t),iFr=r(bw,` property of the config object (either
passed as an argument or loaded from `),eve=n(bw,"CODE",{});var cTt=s(eve);dFr=r(cTt,"pretrained_model_name_or_path"),cTt.forEach(t),cFr=r(bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ove=n(bw,"CODE",{});var fTt=s(ove);fFr=r(fTt,"pretrained_model_name_or_path"),fTt.forEach(t),mFr=r(bw,":"),bw.forEach(t),gFr=i(wl),pe=n(wl,"UL",{});var be=s(pe);kM=n(be,"LI",{});var _Re=s(kM);rve=n(_Re,"STRONG",{});var mTt=s(rve);hFr=r(mTt,"albert"),mTt.forEach(t),pFr=r(_Re," \u2014 "),FH=n(_Re,"A",{href:!0});var gTt=s(FH);uFr=r(gTt,"TFAlbertForMultipleChoice"),gTt.forEach(t),_Fr=r(_Re," (ALBERT model)"),_Re.forEach(t),bFr=i(be),SM=n(be,"LI",{});var bRe=s(SM);tve=n(bRe,"STRONG",{});var hTt=s(tve);vFr=r(hTt,"bert"),hTt.forEach(t),FFr=r(bRe," \u2014 "),TH=n(bRe,"A",{href:!0});var pTt=s(TH);TFr=r(pTt,"TFBertForMultipleChoice"),pTt.forEach(t),MFr=r(bRe," (BERT model)"),bRe.forEach(t),EFr=i(be),RM=n(be,"LI",{});var vRe=s(RM);ave=n(vRe,"STRONG",{});var uTt=s(ave);CFr=r(uTt,"camembert"),uTt.forEach(t),wFr=r(vRe," \u2014 "),MH=n(vRe,"A",{href:!0});var _Tt=s(MH);AFr=r(_Tt,"TFCamembertForMultipleChoice"),_Tt.forEach(t),yFr=r(vRe," (CamemBERT model)"),vRe.forEach(t),LFr=i(be),BM=n(be,"LI",{});var FRe=s(BM);nve=n(FRe,"STRONG",{});var bTt=s(nve);xFr=r(bTt,"convbert"),bTt.forEach(t),$Fr=r(FRe," \u2014 "),EH=n(FRe,"A",{href:!0});var vTt=s(EH);kFr=r(vTt,"TFConvBertForMultipleChoice"),vTt.forEach(t),SFr=r(FRe," (ConvBERT model)"),FRe.forEach(t),RFr=i(be),PM=n(be,"LI",{});var TRe=s(PM);sve=n(TRe,"STRONG",{});var FTt=s(sve);BFr=r(FTt,"distilbert"),FTt.forEach(t),PFr=r(TRe," \u2014 "),CH=n(TRe,"A",{href:!0});var TTt=s(CH);IFr=r(TTt,"TFDistilBertForMultipleChoice"),TTt.forEach(t),qFr=r(TRe," (DistilBERT model)"),TRe.forEach(t),NFr=i(be),IM=n(be,"LI",{});var MRe=s(IM);lve=n(MRe,"STRONG",{});var MTt=s(lve);jFr=r(MTt,"electra"),MTt.forEach(t),DFr=r(MRe," \u2014 "),wH=n(MRe,"A",{href:!0});var ETt=s(wH);GFr=r(ETt,"TFElectraForMultipleChoice"),ETt.forEach(t),OFr=r(MRe," (ELECTRA model)"),MRe.forEach(t),VFr=i(be),qM=n(be,"LI",{});var ERe=s(qM);ive=n(ERe,"STRONG",{});var CTt=s(ive);XFr=r(CTt,"flaubert"),CTt.forEach(t),zFr=r(ERe," \u2014 "),AH=n(ERe,"A",{href:!0});var wTt=s(AH);QFr=r(wTt,"TFFlaubertForMultipleChoice"),wTt.forEach(t),WFr=r(ERe," (FlauBERT model)"),ERe.forEach(t),HFr=i(be),NM=n(be,"LI",{});var CRe=s(NM);dve=n(CRe,"STRONG",{});var ATt=s(dve);UFr=r(ATt,"funnel"),ATt.forEach(t),JFr=r(CRe," \u2014 "),yH=n(CRe,"A",{href:!0});var yTt=s(yH);YFr=r(yTt,"TFFunnelForMultipleChoice"),yTt.forEach(t),KFr=r(CRe," (Funnel Transformer model)"),CRe.forEach(t),ZFr=i(be),jM=n(be,"LI",{});var wRe=s(jM);cve=n(wRe,"STRONG",{});var LTt=s(cve);e6r=r(LTt,"longformer"),LTt.forEach(t),o6r=r(wRe," \u2014 "),LH=n(wRe,"A",{href:!0});var xTt=s(LH);r6r=r(xTt,"TFLongformerForMultipleChoice"),xTt.forEach(t),t6r=r(wRe," (Longformer model)"),wRe.forEach(t),a6r=i(be),DM=n(be,"LI",{});var ARe=s(DM);fve=n(ARe,"STRONG",{});var $Tt=s(fve);n6r=r($Tt,"mobilebert"),$Tt.forEach(t),s6r=r(ARe," \u2014 "),xH=n(ARe,"A",{href:!0});var kTt=s(xH);l6r=r(kTt,"TFMobileBertForMultipleChoice"),kTt.forEach(t),i6r=r(ARe," (MobileBERT model)"),ARe.forEach(t),d6r=i(be),GM=n(be,"LI",{});var yRe=s(GM);mve=n(yRe,"STRONG",{});var STt=s(mve);c6r=r(STt,"mpnet"),STt.forEach(t),f6r=r(yRe," \u2014 "),$H=n(yRe,"A",{href:!0});var RTt=s($H);m6r=r(RTt,"TFMPNetForMultipleChoice"),RTt.forEach(t),g6r=r(yRe," (MPNet model)"),yRe.forEach(t),h6r=i(be),OM=n(be,"LI",{});var LRe=s(OM);gve=n(LRe,"STRONG",{});var BTt=s(gve);p6r=r(BTt,"rembert"),BTt.forEach(t),u6r=r(LRe," \u2014 "),kH=n(LRe,"A",{href:!0});var PTt=s(kH);_6r=r(PTt,"TFRemBertForMultipleChoice"),PTt.forEach(t),b6r=r(LRe," (RemBERT model)"),LRe.forEach(t),v6r=i(be),VM=n(be,"LI",{});var xRe=s(VM);hve=n(xRe,"STRONG",{});var ITt=s(hve);F6r=r(ITt,"roberta"),ITt.forEach(t),T6r=r(xRe," \u2014 "),SH=n(xRe,"A",{href:!0});var qTt=s(SH);M6r=r(qTt,"TFRobertaForMultipleChoice"),qTt.forEach(t),E6r=r(xRe," (RoBERTa model)"),xRe.forEach(t),C6r=i(be),XM=n(be,"LI",{});var $Re=s(XM);pve=n($Re,"STRONG",{});var NTt=s(pve);w6r=r(NTt,"roformer"),NTt.forEach(t),A6r=r($Re," \u2014 "),RH=n($Re,"A",{href:!0});var jTt=s(RH);y6r=r(jTt,"TFRoFormerForMultipleChoice"),jTt.forEach(t),L6r=r($Re," (RoFormer model)"),$Re.forEach(t),x6r=i(be),zM=n(be,"LI",{});var kRe=s(zM);uve=n(kRe,"STRONG",{});var DTt=s(uve);$6r=r(DTt,"xlm"),DTt.forEach(t),k6r=r(kRe," \u2014 "),BH=n(kRe,"A",{href:!0});var GTt=s(BH);S6r=r(GTt,"TFXLMForMultipleChoice"),GTt.forEach(t),R6r=r(kRe," (XLM model)"),kRe.forEach(t),B6r=i(be),QM=n(be,"LI",{});var SRe=s(QM);_ve=n(SRe,"STRONG",{});var OTt=s(_ve);P6r=r(OTt,"xlm-roberta"),OTt.forEach(t),I6r=r(SRe," \u2014 "),PH=n(SRe,"A",{href:!0});var VTt=s(PH);q6r=r(VTt,"TFXLMRobertaForMultipleChoice"),VTt.forEach(t),N6r=r(SRe," (XLM-RoBERTa model)"),SRe.forEach(t),j6r=i(be),WM=n(be,"LI",{});var RRe=s(WM);bve=n(RRe,"STRONG",{});var XTt=s(bve);D6r=r(XTt,"xlnet"),XTt.forEach(t),G6r=r(RRe," \u2014 "),IH=n(RRe,"A",{href:!0});var zTt=s(IH);O6r=r(zTt,"TFXLNetForMultipleChoice"),zTt.forEach(t),V6r=r(RRe," (XLNet model)"),RRe.forEach(t),be.forEach(t),X6r=i(wl),T(HM.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),Vqe=i(f),dc=n(f,"H2",{class:!0});var Uje=s(dc);UM=n(Uje,"A",{id:!0,class:!0,href:!0});var QTt=s(UM);vve=n(QTt,"SPAN",{});var WTt=s(vve);T(A8.$$.fragment,WTt),WTt.forEach(t),QTt.forEach(t),z6r=i(Uje),Fve=n(Uje,"SPAN",{});var HTt=s(Fve);Q6r=r(HTt,"TFAutoModelForNextSentencePrediction"),HTt.forEach(t),Uje.forEach(t),Xqe=i(f),nr=n(f,"DIV",{class:!0});var Al=s(nr);T(y8.$$.fragment,Al),W6r=i(Al),cc=n(Al,"P",{});var IZ=s(cc);H6r=r(IZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),qH=n(IZ,"A",{href:!0});var UTt=s(qH);U6r=r(UTt,"from_pretrained()"),UTt.forEach(t),J6r=r(IZ," class method or the "),NH=n(IZ,"A",{href:!0});var JTt=s(NH);Y6r=r(JTt,"from_config()"),JTt.forEach(t),K6r=r(IZ,` class
method.`),IZ.forEach(t),Z6r=i(Al),L8=n(Al,"P",{});var Jje=s(L8);eTr=r(Jje,"This class cannot be instantiated directly using "),Tve=n(Jje,"CODE",{});var YTt=s(Tve);oTr=r(YTt,"__init__()"),YTt.forEach(t),rTr=r(Jje," (throws an error)."),Jje.forEach(t),tTr=i(Al),Rt=n(Al,"DIV",{class:!0});var vw=s(Rt);T(x8.$$.fragment,vw),aTr=i(vw),Mve=n(vw,"P",{});var KTt=s(Mve);nTr=r(KTt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),KTt.forEach(t),sTr=i(vw),fc=n(vw,"P",{});var qZ=s(fc);lTr=r(qZ,`Note:
Loading a model from its configuration file does `),Eve=n(qZ,"STRONG",{});var ZTt=s(Eve);iTr=r(ZTt,"not"),ZTt.forEach(t),dTr=r(qZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=n(qZ,"A",{href:!0});var e7t=s(jH);cTr=r(e7t,"from_pretrained()"),e7t.forEach(t),fTr=r(qZ," to load the model weights."),qZ.forEach(t),mTr=i(vw),T(JM.$$.fragment,vw),vw.forEach(t),gTr=i(Al),Rr=n(Al,"DIV",{class:!0});var yl=s(Rr);T($8.$$.fragment,yl),hTr=i(yl),Cve=n(yl,"P",{});var o7t=s(Cve);pTr=r(o7t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),o7t.forEach(t),uTr=i(yl),sn=n(yl,"P",{});var Fw=s(sn);_Tr=r(Fw,"The model class to instantiate is selected based on the "),wve=n(Fw,"CODE",{});var r7t=s(wve);bTr=r(r7t,"model_type"),r7t.forEach(t),vTr=r(Fw,` property of the config object (either
passed as an argument or loaded from `),Ave=n(Fw,"CODE",{});var t7t=s(Ave);FTr=r(t7t,"pretrained_model_name_or_path"),t7t.forEach(t),TTr=r(Fw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yve=n(Fw,"CODE",{});var a7t=s(yve);MTr=r(a7t,"pretrained_model_name_or_path"),a7t.forEach(t),ETr=r(Fw,":"),Fw.forEach(t),CTr=i(yl),k8=n(yl,"UL",{});var Yje=s(k8);YM=n(Yje,"LI",{});var BRe=s(YM);Lve=n(BRe,"STRONG",{});var n7t=s(Lve);wTr=r(n7t,"bert"),n7t.forEach(t),ATr=r(BRe," \u2014 "),DH=n(BRe,"A",{href:!0});var s7t=s(DH);yTr=r(s7t,"TFBertForNextSentencePrediction"),s7t.forEach(t),LTr=r(BRe," (BERT model)"),BRe.forEach(t),xTr=i(Yje),KM=n(Yje,"LI",{});var PRe=s(KM);xve=n(PRe,"STRONG",{});var l7t=s(xve);$Tr=r(l7t,"mobilebert"),l7t.forEach(t),kTr=r(PRe," \u2014 "),GH=n(PRe,"A",{href:!0});var i7t=s(GH);STr=r(i7t,"TFMobileBertForNextSentencePrediction"),i7t.forEach(t),RTr=r(PRe," (MobileBERT model)"),PRe.forEach(t),Yje.forEach(t),BTr=i(yl),T(ZM.$$.fragment,yl),yl.forEach(t),Al.forEach(t),zqe=i(f),mc=n(f,"H2",{class:!0});var Kje=s(mc);e4=n(Kje,"A",{id:!0,class:!0,href:!0});var d7t=s(e4);$ve=n(d7t,"SPAN",{});var c7t=s($ve);T(S8.$$.fragment,c7t),c7t.forEach(t),d7t.forEach(t),PTr=i(Kje),kve=n(Kje,"SPAN",{});var f7t=s(kve);ITr=r(f7t,"TFAutoModelForTableQuestionAnswering"),f7t.forEach(t),Kje.forEach(t),Qqe=i(f),sr=n(f,"DIV",{class:!0});var Ll=s(sr);T(R8.$$.fragment,Ll),qTr=i(Ll),gc=n(Ll,"P",{});var NZ=s(gc);NTr=r(NZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),OH=n(NZ,"A",{href:!0});var m7t=s(OH);jTr=r(m7t,"from_pretrained()"),m7t.forEach(t),DTr=r(NZ," class method or the "),VH=n(NZ,"A",{href:!0});var g7t=s(VH);GTr=r(g7t,"from_config()"),g7t.forEach(t),OTr=r(NZ,` class
method.`),NZ.forEach(t),VTr=i(Ll),B8=n(Ll,"P",{});var Zje=s(B8);XTr=r(Zje,"This class cannot be instantiated directly using "),Sve=n(Zje,"CODE",{});var h7t=s(Sve);zTr=r(h7t,"__init__()"),h7t.forEach(t),QTr=r(Zje," (throws an error)."),Zje.forEach(t),WTr=i(Ll),Bt=n(Ll,"DIV",{class:!0});var Tw=s(Bt);T(P8.$$.fragment,Tw),HTr=i(Tw),Rve=n(Tw,"P",{});var p7t=s(Rve);UTr=r(p7t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),p7t.forEach(t),JTr=i(Tw),hc=n(Tw,"P",{});var jZ=s(hc);YTr=r(jZ,`Note:
Loading a model from its configuration file does `),Bve=n(jZ,"STRONG",{});var u7t=s(Bve);KTr=r(u7t,"not"),u7t.forEach(t),ZTr=r(jZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=n(jZ,"A",{href:!0});var _7t=s(XH);e7r=r(_7t,"from_pretrained()"),_7t.forEach(t),o7r=r(jZ," to load the model weights."),jZ.forEach(t),r7r=i(Tw),T(o4.$$.fragment,Tw),Tw.forEach(t),t7r=i(Ll),Br=n(Ll,"DIV",{class:!0});var xl=s(Br);T(I8.$$.fragment,xl),a7r=i(xl),Pve=n(xl,"P",{});var b7t=s(Pve);n7r=r(b7t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),b7t.forEach(t),s7r=i(xl),ln=n(xl,"P",{});var Mw=s(ln);l7r=r(Mw,"The model class to instantiate is selected based on the "),Ive=n(Mw,"CODE",{});var v7t=s(Ive);i7r=r(v7t,"model_type"),v7t.forEach(t),d7r=r(Mw,` property of the config object (either
passed as an argument or loaded from `),qve=n(Mw,"CODE",{});var F7t=s(qve);c7r=r(F7t,"pretrained_model_name_or_path"),F7t.forEach(t),f7r=r(Mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nve=n(Mw,"CODE",{});var T7t=s(Nve);m7r=r(T7t,"pretrained_model_name_or_path"),T7t.forEach(t),g7r=r(Mw,":"),Mw.forEach(t),h7r=i(xl),jve=n(xl,"UL",{});var M7t=s(jve);r4=n(M7t,"LI",{});var IRe=s(r4);Dve=n(IRe,"STRONG",{});var E7t=s(Dve);p7r=r(E7t,"tapas"),E7t.forEach(t),u7r=r(IRe," \u2014 "),zH=n(IRe,"A",{href:!0});var C7t=s(zH);_7r=r(C7t,"TFTapasForQuestionAnswering"),C7t.forEach(t),b7r=r(IRe," (TAPAS model)"),IRe.forEach(t),M7t.forEach(t),v7r=i(xl),T(t4.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),Wqe=i(f),pc=n(f,"H2",{class:!0});var eDe=s(pc);a4=n(eDe,"A",{id:!0,class:!0,href:!0});var w7t=s(a4);Gve=n(w7t,"SPAN",{});var A7t=s(Gve);T(q8.$$.fragment,A7t),A7t.forEach(t),w7t.forEach(t),F7r=i(eDe),Ove=n(eDe,"SPAN",{});var y7t=s(Ove);T7r=r(y7t,"TFAutoModelForTokenClassification"),y7t.forEach(t),eDe.forEach(t),Hqe=i(f),lr=n(f,"DIV",{class:!0});var $l=s(lr);T(N8.$$.fragment,$l),M7r=i($l),uc=n($l,"P",{});var DZ=s(uc);E7r=r(DZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),QH=n(DZ,"A",{href:!0});var L7t=s(QH);C7r=r(L7t,"from_pretrained()"),L7t.forEach(t),w7r=r(DZ," class method or the "),WH=n(DZ,"A",{href:!0});var x7t=s(WH);A7r=r(x7t,"from_config()"),x7t.forEach(t),y7r=r(DZ,` class
method.`),DZ.forEach(t),L7r=i($l),j8=n($l,"P",{});var oDe=s(j8);x7r=r(oDe,"This class cannot be instantiated directly using "),Vve=n(oDe,"CODE",{});var $7t=s(Vve);$7r=r($7t,"__init__()"),$7t.forEach(t),k7r=r(oDe," (throws an error)."),oDe.forEach(t),S7r=i($l),Pt=n($l,"DIV",{class:!0});var Ew=s(Pt);T(D8.$$.fragment,Ew),R7r=i(Ew),Xve=n(Ew,"P",{});var k7t=s(Xve);B7r=r(k7t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),k7t.forEach(t),P7r=i(Ew),_c=n(Ew,"P",{});var GZ=s(_c);I7r=r(GZ,`Note:
Loading a model from its configuration file does `),zve=n(GZ,"STRONG",{});var S7t=s(zve);q7r=r(S7t,"not"),S7t.forEach(t),N7r=r(GZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),HH=n(GZ,"A",{href:!0});var R7t=s(HH);j7r=r(R7t,"from_pretrained()"),R7t.forEach(t),D7r=r(GZ," to load the model weights."),GZ.forEach(t),G7r=i(Ew),T(n4.$$.fragment,Ew),Ew.forEach(t),O7r=i($l),Pr=n($l,"DIV",{class:!0});var kl=s(Pr);T(G8.$$.fragment,kl),V7r=i(kl),Qve=n(kl,"P",{});var B7t=s(Qve);X7r=r(B7t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),B7t.forEach(t),z7r=i(kl),dn=n(kl,"P",{});var Cw=s(dn);Q7r=r(Cw,"The model class to instantiate is selected based on the "),Wve=n(Cw,"CODE",{});var P7t=s(Wve);W7r=r(P7t,"model_type"),P7t.forEach(t),H7r=r(Cw,` property of the config object (either
passed as an argument or loaded from `),Hve=n(Cw,"CODE",{});var I7t=s(Hve);U7r=r(I7t,"pretrained_model_name_or_path"),I7t.forEach(t),J7r=r(Cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uve=n(Cw,"CODE",{});var q7t=s(Uve);Y7r=r(q7t,"pretrained_model_name_or_path"),q7t.forEach(t),K7r=r(Cw,":"),Cw.forEach(t),Z7r=i(kl),de=n(kl,"UL",{});var me=s(de);s4=n(me,"LI",{});var qRe=s(s4);Jve=n(qRe,"STRONG",{});var N7t=s(Jve);eMr=r(N7t,"albert"),N7t.forEach(t),oMr=r(qRe," \u2014 "),UH=n(qRe,"A",{href:!0});var j7t=s(UH);rMr=r(j7t,"TFAlbertForTokenClassification"),j7t.forEach(t),tMr=r(qRe," (ALBERT model)"),qRe.forEach(t),aMr=i(me),l4=n(me,"LI",{});var NRe=s(l4);Yve=n(NRe,"STRONG",{});var D7t=s(Yve);nMr=r(D7t,"bert"),D7t.forEach(t),sMr=r(NRe," \u2014 "),JH=n(NRe,"A",{href:!0});var G7t=s(JH);lMr=r(G7t,"TFBertForTokenClassification"),G7t.forEach(t),iMr=r(NRe," (BERT model)"),NRe.forEach(t),dMr=i(me),i4=n(me,"LI",{});var jRe=s(i4);Kve=n(jRe,"STRONG",{});var O7t=s(Kve);cMr=r(O7t,"camembert"),O7t.forEach(t),fMr=r(jRe," \u2014 "),YH=n(jRe,"A",{href:!0});var V7t=s(YH);mMr=r(V7t,"TFCamembertForTokenClassification"),V7t.forEach(t),gMr=r(jRe," (CamemBERT model)"),jRe.forEach(t),hMr=i(me),d4=n(me,"LI",{});var DRe=s(d4);Zve=n(DRe,"STRONG",{});var X7t=s(Zve);pMr=r(X7t,"convbert"),X7t.forEach(t),uMr=r(DRe," \u2014 "),KH=n(DRe,"A",{href:!0});var z7t=s(KH);_Mr=r(z7t,"TFConvBertForTokenClassification"),z7t.forEach(t),bMr=r(DRe," (ConvBERT model)"),DRe.forEach(t),vMr=i(me),c4=n(me,"LI",{});var GRe=s(c4);eFe=n(GRe,"STRONG",{});var Q7t=s(eFe);FMr=r(Q7t,"deberta"),Q7t.forEach(t),TMr=r(GRe," \u2014 "),ZH=n(GRe,"A",{href:!0});var W7t=s(ZH);MMr=r(W7t,"TFDebertaForTokenClassification"),W7t.forEach(t),EMr=r(GRe," (DeBERTa model)"),GRe.forEach(t),CMr=i(me),f4=n(me,"LI",{});var ORe=s(f4);oFe=n(ORe,"STRONG",{});var H7t=s(oFe);wMr=r(H7t,"deberta-v2"),H7t.forEach(t),AMr=r(ORe," \u2014 "),eU=n(ORe,"A",{href:!0});var U7t=s(eU);yMr=r(U7t,"TFDebertaV2ForTokenClassification"),U7t.forEach(t),LMr=r(ORe," (DeBERTa-v2 model)"),ORe.forEach(t),xMr=i(me),m4=n(me,"LI",{});var VRe=s(m4);rFe=n(VRe,"STRONG",{});var J7t=s(rFe);$Mr=r(J7t,"distilbert"),J7t.forEach(t),kMr=r(VRe," \u2014 "),oU=n(VRe,"A",{href:!0});var Y7t=s(oU);SMr=r(Y7t,"TFDistilBertForTokenClassification"),Y7t.forEach(t),RMr=r(VRe," (DistilBERT model)"),VRe.forEach(t),BMr=i(me),g4=n(me,"LI",{});var XRe=s(g4);tFe=n(XRe,"STRONG",{});var K7t=s(tFe);PMr=r(K7t,"electra"),K7t.forEach(t),IMr=r(XRe," \u2014 "),rU=n(XRe,"A",{href:!0});var Z7t=s(rU);qMr=r(Z7t,"TFElectraForTokenClassification"),Z7t.forEach(t),NMr=r(XRe," (ELECTRA model)"),XRe.forEach(t),jMr=i(me),h4=n(me,"LI",{});var zRe=s(h4);aFe=n(zRe,"STRONG",{});var eMt=s(aFe);DMr=r(eMt,"flaubert"),eMt.forEach(t),GMr=r(zRe," \u2014 "),tU=n(zRe,"A",{href:!0});var oMt=s(tU);OMr=r(oMt,"TFFlaubertForTokenClassification"),oMt.forEach(t),VMr=r(zRe," (FlauBERT model)"),zRe.forEach(t),XMr=i(me),p4=n(me,"LI",{});var QRe=s(p4);nFe=n(QRe,"STRONG",{});var rMt=s(nFe);zMr=r(rMt,"funnel"),rMt.forEach(t),QMr=r(QRe," \u2014 "),aU=n(QRe,"A",{href:!0});var tMt=s(aU);WMr=r(tMt,"TFFunnelForTokenClassification"),tMt.forEach(t),HMr=r(QRe," (Funnel Transformer model)"),QRe.forEach(t),UMr=i(me),u4=n(me,"LI",{});var WRe=s(u4);sFe=n(WRe,"STRONG",{});var aMt=s(sFe);JMr=r(aMt,"layoutlm"),aMt.forEach(t),YMr=r(WRe," \u2014 "),nU=n(WRe,"A",{href:!0});var nMt=s(nU);KMr=r(nMt,"TFLayoutLMForTokenClassification"),nMt.forEach(t),ZMr=r(WRe," (LayoutLM model)"),WRe.forEach(t),e4r=i(me),_4=n(me,"LI",{});var HRe=s(_4);lFe=n(HRe,"STRONG",{});var sMt=s(lFe);o4r=r(sMt,"longformer"),sMt.forEach(t),r4r=r(HRe," \u2014 "),sU=n(HRe,"A",{href:!0});var lMt=s(sU);t4r=r(lMt,"TFLongformerForTokenClassification"),lMt.forEach(t),a4r=r(HRe," (Longformer model)"),HRe.forEach(t),n4r=i(me),b4=n(me,"LI",{});var URe=s(b4);iFe=n(URe,"STRONG",{});var iMt=s(iFe);s4r=r(iMt,"mobilebert"),iMt.forEach(t),l4r=r(URe," \u2014 "),lU=n(URe,"A",{href:!0});var dMt=s(lU);i4r=r(dMt,"TFMobileBertForTokenClassification"),dMt.forEach(t),d4r=r(URe," (MobileBERT model)"),URe.forEach(t),c4r=i(me),v4=n(me,"LI",{});var JRe=s(v4);dFe=n(JRe,"STRONG",{});var cMt=s(dFe);f4r=r(cMt,"mpnet"),cMt.forEach(t),m4r=r(JRe," \u2014 "),iU=n(JRe,"A",{href:!0});var fMt=s(iU);g4r=r(fMt,"TFMPNetForTokenClassification"),fMt.forEach(t),h4r=r(JRe," (MPNet model)"),JRe.forEach(t),p4r=i(me),F4=n(me,"LI",{});var YRe=s(F4);cFe=n(YRe,"STRONG",{});var mMt=s(cFe);u4r=r(mMt,"rembert"),mMt.forEach(t),_4r=r(YRe," \u2014 "),dU=n(YRe,"A",{href:!0});var gMt=s(dU);b4r=r(gMt,"TFRemBertForTokenClassification"),gMt.forEach(t),v4r=r(YRe," (RemBERT model)"),YRe.forEach(t),F4r=i(me),T4=n(me,"LI",{});var KRe=s(T4);fFe=n(KRe,"STRONG",{});var hMt=s(fFe);T4r=r(hMt,"roberta"),hMt.forEach(t),M4r=r(KRe," \u2014 "),cU=n(KRe,"A",{href:!0});var pMt=s(cU);E4r=r(pMt,"TFRobertaForTokenClassification"),pMt.forEach(t),C4r=r(KRe," (RoBERTa model)"),KRe.forEach(t),w4r=i(me),M4=n(me,"LI",{});var ZRe=s(M4);mFe=n(ZRe,"STRONG",{});var uMt=s(mFe);A4r=r(uMt,"roformer"),uMt.forEach(t),y4r=r(ZRe," \u2014 "),fU=n(ZRe,"A",{href:!0});var _Mt=s(fU);L4r=r(_Mt,"TFRoFormerForTokenClassification"),_Mt.forEach(t),x4r=r(ZRe," (RoFormer model)"),ZRe.forEach(t),$4r=i(me),E4=n(me,"LI",{});var eBe=s(E4);gFe=n(eBe,"STRONG",{});var bMt=s(gFe);k4r=r(bMt,"xlm"),bMt.forEach(t),S4r=r(eBe," \u2014 "),mU=n(eBe,"A",{href:!0});var vMt=s(mU);R4r=r(vMt,"TFXLMForTokenClassification"),vMt.forEach(t),B4r=r(eBe," (XLM model)"),eBe.forEach(t),P4r=i(me),C4=n(me,"LI",{});var oBe=s(C4);hFe=n(oBe,"STRONG",{});var FMt=s(hFe);I4r=r(FMt,"xlm-roberta"),FMt.forEach(t),q4r=r(oBe," \u2014 "),gU=n(oBe,"A",{href:!0});var TMt=s(gU);N4r=r(TMt,"TFXLMRobertaForTokenClassification"),TMt.forEach(t),j4r=r(oBe," (XLM-RoBERTa model)"),oBe.forEach(t),D4r=i(me),w4=n(me,"LI",{});var rBe=s(w4);pFe=n(rBe,"STRONG",{});var MMt=s(pFe);G4r=r(MMt,"xlnet"),MMt.forEach(t),O4r=r(rBe," \u2014 "),hU=n(rBe,"A",{href:!0});var EMt=s(hU);V4r=r(EMt,"TFXLNetForTokenClassification"),EMt.forEach(t),X4r=r(rBe," (XLNet model)"),rBe.forEach(t),me.forEach(t),z4r=i(kl),T(A4.$$.fragment,kl),kl.forEach(t),$l.forEach(t),Uqe=i(f),bc=n(f,"H2",{class:!0});var rDe=s(bc);y4=n(rDe,"A",{id:!0,class:!0,href:!0});var CMt=s(y4);uFe=n(CMt,"SPAN",{});var wMt=s(uFe);T(O8.$$.fragment,wMt),wMt.forEach(t),CMt.forEach(t),Q4r=i(rDe),_Fe=n(rDe,"SPAN",{});var AMt=s(_Fe);W4r=r(AMt,"TFAutoModelForQuestionAnswering"),AMt.forEach(t),rDe.forEach(t),Jqe=i(f),ir=n(f,"DIV",{class:!0});var Sl=s(ir);T(V8.$$.fragment,Sl),H4r=i(Sl),vc=n(Sl,"P",{});var OZ=s(vc);U4r=r(OZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),pU=n(OZ,"A",{href:!0});var yMt=s(pU);J4r=r(yMt,"from_pretrained()"),yMt.forEach(t),Y4r=r(OZ," class method or the "),uU=n(OZ,"A",{href:!0});var LMt=s(uU);K4r=r(LMt,"from_config()"),LMt.forEach(t),Z4r=r(OZ,` class
method.`),OZ.forEach(t),eEr=i(Sl),X8=n(Sl,"P",{});var tDe=s(X8);oEr=r(tDe,"This class cannot be instantiated directly using "),bFe=n(tDe,"CODE",{});var xMt=s(bFe);rEr=r(xMt,"__init__()"),xMt.forEach(t),tEr=r(tDe," (throws an error)."),tDe.forEach(t),aEr=i(Sl),It=n(Sl,"DIV",{class:!0});var ww=s(It);T(z8.$$.fragment,ww),nEr=i(ww),vFe=n(ww,"P",{});var $Mt=s(vFe);sEr=r($Mt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),$Mt.forEach(t),lEr=i(ww),Fc=n(ww,"P",{});var VZ=s(Fc);iEr=r(VZ,`Note:
Loading a model from its configuration file does `),FFe=n(VZ,"STRONG",{});var kMt=s(FFe);dEr=r(kMt,"not"),kMt.forEach(t),cEr=r(VZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),_U=n(VZ,"A",{href:!0});var SMt=s(_U);fEr=r(SMt,"from_pretrained()"),SMt.forEach(t),mEr=r(VZ," to load the model weights."),VZ.forEach(t),gEr=i(ww),T(L4.$$.fragment,ww),ww.forEach(t),hEr=i(Sl),Ir=n(Sl,"DIV",{class:!0});var Rl=s(Ir);T(Q8.$$.fragment,Rl),pEr=i(Rl),TFe=n(Rl,"P",{});var RMt=s(TFe);uEr=r(RMt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),RMt.forEach(t),_Er=i(Rl),cn=n(Rl,"P",{});var Aw=s(cn);bEr=r(Aw,"The model class to instantiate is selected based on the "),MFe=n(Aw,"CODE",{});var BMt=s(MFe);vEr=r(BMt,"model_type"),BMt.forEach(t),FEr=r(Aw,` property of the config object (either
passed as an argument or loaded from `),EFe=n(Aw,"CODE",{});var PMt=s(EFe);TEr=r(PMt,"pretrained_model_name_or_path"),PMt.forEach(t),MEr=r(Aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CFe=n(Aw,"CODE",{});var IMt=s(CFe);EEr=r(IMt,"pretrained_model_name_or_path"),IMt.forEach(t),CEr=r(Aw,":"),Aw.forEach(t),wEr=i(Rl),ce=n(Rl,"UL",{});var ge=s(ce);x4=n(ge,"LI",{});var tBe=s(x4);wFe=n(tBe,"STRONG",{});var qMt=s(wFe);AEr=r(qMt,"albert"),qMt.forEach(t),yEr=r(tBe," \u2014 "),bU=n(tBe,"A",{href:!0});var NMt=s(bU);LEr=r(NMt,"TFAlbertForQuestionAnswering"),NMt.forEach(t),xEr=r(tBe," (ALBERT model)"),tBe.forEach(t),$Er=i(ge),$4=n(ge,"LI",{});var aBe=s($4);AFe=n(aBe,"STRONG",{});var jMt=s(AFe);kEr=r(jMt,"bert"),jMt.forEach(t),SEr=r(aBe," \u2014 "),vU=n(aBe,"A",{href:!0});var DMt=s(vU);REr=r(DMt,"TFBertForQuestionAnswering"),DMt.forEach(t),BEr=r(aBe," (BERT model)"),aBe.forEach(t),PEr=i(ge),k4=n(ge,"LI",{});var nBe=s(k4);yFe=n(nBe,"STRONG",{});var GMt=s(yFe);IEr=r(GMt,"camembert"),GMt.forEach(t),qEr=r(nBe," \u2014 "),FU=n(nBe,"A",{href:!0});var OMt=s(FU);NEr=r(OMt,"TFCamembertForQuestionAnswering"),OMt.forEach(t),jEr=r(nBe," (CamemBERT model)"),nBe.forEach(t),DEr=i(ge),S4=n(ge,"LI",{});var sBe=s(S4);LFe=n(sBe,"STRONG",{});var VMt=s(LFe);GEr=r(VMt,"convbert"),VMt.forEach(t),OEr=r(sBe," \u2014 "),TU=n(sBe,"A",{href:!0});var XMt=s(TU);VEr=r(XMt,"TFConvBertForQuestionAnswering"),XMt.forEach(t),XEr=r(sBe," (ConvBERT model)"),sBe.forEach(t),zEr=i(ge),R4=n(ge,"LI",{});var lBe=s(R4);xFe=n(lBe,"STRONG",{});var zMt=s(xFe);QEr=r(zMt,"deberta"),zMt.forEach(t),WEr=r(lBe," \u2014 "),MU=n(lBe,"A",{href:!0});var QMt=s(MU);HEr=r(QMt,"TFDebertaForQuestionAnswering"),QMt.forEach(t),UEr=r(lBe," (DeBERTa model)"),lBe.forEach(t),JEr=i(ge),B4=n(ge,"LI",{});var iBe=s(B4);$Fe=n(iBe,"STRONG",{});var WMt=s($Fe);YEr=r(WMt,"deberta-v2"),WMt.forEach(t),KEr=r(iBe," \u2014 "),EU=n(iBe,"A",{href:!0});var HMt=s(EU);ZEr=r(HMt,"TFDebertaV2ForQuestionAnswering"),HMt.forEach(t),e5r=r(iBe," (DeBERTa-v2 model)"),iBe.forEach(t),o5r=i(ge),P4=n(ge,"LI",{});var dBe=s(P4);kFe=n(dBe,"STRONG",{});var UMt=s(kFe);r5r=r(UMt,"distilbert"),UMt.forEach(t),t5r=r(dBe," \u2014 "),CU=n(dBe,"A",{href:!0});var JMt=s(CU);a5r=r(JMt,"TFDistilBertForQuestionAnswering"),JMt.forEach(t),n5r=r(dBe," (DistilBERT model)"),dBe.forEach(t),s5r=i(ge),I4=n(ge,"LI",{});var cBe=s(I4);SFe=n(cBe,"STRONG",{});var YMt=s(SFe);l5r=r(YMt,"electra"),YMt.forEach(t),i5r=r(cBe," \u2014 "),wU=n(cBe,"A",{href:!0});var KMt=s(wU);d5r=r(KMt,"TFElectraForQuestionAnswering"),KMt.forEach(t),c5r=r(cBe," (ELECTRA model)"),cBe.forEach(t),f5r=i(ge),q4=n(ge,"LI",{});var fBe=s(q4);RFe=n(fBe,"STRONG",{});var ZMt=s(RFe);m5r=r(ZMt,"flaubert"),ZMt.forEach(t),g5r=r(fBe," \u2014 "),AU=n(fBe,"A",{href:!0});var e4t=s(AU);h5r=r(e4t,"TFFlaubertForQuestionAnsweringSimple"),e4t.forEach(t),p5r=r(fBe," (FlauBERT model)"),fBe.forEach(t),u5r=i(ge),N4=n(ge,"LI",{});var mBe=s(N4);BFe=n(mBe,"STRONG",{});var o4t=s(BFe);_5r=r(o4t,"funnel"),o4t.forEach(t),b5r=r(mBe," \u2014 "),yU=n(mBe,"A",{href:!0});var r4t=s(yU);v5r=r(r4t,"TFFunnelForQuestionAnswering"),r4t.forEach(t),F5r=r(mBe," (Funnel Transformer model)"),mBe.forEach(t),T5r=i(ge),j4=n(ge,"LI",{});var gBe=s(j4);PFe=n(gBe,"STRONG",{});var t4t=s(PFe);M5r=r(t4t,"gptj"),t4t.forEach(t),E5r=r(gBe," \u2014 "),LU=n(gBe,"A",{href:!0});var a4t=s(LU);C5r=r(a4t,"TFGPTJForQuestionAnswering"),a4t.forEach(t),w5r=r(gBe," (GPT-J model)"),gBe.forEach(t),A5r=i(ge),D4=n(ge,"LI",{});var hBe=s(D4);IFe=n(hBe,"STRONG",{});var n4t=s(IFe);y5r=r(n4t,"longformer"),n4t.forEach(t),L5r=r(hBe," \u2014 "),xU=n(hBe,"A",{href:!0});var s4t=s(xU);x5r=r(s4t,"TFLongformerForQuestionAnswering"),s4t.forEach(t),$5r=r(hBe," (Longformer model)"),hBe.forEach(t),k5r=i(ge),G4=n(ge,"LI",{});var pBe=s(G4);qFe=n(pBe,"STRONG",{});var l4t=s(qFe);S5r=r(l4t,"mobilebert"),l4t.forEach(t),R5r=r(pBe," \u2014 "),$U=n(pBe,"A",{href:!0});var i4t=s($U);B5r=r(i4t,"TFMobileBertForQuestionAnswering"),i4t.forEach(t),P5r=r(pBe," (MobileBERT model)"),pBe.forEach(t),I5r=i(ge),O4=n(ge,"LI",{});var uBe=s(O4);NFe=n(uBe,"STRONG",{});var d4t=s(NFe);q5r=r(d4t,"mpnet"),d4t.forEach(t),N5r=r(uBe," \u2014 "),kU=n(uBe,"A",{href:!0});var c4t=s(kU);j5r=r(c4t,"TFMPNetForQuestionAnswering"),c4t.forEach(t),D5r=r(uBe," (MPNet model)"),uBe.forEach(t),G5r=i(ge),V4=n(ge,"LI",{});var _Be=s(V4);jFe=n(_Be,"STRONG",{});var f4t=s(jFe);O5r=r(f4t,"rembert"),f4t.forEach(t),V5r=r(_Be," \u2014 "),SU=n(_Be,"A",{href:!0});var m4t=s(SU);X5r=r(m4t,"TFRemBertForQuestionAnswering"),m4t.forEach(t),z5r=r(_Be," (RemBERT model)"),_Be.forEach(t),Q5r=i(ge),X4=n(ge,"LI",{});var bBe=s(X4);DFe=n(bBe,"STRONG",{});var g4t=s(DFe);W5r=r(g4t,"roberta"),g4t.forEach(t),H5r=r(bBe," \u2014 "),RU=n(bBe,"A",{href:!0});var h4t=s(RU);U5r=r(h4t,"TFRobertaForQuestionAnswering"),h4t.forEach(t),J5r=r(bBe," (RoBERTa model)"),bBe.forEach(t),Y5r=i(ge),z4=n(ge,"LI",{});var vBe=s(z4);GFe=n(vBe,"STRONG",{});var p4t=s(GFe);K5r=r(p4t,"roformer"),p4t.forEach(t),Z5r=r(vBe," \u2014 "),BU=n(vBe,"A",{href:!0});var u4t=s(BU);eCr=r(u4t,"TFRoFormerForQuestionAnswering"),u4t.forEach(t),oCr=r(vBe," (RoFormer model)"),vBe.forEach(t),rCr=i(ge),Q4=n(ge,"LI",{});var FBe=s(Q4);OFe=n(FBe,"STRONG",{});var _4t=s(OFe);tCr=r(_4t,"xlm"),_4t.forEach(t),aCr=r(FBe," \u2014 "),PU=n(FBe,"A",{href:!0});var b4t=s(PU);nCr=r(b4t,"TFXLMForQuestionAnsweringSimple"),b4t.forEach(t),sCr=r(FBe," (XLM model)"),FBe.forEach(t),lCr=i(ge),W4=n(ge,"LI",{});var TBe=s(W4);VFe=n(TBe,"STRONG",{});var v4t=s(VFe);iCr=r(v4t,"xlm-roberta"),v4t.forEach(t),dCr=r(TBe," \u2014 "),IU=n(TBe,"A",{href:!0});var F4t=s(IU);cCr=r(F4t,"TFXLMRobertaForQuestionAnswering"),F4t.forEach(t),fCr=r(TBe," (XLM-RoBERTa model)"),TBe.forEach(t),mCr=i(ge),H4=n(ge,"LI",{});var MBe=s(H4);XFe=n(MBe,"STRONG",{});var T4t=s(XFe);gCr=r(T4t,"xlnet"),T4t.forEach(t),hCr=r(MBe," \u2014 "),qU=n(MBe,"A",{href:!0});var M4t=s(qU);pCr=r(M4t,"TFXLNetForQuestionAnsweringSimple"),M4t.forEach(t),uCr=r(MBe," (XLNet model)"),MBe.forEach(t),ge.forEach(t),_Cr=i(Rl),T(U4.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),Yqe=i(f),Tc=n(f,"H2",{class:!0});var aDe=s(Tc);J4=n(aDe,"A",{id:!0,class:!0,href:!0});var E4t=s(J4);zFe=n(E4t,"SPAN",{});var C4t=s(zFe);T(W8.$$.fragment,C4t),C4t.forEach(t),E4t.forEach(t),bCr=i(aDe),QFe=n(aDe,"SPAN",{});var w4t=s(QFe);vCr=r(w4t,"TFAutoModelForVision2Seq"),w4t.forEach(t),aDe.forEach(t),Kqe=i(f),dr=n(f,"DIV",{class:!0});var Bl=s(dr);T(H8.$$.fragment,Bl),FCr=i(Bl),Mc=n(Bl,"P",{});var XZ=s(Mc);TCr=r(XZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),NU=n(XZ,"A",{href:!0});var A4t=s(NU);MCr=r(A4t,"from_pretrained()"),A4t.forEach(t),ECr=r(XZ," class method or the "),jU=n(XZ,"A",{href:!0});var y4t=s(jU);CCr=r(y4t,"from_config()"),y4t.forEach(t),wCr=r(XZ,` class
method.`),XZ.forEach(t),ACr=i(Bl),U8=n(Bl,"P",{});var nDe=s(U8);yCr=r(nDe,"This class cannot be instantiated directly using "),WFe=n(nDe,"CODE",{});var L4t=s(WFe);LCr=r(L4t,"__init__()"),L4t.forEach(t),xCr=r(nDe," (throws an error)."),nDe.forEach(t),$Cr=i(Bl),qt=n(Bl,"DIV",{class:!0});var yw=s(qt);T(J8.$$.fragment,yw),kCr=i(yw),HFe=n(yw,"P",{});var x4t=s(HFe);SCr=r(x4t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),x4t.forEach(t),RCr=i(yw),Ec=n(yw,"P",{});var zZ=s(Ec);BCr=r(zZ,`Note:
Loading a model from its configuration file does `),UFe=n(zZ,"STRONG",{});var $4t=s(UFe);PCr=r($4t,"not"),$4t.forEach(t),ICr=r(zZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),DU=n(zZ,"A",{href:!0});var k4t=s(DU);qCr=r(k4t,"from_pretrained()"),k4t.forEach(t),NCr=r(zZ," to load the model weights."),zZ.forEach(t),jCr=i(yw),T(Y4.$$.fragment,yw),yw.forEach(t),DCr=i(Bl),qr=n(Bl,"DIV",{class:!0});var Pl=s(qr);T(Y8.$$.fragment,Pl),GCr=i(Pl),JFe=n(Pl,"P",{});var S4t=s(JFe);OCr=r(S4t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),S4t.forEach(t),VCr=i(Pl),fn=n(Pl,"P",{});var Lw=s(fn);XCr=r(Lw,"The model class to instantiate is selected based on the "),YFe=n(Lw,"CODE",{});var R4t=s(YFe);zCr=r(R4t,"model_type"),R4t.forEach(t),QCr=r(Lw,` property of the config object (either
passed as an argument or loaded from `),KFe=n(Lw,"CODE",{});var B4t=s(KFe);WCr=r(B4t,"pretrained_model_name_or_path"),B4t.forEach(t),HCr=r(Lw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=n(Lw,"CODE",{});var P4t=s(ZFe);UCr=r(P4t,"pretrained_model_name_or_path"),P4t.forEach(t),JCr=r(Lw,":"),Lw.forEach(t),YCr=i(Pl),e6e=n(Pl,"UL",{});var I4t=s(e6e);K4=n(I4t,"LI",{});var EBe=s(K4);o6e=n(EBe,"STRONG",{});var q4t=s(o6e);KCr=r(q4t,"vision-encoder-decoder"),q4t.forEach(t),ZCr=r(EBe," \u2014 "),GU=n(EBe,"A",{href:!0});var N4t=s(GU);e3r=r(N4t,"TFVisionEncoderDecoderModel"),N4t.forEach(t),o3r=r(EBe," (Vision Encoder decoder model)"),EBe.forEach(t),I4t.forEach(t),r3r=i(Pl),T(Z4.$$.fragment,Pl),Pl.forEach(t),Bl.forEach(t),Zqe=i(f),Cc=n(f,"H2",{class:!0});var sDe=s(Cc);eE=n(sDe,"A",{id:!0,class:!0,href:!0});var j4t=s(eE);r6e=n(j4t,"SPAN",{});var D4t=s(r6e);T(K8.$$.fragment,D4t),D4t.forEach(t),j4t.forEach(t),t3r=i(sDe),t6e=n(sDe,"SPAN",{});var G4t=s(t6e);a3r=r(G4t,"TFAutoModelForSpeechSeq2Seq"),G4t.forEach(t),sDe.forEach(t),eNe=i(f),cr=n(f,"DIV",{class:!0});var Il=s(cr);T(Z8.$$.fragment,Il),n3r=i(Il),wc=n(Il,"P",{});var QZ=s(wc);s3r=r(QZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),OU=n(QZ,"A",{href:!0});var O4t=s(OU);l3r=r(O4t,"from_pretrained()"),O4t.forEach(t),i3r=r(QZ," class method or the "),VU=n(QZ,"A",{href:!0});var V4t=s(VU);d3r=r(V4t,"from_config()"),V4t.forEach(t),c3r=r(QZ,` class
method.`),QZ.forEach(t),f3r=i(Il),ex=n(Il,"P",{});var lDe=s(ex);m3r=r(lDe,"This class cannot be instantiated directly using "),a6e=n(lDe,"CODE",{});var X4t=s(a6e);g3r=r(X4t,"__init__()"),X4t.forEach(t),h3r=r(lDe," (throws an error)."),lDe.forEach(t),p3r=i(Il),Nt=n(Il,"DIV",{class:!0});var xw=s(Nt);T(ox.$$.fragment,xw),u3r=i(xw),n6e=n(xw,"P",{});var z4t=s(n6e);_3r=r(z4t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),z4t.forEach(t),b3r=i(xw),Ac=n(xw,"P",{});var WZ=s(Ac);v3r=r(WZ,`Note:
Loading a model from its configuration file does `),s6e=n(WZ,"STRONG",{});var Q4t=s(s6e);F3r=r(Q4t,"not"),Q4t.forEach(t),T3r=r(WZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XU=n(WZ,"A",{href:!0});var W4t=s(XU);M3r=r(W4t,"from_pretrained()"),W4t.forEach(t),E3r=r(WZ," to load the model weights."),WZ.forEach(t),C3r=i(xw),T(oE.$$.fragment,xw),xw.forEach(t),w3r=i(Il),Nr=n(Il,"DIV",{class:!0});var ql=s(Nr);T(rx.$$.fragment,ql),A3r=i(ql),l6e=n(ql,"P",{});var H4t=s(l6e);y3r=r(H4t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),H4t.forEach(t),L3r=i(ql),mn=n(ql,"P",{});var $w=s(mn);x3r=r($w,"The model class to instantiate is selected based on the "),i6e=n($w,"CODE",{});var U4t=s(i6e);$3r=r(U4t,"model_type"),U4t.forEach(t),k3r=r($w,` property of the config object (either
passed as an argument or loaded from `),d6e=n($w,"CODE",{});var J4t=s(d6e);S3r=r(J4t,"pretrained_model_name_or_path"),J4t.forEach(t),R3r=r($w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c6e=n($w,"CODE",{});var Y4t=s(c6e);B3r=r(Y4t,"pretrained_model_name_or_path"),Y4t.forEach(t),P3r=r($w,":"),$w.forEach(t),I3r=i(ql),f6e=n(ql,"UL",{});var K4t=s(f6e);rE=n(K4t,"LI",{});var CBe=s(rE);m6e=n(CBe,"STRONG",{});var Z4t=s(m6e);q3r=r(Z4t,"speech_to_text"),Z4t.forEach(t),N3r=r(CBe," \u2014 "),zU=n(CBe,"A",{href:!0});var eEt=s(zU);j3r=r(eEt,"TFSpeech2TextForConditionalGeneration"),eEt.forEach(t),D3r=r(CBe," (Speech2Text model)"),CBe.forEach(t),K4t.forEach(t),G3r=i(ql),T(tE.$$.fragment,ql),ql.forEach(t),Il.forEach(t),oNe=i(f),yc=n(f,"H2",{class:!0});var iDe=s(yc);aE=n(iDe,"A",{id:!0,class:!0,href:!0});var oEt=s(aE);g6e=n(oEt,"SPAN",{});var rEt=s(g6e);T(tx.$$.fragment,rEt),rEt.forEach(t),oEt.forEach(t),O3r=i(iDe),h6e=n(iDe,"SPAN",{});var tEt=s(h6e);V3r=r(tEt,"FlaxAutoModel"),tEt.forEach(t),iDe.forEach(t),rNe=i(f),fr=n(f,"DIV",{class:!0});var Nl=s(fr);T(ax.$$.fragment,Nl),X3r=i(Nl),Lc=n(Nl,"P",{});var HZ=s(Lc);z3r=r(HZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),QU=n(HZ,"A",{href:!0});var aEt=s(QU);Q3r=r(aEt,"from_pretrained()"),aEt.forEach(t),W3r=r(HZ," class method or the "),WU=n(HZ,"A",{href:!0});var nEt=s(WU);H3r=r(nEt,"from_config()"),nEt.forEach(t),U3r=r(HZ,` class
method.`),HZ.forEach(t),J3r=i(Nl),nx=n(Nl,"P",{});var dDe=s(nx);Y3r=r(dDe,"This class cannot be instantiated directly using "),p6e=n(dDe,"CODE",{});var sEt=s(p6e);K3r=r(sEt,"__init__()"),sEt.forEach(t),Z3r=r(dDe," (throws an error)."),dDe.forEach(t),ewr=i(Nl),jt=n(Nl,"DIV",{class:!0});var kw=s(jt);T(sx.$$.fragment,kw),owr=i(kw),u6e=n(kw,"P",{});var lEt=s(u6e);rwr=r(lEt,"Instantiates one of the base model classes of the library from a configuration."),lEt.forEach(t),twr=i(kw),xc=n(kw,"P",{});var UZ=s(xc);awr=r(UZ,`Note:
Loading a model from its configuration file does `),_6e=n(UZ,"STRONG",{});var iEt=s(_6e);nwr=r(iEt,"not"),iEt.forEach(t),swr=r(UZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=n(UZ,"A",{href:!0});var dEt=s(HU);lwr=r(dEt,"from_pretrained()"),dEt.forEach(t),iwr=r(UZ," to load the model weights."),UZ.forEach(t),dwr=i(kw),T(nE.$$.fragment,kw),kw.forEach(t),cwr=i(Nl),jr=n(Nl,"DIV",{class:!0});var jl=s(jr);T(lx.$$.fragment,jl),fwr=i(jl),b6e=n(jl,"P",{});var cEt=s(b6e);mwr=r(cEt,"Instantiate one of the base model classes of the library from a pretrained model."),cEt.forEach(t),gwr=i(jl),gn=n(jl,"P",{});var Sw=s(gn);hwr=r(Sw,"The model class to instantiate is selected based on the "),v6e=n(Sw,"CODE",{});var fEt=s(v6e);pwr=r(fEt,"model_type"),fEt.forEach(t),uwr=r(Sw,` property of the config object (either
passed as an argument or loaded from `),F6e=n(Sw,"CODE",{});var mEt=s(F6e);_wr=r(mEt,"pretrained_model_name_or_path"),mEt.forEach(t),bwr=r(Sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=n(Sw,"CODE",{});var gEt=s(T6e);vwr=r(gEt,"pretrained_model_name_or_path"),gEt.forEach(t),Fwr=r(Sw,":"),Sw.forEach(t),Twr=i(jl),re=n(jl,"UL",{});var ne=s(re);sE=n(ne,"LI",{});var wBe=s(sE);M6e=n(wBe,"STRONG",{});var hEt=s(M6e);Mwr=r(hEt,"albert"),hEt.forEach(t),Ewr=r(wBe," \u2014 "),UU=n(wBe,"A",{href:!0});var pEt=s(UU);Cwr=r(pEt,"FlaxAlbertModel"),pEt.forEach(t),wwr=r(wBe," (ALBERT model)"),wBe.forEach(t),Awr=i(ne),lE=n(ne,"LI",{});var ABe=s(lE);E6e=n(ABe,"STRONG",{});var uEt=s(E6e);ywr=r(uEt,"bart"),uEt.forEach(t),Lwr=r(ABe," \u2014 "),JU=n(ABe,"A",{href:!0});var _Et=s(JU);xwr=r(_Et,"FlaxBartModel"),_Et.forEach(t),$wr=r(ABe," (BART model)"),ABe.forEach(t),kwr=i(ne),iE=n(ne,"LI",{});var yBe=s(iE);C6e=n(yBe,"STRONG",{});var bEt=s(C6e);Swr=r(bEt,"beit"),bEt.forEach(t),Rwr=r(yBe," \u2014 "),YU=n(yBe,"A",{href:!0});var vEt=s(YU);Bwr=r(vEt,"FlaxBeitModel"),vEt.forEach(t),Pwr=r(yBe," (BEiT model)"),yBe.forEach(t),Iwr=i(ne),dE=n(ne,"LI",{});var LBe=s(dE);w6e=n(LBe,"STRONG",{});var FEt=s(w6e);qwr=r(FEt,"bert"),FEt.forEach(t),Nwr=r(LBe," \u2014 "),KU=n(LBe,"A",{href:!0});var TEt=s(KU);jwr=r(TEt,"FlaxBertModel"),TEt.forEach(t),Dwr=r(LBe," (BERT model)"),LBe.forEach(t),Gwr=i(ne),cE=n(ne,"LI",{});var xBe=s(cE);A6e=n(xBe,"STRONG",{});var MEt=s(A6e);Owr=r(MEt,"big_bird"),MEt.forEach(t),Vwr=r(xBe," \u2014 "),ZU=n(xBe,"A",{href:!0});var EEt=s(ZU);Xwr=r(EEt,"FlaxBigBirdModel"),EEt.forEach(t),zwr=r(xBe," (BigBird model)"),xBe.forEach(t),Qwr=i(ne),fE=n(ne,"LI",{});var $Be=s(fE);y6e=n($Be,"STRONG",{});var CEt=s(y6e);Wwr=r(CEt,"blenderbot"),CEt.forEach(t),Hwr=r($Be," \u2014 "),eJ=n($Be,"A",{href:!0});var wEt=s(eJ);Uwr=r(wEt,"FlaxBlenderbotModel"),wEt.forEach(t),Jwr=r($Be," (Blenderbot model)"),$Be.forEach(t),Ywr=i(ne),mE=n(ne,"LI",{});var kBe=s(mE);L6e=n(kBe,"STRONG",{});var AEt=s(L6e);Kwr=r(AEt,"blenderbot-small"),AEt.forEach(t),Zwr=r(kBe," \u2014 "),oJ=n(kBe,"A",{href:!0});var yEt=s(oJ);eAr=r(yEt,"FlaxBlenderbotSmallModel"),yEt.forEach(t),oAr=r(kBe," (BlenderbotSmall model)"),kBe.forEach(t),rAr=i(ne),gE=n(ne,"LI",{});var SBe=s(gE);x6e=n(SBe,"STRONG",{});var LEt=s(x6e);tAr=r(LEt,"clip"),LEt.forEach(t),aAr=r(SBe," \u2014 "),rJ=n(SBe,"A",{href:!0});var xEt=s(rJ);nAr=r(xEt,"FlaxCLIPModel"),xEt.forEach(t),sAr=r(SBe," (CLIP model)"),SBe.forEach(t),lAr=i(ne),hE=n(ne,"LI",{});var RBe=s(hE);$6e=n(RBe,"STRONG",{});var $Et=s($6e);iAr=r($Et,"distilbert"),$Et.forEach(t),dAr=r(RBe," \u2014 "),tJ=n(RBe,"A",{href:!0});var kEt=s(tJ);cAr=r(kEt,"FlaxDistilBertModel"),kEt.forEach(t),fAr=r(RBe," (DistilBERT model)"),RBe.forEach(t),mAr=i(ne),pE=n(ne,"LI",{});var BBe=s(pE);k6e=n(BBe,"STRONG",{});var SEt=s(k6e);gAr=r(SEt,"electra"),SEt.forEach(t),hAr=r(BBe," \u2014 "),aJ=n(BBe,"A",{href:!0});var REt=s(aJ);pAr=r(REt,"FlaxElectraModel"),REt.forEach(t),uAr=r(BBe," (ELECTRA model)"),BBe.forEach(t),_Ar=i(ne),uE=n(ne,"LI",{});var PBe=s(uE);S6e=n(PBe,"STRONG",{});var BEt=s(S6e);bAr=r(BEt,"gpt2"),BEt.forEach(t),vAr=r(PBe," \u2014 "),nJ=n(PBe,"A",{href:!0});var PEt=s(nJ);FAr=r(PEt,"FlaxGPT2Model"),PEt.forEach(t),TAr=r(PBe," (OpenAI GPT-2 model)"),PBe.forEach(t),MAr=i(ne),_E=n(ne,"LI",{});var IBe=s(_E);R6e=n(IBe,"STRONG",{});var IEt=s(R6e);EAr=r(IEt,"gpt_neo"),IEt.forEach(t),CAr=r(IBe," \u2014 "),sJ=n(IBe,"A",{href:!0});var qEt=s(sJ);wAr=r(qEt,"FlaxGPTNeoModel"),qEt.forEach(t),AAr=r(IBe," (GPT Neo model)"),IBe.forEach(t),yAr=i(ne),bE=n(ne,"LI",{});var qBe=s(bE);B6e=n(qBe,"STRONG",{});var NEt=s(B6e);LAr=r(NEt,"gptj"),NEt.forEach(t),xAr=r(qBe," \u2014 "),lJ=n(qBe,"A",{href:!0});var jEt=s(lJ);$Ar=r(jEt,"FlaxGPTJModel"),jEt.forEach(t),kAr=r(qBe," (GPT-J model)"),qBe.forEach(t),SAr=i(ne),vE=n(ne,"LI",{});var NBe=s(vE);P6e=n(NBe,"STRONG",{});var DEt=s(P6e);RAr=r(DEt,"marian"),DEt.forEach(t),BAr=r(NBe," \u2014 "),iJ=n(NBe,"A",{href:!0});var GEt=s(iJ);PAr=r(GEt,"FlaxMarianModel"),GEt.forEach(t),IAr=r(NBe," (Marian model)"),NBe.forEach(t),qAr=i(ne),FE=n(ne,"LI",{});var jBe=s(FE);I6e=n(jBe,"STRONG",{});var OEt=s(I6e);NAr=r(OEt,"mbart"),OEt.forEach(t),jAr=r(jBe," \u2014 "),dJ=n(jBe,"A",{href:!0});var VEt=s(dJ);DAr=r(VEt,"FlaxMBartModel"),VEt.forEach(t),GAr=r(jBe," (mBART model)"),jBe.forEach(t),OAr=i(ne),TE=n(ne,"LI",{});var DBe=s(TE);q6e=n(DBe,"STRONG",{});var XEt=s(q6e);VAr=r(XEt,"mt5"),XEt.forEach(t),XAr=r(DBe," \u2014 "),cJ=n(DBe,"A",{href:!0});var zEt=s(cJ);zAr=r(zEt,"FlaxMT5Model"),zEt.forEach(t),QAr=r(DBe," (mT5 model)"),DBe.forEach(t),WAr=i(ne),ME=n(ne,"LI",{});var GBe=s(ME);N6e=n(GBe,"STRONG",{});var QEt=s(N6e);HAr=r(QEt,"pegasus"),QEt.forEach(t),UAr=r(GBe," \u2014 "),fJ=n(GBe,"A",{href:!0});var WEt=s(fJ);JAr=r(WEt,"FlaxPegasusModel"),WEt.forEach(t),YAr=r(GBe," (Pegasus model)"),GBe.forEach(t),KAr=i(ne),EE=n(ne,"LI",{});var OBe=s(EE);j6e=n(OBe,"STRONG",{});var HEt=s(j6e);ZAr=r(HEt,"roberta"),HEt.forEach(t),eyr=r(OBe," \u2014 "),mJ=n(OBe,"A",{href:!0});var UEt=s(mJ);oyr=r(UEt,"FlaxRobertaModel"),UEt.forEach(t),ryr=r(OBe," (RoBERTa model)"),OBe.forEach(t),tyr=i(ne),CE=n(ne,"LI",{});var VBe=s(CE);D6e=n(VBe,"STRONG",{});var JEt=s(D6e);ayr=r(JEt,"roformer"),JEt.forEach(t),nyr=r(VBe," \u2014 "),gJ=n(VBe,"A",{href:!0});var YEt=s(gJ);syr=r(YEt,"FlaxRoFormerModel"),YEt.forEach(t),lyr=r(VBe," (RoFormer model)"),VBe.forEach(t),iyr=i(ne),wE=n(ne,"LI",{});var XBe=s(wE);G6e=n(XBe,"STRONG",{});var KEt=s(G6e);dyr=r(KEt,"t5"),KEt.forEach(t),cyr=r(XBe," \u2014 "),hJ=n(XBe,"A",{href:!0});var ZEt=s(hJ);fyr=r(ZEt,"FlaxT5Model"),ZEt.forEach(t),myr=r(XBe," (T5 model)"),XBe.forEach(t),gyr=i(ne),AE=n(ne,"LI",{});var zBe=s(AE);O6e=n(zBe,"STRONG",{});var e5t=s(O6e);hyr=r(e5t,"vision-text-dual-encoder"),e5t.forEach(t),pyr=r(zBe," \u2014 "),pJ=n(zBe,"A",{href:!0});var o5t=s(pJ);uyr=r(o5t,"FlaxVisionTextDualEncoderModel"),o5t.forEach(t),_yr=r(zBe," (VisionTextDualEncoder model)"),zBe.forEach(t),byr=i(ne),yE=n(ne,"LI",{});var QBe=s(yE);V6e=n(QBe,"STRONG",{});var r5t=s(V6e);vyr=r(r5t,"vit"),r5t.forEach(t),Fyr=r(QBe," \u2014 "),uJ=n(QBe,"A",{href:!0});var t5t=s(uJ);Tyr=r(t5t,"FlaxViTModel"),t5t.forEach(t),Myr=r(QBe," (ViT model)"),QBe.forEach(t),Eyr=i(ne),LE=n(ne,"LI",{});var WBe=s(LE);X6e=n(WBe,"STRONG",{});var a5t=s(X6e);Cyr=r(a5t,"wav2vec2"),a5t.forEach(t),wyr=r(WBe," \u2014 "),_J=n(WBe,"A",{href:!0});var n5t=s(_J);Ayr=r(n5t,"FlaxWav2Vec2Model"),n5t.forEach(t),yyr=r(WBe," (Wav2Vec2 model)"),WBe.forEach(t),Lyr=i(ne),xE=n(ne,"LI",{});var HBe=s(xE);z6e=n(HBe,"STRONG",{});var s5t=s(z6e);xyr=r(s5t,"xglm"),s5t.forEach(t),$yr=r(HBe," \u2014 "),bJ=n(HBe,"A",{href:!0});var l5t=s(bJ);kyr=r(l5t,"FlaxXGLMModel"),l5t.forEach(t),Syr=r(HBe," (XGLM model)"),HBe.forEach(t),Ryr=i(ne),$E=n(ne,"LI",{});var UBe=s($E);Q6e=n(UBe,"STRONG",{});var i5t=s(Q6e);Byr=r(i5t,"xlm-roberta"),i5t.forEach(t),Pyr=r(UBe," \u2014 "),vJ=n(UBe,"A",{href:!0});var d5t=s(vJ);Iyr=r(d5t,"FlaxXLMRobertaModel"),d5t.forEach(t),qyr=r(UBe," (XLM-RoBERTa model)"),UBe.forEach(t),ne.forEach(t),Nyr=i(jl),T(kE.$$.fragment,jl),jl.forEach(t),Nl.forEach(t),tNe=i(f),$c=n(f,"H2",{class:!0});var cDe=s($c);SE=n(cDe,"A",{id:!0,class:!0,href:!0});var c5t=s(SE);W6e=n(c5t,"SPAN",{});var f5t=s(W6e);T(ix.$$.fragment,f5t),f5t.forEach(t),c5t.forEach(t),jyr=i(cDe),H6e=n(cDe,"SPAN",{});var m5t=s(H6e);Dyr=r(m5t,"FlaxAutoModelForCausalLM"),m5t.forEach(t),cDe.forEach(t),aNe=i(f),mr=n(f,"DIV",{class:!0});var Dl=s(mr);T(dx.$$.fragment,Dl),Gyr=i(Dl),kc=n(Dl,"P",{});var JZ=s(kc);Oyr=r(JZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),FJ=n(JZ,"A",{href:!0});var g5t=s(FJ);Vyr=r(g5t,"from_pretrained()"),g5t.forEach(t),Xyr=r(JZ," class method or the "),TJ=n(JZ,"A",{href:!0});var h5t=s(TJ);zyr=r(h5t,"from_config()"),h5t.forEach(t),Qyr=r(JZ,` class
method.`),JZ.forEach(t),Wyr=i(Dl),cx=n(Dl,"P",{});var fDe=s(cx);Hyr=r(fDe,"This class cannot be instantiated directly using "),U6e=n(fDe,"CODE",{});var p5t=s(U6e);Uyr=r(p5t,"__init__()"),p5t.forEach(t),Jyr=r(fDe," (throws an error)."),fDe.forEach(t),Yyr=i(Dl),Dt=n(Dl,"DIV",{class:!0});var Rw=s(Dt);T(fx.$$.fragment,Rw),Kyr=i(Rw),J6e=n(Rw,"P",{});var u5t=s(J6e);Zyr=r(u5t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),u5t.forEach(t),eLr=i(Rw),Sc=n(Rw,"P",{});var YZ=s(Sc);oLr=r(YZ,`Note:
Loading a model from its configuration file does `),Y6e=n(YZ,"STRONG",{});var _5t=s(Y6e);rLr=r(_5t,"not"),_5t.forEach(t),tLr=r(YZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),MJ=n(YZ,"A",{href:!0});var b5t=s(MJ);aLr=r(b5t,"from_pretrained()"),b5t.forEach(t),nLr=r(YZ," to load the model weights."),YZ.forEach(t),sLr=i(Rw),T(RE.$$.fragment,Rw),Rw.forEach(t),lLr=i(Dl),Dr=n(Dl,"DIV",{class:!0});var Gl=s(Dr);T(mx.$$.fragment,Gl),iLr=i(Gl),K6e=n(Gl,"P",{});var v5t=s(K6e);dLr=r(v5t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),v5t.forEach(t),cLr=i(Gl),hn=n(Gl,"P",{});var Bw=s(hn);fLr=r(Bw,"The model class to instantiate is selected based on the "),Z6e=n(Bw,"CODE",{});var F5t=s(Z6e);mLr=r(F5t,"model_type"),F5t.forEach(t),gLr=r(Bw,` property of the config object (either
passed as an argument or loaded from `),eTe=n(Bw,"CODE",{});var T5t=s(eTe);hLr=r(T5t,"pretrained_model_name_or_path"),T5t.forEach(t),pLr=r(Bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=n(Bw,"CODE",{});var M5t=s(oTe);uLr=r(M5t,"pretrained_model_name_or_path"),M5t.forEach(t),_Lr=r(Bw,":"),Bw.forEach(t),bLr=i(Gl),ke=n(Gl,"UL",{});var Oe=s(ke);BE=n(Oe,"LI",{});var JBe=s(BE);rTe=n(JBe,"STRONG",{});var E5t=s(rTe);vLr=r(E5t,"bart"),E5t.forEach(t),FLr=r(JBe," \u2014 "),EJ=n(JBe,"A",{href:!0});var C5t=s(EJ);TLr=r(C5t,"FlaxBartForCausalLM"),C5t.forEach(t),MLr=r(JBe," (BART model)"),JBe.forEach(t),ELr=i(Oe),PE=n(Oe,"LI",{});var YBe=s(PE);tTe=n(YBe,"STRONG",{});var w5t=s(tTe);CLr=r(w5t,"bert"),w5t.forEach(t),wLr=r(YBe," \u2014 "),CJ=n(YBe,"A",{href:!0});var A5t=s(CJ);ALr=r(A5t,"FlaxBertForCausalLM"),A5t.forEach(t),yLr=r(YBe," (BERT model)"),YBe.forEach(t),LLr=i(Oe),IE=n(Oe,"LI",{});var KBe=s(IE);aTe=n(KBe,"STRONG",{});var y5t=s(aTe);xLr=r(y5t,"big_bird"),y5t.forEach(t),$Lr=r(KBe," \u2014 "),wJ=n(KBe,"A",{href:!0});var L5t=s(wJ);kLr=r(L5t,"FlaxBigBirdForCausalLM"),L5t.forEach(t),SLr=r(KBe," (BigBird model)"),KBe.forEach(t),RLr=i(Oe),qE=n(Oe,"LI",{});var ZBe=s(qE);nTe=n(ZBe,"STRONG",{});var x5t=s(nTe);BLr=r(x5t,"electra"),x5t.forEach(t),PLr=r(ZBe," \u2014 "),AJ=n(ZBe,"A",{href:!0});var $5t=s(AJ);ILr=r($5t,"FlaxElectraForCausalLM"),$5t.forEach(t),qLr=r(ZBe," (ELECTRA model)"),ZBe.forEach(t),NLr=i(Oe),NE=n(Oe,"LI",{});var ePe=s(NE);sTe=n(ePe,"STRONG",{});var k5t=s(sTe);jLr=r(k5t,"gpt2"),k5t.forEach(t),DLr=r(ePe," \u2014 "),yJ=n(ePe,"A",{href:!0});var S5t=s(yJ);GLr=r(S5t,"FlaxGPT2LMHeadModel"),S5t.forEach(t),OLr=r(ePe," (OpenAI GPT-2 model)"),ePe.forEach(t),VLr=i(Oe),jE=n(Oe,"LI",{});var oPe=s(jE);lTe=n(oPe,"STRONG",{});var R5t=s(lTe);XLr=r(R5t,"gpt_neo"),R5t.forEach(t),zLr=r(oPe," \u2014 "),LJ=n(oPe,"A",{href:!0});var B5t=s(LJ);QLr=r(B5t,"FlaxGPTNeoForCausalLM"),B5t.forEach(t),WLr=r(oPe," (GPT Neo model)"),oPe.forEach(t),HLr=i(Oe),DE=n(Oe,"LI",{});var rPe=s(DE);iTe=n(rPe,"STRONG",{});var P5t=s(iTe);ULr=r(P5t,"gptj"),P5t.forEach(t),JLr=r(rPe," \u2014 "),xJ=n(rPe,"A",{href:!0});var I5t=s(xJ);YLr=r(I5t,"FlaxGPTJForCausalLM"),I5t.forEach(t),KLr=r(rPe," (GPT-J model)"),rPe.forEach(t),ZLr=i(Oe),GE=n(Oe,"LI",{});var tPe=s(GE);dTe=n(tPe,"STRONG",{});var q5t=s(dTe);e8r=r(q5t,"roberta"),q5t.forEach(t),o8r=r(tPe," \u2014 "),$J=n(tPe,"A",{href:!0});var N5t=s($J);r8r=r(N5t,"FlaxRobertaForCausalLM"),N5t.forEach(t),t8r=r(tPe," (RoBERTa model)"),tPe.forEach(t),a8r=i(Oe),OE=n(Oe,"LI",{});var aPe=s(OE);cTe=n(aPe,"STRONG",{});var j5t=s(cTe);n8r=r(j5t,"xglm"),j5t.forEach(t),s8r=r(aPe," \u2014 "),kJ=n(aPe,"A",{href:!0});var D5t=s(kJ);l8r=r(D5t,"FlaxXGLMForCausalLM"),D5t.forEach(t),i8r=r(aPe," (XGLM model)"),aPe.forEach(t),Oe.forEach(t),d8r=i(Gl),T(VE.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),nNe=i(f),Rc=n(f,"H2",{class:!0});var mDe=s(Rc);XE=n(mDe,"A",{id:!0,class:!0,href:!0});var G5t=s(XE);fTe=n(G5t,"SPAN",{});var O5t=s(fTe);T(gx.$$.fragment,O5t),O5t.forEach(t),G5t.forEach(t),c8r=i(mDe),mTe=n(mDe,"SPAN",{});var V5t=s(mTe);f8r=r(V5t,"FlaxAutoModelForPreTraining"),V5t.forEach(t),mDe.forEach(t),sNe=i(f),gr=n(f,"DIV",{class:!0});var Ol=s(gr);T(hx.$$.fragment,Ol),m8r=i(Ol),Bc=n(Ol,"P",{});var KZ=s(Bc);g8r=r(KZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),SJ=n(KZ,"A",{href:!0});var X5t=s(SJ);h8r=r(X5t,"from_pretrained()"),X5t.forEach(t),p8r=r(KZ," class method or the "),RJ=n(KZ,"A",{href:!0});var z5t=s(RJ);u8r=r(z5t,"from_config()"),z5t.forEach(t),_8r=r(KZ,` class
method.`),KZ.forEach(t),b8r=i(Ol),px=n(Ol,"P",{});var gDe=s(px);v8r=r(gDe,"This class cannot be instantiated directly using "),gTe=n(gDe,"CODE",{});var Q5t=s(gTe);F8r=r(Q5t,"__init__()"),Q5t.forEach(t),T8r=r(gDe," (throws an error)."),gDe.forEach(t),M8r=i(Ol),Gt=n(Ol,"DIV",{class:!0});var Pw=s(Gt);T(ux.$$.fragment,Pw),E8r=i(Pw),hTe=n(Pw,"P",{});var W5t=s(hTe);C8r=r(W5t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),W5t.forEach(t),w8r=i(Pw),Pc=n(Pw,"P",{});var ZZ=s(Pc);A8r=r(ZZ,`Note:
Loading a model from its configuration file does `),pTe=n(ZZ,"STRONG",{});var H5t=s(pTe);y8r=r(H5t,"not"),H5t.forEach(t),L8r=r(ZZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=n(ZZ,"A",{href:!0});var U5t=s(BJ);x8r=r(U5t,"from_pretrained()"),U5t.forEach(t),$8r=r(ZZ," to load the model weights."),ZZ.forEach(t),k8r=i(Pw),T(zE.$$.fragment,Pw),Pw.forEach(t),S8r=i(Ol),Gr=n(Ol,"DIV",{class:!0});var Vl=s(Gr);T(_x.$$.fragment,Vl),R8r=i(Vl),uTe=n(Vl,"P",{});var J5t=s(uTe);B8r=r(J5t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),J5t.forEach(t),P8r=i(Vl),pn=n(Vl,"P",{});var Iw=s(pn);I8r=r(Iw,"The model class to instantiate is selected based on the "),_Te=n(Iw,"CODE",{});var Y5t=s(_Te);q8r=r(Y5t,"model_type"),Y5t.forEach(t),N8r=r(Iw,` property of the config object (either
passed as an argument or loaded from `),bTe=n(Iw,"CODE",{});var K5t=s(bTe);j8r=r(K5t,"pretrained_model_name_or_path"),K5t.forEach(t),D8r=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=n(Iw,"CODE",{});var Z5t=s(vTe);G8r=r(Z5t,"pretrained_model_name_or_path"),Z5t.forEach(t),O8r=r(Iw,":"),Iw.forEach(t),V8r=i(Vl),Me=n(Vl,"UL",{});var we=s(Me);QE=n(we,"LI",{});var nPe=s(QE);FTe=n(nPe,"STRONG",{});var eCt=s(FTe);X8r=r(eCt,"albert"),eCt.forEach(t),z8r=r(nPe," \u2014 "),PJ=n(nPe,"A",{href:!0});var oCt=s(PJ);Q8r=r(oCt,"FlaxAlbertForPreTraining"),oCt.forEach(t),W8r=r(nPe," (ALBERT model)"),nPe.forEach(t),H8r=i(we),WE=n(we,"LI",{});var sPe=s(WE);TTe=n(sPe,"STRONG",{});var rCt=s(TTe);U8r=r(rCt,"bart"),rCt.forEach(t),J8r=r(sPe," \u2014 "),IJ=n(sPe,"A",{href:!0});var tCt=s(IJ);Y8r=r(tCt,"FlaxBartForConditionalGeneration"),tCt.forEach(t),K8r=r(sPe," (BART model)"),sPe.forEach(t),Z8r=i(we),HE=n(we,"LI",{});var lPe=s(HE);MTe=n(lPe,"STRONG",{});var aCt=s(MTe);exr=r(aCt,"bert"),aCt.forEach(t),oxr=r(lPe," \u2014 "),qJ=n(lPe,"A",{href:!0});var nCt=s(qJ);rxr=r(nCt,"FlaxBertForPreTraining"),nCt.forEach(t),txr=r(lPe," (BERT model)"),lPe.forEach(t),axr=i(we),UE=n(we,"LI",{});var iPe=s(UE);ETe=n(iPe,"STRONG",{});var sCt=s(ETe);nxr=r(sCt,"big_bird"),sCt.forEach(t),sxr=r(iPe," \u2014 "),NJ=n(iPe,"A",{href:!0});var lCt=s(NJ);lxr=r(lCt,"FlaxBigBirdForPreTraining"),lCt.forEach(t),ixr=r(iPe," (BigBird model)"),iPe.forEach(t),dxr=i(we),JE=n(we,"LI",{});var dPe=s(JE);CTe=n(dPe,"STRONG",{});var iCt=s(CTe);cxr=r(iCt,"electra"),iCt.forEach(t),fxr=r(dPe," \u2014 "),jJ=n(dPe,"A",{href:!0});var dCt=s(jJ);mxr=r(dCt,"FlaxElectraForPreTraining"),dCt.forEach(t),gxr=r(dPe," (ELECTRA model)"),dPe.forEach(t),hxr=i(we),YE=n(we,"LI",{});var cPe=s(YE);wTe=n(cPe,"STRONG",{});var cCt=s(wTe);pxr=r(cCt,"mbart"),cCt.forEach(t),uxr=r(cPe," \u2014 "),DJ=n(cPe,"A",{href:!0});var fCt=s(DJ);_xr=r(fCt,"FlaxMBartForConditionalGeneration"),fCt.forEach(t),bxr=r(cPe," (mBART model)"),cPe.forEach(t),vxr=i(we),KE=n(we,"LI",{});var fPe=s(KE);ATe=n(fPe,"STRONG",{});var mCt=s(ATe);Fxr=r(mCt,"mt5"),mCt.forEach(t),Txr=r(fPe," \u2014 "),GJ=n(fPe,"A",{href:!0});var gCt=s(GJ);Mxr=r(gCt,"FlaxMT5ForConditionalGeneration"),gCt.forEach(t),Exr=r(fPe," (mT5 model)"),fPe.forEach(t),Cxr=i(we),ZE=n(we,"LI",{});var mPe=s(ZE);yTe=n(mPe,"STRONG",{});var hCt=s(yTe);wxr=r(hCt,"roberta"),hCt.forEach(t),Axr=r(mPe," \u2014 "),OJ=n(mPe,"A",{href:!0});var pCt=s(OJ);yxr=r(pCt,"FlaxRobertaForMaskedLM"),pCt.forEach(t),Lxr=r(mPe," (RoBERTa model)"),mPe.forEach(t),xxr=i(we),e5=n(we,"LI",{});var gPe=s(e5);LTe=n(gPe,"STRONG",{});var uCt=s(LTe);$xr=r(uCt,"roformer"),uCt.forEach(t),kxr=r(gPe," \u2014 "),VJ=n(gPe,"A",{href:!0});var _Ct=s(VJ);Sxr=r(_Ct,"FlaxRoFormerForMaskedLM"),_Ct.forEach(t),Rxr=r(gPe," (RoFormer model)"),gPe.forEach(t),Bxr=i(we),o5=n(we,"LI",{});var hPe=s(o5);xTe=n(hPe,"STRONG",{});var bCt=s(xTe);Pxr=r(bCt,"t5"),bCt.forEach(t),Ixr=r(hPe," \u2014 "),XJ=n(hPe,"A",{href:!0});var vCt=s(XJ);qxr=r(vCt,"FlaxT5ForConditionalGeneration"),vCt.forEach(t),Nxr=r(hPe," (T5 model)"),hPe.forEach(t),jxr=i(we),r5=n(we,"LI",{});var pPe=s(r5);$Te=n(pPe,"STRONG",{});var FCt=s($Te);Dxr=r(FCt,"wav2vec2"),FCt.forEach(t),Gxr=r(pPe," \u2014 "),zJ=n(pPe,"A",{href:!0});var TCt=s(zJ);Oxr=r(TCt,"FlaxWav2Vec2ForPreTraining"),TCt.forEach(t),Vxr=r(pPe," (Wav2Vec2 model)"),pPe.forEach(t),Xxr=i(we),t5=n(we,"LI",{});var uPe=s(t5);kTe=n(uPe,"STRONG",{});var MCt=s(kTe);zxr=r(MCt,"xlm-roberta"),MCt.forEach(t),Qxr=r(uPe," \u2014 "),QJ=n(uPe,"A",{href:!0});var ECt=s(QJ);Wxr=r(ECt,"FlaxXLMRobertaForMaskedLM"),ECt.forEach(t),Hxr=r(uPe," (XLM-RoBERTa model)"),uPe.forEach(t),we.forEach(t),Uxr=i(Vl),T(a5.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),lNe=i(f),Ic=n(f,"H2",{class:!0});var hDe=s(Ic);n5=n(hDe,"A",{id:!0,class:!0,href:!0});var CCt=s(n5);STe=n(CCt,"SPAN",{});var wCt=s(STe);T(bx.$$.fragment,wCt),wCt.forEach(t),CCt.forEach(t),Jxr=i(hDe),RTe=n(hDe,"SPAN",{});var ACt=s(RTe);Yxr=r(ACt,"FlaxAutoModelForMaskedLM"),ACt.forEach(t),hDe.forEach(t),iNe=i(f),hr=n(f,"DIV",{class:!0});var Xl=s(hr);T(vx.$$.fragment,Xl),Kxr=i(Xl),qc=n(Xl,"P",{});var eee=s(qc);Zxr=r(eee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WJ=n(eee,"A",{href:!0});var yCt=s(WJ);e9r=r(yCt,"from_pretrained()"),yCt.forEach(t),o9r=r(eee," class method or the "),HJ=n(eee,"A",{href:!0});var LCt=s(HJ);r9r=r(LCt,"from_config()"),LCt.forEach(t),t9r=r(eee,` class
method.`),eee.forEach(t),a9r=i(Xl),Fx=n(Xl,"P",{});var pDe=s(Fx);n9r=r(pDe,"This class cannot be instantiated directly using "),BTe=n(pDe,"CODE",{});var xCt=s(BTe);s9r=r(xCt,"__init__()"),xCt.forEach(t),l9r=r(pDe," (throws an error)."),pDe.forEach(t),i9r=i(Xl),Ot=n(Xl,"DIV",{class:!0});var qw=s(Ot);T(Tx.$$.fragment,qw),d9r=i(qw),PTe=n(qw,"P",{});var $Ct=s(PTe);c9r=r($Ct,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),$Ct.forEach(t),f9r=i(qw),Nc=n(qw,"P",{});var oee=s(Nc);m9r=r(oee,`Note:
Loading a model from its configuration file does `),ITe=n(oee,"STRONG",{});var kCt=s(ITe);g9r=r(kCt,"not"),kCt.forEach(t),h9r=r(oee,` load the model weights. It only affects the
model\u2019s configuration. Use `),UJ=n(oee,"A",{href:!0});var SCt=s(UJ);p9r=r(SCt,"from_pretrained()"),SCt.forEach(t),u9r=r(oee," to load the model weights."),oee.forEach(t),_9r=i(qw),T(s5.$$.fragment,qw),qw.forEach(t),b9r=i(Xl),Or=n(Xl,"DIV",{class:!0});var zl=s(Or);T(Mx.$$.fragment,zl),v9r=i(zl),qTe=n(zl,"P",{});var RCt=s(qTe);F9r=r(RCt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),RCt.forEach(t),T9r=i(zl),un=n(zl,"P",{});var Nw=s(un);M9r=r(Nw,"The model class to instantiate is selected based on the "),NTe=n(Nw,"CODE",{});var BCt=s(NTe);E9r=r(BCt,"model_type"),BCt.forEach(t),C9r=r(Nw,` property of the config object (either
passed as an argument or loaded from `),jTe=n(Nw,"CODE",{});var PCt=s(jTe);w9r=r(PCt,"pretrained_model_name_or_path"),PCt.forEach(t),A9r=r(Nw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DTe=n(Nw,"CODE",{});var ICt=s(DTe);y9r=r(ICt,"pretrained_model_name_or_path"),ICt.forEach(t),L9r=r(Nw,":"),Nw.forEach(t),x9r=i(zl),Le=n(zl,"UL",{});var Be=s(Le);l5=n(Be,"LI",{});var _Pe=s(l5);GTe=n(_Pe,"STRONG",{});var qCt=s(GTe);$9r=r(qCt,"albert"),qCt.forEach(t),k9r=r(_Pe," \u2014 "),JJ=n(_Pe,"A",{href:!0});var NCt=s(JJ);S9r=r(NCt,"FlaxAlbertForMaskedLM"),NCt.forEach(t),R9r=r(_Pe," (ALBERT model)"),_Pe.forEach(t),B9r=i(Be),i5=n(Be,"LI",{});var bPe=s(i5);OTe=n(bPe,"STRONG",{});var jCt=s(OTe);P9r=r(jCt,"bart"),jCt.forEach(t),I9r=r(bPe," \u2014 "),YJ=n(bPe,"A",{href:!0});var DCt=s(YJ);q9r=r(DCt,"FlaxBartForConditionalGeneration"),DCt.forEach(t),N9r=r(bPe," (BART model)"),bPe.forEach(t),j9r=i(Be),d5=n(Be,"LI",{});var vPe=s(d5);VTe=n(vPe,"STRONG",{});var GCt=s(VTe);D9r=r(GCt,"bert"),GCt.forEach(t),G9r=r(vPe," \u2014 "),KJ=n(vPe,"A",{href:!0});var OCt=s(KJ);O9r=r(OCt,"FlaxBertForMaskedLM"),OCt.forEach(t),V9r=r(vPe," (BERT model)"),vPe.forEach(t),X9r=i(Be),c5=n(Be,"LI",{});var FPe=s(c5);XTe=n(FPe,"STRONG",{});var VCt=s(XTe);z9r=r(VCt,"big_bird"),VCt.forEach(t),Q9r=r(FPe," \u2014 "),ZJ=n(FPe,"A",{href:!0});var XCt=s(ZJ);W9r=r(XCt,"FlaxBigBirdForMaskedLM"),XCt.forEach(t),H9r=r(FPe," (BigBird model)"),FPe.forEach(t),U9r=i(Be),f5=n(Be,"LI",{});var TPe=s(f5);zTe=n(TPe,"STRONG",{});var zCt=s(zTe);J9r=r(zCt,"distilbert"),zCt.forEach(t),Y9r=r(TPe," \u2014 "),eY=n(TPe,"A",{href:!0});var QCt=s(eY);K9r=r(QCt,"FlaxDistilBertForMaskedLM"),QCt.forEach(t),Z9r=r(TPe," (DistilBERT model)"),TPe.forEach(t),e$r=i(Be),m5=n(Be,"LI",{});var MPe=s(m5);QTe=n(MPe,"STRONG",{});var WCt=s(QTe);o$r=r(WCt,"electra"),WCt.forEach(t),r$r=r(MPe," \u2014 "),oY=n(MPe,"A",{href:!0});var HCt=s(oY);t$r=r(HCt,"FlaxElectraForMaskedLM"),HCt.forEach(t),a$r=r(MPe," (ELECTRA model)"),MPe.forEach(t),n$r=i(Be),g5=n(Be,"LI",{});var EPe=s(g5);WTe=n(EPe,"STRONG",{});var UCt=s(WTe);s$r=r(UCt,"mbart"),UCt.forEach(t),l$r=r(EPe," \u2014 "),rY=n(EPe,"A",{href:!0});var JCt=s(rY);i$r=r(JCt,"FlaxMBartForConditionalGeneration"),JCt.forEach(t),d$r=r(EPe," (mBART model)"),EPe.forEach(t),c$r=i(Be),h5=n(Be,"LI",{});var CPe=s(h5);HTe=n(CPe,"STRONG",{});var YCt=s(HTe);f$r=r(YCt,"roberta"),YCt.forEach(t),m$r=r(CPe," \u2014 "),tY=n(CPe,"A",{href:!0});var KCt=s(tY);g$r=r(KCt,"FlaxRobertaForMaskedLM"),KCt.forEach(t),h$r=r(CPe," (RoBERTa model)"),CPe.forEach(t),p$r=i(Be),p5=n(Be,"LI",{});var wPe=s(p5);UTe=n(wPe,"STRONG",{});var ZCt=s(UTe);u$r=r(ZCt,"roformer"),ZCt.forEach(t),_$r=r(wPe," \u2014 "),aY=n(wPe,"A",{href:!0});var e3t=s(aY);b$r=r(e3t,"FlaxRoFormerForMaskedLM"),e3t.forEach(t),v$r=r(wPe," (RoFormer model)"),wPe.forEach(t),F$r=i(Be),u5=n(Be,"LI",{});var APe=s(u5);JTe=n(APe,"STRONG",{});var o3t=s(JTe);T$r=r(o3t,"xlm-roberta"),o3t.forEach(t),M$r=r(APe," \u2014 "),nY=n(APe,"A",{href:!0});var r3t=s(nY);E$r=r(r3t,"FlaxXLMRobertaForMaskedLM"),r3t.forEach(t),C$r=r(APe," (XLM-RoBERTa model)"),APe.forEach(t),Be.forEach(t),w$r=i(zl),T(_5.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),dNe=i(f),jc=n(f,"H2",{class:!0});var uDe=s(jc);b5=n(uDe,"A",{id:!0,class:!0,href:!0});var t3t=s(b5);YTe=n(t3t,"SPAN",{});var a3t=s(YTe);T(Ex.$$.fragment,a3t),a3t.forEach(t),t3t.forEach(t),A$r=i(uDe),KTe=n(uDe,"SPAN",{});var n3t=s(KTe);y$r=r(n3t,"FlaxAutoModelForSeq2SeqLM"),n3t.forEach(t),uDe.forEach(t),cNe=i(f),pr=n(f,"DIV",{class:!0});var Ql=s(pr);T(Cx.$$.fragment,Ql),L$r=i(Ql),Dc=n(Ql,"P",{});var ree=s(Dc);x$r=r(ree,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),sY=n(ree,"A",{href:!0});var s3t=s(sY);$$r=r(s3t,"from_pretrained()"),s3t.forEach(t),k$r=r(ree," class method or the "),lY=n(ree,"A",{href:!0});var l3t=s(lY);S$r=r(l3t,"from_config()"),l3t.forEach(t),R$r=r(ree,` class
method.`),ree.forEach(t),B$r=i(Ql),wx=n(Ql,"P",{});var _De=s(wx);P$r=r(_De,"This class cannot be instantiated directly using "),ZTe=n(_De,"CODE",{});var i3t=s(ZTe);I$r=r(i3t,"__init__()"),i3t.forEach(t),q$r=r(_De," (throws an error)."),_De.forEach(t),N$r=i(Ql),Vt=n(Ql,"DIV",{class:!0});var jw=s(Vt);T(Ax.$$.fragment,jw),j$r=i(jw),e7e=n(jw,"P",{});var d3t=s(e7e);D$r=r(d3t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),d3t.forEach(t),G$r=i(jw),Gc=n(jw,"P",{});var tee=s(Gc);O$r=r(tee,`Note:
Loading a model from its configuration file does `),o7e=n(tee,"STRONG",{});var c3t=s(o7e);V$r=r(c3t,"not"),c3t.forEach(t),X$r=r(tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=n(tee,"A",{href:!0});var f3t=s(iY);z$r=r(f3t,"from_pretrained()"),f3t.forEach(t),Q$r=r(tee," to load the model weights."),tee.forEach(t),W$r=i(jw),T(v5.$$.fragment,jw),jw.forEach(t),H$r=i(Ql),Vr=n(Ql,"DIV",{class:!0});var Wl=s(Vr);T(yx.$$.fragment,Wl),U$r=i(Wl),r7e=n(Wl,"P",{});var m3t=s(r7e);J$r=r(m3t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),m3t.forEach(t),Y$r=i(Wl),_n=n(Wl,"P",{});var Dw=s(_n);K$r=r(Dw,"The model class to instantiate is selected based on the "),t7e=n(Dw,"CODE",{});var g3t=s(t7e);Z$r=r(g3t,"model_type"),g3t.forEach(t),ekr=r(Dw,` property of the config object (either
passed as an argument or loaded from `),a7e=n(Dw,"CODE",{});var h3t=s(a7e);okr=r(h3t,"pretrained_model_name_or_path"),h3t.forEach(t),rkr=r(Dw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=n(Dw,"CODE",{});var p3t=s(n7e);tkr=r(p3t,"pretrained_model_name_or_path"),p3t.forEach(t),akr=r(Dw,":"),Dw.forEach(t),nkr=i(Wl),Se=n(Wl,"UL",{});var Ve=s(Se);F5=n(Ve,"LI",{});var yPe=s(F5);s7e=n(yPe,"STRONG",{});var u3t=s(s7e);skr=r(u3t,"bart"),u3t.forEach(t),lkr=r(yPe," \u2014 "),dY=n(yPe,"A",{href:!0});var _3t=s(dY);ikr=r(_3t,"FlaxBartForConditionalGeneration"),_3t.forEach(t),dkr=r(yPe," (BART model)"),yPe.forEach(t),ckr=i(Ve),T5=n(Ve,"LI",{});var LPe=s(T5);l7e=n(LPe,"STRONG",{});var b3t=s(l7e);fkr=r(b3t,"blenderbot"),b3t.forEach(t),mkr=r(LPe," \u2014 "),cY=n(LPe,"A",{href:!0});var v3t=s(cY);gkr=r(v3t,"FlaxBlenderbotForConditionalGeneration"),v3t.forEach(t),hkr=r(LPe," (Blenderbot model)"),LPe.forEach(t),pkr=i(Ve),M5=n(Ve,"LI",{});var xPe=s(M5);i7e=n(xPe,"STRONG",{});var F3t=s(i7e);ukr=r(F3t,"blenderbot-small"),F3t.forEach(t),_kr=r(xPe," \u2014 "),fY=n(xPe,"A",{href:!0});var T3t=s(fY);bkr=r(T3t,"FlaxBlenderbotSmallForConditionalGeneration"),T3t.forEach(t),vkr=r(xPe," (BlenderbotSmall model)"),xPe.forEach(t),Fkr=i(Ve),E5=n(Ve,"LI",{});var $Pe=s(E5);d7e=n($Pe,"STRONG",{});var M3t=s(d7e);Tkr=r(M3t,"encoder-decoder"),M3t.forEach(t),Mkr=r($Pe," \u2014 "),mY=n($Pe,"A",{href:!0});var E3t=s(mY);Ekr=r(E3t,"FlaxEncoderDecoderModel"),E3t.forEach(t),Ckr=r($Pe," (Encoder decoder model)"),$Pe.forEach(t),wkr=i(Ve),C5=n(Ve,"LI",{});var kPe=s(C5);c7e=n(kPe,"STRONG",{});var C3t=s(c7e);Akr=r(C3t,"marian"),C3t.forEach(t),ykr=r(kPe," \u2014 "),gY=n(kPe,"A",{href:!0});var w3t=s(gY);Lkr=r(w3t,"FlaxMarianMTModel"),w3t.forEach(t),xkr=r(kPe," (Marian model)"),kPe.forEach(t),$kr=i(Ve),w5=n(Ve,"LI",{});var SPe=s(w5);f7e=n(SPe,"STRONG",{});var A3t=s(f7e);kkr=r(A3t,"mbart"),A3t.forEach(t),Skr=r(SPe," \u2014 "),hY=n(SPe,"A",{href:!0});var y3t=s(hY);Rkr=r(y3t,"FlaxMBartForConditionalGeneration"),y3t.forEach(t),Bkr=r(SPe," (mBART model)"),SPe.forEach(t),Pkr=i(Ve),A5=n(Ve,"LI",{});var RPe=s(A5);m7e=n(RPe,"STRONG",{});var L3t=s(m7e);Ikr=r(L3t,"mt5"),L3t.forEach(t),qkr=r(RPe," \u2014 "),pY=n(RPe,"A",{href:!0});var x3t=s(pY);Nkr=r(x3t,"FlaxMT5ForConditionalGeneration"),x3t.forEach(t),jkr=r(RPe," (mT5 model)"),RPe.forEach(t),Dkr=i(Ve),y5=n(Ve,"LI",{});var BPe=s(y5);g7e=n(BPe,"STRONG",{});var $3t=s(g7e);Gkr=r($3t,"pegasus"),$3t.forEach(t),Okr=r(BPe," \u2014 "),uY=n(BPe,"A",{href:!0});var k3t=s(uY);Vkr=r(k3t,"FlaxPegasusForConditionalGeneration"),k3t.forEach(t),Xkr=r(BPe," (Pegasus model)"),BPe.forEach(t),zkr=i(Ve),L5=n(Ve,"LI",{});var PPe=s(L5);h7e=n(PPe,"STRONG",{});var S3t=s(h7e);Qkr=r(S3t,"t5"),S3t.forEach(t),Wkr=r(PPe," \u2014 "),_Y=n(PPe,"A",{href:!0});var R3t=s(_Y);Hkr=r(R3t,"FlaxT5ForConditionalGeneration"),R3t.forEach(t),Ukr=r(PPe," (T5 model)"),PPe.forEach(t),Ve.forEach(t),Jkr=i(Wl),T(x5.$$.fragment,Wl),Wl.forEach(t),Ql.forEach(t),fNe=i(f),Oc=n(f,"H2",{class:!0});var bDe=s(Oc);$5=n(bDe,"A",{id:!0,class:!0,href:!0});var B3t=s($5);p7e=n(B3t,"SPAN",{});var P3t=s(p7e);T(Lx.$$.fragment,P3t),P3t.forEach(t),B3t.forEach(t),Ykr=i(bDe),u7e=n(bDe,"SPAN",{});var I3t=s(u7e);Kkr=r(I3t,"FlaxAutoModelForSequenceClassification"),I3t.forEach(t),bDe.forEach(t),mNe=i(f),ur=n(f,"DIV",{class:!0});var Hl=s(ur);T(xx.$$.fragment,Hl),Zkr=i(Hl),Vc=n(Hl,"P",{});var aee=s(Vc);eSr=r(aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),bY=n(aee,"A",{href:!0});var q3t=s(bY);oSr=r(q3t,"from_pretrained()"),q3t.forEach(t),rSr=r(aee," class method or the "),vY=n(aee,"A",{href:!0});var N3t=s(vY);tSr=r(N3t,"from_config()"),N3t.forEach(t),aSr=r(aee,` class
method.`),aee.forEach(t),nSr=i(Hl),$x=n(Hl,"P",{});var vDe=s($x);sSr=r(vDe,"This class cannot be instantiated directly using "),_7e=n(vDe,"CODE",{});var j3t=s(_7e);lSr=r(j3t,"__init__()"),j3t.forEach(t),iSr=r(vDe," (throws an error)."),vDe.forEach(t),dSr=i(Hl),Xt=n(Hl,"DIV",{class:!0});var Gw=s(Xt);T(kx.$$.fragment,Gw),cSr=i(Gw),b7e=n(Gw,"P",{});var D3t=s(b7e);fSr=r(D3t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),D3t.forEach(t),mSr=i(Gw),Xc=n(Gw,"P",{});var nee=s(Xc);gSr=r(nee,`Note:
Loading a model from its configuration file does `),v7e=n(nee,"STRONG",{});var G3t=s(v7e);hSr=r(G3t,"not"),G3t.forEach(t),pSr=r(nee,` load the model weights. It only affects the
model\u2019s configuration. Use `),FY=n(nee,"A",{href:!0});var O3t=s(FY);uSr=r(O3t,"from_pretrained()"),O3t.forEach(t),_Sr=r(nee," to load the model weights."),nee.forEach(t),bSr=i(Gw),T(k5.$$.fragment,Gw),Gw.forEach(t),vSr=i(Hl),Xr=n(Hl,"DIV",{class:!0});var Ul=s(Xr);T(Sx.$$.fragment,Ul),FSr=i(Ul),F7e=n(Ul,"P",{});var V3t=s(F7e);TSr=r(V3t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),V3t.forEach(t),MSr=i(Ul),bn=n(Ul,"P",{});var Ow=s(bn);ESr=r(Ow,"The model class to instantiate is selected based on the "),T7e=n(Ow,"CODE",{});var X3t=s(T7e);CSr=r(X3t,"model_type"),X3t.forEach(t),wSr=r(Ow,` property of the config object (either
passed as an argument or loaded from `),M7e=n(Ow,"CODE",{});var z3t=s(M7e);ASr=r(z3t,"pretrained_model_name_or_path"),z3t.forEach(t),ySr=r(Ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E7e=n(Ow,"CODE",{});var Q3t=s(E7e);LSr=r(Q3t,"pretrained_model_name_or_path"),Q3t.forEach(t),xSr=r(Ow,":"),Ow.forEach(t),$Sr=i(Ul),xe=n(Ul,"UL",{});var Pe=s(xe);S5=n(Pe,"LI",{});var IPe=s(S5);C7e=n(IPe,"STRONG",{});var W3t=s(C7e);kSr=r(W3t,"albert"),W3t.forEach(t),SSr=r(IPe," \u2014 "),TY=n(IPe,"A",{href:!0});var H3t=s(TY);RSr=r(H3t,"FlaxAlbertForSequenceClassification"),H3t.forEach(t),BSr=r(IPe," (ALBERT model)"),IPe.forEach(t),PSr=i(Pe),R5=n(Pe,"LI",{});var qPe=s(R5);w7e=n(qPe,"STRONG",{});var U3t=s(w7e);ISr=r(U3t,"bart"),U3t.forEach(t),qSr=r(qPe," \u2014 "),MY=n(qPe,"A",{href:!0});var J3t=s(MY);NSr=r(J3t,"FlaxBartForSequenceClassification"),J3t.forEach(t),jSr=r(qPe," (BART model)"),qPe.forEach(t),DSr=i(Pe),B5=n(Pe,"LI",{});var NPe=s(B5);A7e=n(NPe,"STRONG",{});var Y3t=s(A7e);GSr=r(Y3t,"bert"),Y3t.forEach(t),OSr=r(NPe," \u2014 "),EY=n(NPe,"A",{href:!0});var K3t=s(EY);VSr=r(K3t,"FlaxBertForSequenceClassification"),K3t.forEach(t),XSr=r(NPe," (BERT model)"),NPe.forEach(t),zSr=i(Pe),P5=n(Pe,"LI",{});var jPe=s(P5);y7e=n(jPe,"STRONG",{});var Z3t=s(y7e);QSr=r(Z3t,"big_bird"),Z3t.forEach(t),WSr=r(jPe," \u2014 "),CY=n(jPe,"A",{href:!0});var ewt=s(CY);HSr=r(ewt,"FlaxBigBirdForSequenceClassification"),ewt.forEach(t),USr=r(jPe," (BigBird model)"),jPe.forEach(t),JSr=i(Pe),I5=n(Pe,"LI",{});var DPe=s(I5);L7e=n(DPe,"STRONG",{});var owt=s(L7e);YSr=r(owt,"distilbert"),owt.forEach(t),KSr=r(DPe," \u2014 "),wY=n(DPe,"A",{href:!0});var rwt=s(wY);ZSr=r(rwt,"FlaxDistilBertForSequenceClassification"),rwt.forEach(t),eRr=r(DPe," (DistilBERT model)"),DPe.forEach(t),oRr=i(Pe),q5=n(Pe,"LI",{});var GPe=s(q5);x7e=n(GPe,"STRONG",{});var twt=s(x7e);rRr=r(twt,"electra"),twt.forEach(t),tRr=r(GPe," \u2014 "),AY=n(GPe,"A",{href:!0});var awt=s(AY);aRr=r(awt,"FlaxElectraForSequenceClassification"),awt.forEach(t),nRr=r(GPe," (ELECTRA model)"),GPe.forEach(t),sRr=i(Pe),N5=n(Pe,"LI",{});var OPe=s(N5);$7e=n(OPe,"STRONG",{});var nwt=s($7e);lRr=r(nwt,"mbart"),nwt.forEach(t),iRr=r(OPe," \u2014 "),yY=n(OPe,"A",{href:!0});var swt=s(yY);dRr=r(swt,"FlaxMBartForSequenceClassification"),swt.forEach(t),cRr=r(OPe," (mBART model)"),OPe.forEach(t),fRr=i(Pe),j5=n(Pe,"LI",{});var VPe=s(j5);k7e=n(VPe,"STRONG",{});var lwt=s(k7e);mRr=r(lwt,"roberta"),lwt.forEach(t),gRr=r(VPe," \u2014 "),LY=n(VPe,"A",{href:!0});var iwt=s(LY);hRr=r(iwt,"FlaxRobertaForSequenceClassification"),iwt.forEach(t),pRr=r(VPe," (RoBERTa model)"),VPe.forEach(t),uRr=i(Pe),D5=n(Pe,"LI",{});var XPe=s(D5);S7e=n(XPe,"STRONG",{});var dwt=s(S7e);_Rr=r(dwt,"roformer"),dwt.forEach(t),bRr=r(XPe," \u2014 "),xY=n(XPe,"A",{href:!0});var cwt=s(xY);vRr=r(cwt,"FlaxRoFormerForSequenceClassification"),cwt.forEach(t),FRr=r(XPe," (RoFormer model)"),XPe.forEach(t),TRr=i(Pe),G5=n(Pe,"LI",{});var zPe=s(G5);R7e=n(zPe,"STRONG",{});var fwt=s(R7e);MRr=r(fwt,"xlm-roberta"),fwt.forEach(t),ERr=r(zPe," \u2014 "),$Y=n(zPe,"A",{href:!0});var mwt=s($Y);CRr=r(mwt,"FlaxXLMRobertaForSequenceClassification"),mwt.forEach(t),wRr=r(zPe," (XLM-RoBERTa model)"),zPe.forEach(t),Pe.forEach(t),ARr=i(Ul),T(O5.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),gNe=i(f),zc=n(f,"H2",{class:!0});var FDe=s(zc);V5=n(FDe,"A",{id:!0,class:!0,href:!0});var gwt=s(V5);B7e=n(gwt,"SPAN",{});var hwt=s(B7e);T(Rx.$$.fragment,hwt),hwt.forEach(t),gwt.forEach(t),yRr=i(FDe),P7e=n(FDe,"SPAN",{});var pwt=s(P7e);LRr=r(pwt,"FlaxAutoModelForQuestionAnswering"),pwt.forEach(t),FDe.forEach(t),hNe=i(f),_r=n(f,"DIV",{class:!0});var Jl=s(_r);T(Bx.$$.fragment,Jl),xRr=i(Jl),Qc=n(Jl,"P",{});var see=s(Qc);$Rr=r(see,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),kY=n(see,"A",{href:!0});var uwt=s(kY);kRr=r(uwt,"from_pretrained()"),uwt.forEach(t),SRr=r(see," class method or the "),SY=n(see,"A",{href:!0});var _wt=s(SY);RRr=r(_wt,"from_config()"),_wt.forEach(t),BRr=r(see,` class
method.`),see.forEach(t),PRr=i(Jl),Px=n(Jl,"P",{});var TDe=s(Px);IRr=r(TDe,"This class cannot be instantiated directly using "),I7e=n(TDe,"CODE",{});var bwt=s(I7e);qRr=r(bwt,"__init__()"),bwt.forEach(t),NRr=r(TDe," (throws an error)."),TDe.forEach(t),jRr=i(Jl),zt=n(Jl,"DIV",{class:!0});var Vw=s(zt);T(Ix.$$.fragment,Vw),DRr=i(Vw),q7e=n(Vw,"P",{});var vwt=s(q7e);GRr=r(vwt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),vwt.forEach(t),ORr=i(Vw),Wc=n(Vw,"P",{});var lee=s(Wc);VRr=r(lee,`Note:
Loading a model from its configuration file does `),N7e=n(lee,"STRONG",{});var Fwt=s(N7e);XRr=r(Fwt,"not"),Fwt.forEach(t),zRr=r(lee,` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=n(lee,"A",{href:!0});var Twt=s(RY);QRr=r(Twt,"from_pretrained()"),Twt.forEach(t),WRr=r(lee," to load the model weights."),lee.forEach(t),HRr=i(Vw),T(X5.$$.fragment,Vw),Vw.forEach(t),URr=i(Jl),zr=n(Jl,"DIV",{class:!0});var Yl=s(zr);T(qx.$$.fragment,Yl),JRr=i(Yl),j7e=n(Yl,"P",{});var Mwt=s(j7e);YRr=r(Mwt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Mwt.forEach(t),KRr=i(Yl),vn=n(Yl,"P",{});var Xw=s(vn);ZRr=r(Xw,"The model class to instantiate is selected based on the "),D7e=n(Xw,"CODE",{});var Ewt=s(D7e);eBr=r(Ewt,"model_type"),Ewt.forEach(t),oBr=r(Xw,` property of the config object (either
passed as an argument or loaded from `),G7e=n(Xw,"CODE",{});var Cwt=s(G7e);rBr=r(Cwt,"pretrained_model_name_or_path"),Cwt.forEach(t),tBr=r(Xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(Xw,"CODE",{});var wwt=s(O7e);aBr=r(wwt,"pretrained_model_name_or_path"),wwt.forEach(t),nBr=r(Xw,":"),Xw.forEach(t),sBr=i(Yl),$e=n(Yl,"UL",{});var Ie=s($e);z5=n(Ie,"LI",{});var QPe=s(z5);V7e=n(QPe,"STRONG",{});var Awt=s(V7e);lBr=r(Awt,"albert"),Awt.forEach(t),iBr=r(QPe," \u2014 "),BY=n(QPe,"A",{href:!0});var ywt=s(BY);dBr=r(ywt,"FlaxAlbertForQuestionAnswering"),ywt.forEach(t),cBr=r(QPe," (ALBERT model)"),QPe.forEach(t),fBr=i(Ie),Q5=n(Ie,"LI",{});var WPe=s(Q5);X7e=n(WPe,"STRONG",{});var Lwt=s(X7e);mBr=r(Lwt,"bart"),Lwt.forEach(t),gBr=r(WPe," \u2014 "),PY=n(WPe,"A",{href:!0});var xwt=s(PY);hBr=r(xwt,"FlaxBartForQuestionAnswering"),xwt.forEach(t),pBr=r(WPe," (BART model)"),WPe.forEach(t),uBr=i(Ie),W5=n(Ie,"LI",{});var HPe=s(W5);z7e=n(HPe,"STRONG",{});var $wt=s(z7e);_Br=r($wt,"bert"),$wt.forEach(t),bBr=r(HPe," \u2014 "),IY=n(HPe,"A",{href:!0});var kwt=s(IY);vBr=r(kwt,"FlaxBertForQuestionAnswering"),kwt.forEach(t),FBr=r(HPe," (BERT model)"),HPe.forEach(t),TBr=i(Ie),H5=n(Ie,"LI",{});var UPe=s(H5);Q7e=n(UPe,"STRONG",{});var Swt=s(Q7e);MBr=r(Swt,"big_bird"),Swt.forEach(t),EBr=r(UPe," \u2014 "),qY=n(UPe,"A",{href:!0});var Rwt=s(qY);CBr=r(Rwt,"FlaxBigBirdForQuestionAnswering"),Rwt.forEach(t),wBr=r(UPe," (BigBird model)"),UPe.forEach(t),ABr=i(Ie),U5=n(Ie,"LI",{});var JPe=s(U5);W7e=n(JPe,"STRONG",{});var Bwt=s(W7e);yBr=r(Bwt,"distilbert"),Bwt.forEach(t),LBr=r(JPe," \u2014 "),NY=n(JPe,"A",{href:!0});var Pwt=s(NY);xBr=r(Pwt,"FlaxDistilBertForQuestionAnswering"),Pwt.forEach(t),$Br=r(JPe," (DistilBERT model)"),JPe.forEach(t),kBr=i(Ie),J5=n(Ie,"LI",{});var YPe=s(J5);H7e=n(YPe,"STRONG",{});var Iwt=s(H7e);SBr=r(Iwt,"electra"),Iwt.forEach(t),RBr=r(YPe," \u2014 "),jY=n(YPe,"A",{href:!0});var qwt=s(jY);BBr=r(qwt,"FlaxElectraForQuestionAnswering"),qwt.forEach(t),PBr=r(YPe," (ELECTRA model)"),YPe.forEach(t),IBr=i(Ie),Y5=n(Ie,"LI",{});var KPe=s(Y5);U7e=n(KPe,"STRONG",{});var Nwt=s(U7e);qBr=r(Nwt,"mbart"),Nwt.forEach(t),NBr=r(KPe," \u2014 "),DY=n(KPe,"A",{href:!0});var jwt=s(DY);jBr=r(jwt,"FlaxMBartForQuestionAnswering"),jwt.forEach(t),DBr=r(KPe," (mBART model)"),KPe.forEach(t),GBr=i(Ie),K5=n(Ie,"LI",{});var ZPe=s(K5);J7e=n(ZPe,"STRONG",{});var Dwt=s(J7e);OBr=r(Dwt,"roberta"),Dwt.forEach(t),VBr=r(ZPe," \u2014 "),GY=n(ZPe,"A",{href:!0});var Gwt=s(GY);XBr=r(Gwt,"FlaxRobertaForQuestionAnswering"),Gwt.forEach(t),zBr=r(ZPe," (RoBERTa model)"),ZPe.forEach(t),QBr=i(Ie),Z5=n(Ie,"LI",{});var eIe=s(Z5);Y7e=n(eIe,"STRONG",{});var Owt=s(Y7e);WBr=r(Owt,"roformer"),Owt.forEach(t),HBr=r(eIe," \u2014 "),OY=n(eIe,"A",{href:!0});var Vwt=s(OY);UBr=r(Vwt,"FlaxRoFormerForQuestionAnswering"),Vwt.forEach(t),JBr=r(eIe," (RoFormer model)"),eIe.forEach(t),YBr=i(Ie),eC=n(Ie,"LI",{});var oIe=s(eC);K7e=n(oIe,"STRONG",{});var Xwt=s(K7e);KBr=r(Xwt,"xlm-roberta"),Xwt.forEach(t),ZBr=r(oIe," \u2014 "),VY=n(oIe,"A",{href:!0});var zwt=s(VY);ePr=r(zwt,"FlaxXLMRobertaForQuestionAnswering"),zwt.forEach(t),oPr=r(oIe," (XLM-RoBERTa model)"),oIe.forEach(t),Ie.forEach(t),rPr=i(Yl),T(oC.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),pNe=i(f),Hc=n(f,"H2",{class:!0});var MDe=s(Hc);rC=n(MDe,"A",{id:!0,class:!0,href:!0});var Qwt=s(rC);Z7e=n(Qwt,"SPAN",{});var Wwt=s(Z7e);T(Nx.$$.fragment,Wwt),Wwt.forEach(t),Qwt.forEach(t),tPr=i(MDe),eMe=n(MDe,"SPAN",{});var Hwt=s(eMe);aPr=r(Hwt,"FlaxAutoModelForTokenClassification"),Hwt.forEach(t),MDe.forEach(t),uNe=i(f),br=n(f,"DIV",{class:!0});var Kl=s(br);T(jx.$$.fragment,Kl),nPr=i(Kl),Uc=n(Kl,"P",{});var iee=s(Uc);sPr=r(iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),XY=n(iee,"A",{href:!0});var Uwt=s(XY);lPr=r(Uwt,"from_pretrained()"),Uwt.forEach(t),iPr=r(iee," class method or the "),zY=n(iee,"A",{href:!0});var Jwt=s(zY);dPr=r(Jwt,"from_config()"),Jwt.forEach(t),cPr=r(iee,` class
method.`),iee.forEach(t),fPr=i(Kl),Dx=n(Kl,"P",{});var EDe=s(Dx);mPr=r(EDe,"This class cannot be instantiated directly using "),oMe=n(EDe,"CODE",{});var Ywt=s(oMe);gPr=r(Ywt,"__init__()"),Ywt.forEach(t),hPr=r(EDe," (throws an error)."),EDe.forEach(t),pPr=i(Kl),Qt=n(Kl,"DIV",{class:!0});var zw=s(Qt);T(Gx.$$.fragment,zw),uPr=i(zw),rMe=n(zw,"P",{});var Kwt=s(rMe);_Pr=r(Kwt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Kwt.forEach(t),bPr=i(zw),Jc=n(zw,"P",{});var dee=s(Jc);vPr=r(dee,`Note:
Loading a model from its configuration file does `),tMe=n(dee,"STRONG",{});var Zwt=s(tMe);FPr=r(Zwt,"not"),Zwt.forEach(t),TPr=r(dee,` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=n(dee,"A",{href:!0});var eAt=s(QY);MPr=r(eAt,"from_pretrained()"),eAt.forEach(t),EPr=r(dee," to load the model weights."),dee.forEach(t),CPr=i(zw),T(tC.$$.fragment,zw),zw.forEach(t),wPr=i(Kl),Qr=n(Kl,"DIV",{class:!0});var Zl=s(Qr);T(Ox.$$.fragment,Zl),APr=i(Zl),aMe=n(Zl,"P",{});var oAt=s(aMe);yPr=r(oAt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),oAt.forEach(t),LPr=i(Zl),Fn=n(Zl,"P",{});var Qw=s(Fn);xPr=r(Qw,"The model class to instantiate is selected based on the "),nMe=n(Qw,"CODE",{});var rAt=s(nMe);$Pr=r(rAt,"model_type"),rAt.forEach(t),kPr=r(Qw,` property of the config object (either
passed as an argument or loaded from `),sMe=n(Qw,"CODE",{});var tAt=s(sMe);SPr=r(tAt,"pretrained_model_name_or_path"),tAt.forEach(t),RPr=r(Qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lMe=n(Qw,"CODE",{});var aAt=s(lMe);BPr=r(aAt,"pretrained_model_name_or_path"),aAt.forEach(t),PPr=r(Qw,":"),Qw.forEach(t),IPr=i(Zl),De=n(Zl,"UL",{});var Fo=s(De);aC=n(Fo,"LI",{});var rIe=s(aC);iMe=n(rIe,"STRONG",{});var nAt=s(iMe);qPr=r(nAt,"albert"),nAt.forEach(t),NPr=r(rIe," \u2014 "),WY=n(rIe,"A",{href:!0});var sAt=s(WY);jPr=r(sAt,"FlaxAlbertForTokenClassification"),sAt.forEach(t),DPr=r(rIe," (ALBERT model)"),rIe.forEach(t),GPr=i(Fo),nC=n(Fo,"LI",{});var tIe=s(nC);dMe=n(tIe,"STRONG",{});var lAt=s(dMe);OPr=r(lAt,"bert"),lAt.forEach(t),VPr=r(tIe," \u2014 "),HY=n(tIe,"A",{href:!0});var iAt=s(HY);XPr=r(iAt,"FlaxBertForTokenClassification"),iAt.forEach(t),zPr=r(tIe," (BERT model)"),tIe.forEach(t),QPr=i(Fo),sC=n(Fo,"LI",{});var aIe=s(sC);cMe=n(aIe,"STRONG",{});var dAt=s(cMe);WPr=r(dAt,"big_bird"),dAt.forEach(t),HPr=r(aIe," \u2014 "),UY=n(aIe,"A",{href:!0});var cAt=s(UY);UPr=r(cAt,"FlaxBigBirdForTokenClassification"),cAt.forEach(t),JPr=r(aIe," (BigBird model)"),aIe.forEach(t),YPr=i(Fo),lC=n(Fo,"LI",{});var nIe=s(lC);fMe=n(nIe,"STRONG",{});var fAt=s(fMe);KPr=r(fAt,"distilbert"),fAt.forEach(t),ZPr=r(nIe," \u2014 "),JY=n(nIe,"A",{href:!0});var mAt=s(JY);eIr=r(mAt,"FlaxDistilBertForTokenClassification"),mAt.forEach(t),oIr=r(nIe," (DistilBERT model)"),nIe.forEach(t),rIr=i(Fo),iC=n(Fo,"LI",{});var sIe=s(iC);mMe=n(sIe,"STRONG",{});var gAt=s(mMe);tIr=r(gAt,"electra"),gAt.forEach(t),aIr=r(sIe," \u2014 "),YY=n(sIe,"A",{href:!0});var hAt=s(YY);nIr=r(hAt,"FlaxElectraForTokenClassification"),hAt.forEach(t),sIr=r(sIe," (ELECTRA model)"),sIe.forEach(t),lIr=i(Fo),dC=n(Fo,"LI",{});var lIe=s(dC);gMe=n(lIe,"STRONG",{});var pAt=s(gMe);iIr=r(pAt,"roberta"),pAt.forEach(t),dIr=r(lIe," \u2014 "),KY=n(lIe,"A",{href:!0});var uAt=s(KY);cIr=r(uAt,"FlaxRobertaForTokenClassification"),uAt.forEach(t),fIr=r(lIe," (RoBERTa model)"),lIe.forEach(t),mIr=i(Fo),cC=n(Fo,"LI",{});var iIe=s(cC);hMe=n(iIe,"STRONG",{});var _At=s(hMe);gIr=r(_At,"roformer"),_At.forEach(t),hIr=r(iIe," \u2014 "),ZY=n(iIe,"A",{href:!0});var bAt=s(ZY);pIr=r(bAt,"FlaxRoFormerForTokenClassification"),bAt.forEach(t),uIr=r(iIe," (RoFormer model)"),iIe.forEach(t),_Ir=i(Fo),fC=n(Fo,"LI",{});var dIe=s(fC);pMe=n(dIe,"STRONG",{});var vAt=s(pMe);bIr=r(vAt,"xlm-roberta"),vAt.forEach(t),vIr=r(dIe," \u2014 "),eK=n(dIe,"A",{href:!0});var FAt=s(eK);FIr=r(FAt,"FlaxXLMRobertaForTokenClassification"),FAt.forEach(t),TIr=r(dIe," (XLM-RoBERTa model)"),dIe.forEach(t),Fo.forEach(t),MIr=i(Zl),T(mC.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),_Ne=i(f),Yc=n(f,"H2",{class:!0});var CDe=s(Yc);gC=n(CDe,"A",{id:!0,class:!0,href:!0});var TAt=s(gC);uMe=n(TAt,"SPAN",{});var MAt=s(uMe);T(Vx.$$.fragment,MAt),MAt.forEach(t),TAt.forEach(t),EIr=i(CDe),_Me=n(CDe,"SPAN",{});var EAt=s(_Me);CIr=r(EAt,"FlaxAutoModelForMultipleChoice"),EAt.forEach(t),CDe.forEach(t),bNe=i(f),vr=n(f,"DIV",{class:!0});var ei=s(vr);T(Xx.$$.fragment,ei),wIr=i(ei),Kc=n(ei,"P",{});var cee=s(Kc);AIr=r(cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),oK=n(cee,"A",{href:!0});var CAt=s(oK);yIr=r(CAt,"from_pretrained()"),CAt.forEach(t),LIr=r(cee," class method or the "),rK=n(cee,"A",{href:!0});var wAt=s(rK);xIr=r(wAt,"from_config()"),wAt.forEach(t),$Ir=r(cee,` class
method.`),cee.forEach(t),kIr=i(ei),zx=n(ei,"P",{});var wDe=s(zx);SIr=r(wDe,"This class cannot be instantiated directly using "),bMe=n(wDe,"CODE",{});var AAt=s(bMe);RIr=r(AAt,"__init__()"),AAt.forEach(t),BIr=r(wDe," (throws an error)."),wDe.forEach(t),PIr=i(ei),Wt=n(ei,"DIV",{class:!0});var Ww=s(Wt);T(Qx.$$.fragment,Ww),IIr=i(Ww),vMe=n(Ww,"P",{});var yAt=s(vMe);qIr=r(yAt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),yAt.forEach(t),NIr=i(Ww),Zc=n(Ww,"P",{});var fee=s(Zc);jIr=r(fee,`Note:
Loading a model from its configuration file does `),FMe=n(fee,"STRONG",{});var LAt=s(FMe);DIr=r(LAt,"not"),LAt.forEach(t),GIr=r(fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=n(fee,"A",{href:!0});var xAt=s(tK);OIr=r(xAt,"from_pretrained()"),xAt.forEach(t),VIr=r(fee," to load the model weights."),fee.forEach(t),XIr=i(Ww),T(hC.$$.fragment,Ww),Ww.forEach(t),zIr=i(ei),Wr=n(ei,"DIV",{class:!0});var oi=s(Wr);T(Wx.$$.fragment,oi),QIr=i(oi),TMe=n(oi,"P",{});var $At=s(TMe);WIr=r($At,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$At.forEach(t),HIr=i(oi),Tn=n(oi,"P",{});var Hw=s(Tn);UIr=r(Hw,"The model class to instantiate is selected based on the "),MMe=n(Hw,"CODE",{});var kAt=s(MMe);JIr=r(kAt,"model_type"),kAt.forEach(t),YIr=r(Hw,` property of the config object (either
passed as an argument or loaded from `),EMe=n(Hw,"CODE",{});var SAt=s(EMe);KIr=r(SAt,"pretrained_model_name_or_path"),SAt.forEach(t),ZIr=r(Hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CMe=n(Hw,"CODE",{});var RAt=s(CMe);eqr=r(RAt,"pretrained_model_name_or_path"),RAt.forEach(t),oqr=r(Hw,":"),Hw.forEach(t),rqr=i(oi),Ge=n(oi,"UL",{});var To=s(Ge);pC=n(To,"LI",{});var cIe=s(pC);wMe=n(cIe,"STRONG",{});var BAt=s(wMe);tqr=r(BAt,"albert"),BAt.forEach(t),aqr=r(cIe," \u2014 "),aK=n(cIe,"A",{href:!0});var PAt=s(aK);nqr=r(PAt,"FlaxAlbertForMultipleChoice"),PAt.forEach(t),sqr=r(cIe," (ALBERT model)"),cIe.forEach(t),lqr=i(To),uC=n(To,"LI",{});var fIe=s(uC);AMe=n(fIe,"STRONG",{});var IAt=s(AMe);iqr=r(IAt,"bert"),IAt.forEach(t),dqr=r(fIe," \u2014 "),nK=n(fIe,"A",{href:!0});var qAt=s(nK);cqr=r(qAt,"FlaxBertForMultipleChoice"),qAt.forEach(t),fqr=r(fIe," (BERT model)"),fIe.forEach(t),mqr=i(To),_C=n(To,"LI",{});var mIe=s(_C);yMe=n(mIe,"STRONG",{});var NAt=s(yMe);gqr=r(NAt,"big_bird"),NAt.forEach(t),hqr=r(mIe," \u2014 "),sK=n(mIe,"A",{href:!0});var jAt=s(sK);pqr=r(jAt,"FlaxBigBirdForMultipleChoice"),jAt.forEach(t),uqr=r(mIe," (BigBird model)"),mIe.forEach(t),_qr=i(To),bC=n(To,"LI",{});var gIe=s(bC);LMe=n(gIe,"STRONG",{});var DAt=s(LMe);bqr=r(DAt,"distilbert"),DAt.forEach(t),vqr=r(gIe," \u2014 "),lK=n(gIe,"A",{href:!0});var GAt=s(lK);Fqr=r(GAt,"FlaxDistilBertForMultipleChoice"),GAt.forEach(t),Tqr=r(gIe," (DistilBERT model)"),gIe.forEach(t),Mqr=i(To),vC=n(To,"LI",{});var hIe=s(vC);xMe=n(hIe,"STRONG",{});var OAt=s(xMe);Eqr=r(OAt,"electra"),OAt.forEach(t),Cqr=r(hIe," \u2014 "),iK=n(hIe,"A",{href:!0});var VAt=s(iK);wqr=r(VAt,"FlaxElectraForMultipleChoice"),VAt.forEach(t),Aqr=r(hIe," (ELECTRA model)"),hIe.forEach(t),yqr=i(To),FC=n(To,"LI",{});var pIe=s(FC);$Me=n(pIe,"STRONG",{});var XAt=s($Me);Lqr=r(XAt,"roberta"),XAt.forEach(t),xqr=r(pIe," \u2014 "),dK=n(pIe,"A",{href:!0});var zAt=s(dK);$qr=r(zAt,"FlaxRobertaForMultipleChoice"),zAt.forEach(t),kqr=r(pIe," (RoBERTa model)"),pIe.forEach(t),Sqr=i(To),TC=n(To,"LI",{});var uIe=s(TC);kMe=n(uIe,"STRONG",{});var QAt=s(kMe);Rqr=r(QAt,"roformer"),QAt.forEach(t),Bqr=r(uIe," \u2014 "),cK=n(uIe,"A",{href:!0});var WAt=s(cK);Pqr=r(WAt,"FlaxRoFormerForMultipleChoice"),WAt.forEach(t),Iqr=r(uIe," (RoFormer model)"),uIe.forEach(t),qqr=i(To),MC=n(To,"LI",{});var _Ie=s(MC);SMe=n(_Ie,"STRONG",{});var HAt=s(SMe);Nqr=r(HAt,"xlm-roberta"),HAt.forEach(t),jqr=r(_Ie," \u2014 "),fK=n(_Ie,"A",{href:!0});var UAt=s(fK);Dqr=r(UAt,"FlaxXLMRobertaForMultipleChoice"),UAt.forEach(t),Gqr=r(_Ie," (XLM-RoBERTa model)"),_Ie.forEach(t),To.forEach(t),Oqr=i(oi),T(EC.$$.fragment,oi),oi.forEach(t),ei.forEach(t),vNe=i(f),ef=n(f,"H2",{class:!0});var ADe=s(ef);CC=n(ADe,"A",{id:!0,class:!0,href:!0});var JAt=s(CC);RMe=n(JAt,"SPAN",{});var YAt=s(RMe);T(Hx.$$.fragment,YAt),YAt.forEach(t),JAt.forEach(t),Vqr=i(ADe),BMe=n(ADe,"SPAN",{});var KAt=s(BMe);Xqr=r(KAt,"FlaxAutoModelForNextSentencePrediction"),KAt.forEach(t),ADe.forEach(t),FNe=i(f),Fr=n(f,"DIV",{class:!0});var ri=s(Fr);T(Ux.$$.fragment,ri),zqr=i(ri),of=n(ri,"P",{});var mee=s(of);Qqr=r(mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mK=n(mee,"A",{href:!0});var ZAt=s(mK);Wqr=r(ZAt,"from_pretrained()"),ZAt.forEach(t),Hqr=r(mee," class method or the "),gK=n(mee,"A",{href:!0});var eyt=s(gK);Uqr=r(eyt,"from_config()"),eyt.forEach(t),Jqr=r(mee,` class
method.`),mee.forEach(t),Yqr=i(ri),Jx=n(ri,"P",{});var yDe=s(Jx);Kqr=r(yDe,"This class cannot be instantiated directly using "),PMe=n(yDe,"CODE",{});var oyt=s(PMe);Zqr=r(oyt,"__init__()"),oyt.forEach(t),eNr=r(yDe," (throws an error)."),yDe.forEach(t),oNr=i(ri),Ht=n(ri,"DIV",{class:!0});var Uw=s(Ht);T(Yx.$$.fragment,Uw),rNr=i(Uw),IMe=n(Uw,"P",{});var ryt=s(IMe);tNr=r(ryt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ryt.forEach(t),aNr=i(Uw),rf=n(Uw,"P",{});var gee=s(rf);nNr=r(gee,`Note:
Loading a model from its configuration file does `),qMe=n(gee,"STRONG",{});var tyt=s(qMe);sNr=r(tyt,"not"),tyt.forEach(t),lNr=r(gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),hK=n(gee,"A",{href:!0});var ayt=s(hK);iNr=r(ayt,"from_pretrained()"),ayt.forEach(t),dNr=r(gee," to load the model weights."),gee.forEach(t),cNr=i(Uw),T(wC.$$.fragment,Uw),Uw.forEach(t),fNr=i(ri),Hr=n(ri,"DIV",{class:!0});var ti=s(Hr);T(Kx.$$.fragment,ti),mNr=i(ti),NMe=n(ti,"P",{});var nyt=s(NMe);gNr=r(nyt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),nyt.forEach(t),hNr=i(ti),Mn=n(ti,"P",{});var Jw=s(Mn);pNr=r(Jw,"The model class to instantiate is selected based on the "),jMe=n(Jw,"CODE",{});var syt=s(jMe);uNr=r(syt,"model_type"),syt.forEach(t),_Nr=r(Jw,` property of the config object (either
passed as an argument or loaded from `),DMe=n(Jw,"CODE",{});var lyt=s(DMe);bNr=r(lyt,"pretrained_model_name_or_path"),lyt.forEach(t),vNr=r(Jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GMe=n(Jw,"CODE",{});var iyt=s(GMe);FNr=r(iyt,"pretrained_model_name_or_path"),iyt.forEach(t),TNr=r(Jw,":"),Jw.forEach(t),MNr=i(ti),OMe=n(ti,"UL",{});var dyt=s(OMe);AC=n(dyt,"LI",{});var bIe=s(AC);VMe=n(bIe,"STRONG",{});var cyt=s(VMe);ENr=r(cyt,"bert"),cyt.forEach(t),CNr=r(bIe," \u2014 "),pK=n(bIe,"A",{href:!0});var fyt=s(pK);wNr=r(fyt,"FlaxBertForNextSentencePrediction"),fyt.forEach(t),ANr=r(bIe," (BERT model)"),bIe.forEach(t),dyt.forEach(t),yNr=i(ti),T(yC.$$.fragment,ti),ti.forEach(t),ri.forEach(t),TNe=i(f),tf=n(f,"H2",{class:!0});var LDe=s(tf);LC=n(LDe,"A",{id:!0,class:!0,href:!0});var myt=s(LC);XMe=n(myt,"SPAN",{});var gyt=s(XMe);T(Zx.$$.fragment,gyt),gyt.forEach(t),myt.forEach(t),LNr=i(LDe),zMe=n(LDe,"SPAN",{});var hyt=s(zMe);xNr=r(hyt,"FlaxAutoModelForImageClassification"),hyt.forEach(t),LDe.forEach(t),MNe=i(f),Tr=n(f,"DIV",{class:!0});var ai=s(Tr);T(e9.$$.fragment,ai),$Nr=i(ai),af=n(ai,"P",{});var hee=s(af);kNr=r(hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),uK=n(hee,"A",{href:!0});var pyt=s(uK);SNr=r(pyt,"from_pretrained()"),pyt.forEach(t),RNr=r(hee," class method or the "),_K=n(hee,"A",{href:!0});var uyt=s(_K);BNr=r(uyt,"from_config()"),uyt.forEach(t),PNr=r(hee,` class
method.`),hee.forEach(t),INr=i(ai),o9=n(ai,"P",{});var xDe=s(o9);qNr=r(xDe,"This class cannot be instantiated directly using "),QMe=n(xDe,"CODE",{});var _yt=s(QMe);NNr=r(_yt,"__init__()"),_yt.forEach(t),jNr=r(xDe," (throws an error)."),xDe.forEach(t),DNr=i(ai),Ut=n(ai,"DIV",{class:!0});var Yw=s(Ut);T(r9.$$.fragment,Yw),GNr=i(Yw),WMe=n(Yw,"P",{});var byt=s(WMe);ONr=r(byt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),byt.forEach(t),VNr=i(Yw),nf=n(Yw,"P",{});var pee=s(nf);XNr=r(pee,`Note:
Loading a model from its configuration file does `),HMe=n(pee,"STRONG",{});var vyt=s(HMe);zNr=r(vyt,"not"),vyt.forEach(t),QNr=r(pee,` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=n(pee,"A",{href:!0});var Fyt=s(bK);WNr=r(Fyt,"from_pretrained()"),Fyt.forEach(t),HNr=r(pee," to load the model weights."),pee.forEach(t),UNr=i(Yw),T(xC.$$.fragment,Yw),Yw.forEach(t),JNr=i(ai),Ur=n(ai,"DIV",{class:!0});var ni=s(Ur);T(t9.$$.fragment,ni),YNr=i(ni),UMe=n(ni,"P",{});var Tyt=s(UMe);KNr=r(Tyt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Tyt.forEach(t),ZNr=i(ni),En=n(ni,"P",{});var Kw=s(En);ejr=r(Kw,"The model class to instantiate is selected based on the "),JMe=n(Kw,"CODE",{});var Myt=s(JMe);ojr=r(Myt,"model_type"),Myt.forEach(t),rjr=r(Kw,` property of the config object (either
passed as an argument or loaded from `),YMe=n(Kw,"CODE",{});var Eyt=s(YMe);tjr=r(Eyt,"pretrained_model_name_or_path"),Eyt.forEach(t),ajr=r(Kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=n(Kw,"CODE",{});var Cyt=s(KMe);njr=r(Cyt,"pretrained_model_name_or_path"),Cyt.forEach(t),sjr=r(Kw,":"),Kw.forEach(t),ljr=i(ni),a9=n(ni,"UL",{});var $De=s(a9);$C=n($De,"LI",{});var vIe=s($C);ZMe=n(vIe,"STRONG",{});var wyt=s(ZMe);ijr=r(wyt,"beit"),wyt.forEach(t),djr=r(vIe," \u2014 "),vK=n(vIe,"A",{href:!0});var Ayt=s(vK);cjr=r(Ayt,"FlaxBeitForImageClassification"),Ayt.forEach(t),fjr=r(vIe," (BEiT model)"),vIe.forEach(t),mjr=i($De),kC=n($De,"LI",{});var FIe=s(kC);e4e=n(FIe,"STRONG",{});var yyt=s(e4e);gjr=r(yyt,"vit"),yyt.forEach(t),hjr=r(FIe," \u2014 "),FK=n(FIe,"A",{href:!0});var Lyt=s(FK);pjr=r(Lyt,"FlaxViTForImageClassification"),Lyt.forEach(t),ujr=r(FIe," (ViT model)"),FIe.forEach(t),$De.forEach(t),_jr=i(ni),T(SC.$$.fragment,ni),ni.forEach(t),ai.forEach(t),ENe=i(f),sf=n(f,"H2",{class:!0});var kDe=s(sf);RC=n(kDe,"A",{id:!0,class:!0,href:!0});var xyt=s(RC);o4e=n(xyt,"SPAN",{});var $yt=s(o4e);T(n9.$$.fragment,$yt),$yt.forEach(t),xyt.forEach(t),bjr=i(kDe),r4e=n(kDe,"SPAN",{});var kyt=s(r4e);vjr=r(kyt,"FlaxAutoModelForVision2Seq"),kyt.forEach(t),kDe.forEach(t),CNe=i(f),Mr=n(f,"DIV",{class:!0});var si=s(Mr);T(s9.$$.fragment,si),Fjr=i(si),lf=n(si,"P",{});var uee=s(lf);Tjr=r(uee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),TK=n(uee,"A",{href:!0});var Syt=s(TK);Mjr=r(Syt,"from_pretrained()"),Syt.forEach(t),Ejr=r(uee," class method or the "),MK=n(uee,"A",{href:!0});var Ryt=s(MK);Cjr=r(Ryt,"from_config()"),Ryt.forEach(t),wjr=r(uee,` class
method.`),uee.forEach(t),Ajr=i(si),l9=n(si,"P",{});var SDe=s(l9);yjr=r(SDe,"This class cannot be instantiated directly using "),t4e=n(SDe,"CODE",{});var Byt=s(t4e);Ljr=r(Byt,"__init__()"),Byt.forEach(t),xjr=r(SDe," (throws an error)."),SDe.forEach(t),$jr=i(si),Jt=n(si,"DIV",{class:!0});var Zw=s(Jt);T(i9.$$.fragment,Zw),kjr=i(Zw),a4e=n(Zw,"P",{});var Pyt=s(a4e);Sjr=r(Pyt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Pyt.forEach(t),Rjr=i(Zw),df=n(Zw,"P",{});var _ee=s(df);Bjr=r(_ee,`Note:
Loading a model from its configuration file does `),n4e=n(_ee,"STRONG",{});var Iyt=s(n4e);Pjr=r(Iyt,"not"),Iyt.forEach(t),Ijr=r(_ee,` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=n(_ee,"A",{href:!0});var qyt=s(EK);qjr=r(qyt,"from_pretrained()"),qyt.forEach(t),Njr=r(_ee," to load the model weights."),_ee.forEach(t),jjr=i(Zw),T(BC.$$.fragment,Zw),Zw.forEach(t),Djr=i(si),Jr=n(si,"DIV",{class:!0});var li=s(Jr);T(d9.$$.fragment,li),Gjr=i(li),s4e=n(li,"P",{});var Nyt=s(s4e);Ojr=r(Nyt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Nyt.forEach(t),Vjr=i(li),Cn=n(li,"P",{});var eA=s(Cn);Xjr=r(eA,"The model class to instantiate is selected based on the "),l4e=n(eA,"CODE",{});var jyt=s(l4e);zjr=r(jyt,"model_type"),jyt.forEach(t),Qjr=r(eA,` property of the config object (either
passed as an argument or loaded from `),i4e=n(eA,"CODE",{});var Dyt=s(i4e);Wjr=r(Dyt,"pretrained_model_name_or_path"),Dyt.forEach(t),Hjr=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d4e=n(eA,"CODE",{});var Gyt=s(d4e);Ujr=r(Gyt,"pretrained_model_name_or_path"),Gyt.forEach(t),Jjr=r(eA,":"),eA.forEach(t),Yjr=i(li),c4e=n(li,"UL",{});var Oyt=s(c4e);PC=n(Oyt,"LI",{});var TIe=s(PC);f4e=n(TIe,"STRONG",{});var Vyt=s(f4e);Kjr=r(Vyt,"vision-encoder-decoder"),Vyt.forEach(t),Zjr=r(TIe," \u2014 "),CK=n(TIe,"A",{href:!0});var Xyt=s(CK);eDr=r(Xyt,"FlaxVisionEncoderDecoderModel"),Xyt.forEach(t),oDr=r(TIe," (Vision Encoder decoder model)"),TIe.forEach(t),Oyt.forEach(t),rDr=i(li),T(IC.$$.fragment,li),li.forEach(t),si.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(H8t)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(An,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.AutoConfig"),c(Ln,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.AutoModel"),c(xn,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.AutoTokenizer"),c(hi,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertModel"),c(_f,"id","extending-the-auto-classes"),c(_f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_f,"href","#extending-the-auto-classes"),c(pi,"class","relative group"),c(vf,"id","transformers.AutoConfig"),c(vf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vf,"href","#transformers.AutoConfig"),c(ui,"class","relative group"),c(x$,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c($$,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertConfig"),c(k$,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig"),c(S$,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitConfig"),c(R$,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertConfig"),c(B$,"href","/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(P$,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdConfig"),c(I$,"href","/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(q$,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(N$,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(j$,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertConfig"),c(D$,"href","/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineConfig"),c(G$,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPConfig"),c(O$,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertConfig"),c(V$,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextConfig"),c(X$,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLConfig"),c(z$,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(Q$,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(W$,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(H$,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaConfig"),c(U$,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(J$,"href","/docs/transformers/pr_17060/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(Y$,"href","/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTConfig"),c(K$,"href","/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrConfig"),c(Z$,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertConfig"),c(ek,"href","/docs/transformers/pr_17060/en/model_doc/dpr#transformers.DPRConfig"),c(ok,"href","/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTConfig"),c(rk,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraConfig"),c(tk,"href","/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(ak,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertConfig"),c(nk,"href","/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaConfig"),c(sk,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetConfig"),c(lk,"href","/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTConfig"),c(ik,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelConfig"),c(dk,"href","/docs/transformers/pr_17060/en/model_doc/glpn#transformers.GLPNConfig"),c(ck,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Config"),c(fk,"href","/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(mk,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJConfig"),c(gk,"href","/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertConfig"),c(hk,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertConfig"),c(pk,"href","/docs/transformers/pr_17060/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(uk,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(_k,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(bk,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(vk,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDConfig"),c(Fk,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerConfig"),c(Tk,"href","/docs/transformers/pr_17060/en/model_doc/luke#transformers.LukeConfig"),c(Mk,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertConfig"),c(Ek,"href","/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100Config"),c(Ck,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianConfig"),c(wk,"href","/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(Ak,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartConfig"),c(yk,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(Lk,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(xk,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetConfig"),c($k,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Config"),c(kk,"href","/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(Sk,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(Rk,"href","/docs/transformers/pr_17060/en/model_doc/opt#transformers.OPTConfig"),c(Bk,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusConfig"),c(Pk,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverConfig"),c(Ik,"href","/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartConfig"),c(qk,"href","/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(Nk,"href","/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(jk,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(Dk,"href","/docs/transformers/pr_17060/en/model_doc/rag#transformers.RagConfig"),c(Gk,"href","/docs/transformers/pr_17060/en/model_doc/realm#transformers.RealmConfig"),c(Ok,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerConfig"),c(Vk,"href","/docs/transformers/pr_17060/en/model_doc/regnet#transformers.RegNetConfig"),c(Xk,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertConfig"),c(zk,"href","/docs/transformers/pr_17060/en/model_doc/resnet#transformers.ResNetConfig"),c(Qk,"href","/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertConfig"),c(Wk,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaConfig"),c(Hk,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerConfig"),c(Uk,"href","/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerConfig"),c(Jk,"href","/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWConfig"),c(Yk,"href","/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDConfig"),c(Kk,"href","/docs/transformers/pr_17060/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(Zk,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(eS,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(oS,"href","/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterConfig"),c(rS,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(tS,"href","/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinConfig"),c(aS,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Config"),c(nS,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasConfig"),c(sS,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartConfig"),c(lS,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(iS,"href","/docs/transformers/pr_17060/en/model_doc/trocr#transformers.TrOCRConfig"),c(dS,"href","/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(cS,"href","/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(fS,"href","/docs/transformers/pr_17060/en/model_doc/van#transformers.VanConfig"),c(mS,"href","/docs/transformers/pr_17060/en/model_doc/vilt#transformers.ViltConfig"),c(gS,"href","/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(hS,"href","/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(pS,"href","/docs/transformers/pr_17060/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(uS,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTConfig"),c(_S,"href","/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(bS,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(vS,"href","/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMConfig"),c(FS,"href","/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMConfig"),c(TS,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMConfig"),c(MS,"href","/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(ES,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(CS,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(wS,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetConfig"),c(AS,"href","/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosConfig"),c(yS,"href","/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fg,"id","transformers.AutoTokenizer"),c(Fg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fg,"href","#transformers.AutoTokenizer"),c(bi,"class","relative group"),c(LS,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(xS,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertTokenizer"),c($S,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(kS,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartTokenizer"),c(SS,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartTokenizerFast"),c(RS,"href","/docs/transformers/pr_17060/en/model_doc/barthez#transformers.BarthezTokenizer"),c(BS,"href","/docs/transformers/pr_17060/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(PS,"href","/docs/transformers/pr_17060/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(IS,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizer"),c(qS,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizerFast"),c(NS,"href","/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(jS,"href","/docs/transformers/pr_17060/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(DS,"href","/docs/transformers/pr_17060/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(GS,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(OS,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(VS,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(XS,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(zS,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(QS,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(WS,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(HS,"href","/docs/transformers/pr_17060/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(US,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertTokenizer"),c(JS,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(YS,"href","/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineTokenizer"),c(KS,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPTokenizer"),c(ZS,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(eR,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(oR,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(rR,"href","/docs/transformers/pr_17060/en/model_doc/cpm#transformers.CpmTokenizer"),c(tR,"href","/docs/transformers/pr_17060/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(aR,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(nR,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizer"),c(sR,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(lR,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaTokenizer"),c(iR,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(dR,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(cR,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(fR,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(mR,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(gR,"href","/docs/transformers/pr_17060/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(hR,"href","/docs/transformers/pr_17060/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(pR,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraTokenizer"),c(uR,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(_R,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(bR,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetTokenizer"),c(vR,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(FR,"href","/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(TR,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelTokenizer"),c(MR,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(ER,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(CR,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(wR,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(AR,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(yR,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(LR,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(xR,"href","/docs/transformers/pr_17060/en/model_doc/herbert#transformers.HerbertTokenizer"),c($R,"href","/docs/transformers/pr_17060/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(kR,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(SR,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizer"),c(RR,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(BR,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(PR,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(IR,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(qR,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(NR,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(jR,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(DR,"href","/docs/transformers/pr_17060/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(GR,"href","/docs/transformers/pr_17060/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(OR,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDTokenizer"),c(VR,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDTokenizerFast"),c(XR,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerTokenizer"),c(zR,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(QR,"href","/docs/transformers/pr_17060/en/model_doc/luke#transformers.LukeTokenizer"),c(WR,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(HR,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(UR,"href","/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(JR,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianTokenizer"),c(YR,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartTokenizer"),c(KR,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(ZR,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(eB,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(oB,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizer"),c(rB,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizerFast"),c(tB,"href","/docs/transformers/pr_17060/en/model_doc/mluke#transformers.MLukeTokenizer"),c(aB,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(nB,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(sB,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(lB,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(iB,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.T5Tokenizer"),c(dB,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.T5TokenizerFast"),c(cB,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertTokenizer"),c(fB,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(mB,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(gB,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(hB,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(pB,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(uB,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(_B,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(bB,"href","/docs/transformers/pr_17060/en/model_doc/phobert#transformers.PhobertTokenizer"),c(vB,"href","/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartTokenizer"),c(FB,"href","/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(TB,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizer"),c(MB,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizerFast"),c(EB,"href","/docs/transformers/pr_17060/en/model_doc/rag#transformers.RagTokenizer"),c(CB,"href","/docs/transformers/pr_17060/en/model_doc/realm#transformers.RealmTokenizer"),c(wB,"href","/docs/transformers/pr_17060/en/model_doc/realm#transformers.RealmTokenizerFast"),c(AB,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerTokenizer"),c(yB,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(LB,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertTokenizer"),c(xB,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c($B,"href","/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(kB,"href","/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(SB,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizer"),c(RB,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(BB,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(PB,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(IB,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(qB,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(NB,"href","/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterTokenizer"),c(jB,"href","/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(DB,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(GB,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(OB,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.T5Tokenizer"),c(VB,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.T5TokenizerFast"),c(XB,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasTokenizer"),c(zB,"href","/docs/transformers/pr_17060/en/model_doc/tapex#transformers.TapexTokenizer"),c(QB,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(WB,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizer"),c(HB,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertTokenizerFast"),c(UB,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(JB,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(YB,"href","/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMTokenizer"),c(KB,"href","/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(ZB,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMTokenizer"),c(eP,"href","/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(oP,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(rP,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(tP,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizer"),c(aP,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(nP,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(sP,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(lP,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertTokenizer"),c(iP,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zg,"id","transformers.AutoFeatureExtractor"),c(Zg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zg,"href","#transformers.AutoFeatureExtractor"),c(vi,"class","relative group"),c(dP,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(cP,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(fP,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(mP,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(gP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(hP,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(pP,"href","/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(uP,"href","/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(_P,"href","/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(bP,"href","/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(vP,"href","/docs/transformers/pr_17060/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(FP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(TP,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(MP,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(EP,"href","/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(CP,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(wP,"href","/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(AP,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yP,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LP,"href","/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(xP,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c($P,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kP,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SP,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(RP,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(PP,"href","/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xh,"id","transformers.AutoProcessor"),c(xh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xh,"href","#transformers.AutoProcessor"),c(Fi,"class","relative group"),c(IP,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(qP,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPProcessor"),c(NP,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(jP,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(DP,"href","/docs/transformers/pr_17060/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(GP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(OP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(VP,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(XP,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(zP,"href","/docs/transformers/pr_17060/en/model_doc/trocr#transformers.TrOCRProcessor"),c(QP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(WP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(HP,"href","/docs/transformers/pr_17060/en/model_doc/vilt#transformers.ViltProcessor"),c(UP,"href","/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(JP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(YP,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"id","transformers.AutoModel"),c(Uh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uh,"href","#transformers.AutoModel"),c(Mi,"class","relative group"),c(KP,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZP,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eI,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oI,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertModel"),c(rI,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartModel"),c(tI,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitModel"),c(aI,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertModel"),c(nI,"href","/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(sI,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdModel"),c(lI,"href","/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(iI,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(dI,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(cI,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertModel"),c(fI,"href","/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineModel"),c(mI,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.CLIPModel"),c(gI,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertModel"),c(hI,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextModel"),c(pI,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLModel"),c(uI,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(_I,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(bI,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(vI,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaModel"),c(FI,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(TI,"href","/docs/transformers/pr_17060/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(MI,"href","/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTModel"),c(EI,"href","/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrModel"),c(CI,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertModel"),c(wI,"href","/docs/transformers/pr_17060/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(AI,"href","/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTModel"),c(yI,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraModel"),c(LI,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertModel"),c(xI,"href","/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaModel"),c($I,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetModel"),c(kI,"href","/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTModel"),c(SI,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelModel"),c(RI,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelBaseModel"),c(BI,"href","/docs/transformers/pr_17060/en/model_doc/glpn#transformers.GLPNModel"),c(PI,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2Model"),c(II,"href","/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(qI,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJModel"),c(NI,"href","/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertModel"),c(jI,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertModel"),c(DI,"href","/docs/transformers/pr_17060/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(GI,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(OI,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(VI,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(XI,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDModel"),c(zI,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerModel"),c(QI,"href","/docs/transformers/pr_17060/en/model_doc/luke#transformers.LukeModel"),c(WI,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertModel"),c(HI,"href","/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100Model"),c(UI,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianModel"),c(JI,"href","/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerModel"),c(YI,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartModel"),c(KI,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(ZI,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertModel"),c(eq,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetModel"),c(oq,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5Model"),c(rq,"href","/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerModel"),c(tq,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(aq,"href","/docs/transformers/pr_17060/en/model_doc/opt#transformers.OPTModel"),c(nq,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusModel"),c(sq,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverModel"),c(lq,"href","/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartModel"),c(iq,"href","/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerModel"),c(dq,"href","/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(cq,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertModel"),c(fq,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerModel"),c(mq,"href","/docs/transformers/pr_17060/en/model_doc/regnet#transformers.RegNetModel"),c(gq,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertModel"),c(hq,"href","/docs/transformers/pr_17060/en/model_doc/resnet#transformers.ResNetModel"),c(pq,"href","/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertModel"),c(uq,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaModel"),c(_q,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerModel"),c(bq,"href","/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerModel"),c(vq,"href","/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWModel"),c(Fq,"href","/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDModel"),c(Tq,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Mq,"href","/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterModel"),c(Eq,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Cq,"href","/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinModel"),c(wq,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5Model"),c(Aq,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasModel"),c(yq,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(Lq,"href","/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechModel"),c(xq,"href","/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c($q,"href","/docs/transformers/pr_17060/en/model_doc/van#transformers.VanModel"),c(kq,"href","/docs/transformers/pr_17060/en/model_doc/vilt#transformers.ViltModel"),c(Sq,"href","/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Rq,"href","/docs/transformers/pr_17060/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Bq,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTModel"),c(Pq,"href","/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Iq,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(qq,"href","/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMModel"),c(Nq,"href","/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMModel"),c(jq,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMModel"),c(Dq,"href","/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Gq,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Oq,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Vq,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetModel"),c(Xq,"href","/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosModel"),c(zq,"href","/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoModel"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ou,"id","transformers.AutoModelForPreTraining"),c(Ou,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ou,"href","#transformers.AutoModelForPreTraining"),c(wi,"class","relative group"),c(Qq,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wq,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hq,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uq,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForPreTraining"),c(Jq,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Yq,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForPreTraining"),c(Kq,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(Zq,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(eN,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(oN,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(rN,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(tN,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(aN,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(nN,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForPreTraining"),c(sN,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(lN,"href","/docs/transformers/pr_17060/en/model_doc/flava#transformers.FlavaForPreTraining"),c(iN,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForPreTraining"),c(dN,"href","/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(cN,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(fN,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(mN,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(gN,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(hN,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(pN,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(uN,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(_N,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(bN,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(vN,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(FN,"href","/docs/transformers/pr_17060/en/model_doc/retribert#transformers.RetriBertModel"),c(TN,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(MN,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(EN,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(CN,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(wN,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(AN,"href","/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(yN,"href","/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(LN,"href","/docs/transformers/pr_17060/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(xN,"href","/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c($N,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(kN,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(SN,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(RN,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(BN,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S_,"id","transformers.AutoModelForCausalLM"),c(S_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S_,"href","#transformers.AutoModelForCausalLM"),c(Li,"class","relative group"),c(PN,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IN,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qN,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NN,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForCausalLM"),c(jN,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertLMHeadModel"),c(DN,"href","/docs/transformers/pr_17060/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(GN,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(ON,"href","/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(VN,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(XN,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(zN,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(QN,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(WN,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(HN,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForCausalLM"),c(UN,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(JN,"href","/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(YN,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(KN,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianForCausalLM"),c(ZN,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForCausalLM"),c(ej,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(oj,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(rj,"href","/docs/transformers/pr_17060/en/model_doc/opt#transformers.OPTForCausalLM"),c(tj,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(aj,"href","/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(nj,"href","/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(sj,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(lj,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(ij,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(dj,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(cj,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(fj,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(mj,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(gj,"href","/docs/transformers/pr_17060/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(hj,"href","/docs/transformers/pr_17060/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(pj,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(uj,"href","/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(_j,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(bj,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(vj,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b0,"id","transformers.AutoModelForMaskedLM"),c(b0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b0,"href","#transformers.AutoModelForMaskedLM"),c(ki,"class","relative group"),c(Fj,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tj,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mj,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ej,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(Cj,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(wj,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForMaskedLM"),c(Aj,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(yj,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(Lj,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(xj,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c($j,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(kj,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(Sj,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Rj,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(Bj,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Pj,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(Ij,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(qj,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(Nj,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(jj,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(Dj,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(Gj,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(Oj,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(Vj,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(Xj,"href","/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(zj,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(Qj,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(Wj,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(Hj,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(Uj,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(Jj,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(Yj,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(Kj,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(Zj,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(eD,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(oD,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(rD,"href","/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t1,"id","transformers.AutoModelForSeq2SeqLM"),c(t1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t1,"href","#transformers.AutoModelForSeq2SeqLM"),c(Bi,"class","relative group"),c(tD,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aD,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nD,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sD,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(lD,"href","/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(iD,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(dD,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(cD,"href","/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(fD,"href","/docs/transformers/pr_17060/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(mD,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(gD,"href","/docs/transformers/pr_17060/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(hD,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.MarianMTModel"),c(pD,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(uD,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(_D,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(bD,"href","/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(vD,"href","/docs/transformers/pr_17060/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(FD,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(TD,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(MD,"href","/docs/transformers/pr_17060/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C1,"id","transformers.AutoModelForSequenceClassification"),c(C1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C1,"href","#transformers.AutoModelForSequenceClassification"),c(qi,"class","relative group"),c(ED,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CD,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wD,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AD,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(yD,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForSequenceClassification"),c(LD,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForSequenceClassification"),c(xD,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c($D,"href","/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(kD,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(SD,"href","/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(RD,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(BD,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(PD,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(ID,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(qD,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(ND,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(jD,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(DD,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(GD,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(OD,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(VD,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(XD,"href","/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(zD,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(QD,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(WD,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(HD,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(UD,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(JD,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDForSequenceClassification"),c(YD,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(KD,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(ZD,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(eG,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(oG,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(rG,"href","/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(tG,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(aG,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(nG,"href","/docs/transformers/pr_17060/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(sG,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(lG,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(iG,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(dG,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(cG,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(fG,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(mG,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(gG,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForSequenceClassification"),c(hG,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(pG,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(uG,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(_G,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(bG,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(vG,"href","/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mb,"id","transformers.AutoModelForMultipleChoice"),c(Mb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mb,"href","#transformers.AutoModelForMultipleChoice"),c(Di,"class","relative group"),c(FG,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TG,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MG,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EG,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(CG,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForMultipleChoice"),c(wG,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(AG,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(yG,"href","/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(LG,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(xG,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c($G,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(kG,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(SG,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(RG,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(BG,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(PG,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(IG,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(qG,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(NG,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(jG,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(DG,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(GG,"href","/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(OG,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(VG,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(XG,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(zG,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(QG,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(WG,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(HG,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(UG,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(JG,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(YG,"href","/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o2,"id","transformers.AutoModelForNextSentencePrediction"),c(o2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o2,"href","#transformers.AutoModelForNextSentencePrediction"),c(Vi,"class","relative group"),c(KG,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZG,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eO,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oO,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(rO,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(tO,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(aO,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(nO,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c2,"id","transformers.AutoModelForTokenClassification"),c(c2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c2,"href","#transformers.AutoModelForTokenClassification"),c(Qi,"class","relative group"),c(sO,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lO,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iO,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dO,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(cO,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForTokenClassification"),c(fO,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(mO,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(gO,"href","/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForTokenClassification"),c(hO,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(pO,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(uO,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(_O,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(bO,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(vO,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(FO,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(TO,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(MO,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(EO,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(CO,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(wO,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(AO,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(yO,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(LO,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(xO,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c($O,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(kO,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(SO,"href","/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(RO,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(BO,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(PO,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(IO,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(qO,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(NO,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(jO,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(DO,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(GO,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(OO,"href","/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H2,"id","transformers.AutoModelForQuestionAnswering"),c(H2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H2,"href","#transformers.AutoModelForQuestionAnswering"),c(Ui,"class","relative group"),c(VO,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XO,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zO,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QO,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(WO,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(HO,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(UO,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(JO,"href","/docs/transformers/pr_17060/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(YO,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(KO,"href","/docs/transformers/pr_17060/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(ZO,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(eV,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(oV,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(rV,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(tV,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(aV,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(nV,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(sV,"href","/docs/transformers/pr_17060/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(lV,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(iV,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(dV,"href","/docs/transformers/pr_17060/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(cV,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(fV,"href","/docs/transformers/pr_17060/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mV,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(gV,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(hV,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(pV,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(uV,"href","/docs/transformers/pr_17060/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(_V,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(bV,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(vV,"href","/docs/transformers/pr_17060/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(FV,"href","/docs/transformers/pr_17060/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(TV,"href","/docs/transformers/pr_17060/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(MV,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(EV,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(CV,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(wV,"href","/docs/transformers/pr_17060/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(AV,"href","/docs/transformers/pr_17060/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(yV,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(LV,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(xV,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c($V,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(kV,"href","/docs/transformers/pr_17060/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nv,"id","transformers.AutoModelForTableQuestionAnswering"),c(Nv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nv,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Ki,"class","relative group"),c(SV,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RV,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BV,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PV,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vv,"id","transformers.AutoModelForImageClassification"),c(Vv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vv,"href","#transformers.AutoModelForImageClassification"),c(od,"class","relative group"),c(IV,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qV,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NV,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jV,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitForImageClassification"),c(DV,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(GV,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(OV,"href","/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTForImageClassification"),c(VV,"href","/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(XV,"href","/docs/transformers/pr_17060/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(zV,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(QV,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(WV,"href","/docs/transformers/pr_17060/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(HV,"href","/docs/transformers/pr_17060/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(UV,"href","/docs/transformers/pr_17060/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(JV,"href","/docs/transformers/pr_17060/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(YV,"href","/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(KV,"href","/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinForImageClassification"),c(ZV,"href","/docs/transformers/pr_17060/en/model_doc/van#transformers.VanForImageClassification"),c(eX,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTForImageClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aF,"id","transformers.AutoModelForVision2Seq"),c(aF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aF,"href","#transformers.AutoModelForVision2Seq"),c(ad,"class","relative group"),c(oX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aX,"href","/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dF,"id","transformers.AutoModelForAudioClassification"),c(dF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dF,"href","#transformers.AutoModelForAudioClassification"),c(ld,"class","relative group"),c(nX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iX,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(dX,"href","/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(cX,"href","/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(fX,"href","/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(mX,"href","/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(gX,"href","/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(hX,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(pX,"href","/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TF,"id","transformers.AutoModelForAudioFrameClassification"),c(TF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TF,"href","#transformers.AutoModelForAudioFrameClassification"),c(cd,"class","relative group"),c(uX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_X,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vX,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(FX,"href","/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(TX,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(MX,"href","/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xF,"id","transformers.AutoModelForCTC"),c(xF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xF,"href","#transformers.AutoModelForCTC"),c(gd,"class","relative group"),c(EX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AX,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(yX,"href","/docs/transformers/pr_17060/en/model_doc/hubert#transformers.HubertForCTC"),c(LX,"href","/docs/transformers/pr_17060/en/model_doc/sew#transformers.SEWForCTC"),c(xX,"href","/docs/transformers/pr_17060/en/model_doc/sew-d#transformers.SEWDForCTC"),c($X,"href","/docs/transformers/pr_17060/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(kX,"href","/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(SX,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(RX,"href","/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForCTC"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(GF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(ud,"class","relative group"),c(BX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qX,"href","/docs/transformers/pr_17060/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(NX,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WF,"id","transformers.AutoModelForAudioXVector"),c(WF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WF,"href","#transformers.AutoModelForAudioXVector"),c(vd,"class","relative group"),c(jX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OX,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(VX,"href","/docs/transformers/pr_17060/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(XX,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(zX,"href","/docs/transformers/pr_17060/en/model_doc/wavlm#transformers.WavLMForXVector"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o6,"id","transformers.AutoModelForMaskedImageModeling"),c(o6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o6,"href","#transformers.AutoModelForMaskedImageModeling"),c(Md,"class","relative group"),c(QX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UX,"href","/docs/transformers/pr_17060/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(JX,"href","/docs/transformers/pr_17060/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(YX,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i6,"id","transformers.AutoModelForObjectDetection"),c(i6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i6,"href","#transformers.AutoModelForObjectDetection"),c(Ad,"class","relative group"),c(KX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZX,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ez,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oz,"href","/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrForObjectDetection"),c(rz,"href","/docs/transformers/pr_17060/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h6,"id","transformers.AutoModelForImageSegmentation"),c(h6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h6,"href","#transformers.AutoModelForImageSegmentation"),c(xd,"class","relative group"),c(tz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(az,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sz,"href","/docs/transformers/pr_17060/en/model_doc/detr#transformers.DetrForSegmentation"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v6,"id","transformers.AutoModelForSemanticSegmentation"),c(v6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v6,"href","#transformers.AutoModelForSemanticSegmentation"),c(Sd,"class","relative group"),c(lz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cz,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(fz,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(mz,"href","/docs/transformers/pr_17060/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(gz,"href","/docs/transformers/pr_17060/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y6,"id","transformers.AutoModelForInstanceSegmentation"),c(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y6,"href","#transformers.AutoModelForInstanceSegmentation"),c(Pd,"class","relative group"),c(hz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_z,"href","/docs/transformers/pr_17060/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S6,"id","transformers.TFAutoModel"),c(S6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S6,"href","#transformers.TFAutoModel"),c(Nd,"class","relative group"),c(bz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertModel"),c(Mz,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.TFBartModel"),c(Ez,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertModel"),c(Cz,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(wz,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(Az,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertModel"),c(yz,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.TFCLIPModel"),c(Lz,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertModel"),c(xz,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.TFConvNextModel"),c($z,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLModel"),c(kz,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(Sz,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaModel"),c(Rz,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(Bz,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(Pz,"href","/docs/transformers/pr_17060/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(Iz,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraModel"),c(qz,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(Nz,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelModel"),c(jz,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(Dz,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2Model"),c(Gz,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJModel"),c(Oz,"href","/docs/transformers/pr_17060/en/model_doc/hubert#transformers.TFHubertModel"),c(Vz,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(Xz,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.TFLEDModel"),c(zz,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerModel"),c(Qz,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.TFLxmertModel"),c(Wz,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.TFMarianModel"),c(Hz,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.TFMBartModel"),c(Uz,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(Jz,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetModel"),c(Yz,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.TFMT5Model"),c(Kz,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(Zz,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.TFPegasusModel"),c(eQ,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertModel"),c(oQ,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaModel"),c(rQ,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerModel"),c(tQ,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(aQ,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.TFT5Model"),c(nQ,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasModel"),c(sQ,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(lQ,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.TFViTModel"),c(iQ,"href","/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(dQ,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(cQ,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMModel"),c(fQ,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(mQ,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wT,"id","transformers.TFAutoModelForPreTraining"),c(wT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wT,"href","#transformers.TFAutoModelForPreTraining"),c(Gd,"class","relative group"),c(gQ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hQ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pQ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uQ,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(_Q,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(bQ,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForPreTraining"),c(vQ,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(FQ,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(TQ,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(MQ,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(EQ,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(CQ,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(wQ,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(AQ,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(yQ,"href","/docs/transformers/pr_17060/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(LQ,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(xQ,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c($Q,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(kQ,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(SQ,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(RQ,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(BQ,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(PQ,"href","/docs/transformers/pr_17060/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(IQ,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(qQ,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(NQ,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YT,"id","transformers.TFAutoModelForCausalLM"),c(YT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YT,"href","#transformers.TFAutoModelForCausalLM"),c(Xd,"class","relative group"),c(jQ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DQ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GQ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OQ,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(VQ,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(XQ,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(zQ,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(QQ,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(WQ,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(HQ,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(UQ,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(JQ,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(YQ,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(KQ,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(ZQ,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m7,"id","transformers.TFAutoModelForImageClassification"),c(m7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m7,"href","#transformers.TFAutoModelForImageClassification"),c(Wd,"class","relative group"),c(eW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tW,"href","/docs/transformers/pr_17060/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(aW,"href","/docs/transformers/pr_17060/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(nW,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b7,"id","transformers.TFAutoModelForMaskedLM"),c(b7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b7,"href","#transformers.TFAutoModelForMaskedLM"),c(Yd,"class","relative group"),c(sW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dW,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(cW,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(fW,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(mW,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(gW,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(hW,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(pW,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(uW,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(_W,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(bW,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(vW,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(FW,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(TW,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(MW,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(EW,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(CW,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(wW,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(AW,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(yW,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(LW,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G7,"id","transformers.TFAutoModelForSeq2SeqLM"),c(G7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G7,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(ec,"class","relative group"),c(xW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($W,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SW,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(RW,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(BW,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(PW,"href","/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(IW,"href","/docs/transformers/pr_17060/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(qW,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.TFMarianMTModel"),c(NW,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(jW,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(DW,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(GW,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eM,"id","transformers.TFAutoModelForSequenceClassification"),c(eM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eM,"href","#transformers.TFAutoModelForSequenceClassification"),c(tc,"class","relative group"),c(OW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XW,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zW,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(QW,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(WW,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(HW,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(UW,"href","/docs/transformers/pr_17060/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(JW,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(YW,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(KW,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(ZW,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(eH,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(oH,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(rH,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(tH,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(aH,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(nH,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(sH,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(lH,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(iH,"href","/docs/transformers/pr_17060/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(dH,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(cH,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(fH,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(mH,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(gH,"href","/docs/transformers/pr_17060/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(hH,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(pH,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(uH,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xM,"id","transformers.TFAutoModelForMultipleChoice"),c(xM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xM,"href","#transformers.TFAutoModelForMultipleChoice"),c(sc,"class","relative group"),c(_H,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FH,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(TH,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(MH,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(EH,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(CH,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(wH,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(AH,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(yH,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(LH,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(xH,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c($H,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(kH,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(SH,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(RH,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(BH,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(PH,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(IH,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UM,"id","transformers.TFAutoModelForNextSentencePrediction"),c(UM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UM,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(dc,"class","relative group"),c(qH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DH,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(GH,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e4,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(e4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e4,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(mc,"class","relative group"),c(OH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zH,"href","/docs/transformers/pr_17060/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a4,"id","transformers.TFAutoModelForTokenClassification"),c(a4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a4,"href","#transformers.TFAutoModelForTokenClassification"),c(pc,"class","relative group"),c(QH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HH,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UH,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(JH,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(YH,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(KH,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(ZH,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(eU,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(oU,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(rU,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(tU,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(aU,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(nU,"href","/docs/transformers/pr_17060/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(sU,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(lU,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(iU,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(dU,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(cU,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(fU,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(mU,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(gU,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(hU,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y4,"id","transformers.TFAutoModelForQuestionAnswering"),c(y4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y4,"href","#transformers.TFAutoModelForQuestionAnswering"),c(bc,"class","relative group"),c(pU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_U,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bU,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(vU,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(FU,"href","/docs/transformers/pr_17060/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(TU,"href","/docs/transformers/pr_17060/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(MU,"href","/docs/transformers/pr_17060/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(EU,"href","/docs/transformers/pr_17060/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(CU,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(wU,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(AU,"href","/docs/transformers/pr_17060/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(yU,"href","/docs/transformers/pr_17060/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(LU,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(xU,"href","/docs/transformers/pr_17060/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c($U,"href","/docs/transformers/pr_17060/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(kU,"href","/docs/transformers/pr_17060/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(SU,"href","/docs/transformers/pr_17060/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(RU,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(BU,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(PU,"href","/docs/transformers/pr_17060/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(IU,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(qU,"href","/docs/transformers/pr_17060/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J4,"id","transformers.TFAutoModelForVision2Seq"),c(J4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J4,"href","#transformers.TFAutoModelForVision2Seq"),c(Tc,"class","relative group"),c(NU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GU,"href","/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eE,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(eE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eE,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Cc,"class","relative group"),c(OU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zU,"href","/docs/transformers/pr_17060/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aE,"id","transformers.FlaxAutoModel"),c(aE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aE,"href","#transformers.FlaxAutoModel"),c(yc,"class","relative group"),c(QU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HU,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UU,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertModel"),c(JU,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartModel"),c(YU,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.FlaxBeitModel"),c(KU,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertModel"),c(ZU,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(eJ,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(oJ,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(rJ,"href","/docs/transformers/pr_17060/en/model_doc/clip#transformers.FlaxCLIPModel"),c(tJ,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(aJ,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraModel"),c(nJ,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(sJ,"href","/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(lJ,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(iJ,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.FlaxMarianModel"),c(dJ,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartModel"),c(cJ,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.FlaxMT5Model"),c(fJ,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(mJ,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(gJ,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(hJ,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.FlaxT5Model"),c(pJ,"href","/docs/transformers/pr_17060/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(uJ,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.FlaxViTModel"),c(_J,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(bJ,"href","/docs/transformers/pr_17060/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(vJ,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SE,"id","transformers.FlaxAutoModelForCausalLM"),c(SE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SE,"href","#transformers.FlaxAutoModelForCausalLM"),c($c,"class","relative group"),c(FJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EJ,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(CJ,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(wJ,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(AJ,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(yJ,"href","/docs/transformers/pr_17060/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(LJ,"href","/docs/transformers/pr_17060/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(xJ,"href","/docs/transformers/pr_17060/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c($J,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(kJ,"href","/docs/transformers/pr_17060/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XE,"id","transformers.FlaxAutoModelForPreTraining"),c(XE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XE,"href","#transformers.FlaxAutoModelForPreTraining"),c(Rc,"class","relative group"),c(SJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PJ,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(IJ,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(qJ,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(NJ,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(jJ,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(DJ,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(GJ,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(OJ,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(VJ,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(XJ,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(zJ,"href","/docs/transformers/pr_17060/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(QJ,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n5,"id","transformers.FlaxAutoModelForMaskedLM"),c(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n5,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Ic,"class","relative group"),c(WJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UJ,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JJ,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(YJ,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(KJ,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(ZJ,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(eY,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(oY,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(rY,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(tY,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(aY,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(nY,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b5,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(b5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b5,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(jc,"class","relative group"),c(sY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dY,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(cY,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(fY,"href","/docs/transformers/pr_17060/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(mY,"href","/docs/transformers/pr_17060/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(gY,"href","/docs/transformers/pr_17060/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(hY,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(pY,"href","/docs/transformers/pr_17060/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(uY,"href","/docs/transformers/pr_17060/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(_Y,"href","/docs/transformers/pr_17060/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($5,"id","transformers.FlaxAutoModelForSequenceClassification"),c($5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($5,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Oc,"class","relative group"),c(bY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TY,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(MY,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(EY,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(CY,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(wY,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(AY,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(yY,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(LY,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(xY,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c($Y,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V5,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(V5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V5,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(zc,"class","relative group"),c(kY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BY,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(PY,"href","/docs/transformers/pr_17060/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(IY,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(qY,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(NY,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(jY,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(DY,"href","/docs/transformers/pr_17060/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(GY,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(OY,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(VY,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rC,"id","transformers.FlaxAutoModelForTokenClassification"),c(rC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rC,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Hc,"class","relative group"),c(XY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QY,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WY,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(HY,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(UY,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(JY,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(YY,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(KY,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(ZY,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(eK,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gC,"id","transformers.FlaxAutoModelForMultipleChoice"),c(gC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gC,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(Yc,"class","relative group"),c(oK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aK,"href","/docs/transformers/pr_17060/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(nK,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(sK,"href","/docs/transformers/pr_17060/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(lK,"href","/docs/transformers/pr_17060/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(iK,"href","/docs/transformers/pr_17060/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(dK,"href","/docs/transformers/pr_17060/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(cK,"href","/docs/transformers/pr_17060/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(fK,"href","/docs/transformers/pr_17060/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CC,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(CC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CC,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(ef,"class","relative group"),c(mK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pK,"href","/docs/transformers/pr_17060/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LC,"id","transformers.FlaxAutoModelForImageClassification"),c(LC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LC,"href","#transformers.FlaxAutoModelForImageClassification"),c(tf,"class","relative group"),c(uK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_K,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vK,"href","/docs/transformers/pr_17060/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(FK,"href","/docs/transformers/pr_17060/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RC,"id","transformers.FlaxAutoModelForVision2Seq"),c(RC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RC,"href","#transformers.FlaxAutoModelForVision2Seq"),c(sf,"class","relative group"),c(TK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EK,"href","/docs/transformers/pr_17060/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CK,"href","/docs/transformers/pr_17060/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Mo),e(Mo,ii),b(f,gf,_),b(f,et,_),e(et,di),e(et,ci),e(ci,oA),e(et,hf),b(f,qe,_),b(f,Xe,_),e(Xe,fi),e(Xe,An),e(An,rA),e(Xe,yn),e(Xe,Ln),e(Ln,tA),e(Xe,mi),e(Xe,xn),e(xn,aA),e(Xe,gi),b(f,pf,_),M(Ma,f,_),b(f,ze,_),b(f,Ae,_),e(Ae,E$),e(Ae,hi),e(hi,C$),e(Ae,w$),b(f,Eo,_),b(f,Ea,_),e(Ea,A$),e(Ea,uf),e(uf,y$),e(Ea,RDe),b(f,MIe,_),b(f,pi,_),e(pi,_f),e(_f,bee),M(nA,bee,null),e(pi,BDe),e(pi,vee),e(vee,PDe),b(f,EIe,_),b(f,$n,_),e($n,IDe),e($n,Fee),e(Fee,qDe),e($n,NDe),e($n,Tee),e(Tee,jDe),e($n,DDe),b(f,CIe,_),M(sA,f,_),b(f,wIe,_),b(f,L$,_),e(L$,GDe),b(f,AIe,_),M(bf,f,_),b(f,yIe,_),b(f,ui,_),e(ui,vf),e(vf,Mee),M(lA,Mee,null),e(ui,ODe),e(ui,Eee),e(Eee,VDe),b(f,LIe,_),b(f,Co,_),M(iA,Co,null),e(Co,XDe),e(Co,dA),e(dA,zDe),e(dA,x$),e(x$,QDe),e(dA,WDe),e(Co,HDe),e(Co,cA),e(cA,UDe),e(cA,Cee),e(Cee,JDe),e(cA,YDe),e(Co,KDe),e(Co,Er),M(fA,Er,null),e(Er,ZDe),e(Er,wee),e(wee,eGe),e(Er,oGe),e(Er,_i),e(_i,rGe),e(_i,Aee),e(Aee,tGe),e(_i,aGe),e(_i,yee),e(yee,nGe),e(_i,sGe),e(Er,lGe),e(Er,A),e(A,Ff),e(Ff,Lee),e(Lee,iGe),e(Ff,dGe),e(Ff,$$),e($$,cGe),e(Ff,fGe),e(A,mGe),e(A,Tf),e(Tf,xee),e(xee,gGe),e(Tf,hGe),e(Tf,k$),e(k$,pGe),e(Tf,uGe),e(A,_Ge),e(A,Mf),e(Mf,$ee),e($ee,bGe),e(Mf,vGe),e(Mf,S$),e(S$,FGe),e(Mf,TGe),e(A,MGe),e(A,Ef),e(Ef,kee),e(kee,EGe),e(Ef,CGe),e(Ef,R$),e(R$,wGe),e(Ef,AGe),e(A,yGe),e(A,Cf),e(Cf,See),e(See,LGe),e(Cf,xGe),e(Cf,B$),e(B$,$Ge),e(Cf,kGe),e(A,SGe),e(A,wf),e(wf,Ree),e(Ree,RGe),e(wf,BGe),e(wf,P$),e(P$,PGe),e(wf,IGe),e(A,qGe),e(A,Af),e(Af,Bee),e(Bee,NGe),e(Af,jGe),e(Af,I$),e(I$,DGe),e(Af,GGe),e(A,OGe),e(A,yf),e(yf,Pee),e(Pee,VGe),e(yf,XGe),e(yf,q$),e(q$,zGe),e(yf,QGe),e(A,WGe),e(A,Lf),e(Lf,Iee),e(Iee,HGe),e(Lf,UGe),e(Lf,N$),e(N$,JGe),e(Lf,YGe),e(A,KGe),e(A,xf),e(xf,qee),e(qee,ZGe),e(xf,eOe),e(xf,j$),e(j$,oOe),e(xf,rOe),e(A,tOe),e(A,$f),e($f,Nee),e(Nee,aOe),e($f,nOe),e($f,D$),e(D$,sOe),e($f,lOe),e(A,iOe),e(A,kf),e(kf,jee),e(jee,dOe),e(kf,cOe),e(kf,G$),e(G$,fOe),e(kf,mOe),e(A,gOe),e(A,Sf),e(Sf,Dee),e(Dee,hOe),e(Sf,pOe),e(Sf,O$),e(O$,uOe),e(Sf,_Oe),e(A,bOe),e(A,Rf),e(Rf,Gee),e(Gee,vOe),e(Rf,FOe),e(Rf,V$),e(V$,TOe),e(Rf,MOe),e(A,EOe),e(A,Bf),e(Bf,Oee),e(Oee,COe),e(Bf,wOe),e(Bf,X$),e(X$,AOe),e(Bf,yOe),e(A,LOe),e(A,Pf),e(Pf,Vee),e(Vee,xOe),e(Pf,$Oe),e(Pf,z$),e(z$,kOe),e(Pf,SOe),e(A,ROe),e(A,If),e(If,Xee),e(Xee,BOe),e(If,POe),e(If,Q$),e(Q$,IOe),e(If,qOe),e(A,NOe),e(A,qf),e(qf,zee),e(zee,jOe),e(qf,DOe),e(qf,W$),e(W$,GOe),e(qf,OOe),e(A,VOe),e(A,Nf),e(Nf,Qee),e(Qee,XOe),e(Nf,zOe),e(Nf,H$),e(H$,QOe),e(Nf,WOe),e(A,HOe),e(A,jf),e(jf,Wee),e(Wee,UOe),e(jf,JOe),e(jf,U$),e(U$,YOe),e(jf,KOe),e(A,ZOe),e(A,Df),e(Df,Hee),e(Hee,eVe),e(Df,oVe),e(Df,J$),e(J$,rVe),e(Df,tVe),e(A,aVe),e(A,Gf),e(Gf,Uee),e(Uee,nVe),e(Gf,sVe),e(Gf,Y$),e(Y$,lVe),e(Gf,iVe),e(A,dVe),e(A,Of),e(Of,Jee),e(Jee,cVe),e(Of,fVe),e(Of,K$),e(K$,mVe),e(Of,gVe),e(A,hVe),e(A,Vf),e(Vf,Yee),e(Yee,pVe),e(Vf,uVe),e(Vf,Z$),e(Z$,_Ve),e(Vf,bVe),e(A,vVe),e(A,Xf),e(Xf,Kee),e(Kee,FVe),e(Xf,TVe),e(Xf,ek),e(ek,MVe),e(Xf,EVe),e(A,CVe),e(A,zf),e(zf,Zee),e(Zee,wVe),e(zf,AVe),e(zf,ok),e(ok,yVe),e(zf,LVe),e(A,xVe),e(A,Qf),e(Qf,eoe),e(eoe,$Ve),e(Qf,kVe),e(Qf,rk),e(rk,SVe),e(Qf,RVe),e(A,BVe),e(A,Wf),e(Wf,ooe),e(ooe,PVe),e(Wf,IVe),e(Wf,tk),e(tk,qVe),e(Wf,NVe),e(A,jVe),e(A,Hf),e(Hf,roe),e(roe,DVe),e(Hf,GVe),e(Hf,ak),e(ak,OVe),e(Hf,VVe),e(A,XVe),e(A,Uf),e(Uf,toe),e(toe,zVe),e(Uf,QVe),e(Uf,nk),e(nk,WVe),e(Uf,HVe),e(A,UVe),e(A,Jf),e(Jf,aoe),e(aoe,JVe),e(Jf,YVe),e(Jf,sk),e(sk,KVe),e(Jf,ZVe),e(A,eXe),e(A,Yf),e(Yf,noe),e(noe,oXe),e(Yf,rXe),e(Yf,lk),e(lk,tXe),e(Yf,aXe),e(A,nXe),e(A,Kf),e(Kf,soe),e(soe,sXe),e(Kf,lXe),e(Kf,ik),e(ik,iXe),e(Kf,dXe),e(A,cXe),e(A,Zf),e(Zf,loe),e(loe,fXe),e(Zf,mXe),e(Zf,dk),e(dk,gXe),e(Zf,hXe),e(A,pXe),e(A,em),e(em,ioe),e(ioe,uXe),e(em,_Xe),e(em,ck),e(ck,bXe),e(em,vXe),e(A,FXe),e(A,om),e(om,doe),e(doe,TXe),e(om,MXe),e(om,fk),e(fk,EXe),e(om,CXe),e(A,wXe),e(A,rm),e(rm,coe),e(coe,AXe),e(rm,yXe),e(rm,mk),e(mk,LXe),e(rm,xXe),e(A,$Xe),e(A,tm),e(tm,foe),e(foe,kXe),e(tm,SXe),e(tm,gk),e(gk,RXe),e(tm,BXe),e(A,PXe),e(A,am),e(am,moe),e(moe,IXe),e(am,qXe),e(am,hk),e(hk,NXe),e(am,jXe),e(A,DXe),e(A,nm),e(nm,goe),e(goe,GXe),e(nm,OXe),e(nm,pk),e(pk,VXe),e(nm,XXe),e(A,zXe),e(A,sm),e(sm,hoe),e(hoe,QXe),e(sm,WXe),e(sm,uk),e(uk,HXe),e(sm,UXe),e(A,JXe),e(A,lm),e(lm,poe),e(poe,YXe),e(lm,KXe),e(lm,_k),e(_k,ZXe),e(lm,eze),e(A,oze),e(A,im),e(im,uoe),e(uoe,rze),e(im,tze),e(im,bk),e(bk,aze),e(im,nze),e(A,sze),e(A,dm),e(dm,_oe),e(_oe,lze),e(dm,ize),e(dm,vk),e(vk,dze),e(dm,cze),e(A,fze),e(A,cm),e(cm,boe),e(boe,mze),e(cm,gze),e(cm,Fk),e(Fk,hze),e(cm,pze),e(A,uze),e(A,fm),e(fm,voe),e(voe,_ze),e(fm,bze),e(fm,Tk),e(Tk,vze),e(fm,Fze),e(A,Tze),e(A,mm),e(mm,Foe),e(Foe,Mze),e(mm,Eze),e(mm,Mk),e(Mk,Cze),e(mm,wze),e(A,Aze),e(A,gm),e(gm,Toe),e(Toe,yze),e(gm,Lze),e(gm,Ek),e(Ek,xze),e(gm,$ze),e(A,kze),e(A,hm),e(hm,Moe),e(Moe,Sze),e(hm,Rze),e(hm,Ck),e(Ck,Bze),e(hm,Pze),e(A,Ize),e(A,pm),e(pm,Eoe),e(Eoe,qze),e(pm,Nze),e(pm,wk),e(wk,jze),e(pm,Dze),e(A,Gze),e(A,um),e(um,Coe),e(Coe,Oze),e(um,Vze),e(um,Ak),e(Ak,Xze),e(um,zze),e(A,Qze),e(A,_m),e(_m,woe),e(woe,Wze),e(_m,Hze),e(_m,yk),e(yk,Uze),e(_m,Jze),e(A,Yze),e(A,bm),e(bm,Aoe),e(Aoe,Kze),e(bm,Zze),e(bm,Lk),e(Lk,eQe),e(bm,oQe),e(A,rQe),e(A,vm),e(vm,yoe),e(yoe,tQe),e(vm,aQe),e(vm,xk),e(xk,nQe),e(vm,sQe),e(A,lQe),e(A,Fm),e(Fm,Loe),e(Loe,iQe),e(Fm,dQe),e(Fm,$k),e($k,cQe),e(Fm,fQe),e(A,mQe),e(A,Tm),e(Tm,xoe),e(xoe,gQe),e(Tm,hQe),e(Tm,kk),e(kk,pQe),e(Tm,uQe),e(A,_Qe),e(A,Mm),e(Mm,$oe),e($oe,bQe),e(Mm,vQe),e(Mm,Sk),e(Sk,FQe),e(Mm,TQe),e(A,MQe),e(A,Em),e(Em,koe),e(koe,EQe),e(Em,CQe),e(Em,Rk),e(Rk,wQe),e(Em,AQe),e(A,yQe),e(A,Cm),e(Cm,Soe),e(Soe,LQe),e(Cm,xQe),e(Cm,Bk),e(Bk,$Qe),e(Cm,kQe),e(A,SQe),e(A,wm),e(wm,Roe),e(Roe,RQe),e(wm,BQe),e(wm,Pk),e(Pk,PQe),e(wm,IQe),e(A,qQe),e(A,Am),e(Am,Boe),e(Boe,NQe),e(Am,jQe),e(Am,Ik),e(Ik,DQe),e(Am,GQe),e(A,OQe),e(A,ym),e(ym,Poe),e(Poe,VQe),e(ym,XQe),e(ym,qk),e(qk,zQe),e(ym,QQe),e(A,WQe),e(A,Lm),e(Lm,Ioe),e(Ioe,HQe),e(Lm,UQe),e(Lm,Nk),e(Nk,JQe),e(Lm,YQe),e(A,KQe),e(A,xm),e(xm,qoe),e(qoe,ZQe),e(xm,eWe),e(xm,jk),e(jk,oWe),e(xm,rWe),e(A,tWe),e(A,$m),e($m,Noe),e(Noe,aWe),e($m,nWe),e($m,Dk),e(Dk,sWe),e($m,lWe),e(A,iWe),e(A,km),e(km,joe),e(joe,dWe),e(km,cWe),e(km,Gk),e(Gk,fWe),e(km,mWe),e(A,gWe),e(A,Sm),e(Sm,Doe),e(Doe,hWe),e(Sm,pWe),e(Sm,Ok),e(Ok,uWe),e(Sm,_We),e(A,bWe),e(A,Rm),e(Rm,Goe),e(Goe,vWe),e(Rm,FWe),e(Rm,Vk),e(Vk,TWe),e(Rm,MWe),e(A,EWe),e(A,Bm),e(Bm,Ooe),e(Ooe,CWe),e(Bm,wWe),e(Bm,Xk),e(Xk,AWe),e(Bm,yWe),e(A,LWe),e(A,Pm),e(Pm,Voe),e(Voe,xWe),e(Pm,$We),e(Pm,zk),e(zk,kWe),e(Pm,SWe),e(A,RWe),e(A,Im),e(Im,Xoe),e(Xoe,BWe),e(Im,PWe),e(Im,Qk),e(Qk,IWe),e(Im,qWe),e(A,NWe),e(A,qm),e(qm,zoe),e(zoe,jWe),e(qm,DWe),e(qm,Wk),e(Wk,GWe),e(qm,OWe),e(A,VWe),e(A,Nm),e(Nm,Qoe),e(Qoe,XWe),e(Nm,zWe),e(Nm,Hk),e(Hk,QWe),e(Nm,WWe),e(A,HWe),e(A,jm),e(jm,Woe),e(Woe,UWe),e(jm,JWe),e(jm,Uk),e(Uk,YWe),e(jm,KWe),e(A,ZWe),e(A,Dm),e(Dm,Hoe),e(Hoe,eHe),e(Dm,oHe),e(Dm,Jk),e(Jk,rHe),e(Dm,tHe),e(A,aHe),e(A,Gm),e(Gm,Uoe),e(Uoe,nHe),e(Gm,sHe),e(Gm,Yk),e(Yk,lHe),e(Gm,iHe),e(A,dHe),e(A,Om),e(Om,Joe),e(Joe,cHe),e(Om,fHe),e(Om,Kk),e(Kk,mHe),e(Om,gHe),e(A,hHe),e(A,Vm),e(Vm,Yoe),e(Yoe,pHe),e(Vm,uHe),e(Vm,Zk),e(Zk,_He),e(Vm,bHe),e(A,vHe),e(A,Xm),e(Xm,Koe),e(Koe,FHe),e(Xm,THe),e(Xm,eS),e(eS,MHe),e(Xm,EHe),e(A,CHe),e(A,zm),e(zm,Zoe),e(Zoe,wHe),e(zm,AHe),e(zm,oS),e(oS,yHe),e(zm,LHe),e(A,xHe),e(A,Qm),e(Qm,ere),e(ere,$He),e(Qm,kHe),e(Qm,rS),e(rS,SHe),e(Qm,RHe),e(A,BHe),e(A,Wm),e(Wm,ore),e(ore,PHe),e(Wm,IHe),e(Wm,tS),e(tS,qHe),e(Wm,NHe),e(A,jHe),e(A,Hm),e(Hm,rre),e(rre,DHe),e(Hm,GHe),e(Hm,aS),e(aS,OHe),e(Hm,VHe),e(A,XHe),e(A,Um),e(Um,tre),e(tre,zHe),e(Um,QHe),e(Um,nS),e(nS,WHe),e(Um,HHe),e(A,UHe),e(A,Jm),e(Jm,are),e(are,JHe),e(Jm,YHe),e(Jm,sS),e(sS,KHe),e(Jm,ZHe),e(A,eUe),e(A,Ym),e(Ym,nre),e(nre,oUe),e(Ym,rUe),e(Ym,lS),e(lS,tUe),e(Ym,aUe),e(A,nUe),e(A,Km),e(Km,sre),e(sre,sUe),e(Km,lUe),e(Km,iS),e(iS,iUe),e(Km,dUe),e(A,cUe),e(A,Zm),e(Zm,lre),e(lre,fUe),e(Zm,mUe),e(Zm,dS),e(dS,gUe),e(Zm,hUe),e(A,pUe),e(A,eg),e(eg,ire),e(ire,uUe),e(eg,_Ue),e(eg,cS),e(cS,bUe),e(eg,vUe),e(A,FUe),e(A,og),e(og,dre),e(dre,TUe),e(og,MUe),e(og,fS),e(fS,EUe),e(og,CUe),e(A,wUe),e(A,rg),e(rg,cre),e(cre,AUe),e(rg,yUe),e(rg,mS),e(mS,LUe),e(rg,xUe),e(A,$Ue),e(A,tg),e(tg,fre),e(fre,kUe),e(tg,SUe),e(tg,gS),e(gS,RUe),e(tg,BUe),e(A,PUe),e(A,ag),e(ag,mre),e(mre,IUe),e(ag,qUe),e(ag,hS),e(hS,NUe),e(ag,jUe),e(A,DUe),e(A,ng),e(ng,gre),e(gre,GUe),e(ng,OUe),e(ng,pS),e(pS,VUe),e(ng,XUe),e(A,zUe),e(A,sg),e(sg,hre),e(hre,QUe),e(sg,WUe),e(sg,uS),e(uS,HUe),e(sg,UUe),e(A,JUe),e(A,lg),e(lg,pre),e(pre,YUe),e(lg,KUe),e(lg,_S),e(_S,ZUe),e(lg,eJe),e(A,oJe),e(A,ig),e(ig,ure),e(ure,rJe),e(ig,tJe),e(ig,bS),e(bS,aJe),e(ig,nJe),e(A,sJe),e(A,dg),e(dg,_re),e(_re,lJe),e(dg,iJe),e(dg,vS),e(vS,dJe),e(dg,cJe),e(A,fJe),e(A,cg),e(cg,bre),e(bre,mJe),e(cg,gJe),e(cg,FS),e(FS,hJe),e(cg,pJe),e(A,uJe),e(A,fg),e(fg,vre),e(vre,_Je),e(fg,bJe),e(fg,TS),e(TS,vJe),e(fg,FJe),e(A,TJe),e(A,mg),e(mg,Fre),e(Fre,MJe),e(mg,EJe),e(mg,MS),e(MS,CJe),e(mg,wJe),e(A,AJe),e(A,gg),e(gg,Tre),e(Tre,yJe),e(gg,LJe),e(gg,ES),e(ES,xJe),e(gg,$Je),e(A,kJe),e(A,hg),e(hg,Mre),e(Mre,SJe),e(hg,RJe),e(hg,CS),e(CS,BJe),e(hg,PJe),e(A,IJe),e(A,pg),e(pg,Ere),e(Ere,qJe),e(pg,NJe),e(pg,wS),e(wS,jJe),e(pg,DJe),e(A,GJe),e(A,ug),e(ug,Cre),e(Cre,OJe),e(ug,VJe),e(ug,AS),e(AS,XJe),e(ug,zJe),e(A,QJe),e(A,_g),e(_g,wre),e(wre,WJe),e(_g,HJe),e(_g,yS),e(yS,UJe),e(_g,JJe),e(Er,YJe),M(bg,Er,null),e(Co,KJe),e(Co,vg),M(mA,vg,null),e(vg,ZJe),e(vg,Are),e(Are,eYe),b(f,xIe,_),b(f,bi,_),e(bi,Fg),e(Fg,yre),M(gA,yre,null),e(bi,oYe),e(bi,Lre),e(Lre,rYe),b(f,$Ie,_),b(f,wo,_),M(hA,wo,null),e(wo,tYe),e(wo,pA),e(pA,aYe),e(pA,LS),e(LS,nYe),e(pA,sYe),e(wo,lYe),e(wo,uA),e(uA,iYe),e(uA,xre),e(xre,dYe),e(uA,cYe),e(wo,fYe),e(wo,Cr),M(_A,Cr,null),e(Cr,mYe),e(Cr,$re),e($re,gYe),e(Cr,hYe),e(Cr,Ca),e(Ca,pYe),e(Ca,kre),e(kre,uYe),e(Ca,_Ye),e(Ca,Sre),e(Sre,bYe),e(Ca,vYe),e(Ca,Rre),e(Rre,FYe),e(Ca,TYe),e(Cr,MYe),e(Cr,k),e(k,kn),e(kn,Bre),e(Bre,EYe),e(kn,CYe),e(kn,xS),e(xS,wYe),e(kn,AYe),e(kn,$S),e($S,yYe),e(kn,LYe),e(k,xYe),e(k,Sn),e(Sn,Pre),e(Pre,$Ye),e(Sn,kYe),e(Sn,kS),e(kS,SYe),e(Sn,RYe),e(Sn,SS),e(SS,BYe),e(Sn,PYe),e(k,IYe),e(k,Rn),e(Rn,Ire),e(Ire,qYe),e(Rn,NYe),e(Rn,RS),e(RS,jYe),e(Rn,DYe),e(Rn,BS),e(BS,GYe),e(Rn,OYe),e(k,VYe),e(k,Tg),e(Tg,qre),e(qre,XYe),e(Tg,zYe),e(Tg,PS),e(PS,QYe),e(Tg,WYe),e(k,HYe),e(k,Bn),e(Bn,Nre),e(Nre,UYe),e(Bn,JYe),e(Bn,IS),e(IS,YYe),e(Bn,KYe),e(Bn,qS),e(qS,ZYe),e(Bn,eKe),e(k,oKe),e(k,Mg),e(Mg,jre),e(jre,rKe),e(Mg,tKe),e(Mg,NS),e(NS,aKe),e(Mg,nKe),e(k,sKe),e(k,Eg),e(Eg,Dre),e(Dre,lKe),e(Eg,iKe),e(Eg,jS),e(jS,dKe),e(Eg,cKe),e(k,fKe),e(k,Cg),e(Cg,Gre),e(Gre,mKe),e(Cg,gKe),e(Cg,DS),e(DS,hKe),e(Cg,pKe),e(k,uKe),e(k,Pn),e(Pn,Ore),e(Ore,_Ke),e(Pn,bKe),e(Pn,GS),e(GS,vKe),e(Pn,FKe),e(Pn,OS),e(OS,TKe),e(Pn,MKe),e(k,EKe),e(k,In),e(In,Vre),e(Vre,CKe),e(In,wKe),e(In,VS),e(VS,AKe),e(In,yKe),e(In,XS),e(XS,LKe),e(In,xKe),e(k,$Ke),e(k,qn),e(qn,Xre),e(Xre,kKe),e(qn,SKe),e(qn,zS),e(zS,RKe),e(qn,BKe),e(qn,QS),e(QS,PKe),e(qn,IKe),e(k,qKe),e(k,wg),e(wg,zre),e(zre,NKe),e(wg,jKe),e(wg,WS),e(WS,DKe),e(wg,GKe),e(k,OKe),e(k,Ag),e(Ag,Qre),e(Qre,VKe),e(Ag,XKe),e(Ag,HS),e(HS,zKe),e(Ag,QKe),e(k,WKe),e(k,Nn),e(Nn,Wre),e(Wre,HKe),e(Nn,UKe),e(Nn,US),e(US,JKe),e(Nn,YKe),e(Nn,JS),e(JS,KKe),e(Nn,ZKe),e(k,eZe),e(k,yg),e(yg,Hre),e(Hre,oZe),e(yg,rZe),e(yg,YS),e(YS,tZe),e(yg,aZe),e(k,nZe),e(k,jn),e(jn,Ure),e(Ure,sZe),e(jn,lZe),e(jn,KS),e(KS,iZe),e(jn,dZe),e(jn,ZS),e(ZS,cZe),e(jn,fZe),e(k,mZe),e(k,Dn),e(Dn,Jre),e(Jre,gZe),e(Dn,hZe),e(Dn,eR),e(eR,pZe),e(Dn,uZe),e(Dn,oR),e(oR,_Ze),e(Dn,bZe),e(k,vZe),e(k,Gn),e(Gn,Yre),e(Yre,FZe),e(Gn,TZe),e(Gn,rR),e(rR,MZe),e(Gn,EZe),e(Gn,tR),e(tR,CZe),e(Gn,wZe),e(k,AZe),e(k,Lg),e(Lg,Kre),e(Kre,yZe),e(Lg,LZe),e(Lg,aR),e(aR,xZe),e(Lg,$Ze),e(k,kZe),e(k,On),e(On,Zre),e(Zre,SZe),e(On,RZe),e(On,nR),e(nR,BZe),e(On,PZe),e(On,sR),e(sR,IZe),e(On,qZe),e(k,NZe),e(k,Vn),e(Vn,ete),e(ete,jZe),e(Vn,DZe),e(Vn,lR),e(lR,GZe),e(Vn,OZe),e(Vn,iR),e(iR,VZe),e(Vn,XZe),e(k,zZe),e(k,Xn),e(Xn,ote),e(ote,QZe),e(Xn,WZe),e(Xn,dR),e(dR,HZe),e(Xn,UZe),e(Xn,cR),e(cR,JZe),e(Xn,YZe),e(k,KZe),e(k,zn),e(zn,rte),e(rte,ZZe),e(zn,eeo),e(zn,fR),e(fR,oeo),e(zn,reo),e(zn,mR),e(mR,teo),e(zn,aeo),e(k,neo),e(k,Qn),e(Qn,tte),e(tte,seo),e(Qn,leo),e(Qn,gR),e(gR,ieo),e(Qn,deo),e(Qn,hR),e(hR,ceo),e(Qn,feo),e(k,meo),e(k,Wn),e(Wn,ate),e(ate,geo),e(Wn,heo),e(Wn,pR),e(pR,peo),e(Wn,ueo),e(Wn,uR),e(uR,_eo),e(Wn,beo),e(k,veo),e(k,xg),e(xg,nte),e(nte,Feo),e(xg,Teo),e(xg,_R),e(_R,Meo),e(xg,Eeo),e(k,Ceo),e(k,Hn),e(Hn,ste),e(ste,weo),e(Hn,Aeo),e(Hn,bR),e(bR,yeo),e(Hn,Leo),e(Hn,vR),e(vR,xeo),e(Hn,$eo),e(k,keo),e(k,$g),e($g,lte),e(lte,Seo),e($g,Reo),e($g,FR),e(FR,Beo),e($g,Peo),e(k,Ieo),e(k,Un),e(Un,ite),e(ite,qeo),e(Un,Neo),e(Un,TR),e(TR,jeo),e(Un,Deo),e(Un,MR),e(MR,Geo),e(Un,Oeo),e(k,Veo),e(k,Jn),e(Jn,dte),e(dte,Xeo),e(Jn,zeo),e(Jn,ER),e(ER,Qeo),e(Jn,Weo),e(Jn,CR),e(CR,Heo),e(Jn,Ueo),e(k,Jeo),e(k,Yn),e(Yn,cte),e(cte,Yeo),e(Yn,Keo),e(Yn,wR),e(wR,Zeo),e(Yn,eoo),e(Yn,AR),e(AR,ooo),e(Yn,roo),e(k,too),e(k,Kn),e(Kn,fte),e(fte,aoo),e(Kn,noo),e(Kn,yR),e(yR,soo),e(Kn,loo),e(Kn,LR),e(LR,ioo),e(Kn,doo),e(k,coo),e(k,Zn),e(Zn,mte),e(mte,foo),e(Zn,moo),e(Zn,xR),e(xR,goo),e(Zn,hoo),e(Zn,$R),e($R,poo),e(Zn,uoo),e(k,_oo),e(k,kg),e(kg,gte),e(gte,boo),e(kg,voo),e(kg,kR),e(kR,Foo),e(kg,Too),e(k,Moo),e(k,es),e(es,hte),e(hte,Eoo),e(es,Coo),e(es,SR),e(SR,woo),e(es,Aoo),e(es,RR),e(RR,yoo),e(es,Loo),e(k,xoo),e(k,os),e(os,pte),e(pte,$oo),e(os,koo),e(os,BR),e(BR,Soo),e(os,Roo),e(os,PR),e(PR,Boo),e(os,Poo),e(k,Ioo),e(k,rs),e(rs,ute),e(ute,qoo),e(rs,Noo),e(rs,IR),e(IR,joo),e(rs,Doo),e(rs,qR),e(qR,Goo),e(rs,Ooo),e(k,Voo),e(k,ts),e(ts,_te),e(_te,Xoo),e(ts,zoo),e(ts,NR),e(NR,Qoo),e(ts,Woo),e(ts,jR),e(jR,Hoo),e(ts,Uoo),e(k,Joo),e(k,as),e(as,bte),e(bte,Yoo),e(as,Koo),e(as,DR),e(DR,Zoo),e(as,ero),e(as,GR),e(GR,oro),e(as,rro),e(k,tro),e(k,ns),e(ns,vte),e(vte,aro),e(ns,nro),e(ns,OR),e(OR,sro),e(ns,lro),e(ns,VR),e(VR,iro),e(ns,dro),e(k,cro),e(k,ss),e(ss,Fte),e(Fte,fro),e(ss,mro),e(ss,XR),e(XR,gro),e(ss,hro),e(ss,zR),e(zR,pro),e(ss,uro),e(k,_ro),e(k,Sg),e(Sg,Tte),e(Tte,bro),e(Sg,vro),e(Sg,QR),e(QR,Fro),e(Sg,Tro),e(k,Mro),e(k,ls),e(ls,Mte),e(Mte,Ero),e(ls,Cro),e(ls,WR),e(WR,wro),e(ls,Aro),e(ls,HR),e(HR,yro),e(ls,Lro),e(k,xro),e(k,Rg),e(Rg,Ete),e(Ete,$ro),e(Rg,kro),e(Rg,UR),e(UR,Sro),e(Rg,Rro),e(k,Bro),e(k,Bg),e(Bg,Cte),e(Cte,Pro),e(Bg,Iro),e(Bg,JR),e(JR,qro),e(Bg,Nro),e(k,jro),e(k,is),e(is,wte),e(wte,Dro),e(is,Gro),e(is,YR),e(YR,Oro),e(is,Vro),e(is,KR),e(KR,Xro),e(is,zro),e(k,Qro),e(k,ds),e(ds,Ate),e(Ate,Wro),e(ds,Hro),e(ds,ZR),e(ZR,Uro),e(ds,Jro),e(ds,eB),e(eB,Yro),e(ds,Kro),e(k,Zro),e(k,cs),e(cs,yte),e(yte,eto),e(cs,oto),e(cs,oB),e(oB,rto),e(cs,tto),e(cs,rB),e(rB,ato),e(cs,nto),e(k,sto),e(k,Pg),e(Pg,Lte),e(Lte,lto),e(Pg,ito),e(Pg,tB),e(tB,dto),e(Pg,cto),e(k,fto),e(k,fs),e(fs,xte),e(xte,mto),e(fs,gto),e(fs,aB),e(aB,hto),e(fs,pto),e(fs,nB),e(nB,uto),e(fs,_to),e(k,bto),e(k,ms),e(ms,$te),e($te,vto),e(ms,Fto),e(ms,sB),e(sB,Tto),e(ms,Mto),e(ms,lB),e(lB,Eto),e(ms,Cto),e(k,wto),e(k,gs),e(gs,kte),e(kte,Ato),e(gs,yto),e(gs,iB),e(iB,Lto),e(gs,xto),e(gs,dB),e(dB,$to),e(gs,kto),e(k,Sto),e(k,hs),e(hs,Ste),e(Ste,Rto),e(hs,Bto),e(hs,cB),e(cB,Pto),e(hs,Ito),e(hs,fB),e(fB,qto),e(hs,Nto),e(k,jto),e(k,ps),e(ps,Rte),e(Rte,Dto),e(ps,Gto),e(ps,mB),e(mB,Oto),e(ps,Vto),e(ps,gB),e(gB,Xto),e(ps,zto),e(k,Qto),e(k,Ig),e(Ig,Bte),e(Bte,Wto),e(Ig,Hto),e(Ig,hB),e(hB,Uto),e(Ig,Jto),e(k,Yto),e(k,us),e(us,Pte),e(Pte,Kto),e(us,Zto),e(us,pB),e(pB,eao),e(us,oao),e(us,uB),e(uB,rao),e(us,tao),e(k,aao),e(k,qg),e(qg,Ite),e(Ite,nao),e(qg,sao),e(qg,_B),e(_B,lao),e(qg,iao),e(k,dao),e(k,Ng),e(Ng,qte),e(qte,cao),e(Ng,fao),e(Ng,bB),e(bB,mao),e(Ng,gao),e(k,hao),e(k,jg),e(jg,Nte),e(Nte,pao),e(jg,uao),e(jg,vB),e(vB,_ao),e(jg,bao),e(k,vao),e(k,Dg),e(Dg,jte),e(jte,Fao),e(Dg,Tao),e(Dg,FB),e(FB,Mao),e(Dg,Eao),e(k,Cao),e(k,_s),e(_s,Dte),e(Dte,wao),e(_s,Aao),e(_s,TB),e(TB,yao),e(_s,Lao),e(_s,MB),e(MB,xao),e(_s,$ao),e(k,kao),e(k,Gg),e(Gg,Gte),e(Gte,Sao),e(Gg,Rao),e(Gg,EB),e(EB,Bao),e(Gg,Pao),e(k,Iao),e(k,bs),e(bs,Ote),e(Ote,qao),e(bs,Nao),e(bs,CB),e(CB,jao),e(bs,Dao),e(bs,wB),e(wB,Gao),e(bs,Oao),e(k,Vao),e(k,vs),e(vs,Vte),e(Vte,Xao),e(vs,zao),e(vs,AB),e(AB,Qao),e(vs,Wao),e(vs,yB),e(yB,Hao),e(vs,Uao),e(k,Jao),e(k,Fs),e(Fs,Xte),e(Xte,Yao),e(Fs,Kao),e(Fs,LB),e(LB,Zao),e(Fs,eno),e(Fs,xB),e(xB,ono),e(Fs,rno),e(k,tno),e(k,Ts),e(Ts,zte),e(zte,ano),e(Ts,nno),e(Ts,$B),e($B,sno),e(Ts,lno),e(Ts,kB),e(kB,ino),e(Ts,dno),e(k,cno),e(k,Ms),e(Ms,Qte),e(Qte,fno),e(Ms,mno),e(Ms,SB),e(SB,gno),e(Ms,hno),e(Ms,RB),e(RB,pno),e(Ms,uno),e(k,_no),e(k,Es),e(Es,Wte),e(Wte,bno),e(Es,vno),e(Es,BB),e(BB,Fno),e(Es,Tno),e(Es,PB),e(PB,Mno),e(Es,Eno),e(k,Cno),e(k,Og),e(Og,Hte),e(Hte,wno),e(Og,Ano),e(Og,IB),e(IB,yno),e(Og,Lno),e(k,xno),e(k,Vg),e(Vg,Ute),e(Ute,$no),e(Vg,kno),e(Vg,qB),e(qB,Sno),e(Vg,Rno),e(k,Bno),e(k,Cs),e(Cs,Jte),e(Jte,Pno),e(Cs,Ino),e(Cs,NB),e(NB,qno),e(Cs,Nno),e(Cs,jB),e(jB,jno),e(Cs,Dno),e(k,Gno),e(k,ws),e(ws,Yte),e(Yte,Ono),e(ws,Vno),e(ws,DB),e(DB,Xno),e(ws,zno),e(ws,GB),e(GB,Qno),e(ws,Wno),e(k,Hno),e(k,As),e(As,Kte),e(Kte,Uno),e(As,Jno),e(As,OB),e(OB,Yno),e(As,Kno),e(As,VB),e(VB,Zno),e(As,eso),e(k,oso),e(k,Xg),e(Xg,Zte),e(Zte,rso),e(Xg,tso),e(Xg,XB),e(XB,aso),e(Xg,nso),e(k,sso),e(k,zg),e(zg,eae),e(eae,lso),e(zg,iso),e(zg,zB),e(zB,dso),e(zg,cso),e(k,fso),e(k,Qg),e(Qg,oae),e(oae,mso),e(Qg,gso),e(Qg,QB),e(QB,hso),e(Qg,pso),e(k,uso),e(k,ys),e(ys,rae),e(rae,_so),e(ys,bso),e(ys,WB),e(WB,vso),e(ys,Fso),e(ys,HB),e(HB,Tso),e(ys,Mso),e(k,Eso),e(k,Wg),e(Wg,tae),e(tae,Cso),e(Wg,wso),e(Wg,UB),e(UB,Aso),e(Wg,yso),e(k,Lso),e(k,Hg),e(Hg,aae),e(aae,xso),e(Hg,$so),e(Hg,JB),e(JB,kso),e(Hg,Sso),e(k,Rso),e(k,Ls),e(Ls,nae),e(nae,Bso),e(Ls,Pso),e(Ls,YB),e(YB,Iso),e(Ls,qso),e(Ls,KB),e(KB,Nso),e(Ls,jso),e(k,Dso),e(k,Ug),e(Ug,sae),e(sae,Gso),e(Ug,Oso),e(Ug,ZB),e(ZB,Vso),e(Ug,Xso),e(k,zso),e(k,Jg),e(Jg,lae),e(lae,Qso),e(Jg,Wso),e(Jg,eP),e(eP,Hso),e(Jg,Uso),e(k,Jso),e(k,xs),e(xs,iae),e(iae,Yso),e(xs,Kso),e(xs,oP),e(oP,Zso),e(xs,elo),e(xs,rP),e(rP,olo),e(xs,rlo),e(k,tlo),e(k,$s),e($s,dae),e(dae,alo),e($s,nlo),e($s,tP),e(tP,slo),e($s,llo),e($s,aP),e(aP,ilo),e($s,dlo),e(k,clo),e(k,ks),e(ks,cae),e(cae,flo),e(ks,mlo),e(ks,nP),e(nP,glo),e(ks,hlo),e(ks,sP),e(sP,plo),e(ks,ulo),e(k,_lo),e(k,Ss),e(Ss,fae),e(fae,blo),e(Ss,vlo),e(Ss,lP),e(lP,Flo),e(Ss,Tlo),e(Ss,iP),e(iP,Mlo),e(Ss,Elo),e(Cr,Clo),M(Yg,Cr,null),e(wo,wlo),e(wo,Kg),M(bA,Kg,null),e(Kg,Alo),e(Kg,mae),e(mae,ylo),b(f,kIe,_),b(f,vi,_),e(vi,Zg),e(Zg,gae),M(vA,gae,null),e(vi,Llo),e(vi,hae),e(hae,xlo),b(f,SIe,_),b(f,Ao,_),M(FA,Ao,null),e(Ao,$lo),e(Ao,TA),e(TA,klo),e(TA,dP),e(dP,Slo),e(TA,Rlo),e(Ao,Blo),e(Ao,MA),e(MA,Plo),e(MA,pae),e(pae,Ilo),e(MA,qlo),e(Ao,Nlo),e(Ao,Qe),M(EA,Qe,null),e(Qe,jlo),e(Qe,uae),e(uae,Dlo),e(Qe,Glo),e(Qe,wa),e(wa,Olo),e(wa,_ae),e(_ae,Vlo),e(wa,Xlo),e(wa,bae),e(bae,zlo),e(wa,Qlo),e(wa,vae),e(vae,Wlo),e(wa,Hlo),e(Qe,Ulo),e(Qe,Z),e(Z,eh),e(eh,Fae),e(Fae,Jlo),e(eh,Ylo),e(eh,cP),e(cP,Klo),e(eh,Zlo),e(Z,eio),e(Z,oh),e(oh,Tae),e(Tae,oio),e(oh,rio),e(oh,fP),e(fP,tio),e(oh,aio),e(Z,nio),e(Z,rh),e(rh,Mae),e(Mae,sio),e(rh,lio),e(rh,mP),e(mP,iio),e(rh,dio),e(Z,cio),e(Z,th),e(th,Eae),e(Eae,fio),e(th,mio),e(th,gP),e(gP,gio),e(th,hio),e(Z,pio),e(Z,ah),e(ah,Cae),e(Cae,uio),e(ah,_io),e(ah,hP),e(hP,bio),e(ah,vio),e(Z,Fio),e(Z,nh),e(nh,wae),e(wae,Tio),e(nh,Mio),e(nh,pP),e(pP,Eio),e(nh,Cio),e(Z,wio),e(Z,sh),e(sh,Aae),e(Aae,Aio),e(sh,yio),e(sh,uP),e(uP,Lio),e(sh,xio),e(Z,$io),e(Z,lh),e(lh,yae),e(yae,kio),e(lh,Sio),e(lh,_P),e(_P,Rio),e(lh,Bio),e(Z,Pio),e(Z,ih),e(ih,Lae),e(Lae,Iio),e(ih,qio),e(ih,bP),e(bP,Nio),e(ih,jio),e(Z,Dio),e(Z,dh),e(dh,xae),e(xae,Gio),e(dh,Oio),e(dh,vP),e(vP,Vio),e(dh,Xio),e(Z,zio),e(Z,ch),e(ch,$ae),e($ae,Qio),e(ch,Wio),e(ch,FP),e(FP,Hio),e(ch,Uio),e(Z,Jio),e(Z,fh),e(fh,kae),e(kae,Yio),e(fh,Kio),e(fh,TP),e(TP,Zio),e(fh,edo),e(Z,odo),e(Z,mh),e(mh,Sae),e(Sae,rdo),e(mh,tdo),e(mh,MP),e(MP,ado),e(mh,ndo),e(Z,sdo),e(Z,gh),e(gh,Rae),e(Rae,ldo),e(gh,ido),e(gh,EP),e(EP,ddo),e(gh,cdo),e(Z,fdo),e(Z,hh),e(hh,Bae),e(Bae,mdo),e(hh,gdo),e(hh,CP),e(CP,hdo),e(hh,pdo),e(Z,udo),e(Z,ph),e(ph,Pae),e(Pae,_do),e(ph,bdo),e(ph,wP),e(wP,vdo),e(ph,Fdo),e(Z,Tdo),e(Z,uh),e(uh,Iae),e(Iae,Mdo),e(uh,Edo),e(uh,AP),e(AP,Cdo),e(uh,wdo),e(Z,Ado),e(Z,_h),e(_h,qae),e(qae,ydo),e(_h,Ldo),e(_h,yP),e(yP,xdo),e(_h,$do),e(Z,kdo),e(Z,bh),e(bh,Nae),e(Nae,Sdo),e(bh,Rdo),e(bh,LP),e(LP,Bdo),e(bh,Pdo),e(Z,Ido),e(Z,vh),e(vh,jae),e(jae,qdo),e(vh,Ndo),e(vh,xP),e(xP,jdo),e(vh,Ddo),e(Z,Gdo),e(Z,Fh),e(Fh,Dae),e(Dae,Odo),e(Fh,Vdo),e(Fh,$P),e($P,Xdo),e(Fh,zdo),e(Z,Qdo),e(Z,Th),e(Th,Gae),e(Gae,Wdo),e(Th,Hdo),e(Th,kP),e(kP,Udo),e(Th,Jdo),e(Z,Ydo),e(Z,Mh),e(Mh,Oae),e(Oae,Kdo),e(Mh,Zdo),e(Mh,SP),e(SP,eco),e(Mh,oco),e(Z,rco),e(Z,Eh),e(Eh,Vae),e(Vae,tco),e(Eh,aco),e(Eh,RP),e(RP,nco),e(Eh,sco),e(Z,lco),e(Z,Ch),e(Ch,Xae),e(Xae,ico),e(Ch,dco),e(Ch,BP),e(BP,cco),e(Ch,fco),e(Z,mco),e(Z,wh),e(wh,zae),e(zae,gco),e(wh,hco),e(wh,PP),e(PP,pco),e(wh,uco),e(Qe,_co),M(Ah,Qe,null),e(Qe,bco),M(yh,Qe,null),e(Ao,vco),e(Ao,Lh),M(CA,Lh,null),e(Lh,Fco),e(Lh,Qae),e(Qae,Tco),b(f,RIe,_),b(f,Fi,_),e(Fi,xh),e(xh,Wae),M(wA,Wae,null),e(Fi,Mco),e(Fi,Hae),e(Hae,Eco),b(f,BIe,_),b(f,yo,_),M(AA,yo,null),e(yo,Cco),e(yo,yA),e(yA,wco),e(yA,IP),e(IP,Aco),e(yA,yco),e(yo,Lco),e(yo,LA),e(LA,xco),e(LA,Uae),e(Uae,$co),e(LA,kco),e(yo,Sco),e(yo,We),M(xA,We,null),e(We,Rco),e(We,Jae),e(Jae,Bco),e(We,Pco),e(We,Ti),e(Ti,Ico),e(Ti,Yae),e(Yae,qco),e(Ti,Nco),e(Ti,Kae),e(Kae,jco),e(Ti,Dco),e(We,Gco),e(We,ue),e(ue,$h),e($h,Zae),e(Zae,Oco),e($h,Vco),e($h,qP),e(qP,Xco),e($h,zco),e(ue,Qco),e(ue,kh),e(kh,ene),e(ene,Wco),e(kh,Hco),e(kh,one),e(one,Uco),e(kh,Jco),e(ue,Yco),e(ue,Sh),e(Sh,rne),e(rne,Kco),e(Sh,Zco),e(Sh,NP),e(NP,efo),e(Sh,ofo),e(ue,rfo),e(ue,Rh),e(Rh,tne),e(tne,tfo),e(Rh,afo),e(Rh,jP),e(jP,nfo),e(Rh,sfo),e(ue,lfo),e(ue,Bh),e(Bh,ane),e(ane,ifo),e(Bh,dfo),e(Bh,DP),e(DP,cfo),e(Bh,ffo),e(ue,mfo),e(ue,Ph),e(Ph,nne),e(nne,gfo),e(Ph,hfo),e(Ph,GP),e(GP,pfo),e(Ph,ufo),e(ue,_fo),e(ue,Ih),e(Ih,sne),e(sne,bfo),e(Ih,vfo),e(Ih,OP),e(OP,Ffo),e(Ih,Tfo),e(ue,Mfo),e(ue,qh),e(qh,lne),e(lne,Efo),e(qh,Cfo),e(qh,VP),e(VP,wfo),e(qh,Afo),e(ue,yfo),e(ue,Nh),e(Nh,ine),e(ine,Lfo),e(Nh,xfo),e(Nh,XP),e(XP,$fo),e(Nh,kfo),e(ue,Sfo),e(ue,jh),e(jh,dne),e(dne,Rfo),e(jh,Bfo),e(jh,zP),e(zP,Pfo),e(jh,Ifo),e(ue,qfo),e(ue,Dh),e(Dh,cne),e(cne,Nfo),e(Dh,jfo),e(Dh,QP),e(QP,Dfo),e(Dh,Gfo),e(ue,Ofo),e(ue,Gh),e(Gh,fne),e(fne,Vfo),e(Gh,Xfo),e(Gh,WP),e(WP,zfo),e(Gh,Qfo),e(ue,Wfo),e(ue,Oh),e(Oh,mne),e(mne,Hfo),e(Oh,Ufo),e(Oh,HP),e(HP,Jfo),e(Oh,Yfo),e(ue,Kfo),e(ue,Vh),e(Vh,gne),e(gne,Zfo),e(Vh,emo),e(Vh,UP),e(UP,omo),e(Vh,rmo),e(ue,tmo),e(ue,Xh),e(Xh,hne),e(hne,amo),e(Xh,nmo),e(Xh,JP),e(JP,smo),e(Xh,lmo),e(ue,imo),e(ue,zh),e(zh,pne),e(pne,dmo),e(zh,cmo),e(zh,YP),e(YP,fmo),e(zh,mmo),e(We,gmo),M(Qh,We,null),e(We,hmo),M(Wh,We,null),e(yo,pmo),e(yo,Hh),M($A,Hh,null),e(Hh,umo),e(Hh,une),e(une,_mo),b(f,PIe,_),b(f,Mi,_),e(Mi,Uh),e(Uh,_ne),M(kA,_ne,null),e(Mi,bmo),e(Mi,bne),e(bne,vmo),b(f,IIe,_),b(f,Lo,_),M(SA,Lo,null),e(Lo,Fmo),e(Lo,Ei),e(Ei,Tmo),e(Ei,KP),e(KP,Mmo),e(Ei,Emo),e(Ei,ZP),e(ZP,Cmo),e(Ei,wmo),e(Lo,Amo),e(Lo,RA),e(RA,ymo),e(RA,vne),e(vne,Lmo),e(RA,xmo),e(Lo,$mo),e(Lo,ot),M(BA,ot,null),e(ot,kmo),e(ot,Fne),e(Fne,Smo),e(ot,Rmo),e(ot,Ci),e(Ci,Bmo),e(Ci,Tne),e(Tne,Pmo),e(Ci,Imo),e(Ci,eI),e(eI,qmo),e(Ci,Nmo),e(ot,jmo),M(Jh,ot,null),e(Lo,Dmo),e(Lo,He),M(PA,He,null),e(He,Gmo),e(He,Mne),e(Mne,Omo),e(He,Vmo),e(He,Aa),e(Aa,Xmo),e(Aa,Ene),e(Ene,zmo),e(Aa,Qmo),e(Aa,Cne),e(Cne,Wmo),e(Aa,Hmo),e(Aa,wne),e(wne,Umo),e(Aa,Jmo),e(He,Ymo),e(He,x),e(x,Yh),e(Yh,Ane),e(Ane,Kmo),e(Yh,Zmo),e(Yh,oI),e(oI,ego),e(Yh,ogo),e(x,rgo),e(x,Kh),e(Kh,yne),e(yne,tgo),e(Kh,ago),e(Kh,rI),e(rI,ngo),e(Kh,sgo),e(x,lgo),e(x,Zh),e(Zh,Lne),e(Lne,igo),e(Zh,dgo),e(Zh,tI),e(tI,cgo),e(Zh,fgo),e(x,mgo),e(x,ep),e(ep,xne),e(xne,ggo),e(ep,hgo),e(ep,aI),e(aI,pgo),e(ep,ugo),e(x,_go),e(x,op),e(op,$ne),e($ne,bgo),e(op,vgo),e(op,nI),e(nI,Fgo),e(op,Tgo),e(x,Mgo),e(x,rp),e(rp,kne),e(kne,Ego),e(rp,Cgo),e(rp,sI),e(sI,wgo),e(rp,Ago),e(x,ygo),e(x,tp),e(tp,Sne),e(Sne,Lgo),e(tp,xgo),e(tp,lI),e(lI,$go),e(tp,kgo),e(x,Sgo),e(x,ap),e(ap,Rne),e(Rne,Rgo),e(ap,Bgo),e(ap,iI),e(iI,Pgo),e(ap,Igo),e(x,qgo),e(x,np),e(np,Bne),e(Bne,Ngo),e(np,jgo),e(np,dI),e(dI,Dgo),e(np,Ggo),e(x,Ogo),e(x,sp),e(sp,Pne),e(Pne,Vgo),e(sp,Xgo),e(sp,cI),e(cI,zgo),e(sp,Qgo),e(x,Wgo),e(x,lp),e(lp,Ine),e(Ine,Hgo),e(lp,Ugo),e(lp,fI),e(fI,Jgo),e(lp,Ygo),e(x,Kgo),e(x,ip),e(ip,qne),e(qne,Zgo),e(ip,eho),e(ip,mI),e(mI,oho),e(ip,rho),e(x,tho),e(x,dp),e(dp,Nne),e(Nne,aho),e(dp,nho),e(dp,gI),e(gI,sho),e(dp,lho),e(x,iho),e(x,cp),e(cp,jne),e(jne,dho),e(cp,cho),e(cp,hI),e(hI,fho),e(cp,mho),e(x,gho),e(x,fp),e(fp,Dne),e(Dne,hho),e(fp,pho),e(fp,pI),e(pI,uho),e(fp,_ho),e(x,bho),e(x,mp),e(mp,Gne),e(Gne,vho),e(mp,Fho),e(mp,uI),e(uI,Tho),e(mp,Mho),e(x,Eho),e(x,gp),e(gp,One),e(One,Cho),e(gp,who),e(gp,_I),e(_I,Aho),e(gp,yho),e(x,Lho),e(x,hp),e(hp,Vne),e(Vne,xho),e(hp,$ho),e(hp,bI),e(bI,kho),e(hp,Sho),e(x,Rho),e(x,pp),e(pp,Xne),e(Xne,Bho),e(pp,Pho),e(pp,vI),e(vI,Iho),e(pp,qho),e(x,Nho),e(x,up),e(up,zne),e(zne,jho),e(up,Dho),e(up,FI),e(FI,Gho),e(up,Oho),e(x,Vho),e(x,_p),e(_p,Qne),e(Qne,Xho),e(_p,zho),e(_p,TI),e(TI,Qho),e(_p,Who),e(x,Hho),e(x,bp),e(bp,Wne),e(Wne,Uho),e(bp,Jho),e(bp,MI),e(MI,Yho),e(bp,Kho),e(x,Zho),e(x,vp),e(vp,Hne),e(Hne,epo),e(vp,opo),e(vp,EI),e(EI,rpo),e(vp,tpo),e(x,apo),e(x,Fp),e(Fp,Une),e(Une,npo),e(Fp,spo),e(Fp,CI),e(CI,lpo),e(Fp,ipo),e(x,dpo),e(x,Tp),e(Tp,Jne),e(Jne,cpo),e(Tp,fpo),e(Tp,wI),e(wI,mpo),e(Tp,gpo),e(x,hpo),e(x,Mp),e(Mp,Yne),e(Yne,ppo),e(Mp,upo),e(Mp,AI),e(AI,_po),e(Mp,bpo),e(x,vpo),e(x,Ep),e(Ep,Kne),e(Kne,Fpo),e(Ep,Tpo),e(Ep,yI),e(yI,Mpo),e(Ep,Epo),e(x,Cpo),e(x,Cp),e(Cp,Zne),e(Zne,wpo),e(Cp,Apo),e(Cp,LI),e(LI,ypo),e(Cp,Lpo),e(x,xpo),e(x,wp),e(wp,ese),e(ese,$po),e(wp,kpo),e(wp,xI),e(xI,Spo),e(wp,Rpo),e(x,Bpo),e(x,Ap),e(Ap,ose),e(ose,Ppo),e(Ap,Ipo),e(Ap,$I),e($I,qpo),e(Ap,Npo),e(x,jpo),e(x,yp),e(yp,rse),e(rse,Dpo),e(yp,Gpo),e(yp,kI),e(kI,Opo),e(yp,Vpo),e(x,Xpo),e(x,Rs),e(Rs,tse),e(tse,zpo),e(Rs,Qpo),e(Rs,SI),e(SI,Wpo),e(Rs,Hpo),e(Rs,RI),e(RI,Upo),e(Rs,Jpo),e(x,Ypo),e(x,Lp),e(Lp,ase),e(ase,Kpo),e(Lp,Zpo),e(Lp,BI),e(BI,euo),e(Lp,ouo),e(x,ruo),e(x,xp),e(xp,nse),e(nse,tuo),e(xp,auo),e(xp,PI),e(PI,nuo),e(xp,suo),e(x,luo),e(x,$p),e($p,sse),e(sse,iuo),e($p,duo),e($p,II),e(II,cuo),e($p,fuo),e(x,muo),e(x,kp),e(kp,lse),e(lse,guo),e(kp,huo),e(kp,qI),e(qI,puo),e(kp,uuo),e(x,_uo),e(x,Sp),e(Sp,ise),e(ise,buo),e(Sp,vuo),e(Sp,NI),e(NI,Fuo),e(Sp,Tuo),e(x,Muo),e(x,Rp),e(Rp,dse),e(dse,Euo),e(Rp,Cuo),e(Rp,jI),e(jI,wuo),e(Rp,Auo),e(x,yuo),e(x,Bp),e(Bp,cse),e(cse,Luo),e(Bp,xuo),e(Bp,DI),e(DI,$uo),e(Bp,kuo),e(x,Suo),e(x,Pp),e(Pp,fse),e(fse,Ruo),e(Pp,Buo),e(Pp,GI),e(GI,Puo),e(Pp,Iuo),e(x,quo),e(x,Ip),e(Ip,mse),e(mse,Nuo),e(Ip,juo),e(Ip,OI),e(OI,Duo),e(Ip,Guo),e(x,Ouo),e(x,qp),e(qp,gse),e(gse,Vuo),e(qp,Xuo),e(qp,VI),e(VI,zuo),e(qp,Quo),e(x,Wuo),e(x,Np),e(Np,hse),e(hse,Huo),e(Np,Uuo),e(Np,XI),e(XI,Juo),e(Np,Yuo),e(x,Kuo),e(x,jp),e(jp,pse),e(pse,Zuo),e(jp,e_o),e(jp,zI),e(zI,o_o),e(jp,r_o),e(x,t_o),e(x,Dp),e(Dp,use),e(use,a_o),e(Dp,n_o),e(Dp,QI),e(QI,s_o),e(Dp,l_o),e(x,i_o),e(x,Gp),e(Gp,_se),e(_se,d_o),e(Gp,c_o),e(Gp,WI),e(WI,f_o),e(Gp,m_o),e(x,g_o),e(x,Op),e(Op,bse),e(bse,h_o),e(Op,p_o),e(Op,HI),e(HI,u_o),e(Op,__o),e(x,b_o),e(x,Vp),e(Vp,vse),e(vse,v_o),e(Vp,F_o),e(Vp,UI),e(UI,T_o),e(Vp,M_o),e(x,E_o),e(x,Xp),e(Xp,Fse),e(Fse,C_o),e(Xp,w_o),e(Xp,JI),e(JI,A_o),e(Xp,y_o),e(x,L_o),e(x,zp),e(zp,Tse),e(Tse,x_o),e(zp,$_o),e(zp,YI),e(YI,k_o),e(zp,S_o),e(x,R_o),e(x,Qp),e(Qp,Mse),e(Mse,B_o),e(Qp,P_o),e(Qp,KI),e(KI,I_o),e(Qp,q_o),e(x,N_o),e(x,Wp),e(Wp,Ese),e(Ese,j_o),e(Wp,D_o),e(Wp,ZI),e(ZI,G_o),e(Wp,O_o),e(x,V_o),e(x,Hp),e(Hp,Cse),e(Cse,X_o),e(Hp,z_o),e(Hp,eq),e(eq,Q_o),e(Hp,W_o),e(x,H_o),e(x,Up),e(Up,wse),e(wse,U_o),e(Up,J_o),e(Up,oq),e(oq,Y_o),e(Up,K_o),e(x,Z_o),e(x,Jp),e(Jp,Ase),e(Ase,e0o),e(Jp,o0o),e(Jp,rq),e(rq,r0o),e(Jp,t0o),e(x,a0o),e(x,Yp),e(Yp,yse),e(yse,n0o),e(Yp,s0o),e(Yp,tq),e(tq,l0o),e(Yp,i0o),e(x,d0o),e(x,Kp),e(Kp,Lse),e(Lse,c0o),e(Kp,f0o),e(Kp,aq),e(aq,m0o),e(Kp,g0o),e(x,h0o),e(x,Zp),e(Zp,xse),e(xse,p0o),e(Zp,u0o),e(Zp,nq),e(nq,_0o),e(Zp,b0o),e(x,v0o),e(x,eu),e(eu,$se),e($se,F0o),e(eu,T0o),e(eu,sq),e(sq,M0o),e(eu,E0o),e(x,C0o),e(x,ou),e(ou,kse),e(kse,w0o),e(ou,A0o),e(ou,lq),e(lq,y0o),e(ou,L0o),e(x,x0o),e(x,ru),e(ru,Sse),e(Sse,$0o),e(ru,k0o),e(ru,iq),e(iq,S0o),e(ru,R0o),e(x,B0o),e(x,tu),e(tu,Rse),e(Rse,P0o),e(tu,I0o),e(tu,dq),e(dq,q0o),e(tu,N0o),e(x,j0o),e(x,au),e(au,Bse),e(Bse,D0o),e(au,G0o),e(au,cq),e(cq,O0o),e(au,V0o),e(x,X0o),e(x,nu),e(nu,Pse),e(Pse,z0o),e(nu,Q0o),e(nu,fq),e(fq,W0o),e(nu,H0o),e(x,U0o),e(x,su),e(su,Ise),e(Ise,J0o),e(su,Y0o),e(su,mq),e(mq,K0o),e(su,Z0o),e(x,e1o),e(x,lu),e(lu,qse),e(qse,o1o),e(lu,r1o),e(lu,gq),e(gq,t1o),e(lu,a1o),e(x,n1o),e(x,iu),e(iu,Nse),e(Nse,s1o),e(iu,l1o),e(iu,hq),e(hq,i1o),e(iu,d1o),e(x,c1o),e(x,du),e(du,jse),e(jse,f1o),e(du,m1o),e(du,pq),e(pq,g1o),e(du,h1o),e(x,p1o),e(x,cu),e(cu,Dse),e(Dse,u1o),e(cu,_1o),e(cu,uq),e(uq,b1o),e(cu,v1o),e(x,F1o),e(x,fu),e(fu,Gse),e(Gse,T1o),e(fu,M1o),e(fu,_q),e(_q,E1o),e(fu,C1o),e(x,w1o),e(x,mu),e(mu,Ose),e(Ose,A1o),e(mu,y1o),e(mu,bq),e(bq,L1o),e(mu,x1o),e(x,$1o),e(x,gu),e(gu,Vse),e(Vse,k1o),e(gu,S1o),e(gu,vq),e(vq,R1o),e(gu,B1o),e(x,P1o),e(x,hu),e(hu,Xse),e(Xse,I1o),e(hu,q1o),e(hu,Fq),e(Fq,N1o),e(hu,j1o),e(x,D1o),e(x,pu),e(pu,zse),e(zse,G1o),e(pu,O1o),e(pu,Tq),e(Tq,V1o),e(pu,X1o),e(x,z1o),e(x,uu),e(uu,Qse),e(Qse,Q1o),e(uu,W1o),e(uu,Mq),e(Mq,H1o),e(uu,U1o),e(x,J1o),e(x,_u),e(_u,Wse),e(Wse,Y1o),e(_u,K1o),e(_u,Eq),e(Eq,Z1o),e(_u,ebo),e(x,obo),e(x,bu),e(bu,Hse),e(Hse,rbo),e(bu,tbo),e(bu,Cq),e(Cq,abo),e(bu,nbo),e(x,sbo),e(x,vu),e(vu,Use),e(Use,lbo),e(vu,ibo),e(vu,wq),e(wq,dbo),e(vu,cbo),e(x,fbo),e(x,Fu),e(Fu,Jse),e(Jse,mbo),e(Fu,gbo),e(Fu,Aq),e(Aq,hbo),e(Fu,pbo),e(x,ubo),e(x,Tu),e(Tu,Yse),e(Yse,_bo),e(Tu,bbo),e(Tu,yq),e(yq,vbo),e(Tu,Fbo),e(x,Tbo),e(x,Mu),e(Mu,Kse),e(Kse,Mbo),e(Mu,Ebo),e(Mu,Lq),e(Lq,Cbo),e(Mu,wbo),e(x,Abo),e(x,Eu),e(Eu,Zse),e(Zse,ybo),e(Eu,Lbo),e(Eu,xq),e(xq,xbo),e(Eu,$bo),e(x,kbo),e(x,Cu),e(Cu,ele),e(ele,Sbo),e(Cu,Rbo),e(Cu,$q),e($q,Bbo),e(Cu,Pbo),e(x,Ibo),e(x,wu),e(wu,ole),e(ole,qbo),e(wu,Nbo),e(wu,kq),e(kq,jbo),e(wu,Dbo),e(x,Gbo),e(x,Au),e(Au,rle),e(rle,Obo),e(Au,Vbo),e(Au,Sq),e(Sq,Xbo),e(Au,zbo),e(x,Qbo),e(x,yu),e(yu,tle),e(tle,Wbo),e(yu,Hbo),e(yu,Rq),e(Rq,Ubo),e(yu,Jbo),e(x,Ybo),e(x,Lu),e(Lu,ale),e(ale,Kbo),e(Lu,Zbo),e(Lu,Bq),e(Bq,e2o),e(Lu,o2o),e(x,r2o),e(x,xu),e(xu,nle),e(nle,t2o),e(xu,a2o),e(xu,Pq),e(Pq,n2o),e(xu,s2o),e(x,l2o),e(x,$u),e($u,sle),e(sle,i2o),e($u,d2o),e($u,Iq),e(Iq,c2o),e($u,f2o),e(x,m2o),e(x,ku),e(ku,lle),e(lle,g2o),e(ku,h2o),e(ku,qq),e(qq,p2o),e(ku,u2o),e(x,_2o),e(x,Su),e(Su,ile),e(ile,b2o),e(Su,v2o),e(Su,Nq),e(Nq,F2o),e(Su,T2o),e(x,M2o),e(x,Ru),e(Ru,dle),e(dle,E2o),e(Ru,C2o),e(Ru,jq),e(jq,w2o),e(Ru,A2o),e(x,y2o),e(x,Bu),e(Bu,cle),e(cle,L2o),e(Bu,x2o),e(Bu,Dq),e(Dq,$2o),e(Bu,k2o),e(x,S2o),e(x,Pu),e(Pu,fle),e(fle,R2o),e(Pu,B2o),e(Pu,Gq),e(Gq,P2o),e(Pu,I2o),e(x,q2o),e(x,Iu),e(Iu,mle),e(mle,N2o),e(Iu,j2o),e(Iu,Oq),e(Oq,D2o),e(Iu,G2o),e(x,O2o),e(x,qu),e(qu,gle),e(gle,V2o),e(qu,X2o),e(qu,Vq),e(Vq,z2o),e(qu,Q2o),e(x,W2o),e(x,Nu),e(Nu,hle),e(hle,H2o),e(Nu,U2o),e(Nu,Xq),e(Xq,J2o),e(Nu,Y2o),e(x,K2o),e(x,ju),e(ju,ple),e(ple,Z2o),e(ju,evo),e(ju,zq),e(zq,ovo),e(ju,rvo),e(He,tvo),e(He,Du),e(Du,avo),e(Du,ule),e(ule,nvo),e(Du,svo),e(Du,_le),e(_le,lvo),e(He,ivo),M(Gu,He,null),b(f,qIe,_),b(f,wi,_),e(wi,Ou),e(Ou,ble),M(IA,ble,null),e(wi,dvo),e(wi,vle),e(vle,cvo),b(f,NIe,_),b(f,xo,_),M(qA,xo,null),e(xo,fvo),e(xo,Ai),e(Ai,mvo),e(Ai,Qq),e(Qq,gvo),e(Ai,hvo),e(Ai,Wq),e(Wq,pvo),e(Ai,uvo),e(xo,_vo),e(xo,NA),e(NA,bvo),e(NA,Fle),e(Fle,vvo),e(NA,Fvo),e(xo,Tvo),e(xo,rt),M(jA,rt,null),e(rt,Mvo),e(rt,Tle),e(Tle,Evo),e(rt,Cvo),e(rt,yi),e(yi,wvo),e(yi,Mle),e(Mle,Avo),e(yi,yvo),e(yi,Hq),e(Hq,Lvo),e(yi,xvo),e(rt,$vo),M(Vu,rt,null),e(xo,kvo),e(xo,Ue),M(DA,Ue,null),e(Ue,Svo),e(Ue,Ele),e(Ele,Rvo),e(Ue,Bvo),e(Ue,ya),e(ya,Pvo),e(ya,Cle),e(Cle,Ivo),e(ya,qvo),e(ya,wle),e(wle,Nvo),e(ya,jvo),e(ya,Ale),e(Ale,Dvo),e(ya,Gvo),e(Ue,Ovo),e(Ue,G),e(G,Xu),e(Xu,yle),e(yle,Vvo),e(Xu,Xvo),e(Xu,Uq),e(Uq,zvo),e(Xu,Qvo),e(G,Wvo),e(G,zu),e(zu,Lle),e(Lle,Hvo),e(zu,Uvo),e(zu,Jq),e(Jq,Jvo),e(zu,Yvo),e(G,Kvo),e(G,Qu),e(Qu,xle),e(xle,Zvo),e(Qu,eFo),e(Qu,Yq),e(Yq,oFo),e(Qu,rFo),e(G,tFo),e(G,Wu),e(Wu,$le),e($le,aFo),e(Wu,nFo),e(Wu,Kq),e(Kq,sFo),e(Wu,lFo),e(G,iFo),e(G,Hu),e(Hu,kle),e(kle,dFo),e(Hu,cFo),e(Hu,Zq),e(Zq,fFo),e(Hu,mFo),e(G,gFo),e(G,Uu),e(Uu,Sle),e(Sle,hFo),e(Uu,pFo),e(Uu,eN),e(eN,uFo),e(Uu,_Fo),e(G,bFo),e(G,Ju),e(Ju,Rle),e(Rle,vFo),e(Ju,FFo),e(Ju,oN),e(oN,TFo),e(Ju,MFo),e(G,EFo),e(G,Yu),e(Yu,Ble),e(Ble,CFo),e(Yu,wFo),e(Yu,rN),e(rN,AFo),e(Yu,yFo),e(G,LFo),e(G,Ku),e(Ku,Ple),e(Ple,xFo),e(Ku,$Fo),e(Ku,tN),e(tN,kFo),e(Ku,SFo),e(G,RFo),e(G,Zu),e(Zu,Ile),e(Ile,BFo),e(Zu,PFo),e(Zu,aN),e(aN,IFo),e(Zu,qFo),e(G,NFo),e(G,e_),e(e_,qle),e(qle,jFo),e(e_,DFo),e(e_,nN),e(nN,GFo),e(e_,OFo),e(G,VFo),e(G,o_),e(o_,Nle),e(Nle,XFo),e(o_,zFo),e(o_,sN),e(sN,QFo),e(o_,WFo),e(G,HFo),e(G,r_),e(r_,jle),e(jle,UFo),e(r_,JFo),e(r_,lN),e(lN,YFo),e(r_,KFo),e(G,ZFo),e(G,t_),e(t_,Dle),e(Dle,e6o),e(t_,o6o),e(t_,iN),e(iN,r6o),e(t_,t6o),e(G,a6o),e(G,a_),e(a_,Gle),e(Gle,n6o),e(a_,s6o),e(a_,dN),e(dN,l6o),e(a_,i6o),e(G,d6o),e(G,n_),e(n_,Ole),e(Ole,c6o),e(n_,f6o),e(n_,cN),e(cN,m6o),e(n_,g6o),e(G,h6o),e(G,s_),e(s_,Vle),e(Vle,p6o),e(s_,u6o),e(s_,fN),e(fN,_6o),e(s_,b6o),e(G,v6o),e(G,l_),e(l_,Xle),e(Xle,F6o),e(l_,T6o),e(l_,mN),e(mN,M6o),e(l_,E6o),e(G,C6o),e(G,i_),e(i_,zle),e(zle,w6o),e(i_,A6o),e(i_,gN),e(gN,y6o),e(i_,L6o),e(G,x6o),e(G,d_),e(d_,Qle),e(Qle,$6o),e(d_,k6o),e(d_,hN),e(hN,S6o),e(d_,R6o),e(G,B6o),e(G,c_),e(c_,Wle),e(Wle,P6o),e(c_,I6o),e(c_,pN),e(pN,q6o),e(c_,N6o),e(G,j6o),e(G,f_),e(f_,Hle),e(Hle,D6o),e(f_,G6o),e(f_,uN),e(uN,O6o),e(f_,V6o),e(G,X6o),e(G,m_),e(m_,Ule),e(Ule,z6o),e(m_,Q6o),e(m_,_N),e(_N,W6o),e(m_,H6o),e(G,U6o),e(G,g_),e(g_,Jle),e(Jle,J6o),e(g_,Y6o),e(g_,bN),e(bN,K6o),e(g_,Z6o),e(G,eTo),e(G,h_),e(h_,Yle),e(Yle,oTo),e(h_,rTo),e(h_,vN),e(vN,tTo),e(h_,aTo),e(G,nTo),e(G,p_),e(p_,Kle),e(Kle,sTo),e(p_,lTo),e(p_,FN),e(FN,iTo),e(p_,dTo),e(G,cTo),e(G,u_),e(u_,Zle),e(Zle,fTo),e(u_,mTo),e(u_,TN),e(TN,gTo),e(u_,hTo),e(G,pTo),e(G,__),e(__,eie),e(eie,uTo),e(__,_To),e(__,MN),e(MN,bTo),e(__,vTo),e(G,FTo),e(G,b_),e(b_,oie),e(oie,TTo),e(b_,MTo),e(b_,EN),e(EN,ETo),e(b_,CTo),e(G,wTo),e(G,v_),e(v_,rie),e(rie,ATo),e(v_,yTo),e(v_,CN),e(CN,LTo),e(v_,xTo),e(G,$To),e(G,F_),e(F_,tie),e(tie,kTo),e(F_,STo),e(F_,wN),e(wN,RTo),e(F_,BTo),e(G,PTo),e(G,T_),e(T_,aie),e(aie,ITo),e(T_,qTo),e(T_,AN),e(AN,NTo),e(T_,jTo),e(G,DTo),e(G,M_),e(M_,nie),e(nie,GTo),e(M_,OTo),e(M_,yN),e(yN,VTo),e(M_,XTo),e(G,zTo),e(G,E_),e(E_,sie),e(sie,QTo),e(E_,WTo),e(E_,LN),e(LN,HTo),e(E_,UTo),e(G,JTo),e(G,C_),e(C_,lie),e(lie,YTo),e(C_,KTo),e(C_,xN),e(xN,ZTo),e(C_,e7o),e(G,o7o),e(G,w_),e(w_,iie),e(iie,r7o),e(w_,t7o),e(w_,$N),e($N,a7o),e(w_,n7o),e(G,s7o),e(G,A_),e(A_,die),e(die,l7o),e(A_,i7o),e(A_,kN),e(kN,d7o),e(A_,c7o),e(G,f7o),e(G,y_),e(y_,cie),e(cie,m7o),e(y_,g7o),e(y_,SN),e(SN,h7o),e(y_,p7o),e(G,u7o),e(G,L_),e(L_,fie),e(fie,_7o),e(L_,b7o),e(L_,RN),e(RN,v7o),e(L_,F7o),e(G,T7o),e(G,x_),e(x_,mie),e(mie,M7o),e(x_,E7o),e(x_,BN),e(BN,C7o),e(x_,w7o),e(Ue,A7o),e(Ue,$_),e($_,y7o),e($_,gie),e(gie,L7o),e($_,x7o),e($_,hie),e(hie,$7o),e(Ue,k7o),M(k_,Ue,null),b(f,jIe,_),b(f,Li,_),e(Li,S_),e(S_,pie),M(GA,pie,null),e(Li,S7o),e(Li,uie),e(uie,R7o),b(f,DIe,_),b(f,$o,_),M(OA,$o,null),e($o,B7o),e($o,xi),e(xi,P7o),e(xi,PN),e(PN,I7o),e(xi,q7o),e(xi,IN),e(IN,N7o),e(xi,j7o),e($o,D7o),e($o,VA),e(VA,G7o),e(VA,_ie),e(_ie,O7o),e(VA,V7o),e($o,X7o),e($o,tt),M(XA,tt,null),e(tt,z7o),e(tt,bie),e(bie,Q7o),e(tt,W7o),e(tt,$i),e($i,H7o),e($i,vie),e(vie,U7o),e($i,J7o),e($i,qN),e(qN,Y7o),e($i,K7o),e(tt,Z7o),M(R_,tt,null),e($o,eMo),e($o,Je),M(zA,Je,null),e(Je,oMo),e(Je,Fie),e(Fie,rMo),e(Je,tMo),e(Je,La),e(La,aMo),e(La,Tie),e(Tie,nMo),e(La,sMo),e(La,Mie),e(Mie,lMo),e(La,iMo),e(La,Eie),e(Eie,dMo),e(La,cMo),e(Je,fMo),e(Je,z),e(z,B_),e(B_,Cie),e(Cie,mMo),e(B_,gMo),e(B_,NN),e(NN,hMo),e(B_,pMo),e(z,uMo),e(z,P_),e(P_,wie),e(wie,_Mo),e(P_,bMo),e(P_,jN),e(jN,vMo),e(P_,FMo),e(z,TMo),e(z,I_),e(I_,Aie),e(Aie,MMo),e(I_,EMo),e(I_,DN),e(DN,CMo),e(I_,wMo),e(z,AMo),e(z,q_),e(q_,yie),e(yie,yMo),e(q_,LMo),e(q_,GN),e(GN,xMo),e(q_,$Mo),e(z,kMo),e(z,N_),e(N_,Lie),e(Lie,SMo),e(N_,RMo),e(N_,ON),e(ON,BMo),e(N_,PMo),e(z,IMo),e(z,j_),e(j_,xie),e(xie,qMo),e(j_,NMo),e(j_,VN),e(VN,jMo),e(j_,DMo),e(z,GMo),e(z,D_),e(D_,$ie),e($ie,OMo),e(D_,VMo),e(D_,XN),e(XN,XMo),e(D_,zMo),e(z,QMo),e(z,G_),e(G_,kie),e(kie,WMo),e(G_,HMo),e(G_,zN),e(zN,UMo),e(G_,JMo),e(z,YMo),e(z,O_),e(O_,Sie),e(Sie,KMo),e(O_,ZMo),e(O_,QN),e(QN,e4o),e(O_,o4o),e(z,r4o),e(z,V_),e(V_,Rie),e(Rie,t4o),e(V_,a4o),e(V_,WN),e(WN,n4o),e(V_,s4o),e(z,l4o),e(z,X_),e(X_,Bie),e(Bie,i4o),e(X_,d4o),e(X_,HN),e(HN,c4o),e(X_,f4o),e(z,m4o),e(z,z_),e(z_,Pie),e(Pie,g4o),e(z_,h4o),e(z_,UN),e(UN,p4o),e(z_,u4o),e(z,_4o),e(z,Q_),e(Q_,Iie),e(Iie,b4o),e(Q_,v4o),e(Q_,JN),e(JN,F4o),e(Q_,T4o),e(z,M4o),e(z,W_),e(W_,qie),e(qie,E4o),e(W_,C4o),e(W_,YN),e(YN,w4o),e(W_,A4o),e(z,y4o),e(z,H_),e(H_,Nie),e(Nie,L4o),e(H_,x4o),e(H_,KN),e(KN,$4o),e(H_,k4o),e(z,S4o),e(z,U_),e(U_,jie),e(jie,R4o),e(U_,B4o),e(U_,ZN),e(ZN,P4o),e(U_,I4o),e(z,q4o),e(z,J_),e(J_,Die),e(Die,N4o),e(J_,j4o),e(J_,ej),e(ej,D4o),e(J_,G4o),e(z,O4o),e(z,Y_),e(Y_,Gie),e(Gie,V4o),e(Y_,X4o),e(Y_,oj),e(oj,z4o),e(Y_,Q4o),e(z,W4o),e(z,K_),e(K_,Oie),e(Oie,H4o),e(K_,U4o),e(K_,rj),e(rj,J4o),e(K_,Y4o),e(z,K4o),e(z,Z_),e(Z_,Vie),e(Vie,Z4o),e(Z_,eEo),e(Z_,tj),e(tj,oEo),e(Z_,rEo),e(z,tEo),e(z,e0),e(e0,Xie),e(Xie,aEo),e(e0,nEo),e(e0,aj),e(aj,sEo),e(e0,lEo),e(z,iEo),e(z,o0),e(o0,zie),e(zie,dEo),e(o0,cEo),e(o0,nj),e(nj,fEo),e(o0,mEo),e(z,gEo),e(z,r0),e(r0,Qie),e(Qie,hEo),e(r0,pEo),e(r0,sj),e(sj,uEo),e(r0,_Eo),e(z,bEo),e(z,t0),e(t0,Wie),e(Wie,vEo),e(t0,FEo),e(t0,lj),e(lj,TEo),e(t0,MEo),e(z,EEo),e(z,a0),e(a0,Hie),e(Hie,CEo),e(a0,wEo),e(a0,ij),e(ij,AEo),e(a0,yEo),e(z,LEo),e(z,n0),e(n0,Uie),e(Uie,xEo),e(n0,$Eo),e(n0,dj),e(dj,kEo),e(n0,SEo),e(z,REo),e(z,s0),e(s0,Jie),e(Jie,BEo),e(s0,PEo),e(s0,cj),e(cj,IEo),e(s0,qEo),e(z,NEo),e(z,l0),e(l0,Yie),e(Yie,jEo),e(l0,DEo),e(l0,fj),e(fj,GEo),e(l0,OEo),e(z,VEo),e(z,i0),e(i0,Kie),e(Kie,XEo),e(i0,zEo),e(i0,mj),e(mj,QEo),e(i0,WEo),e(z,HEo),e(z,d0),e(d0,Zie),e(Zie,UEo),e(d0,JEo),e(d0,gj),e(gj,YEo),e(d0,KEo),e(z,ZEo),e(z,c0),e(c0,ede),e(ede,e5o),e(c0,o5o),e(c0,hj),e(hj,r5o),e(c0,t5o),e(z,a5o),e(z,f0),e(f0,ode),e(ode,n5o),e(f0,s5o),e(f0,pj),e(pj,l5o),e(f0,i5o),e(z,d5o),e(z,m0),e(m0,rde),e(rde,c5o),e(m0,f5o),e(m0,uj),e(uj,m5o),e(m0,g5o),e(z,h5o),e(z,g0),e(g0,tde),e(tde,p5o),e(g0,u5o),e(g0,_j),e(_j,_5o),e(g0,b5o),e(z,v5o),e(z,h0),e(h0,ade),e(ade,F5o),e(h0,T5o),e(h0,bj),e(bj,M5o),e(h0,E5o),e(z,C5o),e(z,p0),e(p0,nde),e(nde,w5o),e(p0,A5o),e(p0,vj),e(vj,y5o),e(p0,L5o),e(Je,x5o),e(Je,u0),e(u0,$5o),e(u0,sde),e(sde,k5o),e(u0,S5o),e(u0,lde),e(lde,R5o),e(Je,B5o),M(_0,Je,null),b(f,GIe,_),b(f,ki,_),e(ki,b0),e(b0,ide),M(QA,ide,null),e(ki,P5o),e(ki,dde),e(dde,I5o),b(f,OIe,_),b(f,ko,_),M(WA,ko,null),e(ko,q5o),e(ko,Si),e(Si,N5o),e(Si,Fj),e(Fj,j5o),e(Si,D5o),e(Si,Tj),e(Tj,G5o),e(Si,O5o),e(ko,V5o),e(ko,HA),e(HA,X5o),e(HA,cde),e(cde,z5o),e(HA,Q5o),e(ko,W5o),e(ko,at),M(UA,at,null),e(at,H5o),e(at,fde),e(fde,U5o),e(at,J5o),e(at,Ri),e(Ri,Y5o),e(Ri,mde),e(mde,K5o),e(Ri,Z5o),e(Ri,Mj),e(Mj,eCo),e(Ri,oCo),e(at,rCo),M(v0,at,null),e(ko,tCo),e(ko,Ye),M(JA,Ye,null),e(Ye,aCo),e(Ye,gde),e(gde,nCo),e(Ye,sCo),e(Ye,xa),e(xa,lCo),e(xa,hde),e(hde,iCo),e(xa,dCo),e(xa,pde),e(pde,cCo),e(xa,fCo),e(xa,ude),e(ude,mCo),e(xa,gCo),e(Ye,hCo),e(Ye,Q),e(Q,F0),e(F0,_de),e(_de,pCo),e(F0,uCo),e(F0,Ej),e(Ej,_Co),e(F0,bCo),e(Q,vCo),e(Q,T0),e(T0,bde),e(bde,FCo),e(T0,TCo),e(T0,Cj),e(Cj,MCo),e(T0,ECo),e(Q,CCo),e(Q,M0),e(M0,vde),e(vde,wCo),e(M0,ACo),e(M0,wj),e(wj,yCo),e(M0,LCo),e(Q,xCo),e(Q,E0),e(E0,Fde),e(Fde,$Co),e(E0,kCo),e(E0,Aj),e(Aj,SCo),e(E0,RCo),e(Q,BCo),e(Q,C0),e(C0,Tde),e(Tde,PCo),e(C0,ICo),e(C0,yj),e(yj,qCo),e(C0,NCo),e(Q,jCo),e(Q,w0),e(w0,Mde),e(Mde,DCo),e(w0,GCo),e(w0,Lj),e(Lj,OCo),e(w0,VCo),e(Q,XCo),e(Q,A0),e(A0,Ede),e(Ede,zCo),e(A0,QCo),e(A0,xj),e(xj,WCo),e(A0,HCo),e(Q,UCo),e(Q,y0),e(y0,Cde),e(Cde,JCo),e(y0,YCo),e(y0,$j),e($j,KCo),e(y0,ZCo),e(Q,e3o),e(Q,L0),e(L0,wde),e(wde,o3o),e(L0,r3o),e(L0,kj),e(kj,t3o),e(L0,a3o),e(Q,n3o),e(Q,x0),e(x0,Ade),e(Ade,s3o),e(x0,l3o),e(x0,Sj),e(Sj,i3o),e(x0,d3o),e(Q,c3o),e(Q,$0),e($0,yde),e(yde,f3o),e($0,m3o),e($0,Rj),e(Rj,g3o),e($0,h3o),e(Q,p3o),e(Q,k0),e(k0,Lde),e(Lde,u3o),e(k0,_3o),e(k0,Bj),e(Bj,b3o),e(k0,v3o),e(Q,F3o),e(Q,S0),e(S0,xde),e(xde,T3o),e(S0,M3o),e(S0,Pj),e(Pj,E3o),e(S0,C3o),e(Q,w3o),e(Q,R0),e(R0,$de),e($de,A3o),e(R0,y3o),e(R0,Ij),e(Ij,L3o),e(R0,x3o),e(Q,$3o),e(Q,B0),e(B0,kde),e(kde,k3o),e(B0,S3o),e(B0,qj),e(qj,R3o),e(B0,B3o),e(Q,P3o),e(Q,P0),e(P0,Sde),e(Sde,I3o),e(P0,q3o),e(P0,Nj),e(Nj,N3o),e(P0,j3o),e(Q,D3o),e(Q,I0),e(I0,Rde),e(Rde,G3o),e(I0,O3o),e(I0,jj),e(jj,V3o),e(I0,X3o),e(Q,z3o),e(Q,q0),e(q0,Bde),e(Bde,Q3o),e(q0,W3o),e(q0,Dj),e(Dj,H3o),e(q0,U3o),e(Q,J3o),e(Q,N0),e(N0,Pde),e(Pde,Y3o),e(N0,K3o),e(N0,Gj),e(Gj,Z3o),e(N0,ewo),e(Q,owo),e(Q,j0),e(j0,Ide),e(Ide,rwo),e(j0,two),e(j0,Oj),e(Oj,awo),e(j0,nwo),e(Q,swo),e(Q,D0),e(D0,qde),e(qde,lwo),e(D0,iwo),e(D0,Vj),e(Vj,dwo),e(D0,cwo),e(Q,fwo),e(Q,G0),e(G0,Nde),e(Nde,mwo),e(G0,gwo),e(G0,Xj),e(Xj,hwo),e(G0,pwo),e(Q,uwo),e(Q,O0),e(O0,jde),e(jde,_wo),e(O0,bwo),e(O0,zj),e(zj,vwo),e(O0,Fwo),e(Q,Two),e(Q,V0),e(V0,Dde),e(Dde,Mwo),e(V0,Ewo),e(V0,Qj),e(Qj,Cwo),e(V0,wwo),e(Q,Awo),e(Q,X0),e(X0,Gde),e(Gde,ywo),e(X0,Lwo),e(X0,Wj),e(Wj,xwo),e(X0,$wo),e(Q,kwo),e(Q,z0),e(z0,Ode),e(Ode,Swo),e(z0,Rwo),e(z0,Hj),e(Hj,Bwo),e(z0,Pwo),e(Q,Iwo),e(Q,Q0),e(Q0,Vde),e(Vde,qwo),e(Q0,Nwo),e(Q0,Uj),e(Uj,jwo),e(Q0,Dwo),e(Q,Gwo),e(Q,W0),e(W0,Xde),e(Xde,Owo),e(W0,Vwo),e(W0,Jj),e(Jj,Xwo),e(W0,zwo),e(Q,Qwo),e(Q,H0),e(H0,zde),e(zde,Wwo),e(H0,Hwo),e(H0,Yj),e(Yj,Uwo),e(H0,Jwo),e(Q,Ywo),e(Q,U0),e(U0,Qde),e(Qde,Kwo),e(U0,Zwo),e(U0,Kj),e(Kj,eAo),e(U0,oAo),e(Q,rAo),e(Q,J0),e(J0,Wde),e(Wde,tAo),e(J0,aAo),e(J0,Hde),e(Hde,nAo),e(J0,sAo),e(Q,lAo),e(Q,Y0),e(Y0,Ude),e(Ude,iAo),e(Y0,dAo),e(Y0,Zj),e(Zj,cAo),e(Y0,fAo),e(Q,mAo),e(Q,K0),e(K0,Jde),e(Jde,gAo),e(K0,hAo),e(K0,eD),e(eD,pAo),e(K0,uAo),e(Q,_Ao),e(Q,Z0),e(Z0,Yde),e(Yde,bAo),e(Z0,vAo),e(Z0,oD),e(oD,FAo),e(Z0,TAo),e(Q,MAo),e(Q,e1),e(e1,Kde),e(Kde,EAo),e(e1,CAo),e(e1,rD),e(rD,wAo),e(e1,AAo),e(Ye,yAo),e(Ye,o1),e(o1,LAo),e(o1,Zde),e(Zde,xAo),e(o1,$Ao),e(o1,ece),e(ece,kAo),e(Ye,SAo),M(r1,Ye,null),b(f,VIe,_),b(f,Bi,_),e(Bi,t1),e(t1,oce),M(YA,oce,null),e(Bi,RAo),e(Bi,rce),e(rce,BAo),b(f,XIe,_),b(f,So,_),M(KA,So,null),e(So,PAo),e(So,Pi),e(Pi,IAo),e(Pi,tD),e(tD,qAo),e(Pi,NAo),e(Pi,aD),e(aD,jAo),e(Pi,DAo),e(So,GAo),e(So,ZA),e(ZA,OAo),e(ZA,tce),e(tce,VAo),e(ZA,XAo),e(So,zAo),e(So,nt),M(ey,nt,null),e(nt,QAo),e(nt,ace),e(ace,WAo),e(nt,HAo),e(nt,Ii),e(Ii,UAo),e(Ii,nce),e(nce,JAo),e(Ii,YAo),e(Ii,nD),e(nD,KAo),e(Ii,ZAo),e(nt,eyo),M(a1,nt,null),e(So,oyo),e(So,Ke),M(oy,Ke,null),e(Ke,ryo),e(Ke,sce),e(sce,tyo),e(Ke,ayo),e(Ke,$a),e($a,nyo),e($a,lce),e(lce,syo),e($a,lyo),e($a,ice),e(ice,iyo),e($a,dyo),e($a,dce),e(dce,cyo),e($a,fyo),e(Ke,myo),e(Ke,he),e(he,n1),e(n1,cce),e(cce,gyo),e(n1,hyo),e(n1,sD),e(sD,pyo),e(n1,uyo),e(he,_yo),e(he,s1),e(s1,fce),e(fce,byo),e(s1,vyo),e(s1,lD),e(lD,Fyo),e(s1,Tyo),e(he,Myo),e(he,l1),e(l1,mce),e(mce,Eyo),e(l1,Cyo),e(l1,iD),e(iD,wyo),e(l1,Ayo),e(he,yyo),e(he,i1),e(i1,gce),e(gce,Lyo),e(i1,xyo),e(i1,dD),e(dD,$yo),e(i1,kyo),e(he,Syo),e(he,d1),e(d1,hce),e(hce,Ryo),e(d1,Byo),e(d1,cD),e(cD,Pyo),e(d1,Iyo),e(he,qyo),e(he,c1),e(c1,pce),e(pce,Nyo),e(c1,jyo),e(c1,fD),e(fD,Dyo),e(c1,Gyo),e(he,Oyo),e(he,f1),e(f1,uce),e(uce,Vyo),e(f1,Xyo),e(f1,mD),e(mD,zyo),e(f1,Qyo),e(he,Wyo),e(he,m1),e(m1,_ce),e(_ce,Hyo),e(m1,Uyo),e(m1,gD),e(gD,Jyo),e(m1,Yyo),e(he,Kyo),e(he,g1),e(g1,bce),e(bce,Zyo),e(g1,eLo),e(g1,hD),e(hD,oLo),e(g1,rLo),e(he,tLo),e(he,h1),e(h1,vce),e(vce,aLo),e(h1,nLo),e(h1,pD),e(pD,sLo),e(h1,lLo),e(he,iLo),e(he,p1),e(p1,Fce),e(Fce,dLo),e(p1,cLo),e(p1,uD),e(uD,fLo),e(p1,mLo),e(he,gLo),e(he,u1),e(u1,Tce),e(Tce,hLo),e(u1,pLo),e(u1,_D),e(_D,uLo),e(u1,_Lo),e(he,bLo),e(he,_1),e(_1,Mce),e(Mce,vLo),e(_1,FLo),e(_1,bD),e(bD,TLo),e(_1,MLo),e(he,ELo),e(he,b1),e(b1,Ece),e(Ece,CLo),e(b1,wLo),e(b1,vD),e(vD,ALo),e(b1,yLo),e(he,LLo),e(he,v1),e(v1,Cce),e(Cce,xLo),e(v1,$Lo),e(v1,FD),e(FD,kLo),e(v1,SLo),e(he,RLo),e(he,F1),e(F1,wce),e(wce,BLo),e(F1,PLo),e(F1,TD),e(TD,ILo),e(F1,qLo),e(he,NLo),e(he,T1),e(T1,Ace),e(Ace,jLo),e(T1,DLo),e(T1,MD),e(MD,GLo),e(T1,OLo),e(Ke,VLo),e(Ke,M1),e(M1,XLo),e(M1,yce),e(yce,zLo),e(M1,QLo),e(M1,Lce),e(Lce,WLo),e(Ke,HLo),M(E1,Ke,null),b(f,zIe,_),b(f,qi,_),e(qi,C1),e(C1,xce),M(ry,xce,null),e(qi,ULo),e(qi,$ce),e($ce,JLo),b(f,QIe,_),b(f,Ro,_),M(ty,Ro,null),e(Ro,YLo),e(Ro,Ni),e(Ni,KLo),e(Ni,ED),e(ED,ZLo),e(Ni,e8o),e(Ni,CD),e(CD,o8o),e(Ni,r8o),e(Ro,t8o),e(Ro,ay),e(ay,a8o),e(ay,kce),e(kce,n8o),e(ay,s8o),e(Ro,l8o),e(Ro,st),M(ny,st,null),e(st,i8o),e(st,Sce),e(Sce,d8o),e(st,c8o),e(st,ji),e(ji,f8o),e(ji,Rce),e(Rce,m8o),e(ji,g8o),e(ji,wD),e(wD,h8o),e(ji,p8o),e(st,u8o),M(w1,st,null),e(Ro,_8o),e(Ro,Ze),M(sy,Ze,null),e(Ze,b8o),e(Ze,Bce),e(Bce,v8o),e(Ze,F8o),e(Ze,ka),e(ka,T8o),e(ka,Pce),e(Pce,M8o),e(ka,E8o),e(ka,Ice),e(Ice,C8o),e(ka,w8o),e(ka,qce),e(qce,A8o),e(ka,y8o),e(Ze,L8o),e(Ze,q),e(q,A1),e(A1,Nce),e(Nce,x8o),e(A1,$8o),e(A1,AD),e(AD,k8o),e(A1,S8o),e(q,R8o),e(q,y1),e(y1,jce),e(jce,B8o),e(y1,P8o),e(y1,yD),e(yD,I8o),e(y1,q8o),e(q,N8o),e(q,L1),e(L1,Dce),e(Dce,j8o),e(L1,D8o),e(L1,LD),e(LD,G8o),e(L1,O8o),e(q,V8o),e(q,x1),e(x1,Gce),e(Gce,X8o),e(x1,z8o),e(x1,xD),e(xD,Q8o),e(x1,W8o),e(q,H8o),e(q,$1),e($1,Oce),e(Oce,U8o),e($1,J8o),e($1,$D),e($D,Y8o),e($1,K8o),e(q,Z8o),e(q,k1),e(k1,Vce),e(Vce,exo),e(k1,oxo),e(k1,kD),e(kD,rxo),e(k1,txo),e(q,axo),e(q,S1),e(S1,Xce),e(Xce,nxo),e(S1,sxo),e(S1,SD),e(SD,lxo),e(S1,ixo),e(q,dxo),e(q,R1),e(R1,zce),e(zce,cxo),e(R1,fxo),e(R1,RD),e(RD,mxo),e(R1,gxo),e(q,hxo),e(q,B1),e(B1,Qce),e(Qce,pxo),e(B1,uxo),e(B1,BD),e(BD,_xo),e(B1,bxo),e(q,vxo),e(q,P1),e(P1,Wce),e(Wce,Fxo),e(P1,Txo),e(P1,PD),e(PD,Mxo),e(P1,Exo),e(q,Cxo),e(q,I1),e(I1,Hce),e(Hce,wxo),e(I1,Axo),e(I1,ID),e(ID,yxo),e(I1,Lxo),e(q,xxo),e(q,q1),e(q1,Uce),e(Uce,$xo),e(q1,kxo),e(q1,qD),e(qD,Sxo),e(q1,Rxo),e(q,Bxo),e(q,N1),e(N1,Jce),e(Jce,Pxo),e(N1,Ixo),e(N1,ND),e(ND,qxo),e(N1,Nxo),e(q,jxo),e(q,j1),e(j1,Yce),e(Yce,Dxo),e(j1,Gxo),e(j1,jD),e(jD,Oxo),e(j1,Vxo),e(q,Xxo),e(q,D1),e(D1,Kce),e(Kce,zxo),e(D1,Qxo),e(D1,DD),e(DD,Wxo),e(D1,Hxo),e(q,Uxo),e(q,G1),e(G1,Zce),e(Zce,Jxo),e(G1,Yxo),e(G1,GD),e(GD,Kxo),e(G1,Zxo),e(q,e9o),e(q,O1),e(O1,efe),e(efe,o9o),e(O1,r9o),e(O1,OD),e(OD,t9o),e(O1,a9o),e(q,n9o),e(q,V1),e(V1,ofe),e(ofe,s9o),e(V1,l9o),e(V1,VD),e(VD,i9o),e(V1,d9o),e(q,c9o),e(q,X1),e(X1,rfe),e(rfe,f9o),e(X1,m9o),e(X1,XD),e(XD,g9o),e(X1,h9o),e(q,p9o),e(q,z1),e(z1,tfe),e(tfe,u9o),e(z1,_9o),e(z1,zD),e(zD,b9o),e(z1,v9o),e(q,F9o),e(q,Q1),e(Q1,afe),e(afe,T9o),e(Q1,M9o),e(Q1,QD),e(QD,E9o),e(Q1,C9o),e(q,w9o),e(q,W1),e(W1,nfe),e(nfe,A9o),e(W1,y9o),e(W1,WD),e(WD,L9o),e(W1,x9o),e(q,$9o),e(q,H1),e(H1,sfe),e(sfe,k9o),e(H1,S9o),e(H1,HD),e(HD,R9o),e(H1,B9o),e(q,P9o),e(q,U1),e(U1,lfe),e(lfe,I9o),e(U1,q9o),e(U1,UD),e(UD,N9o),e(U1,j9o),e(q,D9o),e(q,J1),e(J1,ife),e(ife,G9o),e(J1,O9o),e(J1,JD),e(JD,V9o),e(J1,X9o),e(q,z9o),e(q,Y1),e(Y1,dfe),e(dfe,Q9o),e(Y1,W9o),e(Y1,YD),e(YD,H9o),e(Y1,U9o),e(q,J9o),e(q,K1),e(K1,cfe),e(cfe,Y9o),e(K1,K9o),e(K1,KD),e(KD,Z9o),e(K1,e$o),e(q,o$o),e(q,Z1),e(Z1,ffe),e(ffe,r$o),e(Z1,t$o),e(Z1,ZD),e(ZD,a$o),e(Z1,n$o),e(q,s$o),e(q,eb),e(eb,mfe),e(mfe,l$o),e(eb,i$o),e(eb,eG),e(eG,d$o),e(eb,c$o),e(q,f$o),e(q,ob),e(ob,gfe),e(gfe,m$o),e(ob,g$o),e(ob,oG),e(oG,h$o),e(ob,p$o),e(q,u$o),e(q,rb),e(rb,hfe),e(hfe,_$o),e(rb,b$o),e(rb,rG),e(rG,v$o),e(rb,F$o),e(q,T$o),e(q,tb),e(tb,pfe),e(pfe,M$o),e(tb,E$o),e(tb,tG),e(tG,C$o),e(tb,w$o),e(q,A$o),e(q,ab),e(ab,ufe),e(ufe,y$o),e(ab,L$o),e(ab,aG),e(aG,x$o),e(ab,$$o),e(q,k$o),e(q,nb),e(nb,_fe),e(_fe,S$o),e(nb,R$o),e(nb,nG),e(nG,B$o),e(nb,P$o),e(q,I$o),e(q,sb),e(sb,bfe),e(bfe,q$o),e(sb,N$o),e(sb,sG),e(sG,j$o),e(sb,D$o),e(q,G$o),e(q,lb),e(lb,vfe),e(vfe,O$o),e(lb,V$o),e(lb,lG),e(lG,X$o),e(lb,z$o),e(q,Q$o),e(q,ib),e(ib,Ffe),e(Ffe,W$o),e(ib,H$o),e(ib,iG),e(iG,U$o),e(ib,J$o),e(q,Y$o),e(q,db),e(db,Tfe),e(Tfe,K$o),e(db,Z$o),e(db,dG),e(dG,eko),e(db,oko),e(q,rko),e(q,cb),e(cb,Mfe),e(Mfe,tko),e(cb,ako),e(cb,cG),e(cG,nko),e(cb,sko),e(q,lko),e(q,fb),e(fb,Efe),e(Efe,iko),e(fb,dko),e(fb,fG),e(fG,cko),e(fb,fko),e(q,mko),e(q,mb),e(mb,Cfe),e(Cfe,gko),e(mb,hko),e(mb,mG),e(mG,pko),e(mb,uko),e(q,_ko),e(q,gb),e(gb,wfe),e(wfe,bko),e(gb,vko),e(gb,gG),e(gG,Fko),e(gb,Tko),e(q,Mko),e(q,hb),e(hb,Afe),e(Afe,Eko),e(hb,Cko),e(hb,hG),e(hG,wko),e(hb,Ako),e(q,yko),e(q,pb),e(pb,yfe),e(yfe,Lko),e(pb,xko),e(pb,pG),e(pG,$ko),e(pb,kko),e(q,Sko),e(q,ub),e(ub,Lfe),e(Lfe,Rko),e(ub,Bko),e(ub,uG),e(uG,Pko),e(ub,Iko),e(q,qko),e(q,_b),e(_b,xfe),e(xfe,Nko),e(_b,jko),e(_b,_G),e(_G,Dko),e(_b,Gko),e(q,Oko),e(q,bb),e(bb,$fe),e($fe,Vko),e(bb,Xko),e(bb,bG),e(bG,zko),e(bb,Qko),e(q,Wko),e(q,vb),e(vb,kfe),e(kfe,Hko),e(vb,Uko),e(vb,vG),e(vG,Jko),e(vb,Yko),e(Ze,Kko),e(Ze,Fb),e(Fb,Zko),e(Fb,Sfe),e(Sfe,eSo),e(Fb,oSo),e(Fb,Rfe),e(Rfe,rSo),e(Ze,tSo),M(Tb,Ze,null),b(f,WIe,_),b(f,Di,_),e(Di,Mb),e(Mb,Bfe),M(ly,Bfe,null),e(Di,aSo),e(Di,Pfe),e(Pfe,nSo),b(f,HIe,_),b(f,Bo,_),M(iy,Bo,null),e(Bo,sSo),e(Bo,Gi),e(Gi,lSo),e(Gi,FG),e(FG,iSo),e(Gi,dSo),e(Gi,TG),e(TG,cSo),e(Gi,fSo),e(Bo,mSo),e(Bo,dy),e(dy,gSo),e(dy,Ife),e(Ife,hSo),e(dy,pSo),e(Bo,uSo),e(Bo,lt),M(cy,lt,null),e(lt,_So),e(lt,qfe),e(qfe,bSo),e(lt,vSo),e(lt,Oi),e(Oi,FSo),e(Oi,Nfe),e(Nfe,TSo),e(Oi,MSo),e(Oi,MG),e(MG,ESo),e(Oi,CSo),e(lt,wSo),M(Eb,lt,null),e(Bo,ASo),e(Bo,eo),M(fy,eo,null),e(eo,ySo),e(eo,jfe),e(jfe,LSo),e(eo,xSo),e(eo,Sa),e(Sa,$So),e(Sa,Dfe),e(Dfe,kSo),e(Sa,SSo),e(Sa,Gfe),e(Gfe,RSo),e(Sa,BSo),e(Sa,Ofe),e(Ofe,PSo),e(Sa,ISo),e(eo,qSo),e(eo,Y),e(Y,Cb),e(Cb,Vfe),e(Vfe,NSo),e(Cb,jSo),e(Cb,EG),e(EG,DSo),e(Cb,GSo),e(Y,OSo),e(Y,wb),e(wb,Xfe),e(Xfe,VSo),e(wb,XSo),e(wb,CG),e(CG,zSo),e(wb,QSo),e(Y,WSo),e(Y,Ab),e(Ab,zfe),e(zfe,HSo),e(Ab,USo),e(Ab,wG),e(wG,JSo),e(Ab,YSo),e(Y,KSo),e(Y,yb),e(yb,Qfe),e(Qfe,ZSo),e(yb,eRo),e(yb,AG),e(AG,oRo),e(yb,rRo),e(Y,tRo),e(Y,Lb),e(Lb,Wfe),e(Wfe,aRo),e(Lb,nRo),e(Lb,yG),e(yG,sRo),e(Lb,lRo),e(Y,iRo),e(Y,xb),e(xb,Hfe),e(Hfe,dRo),e(xb,cRo),e(xb,LG),e(LG,fRo),e(xb,mRo),e(Y,gRo),e(Y,$b),e($b,Ufe),e(Ufe,hRo),e($b,pRo),e($b,xG),e(xG,uRo),e($b,_Ro),e(Y,bRo),e(Y,kb),e(kb,Jfe),e(Jfe,vRo),e(kb,FRo),e(kb,$G),e($G,TRo),e(kb,MRo),e(Y,ERo),e(Y,Sb),e(Sb,Yfe),e(Yfe,CRo),e(Sb,wRo),e(Sb,kG),e(kG,ARo),e(Sb,yRo),e(Y,LRo),e(Y,Rb),e(Rb,Kfe),e(Kfe,xRo),e(Rb,$Ro),e(Rb,SG),e(SG,kRo),e(Rb,SRo),e(Y,RRo),e(Y,Bb),e(Bb,Zfe),e(Zfe,BRo),e(Bb,PRo),e(Bb,RG),e(RG,IRo),e(Bb,qRo),e(Y,NRo),e(Y,Pb),e(Pb,eme),e(eme,jRo),e(Pb,DRo),e(Pb,BG),e(BG,GRo),e(Pb,ORo),e(Y,VRo),e(Y,Ib),e(Ib,ome),e(ome,XRo),e(Ib,zRo),e(Ib,PG),e(PG,QRo),e(Ib,WRo),e(Y,HRo),e(Y,qb),e(qb,rme),e(rme,URo),e(qb,JRo),e(qb,IG),e(IG,YRo),e(qb,KRo),e(Y,ZRo),e(Y,Nb),e(Nb,tme),e(tme,eBo),e(Nb,oBo),e(Nb,qG),e(qG,rBo),e(Nb,tBo),e(Y,aBo),e(Y,jb),e(jb,ame),e(ame,nBo),e(jb,sBo),e(jb,NG),e(NG,lBo),e(jb,iBo),e(Y,dBo),e(Y,Db),e(Db,nme),e(nme,cBo),e(Db,fBo),e(Db,jG),e(jG,mBo),e(Db,gBo),e(Y,hBo),e(Y,Gb),e(Gb,sme),e(sme,pBo),e(Gb,uBo),e(Gb,DG),e(DG,_Bo),e(Gb,bBo),e(Y,vBo),e(Y,Ob),e(Ob,lme),e(lme,FBo),e(Ob,TBo),e(Ob,GG),e(GG,MBo),e(Ob,EBo),e(Y,CBo),e(Y,Vb),e(Vb,ime),e(ime,wBo),e(Vb,ABo),e(Vb,OG),e(OG,yBo),e(Vb,LBo),e(Y,xBo),e(Y,Xb),e(Xb,dme),e(dme,$Bo),e(Xb,kBo),e(Xb,VG),e(VG,SBo),e(Xb,RBo),e(Y,BBo),e(Y,zb),e(zb,cme),e(cme,PBo),e(zb,IBo),e(zb,XG),e(XG,qBo),e(zb,NBo),e(Y,jBo),e(Y,Qb),e(Qb,fme),e(fme,DBo),e(Qb,GBo),e(Qb,zG),e(zG,OBo),e(Qb,VBo),e(Y,XBo),e(Y,Wb),e(Wb,mme),e(mme,zBo),e(Wb,QBo),e(Wb,QG),e(QG,WBo),e(Wb,HBo),e(Y,UBo),e(Y,Hb),e(Hb,gme),e(gme,JBo),e(Hb,YBo),e(Hb,WG),e(WG,KBo),e(Hb,ZBo),e(Y,ePo),e(Y,Ub),e(Ub,hme),e(hme,oPo),e(Ub,rPo),e(Ub,HG),e(HG,tPo),e(Ub,aPo),e(Y,nPo),e(Y,Jb),e(Jb,pme),e(pme,sPo),e(Jb,lPo),e(Jb,UG),e(UG,iPo),e(Jb,dPo),e(Y,cPo),e(Y,Yb),e(Yb,ume),e(ume,fPo),e(Yb,mPo),e(Yb,JG),e(JG,gPo),e(Yb,hPo),e(Y,pPo),e(Y,Kb),e(Kb,_me),e(_me,uPo),e(Kb,_Po),e(Kb,YG),e(YG,bPo),e(Kb,vPo),e(eo,FPo),e(eo,Zb),e(Zb,TPo),e(Zb,bme),e(bme,MPo),e(Zb,EPo),e(Zb,vme),e(vme,CPo),e(eo,wPo),M(e2,eo,null),b(f,UIe,_),b(f,Vi,_),e(Vi,o2),e(o2,Fme),M(my,Fme,null),e(Vi,APo),e(Vi,Tme),e(Tme,yPo),b(f,JIe,_),b(f,Po,_),M(gy,Po,null),e(Po,LPo),e(Po,Xi),e(Xi,xPo),e(Xi,KG),e(KG,$Po),e(Xi,kPo),e(Xi,ZG),e(ZG,SPo),e(Xi,RPo),e(Po,BPo),e(Po,hy),e(hy,PPo),e(hy,Mme),e(Mme,IPo),e(hy,qPo),e(Po,NPo),e(Po,it),M(py,it,null),e(it,jPo),e(it,Eme),e(Eme,DPo),e(it,GPo),e(it,zi),e(zi,OPo),e(zi,Cme),e(Cme,VPo),e(zi,XPo),e(zi,eO),e(eO,zPo),e(zi,QPo),e(it,WPo),M(r2,it,null),e(Po,HPo),e(Po,oo),M(uy,oo,null),e(oo,UPo),e(oo,wme),e(wme,JPo),e(oo,YPo),e(oo,Ra),e(Ra,KPo),e(Ra,Ame),e(Ame,ZPo),e(Ra,eIo),e(Ra,yme),e(yme,oIo),e(Ra,rIo),e(Ra,Lme),e(Lme,tIo),e(Ra,aIo),e(oo,nIo),e(oo,Yr),e(Yr,t2),e(t2,xme),e(xme,sIo),e(t2,lIo),e(t2,oO),e(oO,iIo),e(t2,dIo),e(Yr,cIo),e(Yr,a2),e(a2,$me),e($me,fIo),e(a2,mIo),e(a2,rO),e(rO,gIo),e(a2,hIo),e(Yr,pIo),e(Yr,n2),e(n2,kme),e(kme,uIo),e(n2,_Io),e(n2,tO),e(tO,bIo),e(n2,vIo),e(Yr,FIo),e(Yr,s2),e(s2,Sme),e(Sme,TIo),e(s2,MIo),e(s2,aO),e(aO,EIo),e(s2,CIo),e(Yr,wIo),e(Yr,l2),e(l2,Rme),e(Rme,AIo),e(l2,yIo),e(l2,nO),e(nO,LIo),e(l2,xIo),e(oo,$Io),e(oo,i2),e(i2,kIo),e(i2,Bme),e(Bme,SIo),e(i2,RIo),e(i2,Pme),e(Pme,BIo),e(oo,PIo),M(d2,oo,null),b(f,YIe,_),b(f,Qi,_),e(Qi,c2),e(c2,Ime),M(_y,Ime,null),e(Qi,IIo),e(Qi,qme),e(qme,qIo),b(f,KIe,_),b(f,Io,_),M(by,Io,null),e(Io,NIo),e(Io,Wi),e(Wi,jIo),e(Wi,sO),e(sO,DIo),e(Wi,GIo),e(Wi,lO),e(lO,OIo),e(Wi,VIo),e(Io,XIo),e(Io,vy),e(vy,zIo),e(vy,Nme),e(Nme,QIo),e(vy,WIo),e(Io,HIo),e(Io,dt),M(Fy,dt,null),e(dt,UIo),e(dt,jme),e(jme,JIo),e(dt,YIo),e(dt,Hi),e(Hi,KIo),e(Hi,Dme),e(Dme,ZIo),e(Hi,eqo),e(Hi,iO),e(iO,oqo),e(Hi,rqo),e(dt,tqo),M(f2,dt,null),e(Io,aqo),e(Io,ro),M(Ty,ro,null),e(ro,nqo),e(ro,Gme),e(Gme,sqo),e(ro,lqo),e(ro,Ba),e(Ba,iqo),e(Ba,Ome),e(Ome,dqo),e(Ba,cqo),e(Ba,Vme),e(Vme,fqo),e(Ba,mqo),e(Ba,Xme),e(Xme,gqo),e(Ba,hqo),e(ro,pqo),e(ro,H),e(H,m2),e(m2,zme),e(zme,uqo),e(m2,_qo),e(m2,dO),e(dO,bqo),e(m2,vqo),e(H,Fqo),e(H,g2),e(g2,Qme),e(Qme,Tqo),e(g2,Mqo),e(g2,cO),e(cO,Eqo),e(g2,Cqo),e(H,wqo),e(H,h2),e(h2,Wme),e(Wme,Aqo),e(h2,yqo),e(h2,fO),e(fO,Lqo),e(h2,xqo),e(H,$qo),e(H,p2),e(p2,Hme),e(Hme,kqo),e(p2,Sqo),e(p2,mO),e(mO,Rqo),e(p2,Bqo),e(H,Pqo),e(H,u2),e(u2,Ume),e(Ume,Iqo),e(u2,qqo),e(u2,gO),e(gO,Nqo),e(u2,jqo),e(H,Dqo),e(H,_2),e(_2,Jme),e(Jme,Gqo),e(_2,Oqo),e(_2,hO),e(hO,Vqo),e(_2,Xqo),e(H,zqo),e(H,b2),e(b2,Yme),e(Yme,Qqo),e(b2,Wqo),e(b2,pO),e(pO,Hqo),e(b2,Uqo),e(H,Jqo),e(H,v2),e(v2,Kme),e(Kme,Yqo),e(v2,Kqo),e(v2,uO),e(uO,Zqo),e(v2,eNo),e(H,oNo),e(H,F2),e(F2,Zme),e(Zme,rNo),e(F2,tNo),e(F2,_O),e(_O,aNo),e(F2,nNo),e(H,sNo),e(H,T2),e(T2,ege),e(ege,lNo),e(T2,iNo),e(T2,bO),e(bO,dNo),e(T2,cNo),e(H,fNo),e(H,M2),e(M2,oge),e(oge,mNo),e(M2,gNo),e(M2,vO),e(vO,hNo),e(M2,pNo),e(H,uNo),e(H,E2),e(E2,rge),e(rge,_No),e(E2,bNo),e(E2,FO),e(FO,vNo),e(E2,FNo),e(H,TNo),e(H,C2),e(C2,tge),e(tge,MNo),e(C2,ENo),e(C2,TO),e(TO,CNo),e(C2,wNo),e(H,ANo),e(H,w2),e(w2,age),e(age,yNo),e(w2,LNo),e(w2,MO),e(MO,xNo),e(w2,$No),e(H,kNo),e(H,A2),e(A2,nge),e(nge,SNo),e(A2,RNo),e(A2,EO),e(EO,BNo),e(A2,PNo),e(H,INo),e(H,y2),e(y2,sge),e(sge,qNo),e(y2,NNo),e(y2,CO),e(CO,jNo),e(y2,DNo),e(H,GNo),e(H,L2),e(L2,lge),e(lge,ONo),e(L2,VNo),e(L2,wO),e(wO,XNo),e(L2,zNo),e(H,QNo),e(H,x2),e(x2,ige),e(ige,WNo),e(x2,HNo),e(x2,AO),e(AO,UNo),e(x2,JNo),e(H,YNo),e(H,$2),e($2,dge),e(dge,KNo),e($2,ZNo),e($2,yO),e(yO,ejo),e($2,ojo),e(H,rjo),e(H,k2),e(k2,cge),e(cge,tjo),e(k2,ajo),e(k2,LO),e(LO,njo),e(k2,sjo),e(H,ljo),e(H,S2),e(S2,fge),e(fge,ijo),e(S2,djo),e(S2,xO),e(xO,cjo),e(S2,fjo),e(H,mjo),e(H,R2),e(R2,mge),e(mge,gjo),e(R2,hjo),e(R2,$O),e($O,pjo),e(R2,ujo),e(H,_jo),e(H,B2),e(B2,gge),e(gge,bjo),e(B2,vjo),e(B2,kO),e(kO,Fjo),e(B2,Tjo),e(H,Mjo),e(H,P2),e(P2,hge),e(hge,Ejo),e(P2,Cjo),e(P2,SO),e(SO,wjo),e(P2,Ajo),e(H,yjo),e(H,I2),e(I2,pge),e(pge,Ljo),e(I2,xjo),e(I2,RO),e(RO,$jo),e(I2,kjo),e(H,Sjo),e(H,q2),e(q2,uge),e(uge,Rjo),e(q2,Bjo),e(q2,BO),e(BO,Pjo),e(q2,Ijo),e(H,qjo),e(H,N2),e(N2,_ge),e(_ge,Njo),e(N2,jjo),e(N2,PO),e(PO,Djo),e(N2,Gjo),e(H,Ojo),e(H,j2),e(j2,bge),e(bge,Vjo),e(j2,Xjo),e(j2,IO),e(IO,zjo),e(j2,Qjo),e(H,Wjo),e(H,D2),e(D2,vge),e(vge,Hjo),e(D2,Ujo),e(D2,qO),e(qO,Jjo),e(D2,Yjo),e(H,Kjo),e(H,G2),e(G2,Fge),e(Fge,Zjo),e(G2,eDo),e(G2,NO),e(NO,oDo),e(G2,rDo),e(H,tDo),e(H,O2),e(O2,Tge),e(Tge,aDo),e(O2,nDo),e(O2,jO),e(jO,sDo),e(O2,lDo),e(H,iDo),e(H,V2),e(V2,Mge),e(Mge,dDo),e(V2,cDo),e(V2,DO),e(DO,fDo),e(V2,mDo),e(H,gDo),e(H,X2),e(X2,Ege),e(Ege,hDo),e(X2,pDo),e(X2,GO),e(GO,uDo),e(X2,_Do),e(H,bDo),e(H,z2),e(z2,Cge),e(Cge,vDo),e(z2,FDo),e(z2,OO),e(OO,TDo),e(z2,MDo),e(ro,EDo),e(ro,Q2),e(Q2,CDo),e(Q2,wge),e(wge,wDo),e(Q2,ADo),e(Q2,Age),e(Age,yDo),e(ro,LDo),M(W2,ro,null),b(f,ZIe,_),b(f,Ui,_),e(Ui,H2),e(H2,yge),M(My,yge,null),e(Ui,xDo),e(Ui,Lge),e(Lge,$Do),b(f,eqe,_),b(f,qo,_),M(Ey,qo,null),e(qo,kDo),e(qo,Ji),e(Ji,SDo),e(Ji,VO),e(VO,RDo),e(Ji,BDo),e(Ji,XO),e(XO,PDo),e(Ji,IDo),e(qo,qDo),e(qo,Cy),e(Cy,NDo),e(Cy,xge),e(xge,jDo),e(Cy,DDo),e(qo,GDo),e(qo,ct),M(wy,ct,null),e(ct,ODo),e(ct,$ge),e($ge,VDo),e(ct,XDo),e(ct,Yi),e(Yi,zDo),e(Yi,kge),e(kge,QDo),e(Yi,WDo),e(Yi,zO),e(zO,HDo),e(Yi,UDo),e(ct,JDo),M(U2,ct,null),e(qo,YDo),e(qo,to),M(Ay,to,null),e(to,KDo),e(to,Sge),e(Sge,ZDo),e(to,eGo),e(to,Pa),e(Pa,oGo),e(Pa,Rge),e(Rge,rGo),e(Pa,tGo),e(Pa,Bge),e(Bge,aGo),e(Pa,nGo),e(Pa,Pge),e(Pge,sGo),e(Pa,lGo),e(to,iGo),e(to,O),e(O,J2),e(J2,Ige),e(Ige,dGo),e(J2,cGo),e(J2,QO),e(QO,fGo),e(J2,mGo),e(O,gGo),e(O,Y2),e(Y2,qge),e(qge,hGo),e(Y2,pGo),e(Y2,WO),e(WO,uGo),e(Y2,_Go),e(O,bGo),e(O,K2),e(K2,Nge),e(Nge,vGo),e(K2,FGo),e(K2,HO),e(HO,TGo),e(K2,MGo),e(O,EGo),e(O,Z2),e(Z2,jge),e(jge,CGo),e(Z2,wGo),e(Z2,UO),e(UO,AGo),e(Z2,yGo),e(O,LGo),e(O,ev),e(ev,Dge),e(Dge,xGo),e(ev,$Go),e(ev,JO),e(JO,kGo),e(ev,SGo),e(O,RGo),e(O,ov),e(ov,Gge),e(Gge,BGo),e(ov,PGo),e(ov,YO),e(YO,IGo),e(ov,qGo),e(O,NGo),e(O,rv),e(rv,Oge),e(Oge,jGo),e(rv,DGo),e(rv,KO),e(KO,GGo),e(rv,OGo),e(O,VGo),e(O,tv),e(tv,Vge),e(Vge,XGo),e(tv,zGo),e(tv,ZO),e(ZO,QGo),e(tv,WGo),e(O,HGo),e(O,av),e(av,Xge),e(Xge,UGo),e(av,JGo),e(av,eV),e(eV,YGo),e(av,KGo),e(O,ZGo),e(O,nv),e(nv,zge),e(zge,eOo),e(nv,oOo),e(nv,oV),e(oV,rOo),e(nv,tOo),e(O,aOo),e(O,sv),e(sv,Qge),e(Qge,nOo),e(sv,sOo),e(sv,rV),e(rV,lOo),e(sv,iOo),e(O,dOo),e(O,lv),e(lv,Wge),e(Wge,cOo),e(lv,fOo),e(lv,tV),e(tV,mOo),e(lv,gOo),e(O,hOo),e(O,iv),e(iv,Hge),e(Hge,pOo),e(iv,uOo),e(iv,aV),e(aV,_Oo),e(iv,bOo),e(O,vOo),e(O,dv),e(dv,Uge),e(Uge,FOo),e(dv,TOo),e(dv,nV),e(nV,MOo),e(dv,EOo),e(O,COo),e(O,cv),e(cv,Jge),e(Jge,wOo),e(cv,AOo),e(cv,sV),e(sV,yOo),e(cv,LOo),e(O,xOo),e(O,fv),e(fv,Yge),e(Yge,$Oo),e(fv,kOo),e(fv,lV),e(lV,SOo),e(fv,ROo),e(O,BOo),e(O,mv),e(mv,Kge),e(Kge,POo),e(mv,IOo),e(mv,iV),e(iV,qOo),e(mv,NOo),e(O,jOo),e(O,gv),e(gv,Zge),e(Zge,DOo),e(gv,GOo),e(gv,dV),e(dV,OOo),e(gv,VOo),e(O,XOo),e(O,hv),e(hv,ehe),e(ehe,zOo),e(hv,QOo),e(hv,cV),e(cV,WOo),e(hv,HOo),e(O,UOo),e(O,pv),e(pv,ohe),e(ohe,JOo),e(pv,YOo),e(pv,fV),e(fV,KOo),e(pv,ZOo),e(O,eVo),e(O,uv),e(uv,rhe),e(rhe,oVo),e(uv,rVo),e(uv,mV),e(mV,tVo),e(uv,aVo),e(O,nVo),e(O,_v),e(_v,the),e(the,sVo),e(_v,lVo),e(_v,gV),e(gV,iVo),e(_v,dVo),e(O,cVo),e(O,bv),e(bv,ahe),e(ahe,fVo),e(bv,mVo),e(bv,hV),e(hV,gVo),e(bv,hVo),e(O,pVo),e(O,vv),e(vv,nhe),e(nhe,uVo),e(vv,_Vo),e(vv,pV),e(pV,bVo),e(vv,vVo),e(O,FVo),e(O,Fv),e(Fv,she),e(she,TVo),e(Fv,MVo),e(Fv,uV),e(uV,EVo),e(Fv,CVo),e(O,wVo),e(O,Tv),e(Tv,lhe),e(lhe,AVo),e(Tv,yVo),e(Tv,_V),e(_V,LVo),e(Tv,xVo),e(O,$Vo),e(O,Mv),e(Mv,ihe),e(ihe,kVo),e(Mv,SVo),e(Mv,bV),e(bV,RVo),e(Mv,BVo),e(O,PVo),e(O,Ev),e(Ev,dhe),e(dhe,IVo),e(Ev,qVo),e(Ev,vV),e(vV,NVo),e(Ev,jVo),e(O,DVo),e(O,Cv),e(Cv,che),e(che,GVo),e(Cv,OVo),e(Cv,FV),e(FV,VVo),e(Cv,XVo),e(O,zVo),e(O,wv),e(wv,fhe),e(fhe,QVo),e(wv,WVo),e(wv,TV),e(TV,HVo),e(wv,UVo),e(O,JVo),e(O,Av),e(Av,mhe),e(mhe,YVo),e(Av,KVo),e(Av,MV),e(MV,ZVo),e(Av,eXo),e(O,oXo),e(O,yv),e(yv,ghe),e(ghe,rXo),e(yv,tXo),e(yv,EV),e(EV,aXo),e(yv,nXo),e(O,sXo),e(O,Lv),e(Lv,hhe),e(hhe,lXo),e(Lv,iXo),e(Lv,CV),e(CV,dXo),e(Lv,cXo),e(O,fXo),e(O,xv),e(xv,phe),e(phe,mXo),e(xv,gXo),e(xv,wV),e(wV,hXo),e(xv,pXo),e(O,uXo),e(O,$v),e($v,uhe),e(uhe,_Xo),e($v,bXo),e($v,AV),e(AV,vXo),e($v,FXo),e(O,TXo),e(O,kv),e(kv,_he),e(_he,MXo),e(kv,EXo),e(kv,yV),e(yV,CXo),e(kv,wXo),e(O,AXo),e(O,Sv),e(Sv,bhe),e(bhe,yXo),e(Sv,LXo),e(Sv,LV),e(LV,xXo),e(Sv,$Xo),e(O,kXo),e(O,Rv),e(Rv,vhe),e(vhe,SXo),e(Rv,RXo),e(Rv,xV),e(xV,BXo),e(Rv,PXo),e(O,IXo),e(O,Bv),e(Bv,Fhe),e(Fhe,qXo),e(Bv,NXo),e(Bv,$V),e($V,jXo),e(Bv,DXo),e(O,GXo),e(O,Pv),e(Pv,The),e(The,OXo),e(Pv,VXo),e(Pv,kV),e(kV,XXo),e(Pv,zXo),e(to,QXo),e(to,Iv),e(Iv,WXo),e(Iv,Mhe),e(Mhe,HXo),e(Iv,UXo),e(Iv,Ehe),e(Ehe,JXo),e(to,YXo),M(qv,to,null),b(f,oqe,_),b(f,Ki,_),e(Ki,Nv),e(Nv,Che),M(yy,Che,null),e(Ki,KXo),e(Ki,whe),e(whe,ZXo),b(f,rqe,_),b(f,No,_),M(Ly,No,null),e(No,ezo),e(No,Zi),e(Zi,ozo),e(Zi,SV),e(SV,rzo),e(Zi,tzo),e(Zi,RV),e(RV,azo),e(Zi,nzo),e(No,szo),e(No,xy),e(xy,lzo),e(xy,Ahe),e(Ahe,izo),e(xy,dzo),e(No,czo),e(No,ft),M($y,ft,null),e(ft,fzo),e(ft,yhe),e(yhe,mzo),e(ft,gzo),e(ft,ed),e(ed,hzo),e(ed,Lhe),e(Lhe,pzo),e(ed,uzo),e(ed,BV),e(BV,_zo),e(ed,bzo),e(ft,vzo),M(jv,ft,null),e(No,Fzo),e(No,ao),M(ky,ao,null),e(ao,Tzo),e(ao,xhe),e(xhe,Mzo),e(ao,Ezo),e(ao,Ia),e(Ia,Czo),e(Ia,$he),e($he,wzo),e(Ia,Azo),e(Ia,khe),e(khe,yzo),e(Ia,Lzo),e(Ia,She),e(She,xzo),e(Ia,$zo),e(ao,kzo),e(ao,Rhe),e(Rhe,Dv),e(Dv,Bhe),e(Bhe,Szo),e(Dv,Rzo),e(Dv,PV),e(PV,Bzo),e(Dv,Pzo),e(ao,Izo),e(ao,Gv),e(Gv,qzo),e(Gv,Phe),e(Phe,Nzo),e(Gv,jzo),e(Gv,Ihe),e(Ihe,Dzo),e(ao,Gzo),M(Ov,ao,null),b(f,tqe,_),b(f,od,_),e(od,Vv),e(Vv,qhe),M(Sy,qhe,null),e(od,Ozo),e(od,Nhe),e(Nhe,Vzo),b(f,aqe,_),b(f,jo,_),M(Ry,jo,null),e(jo,Xzo),e(jo,rd),e(rd,zzo),e(rd,IV),e(IV,Qzo),e(rd,Wzo),e(rd,qV),e(qV,Hzo),e(rd,Uzo),e(jo,Jzo),e(jo,By),e(By,Yzo),e(By,jhe),e(jhe,Kzo),e(By,Zzo),e(jo,eQo),e(jo,mt),M(Py,mt,null),e(mt,oQo),e(mt,Dhe),e(Dhe,rQo),e(mt,tQo),e(mt,td),e(td,aQo),e(td,Ghe),e(Ghe,nQo),e(td,sQo),e(td,NV),e(NV,lQo),e(td,iQo),e(mt,dQo),M(Xv,mt,null),e(jo,cQo),e(jo,no),M(Iy,no,null),e(no,fQo),e(no,Ohe),e(Ohe,mQo),e(no,gQo),e(no,qa),e(qa,hQo),e(qa,Vhe),e(Vhe,pQo),e(qa,uQo),e(qa,Xhe),e(Xhe,_Qo),e(qa,bQo),e(qa,zhe),e(zhe,vQo),e(qa,FQo),e(no,TQo),e(no,Fe),e(Fe,zv),e(zv,Qhe),e(Qhe,MQo),e(zv,EQo),e(zv,jV),e(jV,CQo),e(zv,wQo),e(Fe,AQo),e(Fe,Qv),e(Qv,Whe),e(Whe,yQo),e(Qv,LQo),e(Qv,DV),e(DV,xQo),e(Qv,$Qo),e(Fe,kQo),e(Fe,Wv),e(Wv,Hhe),e(Hhe,SQo),e(Wv,RQo),e(Wv,GV),e(GV,BQo),e(Wv,PQo),e(Fe,IQo),e(Fe,Bs),e(Bs,Uhe),e(Uhe,qQo),e(Bs,NQo),e(Bs,OV),e(OV,jQo),e(Bs,DQo),e(Bs,VV),e(VV,GQo),e(Bs,OQo),e(Fe,VQo),e(Fe,Hv),e(Hv,Jhe),e(Jhe,XQo),e(Hv,zQo),e(Hv,XV),e(XV,QQo),e(Hv,WQo),e(Fe,HQo),e(Fe,gt),e(gt,Yhe),e(Yhe,UQo),e(gt,JQo),e(gt,zV),e(zV,YQo),e(gt,KQo),e(gt,QV),e(QV,ZQo),e(gt,eWo),e(gt,WV),e(WV,oWo),e(gt,rWo),e(Fe,tWo),e(Fe,Uv),e(Uv,Khe),e(Khe,aWo),e(Uv,nWo),e(Uv,HV),e(HV,sWo),e(Uv,lWo),e(Fe,iWo),e(Fe,Jv),e(Jv,Zhe),e(Zhe,dWo),e(Jv,cWo),e(Jv,UV),e(UV,fWo),e(Jv,mWo),e(Fe,gWo),e(Fe,Yv),e(Yv,epe),e(epe,hWo),e(Yv,pWo),e(Yv,JV),e(JV,uWo),e(Yv,_Wo),e(Fe,bWo),e(Fe,Kv),e(Kv,ope),e(ope,vWo),e(Kv,FWo),e(Kv,YV),e(YV,TWo),e(Kv,MWo),e(Fe,EWo),e(Fe,Zv),e(Zv,rpe),e(rpe,CWo),e(Zv,wWo),e(Zv,KV),e(KV,AWo),e(Zv,yWo),e(Fe,LWo),e(Fe,eF),e(eF,tpe),e(tpe,xWo),e(eF,$Wo),e(eF,ZV),e(ZV,kWo),e(eF,SWo),e(Fe,RWo),e(Fe,oF),e(oF,ape),e(ape,BWo),e(oF,PWo),e(oF,eX),e(eX,IWo),e(oF,qWo),e(no,NWo),e(no,rF),e(rF,jWo),e(rF,npe),e(npe,DWo),e(rF,GWo),e(rF,spe),e(spe,OWo),e(no,VWo),M(tF,no,null),b(f,nqe,_),b(f,ad,_),e(ad,aF),e(aF,lpe),M(qy,lpe,null),e(ad,XWo),e(ad,ipe),e(ipe,zWo),b(f,sqe,_),b(f,Do,_),M(Ny,Do,null),e(Do,QWo),e(Do,nd),e(nd,WWo),e(nd,oX),e(oX,HWo),e(nd,UWo),e(nd,rX),e(rX,JWo),e(nd,YWo),e(Do,KWo),e(Do,jy),e(jy,ZWo),e(jy,dpe),e(dpe,eHo),e(jy,oHo),e(Do,rHo),e(Do,ht),M(Dy,ht,null),e(ht,tHo),e(ht,cpe),e(cpe,aHo),e(ht,nHo),e(ht,sd),e(sd,sHo),e(sd,fpe),e(fpe,lHo),e(sd,iHo),e(sd,tX),e(tX,dHo),e(sd,cHo),e(ht,fHo),M(nF,ht,null),e(Do,mHo),e(Do,so),M(Gy,so,null),e(so,gHo),e(so,mpe),e(mpe,hHo),e(so,pHo),e(so,Na),e(Na,uHo),e(Na,gpe),e(gpe,_Ho),e(Na,bHo),e(Na,hpe),e(hpe,vHo),e(Na,FHo),e(Na,ppe),e(ppe,THo),e(Na,MHo),e(so,EHo),e(so,upe),e(upe,sF),e(sF,_pe),e(_pe,CHo),e(sF,wHo),e(sF,aX),e(aX,AHo),e(sF,yHo),e(so,LHo),e(so,lF),e(lF,xHo),e(lF,bpe),e(bpe,$Ho),e(lF,kHo),e(lF,vpe),e(vpe,SHo),e(so,RHo),M(iF,so,null),b(f,lqe,_),b(f,ld,_),e(ld,dF),e(dF,Fpe),M(Oy,Fpe,null),e(ld,BHo),e(ld,Tpe),e(Tpe,PHo),b(f,iqe,_),b(f,Go,_),M(Vy,Go,null),e(Go,IHo),e(Go,id),e(id,qHo),e(id,nX),e(nX,NHo),e(id,jHo),e(id,sX),e(sX,DHo),e(id,GHo),e(Go,OHo),e(Go,Xy),e(Xy,VHo),e(Xy,Mpe),e(Mpe,XHo),e(Xy,zHo),e(Go,QHo),e(Go,pt),M(zy,pt,null),e(pt,WHo),e(pt,Epe),e(Epe,HHo),e(pt,UHo),e(pt,dd),e(dd,JHo),e(dd,Cpe),e(Cpe,YHo),e(dd,KHo),e(dd,lX),e(lX,ZHo),e(dd,eUo),e(pt,oUo),M(cF,pt,null),e(Go,rUo),e(Go,lo),M(Qy,lo,null),e(lo,tUo),e(lo,wpe),e(wpe,aUo),e(lo,nUo),e(lo,ja),e(ja,sUo),e(ja,Ape),e(Ape,lUo),e(ja,iUo),e(ja,ype),e(ype,dUo),e(ja,cUo),e(ja,Lpe),e(Lpe,fUo),e(ja,mUo),e(lo,gUo),e(lo,Ne),e(Ne,fF),e(fF,xpe),e(xpe,hUo),e(fF,pUo),e(fF,iX),e(iX,uUo),e(fF,_Uo),e(Ne,bUo),e(Ne,mF),e(mF,$pe),e($pe,vUo),e(mF,FUo),e(mF,dX),e(dX,TUo),e(mF,MUo),e(Ne,EUo),e(Ne,gF),e(gF,kpe),e(kpe,CUo),e(gF,wUo),e(gF,cX),e(cX,AUo),e(gF,yUo),e(Ne,LUo),e(Ne,hF),e(hF,Spe),e(Spe,xUo),e(hF,$Uo),e(hF,fX),e(fX,kUo),e(hF,SUo),e(Ne,RUo),e(Ne,pF),e(pF,Rpe),e(Rpe,BUo),e(pF,PUo),e(pF,mX),e(mX,IUo),e(pF,qUo),e(Ne,NUo),e(Ne,uF),e(uF,Bpe),e(Bpe,jUo),e(uF,DUo),e(uF,gX),e(gX,GUo),e(uF,OUo),e(Ne,VUo),e(Ne,_F),e(_F,Ppe),e(Ppe,XUo),e(_F,zUo),e(_F,hX),e(hX,QUo),e(_F,WUo),e(Ne,HUo),e(Ne,bF),e(bF,Ipe),e(Ipe,UUo),e(bF,JUo),e(bF,pX),e(pX,YUo),e(bF,KUo),e(lo,ZUo),e(lo,vF),e(vF,eJo),e(vF,qpe),e(qpe,oJo),e(vF,rJo),e(vF,Npe),e(Npe,tJo),e(lo,aJo),M(FF,lo,null),b(f,dqe,_),b(f,cd,_),e(cd,TF),e(TF,jpe),M(Wy,jpe,null),e(cd,nJo),e(cd,Dpe),e(Dpe,sJo),b(f,cqe,_),b(f,Oo,_),M(Hy,Oo,null),e(Oo,lJo),e(Oo,fd),e(fd,iJo),e(fd,uX),e(uX,dJo),e(fd,cJo),e(fd,_X),e(_X,fJo),e(fd,mJo),e(Oo,gJo),e(Oo,Uy),e(Uy,hJo),e(Uy,Gpe),e(Gpe,pJo),e(Uy,uJo),e(Oo,_Jo),e(Oo,ut),M(Jy,ut,null),e(ut,bJo),e(ut,Ope),e(Ope,vJo),e(ut,FJo),e(ut,md),e(md,TJo),e(md,Vpe),e(Vpe,MJo),e(md,EJo),e(md,bX),e(bX,CJo),e(md,wJo),e(ut,AJo),M(MF,ut,null),e(Oo,yJo),e(Oo,io),M(Yy,io,null),e(io,LJo),e(io,Xpe),e(Xpe,xJo),e(io,$Jo),e(io,Da),e(Da,kJo),e(Da,zpe),e(zpe,SJo),e(Da,RJo),e(Da,Qpe),e(Qpe,BJo),e(Da,PJo),e(Da,Wpe),e(Wpe,IJo),e(Da,qJo),e(io,NJo),e(io,Ga),e(Ga,EF),e(EF,Hpe),e(Hpe,jJo),e(EF,DJo),e(EF,vX),e(vX,GJo),e(EF,OJo),e(Ga,VJo),e(Ga,CF),e(CF,Upe),e(Upe,XJo),e(CF,zJo),e(CF,FX),e(FX,QJo),e(CF,WJo),e(Ga,HJo),e(Ga,wF),e(wF,Jpe),e(Jpe,UJo),e(wF,JJo),e(wF,TX),e(TX,YJo),e(wF,KJo),e(Ga,ZJo),e(Ga,AF),e(AF,Ype),e(Ype,eYo),e(AF,oYo),e(AF,MX),e(MX,rYo),e(AF,tYo),e(io,aYo),e(io,yF),e(yF,nYo),e(yF,Kpe),e(Kpe,sYo),e(yF,lYo),e(yF,Zpe),e(Zpe,iYo),e(io,dYo),M(LF,io,null),b(f,fqe,_),b(f,gd,_),e(gd,xF),e(xF,eue),M(Ky,eue,null),e(gd,cYo),e(gd,oue),e(oue,fYo),b(f,mqe,_),b(f,Vo,_),M(Zy,Vo,null),e(Vo,mYo),e(Vo,hd),e(hd,gYo),e(hd,EX),e(EX,hYo),e(hd,pYo),e(hd,CX),e(CX,uYo),e(hd,_Yo),e(Vo,bYo),e(Vo,eL),e(eL,vYo),e(eL,rue),e(rue,FYo),e(eL,TYo),e(Vo,MYo),e(Vo,_t),M(oL,_t,null),e(_t,EYo),e(_t,tue),e(tue,CYo),e(_t,wYo),e(_t,pd),e(pd,AYo),e(pd,aue),e(aue,yYo),e(pd,LYo),e(pd,wX),e(wX,xYo),e(pd,$Yo),e(_t,kYo),M($F,_t,null),e(Vo,SYo),e(Vo,co),M(rL,co,null),e(co,RYo),e(co,nue),e(nue,BYo),e(co,PYo),e(co,Oa),e(Oa,IYo),e(Oa,sue),e(sue,qYo),e(Oa,NYo),e(Oa,lue),e(lue,jYo),e(Oa,DYo),e(Oa,iue),e(iue,GYo),e(Oa,OYo),e(co,VYo),e(co,je),e(je,kF),e(kF,due),e(due,XYo),e(kF,zYo),e(kF,AX),e(AX,QYo),e(kF,WYo),e(je,HYo),e(je,SF),e(SF,cue),e(cue,UYo),e(SF,JYo),e(SF,yX),e(yX,YYo),e(SF,KYo),e(je,ZYo),e(je,RF),e(RF,fue),e(fue,eKo),e(RF,oKo),e(RF,LX),e(LX,rKo),e(RF,tKo),e(je,aKo),e(je,BF),e(BF,mue),e(mue,nKo),e(BF,sKo),e(BF,xX),e(xX,lKo),e(BF,iKo),e(je,dKo),e(je,PF),e(PF,gue),e(gue,cKo),e(PF,fKo),e(PF,$X),e($X,mKo),e(PF,gKo),e(je,hKo),e(je,IF),e(IF,hue),e(hue,pKo),e(IF,uKo),e(IF,kX),e(kX,_Ko),e(IF,bKo),e(je,vKo),e(je,qF),e(qF,pue),e(pue,FKo),e(qF,TKo),e(qF,SX),e(SX,MKo),e(qF,EKo),e(je,CKo),e(je,NF),e(NF,uue),e(uue,wKo),e(NF,AKo),e(NF,RX),e(RX,yKo),e(NF,LKo),e(co,xKo),e(co,jF),e(jF,$Ko),e(jF,_ue),e(_ue,kKo),e(jF,SKo),e(jF,bue),e(bue,RKo),e(co,BKo),M(DF,co,null),b(f,gqe,_),b(f,ud,_),e(ud,GF),e(GF,vue),M(tL,vue,null),e(ud,PKo),e(ud,Fue),e(Fue,IKo),b(f,hqe,_),b(f,Xo,_),M(aL,Xo,null),e(Xo,qKo),e(Xo,_d),e(_d,NKo),e(_d,BX),e(BX,jKo),e(_d,DKo),e(_d,PX),e(PX,GKo),e(_d,OKo),e(Xo,VKo),e(Xo,nL),e(nL,XKo),e(nL,Tue),e(Tue,zKo),e(nL,QKo),e(Xo,WKo),e(Xo,bt),M(sL,bt,null),e(bt,HKo),e(bt,Mue),e(Mue,UKo),e(bt,JKo),e(bt,bd),e(bd,YKo),e(bd,Eue),e(Eue,KKo),e(bd,ZKo),e(bd,IX),e(IX,eZo),e(bd,oZo),e(bt,rZo),M(OF,bt,null),e(Xo,tZo),e(Xo,fo),M(lL,fo,null),e(fo,aZo),e(fo,Cue),e(Cue,nZo),e(fo,sZo),e(fo,Va),e(Va,lZo),e(Va,wue),e(wue,iZo),e(Va,dZo),e(Va,Aue),e(Aue,cZo),e(Va,fZo),e(Va,yue),e(yue,mZo),e(Va,gZo),e(fo,hZo),e(fo,iL),e(iL,VF),e(VF,Lue),e(Lue,pZo),e(VF,uZo),e(VF,qX),e(qX,_Zo),e(VF,bZo),e(iL,vZo),e(iL,XF),e(XF,xue),e(xue,FZo),e(XF,TZo),e(XF,NX),e(NX,MZo),e(XF,EZo),e(fo,CZo),e(fo,zF),e(zF,wZo),e(zF,$ue),e($ue,AZo),e(zF,yZo),e(zF,kue),e(kue,LZo),e(fo,xZo),M(QF,fo,null),b(f,pqe,_),b(f,vd,_),e(vd,WF),e(WF,Sue),M(dL,Sue,null),e(vd,$Zo),e(vd,Rue),e(Rue,kZo),b(f,uqe,_),b(f,zo,_),M(cL,zo,null),e(zo,SZo),e(zo,Fd),e(Fd,RZo),e(Fd,jX),e(jX,BZo),e(Fd,PZo),e(Fd,DX),e(DX,IZo),e(Fd,qZo),e(zo,NZo),e(zo,fL),e(fL,jZo),e(fL,Bue),e(Bue,DZo),e(fL,GZo),e(zo,OZo),e(zo,vt),M(mL,vt,null),e(vt,VZo),e(vt,Pue),e(Pue,XZo),e(vt,zZo),e(vt,Td),e(Td,QZo),e(Td,Iue),e(Iue,WZo),e(Td,HZo),e(Td,GX),e(GX,UZo),e(Td,JZo),e(vt,YZo),M(HF,vt,null),e(zo,KZo),e(zo,mo),M(gL,mo,null),e(mo,ZZo),e(mo,que),e(que,eer),e(mo,oer),e(mo,Xa),e(Xa,rer),e(Xa,Nue),e(Nue,ter),e(Xa,aer),e(Xa,jue),e(jue,ner),e(Xa,ser),e(Xa,Due),e(Due,ler),e(Xa,ier),e(mo,der),e(mo,za),e(za,UF),e(UF,Gue),e(Gue,cer),e(UF,fer),e(UF,OX),e(OX,mer),e(UF,ger),e(za,her),e(za,JF),e(JF,Oue),e(Oue,per),e(JF,uer),e(JF,VX),e(VX,_er),e(JF,ber),e(za,ver),e(za,YF),e(YF,Vue),e(Vue,Fer),e(YF,Ter),e(YF,XX),e(XX,Mer),e(YF,Eer),e(za,Cer),e(za,KF),e(KF,Xue),e(Xue,wer),e(KF,Aer),e(KF,zX),e(zX,yer),e(KF,Ler),e(mo,xer),e(mo,ZF),e(ZF,$er),e(ZF,zue),e(zue,ker),e(ZF,Ser),e(ZF,Que),e(Que,Rer),e(mo,Ber),M(e6,mo,null),b(f,_qe,_),b(f,Md,_),e(Md,o6),e(o6,Wue),M(hL,Wue,null),e(Md,Per),e(Md,Hue),e(Hue,Ier),b(f,bqe,_),b(f,Qo,_),M(pL,Qo,null),e(Qo,qer),e(Qo,Ed),e(Ed,Ner),e(Ed,QX),e(QX,jer),e(Ed,Der),e(Ed,WX),e(WX,Ger),e(Ed,Oer),e(Qo,Ver),e(Qo,uL),e(uL,Xer),e(uL,Uue),e(Uue,zer),e(uL,Qer),e(Qo,Wer),e(Qo,Ft),M(_L,Ft,null),e(Ft,Her),e(Ft,Jue),e(Jue,Uer),e(Ft,Jer),e(Ft,Cd),e(Cd,Yer),e(Cd,Yue),e(Yue,Ker),e(Cd,Zer),e(Cd,HX),e(HX,eor),e(Cd,oor),e(Ft,ror),M(r6,Ft,null),e(Qo,tor),e(Qo,go),M(bL,go,null),e(go,aor),e(go,Kue),e(Kue,nor),e(go,sor),e(go,Qa),e(Qa,lor),e(Qa,Zue),e(Zue,ior),e(Qa,dor),e(Qa,e_e),e(e_e,cor),e(Qa,mor),e(Qa,o_e),e(o_e,gor),e(Qa,hor),e(go,por),e(go,wd),e(wd,t6),e(t6,r_e),e(r_e,uor),e(t6,_or),e(t6,UX),e(UX,bor),e(t6,vor),e(wd,For),e(wd,a6),e(a6,t_e),e(t_e,Tor),e(a6,Mor),e(a6,JX),e(JX,Eor),e(a6,Cor),e(wd,wor),e(wd,n6),e(n6,a_e),e(a_e,Aor),e(n6,yor),e(n6,YX),e(YX,Lor),e(n6,xor),e(go,$or),e(go,s6),e(s6,kor),e(s6,n_e),e(n_e,Sor),e(s6,Ror),e(s6,s_e),e(s_e,Bor),e(go,Por),M(l6,go,null),b(f,vqe,_),b(f,Ad,_),e(Ad,i6),e(i6,l_e),M(vL,l_e,null),e(Ad,Ior),e(Ad,i_e),e(i_e,qor),b(f,Fqe,_),b(f,Wo,_),M(FL,Wo,null),e(Wo,Nor),e(Wo,yd),e(yd,jor),e(yd,KX),e(KX,Dor),e(yd,Gor),e(yd,ZX),e(ZX,Oor),e(yd,Vor),e(Wo,Xor),e(Wo,TL),e(TL,zor),e(TL,d_e),e(d_e,Qor),e(TL,Wor),e(Wo,Hor),e(Wo,Tt),M(ML,Tt,null),e(Tt,Uor),e(Tt,c_e),e(c_e,Jor),e(Tt,Yor),e(Tt,Ld),e(Ld,Kor),e(Ld,f_e),e(f_e,Zor),e(Ld,err),e(Ld,ez),e(ez,orr),e(Ld,rrr),e(Tt,trr),M(d6,Tt,null),e(Wo,arr),e(Wo,ho),M(EL,ho,null),e(ho,nrr),e(ho,m_e),e(m_e,srr),e(ho,lrr),e(ho,Wa),e(Wa,irr),e(Wa,g_e),e(g_e,drr),e(Wa,crr),e(Wa,h_e),e(h_e,frr),e(Wa,mrr),e(Wa,p_e),e(p_e,grr),e(Wa,hrr),e(ho,prr),e(ho,CL),e(CL,c6),e(c6,u_e),e(u_e,urr),e(c6,_rr),e(c6,oz),e(oz,brr),e(c6,vrr),e(CL,Frr),e(CL,f6),e(f6,__e),e(__e,Trr),e(f6,Mrr),e(f6,rz),e(rz,Err),e(f6,Crr),e(ho,wrr),e(ho,m6),e(m6,Arr),e(m6,b_e),e(b_e,yrr),e(m6,Lrr),e(m6,v_e),e(v_e,xrr),e(ho,$rr),M(g6,ho,null),b(f,Tqe,_),b(f,xd,_),e(xd,h6),e(h6,F_e),M(wL,F_e,null),e(xd,krr),e(xd,T_e),e(T_e,Srr),b(f,Mqe,_),b(f,Ho,_),M(AL,Ho,null),e(Ho,Rrr),e(Ho,$d),e($d,Brr),e($d,tz),e(tz,Prr),e($d,Irr),e($d,az),e(az,qrr),e($d,Nrr),e(Ho,jrr),e(Ho,yL),e(yL,Drr),e(yL,M_e),e(M_e,Grr),e(yL,Orr),e(Ho,Vrr),e(Ho,Mt),M(LL,Mt,null),e(Mt,Xrr),e(Mt,E_e),e(E_e,zrr),e(Mt,Qrr),e(Mt,kd),e(kd,Wrr),e(kd,C_e),e(C_e,Hrr),e(kd,Urr),e(kd,nz),e(nz,Jrr),e(kd,Yrr),e(Mt,Krr),M(p6,Mt,null),e(Ho,Zrr),e(Ho,po),M(xL,po,null),e(po,etr),e(po,w_e),e(w_e,otr),e(po,rtr),e(po,Ha),e(Ha,ttr),e(Ha,A_e),e(A_e,atr),e(Ha,ntr),e(Ha,y_e),e(y_e,str),e(Ha,ltr),e(Ha,L_e),e(L_e,itr),e(Ha,dtr),e(po,ctr),e(po,x_e),e(x_e,u6),e(u6,$_e),e($_e,ftr),e(u6,mtr),e(u6,sz),e(sz,gtr),e(u6,htr),e(po,ptr),e(po,_6),e(_6,utr),e(_6,k_e),e(k_e,_tr),e(_6,btr),e(_6,S_e),e(S_e,vtr),e(po,Ftr),M(b6,po,null),b(f,Eqe,_),b(f,Sd,_),e(Sd,v6),e(v6,R_e),M($L,R_e,null),e(Sd,Ttr),e(Sd,B_e),e(B_e,Mtr),b(f,Cqe,_),b(f,Uo,_),M(kL,Uo,null),e(Uo,Etr),e(Uo,Rd),e(Rd,Ctr),e(Rd,lz),e(lz,wtr),e(Rd,Atr),e(Rd,iz),e(iz,ytr),e(Rd,Ltr),e(Uo,xtr),e(Uo,SL),e(SL,$tr),e(SL,P_e),e(P_e,ktr),e(SL,Str),e(Uo,Rtr),e(Uo,Et),M(RL,Et,null),e(Et,Btr),e(Et,I_e),e(I_e,Ptr),e(Et,Itr),e(Et,Bd),e(Bd,qtr),e(Bd,q_e),e(q_e,Ntr),e(Bd,jtr),e(Bd,dz),e(dz,Dtr),e(Bd,Gtr),e(Et,Otr),M(F6,Et,null),e(Uo,Vtr),e(Uo,uo),M(BL,uo,null),e(uo,Xtr),e(uo,N_e),e(N_e,ztr),e(uo,Qtr),e(uo,Ua),e(Ua,Wtr),e(Ua,j_e),e(j_e,Htr),e(Ua,Utr),e(Ua,D_e),e(D_e,Jtr),e(Ua,Ytr),e(Ua,G_e),e(G_e,Ktr),e(Ua,Ztr),e(uo,ear),e(uo,Ja),e(Ja,T6),e(T6,O_e),e(O_e,oar),e(T6,rar),e(T6,cz),e(cz,tar),e(T6,aar),e(Ja,nar),e(Ja,M6),e(M6,V_e),e(V_e,sar),e(M6,lar),e(M6,fz),e(fz,iar),e(M6,dar),e(Ja,car),e(Ja,E6),e(E6,X_e),e(X_e,far),e(E6,mar),e(E6,mz),e(mz,gar),e(E6,har),e(Ja,par),e(Ja,C6),e(C6,z_e),e(z_e,uar),e(C6,_ar),e(C6,gz),e(gz,bar),e(C6,Far),e(uo,Tar),e(uo,w6),e(w6,Mar),e(w6,Q_e),e(Q_e,Ear),e(w6,Car),e(w6,W_e),e(W_e,war),e(uo,Aar),M(A6,uo,null),b(f,wqe,_),b(f,Pd,_),e(Pd,y6),e(y6,H_e),M(PL,H_e,null),e(Pd,yar),e(Pd,U_e),e(U_e,Lar),b(f,Aqe,_),b(f,Jo,_),M(IL,Jo,null),e(Jo,xar),e(Jo,Id),e(Id,$ar),e(Id,hz),e(hz,kar),e(Id,Sar),e(Id,pz),e(pz,Rar),e(Id,Bar),e(Jo,Par),e(Jo,qL),e(qL,Iar),e(qL,J_e),e(J_e,qar),e(qL,Nar),e(Jo,jar),e(Jo,Ct),M(NL,Ct,null),e(Ct,Dar),e(Ct,Y_e),e(Y_e,Gar),e(Ct,Oar),e(Ct,qd),e(qd,Var),e(qd,K_e),e(K_e,Xar),e(qd,zar),e(qd,uz),e(uz,Qar),e(qd,War),e(Ct,Har),M(L6,Ct,null),e(Jo,Uar),e(Jo,_o),M(jL,_o,null),e(_o,Jar),e(_o,Z_e),e(Z_e,Yar),e(_o,Kar),e(_o,Ya),e(Ya,Zar),e(Ya,e0e),e(e0e,enr),e(Ya,onr),e(Ya,o0e),e(o0e,rnr),e(Ya,tnr),e(Ya,r0e),e(r0e,anr),e(Ya,nnr),e(_o,snr),e(_o,t0e),e(t0e,x6),e(x6,a0e),e(a0e,lnr),e(x6,inr),e(x6,_z),e(_z,dnr),e(x6,cnr),e(_o,fnr),e(_o,$6),e($6,mnr),e($6,n0e),e(n0e,gnr),e($6,hnr),e($6,s0e),e(s0e,pnr),e(_o,unr),M(k6,_o,null),b(f,yqe,_),b(f,Nd,_),e(Nd,S6),e(S6,l0e),M(DL,l0e,null),e(Nd,_nr),e(Nd,i0e),e(i0e,bnr),b(f,Lqe,_),b(f,Yo,_),M(GL,Yo,null),e(Yo,vnr),e(Yo,jd),e(jd,Fnr),e(jd,bz),e(bz,Tnr),e(jd,Mnr),e(jd,vz),e(vz,Enr),e(jd,Cnr),e(Yo,wnr),e(Yo,OL),e(OL,Anr),e(OL,d0e),e(d0e,ynr),e(OL,Lnr),e(Yo,xnr),e(Yo,wt),M(VL,wt,null),e(wt,$nr),e(wt,c0e),e(c0e,knr),e(wt,Snr),e(wt,Dd),e(Dd,Rnr),e(Dd,f0e),e(f0e,Bnr),e(Dd,Pnr),e(Dd,Fz),e(Fz,Inr),e(Dd,qnr),e(wt,Nnr),M(R6,wt,null),e(Yo,jnr),e(Yo,wr),M(XL,wr,null),e(wr,Dnr),e(wr,m0e),e(m0e,Gnr),e(wr,Onr),e(wr,Ka),e(Ka,Vnr),e(Ka,g0e),e(g0e,Xnr),e(Ka,znr),e(Ka,h0e),e(h0e,Qnr),e(Ka,Wnr),e(Ka,p0e),e(p0e,Hnr),e(Ka,Unr),e(wr,Jnr),e(wr,j),e(j,B6),e(B6,u0e),e(u0e,Ynr),e(B6,Knr),e(B6,Tz),e(Tz,Znr),e(B6,esr),e(j,osr),e(j,P6),e(P6,_0e),e(_0e,rsr),e(P6,tsr),e(P6,Mz),e(Mz,asr),e(P6,nsr),e(j,ssr),e(j,I6),e(I6,b0e),e(b0e,lsr),e(I6,isr),e(I6,Ez),e(Ez,dsr),e(I6,csr),e(j,fsr),e(j,q6),e(q6,v0e),e(v0e,msr),e(q6,gsr),e(q6,Cz),e(Cz,hsr),e(q6,psr),e(j,usr),e(j,N6),e(N6,F0e),e(F0e,_sr),e(N6,bsr),e(N6,wz),e(wz,vsr),e(N6,Fsr),e(j,Tsr),e(j,j6),e(j6,T0e),e(T0e,Msr),e(j6,Esr),e(j6,Az),e(Az,Csr),e(j6,wsr),e(j,Asr),e(j,D6),e(D6,M0e),e(M0e,ysr),e(D6,Lsr),e(D6,yz),e(yz,xsr),e(D6,$sr),e(j,ksr),e(j,G6),e(G6,E0e),e(E0e,Ssr),e(G6,Rsr),e(G6,Lz),e(Lz,Bsr),e(G6,Psr),e(j,Isr),e(j,O6),e(O6,C0e),e(C0e,qsr),e(O6,Nsr),e(O6,xz),e(xz,jsr),e(O6,Dsr),e(j,Gsr),e(j,V6),e(V6,w0e),e(w0e,Osr),e(V6,Vsr),e(V6,$z),e($z,Xsr),e(V6,zsr),e(j,Qsr),e(j,X6),e(X6,A0e),e(A0e,Wsr),e(X6,Hsr),e(X6,kz),e(kz,Usr),e(X6,Jsr),e(j,Ysr),e(j,z6),e(z6,y0e),e(y0e,Ksr),e(z6,Zsr),e(z6,Sz),e(Sz,elr),e(z6,olr),e(j,rlr),e(j,Q6),e(Q6,L0e),e(L0e,tlr),e(Q6,alr),e(Q6,Rz),e(Rz,nlr),e(Q6,slr),e(j,llr),e(j,W6),e(W6,x0e),e(x0e,ilr),e(W6,dlr),e(W6,Bz),e(Bz,clr),e(W6,flr),e(j,mlr),e(j,H6),e(H6,$0e),e($0e,glr),e(H6,hlr),e(H6,Pz),e(Pz,plr),e(H6,ulr),e(j,_lr),e(j,U6),e(U6,k0e),e(k0e,blr),e(U6,vlr),e(U6,Iz),e(Iz,Flr),e(U6,Tlr),e(j,Mlr),e(j,J6),e(J6,S0e),e(S0e,Elr),e(J6,Clr),e(J6,qz),e(qz,wlr),e(J6,Alr),e(j,ylr),e(j,Ps),e(Ps,R0e),e(R0e,Llr),e(Ps,xlr),e(Ps,Nz),e(Nz,$lr),e(Ps,klr),e(Ps,jz),e(jz,Slr),e(Ps,Rlr),e(j,Blr),e(j,Y6),e(Y6,B0e),e(B0e,Plr),e(Y6,Ilr),e(Y6,Dz),e(Dz,qlr),e(Y6,Nlr),e(j,jlr),e(j,K6),e(K6,P0e),e(P0e,Dlr),e(K6,Glr),e(K6,Gz),e(Gz,Olr),e(K6,Vlr),e(j,Xlr),e(j,Z6),e(Z6,I0e),e(I0e,zlr),e(Z6,Qlr),e(Z6,Oz),e(Oz,Wlr),e(Z6,Hlr),e(j,Ulr),e(j,eT),e(eT,q0e),e(q0e,Jlr),e(eT,Ylr),e(eT,Vz),e(Vz,Klr),e(eT,Zlr),e(j,eir),e(j,oT),e(oT,N0e),e(N0e,oir),e(oT,rir),e(oT,Xz),e(Xz,tir),e(oT,air),e(j,nir),e(j,rT),e(rT,j0e),e(j0e,sir),e(rT,lir),e(rT,zz),e(zz,iir),e(rT,dir),e(j,cir),e(j,tT),e(tT,D0e),e(D0e,fir),e(tT,mir),e(tT,Qz),e(Qz,gir),e(tT,hir),e(j,pir),e(j,aT),e(aT,G0e),e(G0e,uir),e(aT,_ir),e(aT,Wz),e(Wz,bir),e(aT,vir),e(j,Fir),e(j,nT),e(nT,O0e),e(O0e,Tir),e(nT,Mir),e(nT,Hz),e(Hz,Eir),e(nT,Cir),e(j,wir),e(j,sT),e(sT,V0e),e(V0e,Air),e(sT,yir),e(sT,Uz),e(Uz,Lir),e(sT,xir),e(j,$ir),e(j,lT),e(lT,X0e),e(X0e,kir),e(lT,Sir),e(lT,Jz),e(Jz,Rir),e(lT,Bir),e(j,Pir),e(j,iT),e(iT,z0e),e(z0e,Iir),e(iT,qir),e(iT,Yz),e(Yz,Nir),e(iT,jir),e(j,Dir),e(j,dT),e(dT,Q0e),e(Q0e,Gir),e(dT,Oir),e(dT,Kz),e(Kz,Vir),e(dT,Xir),e(j,zir),e(j,cT),e(cT,W0e),e(W0e,Qir),e(cT,Wir),e(cT,Zz),e(Zz,Hir),e(cT,Uir),e(j,Jir),e(j,fT),e(fT,H0e),e(H0e,Yir),e(fT,Kir),e(fT,eQ),e(eQ,Zir),e(fT,edr),e(j,odr),e(j,mT),e(mT,U0e),e(U0e,rdr),e(mT,tdr),e(mT,oQ),e(oQ,adr),e(mT,ndr),e(j,sdr),e(j,gT),e(gT,J0e),e(J0e,ldr),e(gT,idr),e(gT,rQ),e(rQ,ddr),e(gT,cdr),e(j,fdr),e(j,hT),e(hT,Y0e),e(Y0e,mdr),e(hT,gdr),e(hT,tQ),e(tQ,hdr),e(hT,pdr),e(j,udr),e(j,pT),e(pT,K0e),e(K0e,_dr),e(pT,bdr),e(pT,aQ),e(aQ,vdr),e(pT,Fdr),e(j,Tdr),e(j,uT),e(uT,Z0e),e(Z0e,Mdr),e(uT,Edr),e(uT,nQ),e(nQ,Cdr),e(uT,wdr),e(j,Adr),e(j,_T),e(_T,e1e),e(e1e,ydr),e(_T,Ldr),e(_T,sQ),e(sQ,xdr),e(_T,$dr),e(j,kdr),e(j,bT),e(bT,o1e),e(o1e,Sdr),e(bT,Rdr),e(bT,lQ),e(lQ,Bdr),e(bT,Pdr),e(j,Idr),e(j,vT),e(vT,r1e),e(r1e,qdr),e(vT,Ndr),e(vT,iQ),e(iQ,jdr),e(vT,Ddr),e(j,Gdr),e(j,FT),e(FT,t1e),e(t1e,Odr),e(FT,Vdr),e(FT,dQ),e(dQ,Xdr),e(FT,zdr),e(j,Qdr),e(j,TT),e(TT,a1e),e(a1e,Wdr),e(TT,Hdr),e(TT,cQ),e(cQ,Udr),e(TT,Jdr),e(j,Ydr),e(j,MT),e(MT,n1e),e(n1e,Kdr),e(MT,Zdr),e(MT,fQ),e(fQ,ecr),e(MT,ocr),e(j,rcr),e(j,ET),e(ET,s1e),e(s1e,tcr),e(ET,acr),e(ET,mQ),e(mQ,ncr),e(ET,scr),e(wr,lcr),M(CT,wr,null),b(f,xqe,_),b(f,Gd,_),e(Gd,wT),e(wT,l1e),M(zL,l1e,null),e(Gd,icr),e(Gd,i1e),e(i1e,dcr),b(f,$qe,_),b(f,Ko,_),M(QL,Ko,null),e(Ko,ccr),e(Ko,Od),e(Od,fcr),e(Od,gQ),e(gQ,mcr),e(Od,gcr),e(Od,hQ),e(hQ,hcr),e(Od,pcr),e(Ko,ucr),e(Ko,WL),e(WL,_cr),e(WL,d1e),e(d1e,bcr),e(WL,vcr),e(Ko,Fcr),e(Ko,At),M(HL,At,null),e(At,Tcr),e(At,c1e),e(c1e,Mcr),e(At,Ecr),e(At,Vd),e(Vd,Ccr),e(Vd,f1e),e(f1e,wcr),e(Vd,Acr),e(Vd,pQ),e(pQ,ycr),e(Vd,Lcr),e(At,xcr),M(AT,At,null),e(Ko,$cr),e(Ko,Ar),M(UL,Ar,null),e(Ar,kcr),e(Ar,m1e),e(m1e,Scr),e(Ar,Rcr),e(Ar,Za),e(Za,Bcr),e(Za,g1e),e(g1e,Pcr),e(Za,Icr),e(Za,h1e),e(h1e,qcr),e(Za,Ncr),e(Za,p1e),e(p1e,jcr),e(Za,Dcr),e(Ar,Gcr),e(Ar,se),e(se,yT),e(yT,u1e),e(u1e,Ocr),e(yT,Vcr),e(yT,uQ),e(uQ,Xcr),e(yT,zcr),e(se,Qcr),e(se,LT),e(LT,_1e),e(_1e,Wcr),e(LT,Hcr),e(LT,_Q),e(_Q,Ucr),e(LT,Jcr),e(se,Ycr),e(se,xT),e(xT,b1e),e(b1e,Kcr),e(xT,Zcr),e(xT,bQ),e(bQ,efr),e(xT,ofr),e(se,rfr),e(se,$T),e($T,v1e),e(v1e,tfr),e($T,afr),e($T,vQ),e(vQ,nfr),e($T,sfr),e(se,lfr),e(se,kT),e(kT,F1e),e(F1e,ifr),e(kT,dfr),e(kT,FQ),e(FQ,cfr),e(kT,ffr),e(se,mfr),e(se,ST),e(ST,T1e),e(T1e,gfr),e(ST,hfr),e(ST,TQ),e(TQ,pfr),e(ST,ufr),e(se,_fr),e(se,RT),e(RT,M1e),e(M1e,bfr),e(RT,vfr),e(RT,MQ),e(MQ,Ffr),e(RT,Tfr),e(se,Mfr),e(se,BT),e(BT,E1e),e(E1e,Efr),e(BT,Cfr),e(BT,EQ),e(EQ,wfr),e(BT,Afr),e(se,yfr),e(se,PT),e(PT,C1e),e(C1e,Lfr),e(PT,xfr),e(PT,CQ),e(CQ,$fr),e(PT,kfr),e(se,Sfr),e(se,IT),e(IT,w1e),e(w1e,Rfr),e(IT,Bfr),e(IT,wQ),e(wQ,Pfr),e(IT,Ifr),e(se,qfr),e(se,qT),e(qT,A1e),e(A1e,Nfr),e(qT,jfr),e(qT,AQ),e(AQ,Dfr),e(qT,Gfr),e(se,Ofr),e(se,NT),e(NT,y1e),e(y1e,Vfr),e(NT,Xfr),e(NT,yQ),e(yQ,zfr),e(NT,Qfr),e(se,Wfr),e(se,jT),e(jT,L1e),e(L1e,Hfr),e(jT,Ufr),e(jT,LQ),e(LQ,Jfr),e(jT,Yfr),e(se,Kfr),e(se,DT),e(DT,x1e),e(x1e,Zfr),e(DT,emr),e(DT,xQ),e(xQ,omr),e(DT,rmr),e(se,tmr),e(se,GT),e(GT,$1e),e($1e,amr),e(GT,nmr),e(GT,$Q),e($Q,smr),e(GT,lmr),e(se,imr),e(se,OT),e(OT,k1e),e(k1e,dmr),e(OT,cmr),e(OT,kQ),e(kQ,fmr),e(OT,mmr),e(se,gmr),e(se,VT),e(VT,S1e),e(S1e,hmr),e(VT,pmr),e(VT,SQ),e(SQ,umr),e(VT,_mr),e(se,bmr),e(se,XT),e(XT,R1e),e(R1e,vmr),e(XT,Fmr),e(XT,RQ),e(RQ,Tmr),e(XT,Mmr),e(se,Emr),e(se,zT),e(zT,B1e),e(B1e,Cmr),e(zT,wmr),e(zT,BQ),e(BQ,Amr),e(zT,ymr),e(se,Lmr),e(se,QT),e(QT,P1e),e(P1e,xmr),e(QT,$mr),e(QT,PQ),e(PQ,kmr),e(QT,Smr),e(se,Rmr),e(se,WT),e(WT,I1e),e(I1e,Bmr),e(WT,Pmr),e(WT,IQ),e(IQ,Imr),e(WT,qmr),e(se,Nmr),e(se,HT),e(HT,q1e),e(q1e,jmr),e(HT,Dmr),e(HT,qQ),e(qQ,Gmr),e(HT,Omr),e(se,Vmr),e(se,UT),e(UT,N1e),e(N1e,Xmr),e(UT,zmr),e(UT,NQ),e(NQ,Qmr),e(UT,Wmr),e(Ar,Hmr),M(JT,Ar,null),b(f,kqe,_),b(f,Xd,_),e(Xd,YT),e(YT,j1e),M(JL,j1e,null),e(Xd,Umr),e(Xd,D1e),e(D1e,Jmr),b(f,Sqe,_),b(f,Zo,_),M(YL,Zo,null),e(Zo,Ymr),e(Zo,zd),e(zd,Kmr),e(zd,jQ),e(jQ,Zmr),e(zd,egr),e(zd,DQ),e(DQ,ogr),e(zd,rgr),e(Zo,tgr),e(Zo,KL),e(KL,agr),e(KL,G1e),e(G1e,ngr),e(KL,sgr),e(Zo,lgr),e(Zo,yt),M(ZL,yt,null),e(yt,igr),e(yt,O1e),e(O1e,dgr),e(yt,cgr),e(yt,Qd),e(Qd,fgr),e(Qd,V1e),e(V1e,mgr),e(Qd,ggr),e(Qd,GQ),e(GQ,hgr),e(Qd,pgr),e(yt,ugr),M(KT,yt,null),e(Zo,_gr),e(Zo,yr),M(e8,yr,null),e(yr,bgr),e(yr,X1e),e(X1e,vgr),e(yr,Fgr),e(yr,en),e(en,Tgr),e(en,z1e),e(z1e,Mgr),e(en,Egr),e(en,Q1e),e(Q1e,Cgr),e(en,wgr),e(en,W1e),e(W1e,Agr),e(en,ygr),e(yr,Lgr),e(yr,Te),e(Te,ZT),e(ZT,H1e),e(H1e,xgr),e(ZT,$gr),e(ZT,OQ),e(OQ,kgr),e(ZT,Sgr),e(Te,Rgr),e(Te,e7),e(e7,U1e),e(U1e,Bgr),e(e7,Pgr),e(e7,VQ),e(VQ,Igr),e(e7,qgr),e(Te,Ngr),e(Te,o7),e(o7,J1e),e(J1e,jgr),e(o7,Dgr),e(o7,XQ),e(XQ,Ggr),e(o7,Ogr),e(Te,Vgr),e(Te,r7),e(r7,Y1e),e(Y1e,Xgr),e(r7,zgr),e(r7,zQ),e(zQ,Qgr),e(r7,Wgr),e(Te,Hgr),e(Te,t7),e(t7,K1e),e(K1e,Ugr),e(t7,Jgr),e(t7,QQ),e(QQ,Ygr),e(t7,Kgr),e(Te,Zgr),e(Te,a7),e(a7,Z1e),e(Z1e,ehr),e(a7,ohr),e(a7,WQ),e(WQ,rhr),e(a7,thr),e(Te,ahr),e(Te,n7),e(n7,ebe),e(ebe,nhr),e(n7,shr),e(n7,HQ),e(HQ,lhr),e(n7,ihr),e(Te,dhr),e(Te,s7),e(s7,obe),e(obe,chr),e(s7,fhr),e(s7,UQ),e(UQ,mhr),e(s7,ghr),e(Te,hhr),e(Te,l7),e(l7,rbe),e(rbe,phr),e(l7,uhr),e(l7,JQ),e(JQ,_hr),e(l7,bhr),e(Te,vhr),e(Te,i7),e(i7,tbe),e(tbe,Fhr),e(i7,Thr),e(i7,YQ),e(YQ,Mhr),e(i7,Ehr),e(Te,Chr),e(Te,d7),e(d7,abe),e(abe,whr),e(d7,Ahr),e(d7,KQ),e(KQ,yhr),e(d7,Lhr),e(Te,xhr),e(Te,c7),e(c7,nbe),e(nbe,$hr),e(c7,khr),e(c7,ZQ),e(ZQ,Shr),e(c7,Rhr),e(yr,Bhr),M(f7,yr,null),b(f,Rqe,_),b(f,Wd,_),e(Wd,m7),e(m7,sbe),M(o8,sbe,null),e(Wd,Phr),e(Wd,lbe),e(lbe,Ihr),b(f,Bqe,_),b(f,er,_),M(r8,er,null),e(er,qhr),e(er,Hd),e(Hd,Nhr),e(Hd,eW),e(eW,jhr),e(Hd,Dhr),e(Hd,oW),e(oW,Ghr),e(Hd,Ohr),e(er,Vhr),e(er,t8),e(t8,Xhr),e(t8,ibe),e(ibe,zhr),e(t8,Qhr),e(er,Whr),e(er,Lt),M(a8,Lt,null),e(Lt,Hhr),e(Lt,dbe),e(dbe,Uhr),e(Lt,Jhr),e(Lt,Ud),e(Ud,Yhr),e(Ud,cbe),e(cbe,Khr),e(Ud,Zhr),e(Ud,rW),e(rW,epr),e(Ud,opr),e(Lt,rpr),M(g7,Lt,null),e(er,tpr),e(er,Lr),M(n8,Lr,null),e(Lr,apr),e(Lr,fbe),e(fbe,npr),e(Lr,spr),e(Lr,on),e(on,lpr),e(on,mbe),e(mbe,ipr),e(on,dpr),e(on,gbe),e(gbe,cpr),e(on,fpr),e(on,hbe),e(hbe,mpr),e(on,gpr),e(Lr,hpr),e(Lr,Jd),e(Jd,h7),e(h7,pbe),e(pbe,ppr),e(h7,upr),e(h7,tW),e(tW,_pr),e(h7,bpr),e(Jd,vpr),e(Jd,p7),e(p7,ube),e(ube,Fpr),e(p7,Tpr),e(p7,aW),e(aW,Mpr),e(p7,Epr),e(Jd,Cpr),e(Jd,u7),e(u7,_be),e(_be,wpr),e(u7,Apr),e(u7,nW),e(nW,ypr),e(u7,Lpr),e(Lr,xpr),M(_7,Lr,null),b(f,Pqe,_),b(f,Yd,_),e(Yd,b7),e(b7,bbe),M(s8,bbe,null),e(Yd,$pr),e(Yd,vbe),e(vbe,kpr),b(f,Iqe,_),b(f,or,_),M(l8,or,null),e(or,Spr),e(or,Kd),e(Kd,Rpr),e(Kd,sW),e(sW,Bpr),e(Kd,Ppr),e(Kd,lW),e(lW,Ipr),e(Kd,qpr),e(or,Npr),e(or,i8),e(i8,jpr),e(i8,Fbe),e(Fbe,Dpr),e(i8,Gpr),e(or,Opr),e(or,xt),M(d8,xt,null),e(xt,Vpr),e(xt,Tbe),e(Tbe,Xpr),e(xt,zpr),e(xt,Zd),e(Zd,Qpr),e(Zd,Mbe),e(Mbe,Wpr),e(Zd,Hpr),e(Zd,iW),e(iW,Upr),e(Zd,Jpr),e(xt,Ypr),M(v7,xt,null),e(or,Kpr),e(or,xr),M(c8,xr,null),e(xr,Zpr),e(xr,Ebe),e(Ebe,eur),e(xr,our),e(xr,rn),e(rn,rur),e(rn,Cbe),e(Cbe,tur),e(rn,aur),e(rn,wbe),e(wbe,nur),e(rn,sur),e(rn,Abe),e(Abe,lur),e(rn,iur),e(xr,dur),e(xr,ie),e(ie,F7),e(F7,ybe),e(ybe,cur),e(F7,fur),e(F7,dW),e(dW,mur),e(F7,gur),e(ie,hur),e(ie,T7),e(T7,Lbe),e(Lbe,pur),e(T7,uur),e(T7,cW),e(cW,_ur),e(T7,bur),e(ie,vur),e(ie,M7),e(M7,xbe),e(xbe,Fur),e(M7,Tur),e(M7,fW),e(fW,Mur),e(M7,Eur),e(ie,Cur),e(ie,E7),e(E7,$be),e($be,wur),e(E7,Aur),e(E7,mW),e(mW,yur),e(E7,Lur),e(ie,xur),e(ie,C7),e(C7,kbe),e(kbe,$ur),e(C7,kur),e(C7,gW),e(gW,Sur),e(C7,Rur),e(ie,Bur),e(ie,w7),e(w7,Sbe),e(Sbe,Pur),e(w7,Iur),e(w7,hW),e(hW,qur),e(w7,Nur),e(ie,jur),e(ie,A7),e(A7,Rbe),e(Rbe,Dur),e(A7,Gur),e(A7,pW),e(pW,Our),e(A7,Vur),e(ie,Xur),e(ie,y7),e(y7,Bbe),e(Bbe,zur),e(y7,Qur),e(y7,uW),e(uW,Wur),e(y7,Hur),e(ie,Uur),e(ie,L7),e(L7,Pbe),e(Pbe,Jur),e(L7,Yur),e(L7,_W),e(_W,Kur),e(L7,Zur),e(ie,e_r),e(ie,x7),e(x7,Ibe),e(Ibe,o_r),e(x7,r_r),e(x7,bW),e(bW,t_r),e(x7,a_r),e(ie,n_r),e(ie,$7),e($7,qbe),e(qbe,s_r),e($7,l_r),e($7,vW),e(vW,i_r),e($7,d_r),e(ie,c_r),e(ie,k7),e(k7,Nbe),e(Nbe,f_r),e(k7,m_r),e(k7,FW),e(FW,g_r),e(k7,h_r),e(ie,p_r),e(ie,S7),e(S7,jbe),e(jbe,u_r),e(S7,__r),e(S7,TW),e(TW,b_r),e(S7,v_r),e(ie,F_r),e(ie,R7),e(R7,Dbe),e(Dbe,T_r),e(R7,M_r),e(R7,MW),e(MW,E_r),e(R7,C_r),e(ie,w_r),e(ie,B7),e(B7,Gbe),e(Gbe,A_r),e(B7,y_r),e(B7,EW),e(EW,L_r),e(B7,x_r),e(ie,$_r),e(ie,P7),e(P7,Obe),e(Obe,k_r),e(P7,S_r),e(P7,CW),e(CW,R_r),e(P7,B_r),e(ie,P_r),e(ie,I7),e(I7,Vbe),e(Vbe,I_r),e(I7,q_r),e(I7,wW),e(wW,N_r),e(I7,j_r),e(ie,D_r),e(ie,q7),e(q7,Xbe),e(Xbe,G_r),e(q7,O_r),e(q7,AW),e(AW,V_r),e(q7,X_r),e(ie,z_r),e(ie,N7),e(N7,zbe),e(zbe,Q_r),e(N7,W_r),e(N7,yW),e(yW,H_r),e(N7,U_r),e(ie,J_r),e(ie,j7),e(j7,Qbe),e(Qbe,Y_r),e(j7,K_r),e(j7,LW),e(LW,Z_r),e(j7,e0r),e(xr,o0r),M(D7,xr,null),b(f,qqe,_),b(f,ec,_),e(ec,G7),e(G7,Wbe),M(f8,Wbe,null),e(ec,r0r),e(ec,Hbe),e(Hbe,t0r),b(f,Nqe,_),b(f,rr,_),M(m8,rr,null),e(rr,a0r),e(rr,oc),e(oc,n0r),e(oc,xW),e(xW,s0r),e(oc,l0r),e(oc,$W),e($W,i0r),e(oc,d0r),e(rr,c0r),e(rr,g8),e(g8,f0r),e(g8,Ube),e(Ube,m0r),e(g8,g0r),e(rr,h0r),e(rr,$t),M(h8,$t,null),e($t,p0r),e($t,Jbe),e(Jbe,u0r),e($t,_0r),e($t,rc),e(rc,b0r),e(rc,Ybe),e(Ybe,v0r),e(rc,F0r),e(rc,kW),e(kW,T0r),e(rc,M0r),e($t,E0r),M(O7,$t,null),e(rr,C0r),e(rr,$r),M(p8,$r,null),e($r,w0r),e($r,Kbe),e(Kbe,A0r),e($r,y0r),e($r,tn),e(tn,L0r),e(tn,Zbe),e(Zbe,x0r),e(tn,$0r),e(tn,e2e),e(e2e,k0r),e(tn,S0r),e(tn,o2e),e(o2e,R0r),e(tn,B0r),e($r,P0r),e($r,ye),e(ye,V7),e(V7,r2e),e(r2e,I0r),e(V7,q0r),e(V7,SW),e(SW,N0r),e(V7,j0r),e(ye,D0r),e(ye,X7),e(X7,t2e),e(t2e,G0r),e(X7,O0r),e(X7,RW),e(RW,V0r),e(X7,X0r),e(ye,z0r),e(ye,z7),e(z7,a2e),e(a2e,Q0r),e(z7,W0r),e(z7,BW),e(BW,H0r),e(z7,U0r),e(ye,J0r),e(ye,Q7),e(Q7,n2e),e(n2e,Y0r),e(Q7,K0r),e(Q7,PW),e(PW,Z0r),e(Q7,e1r),e(ye,o1r),e(ye,W7),e(W7,s2e),e(s2e,r1r),e(W7,t1r),e(W7,IW),e(IW,a1r),e(W7,n1r),e(ye,s1r),e(ye,H7),e(H7,l2e),e(l2e,l1r),e(H7,i1r),e(H7,qW),e(qW,d1r),e(H7,c1r),e(ye,f1r),e(ye,U7),e(U7,i2e),e(i2e,m1r),e(U7,g1r),e(U7,NW),e(NW,h1r),e(U7,p1r),e(ye,u1r),e(ye,J7),e(J7,d2e),e(d2e,_1r),e(J7,b1r),e(J7,jW),e(jW,v1r),e(J7,F1r),e(ye,T1r),e(ye,Y7),e(Y7,c2e),e(c2e,M1r),e(Y7,E1r),e(Y7,DW),e(DW,C1r),e(Y7,w1r),e(ye,A1r),e(ye,K7),e(K7,f2e),e(f2e,y1r),e(K7,L1r),e(K7,GW),e(GW,x1r),e(K7,$1r),e($r,k1r),M(Z7,$r,null),b(f,jqe,_),b(f,tc,_),e(tc,eM),e(eM,m2e),M(u8,m2e,null),e(tc,S1r),e(tc,g2e),e(g2e,R1r),b(f,Dqe,_),b(f,tr,_),M(_8,tr,null),e(tr,B1r),e(tr,ac),e(ac,P1r),e(ac,OW),e(OW,I1r),e(ac,q1r),e(ac,VW),e(VW,N1r),e(ac,j1r),e(tr,D1r),e(tr,b8),e(b8,G1r),e(b8,h2e),e(h2e,O1r),e(b8,V1r),e(tr,X1r),e(tr,kt),M(v8,kt,null),e(kt,z1r),e(kt,p2e),e(p2e,Q1r),e(kt,W1r),e(kt,nc),e(nc,H1r),e(nc,u2e),e(u2e,U1r),e(nc,J1r),e(nc,XW),e(XW,Y1r),e(nc,K1r),e(kt,Z1r),M(oM,kt,null),e(tr,ebr),e(tr,kr),M(F8,kr,null),e(kr,obr),e(kr,_2e),e(_2e,rbr),e(kr,tbr),e(kr,an),e(an,abr),e(an,b2e),e(b2e,nbr),e(an,sbr),e(an,v2e),e(v2e,lbr),e(an,ibr),e(an,F2e),e(F2e,dbr),e(an,cbr),e(kr,fbr),e(kr,ee),e(ee,rM),e(rM,T2e),e(T2e,mbr),e(rM,gbr),e(rM,zW),e(zW,hbr),e(rM,pbr),e(ee,ubr),e(ee,tM),e(tM,M2e),e(M2e,_br),e(tM,bbr),e(tM,QW),e(QW,vbr),e(tM,Fbr),e(ee,Tbr),e(ee,aM),e(aM,E2e),e(E2e,Mbr),e(aM,Ebr),e(aM,WW),e(WW,Cbr),e(aM,wbr),e(ee,Abr),e(ee,nM),e(nM,C2e),e(C2e,ybr),e(nM,Lbr),e(nM,HW),e(HW,xbr),e(nM,$br),e(ee,kbr),e(ee,sM),e(sM,w2e),e(w2e,Sbr),e(sM,Rbr),e(sM,UW),e(UW,Bbr),e(sM,Pbr),e(ee,Ibr),e(ee,lM),e(lM,A2e),e(A2e,qbr),e(lM,Nbr),e(lM,JW),e(JW,jbr),e(lM,Dbr),e(ee,Gbr),e(ee,iM),e(iM,y2e),e(y2e,Obr),e(iM,Vbr),e(iM,YW),e(YW,Xbr),e(iM,zbr),e(ee,Qbr),e(ee,dM),e(dM,L2e),e(L2e,Wbr),e(dM,Hbr),e(dM,KW),e(KW,Ubr),e(dM,Jbr),e(ee,Ybr),e(ee,cM),e(cM,x2e),e(x2e,Kbr),e(cM,Zbr),e(cM,ZW),e(ZW,e2r),e(cM,o2r),e(ee,r2r),e(ee,fM),e(fM,$2e),e($2e,t2r),e(fM,a2r),e(fM,eH),e(eH,n2r),e(fM,s2r),e(ee,l2r),e(ee,mM),e(mM,k2e),e(k2e,i2r),e(mM,d2r),e(mM,oH),e(oH,c2r),e(mM,f2r),e(ee,m2r),e(ee,gM),e(gM,S2e),e(S2e,g2r),e(gM,h2r),e(gM,rH),e(rH,p2r),e(gM,u2r),e(ee,_2r),e(ee,hM),e(hM,R2e),e(R2e,b2r),e(hM,v2r),e(hM,tH),e(tH,F2r),e(hM,T2r),e(ee,M2r),e(ee,pM),e(pM,B2e),e(B2e,E2r),e(pM,C2r),e(pM,aH),e(aH,w2r),e(pM,A2r),e(ee,y2r),e(ee,uM),e(uM,P2e),e(P2e,L2r),e(uM,x2r),e(uM,nH),e(nH,$2r),e(uM,k2r),e(ee,S2r),e(ee,_M),e(_M,I2e),e(I2e,R2r),e(_M,B2r),e(_M,sH),e(sH,P2r),e(_M,I2r),e(ee,q2r),e(ee,bM),e(bM,q2e),e(q2e,N2r),e(bM,j2r),e(bM,lH),e(lH,D2r),e(bM,G2r),e(ee,O2r),e(ee,vM),e(vM,N2e),e(N2e,V2r),e(vM,X2r),e(vM,iH),e(iH,z2r),e(vM,Q2r),e(ee,W2r),e(ee,FM),e(FM,j2e),e(j2e,H2r),e(FM,U2r),e(FM,dH),e(dH,J2r),e(FM,Y2r),e(ee,K2r),e(ee,TM),e(TM,D2e),e(D2e,Z2r),e(TM,evr),e(TM,cH),e(cH,ovr),e(TM,rvr),e(ee,tvr),e(ee,MM),e(MM,G2e),e(G2e,avr),e(MM,nvr),e(MM,fH),e(fH,svr),e(MM,lvr),e(ee,ivr),e(ee,EM),e(EM,O2e),e(O2e,dvr),e(EM,cvr),e(EM,mH),e(mH,fvr),e(EM,mvr),e(ee,gvr),e(ee,CM),e(CM,V2e),e(V2e,hvr),e(CM,pvr),e(CM,gH),e(gH,uvr),e(CM,_vr),e(ee,bvr),e(ee,wM),e(wM,X2e),e(X2e,vvr),e(wM,Fvr),e(wM,hH),e(hH,Tvr),e(wM,Mvr),e(ee,Evr),e(ee,AM),e(AM,z2e),e(z2e,Cvr),e(AM,wvr),e(AM,pH),e(pH,Avr),e(AM,yvr),e(ee,Lvr),e(ee,yM),e(yM,Q2e),e(Q2e,xvr),e(yM,$vr),e(yM,uH),e(uH,kvr),e(yM,Svr),e(kr,Rvr),M(LM,kr,null),b(f,Gqe,_),b(f,sc,_),e(sc,xM),e(xM,W2e),M(T8,W2e,null),e(sc,Bvr),e(sc,H2e),e(H2e,Pvr),b(f,Oqe,_),b(f,ar,_),M(M8,ar,null),e(ar,Ivr),e(ar,lc),e(lc,qvr),e(lc,_H),e(_H,Nvr),e(lc,jvr),e(lc,bH),e(bH,Dvr),e(lc,Gvr),e(ar,Ovr),e(ar,E8),e(E8,Vvr),e(E8,U2e),e(U2e,Xvr),e(E8,zvr),e(ar,Qvr),e(ar,St),M(C8,St,null),e(St,Wvr),e(St,J2e),e(J2e,Hvr),e(St,Uvr),e(St,ic),e(ic,Jvr),e(ic,Y2e),e(Y2e,Yvr),e(ic,Kvr),e(ic,vH),e(vH,Zvr),e(ic,eFr),e(St,oFr),M($M,St,null),e(ar,rFr),e(ar,Sr),M(w8,Sr,null),e(Sr,tFr),e(Sr,K2e),e(K2e,aFr),e(Sr,nFr),e(Sr,nn),e(nn,sFr),e(nn,Z2e),e(Z2e,lFr),e(nn,iFr),e(nn,eve),e(eve,dFr),e(nn,cFr),e(nn,ove),e(ove,fFr),e(nn,mFr),e(Sr,gFr),e(Sr,pe),e(pe,kM),e(kM,rve),e(rve,hFr),e(kM,pFr),e(kM,FH),e(FH,uFr),e(kM,_Fr),e(pe,bFr),e(pe,SM),e(SM,tve),e(tve,vFr),e(SM,FFr),e(SM,TH),e(TH,TFr),e(SM,MFr),e(pe,EFr),e(pe,RM),e(RM,ave),e(ave,CFr),e(RM,wFr),e(RM,MH),e(MH,AFr),e(RM,yFr),e(pe,LFr),e(pe,BM),e(BM,nve),e(nve,xFr),e(BM,$Fr),e(BM,EH),e(EH,kFr),e(BM,SFr),e(pe,RFr),e(pe,PM),e(PM,sve),e(sve,BFr),e(PM,PFr),e(PM,CH),e(CH,IFr),e(PM,qFr),e(pe,NFr),e(pe,IM),e(IM,lve),e(lve,jFr),e(IM,DFr),e(IM,wH),e(wH,GFr),e(IM,OFr),e(pe,VFr),e(pe,qM),e(qM,ive),e(ive,XFr),e(qM,zFr),e(qM,AH),e(AH,QFr),e(qM,WFr),e(pe,HFr),e(pe,NM),e(NM,dve),e(dve,UFr),e(NM,JFr),e(NM,yH),e(yH,YFr),e(NM,KFr),e(pe,ZFr),e(pe,jM),e(jM,cve),e(cve,e6r),e(jM,o6r),e(jM,LH),e(LH,r6r),e(jM,t6r),e(pe,a6r),e(pe,DM),e(DM,fve),e(fve,n6r),e(DM,s6r),e(DM,xH),e(xH,l6r),e(DM,i6r),e(pe,d6r),e(pe,GM),e(GM,mve),e(mve,c6r),e(GM,f6r),e(GM,$H),e($H,m6r),e(GM,g6r),e(pe,h6r),e(pe,OM),e(OM,gve),e(gve,p6r),e(OM,u6r),e(OM,kH),e(kH,_6r),e(OM,b6r),e(pe,v6r),e(pe,VM),e(VM,hve),e(hve,F6r),e(VM,T6r),e(VM,SH),e(SH,M6r),e(VM,E6r),e(pe,C6r),e(pe,XM),e(XM,pve),e(pve,w6r),e(XM,A6r),e(XM,RH),e(RH,y6r),e(XM,L6r),e(pe,x6r),e(pe,zM),e(zM,uve),e(uve,$6r),e(zM,k6r),e(zM,BH),e(BH,S6r),e(zM,R6r),e(pe,B6r),e(pe,QM),e(QM,_ve),e(_ve,P6r),e(QM,I6r),e(QM,PH),e(PH,q6r),e(QM,N6r),e(pe,j6r),e(pe,WM),e(WM,bve),e(bve,D6r),e(WM,G6r),e(WM,IH),e(IH,O6r),e(WM,V6r),e(Sr,X6r),M(HM,Sr,null),b(f,Vqe,_),b(f,dc,_),e(dc,UM),e(UM,vve),M(A8,vve,null),e(dc,z6r),e(dc,Fve),e(Fve,Q6r),b(f,Xqe,_),b(f,nr,_),M(y8,nr,null),e(nr,W6r),e(nr,cc),e(cc,H6r),e(cc,qH),e(qH,U6r),e(cc,J6r),e(cc,NH),e(NH,Y6r),e(cc,K6r),e(nr,Z6r),e(nr,L8),e(L8,eTr),e(L8,Tve),e(Tve,oTr),e(L8,rTr),e(nr,tTr),e(nr,Rt),M(x8,Rt,null),e(Rt,aTr),e(Rt,Mve),e(Mve,nTr),e(Rt,sTr),e(Rt,fc),e(fc,lTr),e(fc,Eve),e(Eve,iTr),e(fc,dTr),e(fc,jH),e(jH,cTr),e(fc,fTr),e(Rt,mTr),M(JM,Rt,null),e(nr,gTr),e(nr,Rr),M($8,Rr,null),e(Rr,hTr),e(Rr,Cve),e(Cve,pTr),e(Rr,uTr),e(Rr,sn),e(sn,_Tr),e(sn,wve),e(wve,bTr),e(sn,vTr),e(sn,Ave),e(Ave,FTr),e(sn,TTr),e(sn,yve),e(yve,MTr),e(sn,ETr),e(Rr,CTr),e(Rr,k8),e(k8,YM),e(YM,Lve),e(Lve,wTr),e(YM,ATr),e(YM,DH),e(DH,yTr),e(YM,LTr),e(k8,xTr),e(k8,KM),e(KM,xve),e(xve,$Tr),e(KM,kTr),e(KM,GH),e(GH,STr),e(KM,RTr),e(Rr,BTr),M(ZM,Rr,null),b(f,zqe,_),b(f,mc,_),e(mc,e4),e(e4,$ve),M(S8,$ve,null),e(mc,PTr),e(mc,kve),e(kve,ITr),b(f,Qqe,_),b(f,sr,_),M(R8,sr,null),e(sr,qTr),e(sr,gc),e(gc,NTr),e(gc,OH),e(OH,jTr),e(gc,DTr),e(gc,VH),e(VH,GTr),e(gc,OTr),e(sr,VTr),e(sr,B8),e(B8,XTr),e(B8,Sve),e(Sve,zTr),e(B8,QTr),e(sr,WTr),e(sr,Bt),M(P8,Bt,null),e(Bt,HTr),e(Bt,Rve),e(Rve,UTr),e(Bt,JTr),e(Bt,hc),e(hc,YTr),e(hc,Bve),e(Bve,KTr),e(hc,ZTr),e(hc,XH),e(XH,e7r),e(hc,o7r),e(Bt,r7r),M(o4,Bt,null),e(sr,t7r),e(sr,Br),M(I8,Br,null),e(Br,a7r),e(Br,Pve),e(Pve,n7r),e(Br,s7r),e(Br,ln),e(ln,l7r),e(ln,Ive),e(Ive,i7r),e(ln,d7r),e(ln,qve),e(qve,c7r),e(ln,f7r),e(ln,Nve),e(Nve,m7r),e(ln,g7r),e(Br,h7r),e(Br,jve),e(jve,r4),e(r4,Dve),e(Dve,p7r),e(r4,u7r),e(r4,zH),e(zH,_7r),e(r4,b7r),e(Br,v7r),M(t4,Br,null),b(f,Wqe,_),b(f,pc,_),e(pc,a4),e(a4,Gve),M(q8,Gve,null),e(pc,F7r),e(pc,Ove),e(Ove,T7r),b(f,Hqe,_),b(f,lr,_),M(N8,lr,null),e(lr,M7r),e(lr,uc),e(uc,E7r),e(uc,QH),e(QH,C7r),e(uc,w7r),e(uc,WH),e(WH,A7r),e(uc,y7r),e(lr,L7r),e(lr,j8),e(j8,x7r),e(j8,Vve),e(Vve,$7r),e(j8,k7r),e(lr,S7r),e(lr,Pt),M(D8,Pt,null),e(Pt,R7r),e(Pt,Xve),e(Xve,B7r),e(Pt,P7r),e(Pt,_c),e(_c,I7r),e(_c,zve),e(zve,q7r),e(_c,N7r),e(_c,HH),e(HH,j7r),e(_c,D7r),e(Pt,G7r),M(n4,Pt,null),e(lr,O7r),e(lr,Pr),M(G8,Pr,null),e(Pr,V7r),e(Pr,Qve),e(Qve,X7r),e(Pr,z7r),e(Pr,dn),e(dn,Q7r),e(dn,Wve),e(Wve,W7r),e(dn,H7r),e(dn,Hve),e(Hve,U7r),e(dn,J7r),e(dn,Uve),e(Uve,Y7r),e(dn,K7r),e(Pr,Z7r),e(Pr,de),e(de,s4),e(s4,Jve),e(Jve,eMr),e(s4,oMr),e(s4,UH),e(UH,rMr),e(s4,tMr),e(de,aMr),e(de,l4),e(l4,Yve),e(Yve,nMr),e(l4,sMr),e(l4,JH),e(JH,lMr),e(l4,iMr),e(de,dMr),e(de,i4),e(i4,Kve),e(Kve,cMr),e(i4,fMr),e(i4,YH),e(YH,mMr),e(i4,gMr),e(de,hMr),e(de,d4),e(d4,Zve),e(Zve,pMr),e(d4,uMr),e(d4,KH),e(KH,_Mr),e(d4,bMr),e(de,vMr),e(de,c4),e(c4,eFe),e(eFe,FMr),e(c4,TMr),e(c4,ZH),e(ZH,MMr),e(c4,EMr),e(de,CMr),e(de,f4),e(f4,oFe),e(oFe,wMr),e(f4,AMr),e(f4,eU),e(eU,yMr),e(f4,LMr),e(de,xMr),e(de,m4),e(m4,rFe),e(rFe,$Mr),e(m4,kMr),e(m4,oU),e(oU,SMr),e(m4,RMr),e(de,BMr),e(de,g4),e(g4,tFe),e(tFe,PMr),e(g4,IMr),e(g4,rU),e(rU,qMr),e(g4,NMr),e(de,jMr),e(de,h4),e(h4,aFe),e(aFe,DMr),e(h4,GMr),e(h4,tU),e(tU,OMr),e(h4,VMr),e(de,XMr),e(de,p4),e(p4,nFe),e(nFe,zMr),e(p4,QMr),e(p4,aU),e(aU,WMr),e(p4,HMr),e(de,UMr),e(de,u4),e(u4,sFe),e(sFe,JMr),e(u4,YMr),e(u4,nU),e(nU,KMr),e(u4,ZMr),e(de,e4r),e(de,_4),e(_4,lFe),e(lFe,o4r),e(_4,r4r),e(_4,sU),e(sU,t4r),e(_4,a4r),e(de,n4r),e(de,b4),e(b4,iFe),e(iFe,s4r),e(b4,l4r),e(b4,lU),e(lU,i4r),e(b4,d4r),e(de,c4r),e(de,v4),e(v4,dFe),e(dFe,f4r),e(v4,m4r),e(v4,iU),e(iU,g4r),e(v4,h4r),e(de,p4r),e(de,F4),e(F4,cFe),e(cFe,u4r),e(F4,_4r),e(F4,dU),e(dU,b4r),e(F4,v4r),e(de,F4r),e(de,T4),e(T4,fFe),e(fFe,T4r),e(T4,M4r),e(T4,cU),e(cU,E4r),e(T4,C4r),e(de,w4r),e(de,M4),e(M4,mFe),e(mFe,A4r),e(M4,y4r),e(M4,fU),e(fU,L4r),e(M4,x4r),e(de,$4r),e(de,E4),e(E4,gFe),e(gFe,k4r),e(E4,S4r),e(E4,mU),e(mU,R4r),e(E4,B4r),e(de,P4r),e(de,C4),e(C4,hFe),e(hFe,I4r),e(C4,q4r),e(C4,gU),e(gU,N4r),e(C4,j4r),e(de,D4r),e(de,w4),e(w4,pFe),e(pFe,G4r),e(w4,O4r),e(w4,hU),e(hU,V4r),e(w4,X4r),e(Pr,z4r),M(A4,Pr,null),b(f,Uqe,_),b(f,bc,_),e(bc,y4),e(y4,uFe),M(O8,uFe,null),e(bc,Q4r),e(bc,_Fe),e(_Fe,W4r),b(f,Jqe,_),b(f,ir,_),M(V8,ir,null),e(ir,H4r),e(ir,vc),e(vc,U4r),e(vc,pU),e(pU,J4r),e(vc,Y4r),e(vc,uU),e(uU,K4r),e(vc,Z4r),e(ir,eEr),e(ir,X8),e(X8,oEr),e(X8,bFe),e(bFe,rEr),e(X8,tEr),e(ir,aEr),e(ir,It),M(z8,It,null),e(It,nEr),e(It,vFe),e(vFe,sEr),e(It,lEr),e(It,Fc),e(Fc,iEr),e(Fc,FFe),e(FFe,dEr),e(Fc,cEr),e(Fc,_U),e(_U,fEr),e(Fc,mEr),e(It,gEr),M(L4,It,null),e(ir,hEr),e(ir,Ir),M(Q8,Ir,null),e(Ir,pEr),e(Ir,TFe),e(TFe,uEr),e(Ir,_Er),e(Ir,cn),e(cn,bEr),e(cn,MFe),e(MFe,vEr),e(cn,FEr),e(cn,EFe),e(EFe,TEr),e(cn,MEr),e(cn,CFe),e(CFe,EEr),e(cn,CEr),e(Ir,wEr),e(Ir,ce),e(ce,x4),e(x4,wFe),e(wFe,AEr),e(x4,yEr),e(x4,bU),e(bU,LEr),e(x4,xEr),e(ce,$Er),e(ce,$4),e($4,AFe),e(AFe,kEr),e($4,SEr),e($4,vU),e(vU,REr),e($4,BEr),e(ce,PEr),e(ce,k4),e(k4,yFe),e(yFe,IEr),e(k4,qEr),e(k4,FU),e(FU,NEr),e(k4,jEr),e(ce,DEr),e(ce,S4),e(S4,LFe),e(LFe,GEr),e(S4,OEr),e(S4,TU),e(TU,VEr),e(S4,XEr),e(ce,zEr),e(ce,R4),e(R4,xFe),e(xFe,QEr),e(R4,WEr),e(R4,MU),e(MU,HEr),e(R4,UEr),e(ce,JEr),e(ce,B4),e(B4,$Fe),e($Fe,YEr),e(B4,KEr),e(B4,EU),e(EU,ZEr),e(B4,e5r),e(ce,o5r),e(ce,P4),e(P4,kFe),e(kFe,r5r),e(P4,t5r),e(P4,CU),e(CU,a5r),e(P4,n5r),e(ce,s5r),e(ce,I4),e(I4,SFe),e(SFe,l5r),e(I4,i5r),e(I4,wU),e(wU,d5r),e(I4,c5r),e(ce,f5r),e(ce,q4),e(q4,RFe),e(RFe,m5r),e(q4,g5r),e(q4,AU),e(AU,h5r),e(q4,p5r),e(ce,u5r),e(ce,N4),e(N4,BFe),e(BFe,_5r),e(N4,b5r),e(N4,yU),e(yU,v5r),e(N4,F5r),e(ce,T5r),e(ce,j4),e(j4,PFe),e(PFe,M5r),e(j4,E5r),e(j4,LU),e(LU,C5r),e(j4,w5r),e(ce,A5r),e(ce,D4),e(D4,IFe),e(IFe,y5r),e(D4,L5r),e(D4,xU),e(xU,x5r),e(D4,$5r),e(ce,k5r),e(ce,G4),e(G4,qFe),e(qFe,S5r),e(G4,R5r),e(G4,$U),e($U,B5r),e(G4,P5r),e(ce,I5r),e(ce,O4),e(O4,NFe),e(NFe,q5r),e(O4,N5r),e(O4,kU),e(kU,j5r),e(O4,D5r),e(ce,G5r),e(ce,V4),e(V4,jFe),e(jFe,O5r),e(V4,V5r),e(V4,SU),e(SU,X5r),e(V4,z5r),e(ce,Q5r),e(ce,X4),e(X4,DFe),e(DFe,W5r),e(X4,H5r),e(X4,RU),e(RU,U5r),e(X4,J5r),e(ce,Y5r),e(ce,z4),e(z4,GFe),e(GFe,K5r),e(z4,Z5r),e(z4,BU),e(BU,eCr),e(z4,oCr),e(ce,rCr),e(ce,Q4),e(Q4,OFe),e(OFe,tCr),e(Q4,aCr),e(Q4,PU),e(PU,nCr),e(Q4,sCr),e(ce,lCr),e(ce,W4),e(W4,VFe),e(VFe,iCr),e(W4,dCr),e(W4,IU),e(IU,cCr),e(W4,fCr),e(ce,mCr),e(ce,H4),e(H4,XFe),e(XFe,gCr),e(H4,hCr),e(H4,qU),e(qU,pCr),e(H4,uCr),e(Ir,_Cr),M(U4,Ir,null),b(f,Yqe,_),b(f,Tc,_),e(Tc,J4),e(J4,zFe),M(W8,zFe,null),e(Tc,bCr),e(Tc,QFe),e(QFe,vCr),b(f,Kqe,_),b(f,dr,_),M(H8,dr,null),e(dr,FCr),e(dr,Mc),e(Mc,TCr),e(Mc,NU),e(NU,MCr),e(Mc,ECr),e(Mc,jU),e(jU,CCr),e(Mc,wCr),e(dr,ACr),e(dr,U8),e(U8,yCr),e(U8,WFe),e(WFe,LCr),e(U8,xCr),e(dr,$Cr),e(dr,qt),M(J8,qt,null),e(qt,kCr),e(qt,HFe),e(HFe,SCr),e(qt,RCr),e(qt,Ec),e(Ec,BCr),e(Ec,UFe),e(UFe,PCr),e(Ec,ICr),e(Ec,DU),e(DU,qCr),e(Ec,NCr),e(qt,jCr),M(Y4,qt,null),e(dr,DCr),e(dr,qr),M(Y8,qr,null),e(qr,GCr),e(qr,JFe),e(JFe,OCr),e(qr,VCr),e(qr,fn),e(fn,XCr),e(fn,YFe),e(YFe,zCr),e(fn,QCr),e(fn,KFe),e(KFe,WCr),e(fn,HCr),e(fn,ZFe),e(ZFe,UCr),e(fn,JCr),e(qr,YCr),e(qr,e6e),e(e6e,K4),e(K4,o6e),e(o6e,KCr),e(K4,ZCr),e(K4,GU),e(GU,e3r),e(K4,o3r),e(qr,r3r),M(Z4,qr,null),b(f,Zqe,_),b(f,Cc,_),e(Cc,eE),e(eE,r6e),M(K8,r6e,null),e(Cc,t3r),e(Cc,t6e),e(t6e,a3r),b(f,eNe,_),b(f,cr,_),M(Z8,cr,null),e(cr,n3r),e(cr,wc),e(wc,s3r),e(wc,OU),e(OU,l3r),e(wc,i3r),e(wc,VU),e(VU,d3r),e(wc,c3r),e(cr,f3r),e(cr,ex),e(ex,m3r),e(ex,a6e),e(a6e,g3r),e(ex,h3r),e(cr,p3r),e(cr,Nt),M(ox,Nt,null),e(Nt,u3r),e(Nt,n6e),e(n6e,_3r),e(Nt,b3r),e(Nt,Ac),e(Ac,v3r),e(Ac,s6e),e(s6e,F3r),e(Ac,T3r),e(Ac,XU),e(XU,M3r),e(Ac,E3r),e(Nt,C3r),M(oE,Nt,null),e(cr,w3r),e(cr,Nr),M(rx,Nr,null),e(Nr,A3r),e(Nr,l6e),e(l6e,y3r),e(Nr,L3r),e(Nr,mn),e(mn,x3r),e(mn,i6e),e(i6e,$3r),e(mn,k3r),e(mn,d6e),e(d6e,S3r),e(mn,R3r),e(mn,c6e),e(c6e,B3r),e(mn,P3r),e(Nr,I3r),e(Nr,f6e),e(f6e,rE),e(rE,m6e),e(m6e,q3r),e(rE,N3r),e(rE,zU),e(zU,j3r),e(rE,D3r),e(Nr,G3r),M(tE,Nr,null),b(f,oNe,_),b(f,yc,_),e(yc,aE),e(aE,g6e),M(tx,g6e,null),e(yc,O3r),e(yc,h6e),e(h6e,V3r),b(f,rNe,_),b(f,fr,_),M(ax,fr,null),e(fr,X3r),e(fr,Lc),e(Lc,z3r),e(Lc,QU),e(QU,Q3r),e(Lc,W3r),e(Lc,WU),e(WU,H3r),e(Lc,U3r),e(fr,J3r),e(fr,nx),e(nx,Y3r),e(nx,p6e),e(p6e,K3r),e(nx,Z3r),e(fr,ewr),e(fr,jt),M(sx,jt,null),e(jt,owr),e(jt,u6e),e(u6e,rwr),e(jt,twr),e(jt,xc),e(xc,awr),e(xc,_6e),e(_6e,nwr),e(xc,swr),e(xc,HU),e(HU,lwr),e(xc,iwr),e(jt,dwr),M(nE,jt,null),e(fr,cwr),e(fr,jr),M(lx,jr,null),e(jr,fwr),e(jr,b6e),e(b6e,mwr),e(jr,gwr),e(jr,gn),e(gn,hwr),e(gn,v6e),e(v6e,pwr),e(gn,uwr),e(gn,F6e),e(F6e,_wr),e(gn,bwr),e(gn,T6e),e(T6e,vwr),e(gn,Fwr),e(jr,Twr),e(jr,re),e(re,sE),e(sE,M6e),e(M6e,Mwr),e(sE,Ewr),e(sE,UU),e(UU,Cwr),e(sE,wwr),e(re,Awr),e(re,lE),e(lE,E6e),e(E6e,ywr),e(lE,Lwr),e(lE,JU),e(JU,xwr),e(lE,$wr),e(re,kwr),e(re,iE),e(iE,C6e),e(C6e,Swr),e(iE,Rwr),e(iE,YU),e(YU,Bwr),e(iE,Pwr),e(re,Iwr),e(re,dE),e(dE,w6e),e(w6e,qwr),e(dE,Nwr),e(dE,KU),e(KU,jwr),e(dE,Dwr),e(re,Gwr),e(re,cE),e(cE,A6e),e(A6e,Owr),e(cE,Vwr),e(cE,ZU),e(ZU,Xwr),e(cE,zwr),e(re,Qwr),e(re,fE),e(fE,y6e),e(y6e,Wwr),e(fE,Hwr),e(fE,eJ),e(eJ,Uwr),e(fE,Jwr),e(re,Ywr),e(re,mE),e(mE,L6e),e(L6e,Kwr),e(mE,Zwr),e(mE,oJ),e(oJ,eAr),e(mE,oAr),e(re,rAr),e(re,gE),e(gE,x6e),e(x6e,tAr),e(gE,aAr),e(gE,rJ),e(rJ,nAr),e(gE,sAr),e(re,lAr),e(re,hE),e(hE,$6e),e($6e,iAr),e(hE,dAr),e(hE,tJ),e(tJ,cAr),e(hE,fAr),e(re,mAr),e(re,pE),e(pE,k6e),e(k6e,gAr),e(pE,hAr),e(pE,aJ),e(aJ,pAr),e(pE,uAr),e(re,_Ar),e(re,uE),e(uE,S6e),e(S6e,bAr),e(uE,vAr),e(uE,nJ),e(nJ,FAr),e(uE,TAr),e(re,MAr),e(re,_E),e(_E,R6e),e(R6e,EAr),e(_E,CAr),e(_E,sJ),e(sJ,wAr),e(_E,AAr),e(re,yAr),e(re,bE),e(bE,B6e),e(B6e,LAr),e(bE,xAr),e(bE,lJ),e(lJ,$Ar),e(bE,kAr),e(re,SAr),e(re,vE),e(vE,P6e),e(P6e,RAr),e(vE,BAr),e(vE,iJ),e(iJ,PAr),e(vE,IAr),e(re,qAr),e(re,FE),e(FE,I6e),e(I6e,NAr),e(FE,jAr),e(FE,dJ),e(dJ,DAr),e(FE,GAr),e(re,OAr),e(re,TE),e(TE,q6e),e(q6e,VAr),e(TE,XAr),e(TE,cJ),e(cJ,zAr),e(TE,QAr),e(re,WAr),e(re,ME),e(ME,N6e),e(N6e,HAr),e(ME,UAr),e(ME,fJ),e(fJ,JAr),e(ME,YAr),e(re,KAr),e(re,EE),e(EE,j6e),e(j6e,ZAr),e(EE,eyr),e(EE,mJ),e(mJ,oyr),e(EE,ryr),e(re,tyr),e(re,CE),e(CE,D6e),e(D6e,ayr),e(CE,nyr),e(CE,gJ),e(gJ,syr),e(CE,lyr),e(re,iyr),e(re,wE),e(wE,G6e),e(G6e,dyr),e(wE,cyr),e(wE,hJ),e(hJ,fyr),e(wE,myr),e(re,gyr),e(re,AE),e(AE,O6e),e(O6e,hyr),e(AE,pyr),e(AE,pJ),e(pJ,uyr),e(AE,_yr),e(re,byr),e(re,yE),e(yE,V6e),e(V6e,vyr),e(yE,Fyr),e(yE,uJ),e(uJ,Tyr),e(yE,Myr),e(re,Eyr),e(re,LE),e(LE,X6e),e(X6e,Cyr),e(LE,wyr),e(LE,_J),e(_J,Ayr),e(LE,yyr),e(re,Lyr),e(re,xE),e(xE,z6e),e(z6e,xyr),e(xE,$yr),e(xE,bJ),e(bJ,kyr),e(xE,Syr),e(re,Ryr),e(re,$E),e($E,Q6e),e(Q6e,Byr),e($E,Pyr),e($E,vJ),e(vJ,Iyr),e($E,qyr),e(jr,Nyr),M(kE,jr,null),b(f,tNe,_),b(f,$c,_),e($c,SE),e(SE,W6e),M(ix,W6e,null),e($c,jyr),e($c,H6e),e(H6e,Dyr),b(f,aNe,_),b(f,mr,_),M(dx,mr,null),e(mr,Gyr),e(mr,kc),e(kc,Oyr),e(kc,FJ),e(FJ,Vyr),e(kc,Xyr),e(kc,TJ),e(TJ,zyr),e(kc,Qyr),e(mr,Wyr),e(mr,cx),e(cx,Hyr),e(cx,U6e),e(U6e,Uyr),e(cx,Jyr),e(mr,Yyr),e(mr,Dt),M(fx,Dt,null),e(Dt,Kyr),e(Dt,J6e),e(J6e,Zyr),e(Dt,eLr),e(Dt,Sc),e(Sc,oLr),e(Sc,Y6e),e(Y6e,rLr),e(Sc,tLr),e(Sc,MJ),e(MJ,aLr),e(Sc,nLr),e(Dt,sLr),M(RE,Dt,null),e(mr,lLr),e(mr,Dr),M(mx,Dr,null),e(Dr,iLr),e(Dr,K6e),e(K6e,dLr),e(Dr,cLr),e(Dr,hn),e(hn,fLr),e(hn,Z6e),e(Z6e,mLr),e(hn,gLr),e(hn,eTe),e(eTe,hLr),e(hn,pLr),e(hn,oTe),e(oTe,uLr),e(hn,_Lr),e(Dr,bLr),e(Dr,ke),e(ke,BE),e(BE,rTe),e(rTe,vLr),e(BE,FLr),e(BE,EJ),e(EJ,TLr),e(BE,MLr),e(ke,ELr),e(ke,PE),e(PE,tTe),e(tTe,CLr),e(PE,wLr),e(PE,CJ),e(CJ,ALr),e(PE,yLr),e(ke,LLr),e(ke,IE),e(IE,aTe),e(aTe,xLr),e(IE,$Lr),e(IE,wJ),e(wJ,kLr),e(IE,SLr),e(ke,RLr),e(ke,qE),e(qE,nTe),e(nTe,BLr),e(qE,PLr),e(qE,AJ),e(AJ,ILr),e(qE,qLr),e(ke,NLr),e(ke,NE),e(NE,sTe),e(sTe,jLr),e(NE,DLr),e(NE,yJ),e(yJ,GLr),e(NE,OLr),e(ke,VLr),e(ke,jE),e(jE,lTe),e(lTe,XLr),e(jE,zLr),e(jE,LJ),e(LJ,QLr),e(jE,WLr),e(ke,HLr),e(ke,DE),e(DE,iTe),e(iTe,ULr),e(DE,JLr),e(DE,xJ),e(xJ,YLr),e(DE,KLr),e(ke,ZLr),e(ke,GE),e(GE,dTe),e(dTe,e8r),e(GE,o8r),e(GE,$J),e($J,r8r),e(GE,t8r),e(ke,a8r),e(ke,OE),e(OE,cTe),e(cTe,n8r),e(OE,s8r),e(OE,kJ),e(kJ,l8r),e(OE,i8r),e(Dr,d8r),M(VE,Dr,null),b(f,nNe,_),b(f,Rc,_),e(Rc,XE),e(XE,fTe),M(gx,fTe,null),e(Rc,c8r),e(Rc,mTe),e(mTe,f8r),b(f,sNe,_),b(f,gr,_),M(hx,gr,null),e(gr,m8r),e(gr,Bc),e(Bc,g8r),e(Bc,SJ),e(SJ,h8r),e(Bc,p8r),e(Bc,RJ),e(RJ,u8r),e(Bc,_8r),e(gr,b8r),e(gr,px),e(px,v8r),e(px,gTe),e(gTe,F8r),e(px,T8r),e(gr,M8r),e(gr,Gt),M(ux,Gt,null),e(Gt,E8r),e(Gt,hTe),e(hTe,C8r),e(Gt,w8r),e(Gt,Pc),e(Pc,A8r),e(Pc,pTe),e(pTe,y8r),e(Pc,L8r),e(Pc,BJ),e(BJ,x8r),e(Pc,$8r),e(Gt,k8r),M(zE,Gt,null),e(gr,S8r),e(gr,Gr),M(_x,Gr,null),e(Gr,R8r),e(Gr,uTe),e(uTe,B8r),e(Gr,P8r),e(Gr,pn),e(pn,I8r),e(pn,_Te),e(_Te,q8r),e(pn,N8r),e(pn,bTe),e(bTe,j8r),e(pn,D8r),e(pn,vTe),e(vTe,G8r),e(pn,O8r),e(Gr,V8r),e(Gr,Me),e(Me,QE),e(QE,FTe),e(FTe,X8r),e(QE,z8r),e(QE,PJ),e(PJ,Q8r),e(QE,W8r),e(Me,H8r),e(Me,WE),e(WE,TTe),e(TTe,U8r),e(WE,J8r),e(WE,IJ),e(IJ,Y8r),e(WE,K8r),e(Me,Z8r),e(Me,HE),e(HE,MTe),e(MTe,exr),e(HE,oxr),e(HE,qJ),e(qJ,rxr),e(HE,txr),e(Me,axr),e(Me,UE),e(UE,ETe),e(ETe,nxr),e(UE,sxr),e(UE,NJ),e(NJ,lxr),e(UE,ixr),e(Me,dxr),e(Me,JE),e(JE,CTe),e(CTe,cxr),e(JE,fxr),e(JE,jJ),e(jJ,mxr),e(JE,gxr),e(Me,hxr),e(Me,YE),e(YE,wTe),e(wTe,pxr),e(YE,uxr),e(YE,DJ),e(DJ,_xr),e(YE,bxr),e(Me,vxr),e(Me,KE),e(KE,ATe),e(ATe,Fxr),e(KE,Txr),e(KE,GJ),e(GJ,Mxr),e(KE,Exr),e(Me,Cxr),e(Me,ZE),e(ZE,yTe),e(yTe,wxr),e(ZE,Axr),e(ZE,OJ),e(OJ,yxr),e(ZE,Lxr),e(Me,xxr),e(Me,e5),e(e5,LTe),e(LTe,$xr),e(e5,kxr),e(e5,VJ),e(VJ,Sxr),e(e5,Rxr),e(Me,Bxr),e(Me,o5),e(o5,xTe),e(xTe,Pxr),e(o5,Ixr),e(o5,XJ),e(XJ,qxr),e(o5,Nxr),e(Me,jxr),e(Me,r5),e(r5,$Te),e($Te,Dxr),e(r5,Gxr),e(r5,zJ),e(zJ,Oxr),e(r5,Vxr),e(Me,Xxr),e(Me,t5),e(t5,kTe),e(kTe,zxr),e(t5,Qxr),e(t5,QJ),e(QJ,Wxr),e(t5,Hxr),e(Gr,Uxr),M(a5,Gr,null),b(f,lNe,_),b(f,Ic,_),e(Ic,n5),e(n5,STe),M(bx,STe,null),e(Ic,Jxr),e(Ic,RTe),e(RTe,Yxr),b(f,iNe,_),b(f,hr,_),M(vx,hr,null),e(hr,Kxr),e(hr,qc),e(qc,Zxr),e(qc,WJ),e(WJ,e9r),e(qc,o9r),e(qc,HJ),e(HJ,r9r),e(qc,t9r),e(hr,a9r),e(hr,Fx),e(Fx,n9r),e(Fx,BTe),e(BTe,s9r),e(Fx,l9r),e(hr,i9r),e(hr,Ot),M(Tx,Ot,null),e(Ot,d9r),e(Ot,PTe),e(PTe,c9r),e(Ot,f9r),e(Ot,Nc),e(Nc,m9r),e(Nc,ITe),e(ITe,g9r),e(Nc,h9r),e(Nc,UJ),e(UJ,p9r),e(Nc,u9r),e(Ot,_9r),M(s5,Ot,null),e(hr,b9r),e(hr,Or),M(Mx,Or,null),e(Or,v9r),e(Or,qTe),e(qTe,F9r),e(Or,T9r),e(Or,un),e(un,M9r),e(un,NTe),e(NTe,E9r),e(un,C9r),e(un,jTe),e(jTe,w9r),e(un,A9r),e(un,DTe),e(DTe,y9r),e(un,L9r),e(Or,x9r),e(Or,Le),e(Le,l5),e(l5,GTe),e(GTe,$9r),e(l5,k9r),e(l5,JJ),e(JJ,S9r),e(l5,R9r),e(Le,B9r),e(Le,i5),e(i5,OTe),e(OTe,P9r),e(i5,I9r),e(i5,YJ),e(YJ,q9r),e(i5,N9r),e(Le,j9r),e(Le,d5),e(d5,VTe),e(VTe,D9r),e(d5,G9r),e(d5,KJ),e(KJ,O9r),e(d5,V9r),e(Le,X9r),e(Le,c5),e(c5,XTe),e(XTe,z9r),e(c5,Q9r),e(c5,ZJ),e(ZJ,W9r),e(c5,H9r),e(Le,U9r),e(Le,f5),e(f5,zTe),e(zTe,J9r),e(f5,Y9r),e(f5,eY),e(eY,K9r),e(f5,Z9r),e(Le,e$r),e(Le,m5),e(m5,QTe),e(QTe,o$r),e(m5,r$r),e(m5,oY),e(oY,t$r),e(m5,a$r),e(Le,n$r),e(Le,g5),e(g5,WTe),e(WTe,s$r),e(g5,l$r),e(g5,rY),e(rY,i$r),e(g5,d$r),e(Le,c$r),e(Le,h5),e(h5,HTe),e(HTe,f$r),e(h5,m$r),e(h5,tY),e(tY,g$r),e(h5,h$r),e(Le,p$r),e(Le,p5),e(p5,UTe),e(UTe,u$r),e(p5,_$r),e(p5,aY),e(aY,b$r),e(p5,v$r),e(Le,F$r),e(Le,u5),e(u5,JTe),e(JTe,T$r),e(u5,M$r),e(u5,nY),e(nY,E$r),e(u5,C$r),e(Or,w$r),M(_5,Or,null),b(f,dNe,_),b(f,jc,_),e(jc,b5),e(b5,YTe),M(Ex,YTe,null),e(jc,A$r),e(jc,KTe),e(KTe,y$r),b(f,cNe,_),b(f,pr,_),M(Cx,pr,null),e(pr,L$r),e(pr,Dc),e(Dc,x$r),e(Dc,sY),e(sY,$$r),e(Dc,k$r),e(Dc,lY),e(lY,S$r),e(Dc,R$r),e(pr,B$r),e(pr,wx),e(wx,P$r),e(wx,ZTe),e(ZTe,I$r),e(wx,q$r),e(pr,N$r),e(pr,Vt),M(Ax,Vt,null),e(Vt,j$r),e(Vt,e7e),e(e7e,D$r),e(Vt,G$r),e(Vt,Gc),e(Gc,O$r),e(Gc,o7e),e(o7e,V$r),e(Gc,X$r),e(Gc,iY),e(iY,z$r),e(Gc,Q$r),e(Vt,W$r),M(v5,Vt,null),e(pr,H$r),e(pr,Vr),M(yx,Vr,null),e(Vr,U$r),e(Vr,r7e),e(r7e,J$r),e(Vr,Y$r),e(Vr,_n),e(_n,K$r),e(_n,t7e),e(t7e,Z$r),e(_n,ekr),e(_n,a7e),e(a7e,okr),e(_n,rkr),e(_n,n7e),e(n7e,tkr),e(_n,akr),e(Vr,nkr),e(Vr,Se),e(Se,F5),e(F5,s7e),e(s7e,skr),e(F5,lkr),e(F5,dY),e(dY,ikr),e(F5,dkr),e(Se,ckr),e(Se,T5),e(T5,l7e),e(l7e,fkr),e(T5,mkr),e(T5,cY),e(cY,gkr),e(T5,hkr),e(Se,pkr),e(Se,M5),e(M5,i7e),e(i7e,ukr),e(M5,_kr),e(M5,fY),e(fY,bkr),e(M5,vkr),e(Se,Fkr),e(Se,E5),e(E5,d7e),e(d7e,Tkr),e(E5,Mkr),e(E5,mY),e(mY,Ekr),e(E5,Ckr),e(Se,wkr),e(Se,C5),e(C5,c7e),e(c7e,Akr),e(C5,ykr),e(C5,gY),e(gY,Lkr),e(C5,xkr),e(Se,$kr),e(Se,w5),e(w5,f7e),e(f7e,kkr),e(w5,Skr),e(w5,hY),e(hY,Rkr),e(w5,Bkr),e(Se,Pkr),e(Se,A5),e(A5,m7e),e(m7e,Ikr),e(A5,qkr),e(A5,pY),e(pY,Nkr),e(A5,jkr),e(Se,Dkr),e(Se,y5),e(y5,g7e),e(g7e,Gkr),e(y5,Okr),e(y5,uY),e(uY,Vkr),e(y5,Xkr),e(Se,zkr),e(Se,L5),e(L5,h7e),e(h7e,Qkr),e(L5,Wkr),e(L5,_Y),e(_Y,Hkr),e(L5,Ukr),e(Vr,Jkr),M(x5,Vr,null),b(f,fNe,_),b(f,Oc,_),e(Oc,$5),e($5,p7e),M(Lx,p7e,null),e(Oc,Ykr),e(Oc,u7e),e(u7e,Kkr),b(f,mNe,_),b(f,ur,_),M(xx,ur,null),e(ur,Zkr),e(ur,Vc),e(Vc,eSr),e(Vc,bY),e(bY,oSr),e(Vc,rSr),e(Vc,vY),e(vY,tSr),e(Vc,aSr),e(ur,nSr),e(ur,$x),e($x,sSr),e($x,_7e),e(_7e,lSr),e($x,iSr),e(ur,dSr),e(ur,Xt),M(kx,Xt,null),e(Xt,cSr),e(Xt,b7e),e(b7e,fSr),e(Xt,mSr),e(Xt,Xc),e(Xc,gSr),e(Xc,v7e),e(v7e,hSr),e(Xc,pSr),e(Xc,FY),e(FY,uSr),e(Xc,_Sr),e(Xt,bSr),M(k5,Xt,null),e(ur,vSr),e(ur,Xr),M(Sx,Xr,null),e(Xr,FSr),e(Xr,F7e),e(F7e,TSr),e(Xr,MSr),e(Xr,bn),e(bn,ESr),e(bn,T7e),e(T7e,CSr),e(bn,wSr),e(bn,M7e),e(M7e,ASr),e(bn,ySr),e(bn,E7e),e(E7e,LSr),e(bn,xSr),e(Xr,$Sr),e(Xr,xe),e(xe,S5),e(S5,C7e),e(C7e,kSr),e(S5,SSr),e(S5,TY),e(TY,RSr),e(S5,BSr),e(xe,PSr),e(xe,R5),e(R5,w7e),e(w7e,ISr),e(R5,qSr),e(R5,MY),e(MY,NSr),e(R5,jSr),e(xe,DSr),e(xe,B5),e(B5,A7e),e(A7e,GSr),e(B5,OSr),e(B5,EY),e(EY,VSr),e(B5,XSr),e(xe,zSr),e(xe,P5),e(P5,y7e),e(y7e,QSr),e(P5,WSr),e(P5,CY),e(CY,HSr),e(P5,USr),e(xe,JSr),e(xe,I5),e(I5,L7e),e(L7e,YSr),e(I5,KSr),e(I5,wY),e(wY,ZSr),e(I5,eRr),e(xe,oRr),e(xe,q5),e(q5,x7e),e(x7e,rRr),e(q5,tRr),e(q5,AY),e(AY,aRr),e(q5,nRr),e(xe,sRr),e(xe,N5),e(N5,$7e),e($7e,lRr),e(N5,iRr),e(N5,yY),e(yY,dRr),e(N5,cRr),e(xe,fRr),e(xe,j5),e(j5,k7e),e(k7e,mRr),e(j5,gRr),e(j5,LY),e(LY,hRr),e(j5,pRr),e(xe,uRr),e(xe,D5),e(D5,S7e),e(S7e,_Rr),e(D5,bRr),e(D5,xY),e(xY,vRr),e(D5,FRr),e(xe,TRr),e(xe,G5),e(G5,R7e),e(R7e,MRr),e(G5,ERr),e(G5,$Y),e($Y,CRr),e(G5,wRr),e(Xr,ARr),M(O5,Xr,null),b(f,gNe,_),b(f,zc,_),e(zc,V5),e(V5,B7e),M(Rx,B7e,null),e(zc,yRr),e(zc,P7e),e(P7e,LRr),b(f,hNe,_),b(f,_r,_),M(Bx,_r,null),e(_r,xRr),e(_r,Qc),e(Qc,$Rr),e(Qc,kY),e(kY,kRr),e(Qc,SRr),e(Qc,SY),e(SY,RRr),e(Qc,BRr),e(_r,PRr),e(_r,Px),e(Px,IRr),e(Px,I7e),e(I7e,qRr),e(Px,NRr),e(_r,jRr),e(_r,zt),M(Ix,zt,null),e(zt,DRr),e(zt,q7e),e(q7e,GRr),e(zt,ORr),e(zt,Wc),e(Wc,VRr),e(Wc,N7e),e(N7e,XRr),e(Wc,zRr),e(Wc,RY),e(RY,QRr),e(Wc,WRr),e(zt,HRr),M(X5,zt,null),e(_r,URr),e(_r,zr),M(qx,zr,null),e(zr,JRr),e(zr,j7e),e(j7e,YRr),e(zr,KRr),e(zr,vn),e(vn,ZRr),e(vn,D7e),e(D7e,eBr),e(vn,oBr),e(vn,G7e),e(G7e,rBr),e(vn,tBr),e(vn,O7e),e(O7e,aBr),e(vn,nBr),e(zr,sBr),e(zr,$e),e($e,z5),e(z5,V7e),e(V7e,lBr),e(z5,iBr),e(z5,BY),e(BY,dBr),e(z5,cBr),e($e,fBr),e($e,Q5),e(Q5,X7e),e(X7e,mBr),e(Q5,gBr),e(Q5,PY),e(PY,hBr),e(Q5,pBr),e($e,uBr),e($e,W5),e(W5,z7e),e(z7e,_Br),e(W5,bBr),e(W5,IY),e(IY,vBr),e(W5,FBr),e($e,TBr),e($e,H5),e(H5,Q7e),e(Q7e,MBr),e(H5,EBr),e(H5,qY),e(qY,CBr),e(H5,wBr),e($e,ABr),e($e,U5),e(U5,W7e),e(W7e,yBr),e(U5,LBr),e(U5,NY),e(NY,xBr),e(U5,$Br),e($e,kBr),e($e,J5),e(J5,H7e),e(H7e,SBr),e(J5,RBr),e(J5,jY),e(jY,BBr),e(J5,PBr),e($e,IBr),e($e,Y5),e(Y5,U7e),e(U7e,qBr),e(Y5,NBr),e(Y5,DY),e(DY,jBr),e(Y5,DBr),e($e,GBr),e($e,K5),e(K5,J7e),e(J7e,OBr),e(K5,VBr),e(K5,GY),e(GY,XBr),e(K5,zBr),e($e,QBr),e($e,Z5),e(Z5,Y7e),e(Y7e,WBr),e(Z5,HBr),e(Z5,OY),e(OY,UBr),e(Z5,JBr),e($e,YBr),e($e,eC),e(eC,K7e),e(K7e,KBr),e(eC,ZBr),e(eC,VY),e(VY,ePr),e(eC,oPr),e(zr,rPr),M(oC,zr,null),b(f,pNe,_),b(f,Hc,_),e(Hc,rC),e(rC,Z7e),M(Nx,Z7e,null),e(Hc,tPr),e(Hc,eMe),e(eMe,aPr),b(f,uNe,_),b(f,br,_),M(jx,br,null),e(br,nPr),e(br,Uc),e(Uc,sPr),e(Uc,XY),e(XY,lPr),e(Uc,iPr),e(Uc,zY),e(zY,dPr),e(Uc,cPr),e(br,fPr),e(br,Dx),e(Dx,mPr),e(Dx,oMe),e(oMe,gPr),e(Dx,hPr),e(br,pPr),e(br,Qt),M(Gx,Qt,null),e(Qt,uPr),e(Qt,rMe),e(rMe,_Pr),e(Qt,bPr),e(Qt,Jc),e(Jc,vPr),e(Jc,tMe),e(tMe,FPr),e(Jc,TPr),e(Jc,QY),e(QY,MPr),e(Jc,EPr),e(Qt,CPr),M(tC,Qt,null),e(br,wPr),e(br,Qr),M(Ox,Qr,null),e(Qr,APr),e(Qr,aMe),e(aMe,yPr),e(Qr,LPr),e(Qr,Fn),e(Fn,xPr),e(Fn,nMe),e(nMe,$Pr),e(Fn,kPr),e(Fn,sMe),e(sMe,SPr),e(Fn,RPr),e(Fn,lMe),e(lMe,BPr),e(Fn,PPr),e(Qr,IPr),e(Qr,De),e(De,aC),e(aC,iMe),e(iMe,qPr),e(aC,NPr),e(aC,WY),e(WY,jPr),e(aC,DPr),e(De,GPr),e(De,nC),e(nC,dMe),e(dMe,OPr),e(nC,VPr),e(nC,HY),e(HY,XPr),e(nC,zPr),e(De,QPr),e(De,sC),e(sC,cMe),e(cMe,WPr),e(sC,HPr),e(sC,UY),e(UY,UPr),e(sC,JPr),e(De,YPr),e(De,lC),e(lC,fMe),e(fMe,KPr),e(lC,ZPr),e(lC,JY),e(JY,eIr),e(lC,oIr),e(De,rIr),e(De,iC),e(iC,mMe),e(mMe,tIr),e(iC,aIr),e(iC,YY),e(YY,nIr),e(iC,sIr),e(De,lIr),e(De,dC),e(dC,gMe),e(gMe,iIr),e(dC,dIr),e(dC,KY),e(KY,cIr),e(dC,fIr),e(De,mIr),e(De,cC),e(cC,hMe),e(hMe,gIr),e(cC,hIr),e(cC,ZY),e(ZY,pIr),e(cC,uIr),e(De,_Ir),e(De,fC),e(fC,pMe),e(pMe,bIr),e(fC,vIr),e(fC,eK),e(eK,FIr),e(fC,TIr),e(Qr,MIr),M(mC,Qr,null),b(f,_Ne,_),b(f,Yc,_),e(Yc,gC),e(gC,uMe),M(Vx,uMe,null),e(Yc,EIr),e(Yc,_Me),e(_Me,CIr),b(f,bNe,_),b(f,vr,_),M(Xx,vr,null),e(vr,wIr),e(vr,Kc),e(Kc,AIr),e(Kc,oK),e(oK,yIr),e(Kc,LIr),e(Kc,rK),e(rK,xIr),e(Kc,$Ir),e(vr,kIr),e(vr,zx),e(zx,SIr),e(zx,bMe),e(bMe,RIr),e(zx,BIr),e(vr,PIr),e(vr,Wt),M(Qx,Wt,null),e(Wt,IIr),e(Wt,vMe),e(vMe,qIr),e(Wt,NIr),e(Wt,Zc),e(Zc,jIr),e(Zc,FMe),e(FMe,DIr),e(Zc,GIr),e(Zc,tK),e(tK,OIr),e(Zc,VIr),e(Wt,XIr),M(hC,Wt,null),e(vr,zIr),e(vr,Wr),M(Wx,Wr,null),e(Wr,QIr),e(Wr,TMe),e(TMe,WIr),e(Wr,HIr),e(Wr,Tn),e(Tn,UIr),e(Tn,MMe),e(MMe,JIr),e(Tn,YIr),e(Tn,EMe),e(EMe,KIr),e(Tn,ZIr),e(Tn,CMe),e(CMe,eqr),e(Tn,oqr),e(Wr,rqr),e(Wr,Ge),e(Ge,pC),e(pC,wMe),e(wMe,tqr),e(pC,aqr),e(pC,aK),e(aK,nqr),e(pC,sqr),e(Ge,lqr),e(Ge,uC),e(uC,AMe),e(AMe,iqr),e(uC,dqr),e(uC,nK),e(nK,cqr),e(uC,fqr),e(Ge,mqr),e(Ge,_C),e(_C,yMe),e(yMe,gqr),e(_C,hqr),e(_C,sK),e(sK,pqr),e(_C,uqr),e(Ge,_qr),e(Ge,bC),e(bC,LMe),e(LMe,bqr),e(bC,vqr),e(bC,lK),e(lK,Fqr),e(bC,Tqr),e(Ge,Mqr),e(Ge,vC),e(vC,xMe),e(xMe,Eqr),e(vC,Cqr),e(vC,iK),e(iK,wqr),e(vC,Aqr),e(Ge,yqr),e(Ge,FC),e(FC,$Me),e($Me,Lqr),e(FC,xqr),e(FC,dK),e(dK,$qr),e(FC,kqr),e(Ge,Sqr),e(Ge,TC),e(TC,kMe),e(kMe,Rqr),e(TC,Bqr),e(TC,cK),e(cK,Pqr),e(TC,Iqr),e(Ge,qqr),e(Ge,MC),e(MC,SMe),e(SMe,Nqr),e(MC,jqr),e(MC,fK),e(fK,Dqr),e(MC,Gqr),e(Wr,Oqr),M(EC,Wr,null),b(f,vNe,_),b(f,ef,_),e(ef,CC),e(CC,RMe),M(Hx,RMe,null),e(ef,Vqr),e(ef,BMe),e(BMe,Xqr),b(f,FNe,_),b(f,Fr,_),M(Ux,Fr,null),e(Fr,zqr),e(Fr,of),e(of,Qqr),e(of,mK),e(mK,Wqr),e(of,Hqr),e(of,gK),e(gK,Uqr),e(of,Jqr),e(Fr,Yqr),e(Fr,Jx),e(Jx,Kqr),e(Jx,PMe),e(PMe,Zqr),e(Jx,eNr),e(Fr,oNr),e(Fr,Ht),M(Yx,Ht,null),e(Ht,rNr),e(Ht,IMe),e(IMe,tNr),e(Ht,aNr),e(Ht,rf),e(rf,nNr),e(rf,qMe),e(qMe,sNr),e(rf,lNr),e(rf,hK),e(hK,iNr),e(rf,dNr),e(Ht,cNr),M(wC,Ht,null),e(Fr,fNr),e(Fr,Hr),M(Kx,Hr,null),e(Hr,mNr),e(Hr,NMe),e(NMe,gNr),e(Hr,hNr),e(Hr,Mn),e(Mn,pNr),e(Mn,jMe),e(jMe,uNr),e(Mn,_Nr),e(Mn,DMe),e(DMe,bNr),e(Mn,vNr),e(Mn,GMe),e(GMe,FNr),e(Mn,TNr),e(Hr,MNr),e(Hr,OMe),e(OMe,AC),e(AC,VMe),e(VMe,ENr),e(AC,CNr),e(AC,pK),e(pK,wNr),e(AC,ANr),e(Hr,yNr),M(yC,Hr,null),b(f,TNe,_),b(f,tf,_),e(tf,LC),e(LC,XMe),M(Zx,XMe,null),e(tf,LNr),e(tf,zMe),e(zMe,xNr),b(f,MNe,_),b(f,Tr,_),M(e9,Tr,null),e(Tr,$Nr),e(Tr,af),e(af,kNr),e(af,uK),e(uK,SNr),e(af,RNr),e(af,_K),e(_K,BNr),e(af,PNr),e(Tr,INr),e(Tr,o9),e(o9,qNr),e(o9,QMe),e(QMe,NNr),e(o9,jNr),e(Tr,DNr),e(Tr,Ut),M(r9,Ut,null),e(Ut,GNr),e(Ut,WMe),e(WMe,ONr),e(Ut,VNr),e(Ut,nf),e(nf,XNr),e(nf,HMe),e(HMe,zNr),e(nf,QNr),e(nf,bK),e(bK,WNr),e(nf,HNr),e(Ut,UNr),M(xC,Ut,null),e(Tr,JNr),e(Tr,Ur),M(t9,Ur,null),e(Ur,YNr),e(Ur,UMe),e(UMe,KNr),e(Ur,ZNr),e(Ur,En),e(En,ejr),e(En,JMe),e(JMe,ojr),e(En,rjr),e(En,YMe),e(YMe,tjr),e(En,ajr),e(En,KMe),e(KMe,njr),e(En,sjr),e(Ur,ljr),e(Ur,a9),e(a9,$C),e($C,ZMe),e(ZMe,ijr),e($C,djr),e($C,vK),e(vK,cjr),e($C,fjr),e(a9,mjr),e(a9,kC),e(kC,e4e),e(e4e,gjr),e(kC,hjr),e(kC,FK),e(FK,pjr),e(kC,ujr),e(Ur,_jr),M(SC,Ur,null),b(f,ENe,_),b(f,sf,_),e(sf,RC),e(RC,o4e),M(n9,o4e,null),e(sf,bjr),e(sf,r4e),e(r4e,vjr),b(f,CNe,_),b(f,Mr,_),M(s9,Mr,null),e(Mr,Fjr),e(Mr,lf),e(lf,Tjr),e(lf,TK),e(TK,Mjr),e(lf,Ejr),e(lf,MK),e(MK,Cjr),e(lf,wjr),e(Mr,Ajr),e(Mr,l9),e(l9,yjr),e(l9,t4e),e(t4e,Ljr),e(l9,xjr),e(Mr,$jr),e(Mr,Jt),M(i9,Jt,null),e(Jt,kjr),e(Jt,a4e),e(a4e,Sjr),e(Jt,Rjr),e(Jt,df),e(df,Bjr),e(df,n4e),e(n4e,Pjr),e(df,Ijr),e(df,EK),e(EK,qjr),e(df,Njr),e(Jt,jjr),M(BC,Jt,null),e(Mr,Djr),e(Mr,Jr),M(d9,Jr,null),e(Jr,Gjr),e(Jr,s4e),e(s4e,Ojr),e(Jr,Vjr),e(Jr,Cn),e(Cn,Xjr),e(Cn,l4e),e(l4e,zjr),e(Cn,Qjr),e(Cn,i4e),e(i4e,Wjr),e(Cn,Hjr),e(Cn,d4e),e(d4e,Ujr),e(Cn,Jjr),e(Jr,Yjr),e(Jr,c4e),e(c4e,PC),e(PC,f4e),e(f4e,Kjr),e(PC,Zjr),e(PC,CK),e(CK,eDr),e(PC,oDr),e(Jr,rDr),M(IC,Jr,null),wNe=!0},p(f,[_]){const c9={};_&2&&(c9.$$scope={dirty:_,ctx:f}),bf.$set(c9);const m4e={};_&2&&(m4e.$$scope={dirty:_,ctx:f}),bg.$set(m4e);const g4e={};_&2&&(g4e.$$scope={dirty:_,ctx:f}),Yg.$set(g4e);const h4e={};_&2&&(h4e.$$scope={dirty:_,ctx:f}),Ah.$set(h4e);const f9={};_&2&&(f9.$$scope={dirty:_,ctx:f}),yh.$set(f9);const p4e={};_&2&&(p4e.$$scope={dirty:_,ctx:f}),Qh.$set(p4e);const wn={};_&2&&(wn.$$scope={dirty:_,ctx:f}),Wh.$set(wn);const u4e={};_&2&&(u4e.$$scope={dirty:_,ctx:f}),Jh.$set(u4e);const _4e={};_&2&&(_4e.$$scope={dirty:_,ctx:f}),Gu.$set(_4e);const b4e={};_&2&&(b4e.$$scope={dirty:_,ctx:f}),Vu.$set(b4e);const m9={};_&2&&(m9.$$scope={dirty:_,ctx:f}),k_.$set(m9);const v4e={};_&2&&(v4e.$$scope={dirty:_,ctx:f}),R_.$set(v4e);const g9={};_&2&&(g9.$$scope={dirty:_,ctx:f}),_0.$set(g9);const F4e={};_&2&&(F4e.$$scope={dirty:_,ctx:f}),v0.$set(F4e);const h9={};_&2&&(h9.$$scope={dirty:_,ctx:f}),r1.$set(h9);const T4e={};_&2&&(T4e.$$scope={dirty:_,ctx:f}),a1.$set(T4e);const M4e={};_&2&&(M4e.$$scope={dirty:_,ctx:f}),E1.$set(M4e);const E4e={};_&2&&(E4e.$$scope={dirty:_,ctx:f}),w1.$set(E4e);const cf={};_&2&&(cf.$$scope={dirty:_,ctx:f}),Tb.$set(cf);const C4e={};_&2&&(C4e.$$scope={dirty:_,ctx:f}),Eb.$set(C4e);const w4e={};_&2&&(w4e.$$scope={dirty:_,ctx:f}),e2.$set(w4e);const A4e={};_&2&&(A4e.$$scope={dirty:_,ctx:f}),r2.$set(A4e);const p9={};_&2&&(p9.$$scope={dirty:_,ctx:f}),d2.$set(p9);const y4e={};_&2&&(y4e.$$scope={dirty:_,ctx:f}),f2.$set(y4e);const L4e={};_&2&&(L4e.$$scope={dirty:_,ctx:f}),W2.$set(L4e);const x4e={};_&2&&(x4e.$$scope={dirty:_,ctx:f}),U2.$set(x4e);const Kr={};_&2&&(Kr.$$scope={dirty:_,ctx:f}),qv.$set(Kr);const u9={};_&2&&(u9.$$scope={dirty:_,ctx:f}),jv.$set(u9);const $4e={};_&2&&($4e.$$scope={dirty:_,ctx:f}),Ov.$set($4e);const _9={};_&2&&(_9.$$scope={dirty:_,ctx:f}),Xv.$set(_9);const k4e={};_&2&&(k4e.$$scope={dirty:_,ctx:f}),tF.$set(k4e);const Zr={};_&2&&(Zr.$$scope={dirty:_,ctx:f}),nF.$set(Zr);const S4e={};_&2&&(S4e.$$scope={dirty:_,ctx:f}),iF.$set(S4e);const ff={};_&2&&(ff.$$scope={dirty:_,ctx:f}),cF.$set(ff);const R4e={};_&2&&(R4e.$$scope={dirty:_,ctx:f}),FF.$set(R4e);const B4e={};_&2&&(B4e.$$scope={dirty:_,ctx:f}),MF.$set(B4e);const y={};_&2&&(y.$$scope={dirty:_,ctx:f}),LF.$set(y);const qC={};_&2&&(qC.$$scope={dirty:_,ctx:f}),$F.$set(qC);const P4e={};_&2&&(P4e.$$scope={dirty:_,ctx:f}),DF.$set(P4e);const I4e={};_&2&&(I4e.$$scope={dirty:_,ctx:f}),OF.$set(I4e);const NC={};_&2&&(NC.$$scope={dirty:_,ctx:f}),QF.$set(NC);const q4e={};_&2&&(q4e.$$scope={dirty:_,ctx:f}),HF.$set(q4e);const N4e={};_&2&&(N4e.$$scope={dirty:_,ctx:f}),e6.$set(N4e);const jC={};_&2&&(jC.$$scope={dirty:_,ctx:f}),r6.$set(jC);const j4e={};_&2&&(j4e.$$scope={dirty:_,ctx:f}),l6.$set(j4e);const D4e={};_&2&&(D4e.$$scope={dirty:_,ctx:f}),d6.$set(D4e);const DC={};_&2&&(DC.$$scope={dirty:_,ctx:f}),g6.$set(DC);const G4e={};_&2&&(G4e.$$scope={dirty:_,ctx:f}),p6.$set(G4e);const O4e={};_&2&&(O4e.$$scope={dirty:_,ctx:f}),b6.$set(O4e);const GC={};_&2&&(GC.$$scope={dirty:_,ctx:f}),F6.$set(GC);const V4e={};_&2&&(V4e.$$scope={dirty:_,ctx:f}),A6.$set(V4e);const X4e={};_&2&&(X4e.$$scope={dirty:_,ctx:f}),L6.$set(X4e);const OC={};_&2&&(OC.$$scope={dirty:_,ctx:f}),k6.$set(OC);const z4e={};_&2&&(z4e.$$scope={dirty:_,ctx:f}),R6.$set(z4e);const Q4e={};_&2&&(Q4e.$$scope={dirty:_,ctx:f}),CT.$set(Q4e);const VC={};_&2&&(VC.$$scope={dirty:_,ctx:f}),AT.$set(VC);const W4e={};_&2&&(W4e.$$scope={dirty:_,ctx:f}),JT.$set(W4e);const H4e={};_&2&&(H4e.$$scope={dirty:_,ctx:f}),KT.$set(H4e);const XC={};_&2&&(XC.$$scope={dirty:_,ctx:f}),f7.$set(XC);const U4e={};_&2&&(U4e.$$scope={dirty:_,ctx:f}),g7.$set(U4e);const J4e={};_&2&&(J4e.$$scope={dirty:_,ctx:f}),_7.$set(J4e);const zC={};_&2&&(zC.$$scope={dirty:_,ctx:f}),v7.$set(zC);const Y4e={};_&2&&(Y4e.$$scope={dirty:_,ctx:f}),D7.$set(Y4e);const K4e={};_&2&&(K4e.$$scope={dirty:_,ctx:f}),O7.$set(K4e);const QC={};_&2&&(QC.$$scope={dirty:_,ctx:f}),Z7.$set(QC);const Z4e={};_&2&&(Z4e.$$scope={dirty:_,ctx:f}),oM.$set(Z4e);const eEe={};_&2&&(eEe.$$scope={dirty:_,ctx:f}),LM.$set(eEe);const WC={};_&2&&(WC.$$scope={dirty:_,ctx:f}),$M.$set(WC);const oEe={};_&2&&(oEe.$$scope={dirty:_,ctx:f}),HM.$set(oEe);const rEe={};_&2&&(rEe.$$scope={dirty:_,ctx:f}),JM.$set(rEe);const HC={};_&2&&(HC.$$scope={dirty:_,ctx:f}),ZM.$set(HC);const tEe={};_&2&&(tEe.$$scope={dirty:_,ctx:f}),o4.$set(tEe);const aEe={};_&2&&(aEe.$$scope={dirty:_,ctx:f}),t4.$set(aEe);const UC={};_&2&&(UC.$$scope={dirty:_,ctx:f}),n4.$set(UC);const nEe={};_&2&&(nEe.$$scope={dirty:_,ctx:f}),A4.$set(nEe);const sEe={};_&2&&(sEe.$$scope={dirty:_,ctx:f}),L4.$set(sEe);const JC={};_&2&&(JC.$$scope={dirty:_,ctx:f}),U4.$set(JC);const lEe={};_&2&&(lEe.$$scope={dirty:_,ctx:f}),Y4.$set(lEe);const iEe={};_&2&&(iEe.$$scope={dirty:_,ctx:f}),Z4.$set(iEe);const YC={};_&2&&(YC.$$scope={dirty:_,ctx:f}),oE.$set(YC);const dEe={};_&2&&(dEe.$$scope={dirty:_,ctx:f}),tE.$set(dEe);const cEe={};_&2&&(cEe.$$scope={dirty:_,ctx:f}),nE.$set(cEe);const KC={};_&2&&(KC.$$scope={dirty:_,ctx:f}),kE.$set(KC);const fEe={};_&2&&(fEe.$$scope={dirty:_,ctx:f}),RE.$set(fEe);const mEe={};_&2&&(mEe.$$scope={dirty:_,ctx:f}),VE.$set(mEe);const ZC={};_&2&&(ZC.$$scope={dirty:_,ctx:f}),zE.$set(ZC);const gEe={};_&2&&(gEe.$$scope={dirty:_,ctx:f}),a5.$set(gEe);const hEe={};_&2&&(hEe.$$scope={dirty:_,ctx:f}),s5.$set(hEe);const e3={};_&2&&(e3.$$scope={dirty:_,ctx:f}),_5.$set(e3);const pEe={};_&2&&(pEe.$$scope={dirty:_,ctx:f}),v5.$set(pEe);const uEe={};_&2&&(uEe.$$scope={dirty:_,ctx:f}),x5.$set(uEe);const o3={};_&2&&(o3.$$scope={dirty:_,ctx:f}),k5.$set(o3);const _Ee={};_&2&&(_Ee.$$scope={dirty:_,ctx:f}),O5.$set(_Ee);const bEe={};_&2&&(bEe.$$scope={dirty:_,ctx:f}),X5.$set(bEe);const r3={};_&2&&(r3.$$scope={dirty:_,ctx:f}),oC.$set(r3);const vEe={};_&2&&(vEe.$$scope={dirty:_,ctx:f}),tC.$set(vEe);const FEe={};_&2&&(FEe.$$scope={dirty:_,ctx:f}),mC.$set(FEe);const t3={};_&2&&(t3.$$scope={dirty:_,ctx:f}),hC.$set(t3);const TEe={};_&2&&(TEe.$$scope={dirty:_,ctx:f}),EC.$set(TEe);const MEe={};_&2&&(MEe.$$scope={dirty:_,ctx:f}),wC.$set(MEe);const a3={};_&2&&(a3.$$scope={dirty:_,ctx:f}),yC.$set(a3);const EEe={};_&2&&(EEe.$$scope={dirty:_,ctx:f}),xC.$set(EEe);const CEe={};_&2&&(CEe.$$scope={dirty:_,ctx:f}),SC.$set(CEe);const n3={};_&2&&(n3.$$scope={dirty:_,ctx:f}),BC.$set(n3);const wEe={};_&2&&(wEe.$$scope={dirty:_,ctx:f}),IC.$set(wEe)},i(f){wNe||(E(d.$$.fragment,f),E(Ma.$$.fragment,f),E(nA.$$.fragment,f),E(sA.$$.fragment,f),E(bf.$$.fragment,f),E(lA.$$.fragment,f),E(iA.$$.fragment,f),E(fA.$$.fragment,f),E(bg.$$.fragment,f),E(mA.$$.fragment,f),E(gA.$$.fragment,f),E(hA.$$.fragment,f),E(_A.$$.fragment,f),E(Yg.$$.fragment,f),E(bA.$$.fragment,f),E(vA.$$.fragment,f),E(FA.$$.fragment,f),E(EA.$$.fragment,f),E(Ah.$$.fragment,f),E(yh.$$.fragment,f),E(CA.$$.fragment,f),E(wA.$$.fragment,f),E(AA.$$.fragment,f),E(xA.$$.fragment,f),E(Qh.$$.fragment,f),E(Wh.$$.fragment,f),E($A.$$.fragment,f),E(kA.$$.fragment,f),E(SA.$$.fragment,f),E(BA.$$.fragment,f),E(Jh.$$.fragment,f),E(PA.$$.fragment,f),E(Gu.$$.fragment,f),E(IA.$$.fragment,f),E(qA.$$.fragment,f),E(jA.$$.fragment,f),E(Vu.$$.fragment,f),E(DA.$$.fragment,f),E(k_.$$.fragment,f),E(GA.$$.fragment,f),E(OA.$$.fragment,f),E(XA.$$.fragment,f),E(R_.$$.fragment,f),E(zA.$$.fragment,f),E(_0.$$.fragment,f),E(QA.$$.fragment,f),E(WA.$$.fragment,f),E(UA.$$.fragment,f),E(v0.$$.fragment,f),E(JA.$$.fragment,f),E(r1.$$.fragment,f),E(YA.$$.fragment,f),E(KA.$$.fragment,f),E(ey.$$.fragment,f),E(a1.$$.fragment,f),E(oy.$$.fragment,f),E(E1.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(ny.$$.fragment,f),E(w1.$$.fragment,f),E(sy.$$.fragment,f),E(Tb.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(cy.$$.fragment,f),E(Eb.$$.fragment,f),E(fy.$$.fragment,f),E(e2.$$.fragment,f),E(my.$$.fragment,f),E(gy.$$.fragment,f),E(py.$$.fragment,f),E(r2.$$.fragment,f),E(uy.$$.fragment,f),E(d2.$$.fragment,f),E(_y.$$.fragment,f),E(by.$$.fragment,f),E(Fy.$$.fragment,f),E(f2.$$.fragment,f),E(Ty.$$.fragment,f),E(W2.$$.fragment,f),E(My.$$.fragment,f),E(Ey.$$.fragment,f),E(wy.$$.fragment,f),E(U2.$$.fragment,f),E(Ay.$$.fragment,f),E(qv.$$.fragment,f),E(yy.$$.fragment,f),E(Ly.$$.fragment,f),E($y.$$.fragment,f),E(jv.$$.fragment,f),E(ky.$$.fragment,f),E(Ov.$$.fragment,f),E(Sy.$$.fragment,f),E(Ry.$$.fragment,f),E(Py.$$.fragment,f),E(Xv.$$.fragment,f),E(Iy.$$.fragment,f),E(tF.$$.fragment,f),E(qy.$$.fragment,f),E(Ny.$$.fragment,f),E(Dy.$$.fragment,f),E(nF.$$.fragment,f),E(Gy.$$.fragment,f),E(iF.$$.fragment,f),E(Oy.$$.fragment,f),E(Vy.$$.fragment,f),E(zy.$$.fragment,f),E(cF.$$.fragment,f),E(Qy.$$.fragment,f),E(FF.$$.fragment,f),E(Wy.$$.fragment,f),E(Hy.$$.fragment,f),E(Jy.$$.fragment,f),E(MF.$$.fragment,f),E(Yy.$$.fragment,f),E(LF.$$.fragment,f),E(Ky.$$.fragment,f),E(Zy.$$.fragment,f),E(oL.$$.fragment,f),E($F.$$.fragment,f),E(rL.$$.fragment,f),E(DF.$$.fragment,f),E(tL.$$.fragment,f),E(aL.$$.fragment,f),E(sL.$$.fragment,f),E(OF.$$.fragment,f),E(lL.$$.fragment,f),E(QF.$$.fragment,f),E(dL.$$.fragment,f),E(cL.$$.fragment,f),E(mL.$$.fragment,f),E(HF.$$.fragment,f),E(gL.$$.fragment,f),E(e6.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(_L.$$.fragment,f),E(r6.$$.fragment,f),E(bL.$$.fragment,f),E(l6.$$.fragment,f),E(vL.$$.fragment,f),E(FL.$$.fragment,f),E(ML.$$.fragment,f),E(d6.$$.fragment,f),E(EL.$$.fragment,f),E(g6.$$.fragment,f),E(wL.$$.fragment,f),E(AL.$$.fragment,f),E(LL.$$.fragment,f),E(p6.$$.fragment,f),E(xL.$$.fragment,f),E(b6.$$.fragment,f),E($L.$$.fragment,f),E(kL.$$.fragment,f),E(RL.$$.fragment,f),E(F6.$$.fragment,f),E(BL.$$.fragment,f),E(A6.$$.fragment,f),E(PL.$$.fragment,f),E(IL.$$.fragment,f),E(NL.$$.fragment,f),E(L6.$$.fragment,f),E(jL.$$.fragment,f),E(k6.$$.fragment,f),E(DL.$$.fragment,f),E(GL.$$.fragment,f),E(VL.$$.fragment,f),E(R6.$$.fragment,f),E(XL.$$.fragment,f),E(CT.$$.fragment,f),E(zL.$$.fragment,f),E(QL.$$.fragment,f),E(HL.$$.fragment,f),E(AT.$$.fragment,f),E(UL.$$.fragment,f),E(JT.$$.fragment,f),E(JL.$$.fragment,f),E(YL.$$.fragment,f),E(ZL.$$.fragment,f),E(KT.$$.fragment,f),E(e8.$$.fragment,f),E(f7.$$.fragment,f),E(o8.$$.fragment,f),E(r8.$$.fragment,f),E(a8.$$.fragment,f),E(g7.$$.fragment,f),E(n8.$$.fragment,f),E(_7.$$.fragment,f),E(s8.$$.fragment,f),E(l8.$$.fragment,f),E(d8.$$.fragment,f),E(v7.$$.fragment,f),E(c8.$$.fragment,f),E(D7.$$.fragment,f),E(f8.$$.fragment,f),E(m8.$$.fragment,f),E(h8.$$.fragment,f),E(O7.$$.fragment,f),E(p8.$$.fragment,f),E(Z7.$$.fragment,f),E(u8.$$.fragment,f),E(_8.$$.fragment,f),E(v8.$$.fragment,f),E(oM.$$.fragment,f),E(F8.$$.fragment,f),E(LM.$$.fragment,f),E(T8.$$.fragment,f),E(M8.$$.fragment,f),E(C8.$$.fragment,f),E($M.$$.fragment,f),E(w8.$$.fragment,f),E(HM.$$.fragment,f),E(A8.$$.fragment,f),E(y8.$$.fragment,f),E(x8.$$.fragment,f),E(JM.$$.fragment,f),E($8.$$.fragment,f),E(ZM.$$.fragment,f),E(S8.$$.fragment,f),E(R8.$$.fragment,f),E(P8.$$.fragment,f),E(o4.$$.fragment,f),E(I8.$$.fragment,f),E(t4.$$.fragment,f),E(q8.$$.fragment,f),E(N8.$$.fragment,f),E(D8.$$.fragment,f),E(n4.$$.fragment,f),E(G8.$$.fragment,f),E(A4.$$.fragment,f),E(O8.$$.fragment,f),E(V8.$$.fragment,f),E(z8.$$.fragment,f),E(L4.$$.fragment,f),E(Q8.$$.fragment,f),E(U4.$$.fragment,f),E(W8.$$.fragment,f),E(H8.$$.fragment,f),E(J8.$$.fragment,f),E(Y4.$$.fragment,f),E(Y8.$$.fragment,f),E(Z4.$$.fragment,f),E(K8.$$.fragment,f),E(Z8.$$.fragment,f),E(ox.$$.fragment,f),E(oE.$$.fragment,f),E(rx.$$.fragment,f),E(tE.$$.fragment,f),E(tx.$$.fragment,f),E(ax.$$.fragment,f),E(sx.$$.fragment,f),E(nE.$$.fragment,f),E(lx.$$.fragment,f),E(kE.$$.fragment,f),E(ix.$$.fragment,f),E(dx.$$.fragment,f),E(fx.$$.fragment,f),E(RE.$$.fragment,f),E(mx.$$.fragment,f),E(VE.$$.fragment,f),E(gx.$$.fragment,f),E(hx.$$.fragment,f),E(ux.$$.fragment,f),E(zE.$$.fragment,f),E(_x.$$.fragment,f),E(a5.$$.fragment,f),E(bx.$$.fragment,f),E(vx.$$.fragment,f),E(Tx.$$.fragment,f),E(s5.$$.fragment,f),E(Mx.$$.fragment,f),E(_5.$$.fragment,f),E(Ex.$$.fragment,f),E(Cx.$$.fragment,f),E(Ax.$$.fragment,f),E(v5.$$.fragment,f),E(yx.$$.fragment,f),E(x5.$$.fragment,f),E(Lx.$$.fragment,f),E(xx.$$.fragment,f),E(kx.$$.fragment,f),E(k5.$$.fragment,f),E(Sx.$$.fragment,f),E(O5.$$.fragment,f),E(Rx.$$.fragment,f),E(Bx.$$.fragment,f),E(Ix.$$.fragment,f),E(X5.$$.fragment,f),E(qx.$$.fragment,f),E(oC.$$.fragment,f),E(Nx.$$.fragment,f),E(jx.$$.fragment,f),E(Gx.$$.fragment,f),E(tC.$$.fragment,f),E(Ox.$$.fragment,f),E(mC.$$.fragment,f),E(Vx.$$.fragment,f),E(Xx.$$.fragment,f),E(Qx.$$.fragment,f),E(hC.$$.fragment,f),E(Wx.$$.fragment,f),E(EC.$$.fragment,f),E(Hx.$$.fragment,f),E(Ux.$$.fragment,f),E(Yx.$$.fragment,f),E(wC.$$.fragment,f),E(Kx.$$.fragment,f),E(yC.$$.fragment,f),E(Zx.$$.fragment,f),E(e9.$$.fragment,f),E(r9.$$.fragment,f),E(xC.$$.fragment,f),E(t9.$$.fragment,f),E(SC.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(BC.$$.fragment,f),E(d9.$$.fragment,f),E(IC.$$.fragment,f),wNe=!0)},o(f){C(d.$$.fragment,f),C(Ma.$$.fragment,f),C(nA.$$.fragment,f),C(sA.$$.fragment,f),C(bf.$$.fragment,f),C(lA.$$.fragment,f),C(iA.$$.fragment,f),C(fA.$$.fragment,f),C(bg.$$.fragment,f),C(mA.$$.fragment,f),C(gA.$$.fragment,f),C(hA.$$.fragment,f),C(_A.$$.fragment,f),C(Yg.$$.fragment,f),C(bA.$$.fragment,f),C(vA.$$.fragment,f),C(FA.$$.fragment,f),C(EA.$$.fragment,f),C(Ah.$$.fragment,f),C(yh.$$.fragment,f),C(CA.$$.fragment,f),C(wA.$$.fragment,f),C(AA.$$.fragment,f),C(xA.$$.fragment,f),C(Qh.$$.fragment,f),C(Wh.$$.fragment,f),C($A.$$.fragment,f),C(kA.$$.fragment,f),C(SA.$$.fragment,f),C(BA.$$.fragment,f),C(Jh.$$.fragment,f),C(PA.$$.fragment,f),C(Gu.$$.fragment,f),C(IA.$$.fragment,f),C(qA.$$.fragment,f),C(jA.$$.fragment,f),C(Vu.$$.fragment,f),C(DA.$$.fragment,f),C(k_.$$.fragment,f),C(GA.$$.fragment,f),C(OA.$$.fragment,f),C(XA.$$.fragment,f),C(R_.$$.fragment,f),C(zA.$$.fragment,f),C(_0.$$.fragment,f),C(QA.$$.fragment,f),C(WA.$$.fragment,f),C(UA.$$.fragment,f),C(v0.$$.fragment,f),C(JA.$$.fragment,f),C(r1.$$.fragment,f),C(YA.$$.fragment,f),C(KA.$$.fragment,f),C(ey.$$.fragment,f),C(a1.$$.fragment,f),C(oy.$$.fragment,f),C(E1.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(ny.$$.fragment,f),C(w1.$$.fragment,f),C(sy.$$.fragment,f),C(Tb.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(cy.$$.fragment,f),C(Eb.$$.fragment,f),C(fy.$$.fragment,f),C(e2.$$.fragment,f),C(my.$$.fragment,f),C(gy.$$.fragment,f),C(py.$$.fragment,f),C(r2.$$.fragment,f),C(uy.$$.fragment,f),C(d2.$$.fragment,f),C(_y.$$.fragment,f),C(by.$$.fragment,f),C(Fy.$$.fragment,f),C(f2.$$.fragment,f),C(Ty.$$.fragment,f),C(W2.$$.fragment,f),C(My.$$.fragment,f),C(Ey.$$.fragment,f),C(wy.$$.fragment,f),C(U2.$$.fragment,f),C(Ay.$$.fragment,f),C(qv.$$.fragment,f),C(yy.$$.fragment,f),C(Ly.$$.fragment,f),C($y.$$.fragment,f),C(jv.$$.fragment,f),C(ky.$$.fragment,f),C(Ov.$$.fragment,f),C(Sy.$$.fragment,f),C(Ry.$$.fragment,f),C(Py.$$.fragment,f),C(Xv.$$.fragment,f),C(Iy.$$.fragment,f),C(tF.$$.fragment,f),C(qy.$$.fragment,f),C(Ny.$$.fragment,f),C(Dy.$$.fragment,f),C(nF.$$.fragment,f),C(Gy.$$.fragment,f),C(iF.$$.fragment,f),C(Oy.$$.fragment,f),C(Vy.$$.fragment,f),C(zy.$$.fragment,f),C(cF.$$.fragment,f),C(Qy.$$.fragment,f),C(FF.$$.fragment,f),C(Wy.$$.fragment,f),C(Hy.$$.fragment,f),C(Jy.$$.fragment,f),C(MF.$$.fragment,f),C(Yy.$$.fragment,f),C(LF.$$.fragment,f),C(Ky.$$.fragment,f),C(Zy.$$.fragment,f),C(oL.$$.fragment,f),C($F.$$.fragment,f),C(rL.$$.fragment,f),C(DF.$$.fragment,f),C(tL.$$.fragment,f),C(aL.$$.fragment,f),C(sL.$$.fragment,f),C(OF.$$.fragment,f),C(lL.$$.fragment,f),C(QF.$$.fragment,f),C(dL.$$.fragment,f),C(cL.$$.fragment,f),C(mL.$$.fragment,f),C(HF.$$.fragment,f),C(gL.$$.fragment,f),C(e6.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(_L.$$.fragment,f),C(r6.$$.fragment,f),C(bL.$$.fragment,f),C(l6.$$.fragment,f),C(vL.$$.fragment,f),C(FL.$$.fragment,f),C(ML.$$.fragment,f),C(d6.$$.fragment,f),C(EL.$$.fragment,f),C(g6.$$.fragment,f),C(wL.$$.fragment,f),C(AL.$$.fragment,f),C(LL.$$.fragment,f),C(p6.$$.fragment,f),C(xL.$$.fragment,f),C(b6.$$.fragment,f),C($L.$$.fragment,f),C(kL.$$.fragment,f),C(RL.$$.fragment,f),C(F6.$$.fragment,f),C(BL.$$.fragment,f),C(A6.$$.fragment,f),C(PL.$$.fragment,f),C(IL.$$.fragment,f),C(NL.$$.fragment,f),C(L6.$$.fragment,f),C(jL.$$.fragment,f),C(k6.$$.fragment,f),C(DL.$$.fragment,f),C(GL.$$.fragment,f),C(VL.$$.fragment,f),C(R6.$$.fragment,f),C(XL.$$.fragment,f),C(CT.$$.fragment,f),C(zL.$$.fragment,f),C(QL.$$.fragment,f),C(HL.$$.fragment,f),C(AT.$$.fragment,f),C(UL.$$.fragment,f),C(JT.$$.fragment,f),C(JL.$$.fragment,f),C(YL.$$.fragment,f),C(ZL.$$.fragment,f),C(KT.$$.fragment,f),C(e8.$$.fragment,f),C(f7.$$.fragment,f),C(o8.$$.fragment,f),C(r8.$$.fragment,f),C(a8.$$.fragment,f),C(g7.$$.fragment,f),C(n8.$$.fragment,f),C(_7.$$.fragment,f),C(s8.$$.fragment,f),C(l8.$$.fragment,f),C(d8.$$.fragment,f),C(v7.$$.fragment,f),C(c8.$$.fragment,f),C(D7.$$.fragment,f),C(f8.$$.fragment,f),C(m8.$$.fragment,f),C(h8.$$.fragment,f),C(O7.$$.fragment,f),C(p8.$$.fragment,f),C(Z7.$$.fragment,f),C(u8.$$.fragment,f),C(_8.$$.fragment,f),C(v8.$$.fragment,f),C(oM.$$.fragment,f),C(F8.$$.fragment,f),C(LM.$$.fragment,f),C(T8.$$.fragment,f),C(M8.$$.fragment,f),C(C8.$$.fragment,f),C($M.$$.fragment,f),C(w8.$$.fragment,f),C(HM.$$.fragment,f),C(A8.$$.fragment,f),C(y8.$$.fragment,f),C(x8.$$.fragment,f),C(JM.$$.fragment,f),C($8.$$.fragment,f),C(ZM.$$.fragment,f),C(S8.$$.fragment,f),C(R8.$$.fragment,f),C(P8.$$.fragment,f),C(o4.$$.fragment,f),C(I8.$$.fragment,f),C(t4.$$.fragment,f),C(q8.$$.fragment,f),C(N8.$$.fragment,f),C(D8.$$.fragment,f),C(n4.$$.fragment,f),C(G8.$$.fragment,f),C(A4.$$.fragment,f),C(O8.$$.fragment,f),C(V8.$$.fragment,f),C(z8.$$.fragment,f),C(L4.$$.fragment,f),C(Q8.$$.fragment,f),C(U4.$$.fragment,f),C(W8.$$.fragment,f),C(H8.$$.fragment,f),C(J8.$$.fragment,f),C(Y4.$$.fragment,f),C(Y8.$$.fragment,f),C(Z4.$$.fragment,f),C(K8.$$.fragment,f),C(Z8.$$.fragment,f),C(ox.$$.fragment,f),C(oE.$$.fragment,f),C(rx.$$.fragment,f),C(tE.$$.fragment,f),C(tx.$$.fragment,f),C(ax.$$.fragment,f),C(sx.$$.fragment,f),C(nE.$$.fragment,f),C(lx.$$.fragment,f),C(kE.$$.fragment,f),C(ix.$$.fragment,f),C(dx.$$.fragment,f),C(fx.$$.fragment,f),C(RE.$$.fragment,f),C(mx.$$.fragment,f),C(VE.$$.fragment,f),C(gx.$$.fragment,f),C(hx.$$.fragment,f),C(ux.$$.fragment,f),C(zE.$$.fragment,f),C(_x.$$.fragment,f),C(a5.$$.fragment,f),C(bx.$$.fragment,f),C(vx.$$.fragment,f),C(Tx.$$.fragment,f),C(s5.$$.fragment,f),C(Mx.$$.fragment,f),C(_5.$$.fragment,f),C(Ex.$$.fragment,f),C(Cx.$$.fragment,f),C(Ax.$$.fragment,f),C(v5.$$.fragment,f),C(yx.$$.fragment,f),C(x5.$$.fragment,f),C(Lx.$$.fragment,f),C(xx.$$.fragment,f),C(kx.$$.fragment,f),C(k5.$$.fragment,f),C(Sx.$$.fragment,f),C(O5.$$.fragment,f),C(Rx.$$.fragment,f),C(Bx.$$.fragment,f),C(Ix.$$.fragment,f),C(X5.$$.fragment,f),C(qx.$$.fragment,f),C(oC.$$.fragment,f),C(Nx.$$.fragment,f),C(jx.$$.fragment,f),C(Gx.$$.fragment,f),C(tC.$$.fragment,f),C(Ox.$$.fragment,f),C(mC.$$.fragment,f),C(Vx.$$.fragment,f),C(Xx.$$.fragment,f),C(Qx.$$.fragment,f),C(hC.$$.fragment,f),C(Wx.$$.fragment,f),C(EC.$$.fragment,f),C(Hx.$$.fragment,f),C(Ux.$$.fragment,f),C(Yx.$$.fragment,f),C(wC.$$.fragment,f),C(Kx.$$.fragment,f),C(yC.$$.fragment,f),C(Zx.$$.fragment,f),C(e9.$$.fragment,f),C(r9.$$.fragment,f),C(xC.$$.fragment,f),C(t9.$$.fragment,f),C(SC.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(BC.$$.fragment,f),C(d9.$$.fragment,f),C(IC.$$.fragment,f),wNe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(gf),f&&t(et),f&&t(qe),f&&t(Xe),f&&t(pf),w(Ma,f),f&&t(ze),f&&t(Ae),f&&t(Eo),f&&t(Ea),f&&t(MIe),f&&t(pi),w(nA),f&&t(EIe),f&&t($n),f&&t(CIe),w(sA,f),f&&t(wIe),f&&t(L$),f&&t(AIe),w(bf,f),f&&t(yIe),f&&t(ui),w(lA),f&&t(LIe),f&&t(Co),w(iA),w(fA),w(bg),w(mA),f&&t(xIe),f&&t(bi),w(gA),f&&t($Ie),f&&t(wo),w(hA),w(_A),w(Yg),w(bA),f&&t(kIe),f&&t(vi),w(vA),f&&t(SIe),f&&t(Ao),w(FA),w(EA),w(Ah),w(yh),w(CA),f&&t(RIe),f&&t(Fi),w(wA),f&&t(BIe),f&&t(yo),w(AA),w(xA),w(Qh),w(Wh),w($A),f&&t(PIe),f&&t(Mi),w(kA),f&&t(IIe),f&&t(Lo),w(SA),w(BA),w(Jh),w(PA),w(Gu),f&&t(qIe),f&&t(wi),w(IA),f&&t(NIe),f&&t(xo),w(qA),w(jA),w(Vu),w(DA),w(k_),f&&t(jIe),f&&t(Li),w(GA),f&&t(DIe),f&&t($o),w(OA),w(XA),w(R_),w(zA),w(_0),f&&t(GIe),f&&t(ki),w(QA),f&&t(OIe),f&&t(ko),w(WA),w(UA),w(v0),w(JA),w(r1),f&&t(VIe),f&&t(Bi),w(YA),f&&t(XIe),f&&t(So),w(KA),w(ey),w(a1),w(oy),w(E1),f&&t(zIe),f&&t(qi),w(ry),f&&t(QIe),f&&t(Ro),w(ty),w(ny),w(w1),w(sy),w(Tb),f&&t(WIe),f&&t(Di),w(ly),f&&t(HIe),f&&t(Bo),w(iy),w(cy),w(Eb),w(fy),w(e2),f&&t(UIe),f&&t(Vi),w(my),f&&t(JIe),f&&t(Po),w(gy),w(py),w(r2),w(uy),w(d2),f&&t(YIe),f&&t(Qi),w(_y),f&&t(KIe),f&&t(Io),w(by),w(Fy),w(f2),w(Ty),w(W2),f&&t(ZIe),f&&t(Ui),w(My),f&&t(eqe),f&&t(qo),w(Ey),w(wy),w(U2),w(Ay),w(qv),f&&t(oqe),f&&t(Ki),w(yy),f&&t(rqe),f&&t(No),w(Ly),w($y),w(jv),w(ky),w(Ov),f&&t(tqe),f&&t(od),w(Sy),f&&t(aqe),f&&t(jo),w(Ry),w(Py),w(Xv),w(Iy),w(tF),f&&t(nqe),f&&t(ad),w(qy),f&&t(sqe),f&&t(Do),w(Ny),w(Dy),w(nF),w(Gy),w(iF),f&&t(lqe),f&&t(ld),w(Oy),f&&t(iqe),f&&t(Go),w(Vy),w(zy),w(cF),w(Qy),w(FF),f&&t(dqe),f&&t(cd),w(Wy),f&&t(cqe),f&&t(Oo),w(Hy),w(Jy),w(MF),w(Yy),w(LF),f&&t(fqe),f&&t(gd),w(Ky),f&&t(mqe),f&&t(Vo),w(Zy),w(oL),w($F),w(rL),w(DF),f&&t(gqe),f&&t(ud),w(tL),f&&t(hqe),f&&t(Xo),w(aL),w(sL),w(OF),w(lL),w(QF),f&&t(pqe),f&&t(vd),w(dL),f&&t(uqe),f&&t(zo),w(cL),w(mL),w(HF),w(gL),w(e6),f&&t(_qe),f&&t(Md),w(hL),f&&t(bqe),f&&t(Qo),w(pL),w(_L),w(r6),w(bL),w(l6),f&&t(vqe),f&&t(Ad),w(vL),f&&t(Fqe),f&&t(Wo),w(FL),w(ML),w(d6),w(EL),w(g6),f&&t(Tqe),f&&t(xd),w(wL),f&&t(Mqe),f&&t(Ho),w(AL),w(LL),w(p6),w(xL),w(b6),f&&t(Eqe),f&&t(Sd),w($L),f&&t(Cqe),f&&t(Uo),w(kL),w(RL),w(F6),w(BL),w(A6),f&&t(wqe),f&&t(Pd),w(PL),f&&t(Aqe),f&&t(Jo),w(IL),w(NL),w(L6),w(jL),w(k6),f&&t(yqe),f&&t(Nd),w(DL),f&&t(Lqe),f&&t(Yo),w(GL),w(VL),w(R6),w(XL),w(CT),f&&t(xqe),f&&t(Gd),w(zL),f&&t($qe),f&&t(Ko),w(QL),w(HL),w(AT),w(UL),w(JT),f&&t(kqe),f&&t(Xd),w(JL),f&&t(Sqe),f&&t(Zo),w(YL),w(ZL),w(KT),w(e8),w(f7),f&&t(Rqe),f&&t(Wd),w(o8),f&&t(Bqe),f&&t(er),w(r8),w(a8),w(g7),w(n8),w(_7),f&&t(Pqe),f&&t(Yd),w(s8),f&&t(Iqe),f&&t(or),w(l8),w(d8),w(v7),w(c8),w(D7),f&&t(qqe),f&&t(ec),w(f8),f&&t(Nqe),f&&t(rr),w(m8),w(h8),w(O7),w(p8),w(Z7),f&&t(jqe),f&&t(tc),w(u8),f&&t(Dqe),f&&t(tr),w(_8),w(v8),w(oM),w(F8),w(LM),f&&t(Gqe),f&&t(sc),w(T8),f&&t(Oqe),f&&t(ar),w(M8),w(C8),w($M),w(w8),w(HM),f&&t(Vqe),f&&t(dc),w(A8),f&&t(Xqe),f&&t(nr),w(y8),w(x8),w(JM),w($8),w(ZM),f&&t(zqe),f&&t(mc),w(S8),f&&t(Qqe),f&&t(sr),w(R8),w(P8),w(o4),w(I8),w(t4),f&&t(Wqe),f&&t(pc),w(q8),f&&t(Hqe),f&&t(lr),w(N8),w(D8),w(n4),w(G8),w(A4),f&&t(Uqe),f&&t(bc),w(O8),f&&t(Jqe),f&&t(ir),w(V8),w(z8),w(L4),w(Q8),w(U4),f&&t(Yqe),f&&t(Tc),w(W8),f&&t(Kqe),f&&t(dr),w(H8),w(J8),w(Y4),w(Y8),w(Z4),f&&t(Zqe),f&&t(Cc),w(K8),f&&t(eNe),f&&t(cr),w(Z8),w(ox),w(oE),w(rx),w(tE),f&&t(oNe),f&&t(yc),w(tx),f&&t(rNe),f&&t(fr),w(ax),w(sx),w(nE),w(lx),w(kE),f&&t(tNe),f&&t($c),w(ix),f&&t(aNe),f&&t(mr),w(dx),w(fx),w(RE),w(mx),w(VE),f&&t(nNe),f&&t(Rc),w(gx),f&&t(sNe),f&&t(gr),w(hx),w(ux),w(zE),w(_x),w(a5),f&&t(lNe),f&&t(Ic),w(bx),f&&t(iNe),f&&t(hr),w(vx),w(Tx),w(s5),w(Mx),w(_5),f&&t(dNe),f&&t(jc),w(Ex),f&&t(cNe),f&&t(pr),w(Cx),w(Ax),w(v5),w(yx),w(x5),f&&t(fNe),f&&t(Oc),w(Lx),f&&t(mNe),f&&t(ur),w(xx),w(kx),w(k5),w(Sx),w(O5),f&&t(gNe),f&&t(zc),w(Rx),f&&t(hNe),f&&t(_r),w(Bx),w(Ix),w(X5),w(qx),w(oC),f&&t(pNe),f&&t(Hc),w(Nx),f&&t(uNe),f&&t(br),w(jx),w(Gx),w(tC),w(Ox),w(mC),f&&t(_Ne),f&&t(Yc),w(Vx),f&&t(bNe),f&&t(vr),w(Xx),w(Qx),w(hC),w(Wx),w(EC),f&&t(vNe),f&&t(ef),w(Hx),f&&t(FNe),f&&t(Fr),w(Ux),w(Yx),w(wC),w(Kx),w(yC),f&&t(TNe),f&&t(tf),w(Zx),f&&t(MNe),f&&t(Tr),w(e9),w(r9),w(xC),w(t9),w(SC),f&&t(ENe),f&&t(sf),w(n9),f&&t(CNe),f&&t(Mr),w(s9),w(i9),w(BC),w(d9),w(IC)}}}const H8t={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function U8t(L){return Uyt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class rxt extends zyt{constructor(g){super();Qyt(this,g,U8t,W8t,Wyt,{})}}export{rxt as default,H8t as metadata};
