import{S as qn,i as En,s as Tn,e as o,k as m,w as j,t as a,M as xn,c as i,d as s,m as h,a as n,x as q,h as r,b as g,F as t,g as f,y as E,q as T,o as x,B as z,v as zn,L as Ra}from"../chunks/vendor-6b77c823.js";import{T as Na}from"../chunks/Tip-39098574.js";import{I as ct}from"../chunks/IconCopyLink-7a11ce68.js";import{C as L}from"../chunks/CodeBlock-3a8b25a8.js";import{F as jn,M as Qa}from"../chunks/Markdown-9acf6d91.js";function Fn(I){let p,$,u,_,y;return{c(){p=o("p"),$=a("You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),u=o("a"),_=a("configuration"),y=a(" documentation for more details."),this.h()},l(v){p=i(v,"P",{});var w=n(p);$=r(w,"You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),u=i(w,"A",{href:!0});var F=n(u);_=r(F,"configuration"),F.forEach(s),y=r(w," documentation for more details."),w.forEach(s),this.h()},h(){g(u,"href","main_classes/configuration")},m(v,w){f(v,p,w),t(p,$),t(p,u),t(u,_),t(p,y)},d(v){v&&s(p)}}}function Dn(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V,d,C,N,P,R;return _=new L({props:{code:`from transformers import DistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
model = DistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel(my_config)`}}),D=new L({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),P=new L({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){p=o("p"),$=a("Load your custom configuration attributes into the model:"),u=m(),j(_.$$.fragment),y=m(),v=o("p"),w=a("This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),F=m(),b=o("p"),W=a("Create a pretrained model with "),k=o("a"),S=a("from_pretrained()"),A=a(":"),M=m(),j(D.$$.fragment),V=m(),d=o("p"),C=a("When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),N=m(),j(P.$$.fragment),this.h()},l(c){p=i(c,"P",{});var B=n(p);$=r(B,"Load your custom configuration attributes into the model:"),B.forEach(s),u=h(c),q(_.$$.fragment,c),y=h(c),v=i(c,"P",{});var O=n(v);w=r(O,"This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),O.forEach(s),F=h(c),b=i(c,"P",{});var H=n(b);W=r(H,"Create a pretrained model with "),k=i(H,"A",{href:!0});var se=n(k);S=r(se,"from_pretrained()"),se.forEach(s),A=r(H,":"),H.forEach(s),M=h(c),q(D.$$.fragment,c),V=h(c),d=i(c,"P",{});var ae=n(d);C=r(ae,"When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),ae.forEach(s),N=h(c),q(P.$$.fragment,c),this.h()},h(){g(k,"href","/docs/transformers/pr_highlight/en/main_classes/model#transformers.PreTrainedModel.from_pretrained")},m(c,B){f(c,p,B),t(p,$),f(c,u,B),E(_,c,B),f(c,y,B),f(c,v,B),t(v,w),f(c,F,B),f(c,b,B),t(b,W),t(b,k),t(k,S),t(b,A),f(c,M,B),E(D,c,B),f(c,V,B),f(c,d,B),t(d,C),f(c,N,B),E(P,c,B),R=!0},p:Ra,i(c){R||(T(_.$$.fragment,c),T(D.$$.fragment,c),T(P.$$.fragment,c),R=!0)},o(c){x(_.$$.fragment,c),x(D.$$.fragment,c),x(P.$$.fragment,c),R=!1},d(c){c&&s(p),c&&s(u),z(_,c),c&&s(y),c&&s(v),c&&s(F),c&&s(b),c&&s(M),z(D,c),c&&s(V),c&&s(d),c&&s(N),z(P,c)}}}function Bn(I){let p,$;return p=new Qa({props:{$$slots:{default:[Dn]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function Cn(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V,d,C,N,P,R;return _=new L({props:{code:`from transformers import TFDistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
tf_model = TFDistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel(my_config)`}}),D=new L({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),P=new L({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){p=o("p"),$=a("Load your custom configuration attributes into the model:"),u=m(),j(_.$$.fragment),y=m(),v=o("p"),w=a("This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),F=m(),b=o("p"),W=a("Create a pretrained model with "),k=o("a"),S=a("from_pretrained()"),A=a(":"),M=m(),j(D.$$.fragment),V=m(),d=o("p"),C=a("When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),N=m(),j(P.$$.fragment),this.h()},l(c){p=i(c,"P",{});var B=n(p);$=r(B,"Load your custom configuration attributes into the model:"),B.forEach(s),u=h(c),q(_.$$.fragment,c),y=h(c),v=i(c,"P",{});var O=n(v);w=r(O,"This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),O.forEach(s),F=h(c),b=i(c,"P",{});var H=n(b);W=r(H,"Create a pretrained model with "),k=i(H,"A",{href:!0});var se=n(k);S=r(se,"from_pretrained()"),se.forEach(s),A=r(H,":"),H.forEach(s),M=h(c),q(D.$$.fragment,c),V=h(c),d=i(c,"P",{});var ae=n(d);C=r(ae,"When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),ae.forEach(s),N=h(c),q(P.$$.fragment,c),this.h()},h(){g(k,"href","/docs/transformers/pr_highlight/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained")},m(c,B){f(c,p,B),t(p,$),f(c,u,B),E(_,c,B),f(c,y,B),f(c,v,B),t(v,w),f(c,F,B),f(c,b,B),t(b,W),t(b,k),t(k,S),t(b,A),f(c,M,B),E(D,c,B),f(c,V,B),f(c,d,B),t(d,C),f(c,N,B),E(P,c,B),R=!0},p:Ra,i(c){R||(T(_.$$.fragment,c),T(D.$$.fragment,c),T(P.$$.fragment,c),R=!0)},o(c){x(_.$$.fragment,c),x(D.$$.fragment,c),x(P.$$.fragment,c),R=!1},d(c){c&&s(p),c&&s(u),z(_,c),c&&s(y),c&&s(v),c&&s(F),c&&s(b),c&&s(M),z(D,c),c&&s(V),c&&s(d),c&&s(N),z(P,c)}}}function An(I){let p,$;return p=new Qa({props:{$$slots:{default:[Cn]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function Pn(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V;return w=new L({props:{code:`from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),D=new L({props:{code:`from transformers import DistilBertForQuestionAnswering

model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){p=o("p"),$=a("For example, "),u=o("a"),_=a("DistilBertForSequenceClassification"),y=a(" is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),v=m(),j(w.$$.fragment),F=m(),b=o("p"),W=a("Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=o("a"),S=a("DistilBertForQuestionAnswering"),A=a(" model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),M=m(),j(D.$$.fragment),this.h()},l(d){p=i(d,"P",{});var C=n(p);$=r(C,"For example, "),u=i(C,"A",{href:!0});var N=n(u);_=r(N,"DistilBertForSequenceClassification"),N.forEach(s),y=r(C," is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),C.forEach(s),v=h(d),q(w.$$.fragment,d),F=h(d),b=i(d,"P",{});var P=n(b);W=r(P,"Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=i(P,"A",{href:!0});var R=n(k);S=r(R,"DistilBertForQuestionAnswering"),R.forEach(s),A=r(P," model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),P.forEach(s),M=h(d),q(D.$$.fragment,d),this.h()},h(){g(u,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),g(k,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering")},m(d,C){f(d,p,C),t(p,$),t(p,u),t(u,_),t(p,y),f(d,v,C),E(w,d,C),f(d,F,C),f(d,b,C),t(b,W),t(b,k),t(k,S),t(b,A),f(d,M,C),E(D,d,C),V=!0},p:Ra,i(d){V||(T(w.$$.fragment,d),T(D.$$.fragment,d),V=!0)},o(d){x(w.$$.fragment,d),x(D.$$.fragment,d),V=!1},d(d){d&&s(p),d&&s(v),z(w,d),d&&s(F),d&&s(b),d&&s(M),z(D,d)}}}function Mn(I){let p,$;return p=new Qa({props:{$$slots:{default:[Pn]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function Vn(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V;return w=new L({props:{code:`from transformers import TFDistilBertForSequenceClassification

tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),D=new L({props:{code:`from transformers import TFDistilBertForQuestionAnswering

tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){p=o("p"),$=a("For example, "),u=o("a"),_=a("TFDistilBertForSequenceClassification"),y=a(" is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),v=m(),j(w.$$.fragment),F=m(),b=o("p"),W=a("Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=o("a"),S=a("TFDistilBertForQuestionAnswering"),A=a(" model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),M=m(),j(D.$$.fragment),this.h()},l(d){p=i(d,"P",{});var C=n(p);$=r(C,"For example, "),u=i(C,"A",{href:!0});var N=n(u);_=r(N,"TFDistilBertForSequenceClassification"),N.forEach(s),y=r(C," is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),C.forEach(s),v=h(d),q(w.$$.fragment,d),F=h(d),b=i(d,"P",{});var P=n(b);W=r(P,"Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=i(P,"A",{href:!0});var R=n(k);S=r(R,"TFDistilBertForQuestionAnswering"),R.forEach(s),A=r(P," model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),P.forEach(s),M=h(d),q(D.$$.fragment,d),this.h()},h(){g(u,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),g(k,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering")},m(d,C){f(d,p,C),t(p,$),t(p,u),t(u,_),t(p,y),f(d,v,C),E(w,d,C),f(d,F,C),f(d,b,C),t(b,W),t(b,k),t(k,S),t(b,A),f(d,M,C),E(D,d,C),V=!0},p:Ra,i(d){V||(T(w.$$.fragment,d),T(D.$$.fragment,d),V=!0)},o(d){x(w.$$.fragment,d),x(D.$$.fragment,d),V=!1},d(d){d&&s(p),d&&s(v),z(w,d),d&&s(F),d&&s(b),d&&s(M),z(D,d)}}}function Sn(I){let p,$;return p=new Qa({props:{$$slots:{default:[Vn]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function In(I){let p,$,u,_,y;return{c(){p=o("p"),$=a("Not every model supports a fast tokenizer. Take a look at this "),u=o("a"),_=a("table"),y=a(" to check if a model has fast tokenizer support."),this.h()},l(v){p=i(v,"P",{});var w=n(p);$=r(w,"Not every model supports a fast tokenizer. Take a look at this "),u=i(w,"A",{href:!0});var F=n(u);_=r(F,"table"),F.forEach(s),y=r(w," to check if a model has fast tokenizer support."),w.forEach(s),this.h()},h(){g(u,"href","index#supported-frameworks")},m(v,w){f(v,p,w),t(p,$),t(p,u),t(u,_),t(p,y)},d(v){v&&s(p)}}}function Wn(I){let p,$,u,_,y,v,w,F,b,W,k;return{c(){p=o("p"),$=a("By default, "),u=o("a"),_=a("AutoTokenizer"),y=a(" will try to load a fast tokenizer. You can disable this behavior by setting "),v=o("code"),w=a("use_fast=False"),F=a(" in "),b=o("code"),W=a("from_pretrained"),k=a("."),this.h()},l(S){p=i(S,"P",{});var A=n(p);$=r(A,"By default, "),u=i(A,"A",{href:!0});var M=n(u);_=r(M,"AutoTokenizer"),M.forEach(s),y=r(A," will try to load a fast tokenizer. You can disable this behavior by setting "),v=i(A,"CODE",{});var D=n(v);w=r(D,"use_fast=False"),D.forEach(s),F=r(A," in "),b=i(A,"CODE",{});var V=n(b);W=r(V,"from_pretrained"),V.forEach(s),k=r(A,"."),A.forEach(s),this.h()},h(){g(u,"href","/docs/transformers/pr_highlight/en/model_doc/auto#transformers.AutoTokenizer")},m(S,A){f(S,p,A),t(p,$),t(p,u),t(u,_),t(p,y),t(p,v),t(v,w),t(p,F),t(p,b),t(b,W),t(p,k)},d(S){S&&s(p)}}}function Ln(I){let p,$,u,_,y;return{c(){p=o("p"),$=a("If you aren\u2019t looking for any customization, just use the "),u=o("code"),_=a("from_pretrained"),y=a(" method to load a model\u2019s default feature extractor parameters.")},l(v){p=i(v,"P",{});var w=n(p);$=r(w,"If you aren\u2019t looking for any customization, just use the "),u=i(w,"CODE",{});var F=n(u);_=r(F,"from_pretrained"),F.forEach(s),y=r(w," method to load a model\u2019s default feature extractor parameters."),w.forEach(s)},m(v,w){f(v,p,w),t(p,$),t(p,u),t(u,_),t(p,y)},d(v){v&&s(p)}}}function On(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V,d,C,N,P,R,c,B,O,H,se,ae,Rt,Ya,Ha,Qt,Ua,Ga,Yt,Ja,Xa,Ht,Ka,js,re,ue,Ut,Se,Za,Gt,er,qs,Y,tr,mt,sr,ar,Jt,rr,or,Xt,ir,nr,Kt,lr,fr,Zt,pr,ur,Es,K,cr,ht,mr,hr,dt,dr,gr,Ts,Ie,xs,oe,gt,_r,$r,_t,vr,wr,zs,ce,We,yr,es,br,kr,jr,Le,qr,ts,Er,Tr,Fs,Oe,Ds,me,xr,$t,zr,Fr,Bs,Ne,Cs,he,Dr,vt,Br,Cr,As,Re,Ps,de,Ar,wt,Pr,Mr,Ms,Qe,Vs,ge,Ss,ie,_e,ss,Ye,Vr,as,Sr,Is,Q,Ir,yt,Wr,Lr,rs,Or,Nr,bt,Rr,Qr,He,os,Yr,Hr,Ue,is,Ur,Gr,Ge,ns,Jr,Xr,Ws,$e,Ls,ne,ve,ls,Je,Kr,fs,Zr,Os,we,eo,ps,to,so,Ns,ye,Rs,le,be,us,Xe,ao,cs,ro,Qs,ke,oo,kt,io,no,Ys,je,jt,qt,lo,fo,po,Z,Et,uo,co,Ke,mo,ho,ms,go,_o,Hs,Tt,$o,Us,qe,Gs,Ee,vo,hs,wo,yo,Js,Ze,Xs,Te,bo,xt,ko,jo,Ks,et,Zs,xe,qo,zt,Eo,To,ea,tt,ta,ze,sa,fe,Fe,ds,st,xo,gs,zo,aa,G,Fo,Ft,Do,Bo,Dt,Co,Ao,Bt,Po,Mo,ra,ee,Vo,Ct,So,Io,At,Wo,Lo,oa,at,ia,De,na,Be,Oo,Pt,No,Ro,la,rt,fa,Ce,Qo,Mt,Yo,Ho,pa,ot,ua,pe,Ae,_s,it,Uo,$s,Go,ca,Pe,Jo,Vt,Xo,Ko,ma,St,Zo,ha,nt,da,It,ei,ga,lt,_a,Me,ti,Wt,si,ai,$a,ft,va,Lt,ri,wa;return v=new ct({}),Se=new ct({}),Ie=new L({props:{code:`from transformers import DistilBertConfig

config = DistilBertConfig()
print(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;gelu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Oe=new L({props:{code:`my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
print(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig(activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;relu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.4</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Ne=new L({props:{code:'my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)'}}),Re=new L({props:{code:'my_config.save_pretrained(save_directory="./your_model_save_path")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config.save_pretrained(save_directory=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>)'}}),Qe=new L({props:{code:'my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)'}}),ge=new Na({props:{$$slots:{default:[Fn]},$$scope:{ctx:I}}}),Ye=new ct({}),$e=new jn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[An],pytorch:[Bn]},$$scope:{ctx:I}}}),Je=new ct({}),ye=new jn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Sn],pytorch:[Mn]},$$scope:{ctx:I}}}),Xe=new ct({}),qe=new Na({props:{warning:!0,$$slots:{default:[In]},$$scope:{ctx:I}}}),Ze=new L({props:{code:`from transformers import DistilBertTokenizer

my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>my_tokenizer = DistilBertTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>, do_lower_case=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)`}}),et=new L({props:{code:`from transformers import DistilBertTokenizer

slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>slow_tokenizer = DistilBertTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),tt=new L({props:{code:`from transformers import DistilBertTokenizerFast

fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizerFast

<span class="hljs-meta">&gt;&gt;&gt; </span>fast_tokenizer = DistilBertTokenizerFast.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),ze=new Na({props:{$$slots:{default:[Wn]},$$scope:{ctx:I}}}),st=new ct({}),at=new L({props:{code:`from transformers import ViTFeatureExtractor

vit_extractor = ViTFeatureExtractor()
print(vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>vit_extractor = ViTFeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),De=new Na({props:{$$slots:{default:[Ln]},$$scope:{ctx:I}}}),rt=new L({props:{code:`from transformers import ViTFeatureExtractor

my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
print(my_vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>my_vit_extractor = ViTFeatureExtractor(resample=<span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, image_mean=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: false,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),ot=new L({props:{code:`from transformers import Wav2Vec2FeatureExtractor

w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>w2v2_extractor = Wav2Vec2FeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;Wav2Vec2FeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;feature_size&quot;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&quot;padding_side&quot;</span>: <span class="hljs-string">&quot;right&quot;</span>,
  <span class="hljs-string">&quot;padding_value&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;return_attention_mask&quot;</span>: false,
  <span class="hljs-string">&quot;sampling_rate&quot;</span>: <span class="hljs-number">16000</span>
}`}}),it=new ct({}),nt=new L({props:{code:`from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = Wav2Vec2FeatureExtractor(padding_value=<span class="hljs-number">1.0</span>, do_normalize=<span class="hljs-literal">True</span>)`}}),lt=new L({props:{code:`from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2CTCTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = Wav2Vec2CTCTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>)`}}),ft=new L({props:{code:`from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),{c(){p=o("meta"),$=m(),u=o("h1"),_=o("a"),y=o("span"),j(v.$$.fragment),w=m(),F=o("span"),b=a("Create a custom model"),W=m(),k=o("p"),S=a("An "),A=o("a"),M=o("code"),D=a("AutoClass"),V=a(" automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),d=o("code"),C=a("AutoClass"),N=a(" to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),P=o("code"),R=a("AutoClass"),c=a(". Learn how to:"),B=m(),O=o("ul"),H=o("li"),se=a("Load and customize a model configuration."),ae=m(),Rt=o("li"),Ya=a("Create a model architecture."),Ha=m(),Qt=o("li"),Ua=a("Create a slow and fast tokenizer for text."),Ga=m(),Yt=o("li"),Ja=a("Create a feature extractor for audio or image tasks."),Xa=m(),Ht=o("li"),Ka=a("Create a processor for multimodal tasks."),js=m(),re=o("h2"),ue=o("a"),Ut=o("span"),j(Se.$$.fragment),Za=m(),Gt=o("span"),er=a("Configuration"),qs=m(),Y=o("p"),tr=a("A "),mt=o("a"),sr=a("configuration"),ar=a(" refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),Jt=o("code"),rr=a("hidden_size"),or=a(", "),Xt=o("code"),ir=a("num_attention_heads"),nr=a(", "),Kt=o("code"),lr=a("num_hidden_layers"),fr=a(" and "),Zt=o("code"),pr=a("vocab_size"),ur=a(" attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),Es=m(),K=o("p"),cr=a("Get a closer look at "),ht=o("a"),mr=a("DistilBERT"),hr=a(" by accessing "),dt=o("a"),dr=a("DistilBertConfig"),gr=a(" to inspect it\u2019s attributes:"),Ts=m(),j(Ie.$$.fragment),xs=m(),oe=o("p"),gt=o("a"),_r=a("DistilBertConfig"),$r=a(" displays all the default attributes used to build a base "),_t=o("a"),vr=a("DistilBertModel"),wr=a(". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),zs=m(),ce=o("ul"),We=o("li"),yr=a("Try a different activation function with the "),es=o("code"),br=a("activation"),kr=a(" parameter."),jr=m(),Le=o("li"),qr=a("Use a higher dropout ratio for the attention probabilities with the "),ts=o("code"),Er=a("attention_dropout"),Tr=a(" parameter."),Fs=m(),j(Oe.$$.fragment),Ds=m(),me=o("p"),xr=a("Pretrained model attributes can be modified in the "),$t=o("a"),zr=a("from_pretrained()"),Fr=a(" function:"),Bs=m(),j(Ne.$$.fragment),Cs=m(),he=o("p"),Dr=a("Once you are satisfied with your model configuration, you can save it with "),vt=o("a"),Br=a("save_pretrained()"),Cr=a(". Your configuration file is stored as a JSON file in the specified save directory:"),As=m(),j(Re.$$.fragment),Ps=m(),de=o("p"),Ar=a("To reuse the configuration file, load it with "),wt=o("a"),Pr=a("from_pretrained()"),Mr=a(":"),Ms=m(),j(Qe.$$.fragment),Vs=m(),j(ge.$$.fragment),Ss=m(),ie=o("h2"),_e=o("a"),ss=o("span"),j(Ye.$$.fragment),Vr=m(),as=o("span"),Sr=a("Model"),Is=m(),Q=o("p"),Ir=a("The next step is to create a "),yt=o("a"),Wr=a("model"),Lr=a(". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),rs=o("code"),Or=a("num_hidden_layers"),Nr=a(" from the configuration are used to define the architecture. Every model shares the base class "),bt=o("a"),Rr=a("PreTrainedModel"),Qr=a(" and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),He=o("a"),os=o("code"),Yr=a("torch.nn.Module"),Hr=a(", "),Ue=o("a"),is=o("code"),Ur=a("tf.keras.Model"),Gr=a(" or "),Ge=o("a"),ns=o("code"),Jr=a("flax.linen.Module"),Xr=a(" subclass. This means models are compatible with each of their respective framework\u2019s usage."),Ws=m(),j($e.$$.fragment),Ls=m(),ne=o("h3"),ve=o("a"),ls=o("span"),j(Je.$$.fragment),Kr=m(),fs=o("span"),Zr=a("Model heads"),Os=m(),we=o("p"),eo=a("At this point, you have a base DistilBERT model which outputs the "),ps=o("em"),to=a("hidden states"),so=a(". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),Ns=m(),j(ye.$$.fragment),Rs=m(),le=o("h2"),be=o("a"),us=o("span"),j(Xe.$$.fragment),ao=m(),cs=o("span"),ro=a("Tokenizer"),Qs=m(),ke=o("p"),oo=a("The last base class you need before using a model for textual data is a "),kt=o("a"),io=a("tokenizer"),no=a(" to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),Ys=m(),je=o("ul"),jt=o("li"),qt=o("a"),lo=a("PreTrainedTokenizer"),fo=a(": a Python implementation of a tokenizer."),po=m(),Z=o("li"),Et=o("a"),uo=a("PreTrainedTokenizerFast"),co=a(": a tokenizer from our Rust-based "),Ke=o("a"),mo=a("\u{1F917} Tokenizer"),ho=a(" library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),ms=o("em"),go=a("offset mapping"),_o=a(" which maps tokens to their original words or characters."),Hs=m(),Tt=o("p"),$o=a("Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),Us=m(),j(qe.$$.fragment),Gs=m(),Ee=o("p"),vo=a("If you trained your own tokenizer, you can create one from your "),hs=o("em"),wo=a("vocabulary"),yo=a(" file:"),Js=m(),j(Ze.$$.fragment),Xs=m(),Te=o("p"),bo=a("It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),xt=o("a"),ko=a("DistilBertTokenizer"),jo=a(" class:"),Ks=m(),j(et.$$.fragment),Zs=m(),xe=o("p"),qo=a("Create a fast tokenizer with the "),zt=o("a"),Eo=a("DistilBertTokenizerFast"),To=a(" class:"),ea=m(),j(tt.$$.fragment),ta=m(),j(ze.$$.fragment),sa=m(),fe=o("h2"),Fe=o("a"),ds=o("span"),j(st.$$.fragment),xo=m(),gs=o("span"),zo=a("Feature Extractor"),aa=m(),G=o("p"),Fo=a("A feature extractor processes audio or image inputs. It inherits from the base "),Ft=o("a"),Do=a("FeatureExtractionMixin"),Bo=a(" class, and may also inherit from the "),Dt=o("a"),Co=a("ImageFeatureExtractionMixin"),Ao=a(" class for processing image features or the "),Bt=o("a"),Po=a("SequenceFeatureExtractor"),Mo=a(" class for processing audio inputs."),ra=m(),ee=o("p"),Vo=a("Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Ct=o("a"),So=a("ViTFeatureExtractor"),Io=a(" if you are using "),At=o("a"),Wo=a("ViT"),Lo=a(" for image classification:"),oa=m(),j(at.$$.fragment),ia=m(),j(De.$$.fragment),na=m(),Be=o("p"),Oo=a("Modify any of the "),Pt=o("a"),No=a("ViTFeatureExtractor"),Ro=a(" parameters to create your custom feature extractor:"),la=m(),j(rt.$$.fragment),fa=m(),Ce=o("p"),Qo=a("For audio inputs, you can create a "),Mt=o("a"),Yo=a("Wav2Vec2FeatureExtractor"),Ho=a(" and customize the parameters in a similar way:"),pa=m(),j(ot.$$.fragment),ua=m(),pe=o("h2"),Ae=o("a"),_s=o("span"),j(it.$$.fragment),Uo=m(),$s=o("span"),Go=a("Processor"),ca=m(),Pe=o("p"),Jo=a("For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),Vt=o("a"),Xo=a("Wav2Vec2Processor"),Ko=a(" for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),ma=m(),St=o("p"),Zo=a("Create a feature extractor to handle the audio inputs:"),ha=m(),j(nt.$$.fragment),da=m(),It=o("p"),ei=a("Create a tokenizer to handle the text inputs:"),ga=m(),j(lt.$$.fragment),_a=m(),Me=o("p"),ti=a("Combine the feature extractor and tokenizer in "),Wt=o("a"),si=a("Wav2Vec2Processor"),ai=a(":"),$a=m(),j(ft.$$.fragment),va=m(),Lt=o("p"),ri=a("With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),this.h()},l(e){const l=xn('[data-svelte="svelte-1phssyn"]',document.head);p=i(l,"META",{name:!0,content:!0}),l.forEach(s),$=h(e),u=i(e,"H1",{class:!0});var pt=n(u);_=i(pt,"A",{id:!0,class:!0,href:!0});var vs=n(_);y=i(vs,"SPAN",{});var ws=n(y);q(v.$$.fragment,ws),ws.forEach(s),vs.forEach(s),w=h(pt),F=i(pt,"SPAN",{});var ys=n(F);b=r(ys,"Create a custom model"),ys.forEach(s),pt.forEach(s),W=h(e),k=i(e,"P",{});var X=n(k);S=r(X,"An "),A=i(X,"A",{href:!0});var bs=n(A);M=i(bs,"CODE",{});var ii=n(M);D=r(ii,"AutoClass"),ii.forEach(s),bs.forEach(s),V=r(X," automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),d=i(X,"CODE",{});var ni=n(d);C=r(ni,"AutoClass"),ni.forEach(s),N=r(X," to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),P=i(X,"CODE",{});var li=n(P);R=r(li,"AutoClass"),li.forEach(s),c=r(X,". Learn how to:"),X.forEach(s),B=h(e),O=i(e,"UL",{});var te=n(O);H=i(te,"LI",{});var fi=n(H);se=r(fi,"Load and customize a model configuration."),fi.forEach(s),ae=h(te),Rt=i(te,"LI",{});var pi=n(Rt);Ya=r(pi,"Create a model architecture."),pi.forEach(s),Ha=h(te),Qt=i(te,"LI",{});var ui=n(Qt);Ua=r(ui,"Create a slow and fast tokenizer for text."),ui.forEach(s),Ga=h(te),Yt=i(te,"LI",{});var ci=n(Yt);Ja=r(ci,"Create a feature extractor for audio or image tasks."),ci.forEach(s),Xa=h(te),Ht=i(te,"LI",{});var mi=n(Ht);Ka=r(mi,"Create a processor for multimodal tasks."),mi.forEach(s),te.forEach(s),js=h(e),re=i(e,"H2",{class:!0});var ya=n(re);ue=i(ya,"A",{id:!0,class:!0,href:!0});var hi=n(ue);Ut=i(hi,"SPAN",{});var di=n(Ut);q(Se.$$.fragment,di),di.forEach(s),hi.forEach(s),Za=h(ya),Gt=i(ya,"SPAN",{});var gi=n(Gt);er=r(gi,"Configuration"),gi.forEach(s),ya.forEach(s),qs=h(e),Y=i(e,"P",{});var J=n(Y);tr=r(J,"A "),mt=i(J,"A",{href:!0});var _i=n(mt);sr=r(_i,"configuration"),_i.forEach(s),ar=r(J," refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),Jt=i(J,"CODE",{});var $i=n(Jt);rr=r($i,"hidden_size"),$i.forEach(s),or=r(J,", "),Xt=i(J,"CODE",{});var vi=n(Xt);ir=r(vi,"num_attention_heads"),vi.forEach(s),nr=r(J,", "),Kt=i(J,"CODE",{});var wi=n(Kt);lr=r(wi,"num_hidden_layers"),wi.forEach(s),fr=r(J," and "),Zt=i(J,"CODE",{});var yi=n(Zt);pr=r(yi,"vocab_size"),yi.forEach(s),ur=r(J," attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),J.forEach(s),Es=h(e),K=i(e,"P",{});var Ot=n(K);cr=r(Ot,"Get a closer look at "),ht=i(Ot,"A",{href:!0});var bi=n(ht);mr=r(bi,"DistilBERT"),bi.forEach(s),hr=r(Ot," by accessing "),dt=i(Ot,"A",{href:!0});var ki=n(dt);dr=r(ki,"DistilBertConfig"),ki.forEach(s),gr=r(Ot," to inspect it\u2019s attributes:"),Ot.forEach(s),Ts=h(e),q(Ie.$$.fragment,e),xs=h(e),oe=i(e,"P",{});var ks=n(oe);gt=i(ks,"A",{href:!0});var ji=n(gt);_r=r(ji,"DistilBertConfig"),ji.forEach(s),$r=r(ks," displays all the default attributes used to build a base "),_t=i(ks,"A",{href:!0});var qi=n(_t);vr=r(qi,"DistilBertModel"),qi.forEach(s),wr=r(ks,". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),ks.forEach(s),zs=h(e),ce=i(e,"UL",{});var ba=n(ce);We=i(ba,"LI",{});var ka=n(We);yr=r(ka,"Try a different activation function with the "),es=i(ka,"CODE",{});var Ei=n(es);br=r(Ei,"activation"),Ei.forEach(s),kr=r(ka," parameter."),ka.forEach(s),jr=h(ba),Le=i(ba,"LI",{});var ja=n(Le);qr=r(ja,"Use a higher dropout ratio for the attention probabilities with the "),ts=i(ja,"CODE",{});var Ti=n(ts);Er=r(Ti,"attention_dropout"),Ti.forEach(s),Tr=r(ja," parameter."),ja.forEach(s),ba.forEach(s),Fs=h(e),q(Oe.$$.fragment,e),Ds=h(e),me=i(e,"P",{});var qa=n(me);xr=r(qa,"Pretrained model attributes can be modified in the "),$t=i(qa,"A",{href:!0});var xi=n($t);zr=r(xi,"from_pretrained()"),xi.forEach(s),Fr=r(qa," function:"),qa.forEach(s),Bs=h(e),q(Ne.$$.fragment,e),Cs=h(e),he=i(e,"P",{});var Ea=n(he);Dr=r(Ea,"Once you are satisfied with your model configuration, you can save it with "),vt=i(Ea,"A",{href:!0});var zi=n(vt);Br=r(zi,"save_pretrained()"),zi.forEach(s),Cr=r(Ea,". Your configuration file is stored as a JSON file in the specified save directory:"),Ea.forEach(s),As=h(e),q(Re.$$.fragment,e),Ps=h(e),de=i(e,"P",{});var Ta=n(de);Ar=r(Ta,"To reuse the configuration file, load it with "),wt=i(Ta,"A",{href:!0});var Fi=n(wt);Pr=r(Fi,"from_pretrained()"),Fi.forEach(s),Mr=r(Ta,":"),Ta.forEach(s),Ms=h(e),q(Qe.$$.fragment,e),Vs=h(e),q(ge.$$.fragment,e),Ss=h(e),ie=i(e,"H2",{class:!0});var xa=n(ie);_e=i(xa,"A",{id:!0,class:!0,href:!0});var Di=n(_e);ss=i(Di,"SPAN",{});var Bi=n(ss);q(Ye.$$.fragment,Bi),Bi.forEach(s),Di.forEach(s),Vr=h(xa),as=i(xa,"SPAN",{});var Ci=n(as);Sr=r(Ci,"Model"),Ci.forEach(s),xa.forEach(s),Is=h(e),Q=i(e,"P",{});var U=n(Q);Ir=r(U,"The next step is to create a "),yt=i(U,"A",{href:!0});var Ai=n(yt);Wr=r(Ai,"model"),Ai.forEach(s),Lr=r(U,". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),rs=i(U,"CODE",{});var Pi=n(rs);Or=r(Pi,"num_hidden_layers"),Pi.forEach(s),Nr=r(U," from the configuration are used to define the architecture. Every model shares the base class "),bt=i(U,"A",{href:!0});var Mi=n(bt);Rr=r(Mi,"PreTrainedModel"),Mi.forEach(s),Qr=r(U," and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),He=i(U,"A",{href:!0,rel:!0});var Vi=n(He);os=i(Vi,"CODE",{});var Si=n(os);Yr=r(Si,"torch.nn.Module"),Si.forEach(s),Vi.forEach(s),Hr=r(U,", "),Ue=i(U,"A",{href:!0,rel:!0});var Ii=n(Ue);is=i(Ii,"CODE",{});var Wi=n(is);Ur=r(Wi,"tf.keras.Model"),Wi.forEach(s),Ii.forEach(s),Gr=r(U," or "),Ge=i(U,"A",{href:!0,rel:!0});var Li=n(Ge);ns=i(Li,"CODE",{});var Oi=n(ns);Jr=r(Oi,"flax.linen.Module"),Oi.forEach(s),Li.forEach(s),Xr=r(U," subclass. This means models are compatible with each of their respective framework\u2019s usage."),U.forEach(s),Ws=h(e),q($e.$$.fragment,e),Ls=h(e),ne=i(e,"H3",{class:!0});var za=n(ne);ve=i(za,"A",{id:!0,class:!0,href:!0});var Ni=n(ve);ls=i(Ni,"SPAN",{});var Ri=n(ls);q(Je.$$.fragment,Ri),Ri.forEach(s),Ni.forEach(s),Kr=h(za),fs=i(za,"SPAN",{});var Qi=n(fs);Zr=r(Qi,"Model heads"),Qi.forEach(s),za.forEach(s),Os=h(e),we=i(e,"P",{});var Fa=n(we);eo=r(Fa,"At this point, you have a base DistilBERT model which outputs the "),ps=i(Fa,"EM",{});var Yi=n(ps);to=r(Yi,"hidden states"),Yi.forEach(s),so=r(Fa,". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),Fa.forEach(s),Ns=h(e),q(ye.$$.fragment,e),Rs=h(e),le=i(e,"H2",{class:!0});var Da=n(le);be=i(Da,"A",{id:!0,class:!0,href:!0});var Hi=n(be);us=i(Hi,"SPAN",{});var Ui=n(us);q(Xe.$$.fragment,Ui),Ui.forEach(s),Hi.forEach(s),ao=h(Da),cs=i(Da,"SPAN",{});var Gi=n(cs);ro=r(Gi,"Tokenizer"),Gi.forEach(s),Da.forEach(s),Qs=h(e),ke=i(e,"P",{});var Ba=n(ke);oo=r(Ba,"The last base class you need before using a model for textual data is a "),kt=i(Ba,"A",{href:!0});var Ji=n(kt);io=r(Ji,"tokenizer"),Ji.forEach(s),no=r(Ba," to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),Ba.forEach(s),Ys=h(e),je=i(e,"UL",{});var Ca=n(je);jt=i(Ca,"LI",{});var oi=n(jt);qt=i(oi,"A",{href:!0});var Xi=n(qt);lo=r(Xi,"PreTrainedTokenizer"),Xi.forEach(s),fo=r(oi,": a Python implementation of a tokenizer."),oi.forEach(s),po=h(Ca),Z=i(Ca,"LI",{});var ut=n(Z);Et=i(ut,"A",{href:!0});var Ki=n(Et);uo=r(Ki,"PreTrainedTokenizerFast"),Ki.forEach(s),co=r(ut,": a tokenizer from our Rust-based "),Ke=i(ut,"A",{href:!0,rel:!0});var Zi=n(Ke);mo=r(Zi,"\u{1F917} Tokenizer"),Zi.forEach(s),ho=r(ut," library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),ms=i(ut,"EM",{});var en=n(ms);go=r(en,"offset mapping"),en.forEach(s),_o=r(ut," which maps tokens to their original words or characters."),ut.forEach(s),Ca.forEach(s),Hs=h(e),Tt=i(e,"P",{});var tn=n(Tt);$o=r(tn,"Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),tn.forEach(s),Us=h(e),q(qe.$$.fragment,e),Gs=h(e),Ee=i(e,"P",{});var Aa=n(Ee);vo=r(Aa,"If you trained your own tokenizer, you can create one from your "),hs=i(Aa,"EM",{});var sn=n(hs);wo=r(sn,"vocabulary"),sn.forEach(s),yo=r(Aa," file:"),Aa.forEach(s),Js=h(e),q(Ze.$$.fragment,e),Xs=h(e),Te=i(e,"P",{});var Pa=n(Te);bo=r(Pa,"It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),xt=i(Pa,"A",{href:!0});var an=n(xt);ko=r(an,"DistilBertTokenizer"),an.forEach(s),jo=r(Pa," class:"),Pa.forEach(s),Ks=h(e),q(et.$$.fragment,e),Zs=h(e),xe=i(e,"P",{});var Ma=n(xe);qo=r(Ma,"Create a fast tokenizer with the "),zt=i(Ma,"A",{href:!0});var rn=n(zt);Eo=r(rn,"DistilBertTokenizerFast"),rn.forEach(s),To=r(Ma," class:"),Ma.forEach(s),ea=h(e),q(tt.$$.fragment,e),ta=h(e),q(ze.$$.fragment,e),sa=h(e),fe=i(e,"H2",{class:!0});var Va=n(fe);Fe=i(Va,"A",{id:!0,class:!0,href:!0});var on=n(Fe);ds=i(on,"SPAN",{});var nn=n(ds);q(st.$$.fragment,nn),nn.forEach(s),on.forEach(s),xo=h(Va),gs=i(Va,"SPAN",{});var ln=n(gs);zo=r(ln,"Feature Extractor"),ln.forEach(s),Va.forEach(s),aa=h(e),G=i(e,"P",{});var Ve=n(G);Fo=r(Ve,"A feature extractor processes audio or image inputs. It inherits from the base "),Ft=i(Ve,"A",{href:!0});var fn=n(Ft);Do=r(fn,"FeatureExtractionMixin"),fn.forEach(s),Bo=r(Ve," class, and may also inherit from the "),Dt=i(Ve,"A",{href:!0});var pn=n(Dt);Co=r(pn,"ImageFeatureExtractionMixin"),pn.forEach(s),Ao=r(Ve," class for processing image features or the "),Bt=i(Ve,"A",{href:!0});var un=n(Bt);Po=r(un,"SequenceFeatureExtractor"),un.forEach(s),Mo=r(Ve," class for processing audio inputs."),Ve.forEach(s),ra=h(e),ee=i(e,"P",{});var Nt=n(ee);Vo=r(Nt,"Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Ct=i(Nt,"A",{href:!0});var cn=n(Ct);So=r(cn,"ViTFeatureExtractor"),cn.forEach(s),Io=r(Nt," if you are using "),At=i(Nt,"A",{href:!0});var mn=n(At);Wo=r(mn,"ViT"),mn.forEach(s),Lo=r(Nt," for image classification:"),Nt.forEach(s),oa=h(e),q(at.$$.fragment,e),ia=h(e),q(De.$$.fragment,e),na=h(e),Be=i(e,"P",{});var Sa=n(Be);Oo=r(Sa,"Modify any of the "),Pt=i(Sa,"A",{href:!0});var hn=n(Pt);No=r(hn,"ViTFeatureExtractor"),hn.forEach(s),Ro=r(Sa," parameters to create your custom feature extractor:"),Sa.forEach(s),la=h(e),q(rt.$$.fragment,e),fa=h(e),Ce=i(e,"P",{});var Ia=n(Ce);Qo=r(Ia,"For audio inputs, you can create a "),Mt=i(Ia,"A",{href:!0});var dn=n(Mt);Yo=r(dn,"Wav2Vec2FeatureExtractor"),dn.forEach(s),Ho=r(Ia," and customize the parameters in a similar way:"),Ia.forEach(s),pa=h(e),q(ot.$$.fragment,e),ua=h(e),pe=i(e,"H2",{class:!0});var Wa=n(pe);Ae=i(Wa,"A",{id:!0,class:!0,href:!0});var gn=n(Ae);_s=i(gn,"SPAN",{});var _n=n(_s);q(it.$$.fragment,_n),_n.forEach(s),gn.forEach(s),Uo=h(Wa),$s=i(Wa,"SPAN",{});var $n=n($s);Go=r($n,"Processor"),$n.forEach(s),Wa.forEach(s),ca=h(e),Pe=i(e,"P",{});var La=n(Pe);Jo=r(La,"For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),Vt=i(La,"A",{href:!0});var vn=n(Vt);Xo=r(vn,"Wav2Vec2Processor"),vn.forEach(s),Ko=r(La," for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),La.forEach(s),ma=h(e),St=i(e,"P",{});var wn=n(St);Zo=r(wn,"Create a feature extractor to handle the audio inputs:"),wn.forEach(s),ha=h(e),q(nt.$$.fragment,e),da=h(e),It=i(e,"P",{});var yn=n(It);ei=r(yn,"Create a tokenizer to handle the text inputs:"),yn.forEach(s),ga=h(e),q(lt.$$.fragment,e),_a=h(e),Me=i(e,"P",{});var Oa=n(Me);ti=r(Oa,"Combine the feature extractor and tokenizer in "),Wt=i(Oa,"A",{href:!0});var bn=n(Wt);si=r(bn,"Wav2Vec2Processor"),bn.forEach(s),ai=r(Oa,":"),Oa.forEach(s),$a=h(e),q(ft.$$.fragment,e),va=h(e),Lt=i(e,"P",{});var kn=n(Lt);ri=r(kn,"With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),kn.forEach(s),this.h()},h(){g(p,"name","hf:doc:metadata"),g(p,"content",JSON.stringify(Nn)),g(_,"id","create-a-custom-model"),g(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(_,"href","#create-a-custom-model"),g(u,"class","relative group"),g(A,"href","model_doc/auto"),g(ue,"id","configuration"),g(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(ue,"href","#configuration"),g(re,"class","relative group"),g(mt,"href","main_classes/configuration"),g(ht,"href","model_doc/distilbert"),g(dt,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.DistilBertConfig"),g(gt,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.DistilBertConfig"),g(_t,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.DistilBertModel"),g($t,"href","/docs/transformers/pr_highlight/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),g(vt,"href","/docs/transformers/pr_highlight/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained"),g(wt,"href","/docs/transformers/pr_highlight/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),g(_e,"id","model"),g(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(_e,"href","#model"),g(ie,"class","relative group"),g(yt,"href","main_classes/models"),g(bt,"href","/docs/transformers/pr_highlight/en/main_classes/model#transformers.PreTrainedModel"),g(He,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html"),g(He,"rel","nofollow"),g(Ue,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),g(Ue,"rel","nofollow"),g(Ge,"href","https://flax.readthedocs.io/en/latest/flax.linen.html#module"),g(Ge,"rel","nofollow"),g(ve,"id","model-heads"),g(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(ve,"href","#model-heads"),g(ne,"class","relative group"),g(be,"id","tokenizer"),g(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(be,"href","#tokenizer"),g(le,"class","relative group"),g(kt,"href","main_classes/tokenizer"),g(qt,"href","/docs/transformers/pr_highlight/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"),g(Et,"href","/docs/transformers/pr_highlight/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"),g(Ke,"href","https://huggingface.co/docs/tokenizers/python/latest/"),g(Ke,"rel","nofollow"),g(xt,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.DistilBertTokenizer"),g(zt,"href","/docs/transformers/pr_highlight/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),g(Fe,"id","feature-extractor"),g(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(Fe,"href","#feature-extractor"),g(fe,"class","relative group"),g(Ft,"href","/docs/transformers/pr_highlight/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),g(Dt,"href","/docs/transformers/pr_highlight/en/main_classes/feature_extractor#transformers.ImageFeatureExtractionMixin"),g(Bt,"href","/docs/transformers/pr_highlight/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor"),g(Ct,"href","/docs/transformers/pr_highlight/en/model_doc/vit#transformers.ViTFeatureExtractor"),g(At,"href","model_doc/vit"),g(Pt,"href","/docs/transformers/pr_highlight/en/model_doc/vit#transformers.ViTFeatureExtractor"),g(Mt,"href","/docs/transformers/pr_highlight/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),g(Ae,"id","processor"),g(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(Ae,"href","#processor"),g(pe,"class","relative group"),g(Vt,"href","/docs/transformers/pr_highlight/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),g(Wt,"href","/docs/transformers/pr_highlight/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor")},m(e,l){t(document.head,p),f(e,$,l),f(e,u,l),t(u,_),t(_,y),E(v,y,null),t(u,w),t(u,F),t(F,b),f(e,W,l),f(e,k,l),t(k,S),t(k,A),t(A,M),t(M,D),t(k,V),t(k,d),t(d,C),t(k,N),t(k,P),t(P,R),t(k,c),f(e,B,l),f(e,O,l),t(O,H),t(H,se),t(O,ae),t(O,Rt),t(Rt,Ya),t(O,Ha),t(O,Qt),t(Qt,Ua),t(O,Ga),t(O,Yt),t(Yt,Ja),t(O,Xa),t(O,Ht),t(Ht,Ka),f(e,js,l),f(e,re,l),t(re,ue),t(ue,Ut),E(Se,Ut,null),t(re,Za),t(re,Gt),t(Gt,er),f(e,qs,l),f(e,Y,l),t(Y,tr),t(Y,mt),t(mt,sr),t(Y,ar),t(Y,Jt),t(Jt,rr),t(Y,or),t(Y,Xt),t(Xt,ir),t(Y,nr),t(Y,Kt),t(Kt,lr),t(Y,fr),t(Y,Zt),t(Zt,pr),t(Y,ur),f(e,Es,l),f(e,K,l),t(K,cr),t(K,ht),t(ht,mr),t(K,hr),t(K,dt),t(dt,dr),t(K,gr),f(e,Ts,l),E(Ie,e,l),f(e,xs,l),f(e,oe,l),t(oe,gt),t(gt,_r),t(oe,$r),t(oe,_t),t(_t,vr),t(oe,wr),f(e,zs,l),f(e,ce,l),t(ce,We),t(We,yr),t(We,es),t(es,br),t(We,kr),t(ce,jr),t(ce,Le),t(Le,qr),t(Le,ts),t(ts,Er),t(Le,Tr),f(e,Fs,l),E(Oe,e,l),f(e,Ds,l),f(e,me,l),t(me,xr),t(me,$t),t($t,zr),t(me,Fr),f(e,Bs,l),E(Ne,e,l),f(e,Cs,l),f(e,he,l),t(he,Dr),t(he,vt),t(vt,Br),t(he,Cr),f(e,As,l),E(Re,e,l),f(e,Ps,l),f(e,de,l),t(de,Ar),t(de,wt),t(wt,Pr),t(de,Mr),f(e,Ms,l),E(Qe,e,l),f(e,Vs,l),E(ge,e,l),f(e,Ss,l),f(e,ie,l),t(ie,_e),t(_e,ss),E(Ye,ss,null),t(ie,Vr),t(ie,as),t(as,Sr),f(e,Is,l),f(e,Q,l),t(Q,Ir),t(Q,yt),t(yt,Wr),t(Q,Lr),t(Q,rs),t(rs,Or),t(Q,Nr),t(Q,bt),t(bt,Rr),t(Q,Qr),t(Q,He),t(He,os),t(os,Yr),t(Q,Hr),t(Q,Ue),t(Ue,is),t(is,Ur),t(Q,Gr),t(Q,Ge),t(Ge,ns),t(ns,Jr),t(Q,Xr),f(e,Ws,l),E($e,e,l),f(e,Ls,l),f(e,ne,l),t(ne,ve),t(ve,ls),E(Je,ls,null),t(ne,Kr),t(ne,fs),t(fs,Zr),f(e,Os,l),f(e,we,l),t(we,eo),t(we,ps),t(ps,to),t(we,so),f(e,Ns,l),E(ye,e,l),f(e,Rs,l),f(e,le,l),t(le,be),t(be,us),E(Xe,us,null),t(le,ao),t(le,cs),t(cs,ro),f(e,Qs,l),f(e,ke,l),t(ke,oo),t(ke,kt),t(kt,io),t(ke,no),f(e,Ys,l),f(e,je,l),t(je,jt),t(jt,qt),t(qt,lo),t(jt,fo),t(je,po),t(je,Z),t(Z,Et),t(Et,uo),t(Z,co),t(Z,Ke),t(Ke,mo),t(Z,ho),t(Z,ms),t(ms,go),t(Z,_o),f(e,Hs,l),f(e,Tt,l),t(Tt,$o),f(e,Us,l),E(qe,e,l),f(e,Gs,l),f(e,Ee,l),t(Ee,vo),t(Ee,hs),t(hs,wo),t(Ee,yo),f(e,Js,l),E(Ze,e,l),f(e,Xs,l),f(e,Te,l),t(Te,bo),t(Te,xt),t(xt,ko),t(Te,jo),f(e,Ks,l),E(et,e,l),f(e,Zs,l),f(e,xe,l),t(xe,qo),t(xe,zt),t(zt,Eo),t(xe,To),f(e,ea,l),E(tt,e,l),f(e,ta,l),E(ze,e,l),f(e,sa,l),f(e,fe,l),t(fe,Fe),t(Fe,ds),E(st,ds,null),t(fe,xo),t(fe,gs),t(gs,zo),f(e,aa,l),f(e,G,l),t(G,Fo),t(G,Ft),t(Ft,Do),t(G,Bo),t(G,Dt),t(Dt,Co),t(G,Ao),t(G,Bt),t(Bt,Po),t(G,Mo),f(e,ra,l),f(e,ee,l),t(ee,Vo),t(ee,Ct),t(Ct,So),t(ee,Io),t(ee,At),t(At,Wo),t(ee,Lo),f(e,oa,l),E(at,e,l),f(e,ia,l),E(De,e,l),f(e,na,l),f(e,Be,l),t(Be,Oo),t(Be,Pt),t(Pt,No),t(Be,Ro),f(e,la,l),E(rt,e,l),f(e,fa,l),f(e,Ce,l),t(Ce,Qo),t(Ce,Mt),t(Mt,Yo),t(Ce,Ho),f(e,pa,l),E(ot,e,l),f(e,ua,l),f(e,pe,l),t(pe,Ae),t(Ae,_s),E(it,_s,null),t(pe,Uo),t(pe,$s),t($s,Go),f(e,ca,l),f(e,Pe,l),t(Pe,Jo),t(Pe,Vt),t(Vt,Xo),t(Pe,Ko),f(e,ma,l),f(e,St,l),t(St,Zo),f(e,ha,l),E(nt,e,l),f(e,da,l),f(e,It,l),t(It,ei),f(e,ga,l),E(lt,e,l),f(e,_a,l),f(e,Me,l),t(Me,ti),t(Me,Wt),t(Wt,si),t(Me,ai),f(e,$a,l),E(ft,e,l),f(e,va,l),f(e,Lt,l),t(Lt,ri),wa=!0},p(e,[l]){const pt={};l&2&&(pt.$$scope={dirty:l,ctx:e}),ge.$set(pt);const vs={};l&2&&(vs.$$scope={dirty:l,ctx:e}),$e.$set(vs);const ws={};l&2&&(ws.$$scope={dirty:l,ctx:e}),ye.$set(ws);const ys={};l&2&&(ys.$$scope={dirty:l,ctx:e}),qe.$set(ys);const X={};l&2&&(X.$$scope={dirty:l,ctx:e}),ze.$set(X);const bs={};l&2&&(bs.$$scope={dirty:l,ctx:e}),De.$set(bs)},i(e){wa||(T(v.$$.fragment,e),T(Se.$$.fragment,e),T(Ie.$$.fragment,e),T(Oe.$$.fragment,e),T(Ne.$$.fragment,e),T(Re.$$.fragment,e),T(Qe.$$.fragment,e),T(ge.$$.fragment,e),T(Ye.$$.fragment,e),T($e.$$.fragment,e),T(Je.$$.fragment,e),T(ye.$$.fragment,e),T(Xe.$$.fragment,e),T(qe.$$.fragment,e),T(Ze.$$.fragment,e),T(et.$$.fragment,e),T(tt.$$.fragment,e),T(ze.$$.fragment,e),T(st.$$.fragment,e),T(at.$$.fragment,e),T(De.$$.fragment,e),T(rt.$$.fragment,e),T(ot.$$.fragment,e),T(it.$$.fragment,e),T(nt.$$.fragment,e),T(lt.$$.fragment,e),T(ft.$$.fragment,e),wa=!0)},o(e){x(v.$$.fragment,e),x(Se.$$.fragment,e),x(Ie.$$.fragment,e),x(Oe.$$.fragment,e),x(Ne.$$.fragment,e),x(Re.$$.fragment,e),x(Qe.$$.fragment,e),x(ge.$$.fragment,e),x(Ye.$$.fragment,e),x($e.$$.fragment,e),x(Je.$$.fragment,e),x(ye.$$.fragment,e),x(Xe.$$.fragment,e),x(qe.$$.fragment,e),x(Ze.$$.fragment,e),x(et.$$.fragment,e),x(tt.$$.fragment,e),x(ze.$$.fragment,e),x(st.$$.fragment,e),x(at.$$.fragment,e),x(De.$$.fragment,e),x(rt.$$.fragment,e),x(ot.$$.fragment,e),x(it.$$.fragment,e),x(nt.$$.fragment,e),x(lt.$$.fragment,e),x(ft.$$.fragment,e),wa=!1},d(e){s(p),e&&s($),e&&s(u),z(v),e&&s(W),e&&s(k),e&&s(B),e&&s(O),e&&s(js),e&&s(re),z(Se),e&&s(qs),e&&s(Y),e&&s(Es),e&&s(K),e&&s(Ts),z(Ie,e),e&&s(xs),e&&s(oe),e&&s(zs),e&&s(ce),e&&s(Fs),z(Oe,e),e&&s(Ds),e&&s(me),e&&s(Bs),z(Ne,e),e&&s(Cs),e&&s(he),e&&s(As),z(Re,e),e&&s(Ps),e&&s(de),e&&s(Ms),z(Qe,e),e&&s(Vs),z(ge,e),e&&s(Ss),e&&s(ie),z(Ye),e&&s(Is),e&&s(Q),e&&s(Ws),z($e,e),e&&s(Ls),e&&s(ne),z(Je),e&&s(Os),e&&s(we),e&&s(Ns),z(ye,e),e&&s(Rs),e&&s(le),z(Xe),e&&s(Qs),e&&s(ke),e&&s(Ys),e&&s(je),e&&s(Hs),e&&s(Tt),e&&s(Us),z(qe,e),e&&s(Gs),e&&s(Ee),e&&s(Js),z(Ze,e),e&&s(Xs),e&&s(Te),e&&s(Ks),z(et,e),e&&s(Zs),e&&s(xe),e&&s(ea),z(tt,e),e&&s(ta),z(ze,e),e&&s(sa),e&&s(fe),z(st),e&&s(aa),e&&s(G),e&&s(ra),e&&s(ee),e&&s(oa),z(at,e),e&&s(ia),z(De,e),e&&s(na),e&&s(Be),e&&s(la),z(rt,e),e&&s(fa),e&&s(Ce),e&&s(pa),z(ot,e),e&&s(ua),e&&s(pe),z(it),e&&s(ca),e&&s(Pe),e&&s(ma),e&&s(St),e&&s(ha),z(nt,e),e&&s(da),e&&s(It),e&&s(ga),z(lt,e),e&&s(_a),e&&s(Me),e&&s($a),z(ft,e),e&&s(va),e&&s(Lt)}}}const Nn={local:"create-a-custom-model",sections:[{local:"configuration",title:"Configuration"},{local:"model",sections:[{local:"model-heads",title:"Model heads"}],title:"Model"},{local:"tokenizer",title:"Tokenizer"},{local:"feature-extractor",title:"Feature Extractor"},{local:"processor",title:"Processor"}],title:"Create a custom model"};function Rn(I){return zn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Jn extends qn{constructor(p){super();En(this,p,Rn,On,Tn,{})}}export{Jn as default,Nn as metadata};
