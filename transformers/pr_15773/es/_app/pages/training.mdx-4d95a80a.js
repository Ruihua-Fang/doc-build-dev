import{S as Lc,i as Ic,s as Mc,e as r,k as c,w as u,t as i,M as Hc,c as n,d as a,m as d,a as o,x as f,h as p,b as m,F as t,g as l,y as h,q as g,o as _,B as v,v as Rc}from"../chunks/vendor-c570b7f7.js";import{T as Mi}from"../chunks/Tip-4965f0b6.js";import{Y as Rn}from"../chunks/Youtube-ea859fc9.js";import{I as z,C as j}from"../chunks/CodeBlock-8a2530c2.js";import{D as Bc}from"../chunks/DocNotebookDropdown-e51be72e.js";function Kc(se){let $,E;return{c(){$=r("p"),E=i(`Ver\xE1s una advertencia acerca de que algunos de los pesos pre-entrenados que no est\xE1n siendo utilizados y que algunos pesos est\xE1n siendo inicializados al azar.
No te preocupes, esto es completamente normal. El head/cabezal pre-entrenado del modelo BERT se descarta y se sustituye por un head de clasificaci\xF3n inicializado aleatoriamente. Puedes aplicar fine-tuning a este nuevo head del modelo en tu tarea de clasificaci\xF3n de secuencias haciendo transfer learning del modelo pre-entrenado.`)},l(b){$=n(b,"P",{});var w=o($);E=p(w,`Ver\xE1s una advertencia acerca de que algunos de los pesos pre-entrenados que no est\xE1n siendo utilizados y que algunos pesos est\xE1n siendo inicializados al azar.
No te preocupes, esto es completamente normal. El head/cabezal pre-entrenado del modelo BERT se descarta y se sustituye por un head de clasificaci\xF3n inicializado aleatoriamente. Puedes aplicar fine-tuning a este nuevo head del modelo en tu tarea de clasificaci\xF3n de secuencias haciendo transfer learning del modelo pre-entrenado.`),w.forEach(a)},m(b,w){l(b,$,w),t($,E)},d(b){b&&a($)}}}function Uc(se){let $,E,b,w,P,y,F;return{c(){$=r("p"),E=r("code"),b=i("Trainer"),w=i("utiliza "),P=r("code"),y=i("DataCollatorWithPadding"),F=i("por defecto por lo que no es necesario especificar expl\xEDcitamente un intercalador de datos (data collator, en ingl\xE9s).")},l(T){$=n(T,"P",{});var k=o($);E=n(k,"CODE",{});var q=o(E);b=p(q,"Trainer"),q.forEach(a),w=p(k,"utiliza "),P=n(k,"CODE",{});var C=o(P);y=p(C,"DataCollatorWithPadding"),C.forEach(a),F=p(k,"por defecto por lo que no es necesario especificar expl\xEDcitamente un intercalador de datos (data collator, en ingl\xE9s)."),k.forEach(a)},m(T,k){l(T,$,k),t($,E),t(E,b),t($,w),t($,P),t(P,y),t($,F)},d(T){T&&a($)}}}function Wc(se){let $,E,b,w,P,y,F,T;return{c(){$=r("p"),E=i("Consigue acceso gratuito a una GPU en la nube si es que no tienes este recurso de forma local con un notebook alojado en "),b=r("a"),w=i("Colaboratory"),P=i(" o "),y=r("a"),F=i("SageMaker StudioLab"),T=i("."),this.h()},l(k){$=n(k,"P",{});var q=o($);E=p(q,"Consigue acceso gratuito a una GPU en la nube si es que no tienes este recurso de forma local con un notebook alojado en "),b=n(q,"A",{href:!0,rel:!0});var C=o(b);w=p(C,"Colaboratory"),C.forEach(a),P=p(q," o "),y=n(q,"A",{href:!0,rel:!0});var Ne=o(y);F=p(Ne,"SageMaker StudioLab"),Ne.forEach(a),T=p(q,"."),q.forEach(a),this.h()},h(){m(b,"href","https://colab.research.google.com/"),m(b,"rel","nofollow"),m(y,"href","https://studiolab.sagemaker.aws/"),m(y,"rel","nofollow")},m(k,q){l(k,$,q),t($,E),t($,b),t(b,w),t($,P),t($,y),t(y,F),t($,T)},d(k){k&&a($)}}}function Gc(se){let $,E,b,w,P,y,F,T,k,q,C,Ne,Ga,Bn,Ss,N,Ya,Kn,bt,Un,Wn,jt,Gn,Yn,wt,Vn,Fs,Va,Os,B,re,yt,Le,Jn,Et,Xn,Ns,Ie,Ls,Ja,Zn,Is,ne,Qn,Me,eo,ao,Ms,He,Hs,oe,to,Re,kt,so,ro,Rs,Be,Bs,Xa,no,Ks,Ke,Us,Za,Ws,K,le,qt,Ue,oo,Qa,lo,At,io,Gs,We,Ys,L,po,Pt,co,mo,Tt,uo,fo,Vs,ie,ho,Ge,go,_o,Js,Ye,Xs,pe,Zs,U,ce,zt,Ve,vo,Ct,$o,Qs,I,bo,Dt,jo,wo,Je,yo,Eo,er,et,ko,ar,Xe,tr,W,de,xt,Ze,qo,St,Ao,sr,A,Po,Ft,To,zo,Ot,Co,Do,Qe,Nt,xo,So,Lt,Fo,Oo,ea,No,Lo,rr,aa,nr,D,Io,It,Mo,Ho,Mt,Ro,Bo,Ht,Ko,Uo,or,ta,lr,me,Wo,Rt,Go,Yo,ir,sa,pr,G,ue,Bt,ra,Vo,Kt,Jo,cr,fe,Xo,Ut,Zo,Qo,dr,na,mr,oa,el,Wt,al,ur,la,fr,at,hr,Y,he,Gt,ia,tl,Yt,sl,gr,pa,_r,tt,rl,vr,V,ge,Vt,ca,nl,Jt,ol,$r,M,ll,Xt,il,pl,Zt,cl,dl,br,da,jr,_e,wr,x,ml,ma,Qt,ul,fl,es,hl,gl,as,_l,vl,yr,ua,Er,J,ve,ts,fa,$l,ss,bl,kr,st,jl,qr,ha,Ar,$e,wl,ga,rs,yl,El,Pr,_a,Tr,rt,zr,X,be,ns,va,kl,os,ql,Cr,$a,Dr,je,Al,ls,Pl,Tl,xr,nt,zl,Sr,ba,Fr,we,Cl,is,Dl,xl,Or,H,ja,wa,Sl,ps,Fl,Ol,Nl,ya,Ll,Ea,O,Il,cs,Ml,Hl,ds,Rl,Bl,ms,Kl,Ul,Wl,ka,Gl,qa,us,Yl,Vl,Aa,Nr,ot,Jl,Lr,Pa,Ir,Z,ye,fs,Ta,Xl,hs,Zl,Mr,Ee,Ql,gs,ei,ai,Hr,za,Rr,lt,ti,Br,Ca,Kr,Q,ke,_s,Da,si,vs,ri,Ur,qe,ni,xa,$s,oi,li,Wr,Sa,Gr,Fa,ii,bs,pi,Yr,Oa,Vr,Ae,ci,js,di,mi,Jr,Na,Xr,Pe,Zr,it,ui,Qr,ee,Te,ws,La,fi,ys,hi,en,ze,gi,Ia,_i,vi,an,Ma,tn,ae,Ce,Es,Ha,$i,ks,bi,sn,R,ji,qs,wi,yi,Ra,As,Ei,ki,rn,Ba,nn,pt,on,te,De,Ps,Ka,qi,Ts,Ai,ln,ct,Pi,pn,xe,zs,dt,Ua,Ti,zi,Ci,Cs,mt,ut,Di,xi,cn;return y=new z({}),C=new Bc({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/training.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/training.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/training.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/training.ipynb"}]}}),Le=new z({}),Ie=new Rn({props:{id:"_BZearw7f0w"}}),He=new j({props:{code:`from datasets import load_dataset

dataset = load_dataset("yelp_review_full")
dataset[100]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">100</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\&#x27;s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\&#x27;s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\&quot;serving off their orders\\\\&quot; when they didn\\&#x27;t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\&#x27;t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\&#x27;ve eaten at various McDonalds restaurants for over 30 years. I\\&#x27;ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;</span>}`}}),Be=new j({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


tokenized_datasets = dataset.map(tokenize_function, batched=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)`}}),Ke=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),Ue=new z({}),We=new Rn({props:{id:"nvBXf7s7vTI"}}),Ye=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),pe=new Mi({props:{$$slots:{default:[Kc]},$$scope:{ctx:se}}}),Ve=new z({}),Xe=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>)`}}),Ze=new z({}),aa=new j({props:{code:`import numpy as np
from datasets import load_metric

metric = load_metric("accuracy")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)`}}),ta=new j({props:{code:`def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    logits, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),sa=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="epoch")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)`}}),ra=new z({}),na=new j({props:{code:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`}}),la=new j({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),ia=new z({}),pa=new Rn({props:{id:"rnTGBy2ax1c"}}),ca=new z({}),da=new j({props:{code:`from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),_e=new Mi({props:{$$slots:{default:[Uc]},$$scope:{ctx:se}}}),ua=new j({props:{code:`tf_train_dataset = small_train_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = small_eval_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = small_train_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_dataset = small_eval_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)`}}),fa=new z({}),ha=new j({props:{code:`import tensorflow as tf
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),_a=new j({props:{code:`model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=tf.metrics.SparseCategoricalAccuracy(),
)

model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(
<span class="hljs-meta">... </span>    optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">5e-5</span>),
<span class="hljs-meta">... </span>    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
<span class="hljs-meta">... </span>    metrics=tf.metrics.SparseCategoricalAccuracy(),
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>)`}}),va=new z({}),$a=new Rn({props:{id:"Dh9CL8fyG80"}}),ba=new j({props:{code:`del model
del pytorch_model
del trainer
torch.cuda.empty_cache()`,highlighted:`<span class="hljs-keyword">del</span> model
<span class="hljs-keyword">del</span> pytorch_model
<span class="hljs-keyword">del</span> trainer
torch.cuda.empty_cache()`}}),ya=new j({props:{code:'tokenized_datasets = tokenized_datasets.remove_columns(["text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">&quot;text&quot;</span>])'}}),ka=new j({props:{code:'tokenized_datasets = tokenized_datasets.rename_column("label", "labels")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)'}}),Aa=new j({props:{code:'tokenized_datasets.set_format("torch")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)'}}),Pa=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),Ta=new z({}),za=new j({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)
eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataloader = DataLoader(small_train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>eval_dataloader = DataLoader(small_eval_dataset, batch_size=<span class="hljs-number">8</span>)`}}),Ca=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),Da=new z({}),Sa=new j({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>)`}}),Oa=new j({props:{code:`from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
<span class="hljs-meta">&gt;&gt;&gt; </span>lr_scheduler = get_scheduler(
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;linear&quot;</span>, optimizer=optimizer, num_warmup_steps=<span class="hljs-number">0</span>, num_training_steps=num_training_steps
<span class="hljs-meta">... </span>)`}}),Na=new j({props:{code:`import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.to(device)`}}),Pe=new Mi({props:{$$slots:{default:[Wc]},$$scope:{ctx:se}}}),La=new z({}),Ma=new j({props:{code:`from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm

<span class="hljs-meta">&gt;&gt;&gt; </span>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-meta">&gt;&gt;&gt; </span>model.train()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs.loss
<span class="hljs-meta">... </span>        loss.backward()

<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        lr_scheduler.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        progress_bar.update(<span class="hljs-number">1</span>)`}}),Ha=new z({}),Ba=new j({props:{code:`metric = load_metric("accuracy")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
<span class="hljs-meta">... </span>    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>        outputs = model(**batch)

<span class="hljs-meta">... </span>    logits = outputs.logits
<span class="hljs-meta">... </span>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">&quot;labels&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>metric.compute()`}}),Ka=new z({}),{c(){$=r("meta"),E=c(),b=r("h1"),w=r("a"),P=r("span"),u(y.$$.fragment),F=c(),T=r("span"),k=i("Fine-tuning a un modelo pre-entrenado"),q=c(),u(C.$$.fragment),Ne=c(),Ga=r("p"),Bn=i("El uso de un modelo pre-entrenado tiene importantes ventajas. Reduce los costos de computaci\xF3n, la huella de carbono, y te permite utilizar modelos de \xFAltima generaci\xF3n sin tener que entrenar uno desde cero. \u{1F917} Transformers proporciona acceso a miles de modelos pre-entrenados en una amplia gama de tareas. Cuando utilizas un modelo pre-entrenado, lo entrenas con un dataset espec\xEDfico para tu tarea. Esto se conoce como fine-tuning, una t\xE9cnica de entrenamiento incre\xEDblemente poderosa. En este tutorial haremos fine-tuning a un modelo pre-entrenado con un framework de Deep Learning de tu elecci\xF3n:"),Ss=c(),N=r("ul"),Ya=r("li"),Kn=i("Fine-tuning a un modelo pre-entrenado con \u{1F917} Transformers "),bt=r("code"),Un=i("Trainer"),Wn=c(),jt=r("li"),Gn=i("Fine-tuning a un modelo pre-entrenado en TensorFlow con Keras."),Yn=c(),wt=r("li"),Vn=i("Fine-tuning a un modelo pre-entrenado en PyTorch nativo."),Fs=c(),Va=r("a"),Os=c(),B=r("h2"),re=r("a"),yt=r("span"),u(Le.$$.fragment),Jn=c(),Et=r("span"),Xn=i("Prepara un dataset"),Ns=c(),u(Ie.$$.fragment),Ls=c(),Ja=r("p"),Zn=i("Antes de aplicar fine-tuning a un modelo pre-entrenado, descarga un dataset y prep\xE1ralo para el entrenamiento. El tutorial anterior nos ense\xF1\xF3 c\xF3mo procesar los datos para el entrenamiento, y ahora es la oportunidad de poner a prueba estas habilidades."),Is=c(),ne=r("p"),Qn=i("Comienza cargando el dataset de "),Me=r("a"),eo=i("Yelp Reviews"),ao=i(":"),Ms=c(),u(He.$$.fragment),Hs=c(),oe=r("p"),to=i("Como ya sabes, necesitas un tokenizador para procesar el texto e incluir una estrategia para el padding y el truncamiento, para manejar cualquier longitud de secuencia variable. Para procesar tu dataset en un solo paso, utiliza el m\xE9todo de \u{1F917} Datasets "),Re=r("a"),kt=r("code"),so=i("map"),ro=i(" para aplicar una funci\xF3n de preprocesamiento sobre todo el dataset:"),Rs=c(),u(Be.$$.fragment),Bs=c(),Xa=r("p"),no=i("Si lo deseas, puedes crear un subconjunto m\xE1s peque\xF1o del dataset completo para aplicarle fine-tuning y as\xED reducir el tiempo."),Ks=c(),u(Ke.$$.fragment),Us=c(),Za=r("a"),Ws=c(),K=r("h2"),le=r("a"),qt=r("span"),u(Ue.$$.fragment),oo=c(),Qa=r("span"),lo=i("Fine-tuning con "),At=r("code"),io=i("Trainer"),Gs=c(),u(We.$$.fragment),Ys=c(),L=r("p"),po=i("\u{1F917} Transformers proporciona una clase "),Pt=r("code"),co=i("Trainer"),mo=i("optimizada para el entrenamiento de modelos de \u{1F917} Transformers, haciendo m\xE1s f\xE1cil el inicio del entrenamiento sin necesidad de escribir manualmente tu propio ciclo. La API del "),Tt=r("code"),uo=i("Trainer"),fo=i("soporta una amplia gama de opciones de entrenamiento y caracter\xEDsticas como el logging, el gradient accumulation y el mixed precision."),Vs=c(),ie=r("p"),ho=i("Comienza cargando tu modelo y especifica el n\xFAmero de labels previstas. A partir del "),Ge=r("a"),go=i("Card Dataset"),_o=i(" de Yelp Review, que como ya sabemos tiene 5 labels:"),Js=c(),u(Ye.$$.fragment),Xs=c(),u(pe.$$.fragment),Zs=c(),U=r("h3"),ce=r("a"),zt=r("span"),u(Ve.$$.fragment),vo=c(),Ct=r("span"),$o=i("Hiperpar\xE1metros de entrenamiento"),Qs=c(),I=r("p"),bo=i("A continuaci\xF3n, crea una clase "),Dt=r("code"),jo=i("TrainingArguments"),wo=i("que contenga todos los hiperpar\xE1metros que puedes ajustar as\xED como los indicadores para activar las diferentes opciones de entrenamiento. Para este tutorial puedes empezar con los "),Je=r("a"),yo=i("hiperpar\xE1metros"),Eo=i(" de entrenamiento por defecto, pero si\xE9ntete libre de experimentar con ellos para encontrar tu configuraci\xF3n \xF3ptima."),er=c(),et=r("p"),ko=i("Especifica d\xF3nde vas a guardar los checkpoints de tu entrenamiento:"),ar=c(),u(Xe.$$.fragment),tr=c(),W=r("h3"),de=r("a"),xt=r("span"),u(Ze.$$.fragment),qo=c(),St=r("span"),Ao=i("M\xE9tricas"),sr=c(),A=r("p"),Po=i("El "),Ft=r("code"),To=i("Trainer"),zo=i("no eval\xFAa autom\xE1ticamente el rendimiento del modelo durante el entrenamiento. Tendr\xE1s que pasarle a "),Ot=r("code"),Co=i("Trainer"),Do=i("una funci\xF3n para calcular y hacer un reporte de las m\xE9tricas. La librer\xEDa de \u{1F917} Datasets proporciona una funci\xF3n de "),Qe=r("a"),Nt=r("code"),xo=i("accuracy"),So=i(" simple que puedes cargar con la funci\xF3n "),Lt=r("code"),Fo=i("load_metric"),Oo=i(" (ver este "),ea=r("a"),No=i("tutorial"),Lo=i(" para m\xE1s informaci\xF3n):"),rr=c(),u(aa.$$.fragment),nr=c(),D=r("p"),Io=i("Define la funci\xF3n "),It=r("code"),Mo=i("compute"),Ho=i(" en "),Mt=r("code"),Ro=i("metric"),Bo=i(" para calcular el accuracy de tus predicciones. Antes de pasar tus predicciones a "),Ht=r("code"),Ko=i("compute"),Uo=i(", necesitas convertir las predicciones a logits (recuerda que todos los modelos de \u{1F917} Transformers devuelven logits)."),or=c(),u(ta.$$.fragment),lr=c(),me=r("p"),Wo=i("Si quieres controlar tus m\xE9tricas de evaluaci\xF3n durante el fine-tuning, especifica el par\xE1metro "),Rt=r("code"),Go=i("evaluation_strategy"),Yo=i(" en tus argumentos de entrenamiento para que el modelo tenga en cuenta la m\xE9trica de evaluaci\xF3n al final de cada \xE9poca:"),ir=c(),u(sa.$$.fragment),pr=c(),G=r("h3"),ue=r("a"),Bt=r("span"),u(ra.$$.fragment),Vo=c(),Kt=r("span"),Jo=i("Trainer"),cr=c(),fe=r("p"),Xo=i("Crea un objeto "),Ut=r("code"),Zo=i("Trainer"),Qo=i("con tu modelo, argumentos de entrenamiento, conjuntos de datos de entrenamiento y de prueba, y tu funci\xF3n de evaluaci\xF3n:"),dr=c(),u(na.$$.fragment),mr=c(),oa=r("p"),el=i("A continuaci\xF3n, aplica fine-tuning a tu modelo llamando "),Wt=r("code"),al=i("train()"),ur=c(),u(la.$$.fragment),fr=c(),at=r("a"),hr=c(),Y=r("h2"),he=r("a"),Gt=r("span"),u(ia.$$.fragment),tl=c(),Yt=r("span"),sl=i("Fine-tuning con Keras"),gr=c(),u(pa.$$.fragment),_r=c(),tt=r("p"),rl=i("Los modelos de \u{1F917} Transformers tambi\xE9n permiten realizar el entrenamiento en TensorFlow con la API de Keras. S\xF3lo es necesario hacer algunos cambios antes de hacer fine-tuning."),vr=c(),V=r("h3"),ge=r("a"),Vt=r("span"),u(ca.$$.fragment),nl=c(),Jt=r("span"),ol=i("Convierte el dataset al formato de TensorFlow"),$r=c(),M=r("p"),ll=i("El "),Xt=r("code"),il=i("DefaultDataCollator"),pl=i("junta los tensores en un batch para que el modelo se entrene en \xE9l. Aseg\xFArate de especificar "),Zt=r("code"),cl=i("return_tensors"),dl=i(" para devolver los tensores de TensorFlow:"),br=c(),u(da.$$.fragment),jr=c(),u(_e.$$.fragment),wr=c(),x=r("p"),ml=i("A continuaci\xF3n, convierte los datasets tokenizados en datasets de TensorFlow con el m\xE9todo "),ma=r("a"),Qt=r("code"),ul=i("to_tf_dataset"),fl=i(". Especifica tus entradas en "),es=r("code"),hl=i("columns"),gl=i(" y tu etiqueta en "),as=r("code"),_l=i("label_cols"),vl=i(":"),yr=c(),u(ua.$$.fragment),Er=c(),J=r("h3"),ve=r("a"),ts=r("span"),u(fa.$$.fragment),$l=c(),ss=r("span"),bl=i("Compila y ajusta"),kr=c(),st=r("p"),jl=i("Carguemos un modelo TensorFlow con el n\xFAmero esperado de labels:"),qr=c(),u(ha.$$.fragment),Ar=c(),$e=r("p"),wl=i("A continuaci\xF3n, compila y aplica fine-tuning a tu modelo con "),ga=r("a"),rs=r("code"),yl=i("fit"),El=i(" como lo har\xEDas con cualquier otro modelo de Keras:"),Pr=c(),u(_a.$$.fragment),Tr=c(),rt=r("a"),zr=c(),X=r("h2"),be=r("a"),ns=r("span"),u(va.$$.fragment),kl=c(),os=r("span"),ql=i("Fine-tune en PyTorch nativo"),Cr=c(),u($a.$$.fragment),Dr=c(),je=r("p"),Al=i("El "),ls=r("code"),Pl=i("Trainer"),Tl=i("se encarga del ciclo de entrenamiento y permite aplicar fine-tuning a un modelo en una sola l\xEDnea de c\xF3digo. Para los usuarios que prefieren escribir tu propio ciclo de entrenamiento, tambi\xE9n puedes aplicar fine-tuning a un modelo de \u{1F917} Transformers en PyTorch nativo."),xr=c(),nt=r("p"),zl=i("En este punto, es posible que necesites reiniciar tu notebook o ejecutar el siguiente c\xF3digo para liberar algo de memoria:"),Sr=c(),u(ba.$$.fragment),Fr=c(),we=r("p"),Cl=i("A continuaci\xF3n, haremos un post-procesamiento manual al "),is=r("code"),Dl=i("tokenized_dataset"),xl=i(" y as\xED prepararlo para el entrenamiento."),Or=c(),H=r("ol"),ja=r("li"),wa=r("p"),Sl=i("Elimina la columna de "),ps=r("code"),Fl=i("text"),Ol=i(" porque el modelo no acepta texto en crudo como entrada:"),Nl=c(),u(ya.$$.fragment),Ll=c(),Ea=r("li"),O=r("p"),Il=i("Cambia el nombre de la columna de "),cs=r("code"),Ml=i("label"),Hl=i(" a "),ds=r("code"),Rl=i("labels"),Bl=i(" porque el modelo espera que el argumento se llame "),ms=r("code"),Kl=i("labels"),Ul=i(":"),Wl=c(),u(ka.$$.fragment),Gl=c(),qa=r("li"),us=r("p"),Yl=i("Establece el formato del dataset para devolver tensores PyTorch en lugar de listas:"),Vl=c(),u(Aa.$$.fragment),Nr=c(),ot=r("p"),Jl=i("A continuaci\xF3n, crea un subconjunto m\xE1s peque\xF1o del dataset, como se ha mostrado anteriormente, para acelerar el fine-tuning:"),Lr=c(),u(Pa.$$.fragment),Ir=c(),Z=r("h3"),ye=r("a"),fs=r("span"),u(Ta.$$.fragment),Xl=c(),hs=r("span"),Zl=i("DataLoader"),Mr=c(),Ee=r("p"),Ql=i("Crea un "),gs=r("code"),ei=i("DataLoader"),ai=i(" para tus datasets de entrenamiento y de prueba para poder iterar sobre batches de datos:"),Hr=c(),u(za.$$.fragment),Rr=c(),lt=r("p"),ti=i("Carga tu modelo con el n\xFAmero de labels previstas:"),Br=c(),u(Ca.$$.fragment),Kr=c(),Q=r("h3"),ke=r("a"),_s=r("span"),u(Da.$$.fragment),si=c(),vs=r("span"),ri=i("Optimiza y progrma el learning rate"),Ur=c(),qe=r("p"),ni=i("Crea un optimizador y el learning rate para aplicar fine-tuning al modelo. Vamos a utilizar el optimizador "),xa=r("a"),$s=r("code"),oi=i("AdamW"),li=i(" de PyTorch:"),Wr=c(),u(Sa.$$.fragment),Gr=c(),Fa=r("p"),ii=i("Crea el learning rate desde el "),bs=r("code"),pi=i("Trainer"),Yr=c(),u(Oa.$$.fragment),Vr=c(),Ae=r("p"),ci=i("Por \xFAltimo, especifica el "),js=r("code"),di=i("device"),mi=i(" o entorno de ejecuci\xF3n para utilizar una GPU si tienes acceso a una. De lo contrario, el entrenamiento en una CPU puede llevarte varias horas en lugar de un par de minutos."),Jr=c(),u(Na.$$.fragment),Xr=c(),u(Pe.$$.fragment),Zr=c(),it=r("p"),ui=i("Genial, \xA1ahora estamos listos entrenar! \u{1F973}"),Qr=c(),ee=r("h3"),Te=r("a"),ws=r("span"),u(La.$$.fragment),fi=c(),ys=r("span"),hi=i("Ciclo de entrenamiento"),en=c(),ze=r("p"),gi=i("Para hacer un seguimiento al progreso del entrenamiento, utiliza la librer\xEDa "),Ia=r("a"),_i=i("tqdm"),vi=i(" para a\xF1adir una barra de progreso sobre el n\xFAmero de pasos de entrenamiento:"),an=c(),u(Ma.$$.fragment),tn=c(),ae=r("h3"),Ce=r("a"),Es=r("span"),u(Ha.$$.fragment),$i=c(),ks=r("span"),bi=i("M\xE9tricas"),sn=c(),R=r("p"),ji=i("De la misma manera que necesitas a\xF1adir una funci\xF3n de evaluaci\xF3n al "),qs=r("code"),wi=i("Trainer"),yi=i(" necesitas hacer lo mismo cuando escribas tu propio ciclo de entrenamiento. Pero en lugar de calcular y reportar la m\xE9trica al final de cada \xE9poca, esta vez acumular\xE1s todos los batches con "),Ra=r("a"),As=r("code"),Ei=i("add_batch"),ki=i(" y calcular\xE1s la m\xE9trica al final."),rn=c(),u(Ba.$$.fragment),nn=c(),pt=r("a"),on=c(),te=r("h2"),De=r("a"),Ps=r("span"),u(Ka.$$.fragment),qi=c(),Ts=r("span"),Ai=i("Recursos adicionales"),ln=c(),ct=r("p"),Pi=i("Para m\xE1s ejemplos de fine-tuning consulta:"),pn=c(),xe=r("ul"),zs=r("li"),dt=r("p"),Ua=r("a"),Ti=i("\u{1F917} Transformers Examples"),zi=i(` incluye scripts
para entrenar tareas comunes de NLP en PyTorch y TensorFlow.`),Ci=c(),Cs=r("li"),mt=r("p"),ut=r("a"),Di=i("\u{1F917} Transformers Notebooks"),xi=i(" contiene varios notebooks sobre c\xF3mo aplicar fine-tuning a un modelo para tareas espec\xEDficas en PyTorch y TensorFlow."),this.h()},l(e){const s=Hc('[data-svelte="svelte-1phssyn"]',document.head);$=n(s,"META",{name:!0,content:!0}),s.forEach(a),E=d(e),b=n(e,"H1",{class:!0});var Wa=o(b);w=n(Wa,"A",{id:!0,class:!0,href:!0});var Ds=o(w);P=n(Ds,"SPAN",{});var xs=o(P);f(y.$$.fragment,xs),xs.forEach(a),Ds.forEach(a),F=d(Wa),T=n(Wa,"SPAN",{});var Hi=o(T);k=p(Hi,"Fine-tuning a un modelo pre-entrenado"),Hi.forEach(a),Wa.forEach(a),q=d(e),f(C.$$.fragment,e),Ne=d(e),Ga=n(e,"P",{});var Ri=o(Ga);Bn=p(Ri,"El uso de un modelo pre-entrenado tiene importantes ventajas. Reduce los costos de computaci\xF3n, la huella de carbono, y te permite utilizar modelos de \xFAltima generaci\xF3n sin tener que entrenar uno desde cero. \u{1F917} Transformers proporciona acceso a miles de modelos pre-entrenados en una amplia gama de tareas. Cuando utilizas un modelo pre-entrenado, lo entrenas con un dataset espec\xEDfico para tu tarea. Esto se conoce como fine-tuning, una t\xE9cnica de entrenamiento incre\xEDblemente poderosa. En este tutorial haremos fine-tuning a un modelo pre-entrenado con un framework de Deep Learning de tu elecci\xF3n:"),Ri.forEach(a),Ss=d(e),N=n(e,"UL",{});var ft=o(N);Ya=n(ft,"LI",{});var Si=o(Ya);Kn=p(Si,"Fine-tuning a un modelo pre-entrenado con \u{1F917} Transformers "),bt=n(Si,"CODE",{});var Bi=o(bt);Un=p(Bi,"Trainer"),Bi.forEach(a),Si.forEach(a),Wn=d(ft),jt=n(ft,"LI",{});var Ki=o(jt);Gn=p(Ki,"Fine-tuning a un modelo pre-entrenado en TensorFlow con Keras."),Ki.forEach(a),Yn=d(ft),wt=n(ft,"LI",{});var Ui=o(wt);Vn=p(Ui,"Fine-tuning a un modelo pre-entrenado en PyTorch nativo."),Ui.forEach(a),ft.forEach(a),Fs=d(e),Va=n(e,"A",{id:!0}),o(Va).forEach(a),Os=d(e),B=n(e,"H2",{class:!0});var dn=o(B);re=n(dn,"A",{id:!0,class:!0,href:!0});var Wi=o(re);yt=n(Wi,"SPAN",{});var Gi=o(yt);f(Le.$$.fragment,Gi),Gi.forEach(a),Wi.forEach(a),Jn=d(dn),Et=n(dn,"SPAN",{});var Yi=o(Et);Xn=p(Yi,"Prepara un dataset"),Yi.forEach(a),dn.forEach(a),Ns=d(e),f(Ie.$$.fragment,e),Ls=d(e),Ja=n(e,"P",{});var Vi=o(Ja);Zn=p(Vi,"Antes de aplicar fine-tuning a un modelo pre-entrenado, descarga un dataset y prep\xE1ralo para el entrenamiento. El tutorial anterior nos ense\xF1\xF3 c\xF3mo procesar los datos para el entrenamiento, y ahora es la oportunidad de poner a prueba estas habilidades."),Vi.forEach(a),Is=d(e),ne=n(e,"P",{});var mn=o(ne);Qn=p(mn,"Comienza cargando el dataset de "),Me=n(mn,"A",{href:!0,rel:!0});var Ji=o(Me);eo=p(Ji,"Yelp Reviews"),Ji.forEach(a),ao=p(mn,":"),mn.forEach(a),Ms=d(e),f(He.$$.fragment,e),Hs=d(e),oe=n(e,"P",{});var un=o(oe);to=p(un,"Como ya sabes, necesitas un tokenizador para procesar el texto e incluir una estrategia para el padding y el truncamiento, para manejar cualquier longitud de secuencia variable. Para procesar tu dataset en un solo paso, utiliza el m\xE9todo de \u{1F917} Datasets "),Re=n(un,"A",{href:!0,rel:!0});var Xi=o(Re);kt=n(Xi,"CODE",{});var Zi=o(kt);so=p(Zi,"map"),Zi.forEach(a),Xi.forEach(a),ro=p(un," para aplicar una funci\xF3n de preprocesamiento sobre todo el dataset:"),un.forEach(a),Rs=d(e),f(Be.$$.fragment,e),Bs=d(e),Xa=n(e,"P",{});var Qi=o(Xa);no=p(Qi,"Si lo deseas, puedes crear un subconjunto m\xE1s peque\xF1o del dataset completo para aplicarle fine-tuning y as\xED reducir el tiempo."),Qi.forEach(a),Ks=d(e),f(Ke.$$.fragment,e),Us=d(e),Za=n(e,"A",{id:!0}),o(Za).forEach(a),Ws=d(e),K=n(e,"H2",{class:!0});var fn=o(K);le=n(fn,"A",{id:!0,class:!0,href:!0});var ep=o(le);qt=n(ep,"SPAN",{});var ap=o(qt);f(Ue.$$.fragment,ap),ap.forEach(a),ep.forEach(a),oo=d(fn),Qa=n(fn,"SPAN",{});var Fi=o(Qa);lo=p(Fi,"Fine-tuning con "),At=n(Fi,"CODE",{});var tp=o(At);io=p(tp,"Trainer"),tp.forEach(a),Fi.forEach(a),fn.forEach(a),Gs=d(e),f(We.$$.fragment,e),Ys=d(e),L=n(e,"P",{});var ht=o(L);po=p(ht,"\u{1F917} Transformers proporciona una clase "),Pt=n(ht,"CODE",{});var sp=o(Pt);co=p(sp,"Trainer"),sp.forEach(a),mo=p(ht,"optimizada para el entrenamiento de modelos de \u{1F917} Transformers, haciendo m\xE1s f\xE1cil el inicio del entrenamiento sin necesidad de escribir manualmente tu propio ciclo. La API del "),Tt=n(ht,"CODE",{});var rp=o(Tt);uo=p(rp,"Trainer"),rp.forEach(a),fo=p(ht,"soporta una amplia gama de opciones de entrenamiento y caracter\xEDsticas como el logging, el gradient accumulation y el mixed precision."),ht.forEach(a),Vs=d(e),ie=n(e,"P",{});var hn=o(ie);ho=p(hn,"Comienza cargando tu modelo y especifica el n\xFAmero de labels previstas. A partir del "),Ge=n(hn,"A",{href:!0,rel:!0});var np=o(Ge);go=p(np,"Card Dataset"),np.forEach(a),_o=p(hn," de Yelp Review, que como ya sabemos tiene 5 labels:"),hn.forEach(a),Js=d(e),f(Ye.$$.fragment,e),Xs=d(e),f(pe.$$.fragment,e),Zs=d(e),U=n(e,"H3",{class:!0});var gn=o(U);ce=n(gn,"A",{id:!0,class:!0,href:!0});var op=o(ce);zt=n(op,"SPAN",{});var lp=o(zt);f(Ve.$$.fragment,lp),lp.forEach(a),op.forEach(a),vo=d(gn),Ct=n(gn,"SPAN",{});var ip=o(Ct);$o=p(ip,"Hiperpar\xE1metros de entrenamiento"),ip.forEach(a),gn.forEach(a),Qs=d(e),I=n(e,"P",{});var gt=o(I);bo=p(gt,"A continuaci\xF3n, crea una clase "),Dt=n(gt,"CODE",{});var pp=o(Dt);jo=p(pp,"TrainingArguments"),pp.forEach(a),wo=p(gt,"que contenga todos los hiperpar\xE1metros que puedes ajustar as\xED como los indicadores para activar las diferentes opciones de entrenamiento. Para este tutorial puedes empezar con los "),Je=n(gt,"A",{href:!0,rel:!0});var cp=o(Je);yo=p(cp,"hiperpar\xE1metros"),cp.forEach(a),Eo=p(gt," de entrenamiento por defecto, pero si\xE9ntete libre de experimentar con ellos para encontrar tu configuraci\xF3n \xF3ptima."),gt.forEach(a),er=d(e),et=n(e,"P",{});var dp=o(et);ko=p(dp,"Especifica d\xF3nde vas a guardar los checkpoints de tu entrenamiento:"),dp.forEach(a),ar=d(e),f(Xe.$$.fragment,e),tr=d(e),W=n(e,"H3",{class:!0});var _n=o(W);de=n(_n,"A",{id:!0,class:!0,href:!0});var mp=o(de);xt=n(mp,"SPAN",{});var up=o(xt);f(Ze.$$.fragment,up),up.forEach(a),mp.forEach(a),qo=d(_n),St=n(_n,"SPAN",{});var fp=o(St);Ao=p(fp,"M\xE9tricas"),fp.forEach(a),_n.forEach(a),sr=d(e),A=n(e,"P",{});var S=o(A);Po=p(S,"El "),Ft=n(S,"CODE",{});var hp=o(Ft);To=p(hp,"Trainer"),hp.forEach(a),zo=p(S,"no eval\xFAa autom\xE1ticamente el rendimiento del modelo durante el entrenamiento. Tendr\xE1s que pasarle a "),Ot=n(S,"CODE",{});var gp=o(Ot);Co=p(gp,"Trainer"),gp.forEach(a),Do=p(S,"una funci\xF3n para calcular y hacer un reporte de las m\xE9tricas. La librer\xEDa de \u{1F917} Datasets proporciona una funci\xF3n de "),Qe=n(S,"A",{href:!0,rel:!0});var _p=o(Qe);Nt=n(_p,"CODE",{});var vp=o(Nt);xo=p(vp,"accuracy"),vp.forEach(a),_p.forEach(a),So=p(S," simple que puedes cargar con la funci\xF3n "),Lt=n(S,"CODE",{});var $p=o(Lt);Fo=p($p,"load_metric"),$p.forEach(a),Oo=p(S," (ver este "),ea=n(S,"A",{href:!0,rel:!0});var bp=o(ea);No=p(bp,"tutorial"),bp.forEach(a),Lo=p(S," para m\xE1s informaci\xF3n):"),S.forEach(a),rr=d(e),f(aa.$$.fragment,e),nr=d(e),D=n(e,"P",{});var Se=o(D);Io=p(Se,"Define la funci\xF3n "),It=n(Se,"CODE",{});var jp=o(It);Mo=p(jp,"compute"),jp.forEach(a),Ho=p(Se," en "),Mt=n(Se,"CODE",{});var wp=o(Mt);Ro=p(wp,"metric"),wp.forEach(a),Bo=p(Se," para calcular el accuracy de tus predicciones. Antes de pasar tus predicciones a "),Ht=n(Se,"CODE",{});var yp=o(Ht);Ko=p(yp,"compute"),yp.forEach(a),Uo=p(Se,", necesitas convertir las predicciones a logits (recuerda que todos los modelos de \u{1F917} Transformers devuelven logits)."),Se.forEach(a),or=d(e),f(ta.$$.fragment,e),lr=d(e),me=n(e,"P",{});var vn=o(me);Wo=p(vn,"Si quieres controlar tus m\xE9tricas de evaluaci\xF3n durante el fine-tuning, especifica el par\xE1metro "),Rt=n(vn,"CODE",{});var Ep=o(Rt);Go=p(Ep,"evaluation_strategy"),Ep.forEach(a),Yo=p(vn," en tus argumentos de entrenamiento para que el modelo tenga en cuenta la m\xE9trica de evaluaci\xF3n al final de cada \xE9poca:"),vn.forEach(a),ir=d(e),f(sa.$$.fragment,e),pr=d(e),G=n(e,"H3",{class:!0});var $n=o(G);ue=n($n,"A",{id:!0,class:!0,href:!0});var kp=o(ue);Bt=n(kp,"SPAN",{});var qp=o(Bt);f(ra.$$.fragment,qp),qp.forEach(a),kp.forEach(a),Vo=d($n),Kt=n($n,"SPAN",{});var Ap=o(Kt);Jo=p(Ap,"Trainer"),Ap.forEach(a),$n.forEach(a),cr=d(e),fe=n(e,"P",{});var bn=o(fe);Xo=p(bn,"Crea un objeto "),Ut=n(bn,"CODE",{});var Pp=o(Ut);Zo=p(Pp,"Trainer"),Pp.forEach(a),Qo=p(bn,"con tu modelo, argumentos de entrenamiento, conjuntos de datos de entrenamiento y de prueba, y tu funci\xF3n de evaluaci\xF3n:"),bn.forEach(a),dr=d(e),f(na.$$.fragment,e),mr=d(e),oa=n(e,"P",{});var Oi=o(oa);el=p(Oi,"A continuaci\xF3n, aplica fine-tuning a tu modelo llamando "),Wt=n(Oi,"CODE",{});var Tp=o(Wt);al=p(Tp,"train()"),Tp.forEach(a),Oi.forEach(a),ur=d(e),f(la.$$.fragment,e),fr=d(e),at=n(e,"A",{id:!0}),o(at).forEach(a),hr=d(e),Y=n(e,"H2",{class:!0});var jn=o(Y);he=n(jn,"A",{id:!0,class:!0,href:!0});var zp=o(he);Gt=n(zp,"SPAN",{});var Cp=o(Gt);f(ia.$$.fragment,Cp),Cp.forEach(a),zp.forEach(a),tl=d(jn),Yt=n(jn,"SPAN",{});var Dp=o(Yt);sl=p(Dp,"Fine-tuning con Keras"),Dp.forEach(a),jn.forEach(a),gr=d(e),f(pa.$$.fragment,e),_r=d(e),tt=n(e,"P",{});var xp=o(tt);rl=p(xp,"Los modelos de \u{1F917} Transformers tambi\xE9n permiten realizar el entrenamiento en TensorFlow con la API de Keras. S\xF3lo es necesario hacer algunos cambios antes de hacer fine-tuning."),xp.forEach(a),vr=d(e),V=n(e,"H3",{class:!0});var wn=o(V);ge=n(wn,"A",{id:!0,class:!0,href:!0});var Sp=o(ge);Vt=n(Sp,"SPAN",{});var Fp=o(Vt);f(ca.$$.fragment,Fp),Fp.forEach(a),Sp.forEach(a),nl=d(wn),Jt=n(wn,"SPAN",{});var Op=o(Jt);ol=p(Op,"Convierte el dataset al formato de TensorFlow"),Op.forEach(a),wn.forEach(a),$r=d(e),M=n(e,"P",{});var _t=o(M);ll=p(_t,"El "),Xt=n(_t,"CODE",{});var Np=o(Xt);il=p(Np,"DefaultDataCollator"),Np.forEach(a),pl=p(_t,"junta los tensores en un batch para que el modelo se entrene en \xE9l. Aseg\xFArate de especificar "),Zt=n(_t,"CODE",{});var Lp=o(Zt);cl=p(Lp,"return_tensors"),Lp.forEach(a),dl=p(_t," para devolver los tensores de TensorFlow:"),_t.forEach(a),br=d(e),f(da.$$.fragment,e),jr=d(e),f(_e.$$.fragment,e),wr=d(e),x=n(e,"P",{});var Fe=o(x);ml=p(Fe,"A continuaci\xF3n, convierte los datasets tokenizados en datasets de TensorFlow con el m\xE9todo "),ma=n(Fe,"A",{href:!0,rel:!0});var Ip=o(ma);Qt=n(Ip,"CODE",{});var Mp=o(Qt);ul=p(Mp,"to_tf_dataset"),Mp.forEach(a),Ip.forEach(a),fl=p(Fe,". Especifica tus entradas en "),es=n(Fe,"CODE",{});var Hp=o(es);hl=p(Hp,"columns"),Hp.forEach(a),gl=p(Fe," y tu etiqueta en "),as=n(Fe,"CODE",{});var Rp=o(as);_l=p(Rp,"label_cols"),Rp.forEach(a),vl=p(Fe,":"),Fe.forEach(a),yr=d(e),f(ua.$$.fragment,e),Er=d(e),J=n(e,"H3",{class:!0});var yn=o(J);ve=n(yn,"A",{id:!0,class:!0,href:!0});var Bp=o(ve);ts=n(Bp,"SPAN",{});var Kp=o(ts);f(fa.$$.fragment,Kp),Kp.forEach(a),Bp.forEach(a),$l=d(yn),ss=n(yn,"SPAN",{});var Up=o(ss);bl=p(Up,"Compila y ajusta"),Up.forEach(a),yn.forEach(a),kr=d(e),st=n(e,"P",{});var Wp=o(st);jl=p(Wp,"Carguemos un modelo TensorFlow con el n\xFAmero esperado de labels:"),Wp.forEach(a),qr=d(e),f(ha.$$.fragment,e),Ar=d(e),$e=n(e,"P",{});var En=o($e);wl=p(En,"A continuaci\xF3n, compila y aplica fine-tuning a tu modelo con "),ga=n(En,"A",{href:!0,rel:!0});var Gp=o(ga);rs=n(Gp,"CODE",{});var Yp=o(rs);yl=p(Yp,"fit"),Yp.forEach(a),Gp.forEach(a),El=p(En," como lo har\xEDas con cualquier otro modelo de Keras:"),En.forEach(a),Pr=d(e),f(_a.$$.fragment,e),Tr=d(e),rt=n(e,"A",{id:!0}),o(rt).forEach(a),zr=d(e),X=n(e,"H2",{class:!0});var kn=o(X);be=n(kn,"A",{id:!0,class:!0,href:!0});var Vp=o(be);ns=n(Vp,"SPAN",{});var Jp=o(ns);f(va.$$.fragment,Jp),Jp.forEach(a),Vp.forEach(a),kl=d(kn),os=n(kn,"SPAN",{});var Xp=o(os);ql=p(Xp,"Fine-tune en PyTorch nativo"),Xp.forEach(a),kn.forEach(a),Cr=d(e),f($a.$$.fragment,e),Dr=d(e),je=n(e,"P",{});var qn=o(je);Al=p(qn,"El "),ls=n(qn,"CODE",{});var Zp=o(ls);Pl=p(Zp,"Trainer"),Zp.forEach(a),Tl=p(qn,"se encarga del ciclo de entrenamiento y permite aplicar fine-tuning a un modelo en una sola l\xEDnea de c\xF3digo. Para los usuarios que prefieren escribir tu propio ciclo de entrenamiento, tambi\xE9n puedes aplicar fine-tuning a un modelo de \u{1F917} Transformers en PyTorch nativo."),qn.forEach(a),xr=d(e),nt=n(e,"P",{});var Qp=o(nt);zl=p(Qp,"En este punto, es posible que necesites reiniciar tu notebook o ejecutar el siguiente c\xF3digo para liberar algo de memoria:"),Qp.forEach(a),Sr=d(e),f(ba.$$.fragment,e),Fr=d(e),we=n(e,"P",{});var An=o(we);Cl=p(An,"A continuaci\xF3n, haremos un post-procesamiento manual al "),is=n(An,"CODE",{});var ec=o(is);Dl=p(ec,"tokenized_dataset"),ec.forEach(a),xl=p(An," y as\xED prepararlo para el entrenamiento."),An.forEach(a),Or=d(e),H=n(e,"OL",{});var vt=o(H);ja=n(vt,"LI",{});var Pn=o(ja);wa=n(Pn,"P",{});var Tn=o(wa);Sl=p(Tn,"Elimina la columna de "),ps=n(Tn,"CODE",{});var ac=o(ps);Fl=p(ac,"text"),ac.forEach(a),Ol=p(Tn," porque el modelo no acepta texto en crudo como entrada:"),Tn.forEach(a),Nl=d(Pn),f(ya.$$.fragment,Pn),Pn.forEach(a),Ll=d(vt),Ea=n(vt,"LI",{});var zn=o(Ea);O=n(zn,"P",{});var Oe=o(O);Il=p(Oe,"Cambia el nombre de la columna de "),cs=n(Oe,"CODE",{});var tc=o(cs);Ml=p(tc,"label"),tc.forEach(a),Hl=p(Oe," a "),ds=n(Oe,"CODE",{});var sc=o(ds);Rl=p(sc,"labels"),sc.forEach(a),Bl=p(Oe," porque el modelo espera que el argumento se llame "),ms=n(Oe,"CODE",{});var rc=o(ms);Kl=p(rc,"labels"),rc.forEach(a),Ul=p(Oe,":"),Oe.forEach(a),Wl=d(zn),f(ka.$$.fragment,zn),zn.forEach(a),Gl=d(vt),qa=n(vt,"LI",{});var Cn=o(qa);us=n(Cn,"P",{});var nc=o(us);Yl=p(nc,"Establece el formato del dataset para devolver tensores PyTorch en lugar de listas:"),nc.forEach(a),Vl=d(Cn),f(Aa.$$.fragment,Cn),Cn.forEach(a),vt.forEach(a),Nr=d(e),ot=n(e,"P",{});var oc=o(ot);Jl=p(oc,"A continuaci\xF3n, crea un subconjunto m\xE1s peque\xF1o del dataset, como se ha mostrado anteriormente, para acelerar el fine-tuning:"),oc.forEach(a),Lr=d(e),f(Pa.$$.fragment,e),Ir=d(e),Z=n(e,"H3",{class:!0});var Dn=o(Z);ye=n(Dn,"A",{id:!0,class:!0,href:!0});var lc=o(ye);fs=n(lc,"SPAN",{});var ic=o(fs);f(Ta.$$.fragment,ic),ic.forEach(a),lc.forEach(a),Xl=d(Dn),hs=n(Dn,"SPAN",{});var pc=o(hs);Zl=p(pc,"DataLoader"),pc.forEach(a),Dn.forEach(a),Mr=d(e),Ee=n(e,"P",{});var xn=o(Ee);Ql=p(xn,"Crea un "),gs=n(xn,"CODE",{});var cc=o(gs);ei=p(cc,"DataLoader"),cc.forEach(a),ai=p(xn," para tus datasets de entrenamiento y de prueba para poder iterar sobre batches de datos:"),xn.forEach(a),Hr=d(e),f(za.$$.fragment,e),Rr=d(e),lt=n(e,"P",{});var dc=o(lt);ti=p(dc,"Carga tu modelo con el n\xFAmero de labels previstas:"),dc.forEach(a),Br=d(e),f(Ca.$$.fragment,e),Kr=d(e),Q=n(e,"H3",{class:!0});var Sn=o(Q);ke=n(Sn,"A",{id:!0,class:!0,href:!0});var mc=o(ke);_s=n(mc,"SPAN",{});var uc=o(_s);f(Da.$$.fragment,uc),uc.forEach(a),mc.forEach(a),si=d(Sn),vs=n(Sn,"SPAN",{});var fc=o(vs);ri=p(fc,"Optimiza y progrma el learning rate"),fc.forEach(a),Sn.forEach(a),Ur=d(e),qe=n(e,"P",{});var Fn=o(qe);ni=p(Fn,"Crea un optimizador y el learning rate para aplicar fine-tuning al modelo. Vamos a utilizar el optimizador "),xa=n(Fn,"A",{href:!0,rel:!0});var hc=o(xa);$s=n(hc,"CODE",{});var gc=o($s);oi=p(gc,"AdamW"),gc.forEach(a),hc.forEach(a),li=p(Fn," de PyTorch:"),Fn.forEach(a),Wr=d(e),f(Sa.$$.fragment,e),Gr=d(e),Fa=n(e,"P",{});var Ni=o(Fa);ii=p(Ni,"Crea el learning rate desde el "),bs=n(Ni,"CODE",{});var _c=o(bs);pi=p(_c,"Trainer"),_c.forEach(a),Ni.forEach(a),Yr=d(e),f(Oa.$$.fragment,e),Vr=d(e),Ae=n(e,"P",{});var On=o(Ae);ci=p(On,"Por \xFAltimo, especifica el "),js=n(On,"CODE",{});var vc=o(js);di=p(vc,"device"),vc.forEach(a),mi=p(On," o entorno de ejecuci\xF3n para utilizar una GPU si tienes acceso a una. De lo contrario, el entrenamiento en una CPU puede llevarte varias horas en lugar de un par de minutos."),On.forEach(a),Jr=d(e),f(Na.$$.fragment,e),Xr=d(e),f(Pe.$$.fragment,e),Zr=d(e),it=n(e,"P",{});var $c=o(it);ui=p($c,"Genial, \xA1ahora estamos listos entrenar! \u{1F973}"),$c.forEach(a),Qr=d(e),ee=n(e,"H3",{class:!0});var Nn=o(ee);Te=n(Nn,"A",{id:!0,class:!0,href:!0});var bc=o(Te);ws=n(bc,"SPAN",{});var jc=o(ws);f(La.$$.fragment,jc),jc.forEach(a),bc.forEach(a),fi=d(Nn),ys=n(Nn,"SPAN",{});var wc=o(ys);hi=p(wc,"Ciclo de entrenamiento"),wc.forEach(a),Nn.forEach(a),en=d(e),ze=n(e,"P",{});var Ln=o(ze);gi=p(Ln,"Para hacer un seguimiento al progreso del entrenamiento, utiliza la librer\xEDa "),Ia=n(Ln,"A",{href:!0,rel:!0});var yc=o(Ia);_i=p(yc,"tqdm"),yc.forEach(a),vi=p(Ln," para a\xF1adir una barra de progreso sobre el n\xFAmero de pasos de entrenamiento:"),Ln.forEach(a),an=d(e),f(Ma.$$.fragment,e),tn=d(e),ae=n(e,"H3",{class:!0});var In=o(ae);Ce=n(In,"A",{id:!0,class:!0,href:!0});var Ec=o(Ce);Es=n(Ec,"SPAN",{});var kc=o(Es);f(Ha.$$.fragment,kc),kc.forEach(a),Ec.forEach(a),$i=d(In),ks=n(In,"SPAN",{});var qc=o(ks);bi=p(qc,"M\xE9tricas"),qc.forEach(a),In.forEach(a),sn=d(e),R=n(e,"P",{});var $t=o(R);ji=p($t,"De la misma manera que necesitas a\xF1adir una funci\xF3n de evaluaci\xF3n al "),qs=n($t,"CODE",{});var Ac=o(qs);wi=p(Ac,"Trainer"),Ac.forEach(a),yi=p($t," necesitas hacer lo mismo cuando escribas tu propio ciclo de entrenamiento. Pero en lugar de calcular y reportar la m\xE9trica al final de cada \xE9poca, esta vez acumular\xE1s todos los batches con "),Ra=n($t,"A",{href:!0,rel:!0});var Pc=o(Ra);As=n(Pc,"CODE",{});var Tc=o(As);Ei=p(Tc,"add_batch"),Tc.forEach(a),Pc.forEach(a),ki=p($t," y calcular\xE1s la m\xE9trica al final."),$t.forEach(a),rn=d(e),f(Ba.$$.fragment,e),nn=d(e),pt=n(e,"A",{id:!0}),o(pt).forEach(a),on=d(e),te=n(e,"H2",{class:!0});var Mn=o(te);De=n(Mn,"A",{id:!0,class:!0,href:!0});var zc=o(De);Ps=n(zc,"SPAN",{});var Cc=o(Ps);f(Ka.$$.fragment,Cc),Cc.forEach(a),zc.forEach(a),qi=d(Mn),Ts=n(Mn,"SPAN",{});var Dc=o(Ts);Ai=p(Dc,"Recursos adicionales"),Dc.forEach(a),Mn.forEach(a),ln=d(e),ct=n(e,"P",{});var xc=o(ct);Pi=p(xc,"Para m\xE1s ejemplos de fine-tuning consulta:"),xc.forEach(a),pn=d(e),xe=n(e,"UL",{});var Hn=o(xe);zs=n(Hn,"LI",{});var Sc=o(zs);dt=n(Sc,"P",{});var Li=o(dt);Ua=n(Li,"A",{href:!0,rel:!0});var Fc=o(Ua);Ti=p(Fc,"\u{1F917} Transformers Examples"),Fc.forEach(a),zi=p(Li,` incluye scripts
para entrenar tareas comunes de NLP en PyTorch y TensorFlow.`),Li.forEach(a),Sc.forEach(a),Ci=d(Hn),Cs=n(Hn,"LI",{});var Oc=o(Cs);mt=n(Oc,"P",{});var Ii=o(mt);ut=n(Ii,"A",{href:!0});var Nc=o(ut);Di=p(Nc,"\u{1F917} Transformers Notebooks"),Nc.forEach(a),xi=p(Ii," contiene varios notebooks sobre c\xF3mo aplicar fine-tuning a un modelo para tareas espec\xEDficas en PyTorch y TensorFlow."),Ii.forEach(a),Oc.forEach(a),Hn.forEach(a),this.h()},h(){m($,"name","hf:doc:metadata"),m($,"content",JSON.stringify(Yc)),m(w,"id","finetuning-a-un-modelo-preentrenado"),m(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w,"href","#finetuning-a-un-modelo-preentrenado"),m(b,"class","relative group"),m(Va,"id","data-processing"),m(re,"id","prepara-un-dataset"),m(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(re,"href","#prepara-un-dataset"),m(B,"class","relative group"),m(Me,"href","https://huggingface.co/datasets/yelp_review_full"),m(Me,"rel","nofollow"),m(Re,"href","https://huggingface.co/docs/datasets/process.html#map"),m(Re,"rel","nofollow"),m(Za,"id","trainer"),m(le,"id","finetuning-con-trainer"),m(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(le,"href","#finetuning-con-trainer"),m(K,"class","relative group"),m(Ge,"href","https://huggingface.co/datasets/yelp_review_full#data-fields"),m(Ge,"rel","nofollow"),m(ce,"id","hiperparmetros-de-entrenamiento"),m(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ce,"href","#hiperparmetros-de-entrenamiento"),m(U,"class","relative group"),m(Je,"href","https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments"),m(Je,"rel","nofollow"),m(de,"id","mtricas"),m(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(de,"href","#mtricas"),m(W,"class","relative group"),m(Qe,"href","https://huggingface.co/metrics/accuracy"),m(Qe,"rel","nofollow"),m(ea,"href","https://huggingface.co/docs/datasets/metrics.html"),m(ea,"rel","nofollow"),m(ue,"id","trainer"),m(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ue,"href","#trainer"),m(G,"class","relative group"),m(at,"id","keras"),m(he,"id","finetuning-con-keras"),m(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(he,"href","#finetuning-con-keras"),m(Y,"class","relative group"),m(ge,"id","convierte-el-dataset-al-formato-de-tensorflow"),m(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ge,"href","#convierte-el-dataset-al-formato-de-tensorflow"),m(V,"class","relative group"),m(ma,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),m(ma,"rel","nofollow"),m(ve,"id","compila-y-ajusta"),m(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ve,"href","#compila-y-ajusta"),m(J,"class","relative group"),m(ga,"href","https://keras.io/api/models/model_training_apis/"),m(ga,"rel","nofollow"),m(rt,"id","pytorch_native"),m(be,"id","finetune-en-pytorch-nativo"),m(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(be,"href","#finetune-en-pytorch-nativo"),m(X,"class","relative group"),m(ye,"id","dataloader"),m(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ye,"href","#dataloader"),m(Z,"class","relative group"),m(ke,"id","optimiza-y-progrma-el-learning-rate"),m(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ke,"href","#optimiza-y-progrma-el-learning-rate"),m(Q,"class","relative group"),m(xa,"href","https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"),m(xa,"rel","nofollow"),m(Te,"id","ciclo-de-entrenamiento"),m(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Te,"href","#ciclo-de-entrenamiento"),m(ee,"class","relative group"),m(Ia,"href","https://tqdm.github.io/"),m(Ia,"rel","nofollow"),m(Ce,"id","mtricas"),m(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ce,"href","#mtricas"),m(ae,"class","relative group"),m(Ra,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=add_batch#datasets.Metric.add_batch"),m(Ra,"rel","nofollow"),m(pt,"id","additional-resources"),m(De,"id","recursos-adicionales"),m(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(De,"href","#recursos-adicionales"),m(te,"class","relative group"),m(Ua,"href","https://github.com/huggingface/transformers/tree/main/examples"),m(Ua,"rel","nofollow"),m(ut,"href","notebooks")},m(e,s){t(document.head,$),l(e,E,s),l(e,b,s),t(b,w),t(w,P),h(y,P,null),t(b,F),t(b,T),t(T,k),l(e,q,s),h(C,e,s),l(e,Ne,s),l(e,Ga,s),t(Ga,Bn),l(e,Ss,s),l(e,N,s),t(N,Ya),t(Ya,Kn),t(Ya,bt),t(bt,Un),t(N,Wn),t(N,jt),t(jt,Gn),t(N,Yn),t(N,wt),t(wt,Vn),l(e,Fs,s),l(e,Va,s),l(e,Os,s),l(e,B,s),t(B,re),t(re,yt),h(Le,yt,null),t(B,Jn),t(B,Et),t(Et,Xn),l(e,Ns,s),h(Ie,e,s),l(e,Ls,s),l(e,Ja,s),t(Ja,Zn),l(e,Is,s),l(e,ne,s),t(ne,Qn),t(ne,Me),t(Me,eo),t(ne,ao),l(e,Ms,s),h(He,e,s),l(e,Hs,s),l(e,oe,s),t(oe,to),t(oe,Re),t(Re,kt),t(kt,so),t(oe,ro),l(e,Rs,s),h(Be,e,s),l(e,Bs,s),l(e,Xa,s),t(Xa,no),l(e,Ks,s),h(Ke,e,s),l(e,Us,s),l(e,Za,s),l(e,Ws,s),l(e,K,s),t(K,le),t(le,qt),h(Ue,qt,null),t(K,oo),t(K,Qa),t(Qa,lo),t(Qa,At),t(At,io),l(e,Gs,s),h(We,e,s),l(e,Ys,s),l(e,L,s),t(L,po),t(L,Pt),t(Pt,co),t(L,mo),t(L,Tt),t(Tt,uo),t(L,fo),l(e,Vs,s),l(e,ie,s),t(ie,ho),t(ie,Ge),t(Ge,go),t(ie,_o),l(e,Js,s),h(Ye,e,s),l(e,Xs,s),h(pe,e,s),l(e,Zs,s),l(e,U,s),t(U,ce),t(ce,zt),h(Ve,zt,null),t(U,vo),t(U,Ct),t(Ct,$o),l(e,Qs,s),l(e,I,s),t(I,bo),t(I,Dt),t(Dt,jo),t(I,wo),t(I,Je),t(Je,yo),t(I,Eo),l(e,er,s),l(e,et,s),t(et,ko),l(e,ar,s),h(Xe,e,s),l(e,tr,s),l(e,W,s),t(W,de),t(de,xt),h(Ze,xt,null),t(W,qo),t(W,St),t(St,Ao),l(e,sr,s),l(e,A,s),t(A,Po),t(A,Ft),t(Ft,To),t(A,zo),t(A,Ot),t(Ot,Co),t(A,Do),t(A,Qe),t(Qe,Nt),t(Nt,xo),t(A,So),t(A,Lt),t(Lt,Fo),t(A,Oo),t(A,ea),t(ea,No),t(A,Lo),l(e,rr,s),h(aa,e,s),l(e,nr,s),l(e,D,s),t(D,Io),t(D,It),t(It,Mo),t(D,Ho),t(D,Mt),t(Mt,Ro),t(D,Bo),t(D,Ht),t(Ht,Ko),t(D,Uo),l(e,or,s),h(ta,e,s),l(e,lr,s),l(e,me,s),t(me,Wo),t(me,Rt),t(Rt,Go),t(me,Yo),l(e,ir,s),h(sa,e,s),l(e,pr,s),l(e,G,s),t(G,ue),t(ue,Bt),h(ra,Bt,null),t(G,Vo),t(G,Kt),t(Kt,Jo),l(e,cr,s),l(e,fe,s),t(fe,Xo),t(fe,Ut),t(Ut,Zo),t(fe,Qo),l(e,dr,s),h(na,e,s),l(e,mr,s),l(e,oa,s),t(oa,el),t(oa,Wt),t(Wt,al),l(e,ur,s),h(la,e,s),l(e,fr,s),l(e,at,s),l(e,hr,s),l(e,Y,s),t(Y,he),t(he,Gt),h(ia,Gt,null),t(Y,tl),t(Y,Yt),t(Yt,sl),l(e,gr,s),h(pa,e,s),l(e,_r,s),l(e,tt,s),t(tt,rl),l(e,vr,s),l(e,V,s),t(V,ge),t(ge,Vt),h(ca,Vt,null),t(V,nl),t(V,Jt),t(Jt,ol),l(e,$r,s),l(e,M,s),t(M,ll),t(M,Xt),t(Xt,il),t(M,pl),t(M,Zt),t(Zt,cl),t(M,dl),l(e,br,s),h(da,e,s),l(e,jr,s),h(_e,e,s),l(e,wr,s),l(e,x,s),t(x,ml),t(x,ma),t(ma,Qt),t(Qt,ul),t(x,fl),t(x,es),t(es,hl),t(x,gl),t(x,as),t(as,_l),t(x,vl),l(e,yr,s),h(ua,e,s),l(e,Er,s),l(e,J,s),t(J,ve),t(ve,ts),h(fa,ts,null),t(J,$l),t(J,ss),t(ss,bl),l(e,kr,s),l(e,st,s),t(st,jl),l(e,qr,s),h(ha,e,s),l(e,Ar,s),l(e,$e,s),t($e,wl),t($e,ga),t(ga,rs),t(rs,yl),t($e,El),l(e,Pr,s),h(_a,e,s),l(e,Tr,s),l(e,rt,s),l(e,zr,s),l(e,X,s),t(X,be),t(be,ns),h(va,ns,null),t(X,kl),t(X,os),t(os,ql),l(e,Cr,s),h($a,e,s),l(e,Dr,s),l(e,je,s),t(je,Al),t(je,ls),t(ls,Pl),t(je,Tl),l(e,xr,s),l(e,nt,s),t(nt,zl),l(e,Sr,s),h(ba,e,s),l(e,Fr,s),l(e,we,s),t(we,Cl),t(we,is),t(is,Dl),t(we,xl),l(e,Or,s),l(e,H,s),t(H,ja),t(ja,wa),t(wa,Sl),t(wa,ps),t(ps,Fl),t(wa,Ol),t(ja,Nl),h(ya,ja,null),t(H,Ll),t(H,Ea),t(Ea,O),t(O,Il),t(O,cs),t(cs,Ml),t(O,Hl),t(O,ds),t(ds,Rl),t(O,Bl),t(O,ms),t(ms,Kl),t(O,Ul),t(Ea,Wl),h(ka,Ea,null),t(H,Gl),t(H,qa),t(qa,us),t(us,Yl),t(qa,Vl),h(Aa,qa,null),l(e,Nr,s),l(e,ot,s),t(ot,Jl),l(e,Lr,s),h(Pa,e,s),l(e,Ir,s),l(e,Z,s),t(Z,ye),t(ye,fs),h(Ta,fs,null),t(Z,Xl),t(Z,hs),t(hs,Zl),l(e,Mr,s),l(e,Ee,s),t(Ee,Ql),t(Ee,gs),t(gs,ei),t(Ee,ai),l(e,Hr,s),h(za,e,s),l(e,Rr,s),l(e,lt,s),t(lt,ti),l(e,Br,s),h(Ca,e,s),l(e,Kr,s),l(e,Q,s),t(Q,ke),t(ke,_s),h(Da,_s,null),t(Q,si),t(Q,vs),t(vs,ri),l(e,Ur,s),l(e,qe,s),t(qe,ni),t(qe,xa),t(xa,$s),t($s,oi),t(qe,li),l(e,Wr,s),h(Sa,e,s),l(e,Gr,s),l(e,Fa,s),t(Fa,ii),t(Fa,bs),t(bs,pi),l(e,Yr,s),h(Oa,e,s),l(e,Vr,s),l(e,Ae,s),t(Ae,ci),t(Ae,js),t(js,di),t(Ae,mi),l(e,Jr,s),h(Na,e,s),l(e,Xr,s),h(Pe,e,s),l(e,Zr,s),l(e,it,s),t(it,ui),l(e,Qr,s),l(e,ee,s),t(ee,Te),t(Te,ws),h(La,ws,null),t(ee,fi),t(ee,ys),t(ys,hi),l(e,en,s),l(e,ze,s),t(ze,gi),t(ze,Ia),t(Ia,_i),t(ze,vi),l(e,an,s),h(Ma,e,s),l(e,tn,s),l(e,ae,s),t(ae,Ce),t(Ce,Es),h(Ha,Es,null),t(ae,$i),t(ae,ks),t(ks,bi),l(e,sn,s),l(e,R,s),t(R,ji),t(R,qs),t(qs,wi),t(R,yi),t(R,Ra),t(Ra,As),t(As,Ei),t(R,ki),l(e,rn,s),h(Ba,e,s),l(e,nn,s),l(e,pt,s),l(e,on,s),l(e,te,s),t(te,De),t(De,Ps),h(Ka,Ps,null),t(te,qi),t(te,Ts),t(Ts,Ai),l(e,ln,s),l(e,ct,s),t(ct,Pi),l(e,pn,s),l(e,xe,s),t(xe,zs),t(zs,dt),t(dt,Ua),t(Ua,Ti),t(dt,zi),t(xe,Ci),t(xe,Cs),t(Cs,mt),t(mt,ut),t(ut,Di),t(mt,xi),cn=!0},p(e,[s]){const Wa={};s&2&&(Wa.$$scope={dirty:s,ctx:e}),pe.$set(Wa);const Ds={};s&2&&(Ds.$$scope={dirty:s,ctx:e}),_e.$set(Ds);const xs={};s&2&&(xs.$$scope={dirty:s,ctx:e}),Pe.$set(xs)},i(e){cn||(g(y.$$.fragment,e),g(C.$$.fragment,e),g(Le.$$.fragment,e),g(Ie.$$.fragment,e),g(He.$$.fragment,e),g(Be.$$.fragment,e),g(Ke.$$.fragment,e),g(Ue.$$.fragment,e),g(We.$$.fragment,e),g(Ye.$$.fragment,e),g(pe.$$.fragment,e),g(Ve.$$.fragment,e),g(Xe.$$.fragment,e),g(Ze.$$.fragment,e),g(aa.$$.fragment,e),g(ta.$$.fragment,e),g(sa.$$.fragment,e),g(ra.$$.fragment,e),g(na.$$.fragment,e),g(la.$$.fragment,e),g(ia.$$.fragment,e),g(pa.$$.fragment,e),g(ca.$$.fragment,e),g(da.$$.fragment,e),g(_e.$$.fragment,e),g(ua.$$.fragment,e),g(fa.$$.fragment,e),g(ha.$$.fragment,e),g(_a.$$.fragment,e),g(va.$$.fragment,e),g($a.$$.fragment,e),g(ba.$$.fragment,e),g(ya.$$.fragment,e),g(ka.$$.fragment,e),g(Aa.$$.fragment,e),g(Pa.$$.fragment,e),g(Ta.$$.fragment,e),g(za.$$.fragment,e),g(Ca.$$.fragment,e),g(Da.$$.fragment,e),g(Sa.$$.fragment,e),g(Oa.$$.fragment,e),g(Na.$$.fragment,e),g(Pe.$$.fragment,e),g(La.$$.fragment,e),g(Ma.$$.fragment,e),g(Ha.$$.fragment,e),g(Ba.$$.fragment,e),g(Ka.$$.fragment,e),cn=!0)},o(e){_(y.$$.fragment,e),_(C.$$.fragment,e),_(Le.$$.fragment,e),_(Ie.$$.fragment,e),_(He.$$.fragment,e),_(Be.$$.fragment,e),_(Ke.$$.fragment,e),_(Ue.$$.fragment,e),_(We.$$.fragment,e),_(Ye.$$.fragment,e),_(pe.$$.fragment,e),_(Ve.$$.fragment,e),_(Xe.$$.fragment,e),_(Ze.$$.fragment,e),_(aa.$$.fragment,e),_(ta.$$.fragment,e),_(sa.$$.fragment,e),_(ra.$$.fragment,e),_(na.$$.fragment,e),_(la.$$.fragment,e),_(ia.$$.fragment,e),_(pa.$$.fragment,e),_(ca.$$.fragment,e),_(da.$$.fragment,e),_(_e.$$.fragment,e),_(ua.$$.fragment,e),_(fa.$$.fragment,e),_(ha.$$.fragment,e),_(_a.$$.fragment,e),_(va.$$.fragment,e),_($a.$$.fragment,e),_(ba.$$.fragment,e),_(ya.$$.fragment,e),_(ka.$$.fragment,e),_(Aa.$$.fragment,e),_(Pa.$$.fragment,e),_(Ta.$$.fragment,e),_(za.$$.fragment,e),_(Ca.$$.fragment,e),_(Da.$$.fragment,e),_(Sa.$$.fragment,e),_(Oa.$$.fragment,e),_(Na.$$.fragment,e),_(Pe.$$.fragment,e),_(La.$$.fragment,e),_(Ma.$$.fragment,e),_(Ha.$$.fragment,e),_(Ba.$$.fragment,e),_(Ka.$$.fragment,e),cn=!1},d(e){a($),e&&a(E),e&&a(b),v(y),e&&a(q),v(C,e),e&&a(Ne),e&&a(Ga),e&&a(Ss),e&&a(N),e&&a(Fs),e&&a(Va),e&&a(Os),e&&a(B),v(Le),e&&a(Ns),v(Ie,e),e&&a(Ls),e&&a(Ja),e&&a(Is),e&&a(ne),e&&a(Ms),v(He,e),e&&a(Hs),e&&a(oe),e&&a(Rs),v(Be,e),e&&a(Bs),e&&a(Xa),e&&a(Ks),v(Ke,e),e&&a(Us),e&&a(Za),e&&a(Ws),e&&a(K),v(Ue),e&&a(Gs),v(We,e),e&&a(Ys),e&&a(L),e&&a(Vs),e&&a(ie),e&&a(Js),v(Ye,e),e&&a(Xs),v(pe,e),e&&a(Zs),e&&a(U),v(Ve),e&&a(Qs),e&&a(I),e&&a(er),e&&a(et),e&&a(ar),v(Xe,e),e&&a(tr),e&&a(W),v(Ze),e&&a(sr),e&&a(A),e&&a(rr),v(aa,e),e&&a(nr),e&&a(D),e&&a(or),v(ta,e),e&&a(lr),e&&a(me),e&&a(ir),v(sa,e),e&&a(pr),e&&a(G),v(ra),e&&a(cr),e&&a(fe),e&&a(dr),v(na,e),e&&a(mr),e&&a(oa),e&&a(ur),v(la,e),e&&a(fr),e&&a(at),e&&a(hr),e&&a(Y),v(ia),e&&a(gr),v(pa,e),e&&a(_r),e&&a(tt),e&&a(vr),e&&a(V),v(ca),e&&a($r),e&&a(M),e&&a(br),v(da,e),e&&a(jr),v(_e,e),e&&a(wr),e&&a(x),e&&a(yr),v(ua,e),e&&a(Er),e&&a(J),v(fa),e&&a(kr),e&&a(st),e&&a(qr),v(ha,e),e&&a(Ar),e&&a($e),e&&a(Pr),v(_a,e),e&&a(Tr),e&&a(rt),e&&a(zr),e&&a(X),v(va),e&&a(Cr),v($a,e),e&&a(Dr),e&&a(je),e&&a(xr),e&&a(nt),e&&a(Sr),v(ba,e),e&&a(Fr),e&&a(we),e&&a(Or),e&&a(H),v(ya),v(ka),v(Aa),e&&a(Nr),e&&a(ot),e&&a(Lr),v(Pa,e),e&&a(Ir),e&&a(Z),v(Ta),e&&a(Mr),e&&a(Ee),e&&a(Hr),v(za,e),e&&a(Rr),e&&a(lt),e&&a(Br),v(Ca,e),e&&a(Kr),e&&a(Q),v(Da),e&&a(Ur),e&&a(qe),e&&a(Wr),v(Sa,e),e&&a(Gr),e&&a(Fa),e&&a(Yr),v(Oa,e),e&&a(Vr),e&&a(Ae),e&&a(Jr),v(Na,e),e&&a(Xr),v(Pe,e),e&&a(Zr),e&&a(it),e&&a(Qr),e&&a(ee),v(La),e&&a(en),e&&a(ze),e&&a(an),v(Ma,e),e&&a(tn),e&&a(ae),v(Ha),e&&a(sn),e&&a(R),e&&a(rn),v(Ba,e),e&&a(nn),e&&a(pt),e&&a(on),e&&a(te),v(Ka),e&&a(ln),e&&a(ct),e&&a(pn),e&&a(xe)}}}const Yc={local:"finetuning-a-un-modelo-preentrenado",sections:[{local:"prepara-un-dataset",title:"Prepara un dataset"},{local:"finetuning-con-trainer",sections:[{local:"hiperparmetros-de-entrenamiento",title:"Hiperpar\xE1metros de entrenamiento"},{local:"mtricas",title:"M\xE9tricas"},{local:"trainer",title:"Trainer"}],title:"Fine-tuning con `Trainer`"},{local:"finetuning-con-keras",sections:[{local:"convierte-el-dataset-al-formato-de-tensorflow",title:"Convierte el dataset al formato de TensorFlow"},{local:"compila-y-ajusta",title:"Compila y ajusta"}],title:"Fine-tuning con Keras"},{local:"finetune-en-pytorch-nativo",sections:[{local:"dataloader",title:"DataLoader"},{local:"optimiza-y-progrma-el-learning-rate",title:"Optimiza y progrma el learning rate"},{local:"ciclo-de-entrenamiento",title:"Ciclo de entrenamiento"},{local:"mtricas",title:"M\xE9tricas"}],title:"Fine-tune en PyTorch nativo"},{local:"recursos-adicionales",title:"Recursos adicionales"}],title:"Fine-tuning a un modelo pre-entrenado"};function Vc(se){return Rc(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ad extends Lc{constructor($){super();Ic(this,$,Vc,Gc,Mc,{})}}export{ad as default,Yc as metadata};
