import{S as Oi,i as Ai,s as Ci,e as s,k as i,w as b,t as o,M as Li,c as r,d as t,m as c,a as n,x as v,h as l,b as d,F as e,g as m,y as _,L as Ii,q as w,o as $,B as y}from"../../chunks/vendor-4833417e.js";import{D as j}from"../../chunks/Docstring-4f315ed9.js";import{C as ka}from"../../chunks/CodeBlock-6a3d1b46.js";import{I as st}from"../../chunks/IconCopyLink-4b81c553.js";import"../../chunks/CopyButton-dacfbfaf.js";function Ui(vs){let O,Ve,P,T,rt,ne,_s,nt,ws,Ta,Y,$s,Me,ys,Es,xa,Re,Ds,Oa,L,W,ot,oe,js,lt,Ps,Aa,I,le,ks,it,Ts,Ca,U,ie,xs,ct,Os,La,z,ce,As,D,Cs,pt,Ls,Is,ht,Us,zs,dt,Ss,Hs,ut,Ns,Gs,Ia,S,pe,Vs,ft,Ms,Ua,H,J,mt,he,Rs,gt,Fs,za,N,de,qs,bt,Bs,Sa,G,Q,vt,ue,Ks,_t,Ys,Ha,u,fe,Ws,wt,Js,Qs,$t,Xs,Zs,yt,Et,er,tr,Dt,ar,sr,V,Fe,rr,jt,nr,or,qe,lr,Pt,ir,cr,Be,pr,kt,hr,dr,Tt,ur,fr,M,Ke,mr,xt,gr,br,Ye,vr,Ot,_r,wr,We,$r,At,yr,Er,Ct,Dr,jr,Lt,It,Pr,kr,Ut,Tr,xr,zt,St,Or,Ar,Ht,Cr,Lr,X,me,Ir,ge,Ur,Nt,zr,Sr,Hr,Z,be,Nr,Gt,Gr,Na,R,ee,Vt,ve,Vr,Mt,Mr,Ga,E,_e,Rr,we,Fr,Rt,qr,Br,Kr,$e,Yr,Ft,Wr,Jr,Qr,A,ye,Xr,qt,Zr,en,Ee,tn,Bt,an,sn,rn,te,De,nn,je,on,Kt,ln,cn,pn,ae,Pe,hn,ke,dn,Yt,un,fn,Va,F,se,Wt,Te,mn,Jt,gn,Ma,p,xe,bn,q,vn,Qt,_n,wn,Xt,$n,yn,En,Zt,Dn,jn,Oe,ea,Pn,kn,ta,Tn,xn,aa,On,An,sa,Cn,Ln,Ae,In,x,Un,ra,zn,Sn,na,Hn,Nn,oa,Gn,Vn,Mn,Ce,Le,Rn,la,Fn,qn,Bn,ia,Kn,Yn,Ie,Wn,ca,Jn,Qn,Xn,Ue,Zn,B,eo,pa,to,ao,ha,so,ro,no,da,oo,lo,ze,io,ua,co,po,ho,fa,uo,fo,Se,mo,ma,go,bo,ga,vo,_o,ba,wo,$o,He,yo,va,Eo,Do,jo,Ne,Po,_a,ko,To,wa,xo,Oo,$a,Ao,Co,ya,Lo,Io,Ge,Uo,Ea,zo,So,Je,Da,Ho,No,Go,K,Vo,ja,Mo,Ro,Pa,Fo,qo,Ra;return ne=new st({}),oe=new st({}),le=new j({props:{name:"class transformers.EvalPrediction",anchor:"transformers.EvalPrediction",parameters:[{name:"predictions",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"},{name:"label_ids",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_utils.py#L67",parametersDescription:[{anchor:"transformers.EvalPrediction.predictions",description:"<strong>predictions</strong> (<code>np.ndarray</code>) &#x2014; Predictions of the model.",name:"predictions"},{anchor:"transformers.EvalPrediction.label_ids",description:"<strong>label_ids</strong> (<code>np.ndarray</code>) &#x2014; Targets to be matched.",name:"label_ids"}]}}),ie=new j({props:{name:"class transformers.IntervalStrategy",anchor:"transformers.IntervalStrategy",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_utils.py#L115"}}),ce=new j({props:{name:"transformers.set_seed",anchor:"transformers.set_seed",parameters:[{name:"seed",val:": int"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_utils.py#L50",parametersDescription:[{anchor:"transformers.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"}]}}),pe=new j({props:{name:"transformers.torch_distributed_zero_first",anchor:"transformers.torch_distributed_zero_first",parameters:[{name:"local_rank",val:": int"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_pt_utils.py#L212",parametersDescription:[{anchor:"transformers.torch_distributed_zero_first.local_rank",description:"<strong>local_rank</strong> (<code>int</code>) &#x2014; The rank of the local process.",name:"local_rank"}]}}),he=new st({}),de=new j({props:{name:"class transformers.trainer_callback.CallbackHandler",anchor:"transformers.trainer_callback.CallbackHandler",parameters:[{name:"callbacks",val:""},{name:"model",val:""},{name:"tokenizer",val:""},{name:"optimizer",val:""},{name:"lr_scheduler",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_callback.py#L284"}}),ue=new st({}),fe=new j({props:{name:"class transformers.trainer_pt_utils.DistributedTensorGatherer",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer",parameters:[{name:"world_size",val:""},{name:"num_samples",val:""},{name:"make_multiple_of",val:" = None"},{name:"padding_index",val:" = -100"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_pt_utils.py#L338",parametersDescription:[{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.world_size",description:`<strong>world_size</strong> (<code>int</code>) &#x2014;
The number of processes used in the distributed training.`,name:"world_size"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.num_samples",description:`<strong>num_samples</strong> (<code>int</code>) &#x2014;
The number of samples in our dataset.`,name:"num_samples"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.make_multiple_of",description:`<strong>make_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If passed, the class assumes the datasets passed to each process are made to be a multiple of this argument
(by adding samples).`,name:"make_multiple_of"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.padding_index",description:`<strong>padding_index</strong> (<code>int</code>, <em>optional</em>, defaults to -100) &#x2014;
The padding index to use if the arrays don&#x2019;t all have the same sequence length.`,name:"padding_index"}]}}),me=new j({props:{name:"add_arrays",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.add_arrays",parameters:[{name:"arrays",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_pt_utils.py#L399"}}),be=new j({props:{name:"finalize",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.finalize",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/trainer_pt_utils.py#L435"}}),ve=new st({}),_e=new j({props:{name:"class transformers.HfArgumentParser",anchor:"transformers.HfArgumentParser",parameters:[{name:"dataclass_types",val:": typing.Union[DataClassType, typing.Iterable[DataClassType]]"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/hf_argparser.py#L44"}}),ye=new j({props:{name:"parse_args_into_dataclasses",anchor:"transformers.HfArgumentParser.parse_args_into_dataclasses",parameters:[{name:"args",val:" = None"},{name:"return_remaining_strings",val:" = False"},{name:"look_for_args_file",val:" = True"},{name:"args_filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/hf_argparser.py#L161",returnDescription:`
<ul>
<li>the dataclass instances in the same order as they were passed to the initializer.abspath</li>
<li>if applicable, an additional namespace for more (non-dataclass backed) arguments added to the parser
after initialization.</li>
<li>The potential list of remaining argument strings. (same as argparse.ArgumentParser.parse_known_args)</li>
</ul>
`,returnType:`
<p>Tuple consisting of</p>
`}}),De=new j({props:{name:"parse_dict",anchor:"transformers.HfArgumentParser.parse_dict",parameters:[{name:"args",val:": dict"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/hf_argparser.py#L234"}}),Pe=new j({props:{name:"parse_json_file",anchor:"transformers.HfArgumentParser.parse_json_file",parameters:[{name:"json_file",val:": str"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/hf_argparser.py#L220"}}),Te=new st({}),xe=new j({props:{name:"class transformers.debug_utils.DebugUnderflowOverflow",anchor:"transformers.debug_utils.DebugUnderflowOverflow",parameters:[{name:"model",val:""},{name:"max_frames_to_save",val:" = 21"},{name:"trace_batch_nums",val:" = []"},{name:"abort_after_batch_num",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_16111/src/transformers/debug_utils.py#L28",parametersDescription:[{anchor:"transformers.debug_utils.DebugUnderflowOverflow.model",description:`<strong>model</strong> (<code>nn.Module</code>) &#x2014;
The model to debug.`,name:"model"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.max_frames_to_save",description:`<strong>max_frames_to_save</strong> (<code>int</code>, <em>optional</em>, defaults to 21) &#x2014;
How many frames back to record`,name:"max_frames_to_save"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.trace_batch_nums(List[int],",description:`<strong>trace_batch_nums(<code>List[int]</code>,</strong> <em>optional</em>, defaults to <code>[]</code>) &#x2014;
Which batch numbers to trace (turns detection off)`,name:"trace_batch_nums(List[int],"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.abort_after_batch_num",description:"<strong>abort_after_batch_num</strong>  (`int&#x201C;, <em>optional</em>) &#x2014;\nWhether to abort after a certain batch number has finished",name:"abort_after_batch_num"}]}}),Ae=new ka({props:{code:"debug_overflow = DebugUnderflowOverflow(model)",highlighted:"debug_overflow = DebugUnderflowOverflow(model)"}}),Ue=new ka({props:{code:`Detected inf/nan during batch_number=0
Last 21 forward frames:
abs min  abs max  metadata
[...]
                  encoder.block.2.layer.1.DenseReluDense.wi_0 Linear
2.17e-07 4.50e+00 weight
1.79e-06 4.65e+00 input[0]
2.68e-06 3.70e+01 output
                  encoder.block.2.layer.1.DenseReluDense.wi_1 Linear
8.08e-07 2.66e+01 weight
1.79e-06 4.65e+00 input[0]
1.27e-04 2.37e+02 output
                  encoder.block.2.layer.1.DenseReluDense.wo Linear
1.01e-06 6.44e+00 weight
0.00e+00 9.74e+03 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.DenseReluDense T5DenseGatedGeluDense
1.79e-06 4.65e+00 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.dropout Dropout
3.18e-04 6.27e+04 input[0]
0.00e+00      inf output`,highlighted:`<span class="hljs-attribute">Detected</span> inf/nan during batch_number=<span class="hljs-number">0</span>
<span class="hljs-attribute">Last</span> <span class="hljs-number">21</span> forward frames:
<span class="hljs-attribute">abs</span> min  abs max  metadata<span class="hljs-meta">
[...]</span>
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wi_0 Linear
<span class="hljs-attribute">2</span>.<span class="hljs-number">17</span>e-<span class="hljs-number">07</span> <span class="hljs-number">4</span>.<span class="hljs-number">50</span>e+<span class="hljs-number">00</span> weight
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">2</span>.<span class="hljs-number">68</span>e-<span class="hljs-number">06</span> <span class="hljs-number">3</span>.<span class="hljs-number">70</span>e+<span class="hljs-number">01</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wi_1 Linear
<span class="hljs-attribute">8</span>.<span class="hljs-number">08</span>e-<span class="hljs-number">07</span> <span class="hljs-number">2</span>.<span class="hljs-number">66</span>e+<span class="hljs-number">01</span> weight
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">1</span>.<span class="hljs-number">27</span>e-<span class="hljs-number">04</span> <span class="hljs-number">2</span>.<span class="hljs-number">37</span>e+<span class="hljs-number">02</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wo Linear
<span class="hljs-attribute">1</span>.<span class="hljs-number">01</span>e-<span class="hljs-number">06</span> <span class="hljs-number">6</span>.<span class="hljs-number">44</span>e+<span class="hljs-number">00</span> weight
<span class="hljs-attribute">0</span>.<span class="hljs-number">00</span>e+<span class="hljs-number">00</span> <span class="hljs-number">9</span>.<span class="hljs-number">74</span>e+<span class="hljs-number">03</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense T5DenseGatedGeluDense
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.dropout Dropout
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">0</span>.<span class="hljs-number">00</span>e+<span class="hljs-number">00</span>      inf output`}}),Se=new ka({props:{code:"debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=100)",highlighted:'debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=<span class="hljs-number">100</span>)'}}),Ne=new ka({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3])",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])'}}),Ge=new ka({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3], abort_after_batch_num=3)",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>], abort_after_batch_num=<span class="hljs-number">3</span>)'}}),{c(){O=s("meta"),Ve=i(),P=s("h1"),T=s("a"),rt=s("span"),b(ne.$$.fragment),_s=i(),nt=s("span"),ws=o("Utilities for Trainer"),Ta=i(),Y=s("p"),$s=o("This page lists all the utility functions used by "),Me=s("a"),ys=o("Trainer"),Es=o("."),xa=i(),Re=s("p"),Ds=o("Most of those are only useful if you are studying the code of the Trainer in the library."),Oa=i(),L=s("h2"),W=s("a"),ot=s("span"),b(oe.$$.fragment),js=i(),lt=s("span"),Ps=o("Utilities"),Aa=i(),I=s("div"),b(le.$$.fragment),ks=i(),it=s("p"),Ts=o("Evaluation output (always contains labels), to be used to compute metrics."),Ca=i(),U=s("div"),b(ie.$$.fragment),xs=i(),ct=s("p"),Os=o("An enumeration."),La=i(),z=s("div"),b(ce.$$.fragment),As=i(),D=s("p"),Cs=o("Helper function for reproducible behavior to set the seed in "),pt=s("code"),Ls=o("random"),Is=o(", "),ht=s("code"),Us=o("numpy"),zs=o(", "),dt=s("code"),Ss=o("torch"),Hs=o(" and/or "),ut=s("code"),Ns=o("tf"),Gs=o(" (if installed)."),Ia=i(),S=s("div"),b(pe.$$.fragment),Vs=i(),ft=s("p"),Ms=o("Decorator to make all processes in distributed training wait for each local_master to do something."),Ua=i(),H=s("h2"),J=s("a"),mt=s("span"),b(he.$$.fragment),Rs=i(),gt=s("span"),Fs=o("Callbacks internals"),za=i(),N=s("div"),b(de.$$.fragment),qs=i(),bt=s("p"),Bs=o("Internal class that just calls the list of callbacks in order."),Sa=i(),G=s("h2"),Q=s("a"),vt=s("span"),b(ue.$$.fragment),Ks=i(),_t=s("span"),Ys=o("Distributed Evaluation"),Ha=i(),u=s("div"),b(fe.$$.fragment),Ws=i(),wt=s("p"),Js=o("A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),Qs=i(),$t=s("p"),Xs=o(`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),Zs=i(),yt=s("p"),Et=s("code"),er=o("[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),tr=i(),Dt=s("p"),ar=o(`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),sr=i(),V=s("ul"),Fe=s("li"),rr=o("P0: "),jt=s("code"),nr=o("[0, 1, 2, 3, 4, 5]"),or=i(),qe=s("li"),lr=o("P1: "),Pt=s("code"),ir=o("[6, 7, 8, 9, 10, 11]"),cr=i(),Be=s("li"),pr=o("P2: "),kt=s("code"),hr=o("[12, 13, 14, 15, 0, 1]"),dr=i(),Tt=s("p"),ur=o("The first batch treated on each process will be"),fr=i(),M=s("ul"),Ke=s("li"),mr=o("P0: "),xt=s("code"),gr=o("[0, 1]"),br=i(),Ye=s("li"),vr=o("P1: "),Ot=s("code"),_r=o("[6, 7]"),wr=i(),We=s("li"),$r=o("P2: "),At=s("code"),yr=o("[12, 13]"),Er=i(),Ct=s("p"),Dr=o(`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),jr=i(),Lt=s("p"),It=s("code"),Pr=o("[0, 1, 6, 7, 12, 13]"),kr=i(),Ut=s("p"),Tr=o(`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),xr=i(),zt=s("p"),St=s("code"),Or=o("[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),Ar=i(),Ht=s("p"),Cr=o("For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),Lr=i(),X=s("div"),b(me.$$.fragment),Ir=i(),ge=s("p"),Ur=o("Add "),Nt=s("code"),zr=o("arrays"),Sr=o(` to the internal storage, Will initialize the storage to the full size at the first arrays passed
so that if we\u2019re bound to get an OOM, it happens at the beginning.`),Hr=i(),Z=s("div"),b(be.$$.fragment),Nr=i(),Gt=s("p"),Gr=o(`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),Na=i(),R=s("h2"),ee=s("a"),Vt=s("span"),b(ve.$$.fragment),Vr=i(),Mt=s("span"),Mr=o("Distributed Evaluation"),Ga=i(),E=s("div"),b(_e.$$.fragment),Rr=i(),we=s("p"),Fr=o("This subclass of "),Rt=s("code"),qr=o("argparse.ArgumentParser"),Br=o(" uses type hints on dataclasses to generate arguments."),Kr=i(),$e=s("p"),Yr=o(`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),Ft=s("code"),Wr=o("_argument_group_name"),Jr=o(" attribute in the dataclass."),Qr=i(),A=s("div"),b(ye.$$.fragment),Xr=i(),qt=s("p"),Zr=o("Parse command-line args into instances of the specified dataclass types."),en=i(),Ee=s("p"),tn=o("This relies on argparse\u2019s "),Bt=s("code"),an=o("ArgumentParser.parse_known_args"),sn=o(`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),rn=i(),te=s("div"),b(De.$$.fragment),nn=i(),je=s("p"),on=o("Alternative helper method that does not use "),Kt=s("code"),ln=o("argparse"),cn=o(` at all, instead uses a dict and populating the dataclass
types.`),pn=i(),ae=s("div"),b(Pe.$$.fragment),hn=i(),ke=s("p"),dn=o("Alternative helper method that does not use "),Yt=s("code"),un=o("argparse"),fn=o(` at all, instead loading a json file and populating the
dataclass types.`),Va=i(),F=s("h2"),se=s("a"),Wt=s("span"),b(Te.$$.fragment),mn=i(),Jt=s("span"),gn=o("Debug Utilities"),Ma=i(),p=s("div"),b(xe.$$.fragment),bn=i(),q=s("p"),vn=o(`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),Qt=s("code"),_n=o("nan"),wn=o(" or "),Xt=s("code"),$n=o("inf"),yn=o(" weight and activation elements."),En=i(),Zt=s("p"),Dn=o("There are 2 working modes:"),jn=i(),Oe=s("ol"),ea=s("li"),Pn=o("Underflow/overflow detection (default)"),kn=i(),ta=s("li"),Tn=o("Specific batch absolute min/max tracing without detection"),xn=i(),aa=s("p"),On=o("Mode 1: Underflow/overflow detection"),An=i(),sa=s("p"),Cn=o("To activate the underflow/overflow detection, initialize the object with the model :"),Ln=i(),b(Ae.$$.fragment),In=i(),x=s("p"),Un=o("then run the training as normal and if "),ra=s("code"),zn=o("nan"),Sn=o(" or "),na=s("code"),Hn=o("inf"),Nn=o(` gets detected in at least one of the weight, input or output
elements this module will throw an exception and will print `),oa=s("code"),Gn=o("max_frames_to_save"),Vn=o(` frames that lead to this event,
each frame reporting`),Mn=i(),Ce=s("ol"),Le=s("li"),Rn=o("the fully qualified module name plus the class name whose "),la=s("code"),Fn=o("forward"),qn=o(" was run"),Bn=i(),ia=s("li"),Kn=o("the absolute min and max value of all elements for each module weights, and the inputs and output"),Yn=i(),Ie=s("p"),Wn=o("For example, here is the header and the last few frames in detection report for "),ca=s("code"),Jn=o("google/mt5-small"),Qn=o(` run in fp16
mixed precision :`),Xn=i(),b(Ue.$$.fragment),Zn=i(),B=s("p"),eo=o("You can see here, that "),pa=s("code"),to=o("T5DenseGatedGeluDense.forward"),ao=o(` resulted in output activations, whose absolute max value was
around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),ha=s("code"),so=o("Dropout"),ro=o(` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),no=i(),da=s("p"),oo=o(`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),lo=i(),ze=s("p"),io=o("The tracking is done in a forward hook, which gets invoked immediately after "),ua=s("code"),co=o("forward"),po=o(" has completed."),ho=i(),fa=s("p"),uo=o("By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),fo=i(),b(Se.$$.fragment),mo=i(),ma=s("p"),go=o(`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that
may take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in
the next section.`),bo=i(),ga=s("p"),vo=o("Mode 2. Specific batch absolute min/max tracing without detection"),_o=i(),ba=s("p"),wo=o("The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),$o=i(),He=s("p"),yo=o("Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),va=s("code"),Eo=o("forward"),Do=o(` call of a
given batch, and only do that for batches 1 and 3. Then you instantiate this class as :`),jo=i(),b(Ne.$$.fragment),Po=i(),_a=s("p"),ko=o("And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),To=i(),wa=s("p"),xo=o(`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),Oo=i(),$a=s("p"),Ao=o("Early stopping:"),Co=i(),ya=s("p"),Lo=o("You can also specify the batch number after which to stop the training, with :"),Io=i(),b(Ge.$$.fragment),Uo=i(),Ea=s("p"),zo=o("This feature is mainly useful in the tracing mode, but you can use it for any mode."),So=i(),Je=s("p"),Da=s("strong"),Ho=o("Performance"),No=o(":"),Go=i(),K=s("p"),Vo=o("As this module measures absolute "),ja=s("code"),Mo=o("min"),Ro=o("/`"),Pa=s("code"),Fo=o("max"),qo=o(` of each weight of the model on every forward it\u2019ll slow the training
down. Therefore remember to turn it off once the debugging needs have been met.`),this.h()},l(a){const f=Li('[data-svelte="svelte-1phssyn"]',document.head);O=r(f,"META",{name:!0,content:!0}),f.forEach(t),Ve=c(a),P=r(a,"H1",{class:!0});var Fa=n(P);T=r(Fa,"A",{id:!0,class:!0,href:!0});var Zo=n(T);rt=r(Zo,"SPAN",{});var el=n(rt);v(ne.$$.fragment,el),el.forEach(t),Zo.forEach(t),_s=c(Fa),nt=r(Fa,"SPAN",{});var tl=n(nt);ws=l(tl,"Utilities for Trainer"),tl.forEach(t),Fa.forEach(t),Ta=c(a),Y=r(a,"P",{});var qa=n(Y);$s=l(qa,"This page lists all the utility functions used by "),Me=r(qa,"A",{href:!0});var al=n(Me);ys=l(al,"Trainer"),al.forEach(t),Es=l(qa,"."),qa.forEach(t),xa=c(a),Re=r(a,"P",{});var sl=n(Re);Ds=l(sl,"Most of those are only useful if you are studying the code of the Trainer in the library."),sl.forEach(t),Oa=c(a),L=r(a,"H2",{class:!0});var Ba=n(L);W=r(Ba,"A",{id:!0,class:!0,href:!0});var rl=n(W);ot=r(rl,"SPAN",{});var nl=n(ot);v(oe.$$.fragment,nl),nl.forEach(t),rl.forEach(t),js=c(Ba),lt=r(Ba,"SPAN",{});var ol=n(lt);Ps=l(ol,"Utilities"),ol.forEach(t),Ba.forEach(t),Aa=c(a),I=r(a,"DIV",{class:!0});var Ka=n(I);v(le.$$.fragment,Ka),ks=c(Ka),it=r(Ka,"P",{});var ll=n(it);Ts=l(ll,"Evaluation output (always contains labels), to be used to compute metrics."),ll.forEach(t),Ka.forEach(t),Ca=c(a),U=r(a,"DIV",{class:!0});var Ya=n(U);v(ie.$$.fragment,Ya),xs=c(Ya),ct=r(Ya,"P",{});var il=n(ct);Os=l(il,"An enumeration."),il.forEach(t),Ya.forEach(t),La=c(a),z=r(a,"DIV",{class:!0});var Wa=n(z);v(ce.$$.fragment,Wa),As=c(Wa),D=r(Wa,"P",{});var C=n(D);Cs=l(C,"Helper function for reproducible behavior to set the seed in "),pt=r(C,"CODE",{});var cl=n(pt);Ls=l(cl,"random"),cl.forEach(t),Is=l(C,", "),ht=r(C,"CODE",{});var pl=n(ht);Us=l(pl,"numpy"),pl.forEach(t),zs=l(C,", "),dt=r(C,"CODE",{});var hl=n(dt);Ss=l(hl,"torch"),hl.forEach(t),Hs=l(C," and/or "),ut=r(C,"CODE",{});var dl=n(ut);Ns=l(dl,"tf"),dl.forEach(t),Gs=l(C," (if installed)."),C.forEach(t),Wa.forEach(t),Ia=c(a),S=r(a,"DIV",{class:!0});var Ja=n(S);v(pe.$$.fragment,Ja),Vs=c(Ja),ft=r(Ja,"P",{});var ul=n(ft);Ms=l(ul,"Decorator to make all processes in distributed training wait for each local_master to do something."),ul.forEach(t),Ja.forEach(t),Ua=c(a),H=r(a,"H2",{class:!0});var Qa=n(H);J=r(Qa,"A",{id:!0,class:!0,href:!0});var fl=n(J);mt=r(fl,"SPAN",{});var ml=n(mt);v(he.$$.fragment,ml),ml.forEach(t),fl.forEach(t),Rs=c(Qa),gt=r(Qa,"SPAN",{});var gl=n(gt);Fs=l(gl,"Callbacks internals"),gl.forEach(t),Qa.forEach(t),za=c(a),N=r(a,"DIV",{class:!0});var Xa=n(N);v(de.$$.fragment,Xa),qs=c(Xa),bt=r(Xa,"P",{});var bl=n(bt);Bs=l(bl,"Internal class that just calls the list of callbacks in order."),bl.forEach(t),Xa.forEach(t),Sa=c(a),G=r(a,"H2",{class:!0});var Za=n(G);Q=r(Za,"A",{id:!0,class:!0,href:!0});var vl=n(Q);vt=r(vl,"SPAN",{});var _l=n(vt);v(ue.$$.fragment,_l),_l.forEach(t),vl.forEach(t),Ks=c(Za),_t=r(Za,"SPAN",{});var wl=n(_t);Ys=l(wl,"Distributed Evaluation"),wl.forEach(t),Za.forEach(t),Ha=c(a),u=r(a,"DIV",{class:!0});var g=n(u);v(fe.$$.fragment,g),Ws=c(g),wt=r(g,"P",{});var $l=n(wt);Js=l($l,"A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),$l.forEach(t),Qs=c(g),$t=r(g,"P",{});var yl=n($t);Xs=l(yl,`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),yl.forEach(t),Zs=c(g),yt=r(g,"P",{});var El=n(yt);Et=r(El,"CODE",{});var Dl=n(Et);er=l(Dl,"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),Dl.forEach(t),El.forEach(t),tr=c(g),Dt=r(g,"P",{});var jl=n(Dt);ar=l(jl,`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),jl.forEach(t),sr=c(g),V=r(g,"UL",{});var Qe=n(V);Fe=r(Qe,"LI",{});var Bo=n(Fe);rr=l(Bo,"P0: "),jt=r(Bo,"CODE",{});var Pl=n(jt);nr=l(Pl,"[0, 1, 2, 3, 4, 5]"),Pl.forEach(t),Bo.forEach(t),or=c(Qe),qe=r(Qe,"LI",{});var Ko=n(qe);lr=l(Ko,"P1: "),Pt=r(Ko,"CODE",{});var kl=n(Pt);ir=l(kl,"[6, 7, 8, 9, 10, 11]"),kl.forEach(t),Ko.forEach(t),cr=c(Qe),Be=r(Qe,"LI",{});var Yo=n(Be);pr=l(Yo,"P2: "),kt=r(Yo,"CODE",{});var Tl=n(kt);hr=l(Tl,"[12, 13, 14, 15, 0, 1]"),Tl.forEach(t),Yo.forEach(t),Qe.forEach(t),dr=c(g),Tt=r(g,"P",{});var xl=n(Tt);ur=l(xl,"The first batch treated on each process will be"),xl.forEach(t),fr=c(g),M=r(g,"UL",{});var Xe=n(M);Ke=r(Xe,"LI",{});var Wo=n(Ke);mr=l(Wo,"P0: "),xt=r(Wo,"CODE",{});var Ol=n(xt);gr=l(Ol,"[0, 1]"),Ol.forEach(t),Wo.forEach(t),br=c(Xe),Ye=r(Xe,"LI",{});var Jo=n(Ye);vr=l(Jo,"P1: "),Ot=r(Jo,"CODE",{});var Al=n(Ot);_r=l(Al,"[6, 7]"),Al.forEach(t),Jo.forEach(t),wr=c(Xe),We=r(Xe,"LI",{});var Qo=n(We);$r=l(Qo,"P2: "),At=r(Qo,"CODE",{});var Cl=n(At);yr=l(Cl,"[12, 13]"),Cl.forEach(t),Qo.forEach(t),Xe.forEach(t),Er=c(g),Ct=r(g,"P",{});var Ll=n(Ct);Dr=l(Ll,`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),Ll.forEach(t),jr=c(g),Lt=r(g,"P",{});var Il=n(Lt);It=r(Il,"CODE",{});var Ul=n(It);Pr=l(Ul,"[0, 1, 6, 7, 12, 13]"),Ul.forEach(t),Il.forEach(t),kr=c(g),Ut=r(g,"P",{});var zl=n(Ut);Tr=l(zl,`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),zl.forEach(t),xr=c(g),zt=r(g,"P",{});var Sl=n(zt);St=r(Sl,"CODE",{});var Hl=n(St);Or=l(Hl,"[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),Hl.forEach(t),Sl.forEach(t),Ar=c(g),Ht=r(g,"P",{});var Nl=n(Ht);Cr=l(Nl,"For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),Nl.forEach(t),Lr=c(g),X=r(g,"DIV",{class:!0});var es=n(X);v(me.$$.fragment,es),Ir=c(es),ge=r(es,"P",{});var ts=n(ge);Ur=l(ts,"Add "),Nt=r(ts,"CODE",{});var Gl=n(Nt);zr=l(Gl,"arrays"),Gl.forEach(t),Sr=l(ts,` to the internal storage, Will initialize the storage to the full size at the first arrays passed
so that if we\u2019re bound to get an OOM, it happens at the beginning.`),ts.forEach(t),es.forEach(t),Hr=c(g),Z=r(g,"DIV",{class:!0});var as=n(Z);v(be.$$.fragment,as),Nr=c(as),Gt=r(as,"P",{});var Vl=n(Gt);Gr=l(Vl,`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),Vl.forEach(t),as.forEach(t),g.forEach(t),Na=c(a),R=r(a,"H2",{class:!0});var ss=n(R);ee=r(ss,"A",{id:!0,class:!0,href:!0});var Ml=n(ee);Vt=r(Ml,"SPAN",{});var Rl=n(Vt);v(ve.$$.fragment,Rl),Rl.forEach(t),Ml.forEach(t),Vr=c(ss),Mt=r(ss,"SPAN",{});var Fl=n(Mt);Mr=l(Fl,"Distributed Evaluation"),Fl.forEach(t),ss.forEach(t),Ga=c(a),E=r(a,"DIV",{class:!0});var k=n(E);v(_e.$$.fragment,k),Rr=c(k),we=r(k,"P",{});var rs=n(we);Fr=l(rs,"This subclass of "),Rt=r(rs,"CODE",{});var ql=n(Rt);qr=l(ql,"argparse.ArgumentParser"),ql.forEach(t),Br=l(rs," uses type hints on dataclasses to generate arguments."),rs.forEach(t),Kr=c(k),$e=r(k,"P",{});var ns=n($e);Yr=l(ns,`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),Ft=r(ns,"CODE",{});var Bl=n(Ft);Wr=l(Bl,"_argument_group_name"),Bl.forEach(t),Jr=l(ns," attribute in the dataclass."),ns.forEach(t),Qr=c(k),A=r(k,"DIV",{class:!0});var Ze=n(A);v(ye.$$.fragment,Ze),Xr=c(Ze),qt=r(Ze,"P",{});var Kl=n(qt);Zr=l(Kl,"Parse command-line args into instances of the specified dataclass types."),Kl.forEach(t),en=c(Ze),Ee=r(Ze,"P",{});var os=n(Ee);tn=l(os,"This relies on argparse\u2019s "),Bt=r(os,"CODE",{});var Yl=n(Bt);an=l(Yl,"ArgumentParser.parse_known_args"),Yl.forEach(t),sn=l(os,`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),os.forEach(t),Ze.forEach(t),rn=c(k),te=r(k,"DIV",{class:!0});var ls=n(te);v(De.$$.fragment,ls),nn=c(ls),je=r(ls,"P",{});var is=n(je);on=l(is,"Alternative helper method that does not use "),Kt=r(is,"CODE",{});var Wl=n(Kt);ln=l(Wl,"argparse"),Wl.forEach(t),cn=l(is,` at all, instead uses a dict and populating the dataclass
types.`),is.forEach(t),ls.forEach(t),pn=c(k),ae=r(k,"DIV",{class:!0});var cs=n(ae);v(Pe.$$.fragment,cs),hn=c(cs),ke=r(cs,"P",{});var ps=n(ke);dn=l(ps,"Alternative helper method that does not use "),Yt=r(ps,"CODE",{});var Jl=n(Yt);un=l(Jl,"argparse"),Jl.forEach(t),fn=l(ps,` at all, instead loading a json file and populating the
dataclass types.`),ps.forEach(t),cs.forEach(t),k.forEach(t),Va=c(a),F=r(a,"H2",{class:!0});var hs=n(F);se=r(hs,"A",{id:!0,class:!0,href:!0});var Ql=n(se);Wt=r(Ql,"SPAN",{});var Xl=n(Wt);v(Te.$$.fragment,Xl),Xl.forEach(t),Ql.forEach(t),mn=c(hs),Jt=r(hs,"SPAN",{});var Zl=n(Jt);gn=l(Zl,"Debug Utilities"),Zl.forEach(t),hs.forEach(t),Ma=c(a),p=r(a,"DIV",{class:!0});var h=n(p);v(xe.$$.fragment,h),bn=c(h),q=r(h,"P",{});var et=n(q);vn=l(et,`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),Qt=r(et,"CODE",{});var ei=n(Qt);_n=l(ei,"nan"),ei.forEach(t),wn=l(et," or "),Xt=r(et,"CODE",{});var ti=n(Xt);$n=l(ti,"inf"),ti.forEach(t),yn=l(et," weight and activation elements."),et.forEach(t),En=c(h),Zt=r(h,"P",{});var ai=n(Zt);Dn=l(ai,"There are 2 working modes:"),ai.forEach(t),jn=c(h),Oe=r(h,"OL",{});var ds=n(Oe);ea=r(ds,"LI",{});var si=n(ea);Pn=l(si,"Underflow/overflow detection (default)"),si.forEach(t),kn=c(ds),ta=r(ds,"LI",{});var ri=n(ta);Tn=l(ri,"Specific batch absolute min/max tracing without detection"),ri.forEach(t),ds.forEach(t),xn=c(h),aa=r(h,"P",{});var ni=n(aa);On=l(ni,"Mode 1: Underflow/overflow detection"),ni.forEach(t),An=c(h),sa=r(h,"P",{});var oi=n(sa);Cn=l(oi,"To activate the underflow/overflow detection, initialize the object with the model :"),oi.forEach(t),Ln=c(h),v(Ae.$$.fragment,h),In=c(h),x=r(h,"P",{});var re=n(x);Un=l(re,"then run the training as normal and if "),ra=r(re,"CODE",{});var li=n(ra);zn=l(li,"nan"),li.forEach(t),Sn=l(re," or "),na=r(re,"CODE",{});var ii=n(na);Hn=l(ii,"inf"),ii.forEach(t),Nn=l(re,` gets detected in at least one of the weight, input or output
elements this module will throw an exception and will print `),oa=r(re,"CODE",{});var ci=n(oa);Gn=l(ci,"max_frames_to_save"),ci.forEach(t),Vn=l(re,` frames that lead to this event,
each frame reporting`),re.forEach(t),Mn=c(h),Ce=r(h,"OL",{});var us=n(Ce);Le=r(us,"LI",{});var fs=n(Le);Rn=l(fs,"the fully qualified module name plus the class name whose "),la=r(fs,"CODE",{});var pi=n(la);Fn=l(pi,"forward"),pi.forEach(t),qn=l(fs," was run"),fs.forEach(t),Bn=c(us),ia=r(us,"LI",{});var hi=n(ia);Kn=l(hi,"the absolute min and max value of all elements for each module weights, and the inputs and output"),hi.forEach(t),us.forEach(t),Yn=c(h),Ie=r(h,"P",{});var ms=n(Ie);Wn=l(ms,"For example, here is the header and the last few frames in detection report for "),ca=r(ms,"CODE",{});var di=n(ca);Jn=l(di,"google/mt5-small"),di.forEach(t),Qn=l(ms,` run in fp16
mixed precision :`),ms.forEach(t),Xn=c(h),v(Ue.$$.fragment,h),Zn=c(h),B=r(h,"P",{});var tt=n(B);eo=l(tt,"You can see here, that "),pa=r(tt,"CODE",{});var ui=n(pa);to=l(ui,"T5DenseGatedGeluDense.forward"),ui.forEach(t),ao=l(tt,` resulted in output activations, whose absolute max value was
around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),ha=r(tt,"CODE",{});var fi=n(ha);so=l(fi,"Dropout"),fi.forEach(t),ro=l(tt,` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),tt.forEach(t),no=c(h),da=r(h,"P",{});var mi=n(da);oo=l(mi,`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),mi.forEach(t),lo=c(h),ze=r(h,"P",{});var gs=n(ze);io=l(gs,"The tracking is done in a forward hook, which gets invoked immediately after "),ua=r(gs,"CODE",{});var gi=n(ua);co=l(gi,"forward"),gi.forEach(t),po=l(gs," has completed."),gs.forEach(t),ho=c(h),fa=r(h,"P",{});var bi=n(fa);uo=l(bi,"By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),bi.forEach(t),fo=c(h),v(Se.$$.fragment,h),mo=c(h),ma=r(h,"P",{});var vi=n(ma);go=l(vi,`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that
may take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in
the next section.`),vi.forEach(t),bo=c(h),ga=r(h,"P",{});var _i=n(ga);vo=l(_i,"Mode 2. Specific batch absolute min/max tracing without detection"),_i.forEach(t),_o=c(h),ba=r(h,"P",{});var wi=n(ba);wo=l(wi,"The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),wi.forEach(t),$o=c(h),He=r(h,"P",{});var bs=n(He);yo=l(bs,"Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),va=r(bs,"CODE",{});var $i=n(va);Eo=l($i,"forward"),$i.forEach(t),Do=l(bs,` call of a
given batch, and only do that for batches 1 and 3. Then you instantiate this class as :`),bs.forEach(t),jo=c(h),v(Ne.$$.fragment,h),Po=c(h),_a=r(h,"P",{});var yi=n(_a);ko=l(yi,"And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),yi.forEach(t),To=c(h),wa=r(h,"P",{});var Ei=n(wa);xo=l(Ei,`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),Ei.forEach(t),Oo=c(h),$a=r(h,"P",{});var Di=n($a);Ao=l(Di,"Early stopping:"),Di.forEach(t),Co=c(h),ya=r(h,"P",{});var ji=n(ya);Lo=l(ji,"You can also specify the batch number after which to stop the training, with :"),ji.forEach(t),Io=c(h),v(Ge.$$.fragment,h),Uo=c(h),Ea=r(h,"P",{});var Pi=n(Ea);zo=l(Pi,"This feature is mainly useful in the tracing mode, but you can use it for any mode."),Pi.forEach(t),So=c(h),Je=r(h,"P",{});var Xo=n(Je);Da=r(Xo,"STRONG",{});var ki=n(Da);Ho=l(ki,"Performance"),ki.forEach(t),No=l(Xo,":"),Xo.forEach(t),Go=c(h),K=r(h,"P",{});var at=n(K);Vo=l(at,"As this module measures absolute "),ja=r(at,"CODE",{});var Ti=n(ja);Mo=l(Ti,"min"),Ti.forEach(t),Ro=l(at,"/`"),Pa=r(at,"CODE",{});var xi=n(Pa);Fo=l(xi,"max"),xi.forEach(t),qo=l(at,` of each weight of the model on every forward it\u2019ll slow the training
down. Therefore remember to turn it off once the debugging needs have been met.`),at.forEach(t),h.forEach(t),this.h()},h(){d(O,"name","hf:doc:metadata"),d(O,"content",JSON.stringify(zi)),d(T,"id","utilities-for-trainer"),d(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(T,"href","#utilities-for-trainer"),d(P,"class","relative group"),d(Me,"href","/docs/transformers/pr_16111/en/main_classes/trainer#transformers.Trainer"),d(W,"id","transformers.EvalPrediction"),d(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W,"href","#transformers.EvalPrediction"),d(L,"class","relative group"),d(I,"class","docstring"),d(U,"class","docstring"),d(z,"class","docstring"),d(S,"class","docstring"),d(J,"id","transformers.trainer_callback.CallbackHandler"),d(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J,"href","#transformers.trainer_callback.CallbackHandler"),d(H,"class","relative group"),d(N,"class","docstring"),d(Q,"id","transformers.trainer_pt_utils.DistributedTensorGatherer"),d(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Q,"href","#transformers.trainer_pt_utils.DistributedTensorGatherer"),d(G,"class","relative group"),d(X,"class","docstring"),d(Z,"class","docstring"),d(u,"class","docstring"),d(ee,"id","transformers.HfArgumentParser"),d(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ee,"href","#transformers.HfArgumentParser"),d(R,"class","relative group"),d(A,"class","docstring"),d(te,"class","docstring"),d(ae,"class","docstring"),d(E,"class","docstring"),d(se,"id","transformers.debug_utils.DebugUnderflowOverflow"),d(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(se,"href","#transformers.debug_utils.DebugUnderflowOverflow"),d(F,"class","relative group"),d(p,"class","docstring")},m(a,f){e(document.head,O),m(a,Ve,f),m(a,P,f),e(P,T),e(T,rt),_(ne,rt,null),e(P,_s),e(P,nt),e(nt,ws),m(a,Ta,f),m(a,Y,f),e(Y,$s),e(Y,Me),e(Me,ys),e(Y,Es),m(a,xa,f),m(a,Re,f),e(Re,Ds),m(a,Oa,f),m(a,L,f),e(L,W),e(W,ot),_(oe,ot,null),e(L,js),e(L,lt),e(lt,Ps),m(a,Aa,f),m(a,I,f),_(le,I,null),e(I,ks),e(I,it),e(it,Ts),m(a,Ca,f),m(a,U,f),_(ie,U,null),e(U,xs),e(U,ct),e(ct,Os),m(a,La,f),m(a,z,f),_(ce,z,null),e(z,As),e(z,D),e(D,Cs),e(D,pt),e(pt,Ls),e(D,Is),e(D,ht),e(ht,Us),e(D,zs),e(D,dt),e(dt,Ss),e(D,Hs),e(D,ut),e(ut,Ns),e(D,Gs),m(a,Ia,f),m(a,S,f),_(pe,S,null),e(S,Vs),e(S,ft),e(ft,Ms),m(a,Ua,f),m(a,H,f),e(H,J),e(J,mt),_(he,mt,null),e(H,Rs),e(H,gt),e(gt,Fs),m(a,za,f),m(a,N,f),_(de,N,null),e(N,qs),e(N,bt),e(bt,Bs),m(a,Sa,f),m(a,G,f),e(G,Q),e(Q,vt),_(ue,vt,null),e(G,Ks),e(G,_t),e(_t,Ys),m(a,Ha,f),m(a,u,f),_(fe,u,null),e(u,Ws),e(u,wt),e(wt,Js),e(u,Qs),e(u,$t),e($t,Xs),e(u,Zs),e(u,yt),e(yt,Et),e(Et,er),e(u,tr),e(u,Dt),e(Dt,ar),e(u,sr),e(u,V),e(V,Fe),e(Fe,rr),e(Fe,jt),e(jt,nr),e(V,or),e(V,qe),e(qe,lr),e(qe,Pt),e(Pt,ir),e(V,cr),e(V,Be),e(Be,pr),e(Be,kt),e(kt,hr),e(u,dr),e(u,Tt),e(Tt,ur),e(u,fr),e(u,M),e(M,Ke),e(Ke,mr),e(Ke,xt),e(xt,gr),e(M,br),e(M,Ye),e(Ye,vr),e(Ye,Ot),e(Ot,_r),e(M,wr),e(M,We),e(We,$r),e(We,At),e(At,yr),e(u,Er),e(u,Ct),e(Ct,Dr),e(u,jr),e(u,Lt),e(Lt,It),e(It,Pr),e(u,kr),e(u,Ut),e(Ut,Tr),e(u,xr),e(u,zt),e(zt,St),e(St,Or),e(u,Ar),e(u,Ht),e(Ht,Cr),e(u,Lr),e(u,X),_(me,X,null),e(X,Ir),e(X,ge),e(ge,Ur),e(ge,Nt),e(Nt,zr),e(ge,Sr),e(u,Hr),e(u,Z),_(be,Z,null),e(Z,Nr),e(Z,Gt),e(Gt,Gr),m(a,Na,f),m(a,R,f),e(R,ee),e(ee,Vt),_(ve,Vt,null),e(R,Vr),e(R,Mt),e(Mt,Mr),m(a,Ga,f),m(a,E,f),_(_e,E,null),e(E,Rr),e(E,we),e(we,Fr),e(we,Rt),e(Rt,qr),e(we,Br),e(E,Kr),e(E,$e),e($e,Yr),e($e,Ft),e(Ft,Wr),e($e,Jr),e(E,Qr),e(E,A),_(ye,A,null),e(A,Xr),e(A,qt),e(qt,Zr),e(A,en),e(A,Ee),e(Ee,tn),e(Ee,Bt),e(Bt,an),e(Ee,sn),e(E,rn),e(E,te),_(De,te,null),e(te,nn),e(te,je),e(je,on),e(je,Kt),e(Kt,ln),e(je,cn),e(E,pn),e(E,ae),_(Pe,ae,null),e(ae,hn),e(ae,ke),e(ke,dn),e(ke,Yt),e(Yt,un),e(ke,fn),m(a,Va,f),m(a,F,f),e(F,se),e(se,Wt),_(Te,Wt,null),e(F,mn),e(F,Jt),e(Jt,gn),m(a,Ma,f),m(a,p,f),_(xe,p,null),e(p,bn),e(p,q),e(q,vn),e(q,Qt),e(Qt,_n),e(q,wn),e(q,Xt),e(Xt,$n),e(q,yn),e(p,En),e(p,Zt),e(Zt,Dn),e(p,jn),e(p,Oe),e(Oe,ea),e(ea,Pn),e(Oe,kn),e(Oe,ta),e(ta,Tn),e(p,xn),e(p,aa),e(aa,On),e(p,An),e(p,sa),e(sa,Cn),e(p,Ln),_(Ae,p,null),e(p,In),e(p,x),e(x,Un),e(x,ra),e(ra,zn),e(x,Sn),e(x,na),e(na,Hn),e(x,Nn),e(x,oa),e(oa,Gn),e(x,Vn),e(p,Mn),e(p,Ce),e(Ce,Le),e(Le,Rn),e(Le,la),e(la,Fn),e(Le,qn),e(Ce,Bn),e(Ce,ia),e(ia,Kn),e(p,Yn),e(p,Ie),e(Ie,Wn),e(Ie,ca),e(ca,Jn),e(Ie,Qn),e(p,Xn),_(Ue,p,null),e(p,Zn),e(p,B),e(B,eo),e(B,pa),e(pa,to),e(B,ao),e(B,ha),e(ha,so),e(B,ro),e(p,no),e(p,da),e(da,oo),e(p,lo),e(p,ze),e(ze,io),e(ze,ua),e(ua,co),e(ze,po),e(p,ho),e(p,fa),e(fa,uo),e(p,fo),_(Se,p,null),e(p,mo),e(p,ma),e(ma,go),e(p,bo),e(p,ga),e(ga,vo),e(p,_o),e(p,ba),e(ba,wo),e(p,$o),e(p,He),e(He,yo),e(He,va),e(va,Eo),e(He,Do),e(p,jo),_(Ne,p,null),e(p,Po),e(p,_a),e(_a,ko),e(p,To),e(p,wa),e(wa,xo),e(p,Oo),e(p,$a),e($a,Ao),e(p,Co),e(p,ya),e(ya,Lo),e(p,Io),_(Ge,p,null),e(p,Uo),e(p,Ea),e(Ea,zo),e(p,So),e(p,Je),e(Je,Da),e(Da,Ho),e(Je,No),e(p,Go),e(p,K),e(K,Vo),e(K,ja),e(ja,Mo),e(K,Ro),e(K,Pa),e(Pa,Fo),e(K,qo),Ra=!0},p:Ii,i(a){Ra||(w(ne.$$.fragment,a),w(oe.$$.fragment,a),w(le.$$.fragment,a),w(ie.$$.fragment,a),w(ce.$$.fragment,a),w(pe.$$.fragment,a),w(he.$$.fragment,a),w(de.$$.fragment,a),w(ue.$$.fragment,a),w(fe.$$.fragment,a),w(me.$$.fragment,a),w(be.$$.fragment,a),w(ve.$$.fragment,a),w(_e.$$.fragment,a),w(ye.$$.fragment,a),w(De.$$.fragment,a),w(Pe.$$.fragment,a),w(Te.$$.fragment,a),w(xe.$$.fragment,a),w(Ae.$$.fragment,a),w(Ue.$$.fragment,a),w(Se.$$.fragment,a),w(Ne.$$.fragment,a),w(Ge.$$.fragment,a),Ra=!0)},o(a){$(ne.$$.fragment,a),$(oe.$$.fragment,a),$(le.$$.fragment,a),$(ie.$$.fragment,a),$(ce.$$.fragment,a),$(pe.$$.fragment,a),$(he.$$.fragment,a),$(de.$$.fragment,a),$(ue.$$.fragment,a),$(fe.$$.fragment,a),$(me.$$.fragment,a),$(be.$$.fragment,a),$(ve.$$.fragment,a),$(_e.$$.fragment,a),$(ye.$$.fragment,a),$(De.$$.fragment,a),$(Pe.$$.fragment,a),$(Te.$$.fragment,a),$(xe.$$.fragment,a),$(Ae.$$.fragment,a),$(Ue.$$.fragment,a),$(Se.$$.fragment,a),$(Ne.$$.fragment,a),$(Ge.$$.fragment,a),Ra=!1},d(a){t(O),a&&t(Ve),a&&t(P),y(ne),a&&t(Ta),a&&t(Y),a&&t(xa),a&&t(Re),a&&t(Oa),a&&t(L),y(oe),a&&t(Aa),a&&t(I),y(le),a&&t(Ca),a&&t(U),y(ie),a&&t(La),a&&t(z),y(ce),a&&t(Ia),a&&t(S),y(pe),a&&t(Ua),a&&t(H),y(he),a&&t(za),a&&t(N),y(de),a&&t(Sa),a&&t(G),y(ue),a&&t(Ha),a&&t(u),y(fe),y(me),y(be),a&&t(Na),a&&t(R),y(ve),a&&t(Ga),a&&t(E),y(_e),y(ye),y(De),y(Pe),a&&t(Va),a&&t(F),y(Te),a&&t(Ma),a&&t(p),y(xe),y(Ae),y(Ue),y(Se),y(Ne),y(Ge)}}}const zi={local:"utilities-for-trainer",sections:[{local:"transformers.EvalPrediction",title:"Utilities"},{local:"transformers.trainer_callback.CallbackHandler",title:"Callbacks internals"},{local:"transformers.trainer_pt_utils.DistributedTensorGatherer",title:"Distributed Evaluation"},{local:"transformers.HfArgumentParser",title:"Distributed Evaluation"},{local:"transformers.debug_utils.DebugUnderflowOverflow",title:"Debug Utilities"}],title:"Utilities for Trainer"};function Si(vs,O,Ve){let{fw:P}=O;return vs.$$set=T=>{"fw"in T&&Ve(0,P=T.fw)},[P]}class Ri extends Oi{constructor(O){super();Ai(this,O,Si,Ui,Ci,{fw:0})}}export{Ri as default,zi as metadata};
